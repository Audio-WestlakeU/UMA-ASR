# python3 -m espnet2.bin.asr_unimodal_train --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/train_dev/wav.scp,speech,sound --valid_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp --config conf/train_asr_uma_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_nodup_sp/wav.scp,speech,sound --train_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_nodup_sp/text,text,text --train_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/train_dev/text,text,text --valid_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Wed Jun  7 10:41:00 CST 2023
#
/data/home/fangying/anaconda3/envs/espnet/bin/python3 /data/home/fangying/espnet/espnet2/bin/asr_unimodal_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/train_dev/wav.scp,speech,sound --valid_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp --config conf/train_asr_uma_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_nodup_sp/wav.scp,speech,sound --train_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_nodup_sp/text,text,text --train_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/train_dev/text,text,text --valid_shape_file exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 1 --multiprocessing_distributed True
[ALab02] 2023-06-07 10:41:03,238 (asr_unimodal:512) INFO: Vocabulary size: 3655
[ALab02] 2023-06-07 10:41:05,447 (abs_task:1201) INFO: pytorch.version=1.12.1, cuda.available=True, cudnn.version=8302, cudnn.benchmark=False, cudnn.deterministic=True
[ALab02] 2023-06-07 10:41:05,453 (abs_task:1202) INFO: Model structure:
UAMASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=128, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=2, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (uma): UMA(
    (linear_sigmoid): Sequential(
      (0): Linear(in_features=256, out_features=1, bias=True)
      (1): Sigmoid()
    )
  )
  (decoder): UnimodalAttentionDecoder(
    (embed): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): ReLU()
      (4): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=3655, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: UAMASRModel
    Total Number of model parameters: 42.41 M
    Number of trainable parameters: 42.41 M (100.0%)
    Size: 169.64 MB
    Type: torch.float32
[ALab02] 2023-06-07 10:41:05,453 (abs_task:1205) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0005
    lr: 1.6666666666666667e-08
    maximize: False
    weight_decay: 0
)
[ALab02] 2023-06-07 10:41:05,453 (abs_task:1206) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[ALab02] 2023-06-07 10:41:05,453 (abs_task:1215) INFO: Saving the configuration in exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/config.yaml
[ALab02] 2023-06-07 10:41:06,609 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02] 2023-06-07 10:41:11,245 (abs_task:1570) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_nodup_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_nodup_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f37a543c310>)
[ALab02] 2023-06-07 10:41:11,245 (abs_task:1571) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=2994, batch_bins=20000000, sort_in_batch=descending, sort_batch=descending)
[ALab02] 2023-06-07 10:41:11,246 (abs_task:1572) INFO: [train] mini-batch sizes summary: N-batch=2994, mean=167.2, min=2, max=981
[ALab02] 2023-06-07 10:41:11,301 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02] 2023-06-07 10:41:11,322 (abs_task:1570) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f37a543c6d0>)
[ALab02] 2023-06-07 10:41:11,322 (abs_task:1571) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=30, batch_bins=20000000, sort_in_batch=descending, sort_batch=descending)
[ALab02] 2023-06-07 10:41:11,322 (abs_task:1572) INFO: [valid] mini-batch sizes summary: N-batch=30, mean=133.3, min=43, max=291
[ALab02] 2023-06-07 10:41:11,329 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02] 2023-06-07 10:41:11,351 (abs_task:1570) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f37a543c190>)
[ALab02] 2023-06-07 10:41:11,351 (abs_task:1571) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=4000, batch_size=1, key_file=exp_uma_conformer_12e_67/asr_stats_raw_zh_char_sp/valid/speech_shape, 
[ALab02] 2023-06-07 10:41:11,351 (abs_task:1572) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
[ALab02] 2023-06-07 10:41:11,454 (trainer:284) INFO: 1/70epoch started
[ALab02] 2023-06-07 10:42:31,143 (trainer:721) INFO: 1epoch:train:1-149batch: iter_time=0.005, forward_time=0.196, loss_ctc=67.825, loss=67.825, backward_time=0.166, optim_step_time=0.035, optim0_lr0=3.333e-07, train_time=2.142
[ALab02] 2023-06-07 10:43:45,253 (trainer:721) INFO: 1epoch:train:150-298batch: iter_time=5.508e-04, forward_time=0.172, loss_ctc=51.119, loss=51.119, backward_time=0.161, optim_step_time=0.033, optim0_lr0=9.500e-07, train_time=1.992
[ALab02] 2023-06-07 10:45:03,819 (trainer:721) INFO: 1epoch:train:299-447batch: iter_time=0.029, forward_time=0.181, loss_ctc=46.144, loss=46.144, backward_time=0.167, optim_step_time=0.036, optim0_lr0=1.567e-06, train_time=2.105
[ALab02] 2023-06-07 10:46:18,463 (trainer:721) INFO: 1epoch:train:448-596batch: iter_time=1.996e-04, forward_time=0.171, loss_ctc=33.982, loss=33.982, backward_time=0.163, optim_step_time=0.032, optim0_lr0=2.192e-06, train_time=2.002
[ALab02] 2023-06-07 10:47:36,124 (trainer:721) INFO: 1epoch:train:597-745batch: iter_time=2.575e-04, forward_time=0.181, loss_ctc=32.098, loss=32.098, backward_time=0.169, optim_step_time=0.034, optim0_lr0=2.817e-06, train_time=2.090
[ALab02] 2023-06-07 10:48:49,853 (trainer:721) INFO: 1epoch:train:746-894batch: iter_time=1.977e-04, forward_time=0.169, loss_ctc=28.537, loss=28.537, backward_time=0.161, optim_step_time=0.032, optim0_lr0=3.433e-06, train_time=1.980
[ALab02] 2023-06-07 10:50:05,475 (trainer:721) INFO: 1epoch:train:895-1043batch: iter_time=2.054e-04, forward_time=0.176, loss_ctc=26.172, loss=26.172, backward_time=0.164, optim_step_time=0.032, optim0_lr0=4.050e-06, train_time=2.028
[ALab02] 2023-06-07 10:51:20,136 (trainer:721) INFO: 1epoch:train:1044-1192batch: iter_time=2.016e-04, forward_time=0.172, loss_ctc=25.028, loss=25.028, backward_time=0.162, optim_step_time=0.031, optim0_lr0=4.675e-06, train_time=2.001
[ALab02] 2023-06-07 10:52:33,903 (trainer:721) INFO: 1epoch:train:1193-1341batch: iter_time=1.974e-04, forward_time=0.167, loss_ctc=22.863, loss=22.863, backward_time=0.164, optim_step_time=0.033, optim0_lr0=5.300e-06, train_time=1.983
[ALab02] 2023-06-07 10:53:49,748 (trainer:721) INFO: 1epoch:train:1342-1490batch: iter_time=0.025, forward_time=0.174, loss_ctc=21.744, loss=21.744, backward_time=0.163, optim_step_time=0.036, optim0_lr0=5.917e-06, train_time=2.036
[ALab02] 2023-06-07 10:55:04,690 (trainer:721) INFO: 1epoch:train:1491-1639batch: iter_time=0.008, forward_time=0.172, loss_ctc=25.261, loss=25.261, backward_time=0.163, optim_step_time=0.036, optim0_lr0=6.533e-06, train_time=2.012
[ALab02] 2023-06-07 10:56:22,527 (trainer:721) INFO: 1epoch:train:1640-1788batch: iter_time=2.639e-04, forward_time=0.182, loss_ctc=21.539, loss=21.539, backward_time=0.168, optim_step_time=0.035, optim0_lr0=7.158e-06, train_time=2.085
[ALab02] 2023-06-07 10:57:38,368 (trainer:721) INFO: 1epoch:train:1789-1937batch: iter_time=0.015, forward_time=0.177, loss_ctc=22.570, loss=22.570, backward_time=0.163, optim_step_time=0.038, optim0_lr0=7.783e-06, train_time=2.042
[ALab02] 2023-06-07 10:58:54,695 (trainer:721) INFO: 1epoch:train:1938-2086batch: iter_time=0.024, forward_time=0.177, loss_ctc=21.625, loss=21.625, backward_time=0.163, optim_step_time=0.037, optim0_lr0=8.400e-06, train_time=2.048
[ALab02] 2023-06-07 11:00:16,794 (trainer:721) INFO: 1epoch:train:2087-2235batch: iter_time=0.014, forward_time=0.199, loss_ctc=19.547, loss=19.547, backward_time=0.175, optim_step_time=0.037, optim0_lr0=9.017e-06, train_time=2.205
[ALab02] 2023-06-07 11:01:35,670 (trainer:721) INFO: 1epoch:train:2236-2384batch: iter_time=0.041, forward_time=0.181, loss_ctc=19.125, loss=19.125, backward_time=0.162, optim_step_time=0.036, optim0_lr0=9.642e-06, train_time=2.111
[ALab02] 2023-06-07 11:02:51,315 (trainer:721) INFO: 1epoch:train:2385-2533batch: iter_time=2.432e-04, forward_time=0.178, loss_ctc=21.654, loss=21.654, backward_time=0.163, optim_step_time=0.035, optim0_lr0=1.027e-05, train_time=2.034
[ALab02] 2023-06-07 11:04:08,269 (trainer:721) INFO: 1epoch:train:2534-2682batch: iter_time=0.015, forward_time=0.181, loss_ctc=19.269, loss=19.269, backward_time=0.164, optim_step_time=0.036, optim0_lr0=1.088e-05, train_time=2.066
[ALab02] 2023-06-07 11:05:24,800 (trainer:721) INFO: 1epoch:train:2683-2831batch: iter_time=0.016, forward_time=0.179, loss_ctc=18.446, loss=18.446, backward_time=0.162, optim_step_time=0.037, optim0_lr0=1.150e-05, train_time=2.054
[ALab02] 2023-06-07 11:06:41,335 (trainer:721) INFO: 1epoch:train:2832-2980batch: iter_time=0.022, forward_time=0.179, loss_ctc=17.909, loss=17.909, backward_time=0.162, optim_step_time=0.035, optim0_lr0=1.212e-05, train_time=2.051
[ALab02] 2023-06-07 11:07:36,600 (trainer:338) INFO: 1epoch results: [train] iter_time=0.011, forward_time=0.178, loss_ctc=27.955, loss=27.955, backward_time=0.164, optim_step_time=0.035, optim0_lr0=6.258e-06, train_time=2.054, time=25 minutes and 37.26 seconds, total_count=2994, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=77.556, cer_ctc=1.000, cer=1.000, loss=77.556, time=14.36 seconds, total_count=30, gpu_max_cached_mem_GB=52.041, [att_plot] time=33.5 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 11:07:38,907 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 11:07:38,908 (trainer:272) INFO: 2/70epoch started. Estimated time to finish: 1 day, 6 hours and 25 minutes
[ALab02] 2023-06-07 11:09:19,752 (trainer:721) INFO: 2epoch:train:1-149batch: iter_time=0.254, forward_time=0.196, loss_ctc=17.845, loss=17.845, backward_time=0.161, optim_step_time=0.051, optim0_lr0=1.280e-05, train_time=2.714
[ALab02] 2023-06-07 11:11:04,488 (trainer:721) INFO: 2epoch:train:150-298batch: iter_time=0.277, forward_time=0.201, loss_ctc=19.448, loss=19.448, backward_time=0.163, optim_step_time=0.052, optim0_lr0=1.342e-05, train_time=2.809
[ALab02] 2023-06-07 11:12:46,230 (trainer:721) INFO: 2epoch:train:299-447batch: iter_time=0.258, forward_time=0.201, loss_ctc=17.057, loss=17.057, backward_time=0.163, optim_step_time=0.051, optim0_lr0=1.403e-05, train_time=2.742
[ALab02] 2023-06-07 11:14:13,301 (trainer:721) INFO: 2epoch:train:448-596batch: iter_time=0.150, forward_time=0.188, loss_ctc=17.374, loss=17.374, backward_time=0.162, optim_step_time=0.042, optim0_lr0=1.466e-05, train_time=2.329
[ALab02] 2023-06-07 11:15:35,873 (trainer:721) INFO: 2epoch:train:597-745batch: iter_time=0.121, forward_time=0.180, loss_ctc=16.989, loss=16.989, backward_time=0.161, optim_step_time=0.038, optim0_lr0=1.528e-05, train_time=2.221
[ALab02] 2023-06-07 11:16:52,646 (trainer:721) INFO: 2epoch:train:746-894batch: iter_time=0.022, forward_time=0.177, loss_ctc=17.798, loss=17.798, backward_time=0.162, optim_step_time=0.036, optim0_lr0=1.590e-05, train_time=2.061
[ALab02] 2023-06-07 11:18:08,526 (trainer:721) INFO: 2epoch:train:895-1043batch: iter_time=0.015, forward_time=0.175, loss_ctc=19.451, loss=19.451, backward_time=0.161, optim_step_time=0.035, optim0_lr0=1.652e-05, train_time=2.038
[ALab02] 2023-06-07 11:19:27,562 (trainer:721) INFO: 2epoch:train:1044-1192batch: iter_time=0.046, forward_time=0.185, loss_ctc=17.461, loss=17.461, backward_time=0.165, optim_step_time=0.039, optim0_lr0=1.714e-05, train_time=2.115
[ALab02] 2023-06-07 11:20:54,401 (trainer:721) INFO: 2epoch:train:1193-1341batch: iter_time=0.132, forward_time=0.190, loss_ctc=18.019, loss=18.019, backward_time=0.164, optim_step_time=0.042, optim0_lr0=1.777e-05, train_time=2.337
[ALab02] 2023-06-07 11:22:18,550 (trainer:721) INFO: 2epoch:train:1342-1490batch: iter_time=0.122, forward_time=0.192, loss_ctc=16.729, loss=16.729, backward_time=0.165, optim_step_time=0.044, optim0_lr0=1.838e-05, train_time=2.258
[ALab02] 2023-06-07 11:23:41,738 (trainer:721) INFO: 2epoch:train:1491-1639batch: iter_time=0.100, forward_time=0.191, loss_ctc=18.375, loss=18.375, backward_time=0.163, optim_step_time=0.046, optim0_lr0=1.900e-05, train_time=2.236
[ALab02] 2023-06-07 11:25:03,908 (trainer:721) INFO: 2epoch:train:1640-1788batch: iter_time=0.104, forward_time=0.187, loss_ctc=19.360, loss=19.360, backward_time=0.164, optim_step_time=0.041, optim0_lr0=1.962e-05, train_time=2.199
[ALab02] 2023-06-07 11:26:28,254 (trainer:721) INFO: 2epoch:train:1789-1937batch: iter_time=0.105, forward_time=0.197, loss_ctc=17.433, loss=17.433, backward_time=0.166, optim_step_time=0.045, optim0_lr0=2.025e-05, train_time=2.269
[ALab02] 2023-06-07 11:27:51,317 (trainer:721) INFO: 2epoch:train:1938-2086batch: iter_time=0.104, forward_time=0.192, loss_ctc=16.341, loss=16.341, backward_time=0.163, optim_step_time=0.043, optim0_lr0=2.087e-05, train_time=2.228
[ALab02] 2023-06-07 11:29:16,968 (trainer:721) INFO: 2epoch:train:2087-2235batch: iter_time=0.147, forward_time=0.191, loss_ctc=16.909, loss=16.909, backward_time=0.161, optim_step_time=0.046, optim0_lr0=2.148e-05, train_time=2.299
[ALab02] 2023-06-07 11:30:40,872 (trainer:721) INFO: 2epoch:train:2236-2384batch: iter_time=0.120, forward_time=0.189, loss_ctc=16.708, loss=16.708, backward_time=0.161, optim_step_time=0.043, optim0_lr0=2.211e-05, train_time=2.249
[ALab02] 2023-06-07 11:32:04,436 (trainer:721) INFO: 2epoch:train:2385-2533batch: iter_time=0.076, forward_time=0.196, loss_ctc=19.588, loss=19.588, backward_time=0.168, optim_step_time=0.047, optim0_lr0=2.273e-05, train_time=2.239
[ALab02] 2023-06-07 11:33:30,530 (trainer:721) INFO: 2epoch:train:2534-2682batch: iter_time=0.084, forward_time=0.201, loss_ctc=17.602, loss=17.602, backward_time=0.171, optim_step_time=0.046, optim0_lr0=2.335e-05, train_time=2.324
[ALab02] 2023-06-07 11:34:53,041 (trainer:721) INFO: 2epoch:train:2683-2831batch: iter_time=0.107, forward_time=0.189, loss_ctc=17.678, loss=17.678, backward_time=0.163, optim_step_time=0.043, optim0_lr0=2.397e-05, train_time=2.208
[ALab02] 2023-06-07 11:36:17,910 (trainer:721) INFO: 2epoch:train:2832-2980batch: iter_time=0.092, forward_time=0.196, loss_ctc=15.396, loss=15.396, backward_time=0.166, optim_step_time=0.043, optim0_lr0=2.459e-05, train_time=2.275
[ALab02] 2023-06-07 11:37:22,743 (trainer:338) INFO: 2epoch results: [train] iter_time=0.122, forward_time=0.191, loss_ctc=17.596, loss=17.596, backward_time=0.164, optim_step_time=0.044, optim0_lr0=1.872e-05, train_time=2.307, time=28 minutes and 46.82 seconds, total_count=5988, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=71.449, cer_ctc=0.998, cer=0.998, loss=71.449, time=19.83 seconds, total_count=60, gpu_max_cached_mem_GB=52.041, [att_plot] time=37.19 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 11:37:25,642 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 11:37:25,642 (trainer:272) INFO: 3/70epoch started. Estimated time to finish: 1 day, 7 hours and 52 minutes
[ALab02] 2023-06-07 11:38:49,521 (trainer:721) INFO: 3epoch:train:1-149batch: iter_time=0.110, forward_time=0.186, loss_ctc=17.609, loss=17.609, backward_time=0.162, optim_step_time=0.038, optim0_lr0=2.527e-05, train_time=2.257
[ALab02] 2023-06-07 11:40:06,984 (trainer:721) INFO: 3epoch:train:150-298batch: iter_time=0.040, forward_time=0.181, loss_ctc=17.532, loss=17.532, backward_time=0.160, optim_step_time=0.036, optim0_lr0=2.588e-05, train_time=2.081
[ALab02] 2023-06-07 11:41:25,449 (trainer:721) INFO: 3epoch:train:299-447batch: iter_time=0.046, forward_time=0.180, loss_ctc=17.042, loss=17.042, backward_time=0.161, optim_step_time=0.036, optim0_lr0=2.650e-05, train_time=2.105
[ALab02] 2023-06-07 11:42:44,096 (trainer:721) INFO: 3epoch:train:448-596batch: iter_time=0.026, forward_time=0.184, loss_ctc=15.878, loss=15.878, backward_time=0.164, optim_step_time=0.035, optim0_lr0=2.712e-05, train_time=2.106
[ALab02] 2023-06-07 11:44:00,187 (trainer:721) INFO: 3epoch:train:597-745batch: iter_time=2.718e-04, forward_time=0.180, loss_ctc=16.684, loss=16.684, backward_time=0.161, optim_step_time=0.037, optim0_lr0=2.775e-05, train_time=2.046
[ALab02] 2023-06-07 11:45:28,023 (trainer:721) INFO: 3epoch:train:746-894batch: iter_time=0.115, forward_time=0.195, loss_ctc=17.551, loss=17.551, backward_time=0.162, optim_step_time=0.047, optim0_lr0=2.837e-05, train_time=2.359
[ALab02] 2023-06-07 11:47:08,663 (trainer:721) INFO: 3epoch:train:895-1043batch: iter_time=0.252, forward_time=0.200, loss_ctc=15.931, loss=15.931, backward_time=0.160, optim_step_time=0.053, optim0_lr0=2.898e-05, train_time=2.677
[ALab02] 2023-06-07 11:48:46,475 (trainer:721) INFO: 3epoch:train:1044-1192batch: iter_time=0.229, forward_time=0.201, loss_ctc=16.566, loss=16.566, backward_time=0.161, optim_step_time=0.049, optim0_lr0=2.961e-05, train_time=2.639
[ALab02] 2023-06-07 11:50:28,040 (trainer:721) INFO: 3epoch:train:1193-1341batch: iter_time=0.257, forward_time=0.202, loss_ctc=16.366, loss=16.366, backward_time=0.159, optim_step_time=0.054, optim0_lr0=3.023e-05, train_time=2.729
[ALab02] 2023-06-07 11:52:05,174 (trainer:721) INFO: 3epoch:train:1342-1490batch: iter_time=0.239, forward_time=0.192, loss_ctc=17.523, loss=17.523, backward_time=0.158, optim_step_time=0.048, optim0_lr0=3.085e-05, train_time=2.609
[ALab02] 2023-06-07 11:53:43,281 (trainer:721) INFO: 3epoch:train:1491-1639batch: iter_time=0.235, forward_time=0.198, loss_ctc=16.480, loss=16.480, backward_time=0.162, optim_step_time=0.047, optim0_lr0=3.147e-05, train_time=2.644
[ALab02] 2023-06-07 11:55:07,023 (trainer:721) INFO: 3epoch:train:1640-1788batch: iter_time=0.123, forward_time=0.188, loss_ctc=17.823, loss=17.823, backward_time=0.162, optim_step_time=0.045, optim0_lr0=3.209e-05, train_time=2.241
[ALab02] 2023-06-07 11:56:26,981 (trainer:721) INFO: 3epoch:train:1789-1937batch: iter_time=0.108, forward_time=0.174, loss_ctc=15.650, loss=15.650, backward_time=0.160, optim_step_time=0.041, optim0_lr0=3.272e-05, train_time=2.151
[ALab02] 2023-06-07 11:57:45,871 (trainer:721) INFO: 3epoch:train:1938-2086batch: iter_time=0.109, forward_time=0.169, loss_ctc=16.615, loss=16.615, backward_time=0.160, optim_step_time=0.036, optim0_lr0=3.333e-05, train_time=2.121
[ALab02] 2023-06-07 11:59:01,957 (trainer:721) INFO: 3epoch:train:2087-2235batch: iter_time=0.059, forward_time=0.168, loss_ctc=17.440, loss=17.440, backward_time=0.160, optim_step_time=0.035, optim0_lr0=3.395e-05, train_time=2.039
[ALab02] 2023-06-07 12:00:52,483 (trainer:721) INFO: 3epoch:train:2236-2384batch: iter_time=0.299, forward_time=0.187, loss_ctc=16.085, loss=16.085, backward_time=0.160, optim_step_time=0.054, optim0_lr0=3.458e-05, train_time=2.944
[ALab02] 2023-06-07 12:03:02,396 (trainer:721) INFO: 3epoch:train:2385-2533batch: iter_time=0.444, forward_time=0.198, loss_ctc=17.781, loss=17.781, backward_time=0.164, optim_step_time=0.066, optim0_lr0=3.520e-05, train_time=3.489
[ALab02] 2023-06-07 12:05:03,776 (trainer:721) INFO: 3epoch:train:2534-2682batch: iter_time=0.388, forward_time=0.200, loss_ctc=17.215, loss=17.215, backward_time=0.163, optim_step_time=0.061, optim0_lr0=3.582e-05, train_time=3.271
[ALab02] 2023-06-07 12:06:59,309 (trainer:721) INFO: 3epoch:train:2683-2831batch: iter_time=0.355, forward_time=0.196, loss_ctc=16.525, loss=16.525, backward_time=0.162, optim_step_time=0.058, optim0_lr0=3.643e-05, train_time=3.088
[ALab02] 2023-06-07 12:08:55,276 (trainer:721) INFO: 3epoch:train:2832-2980batch: iter_time=0.368, forward_time=0.188, loss_ctc=16.252, loss=16.252, backward_time=0.160, optim_step_time=0.053, optim0_lr0=3.706e-05, train_time=3.114
[ALab02] 2023-06-07 12:10:16,059 (trainer:338) INFO: 3epoch results: [train] iter_time=0.192, forward_time=0.188, loss_ctc=16.778, loss=16.778, backward_time=0.161, optim_step_time=0.046, optim0_lr0=3.119e-05, train_time=2.541, time=31 minutes and 42.77 seconds, total_count=8982, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=68.081, cer_ctc=0.964, cer=0.964, loss=68.081, time=23.28 seconds, total_count=90, gpu_max_cached_mem_GB=52.041, [att_plot] time=44.36 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 12:10:19,695 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 12:10:19,695 (trainer:272) INFO: 4/70epoch started. Estimated time to finish: 1 day, 9 hours and 10 minutes
[ALab02] 2023-06-07 12:11:47,448 (trainer:721) INFO: 4epoch:train:1-149batch: iter_time=0.174, forward_time=0.183, loss_ctc=15.833, loss=15.833, backward_time=0.161, optim_step_time=0.044, optim0_lr0=3.773e-05, train_time=2.361
[ALab02] 2023-06-07 12:13:07,513 (trainer:721) INFO: 4epoch:train:150-298batch: iter_time=0.084, forward_time=0.177, loss_ctc=17.243, loss=17.243, backward_time=0.160, optim_step_time=0.041, optim0_lr0=3.835e-05, train_time=2.151
[ALab02] 2023-06-07 12:14:31,286 (trainer:721) INFO: 4epoch:train:299-447batch: iter_time=0.120, forward_time=0.173, loss_ctc=15.525, loss=15.525, backward_time=0.158, optim_step_time=0.040, optim0_lr0=3.897e-05, train_time=2.253
[ALab02] 2023-06-07 12:15:47,919 (trainer:721) INFO: 4epoch:train:448-596batch: iter_time=0.069, forward_time=0.167, loss_ctc=15.693, loss=15.693, backward_time=0.157, optim_step_time=0.037, optim0_lr0=3.959e-05, train_time=2.049
[ALab02] 2023-06-07 12:17:08,436 (trainer:721) INFO: 4epoch:train:597-745batch: iter_time=0.132, forward_time=0.170, loss_ctc=16.473, loss=16.473, backward_time=0.158, optim_step_time=0.042, optim0_lr0=4.022e-05, train_time=2.168
[ALab02] 2023-06-07 12:18:33,209 (trainer:721) INFO: 4epoch:train:746-894batch: iter_time=0.163, forward_time=0.175, loss_ctc=16.186, loss=16.186, backward_time=0.158, optim_step_time=0.046, optim0_lr0=4.083e-05, train_time=2.270
[ALab02] 2023-06-07 12:19:57,847 (trainer:721) INFO: 4epoch:train:895-1043batch: iter_time=0.157, forward_time=0.177, loss_ctc=15.649, loss=15.649, backward_time=0.157, optim_step_time=0.043, optim0_lr0=4.145e-05, train_time=2.265
[ALab02] 2023-06-07 12:21:21,185 (trainer:721) INFO: 4epoch:train:1044-1192batch: iter_time=0.134, forward_time=0.176, loss_ctc=15.591, loss=15.591, backward_time=0.158, optim_step_time=0.045, optim0_lr0=4.208e-05, train_time=2.243
[ALab02] 2023-06-07 12:22:47,206 (trainer:721) INFO: 4epoch:train:1193-1341batch: iter_time=0.175, forward_time=0.178, loss_ctc=16.252, loss=16.252, backward_time=0.157, optim_step_time=0.047, optim0_lr0=4.270e-05, train_time=2.316
[ALab02] 2023-06-07 12:24:15,995 (trainer:721) INFO: 4epoch:train:1342-1490batch: iter_time=0.191, forward_time=0.180, loss_ctc=16.441, loss=16.441, backward_time=0.159, optim_step_time=0.049, optim0_lr0=4.332e-05, train_time=2.379
[ALab02] 2023-06-07 12:25:36,337 (trainer:721) INFO: 4epoch:train:1491-1639batch: iter_time=0.124, forward_time=0.176, loss_ctc=15.494, loss=15.494, backward_time=0.157, optim_step_time=0.044, optim0_lr0=4.393e-05, train_time=2.160
[ALab02] 2023-06-07 12:26:52,816 (trainer:721) INFO: 4epoch:train:1640-1788batch: iter_time=0.074, forward_time=0.169, loss_ctc=15.453, loss=15.453, backward_time=0.156, optim_step_time=0.042, optim0_lr0=4.456e-05, train_time=2.050
[ALab02] 2023-06-07 12:28:08,392 (trainer:721) INFO: 4epoch:train:1789-1937batch: iter_time=0.039, forward_time=0.170, loss_ctc=15.494, loss=15.494, backward_time=0.158, optim_step_time=0.038, optim0_lr0=4.518e-05, train_time=2.033
[ALab02] 2023-06-07 12:29:25,946 (trainer:721) INFO: 4epoch:train:1938-2086batch: iter_time=0.048, forward_time=0.172, loss_ctc=16.245, loss=16.245, backward_time=0.159, optim_step_time=0.041, optim0_lr0=4.580e-05, train_time=2.084
[ALab02] 2023-06-07 12:30:39,634 (trainer:721) INFO: 4epoch:train:2087-2235batch: iter_time=0.001, forward_time=0.167, loss_ctc=15.752, loss=15.752, backward_time=0.159, optim_step_time=0.036, optim0_lr0=4.642e-05, train_time=1.978
[ALab02] 2023-06-07 12:31:51,722 (trainer:721) INFO: 4epoch:train:2236-2384batch: iter_time=2.330e-04, forward_time=0.164, loss_ctc=14.168, loss=14.168, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.704e-05, train_time=1.931
[ALab02] 2023-06-07 12:33:04,402 (trainer:721) INFO: 4epoch:train:2385-2533batch: iter_time=2.228e-04, forward_time=0.165, loss_ctc=16.239, loss=16.239, backward_time=0.158, optim_step_time=0.032, optim0_lr0=4.767e-05, train_time=1.954
[ALab02] 2023-06-07 12:34:18,602 (trainer:721) INFO: 4epoch:train:2534-2682batch: iter_time=0.021, forward_time=0.166, loss_ctc=14.627, loss=14.627, backward_time=0.156, optim_step_time=0.037, optim0_lr0=4.828e-05, train_time=1.995
[ALab02] 2023-06-07 12:35:31,291 (trainer:721) INFO: 4epoch:train:2683-2831batch: iter_time=2.555e-04, forward_time=0.164, loss_ctc=14.144, loss=14.144, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.890e-05, train_time=1.951
[ALab02] 2023-06-07 12:36:44,522 (trainer:721) INFO: 4epoch:train:2832-2980batch: iter_time=2.549e-04, forward_time=0.165, loss_ctc=15.617, loss=15.617, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.953e-05, train_time=1.960
[ALab02] 2023-06-07 12:37:33,266 (trainer:338) INFO: 4epoch results: [train] iter_time=0.085, forward_time=0.172, loss_ctc=15.681, loss=15.681, backward_time=0.158, optim_step_time=0.040, optim0_lr0=4.366e-05, train_time=2.126, time=26 minutes and 31.8 seconds, total_count=11976, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=58.129, cer_ctc=0.844, cer=0.844, loss=58.129, time=14.72 seconds, total_count=120, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.04 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 12:37:35,731 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 12:37:35,731 (trainer:272) INFO: 5/70epoch started. Estimated time to finish: 1 day, 8 hours and 40.56 seconds
[ALab02] 2023-06-07 12:38:49,200 (trainer:721) INFO: 5epoch:train:1-149batch: iter_time=0.016, forward_time=0.165, loss_ctc=15.523, loss=15.523, backward_time=0.156, optim_step_time=0.035, optim0_lr0=5.020e-05, train_time=1.977
[ALab02] 2023-06-07 12:40:02,436 (trainer:721) INFO: 5epoch:train:150-298batch: iter_time=3.233e-04, forward_time=0.166, loss_ctc=14.277, loss=14.277, backward_time=0.157, optim_step_time=0.036, optim0_lr0=5.082e-05, train_time=1.964
[ALab02] 2023-06-07 12:41:15,236 (trainer:721) INFO: 5epoch:train:299-447batch: iter_time=5.309e-04, forward_time=0.165, loss_ctc=15.347, loss=15.347, backward_time=0.157, optim_step_time=0.034, optim0_lr0=5.143e-05, train_time=1.952
[ALab02] 2023-06-07 12:42:28,129 (trainer:721) INFO: 5epoch:train:448-596batch: iter_time=2.963e-04, forward_time=0.166, loss_ctc=14.073, loss=14.073, backward_time=0.156, optim_step_time=0.035, optim0_lr0=5.206e-05, train_time=1.956
[ALab02] 2023-06-07 12:43:41,058 (trainer:721) INFO: 5epoch:train:597-745batch: iter_time=2.757e-04, forward_time=0.167, loss_ctc=14.462, loss=14.462, backward_time=0.157, optim_step_time=0.035, optim0_lr0=5.268e-05, train_time=1.962
[ALab02] 2023-06-07 12:44:53,645 (trainer:721) INFO: 5epoch:train:746-894batch: iter_time=4.149e-04, forward_time=0.166, loss_ctc=13.648, loss=13.648, backward_time=0.155, optim_step_time=0.035, optim0_lr0=5.330e-05, train_time=1.949
[ALab02] 2023-06-07 12:46:05,917 (trainer:721) INFO: 5epoch:train:895-1043batch: iter_time=6.994e-04, forward_time=0.164, loss_ctc=14.823, loss=14.823, backward_time=0.155, optim_step_time=0.034, optim0_lr0=5.392e-05, train_time=1.939
[ALab02] 2023-06-07 12:47:18,158 (trainer:721) INFO: 5epoch:train:1044-1192batch: iter_time=2.670e-04, forward_time=0.164, loss_ctc=13.917, loss=13.917, backward_time=0.155, optim_step_time=0.033, optim0_lr0=5.454e-05, train_time=1.935
[ALab02] 2023-06-07 12:48:30,373 (trainer:721) INFO: 5epoch:train:1193-1341batch: iter_time=2.658e-04, forward_time=0.165, loss_ctc=14.452, loss=14.452, backward_time=0.155, optim_step_time=0.033, optim0_lr0=5.517e-05, train_time=1.943
[ALab02] 2023-06-07 12:49:43,038 (trainer:721) INFO: 5epoch:train:1342-1490batch: iter_time=7.034e-04, forward_time=0.166, loss_ctc=13.513, loss=13.513, backward_time=0.156, optim_step_time=0.033, optim0_lr0=5.578e-05, train_time=1.950
[ALab02] 2023-06-07 12:50:56,363 (trainer:721) INFO: 5epoch:train:1491-1639batch: iter_time=0.012, forward_time=0.164, loss_ctc=14.452, loss=14.452, backward_time=0.156, optim_step_time=0.036, optim0_lr0=5.640e-05, train_time=1.970
[ALab02] 2023-06-07 12:52:11,091 (trainer:721) INFO: 5epoch:train:1640-1788batch: iter_time=0.013, forward_time=0.167, loss_ctc=13.923, loss=13.923, backward_time=0.158, optim_step_time=0.034, optim0_lr0=5.702e-05, train_time=2.000
[ALab02] 2023-06-07 12:53:23,287 (trainer:721) INFO: 5epoch:train:1789-1937batch: iter_time=2.829e-04, forward_time=0.164, loss_ctc=13.713, loss=13.713, backward_time=0.155, optim_step_time=0.035, optim0_lr0=5.765e-05, train_time=1.944
[ALab02] 2023-06-07 12:54:36,090 (trainer:721) INFO: 5epoch:train:1938-2086batch: iter_time=2.861e-04, forward_time=0.166, loss_ctc=13.179, loss=13.179, backward_time=0.156, optim_step_time=0.033, optim0_lr0=5.827e-05, train_time=1.954
[ALab02] 2023-06-07 12:55:48,970 (trainer:721) INFO: 5epoch:train:2087-2235batch: iter_time=2.315e-04, forward_time=0.166, loss_ctc=12.745, loss=12.745, backward_time=0.156, optim_step_time=0.033, optim0_lr0=5.888e-05, train_time=1.954
[ALab02] 2023-06-07 12:57:01,931 (trainer:721) INFO: 5epoch:train:2236-2384batch: iter_time=2.332e-04, forward_time=0.165, loss_ctc=12.633, loss=12.633, backward_time=0.156, optim_step_time=0.034, optim0_lr0=5.951e-05, train_time=1.955
[ALab02] 2023-06-07 12:58:14,319 (trainer:721) INFO: 5epoch:train:2385-2533batch: iter_time=0.003, forward_time=0.164, loss_ctc=13.430, loss=13.430, backward_time=0.156, optim_step_time=0.034, optim0_lr0=6.013e-05, train_time=1.949
[ALab02] 2023-06-07 12:59:26,234 (trainer:721) INFO: 5epoch:train:2534-2682batch: iter_time=3.177e-04, forward_time=0.162, loss_ctc=13.743, loss=13.743, backward_time=0.154, optim_step_time=0.034, optim0_lr0=6.075e-05, train_time=1.931
[ALab02] 2023-06-07 13:00:38,178 (trainer:721) INFO: 5epoch:train:2683-2831batch: iter_time=2.318e-04, forward_time=0.162, loss_ctc=13.533, loss=13.533, backward_time=0.155, optim_step_time=0.035, optim0_lr0=6.137e-05, train_time=1.931
[ALab02] 2023-06-07 13:01:50,702 (trainer:721) INFO: 5epoch:train:2832-2980batch: iter_time=2.262e-04, forward_time=0.165, loss_ctc=13.751, loss=13.751, backward_time=0.155, optim_step_time=0.034, optim0_lr0=6.199e-05, train_time=1.941
[ALab02] 2023-06-07 13:02:39,731 (trainer:338) INFO: 5epoch results: [train] iter_time=0.003, forward_time=0.165, loss_ctc=13.928, loss=13.928, backward_time=0.156, optim_step_time=0.034, optim0_lr0=5.612e-05, train_time=1.953, time=24 minutes and 21.75 seconds, total_count=14970, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=48.614, cer_ctc=0.749, cer=0.749, loss=48.614, time=14.83 seconds, total_count=150, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.41 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 13:02:42,041 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 13:02:42,042 (trainer:272) INFO: 6/70epoch started. Estimated time to finish: 1 day, 6 hours and 39 minutes
[ALab02] 2023-06-07 13:03:54,731 (trainer:721) INFO: 6epoch:train:1-149batch: iter_time=0.012, forward_time=0.164, loss_ctc=12.557, loss=12.557, backward_time=0.153, optim_step_time=0.035, optim0_lr0=6.267e-05, train_time=1.956
[ALab02] 2023-06-07 13:05:07,633 (trainer:721) INFO: 6epoch:train:150-298batch: iter_time=2.866e-04, forward_time=0.166, loss_ctc=13.819, loss=13.819, backward_time=0.156, optim_step_time=0.036, optim0_lr0=6.328e-05, train_time=1.956
[ALab02] 2023-06-07 13:06:20,695 (trainer:721) INFO: 6epoch:train:299-447batch: iter_time=2.739e-04, forward_time=0.167, loss_ctc=12.806, loss=12.806, backward_time=0.156, optim_step_time=0.033, optim0_lr0=6.390e-05, train_time=1.962
[ALab02] 2023-06-07 13:07:33,022 (trainer:721) INFO: 6epoch:train:448-596batch: iter_time=0.002, forward_time=0.164, loss_ctc=12.666, loss=12.666, backward_time=0.154, optim_step_time=0.034, optim0_lr0=6.453e-05, train_time=1.937
[ALab02] 2023-06-07 13:08:45,426 (trainer:721) INFO: 6epoch:train:597-745batch: iter_time=2.273e-04, forward_time=0.164, loss_ctc=13.372, loss=13.372, backward_time=0.156, optim_step_time=0.034, optim0_lr0=6.515e-05, train_time=1.947
[ALab02] 2023-06-07 13:09:58,150 (trainer:721) INFO: 6epoch:train:746-894batch: iter_time=0.017, forward_time=0.163, loss_ctc=12.040, loss=12.040, backward_time=0.153, optim_step_time=0.035, optim0_lr0=6.577e-05, train_time=1.954
[ALab02] 2023-06-07 13:11:11,626 (trainer:721) INFO: 6epoch:train:895-1043batch: iter_time=0.027, forward_time=0.164, loss_ctc=12.480, loss=12.480, backward_time=0.155, optim_step_time=0.035, optim0_lr0=6.638e-05, train_time=1.973
[ALab02] 2023-06-07 13:12:24,221 (trainer:721) INFO: 6epoch:train:1044-1192batch: iter_time=9.330e-04, forward_time=0.165, loss_ctc=11.664, loss=11.664, backward_time=0.156, optim_step_time=0.033, optim0_lr0=6.701e-05, train_time=1.942
[ALab02] 2023-06-07 13:13:36,580 (trainer:721) INFO: 6epoch:train:1193-1341batch: iter_time=0.001, forward_time=0.164, loss_ctc=13.164, loss=13.164, backward_time=0.156, optim_step_time=0.034, optim0_lr0=6.763e-05, train_time=1.947
[ALab02] 2023-06-07 13:14:49,503 (trainer:721) INFO: 6epoch:train:1342-1490batch: iter_time=2.544e-04, forward_time=0.165, loss_ctc=12.320, loss=12.320, backward_time=0.157, optim_step_time=0.035, optim0_lr0=6.825e-05, train_time=1.961
[ALab02] 2023-06-07 13:16:01,703 (trainer:721) INFO: 6epoch:train:1491-1639batch: iter_time=2.236e-04, forward_time=0.165, loss_ctc=11.379, loss=11.379, backward_time=0.154, optim_step_time=0.034, optim0_lr0=6.887e-05, train_time=1.932
[ALab02] 2023-06-07 13:17:34,279 (trainer:721) INFO: 6epoch:train:1640-1788batch: iter_time=0.165, forward_time=0.184, loss_ctc=12.615, loss=12.615, backward_time=0.158, optim_step_time=0.051, optim0_lr0=6.949e-05, train_time=2.472
[ALab02] 2023-06-07 13:19:25,437 (trainer:721) INFO: 6epoch:train:1789-1937batch: iter_time=0.334, forward_time=0.192, loss_ctc=12.477, loss=12.477, backward_time=0.157, optim_step_time=0.058, optim0_lr0=7.012e-05, train_time=2.987
[ALab02] 2023-06-07 13:21:19,220 (trainer:721) INFO: 6epoch:train:1938-2086batch: iter_time=0.350, forward_time=0.193, loss_ctc=12.159, loss=12.159, backward_time=0.158, optim_step_time=0.059, optim0_lr0=7.073e-05, train_time=3.046
[ALab02] 2023-06-07 13:23:16,879 (trainer:721) INFO: 6epoch:train:2087-2235batch: iter_time=0.375, forward_time=0.193, loss_ctc=11.802, loss=11.802, backward_time=0.157, optim_step_time=0.059, optim0_lr0=7.135e-05, train_time=3.173
[ALab02] 2023-06-07 13:25:09,973 (trainer:721) INFO: 6epoch:train:2236-2384batch: iter_time=0.338, forward_time=0.197, loss_ctc=12.304, loss=12.304, backward_time=0.159, optim_step_time=0.062, optim0_lr0=7.198e-05, train_time=3.026
[ALab02] 2023-06-07 13:27:00,240 (trainer:721) INFO: 6epoch:train:2385-2533batch: iter_time=0.326, forward_time=0.194, loss_ctc=11.439, loss=11.439, backward_time=0.157, optim_step_time=0.059, optim0_lr0=7.260e-05, train_time=2.964
[ALab02] 2023-06-07 13:28:26,906 (trainer:721) INFO: 6epoch:train:2534-2682batch: iter_time=0.183, forward_time=0.176, loss_ctc=12.725, loss=12.725, backward_time=0.156, optim_step_time=0.048, optim0_lr0=7.322e-05, train_time=2.333
[ALab02] 2023-06-07 13:29:49,522 (trainer:721) INFO: 6epoch:train:2683-2831batch: iter_time=0.123, forward_time=0.176, loss_ctc=11.504, loss=11.504, backward_time=0.157, optim_step_time=0.042, optim0_lr0=7.383e-05, train_time=2.223
[ALab02] 2023-06-07 13:31:06,232 (trainer:721) INFO: 6epoch:train:2832-2980batch: iter_time=0.082, forward_time=0.167, loss_ctc=11.964, loss=11.964, backward_time=0.154, optim_step_time=0.038, optim0_lr0=7.446e-05, train_time=2.052
[ALab02] 2023-06-07 13:31:55,709 (trainer:338) INFO: 6epoch results: [train] iter_time=0.117, forward_time=0.174, loss_ctc=12.336, loss=12.336, backward_time=0.156, optim_step_time=0.043, optim0_lr0=6.859e-05, train_time=2.286, time=28 minutes and 31.58 seconds, total_count=17964, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=41.436, cer_ctc=0.686, cer=0.686, loss=41.436, time=14.3 seconds, total_count=180, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.78 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 13:31:58,558 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 13:31:58,559 (trainer:272) INFO: 7/70epoch started. Estimated time to finish: 1 day, 6 hours and 21 minutes
[ALab02] 2023-06-07 13:33:19,276 (trainer:721) INFO: 7epoch:train:1-149batch: iter_time=0.101, forward_time=0.174, loss_ctc=11.028, loss=11.028, backward_time=0.155, optim_step_time=0.044, optim0_lr0=7.513e-05, train_time=2.170
[ALab02] 2023-06-07 13:34:56,549 (trainer:721) INFO: 7epoch:train:150-298batch: iter_time=0.244, forward_time=0.189, loss_ctc=11.897, loss=11.897, backward_time=0.157, optim_step_time=0.056, optim0_lr0=7.575e-05, train_time=2.610
[ALab02] 2023-06-07 13:36:36,000 (trainer:721) INFO: 7epoch:train:299-447batch: iter_time=0.252, forward_time=0.191, loss_ctc=11.804, loss=11.804, backward_time=0.160, optim_step_time=0.060, optim0_lr0=7.637e-05, train_time=2.672
[ALab02] 2023-06-07 13:38:18,641 (trainer:721) INFO: 7epoch:train:448-596batch: iter_time=0.272, forward_time=0.193, loss_ctc=11.546, loss=11.546, backward_time=0.160, optim_step_time=0.058, optim0_lr0=7.699e-05, train_time=2.745
[ALab02] 2023-06-07 13:39:57,436 (trainer:721) INFO: 7epoch:train:597-745batch: iter_time=0.242, forward_time=0.195, loss_ctc=11.538, loss=11.538, backward_time=0.160, optim_step_time=0.060, optim0_lr0=7.762e-05, train_time=2.659
[ALab02] 2023-06-07 13:41:35,680 (trainer:721) INFO: 7epoch:train:746-894batch: iter_time=0.247, forward_time=0.188, loss_ctc=12.199, loss=12.199, backward_time=0.161, optim_step_time=0.058, optim0_lr0=7.823e-05, train_time=2.634
[ALab02] 2023-06-07 13:43:07,398 (trainer:721) INFO: 7epoch:train:895-1043batch: iter_time=0.186, forward_time=0.190, loss_ctc=10.993, loss=10.993, backward_time=0.159, optim_step_time=0.058, optim0_lr0=7.885e-05, train_time=2.455
[ALab02] 2023-06-07 13:44:30,265 (trainer:721) INFO: 7epoch:train:1044-1192batch: iter_time=0.133, forward_time=0.180, loss_ctc=12.477, loss=12.477, backward_time=0.160, optim_step_time=0.048, optim0_lr0=7.947e-05, train_time=2.233
[ALab02] 2023-06-07 13:45:49,256 (trainer:721) INFO: 7epoch:train:1193-1341batch: iter_time=0.103, forward_time=0.170, loss_ctc=11.292, loss=11.292, backward_time=0.157, optim_step_time=0.039, optim0_lr0=8.010e-05, train_time=2.126
[ALab02] 2023-06-07 13:47:05,971 (trainer:721) INFO: 7epoch:train:1342-1490batch: iter_time=0.055, forward_time=0.170, loss_ctc=11.805, loss=11.805, backward_time=0.162, optim_step_time=0.036, optim0_lr0=8.072e-05, train_time=2.058
[ALab02] 2023-06-07 13:48:19,519 (trainer:721) INFO: 7epoch:train:1491-1639batch: iter_time=0.036, forward_time=0.166, loss_ctc=11.020, loss=11.020, backward_time=0.158, optim_step_time=0.034, optim0_lr0=8.133e-05, train_time=1.977
[ALab02] 2023-06-07 13:49:32,545 (trainer:721) INFO: 7epoch:train:1640-1788batch: iter_time=0.011, forward_time=0.165, loss_ctc=11.116, loss=11.116, backward_time=0.157, optim_step_time=0.034, optim0_lr0=8.196e-05, train_time=1.955
[ALab02] 2023-06-07 13:50:47,028 (trainer:721) INFO: 7epoch:train:1789-1937batch: iter_time=0.014, forward_time=0.166, loss_ctc=11.456, loss=11.456, backward_time=0.161, optim_step_time=0.035, optim0_lr0=8.258e-05, train_time=2.004
[ALab02] 2023-06-07 13:52:02,742 (trainer:721) INFO: 7epoch:train:1938-2086batch: iter_time=0.044, forward_time=0.167, loss_ctc=11.630, loss=11.630, backward_time=0.159, optim_step_time=0.036, optim0_lr0=8.320e-05, train_time=2.032
[ALab02] 2023-06-07 13:53:23,632 (trainer:721) INFO: 7epoch:train:2087-2235batch: iter_time=0.097, forward_time=0.168, loss_ctc=10.740, loss=10.740, backward_time=0.159, optim_step_time=0.038, optim0_lr0=8.382e-05, train_time=2.173
[ALab02] 2023-06-07 13:54:37,403 (trainer:721) INFO: 7epoch:train:2236-2384batch: iter_time=0.008, forward_time=0.165, loss_ctc=11.339, loss=11.339, backward_time=0.159, optim_step_time=0.034, optim0_lr0=8.444e-05, train_time=1.976
[ALab02] 2023-06-07 13:55:50,405 (trainer:721) INFO: 7epoch:train:2385-2533batch: iter_time=0.005, forward_time=0.167, loss_ctc=10.859, loss=10.859, backward_time=0.158, optim_step_time=0.034, optim0_lr0=8.507e-05, train_time=1.963
[ALab02] 2023-06-07 13:57:02,893 (trainer:721) INFO: 7epoch:train:2534-2682batch: iter_time=0.004, forward_time=0.162, loss_ctc=11.177, loss=11.177, backward_time=0.157, optim_step_time=0.034, optim0_lr0=8.568e-05, train_time=1.945
[ALab02] 2023-06-07 13:58:16,083 (trainer:721) INFO: 7epoch:train:2683-2831batch: iter_time=0.004, forward_time=0.166, loss_ctc=10.977, loss=10.977, backward_time=0.159, optim_step_time=0.033, optim0_lr0=8.630e-05, train_time=1.968
[ALab02] 2023-06-07 13:59:30,424 (trainer:721) INFO: 7epoch:train:2832-2980batch: iter_time=0.007, forward_time=0.168, loss_ctc=11.951, loss=11.951, backward_time=0.160, optim_step_time=0.036, optim0_lr0=8.692e-05, train_time=1.988
[ALab02] 2023-06-07 14:00:17,972 (trainer:338) INFO: 7epoch results: [train] iter_time=0.103, forward_time=0.175, loss_ctc=11.432, loss=11.432, backward_time=0.159, optim_step_time=0.043, optim0_lr0=8.106e-05, train_time=2.216, time=27 minutes and 38.92 seconds, total_count=20958, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=38.795, cer_ctc=0.662, cer=0.662, loss=38.795, time=13.85 seconds, total_count=210, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.64 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 14:00:20,299 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 14:00:20,299 (trainer:272) INFO: 8/70epoch started. Estimated time to finish: 1 day, 5 hours and 52 minutes
[ALab02] 2023-06-07 14:01:33,780 (trainer:721) INFO: 8epoch:train:1-149batch: iter_time=0.007, forward_time=0.164, loss_ctc=10.983, loss=10.983, backward_time=0.158, optim_step_time=0.035, optim0_lr0=8.760e-05, train_time=1.977
[ALab02] 2023-06-07 14:03:10,701 (trainer:721) INFO: 8epoch:train:150-298batch: iter_time=0.236, forward_time=0.188, loss_ctc=11.227, loss=11.227, backward_time=0.162, optim_step_time=0.054, optim0_lr0=8.822e-05, train_time=2.598
[ALab02] 2023-06-07 14:04:50,078 (trainer:721) INFO: 8epoch:train:299-447batch: iter_time=0.265, forward_time=0.182, loss_ctc=10.470, loss=10.470, backward_time=0.159, optim_step_time=0.054, optim0_lr0=8.883e-05, train_time=2.665
[ALab02] 2023-06-07 14:06:27,516 (trainer:721) INFO: 8epoch:train:448-596batch: iter_time=0.242, forward_time=0.186, loss_ctc=12.148, loss=12.148, backward_time=0.161, optim_step_time=0.050, optim0_lr0=8.946e-05, train_time=2.613
[ALab02] 2023-06-07 14:08:02,513 (trainer:721) INFO: 8epoch:train:597-745batch: iter_time=0.223, forward_time=0.190, loss_ctc=11.355, loss=11.355, backward_time=0.162, optim_step_time=0.054, optim0_lr0=9.008e-05, train_time=2.554
[ALab02] 2023-06-07 14:09:35,326 (trainer:721) INFO: 8epoch:train:746-894batch: iter_time=0.222, forward_time=0.180, loss_ctc=11.244, loss=11.244, backward_time=0.159, optim_step_time=0.049, optim0_lr0=9.070e-05, train_time=2.488
[ALab02] 2023-06-07 14:11:05,182 (trainer:721) INFO: 8epoch:train:895-1043batch: iter_time=0.198, forward_time=0.182, loss_ctc=11.500, loss=11.500, backward_time=0.159, optim_step_time=0.049, optim0_lr0=9.132e-05, train_time=2.403
[ALab02] 2023-06-07 14:12:26,005 (trainer:721) INFO: 8epoch:train:1044-1192batch: iter_time=0.086, forward_time=0.177, loss_ctc=11.881, loss=11.881, backward_time=0.160, optim_step_time=0.045, optim0_lr0=9.194e-05, train_time=2.183
[ALab02] 2023-06-07 14:13:45,825 (trainer:721) INFO: 8epoch:train:1193-1341batch: iter_time=0.063, forward_time=0.175, loss_ctc=11.635, loss=11.635, backward_time=0.161, optim_step_time=0.040, optim0_lr0=9.257e-05, train_time=2.148
[ALab02] 2023-06-07 14:14:58,418 (trainer:721) INFO: 8epoch:train:1342-1490batch: iter_time=2.206e-04, forward_time=0.165, loss_ctc=10.961, loss=10.961, backward_time=0.157, optim_step_time=0.035, optim0_lr0=9.318e-05, train_time=1.948
[ALab02] 2023-06-07 14:16:12,114 (trainer:721) INFO: 8epoch:train:1491-1639batch: iter_time=2.381e-04, forward_time=0.164, loss_ctc=11.899, loss=11.899, backward_time=0.161, optim_step_time=0.033, optim0_lr0=9.380e-05, train_time=1.979
[ALab02] 2023-06-07 14:17:33,490 (trainer:721) INFO: 8epoch:train:1640-1788batch: iter_time=0.127, forward_time=0.174, loss_ctc=10.803, loss=10.803, backward_time=0.158, optim_step_time=0.045, optim0_lr0=9.443e-05, train_time=2.175
[ALab02] 2023-06-07 14:18:50,475 (trainer:721) INFO: 8epoch:train:1789-1937batch: iter_time=0.086, forward_time=0.172, loss_ctc=10.599, loss=10.599, backward_time=0.158, optim_step_time=0.043, optim0_lr0=9.505e-05, train_time=2.071
[ALab02] 2023-06-07 14:20:13,860 (trainer:721) INFO: 8epoch:train:1938-2086batch: iter_time=0.143, forward_time=0.177, loss_ctc=11.399, loss=11.399, backward_time=0.160, optim_step_time=0.045, optim0_lr0=9.567e-05, train_time=2.230
[ALab02] 2023-06-07 14:21:38,993 (trainer:721) INFO: 8epoch:train:2087-2235batch: iter_time=0.147, forward_time=0.181, loss_ctc=10.495, loss=10.495, backward_time=0.161, optim_step_time=0.045, optim0_lr0=9.628e-05, train_time=2.292
[ALab02] 2023-06-07 14:23:07,105 (trainer:721) INFO: 8epoch:train:2236-2384batch: iter_time=0.178, forward_time=0.182, loss_ctc=10.293, loss=10.293, backward_time=0.161, optim_step_time=0.048, optim0_lr0=9.691e-05, train_time=2.358
[ALab02] 2023-06-07 14:24:36,734 (trainer:721) INFO: 8epoch:train:2385-2533batch: iter_time=0.199, forward_time=0.180, loss_ctc=10.307, loss=10.307, backward_time=0.158, optim_step_time=0.050, optim0_lr0=9.753e-05, train_time=2.409
[ALab02] 2023-06-07 14:25:58,299 (trainer:721) INFO: 8epoch:train:2534-2682batch: iter_time=0.124, forward_time=0.179, loss_ctc=10.909, loss=10.909, backward_time=0.160, optim_step_time=0.044, optim0_lr0=9.815e-05, train_time=2.191
[ALab02] 2023-06-07 14:27:17,953 (trainer:721) INFO: 8epoch:train:2683-2831batch: iter_time=0.098, forward_time=0.174, loss_ctc=10.217, loss=10.217, backward_time=0.159, optim_step_time=0.042, optim0_lr0=9.877e-05, train_time=2.142
[ALab02] 2023-06-07 14:28:32,466 (trainer:721) INFO: 8epoch:train:2832-2980batch: iter_time=0.033, forward_time=0.168, loss_ctc=11.305, loss=11.305, backward_time=0.159, optim_step_time=0.037, optim0_lr0=9.939e-05, train_time=1.996
[ALab02] 2023-06-07 14:29:22,100 (trainer:338) INFO: 8epoch results: [train] iter_time=0.133, forward_time=0.177, loss_ctc=11.055, loss=11.055, backward_time=0.160, optim_step_time=0.045, optim0_lr0=9.353e-05, train_time=2.270, time=28 minutes and 19.05 seconds, total_count=23952, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=35.590, cer_ctc=0.626, cer=0.626, loss=35.590, time=15.45 seconds, total_count=240, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.29 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 14:29:24,522 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 14:29:24,523 (trainer:272) INFO: 9/70epoch started. Estimated time to finish: 1 day, 5 hours and 28 minutes
[ALab02] 2023-06-07 14:30:48,536 (trainer:721) INFO: 9epoch:train:1-149batch: iter_time=0.166, forward_time=0.172, loss_ctc=10.574, loss=10.574, backward_time=0.158, optim_step_time=0.037, optim0_lr0=1.001e-04, train_time=2.259
[ALab02] 2023-06-07 14:32:04,085 (trainer:721) INFO: 9epoch:train:150-298batch: iter_time=0.036, forward_time=0.168, loss_ctc=11.281, loss=11.281, backward_time=0.160, optim_step_time=0.035, optim0_lr0=1.007e-04, train_time=2.022
[ALab02] 2023-06-07 14:34:11,102 (trainer:721) INFO: 9epoch:train:299-447batch: iter_time=0.455, forward_time=0.180, loss_ctc=11.063, loss=11.063, backward_time=0.161, optim_step_time=0.045, optim0_lr0=1.013e-04, train_time=3.406
[ALab02] 2023-06-07 14:36:14,010 (trainer:721) INFO: 9epoch:train:448-596batch: iter_time=0.422, forward_time=0.181, loss_ctc=10.244, loss=10.244, backward_time=0.162, optim_step_time=0.047, optim0_lr0=1.019e-04, train_time=3.290
[ALab02] 2023-06-07 14:38:14,358 (trainer:721) INFO: 9epoch:train:597-745batch: iter_time=0.405, forward_time=0.182, loss_ctc=11.016, loss=11.016, backward_time=0.162, optim_step_time=0.046, optim0_lr0=1.025e-04, train_time=3.239
[ALab02] 2023-06-07 14:40:19,753 (trainer:721) INFO: 9epoch:train:746-894batch: iter_time=0.448, forward_time=0.178, loss_ctc=10.945, loss=10.945, backward_time=0.161, optim_step_time=0.043, optim0_lr0=1.032e-04, train_time=3.359
[ALab02] 2023-06-07 14:42:22,567 (trainer:721) INFO: 9epoch:train:895-1043batch: iter_time=0.436, forward_time=0.176, loss_ctc=9.564, loss=9.564, backward_time=0.158, optim_step_time=0.039, optim0_lr0=1.038e-04, train_time=3.299
[ALab02] 2023-06-07 14:44:01,555 (trainer:721) INFO: 9epoch:train:1044-1192batch: iter_time=0.271, forward_time=0.172, loss_ctc=11.808, loss=11.808, backward_time=0.161, optim_step_time=0.040, optim0_lr0=1.044e-04, train_time=2.666
[ALab02] 2023-06-07 14:45:33,747 (trainer:721) INFO: 9epoch:train:1193-1341batch: iter_time=0.228, forward_time=0.171, loss_ctc=11.321, loss=11.321, backward_time=0.161, optim_step_time=0.038, optim0_lr0=1.050e-04, train_time=2.482
[ALab02] 2023-06-07 14:46:55,211 (trainer:721) INFO: 9epoch:train:1342-1490batch: iter_time=0.148, forward_time=0.168, loss_ctc=10.923, loss=10.923, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.056e-04, train_time=2.188
[ALab02] 2023-06-07 14:48:10,394 (trainer:721) INFO: 9epoch:train:1491-1639batch: iter_time=0.051, forward_time=0.165, loss_ctc=10.689, loss=10.689, backward_time=0.157, optim_step_time=0.035, optim0_lr0=1.063e-04, train_time=2.004
[ALab02] 2023-06-07 14:49:52,099 (trainer:721) INFO: 9epoch:train:1640-1788batch: iter_time=0.258, forward_time=0.194, loss_ctc=10.686, loss=10.686, backward_time=0.162, optim_step_time=0.062, optim0_lr0=1.069e-04, train_time=2.725
[ALab02] 2023-06-07 14:51:28,942 (trainer:721) INFO: 9epoch:train:1789-1937batch: iter_time=0.224, forward_time=0.189, loss_ctc=9.770, loss=9.770, backward_time=0.159, optim_step_time=0.058, optim0_lr0=1.075e-04, train_time=2.600
[ALab02] 2023-06-07 14:53:18,644 (trainer:721) INFO: 9epoch:train:1938-2086batch: iter_time=0.325, forward_time=0.188, loss_ctc=10.288, loss=10.288, backward_time=0.160, optim_step_time=0.057, optim0_lr0=1.081e-04, train_time=2.943
[ALab02] 2023-06-07 14:55:04,168 (trainer:721) INFO: 9epoch:train:2087-2235batch: iter_time=0.299, forward_time=0.187, loss_ctc=10.129, loss=10.129, backward_time=0.160, optim_step_time=0.054, optim0_lr0=1.087e-04, train_time=2.838
[ALab02] 2023-06-07 14:56:48,008 (trainer:721) INFO: 9epoch:train:2236-2384batch: iter_time=0.284, forward_time=0.186, loss_ctc=10.656, loss=10.656, backward_time=0.161, optim_step_time=0.055, optim0_lr0=1.094e-04, train_time=2.783
[ALab02] 2023-06-07 14:58:30,046 (trainer:721) INFO: 9epoch:train:2385-2533batch: iter_time=0.276, forward_time=0.187, loss_ctc=10.567, loss=10.567, backward_time=0.160, optim_step_time=0.051, optim0_lr0=1.100e-04, train_time=2.743
[ALab02] 2023-06-07 15:00:05,091 (trainer:721) INFO: 9epoch:train:2534-2682batch: iter_time=0.242, forward_time=0.174, loss_ctc=10.172, loss=10.172, backward_time=0.159, optim_step_time=0.042, optim0_lr0=1.106e-04, train_time=2.552
[ALab02] 2023-06-07 15:01:30,568 (trainer:721) INFO: 9epoch:train:2683-2831batch: iter_time=0.174, forward_time=0.169, loss_ctc=11.094, loss=11.094, backward_time=0.159, optim_step_time=0.038, optim0_lr0=1.112e-04, train_time=2.304
[ALab02] 2023-06-07 15:02:45,760 (trainer:721) INFO: 9epoch:train:2832-2980batch: iter_time=0.062, forward_time=0.167, loss_ctc=9.675, loss=9.675, backward_time=0.157, optim_step_time=0.035, optim0_lr0=1.119e-04, train_time=2.014
[ALab02] 2023-06-07 15:03:33,250 (trainer:338) INFO: 9epoch results: [train] iter_time=0.259, forward_time=0.178, loss_ctc=10.600, loss=10.600, backward_time=0.160, optim_step_time=0.045, optim0_lr0=1.060e-04, train_time=2.683, time=33 minutes and 28.09 seconds, total_count=26946, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=33.935, cer_ctc=0.606, cer=0.606, loss=33.935, time=14.1 seconds, total_count=270, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.54 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 15:03:35,844 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 15:03:35,847 (trainer:272) INFO: 10/70epoch started. Estimated time to finish: 1 day, 5 hours and 38 minutes
[ALab02] 2023-06-07 15:04:49,658 (trainer:721) INFO: 10epoch:train:1-149batch: iter_time=0.009, forward_time=0.165, loss_ctc=10.572, loss=10.572, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.125e-04, train_time=1.985
[ALab02] 2023-06-07 15:06:03,141 (trainer:721) INFO: 10epoch:train:150-298batch: iter_time=2.790e-04, forward_time=0.165, loss_ctc=10.938, loss=10.938, backward_time=0.160, optim_step_time=0.032, optim0_lr0=1.132e-04, train_time=1.977
[ALab02] 2023-06-07 15:07:16,596 (trainer:721) INFO: 10epoch:train:299-447batch: iter_time=2.555e-04, forward_time=0.167, loss_ctc=9.969, loss=9.969, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.138e-04, train_time=1.968
[ALab02] 2023-06-07 15:08:28,821 (trainer:721) INFO: 10epoch:train:448-596batch: iter_time=4.971e-04, forward_time=0.162, loss_ctc=10.876, loss=10.876, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.144e-04, train_time=1.936
[ALab02] 2023-06-07 15:09:42,120 (trainer:721) INFO: 10epoch:train:597-745batch: iter_time=0.004, forward_time=0.167, loss_ctc=10.442, loss=10.442, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.150e-04, train_time=1.970
[ALab02] 2023-06-07 15:10:55,460 (trainer:721) INFO: 10epoch:train:746-894batch: iter_time=2.559e-04, forward_time=0.165, loss_ctc=10.223, loss=10.223, backward_time=0.160, optim_step_time=0.032, optim0_lr0=1.156e-04, train_time=1.971
[ALab02] 2023-06-07 15:12:09,259 (trainer:721) INFO: 10epoch:train:895-1043batch: iter_time=0.001, forward_time=0.165, loss_ctc=11.078, loss=11.078, backward_time=0.161, optim_step_time=0.034, optim0_lr0=1.163e-04, train_time=1.978
[ALab02] 2023-06-07 15:13:23,089 (trainer:721) INFO: 10epoch:train:1044-1192batch: iter_time=0.006, forward_time=0.166, loss_ctc=10.583, loss=10.583, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.169e-04, train_time=1.980
[ALab02] 2023-06-07 15:14:35,744 (trainer:721) INFO: 10epoch:train:1193-1341batch: iter_time=2.574e-04, forward_time=0.163, loss_ctc=10.307, loss=10.307, backward_time=0.159, optim_step_time=0.035, optim0_lr0=1.175e-04, train_time=1.955
[ALab02] 2023-06-07 15:15:48,866 (trainer:721) INFO: 10epoch:train:1342-1490batch: iter_time=2.461e-04, forward_time=0.166, loss_ctc=9.957, loss=9.957, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.181e-04, train_time=1.961
[ALab02] 2023-06-07 15:17:02,498 (trainer:721) INFO: 10epoch:train:1491-1639batch: iter_time=0.014, forward_time=0.167, loss_ctc=9.510, loss=9.510, backward_time=0.158, optim_step_time=0.035, optim0_lr0=1.187e-04, train_time=1.977
[ALab02] 2023-06-07 15:18:16,267 (trainer:721) INFO: 10epoch:train:1640-1788batch: iter_time=2.485e-04, forward_time=0.168, loss_ctc=9.721, loss=9.721, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.194e-04, train_time=1.977
[ALab02] 2023-06-07 15:19:29,661 (trainer:721) INFO: 10epoch:train:1789-1937batch: iter_time=2.341e-04, forward_time=0.166, loss_ctc=10.554, loss=10.554, backward_time=0.161, optim_step_time=0.033, optim0_lr0=1.200e-04, train_time=1.975
[ALab02] 2023-06-07 15:21:29,647 (trainer:721) INFO: 10epoch:train:1938-2086batch: iter_time=0.346, forward_time=0.191, loss_ctc=10.377, loss=10.377, backward_time=0.163, optim_step_time=0.058, optim0_lr0=1.206e-04, train_time=3.216
[ALab02] 2023-06-07 15:23:42,514 (trainer:721) INFO: 10epoch:train:2087-2235batch: iter_time=0.460, forward_time=0.203, loss_ctc=9.810, loss=9.810, backward_time=0.164, optim_step_time=0.065, optim0_lr0=1.212e-04, train_time=3.565
[ALab02] 2023-06-07 15:25:42,620 (trainer:721) INFO: 10epoch:train:2236-2384batch: iter_time=0.376, forward_time=0.199, loss_ctc=10.292, loss=10.292, backward_time=0.162, optim_step_time=0.063, optim0_lr0=1.218e-04, train_time=3.218
[ALab02] 2023-06-07 15:27:35,731 (trainer:721) INFO: 10epoch:train:2385-2533batch: iter_time=0.344, forward_time=0.193, loss_ctc=9.870, loss=9.870, backward_time=0.160, optim_step_time=0.060, optim0_lr0=1.225e-04, train_time=3.046
[ALab02] 2023-06-07 15:29:19,169 (trainer:721) INFO: 10epoch:train:2534-2682batch: iter_time=0.285, forward_time=0.187, loss_ctc=9.894, loss=9.894, backward_time=0.160, optim_step_time=0.055, optim0_lr0=1.231e-04, train_time=2.767
[ALab02] 2023-06-07 15:30:58,562 (trainer:721) INFO: 10epoch:train:2683-2831batch: iter_time=0.258, forward_time=0.187, loss_ctc=10.669, loss=10.669, backward_time=0.162, optim_step_time=0.050, optim0_lr0=1.237e-04, train_time=2.681
[ALab02] 2023-06-07 15:32:20,766 (trainer:721) INFO: 10epoch:train:2832-2980batch: iter_time=0.146, forward_time=0.174, loss_ctc=9.410, loss=9.410, backward_time=0.158, optim_step_time=0.044, optim0_lr0=1.243e-04, train_time=2.205
[ALab02] 2023-06-07 15:33:13,949 (trainer:338) INFO: 10epoch results: [train] iter_time=0.113, forward_time=0.174, loss_ctc=10.245, loss=10.245, backward_time=0.160, optim_step_time=0.042, optim0_lr0=1.185e-04, train_time=2.315, time=28 minutes and 52.74 seconds, total_count=29940, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=32.472, cer_ctc=0.597, cer=0.597, loss=32.472, time=15.25 seconds, total_count=300, gpu_max_cached_mem_GB=52.041, [att_plot] time=30.11 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 15:33:16,857 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 15:33:16,859 (trainer:272) INFO: 11/70epoch started. Estimated time to finish: 1 day, 5 hours and 12 minutes
[ALab02] 2023-06-07 15:34:32,802 (trainer:721) INFO: 11epoch:train:1-149batch: iter_time=0.044, forward_time=0.168, loss_ctc=9.501, loss=9.501, backward_time=0.160, optim_step_time=0.036, optim0_lr0=1.250e-04, train_time=2.042
[ALab02] 2023-06-07 15:35:46,140 (trainer:721) INFO: 11epoch:train:150-298batch: iter_time=0.015, forward_time=0.166, loss_ctc=9.718, loss=9.718, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.256e-04, train_time=1.970
[ALab02] 2023-06-07 15:36:58,946 (trainer:721) INFO: 11epoch:train:299-447batch: iter_time=0.008, forward_time=0.162, loss_ctc=10.251, loss=10.251, backward_time=0.159, optim_step_time=0.035, optim0_lr0=1.262e-04, train_time=1.951
[ALab02] 2023-06-07 15:38:12,500 (trainer:721) INFO: 11epoch:train:448-596batch: iter_time=9.105e-04, forward_time=0.166, loss_ctc=9.974, loss=9.974, backward_time=0.161, optim_step_time=0.033, optim0_lr0=1.269e-04, train_time=1.972
[ALab02] 2023-06-07 15:39:26,262 (trainer:721) INFO: 11epoch:train:597-745batch: iter_time=0.025, forward_time=0.166, loss_ctc=9.890, loss=9.890, backward_time=0.160, optim_step_time=0.035, optim0_lr0=1.275e-04, train_time=1.984
[ALab02] 2023-06-07 15:40:39,034 (trainer:721) INFO: 11epoch:train:746-894batch: iter_time=2.116e-04, forward_time=0.164, loss_ctc=9.740, loss=9.740, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.281e-04, train_time=1.952
[ALab02] 2023-06-07 15:41:52,093 (trainer:721) INFO: 11epoch:train:895-1043batch: iter_time=0.008, forward_time=0.165, loss_ctc=10.329, loss=10.329, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.287e-04, train_time=1.963
[ALab02] 2023-06-07 15:43:06,385 (trainer:721) INFO: 11epoch:train:1044-1192batch: iter_time=1.976e-04, forward_time=0.166, loss_ctc=10.948, loss=10.948, backward_time=0.162, optim_step_time=0.033, optim0_lr0=1.293e-04, train_time=1.989
[ALab02] 2023-06-07 15:44:18,764 (trainer:721) INFO: 11epoch:train:1193-1341batch: iter_time=2.315e-04, forward_time=0.163, loss_ctc=9.650, loss=9.650, backward_time=0.158, optim_step_time=0.032, optim0_lr0=1.300e-04, train_time=1.947
[ALab02] 2023-06-07 15:45:32,030 (trainer:721) INFO: 11epoch:train:1342-1490batch: iter_time=0.001, forward_time=0.164, loss_ctc=10.643, loss=10.643, backward_time=0.161, optim_step_time=0.032, optim0_lr0=1.306e-04, train_time=1.967
[ALab02] 2023-06-07 15:46:44,726 (trainer:721) INFO: 11epoch:train:1491-1639batch: iter_time=2.247e-04, forward_time=0.163, loss_ctc=9.944, loss=9.944, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.312e-04, train_time=1.948
[ALab02] 2023-06-07 15:47:57,406 (trainer:721) INFO: 11epoch:train:1640-1788batch: iter_time=2.270e-04, forward_time=0.162, loss_ctc=10.062, loss=10.062, backward_time=0.158, optim_step_time=0.035, optim0_lr0=1.318e-04, train_time=1.950
[ALab02] 2023-06-07 15:49:11,487 (trainer:721) INFO: 11epoch:train:1789-1937batch: iter_time=2.229e-04, forward_time=0.168, loss_ctc=10.476, loss=10.476, backward_time=0.162, optim_step_time=0.032, optim0_lr0=1.324e-04, train_time=1.992
[ALab02] 2023-06-07 15:50:24,488 (trainer:721) INFO: 11epoch:train:1938-2086batch: iter_time=2.107e-04, forward_time=0.163, loss_ctc=9.987, loss=9.987, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.331e-04, train_time=1.960
[ALab02] 2023-06-07 15:51:38,033 (trainer:721) INFO: 11epoch:train:2087-2235batch: iter_time=2.303e-04, forward_time=0.167, loss_ctc=9.820, loss=9.820, backward_time=0.161, optim_step_time=0.032, optim0_lr0=1.337e-04, train_time=1.977
[ALab02] 2023-06-07 15:52:51,332 (trainer:721) INFO: 11epoch:train:2236-2384batch: iter_time=2.296e-04, forward_time=0.165, loss_ctc=9.448, loss=9.448, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.343e-04, train_time=1.961
[ALab02] 2023-06-07 15:54:04,241 (trainer:721) INFO: 11epoch:train:2385-2533batch: iter_time=2.360e-04, forward_time=0.167, loss_ctc=9.840, loss=9.840, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.349e-04, train_time=1.961
[ALab02] 2023-06-07 15:55:18,265 (trainer:721) INFO: 11epoch:train:2534-2682batch: iter_time=0.008, forward_time=0.167, loss_ctc=10.243, loss=10.243, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.355e-04, train_time=1.988
[ALab02] 2023-06-07 15:56:31,231 (trainer:721) INFO: 11epoch:train:2683-2831batch: iter_time=0.010, forward_time=0.166, loss_ctc=9.364, loss=9.364, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.362e-04, train_time=1.953
[ALab02] 2023-06-07 15:57:45,618 (trainer:721) INFO: 11epoch:train:2832-2980batch: iter_time=0.006, forward_time=0.166, loss_ctc=10.244, loss=10.244, backward_time=0.161, optim_step_time=0.034, optim0_lr0=1.368e-04, train_time=1.997
[ALab02] 2023-06-07 15:58:33,262 (trainer:338) INFO: 11epoch results: [train] iter_time=0.007, forward_time=0.165, loss_ctc=9.996, loss=9.996, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.309e-04, train_time=1.971, time=24 minutes and 35.67 seconds, total_count=32934, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=31.588, cer_ctc=0.585, cer=0.585, loss=31.588, time=14.56 seconds, total_count=330, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.17 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 15:58:35,695 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 15:58:35,696 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/1epoch.pth
[ALab02] 2023-06-07 15:58:35,696 (trainer:272) INFO: 12/70epoch started. Estimated time to finish: 1 day, 4 hours and 22 minutes
[ALab02] 2023-06-07 15:59:50,449 (trainer:721) INFO: 12epoch:train:1-149batch: iter_time=0.009, forward_time=0.169, loss_ctc=9.689, loss=9.689, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.375e-04, train_time=2.010
[ALab02] 2023-06-07 16:01:03,310 (trainer:721) INFO: 12epoch:train:150-298batch: iter_time=2.427e-04, forward_time=0.165, loss_ctc=9.505, loss=9.505, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.381e-04, train_time=1.957
[ALab02] 2023-06-07 16:02:16,471 (trainer:721) INFO: 12epoch:train:299-447batch: iter_time=2.463e-04, forward_time=0.165, loss_ctc=9.770, loss=9.770, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.387e-04, train_time=1.967
[ALab02] 2023-06-07 16:03:30,045 (trainer:721) INFO: 12epoch:train:448-596batch: iter_time=2.333e-04, forward_time=0.166, loss_ctc=9.236, loss=9.236, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.393e-04, train_time=1.967
[ALab02] 2023-06-07 16:04:42,519 (trainer:721) INFO: 12epoch:train:597-745batch: iter_time=3.610e-04, forward_time=0.163, loss_ctc=10.084, loss=10.084, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.400e-04, train_time=1.951
[ALab02] 2023-06-07 16:05:54,981 (trainer:721) INFO: 12epoch:train:746-894batch: iter_time=2.252e-04, forward_time=0.161, loss_ctc=10.207, loss=10.207, backward_time=0.159, optim_step_time=0.035, optim0_lr0=1.406e-04, train_time=1.946
[ALab02] 2023-06-07 16:07:08,850 (trainer:721) INFO: 12epoch:train:895-1043batch: iter_time=2.949e-04, forward_time=0.167, loss_ctc=9.472, loss=9.472, backward_time=0.161, optim_step_time=0.034, optim0_lr0=1.412e-04, train_time=1.985
[ALab02] 2023-06-07 16:08:21,443 (trainer:721) INFO: 12epoch:train:1044-1192batch: iter_time=2.227e-04, forward_time=0.164, loss_ctc=9.152, loss=9.152, backward_time=0.158, optim_step_time=0.035, optim0_lr0=1.418e-04, train_time=1.941
[ALab02] 2023-06-07 16:09:34,708 (trainer:721) INFO: 12epoch:train:1193-1341batch: iter_time=2.180e-04, forward_time=0.164, loss_ctc=9.719, loss=9.719, backward_time=0.160, optim_step_time=0.032, optim0_lr0=1.424e-04, train_time=1.971
[ALab02] 2023-06-07 16:10:48,282 (trainer:721) INFO: 12epoch:train:1342-1490batch: iter_time=2.303e-04, forward_time=0.164, loss_ctc=10.997, loss=10.997, backward_time=0.162, optim_step_time=0.034, optim0_lr0=1.431e-04, train_time=1.975
[ALab02] 2023-06-07 16:12:01,926 (trainer:721) INFO: 12epoch:train:1491-1639batch: iter_time=2.140e-04, forward_time=0.166, loss_ctc=10.382, loss=10.382, backward_time=0.162, optim_step_time=0.033, optim0_lr0=1.437e-04, train_time=1.981
[ALab02] 2023-06-07 16:13:14,882 (trainer:721) INFO: 12epoch:train:1640-1788batch: iter_time=2.030e-04, forward_time=0.164, loss_ctc=9.704, loss=9.704, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.443e-04, train_time=1.951
[ALab02] 2023-06-07 16:14:28,171 (trainer:721) INFO: 12epoch:train:1789-1937batch: iter_time=1.853e-04, forward_time=0.166, loss_ctc=9.401, loss=9.401, backward_time=0.160, optim_step_time=0.032, optim0_lr0=1.449e-04, train_time=1.972
[ALab02] 2023-06-07 16:15:41,487 (trainer:721) INFO: 12epoch:train:1938-2086batch: iter_time=0.004, forward_time=0.164, loss_ctc=10.151, loss=10.151, backward_time=0.159, optim_step_time=0.036, optim0_lr0=1.455e-04, train_time=1.965
[ALab02] 2023-06-07 16:16:55,865 (trainer:721) INFO: 12epoch:train:2087-2235batch: iter_time=0.019, forward_time=0.167, loss_ctc=9.339, loss=9.339, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.462e-04, train_time=2.002
[ALab02] 2023-06-07 16:18:08,531 (trainer:721) INFO: 12epoch:train:2236-2384batch: iter_time=2.175e-04, forward_time=0.163, loss_ctc=9.343, loss=9.343, backward_time=0.158, optim_step_time=0.032, optim0_lr0=1.468e-04, train_time=1.943
[ALab02] 2023-06-07 16:19:21,429 (trainer:721) INFO: 12epoch:train:2385-2533batch: iter_time=4.212e-04, forward_time=0.166, loss_ctc=9.481, loss=9.481, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.474e-04, train_time=1.961
[ALab02] 2023-06-07 16:20:34,303 (trainer:721) INFO: 12epoch:train:2534-2682batch: iter_time=2.336e-04, forward_time=0.163, loss_ctc=10.268, loss=10.268, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.480e-04, train_time=1.955
[ALab02] 2023-06-07 16:21:46,823 (trainer:721) INFO: 12epoch:train:2683-2831batch: iter_time=2.171e-04, forward_time=0.164, loss_ctc=9.233, loss=9.233, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.486e-04, train_time=1.948
[ALab02] 2023-06-07 16:22:59,726 (trainer:721) INFO: 12epoch:train:2832-2980batch: iter_time=2.294e-04, forward_time=0.163, loss_ctc=9.777, loss=9.777, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.493e-04, train_time=1.953
[ALab02] 2023-06-07 16:23:47,249 (trainer:338) INFO: 12epoch results: [train] iter_time=0.002, forward_time=0.165, loss_ctc=9.740, loss=9.740, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.434e-04, train_time=1.965, time=24 minutes and 31.17 seconds, total_count=35928, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=29.360, cer_ctc=0.576, cer=0.576, loss=29.360, time=14.49 seconds, total_count=360, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.88 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 16:23:49,706 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 16:23:49,707 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/2epoch.pth
[ALab02] 2023-06-07 16:23:49,707 (trainer:272) INFO: 13/70epoch started. Estimated time to finish: 1 day, 3 hours and 36 minutes
[ALab02] 2023-06-07 16:25:04,346 (trainer:721) INFO: 13epoch:train:1-149batch: iter_time=0.006, forward_time=0.167, loss_ctc=9.831, loss=9.831, backward_time=0.161, optim_step_time=0.034, optim0_lr0=1.499e-04, train_time=2.009
[ALab02] 2023-06-07 16:26:16,813 (trainer:721) INFO: 13epoch:train:150-298batch: iter_time=2.499e-04, forward_time=0.162, loss_ctc=10.023, loss=10.023, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.506e-04, train_time=1.944
[ALab02] 2023-06-07 16:27:29,485 (trainer:721) INFO: 13epoch:train:299-447batch: iter_time=2.436e-04, forward_time=0.164, loss_ctc=9.387, loss=9.387, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.512e-04, train_time=1.953
[ALab02] 2023-06-07 16:28:42,219 (trainer:721) INFO: 13epoch:train:448-596batch: iter_time=2.245e-04, forward_time=0.163, loss_ctc=9.170, loss=9.170, backward_time=0.158, optim_step_time=0.032, optim0_lr0=1.518e-04, train_time=1.946
[ALab02] 2023-06-07 16:29:55,650 (trainer:721) INFO: 13epoch:train:597-745batch: iter_time=2.150e-04, forward_time=0.166, loss_ctc=10.354, loss=10.354, backward_time=0.161, optim_step_time=0.033, optim0_lr0=1.524e-04, train_time=1.975
[ALab02] 2023-06-07 16:31:08,742 (trainer:721) INFO: 13epoch:train:746-894batch: iter_time=2.288e-04, forward_time=0.165, loss_ctc=9.928, loss=9.928, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.530e-04, train_time=1.964
[ALab02] 2023-06-07 16:32:22,199 (trainer:721) INFO: 13epoch:train:895-1043batch: iter_time=2.551e-04, forward_time=0.166, loss_ctc=9.502, loss=9.502, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.536e-04, train_time=1.968
[ALab02] 2023-06-07 16:33:34,768 (trainer:721) INFO: 13epoch:train:1044-1192batch: iter_time=0.002, forward_time=0.163, loss_ctc=9.005, loss=9.005, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.543e-04, train_time=1.946
[ALab02] 2023-06-07 16:34:48,748 (trainer:721) INFO: 13epoch:train:1193-1341batch: iter_time=0.003, forward_time=0.167, loss_ctc=9.885, loss=9.885, backward_time=0.162, optim_step_time=0.035, optim0_lr0=1.549e-04, train_time=1.992
[ALab02] 2023-06-07 16:36:01,354 (trainer:721) INFO: 13epoch:train:1342-1490batch: iter_time=2.166e-04, forward_time=0.164, loss_ctc=9.404, loss=9.404, backward_time=0.158, optim_step_time=0.035, optim0_lr0=1.555e-04, train_time=1.948
[ALab02] 2023-06-07 16:37:13,919 (trainer:721) INFO: 13epoch:train:1491-1639batch: iter_time=2.300e-04, forward_time=0.166, loss_ctc=9.146, loss=9.146, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.561e-04, train_time=1.948
[ALab02] 2023-06-07 16:38:28,179 (trainer:721) INFO: 13epoch:train:1640-1788batch: iter_time=2.166e-04, forward_time=0.173, loss_ctc=9.219, loss=9.219, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.568e-04, train_time=1.987
[ALab02] 2023-06-07 16:39:43,011 (trainer:721) INFO: 13epoch:train:1789-1937batch: iter_time=2.208e-04, forward_time=0.177, loss_ctc=9.254, loss=9.254, backward_time=0.160, optim_step_time=0.032, optim0_lr0=1.574e-04, train_time=2.014
[ALab02] 2023-06-07 16:40:57,790 (trainer:721) INFO: 13epoch:train:1938-2086batch: iter_time=2.109e-04, forward_time=0.176, loss_ctc=9.796, loss=9.796, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.580e-04, train_time=2.006
[ALab02] 2023-06-07 16:42:13,330 (trainer:721) INFO: 13epoch:train:2087-2235batch: iter_time=2.359e-04, forward_time=0.179, loss_ctc=9.927, loss=9.927, backward_time=0.162, optim_step_time=0.033, optim0_lr0=1.586e-04, train_time=2.027
[ALab02] 2023-06-07 16:43:26,476 (trainer:721) INFO: 13epoch:train:2236-2384batch: iter_time=2.163e-04, forward_time=0.172, loss_ctc=9.065, loss=9.065, backward_time=0.156, optim_step_time=0.033, optim0_lr0=1.592e-04, train_time=1.961
[ALab02] 2023-06-07 16:44:41,385 (trainer:721) INFO: 13epoch:train:2385-2533batch: iter_time=0.001, forward_time=0.179, loss_ctc=8.701, loss=8.701, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.599e-04, train_time=2.015
[ALab02] 2023-06-07 16:45:56,917 (trainer:721) INFO: 13epoch:train:2534-2682batch: iter_time=2.114e-04, forward_time=0.176, loss_ctc=9.613, loss=9.613, backward_time=0.162, optim_step_time=0.033, optim0_lr0=1.605e-04, train_time=2.028
[ALab02] 2023-06-07 16:47:12,597 (trainer:721) INFO: 13epoch:train:2683-2831batch: iter_time=2.253e-04, forward_time=0.178, loss_ctc=9.819, loss=9.819, backward_time=0.161, optim_step_time=0.033, optim0_lr0=1.611e-04, train_time=2.031
[ALab02] 2023-06-07 16:48:27,508 (trainer:721) INFO: 13epoch:train:2832-2980batch: iter_time=0.001, forward_time=0.176, loss_ctc=8.760, loss=8.760, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.617e-04, train_time=2.006
[ALab02] 2023-06-07 16:49:15,404 (trainer:338) INFO: 13epoch results: [train] iter_time=8.326e-04, forward_time=0.170, loss_ctc=9.475, loss=9.475, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.559e-04, train_time=1.984, time=24 minutes and 45.01 seconds, total_count=38922, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=28.210, cer_ctc=0.567, cer=0.567, loss=28.210, time=14.74 seconds, total_count=390, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.95 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 16:49:17,934 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 16:49:17,938 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/3epoch.pth
[ALab02] 2023-06-07 16:49:17,938 (trainer:272) INFO: 14/70epoch started. Estimated time to finish: 1 day, 2 hours and 54 minutes
[ALab02] 2023-06-07 16:50:33,805 (trainer:721) INFO: 14epoch:train:1-149batch: iter_time=0.007, forward_time=0.176, loss_ctc=9.549, loss=9.549, backward_time=0.161, optim_step_time=0.033, optim0_lr0=1.624e-04, train_time=2.042
[ALab02] 2023-06-07 16:51:47,370 (trainer:721) INFO: 14epoch:train:150-298batch: iter_time=4.643e-04, forward_time=0.173, loss_ctc=8.812, loss=8.812, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.630e-04, train_time=1.975
[ALab02] 2023-06-07 16:53:02,665 (trainer:721) INFO: 14epoch:train:299-447batch: iter_time=0.009, forward_time=0.174, loss_ctc=9.371, loss=9.371, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.636e-04, train_time=2.013
[ALab02] 2023-06-07 16:54:17,922 (trainer:721) INFO: 14epoch:train:448-596batch: iter_time=0.004, forward_time=0.178, loss_ctc=8.916, loss=8.916, backward_time=0.161, optim_step_time=0.032, optim0_lr0=1.643e-04, train_time=2.022
[ALab02] 2023-06-07 16:55:32,492 (trainer:721) INFO: 14epoch:train:597-745batch: iter_time=2.198e-04, forward_time=0.173, loss_ctc=9.680, loss=9.680, backward_time=0.162, optim_step_time=0.032, optim0_lr0=1.649e-04, train_time=2.005
[ALab02] 2023-06-07 16:56:46,845 (trainer:721) INFO: 14epoch:train:746-894batch: iter_time=0.010, forward_time=0.174, loss_ctc=9.400, loss=9.400, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.655e-04, train_time=1.997
[ALab02] 2023-06-07 16:58:00,337 (trainer:721) INFO: 14epoch:train:895-1043batch: iter_time=2.475e-04, forward_time=0.172, loss_ctc=8.290, loss=8.290, backward_time=0.157, optim_step_time=0.033, optim0_lr0=1.661e-04, train_time=1.977
[ALab02] 2023-06-07 16:59:16,172 (trainer:721) INFO: 14epoch:train:1044-1192batch: iter_time=2.147e-04, forward_time=0.178, loss_ctc=8.954, loss=8.954, backward_time=0.162, optim_step_time=0.034, optim0_lr0=1.667e-04, train_time=2.025
[ALab02] 2023-06-07 17:00:30,454 (trainer:721) INFO: 14epoch:train:1193-1341batch: iter_time=2.672e-04, forward_time=0.176, loss_ctc=8.756, loss=8.756, backward_time=0.159, optim_step_time=0.032, optim0_lr0=1.674e-04, train_time=1.997
[ALab02] 2023-06-07 17:01:43,849 (trainer:721) INFO: 14epoch:train:1342-1490batch: iter_time=2.332e-04, forward_time=0.172, loss_ctc=8.491, loss=8.491, backward_time=0.157, optim_step_time=0.033, optim0_lr0=1.680e-04, train_time=1.972
[ALab02] 2023-06-07 17:02:57,181 (trainer:721) INFO: 14epoch:train:1491-1639batch: iter_time=2.130e-04, forward_time=0.170, loss_ctc=8.601, loss=8.601, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.686e-04, train_time=1.965
[ALab02] 2023-06-07 17:04:12,220 (trainer:721) INFO: 14epoch:train:1640-1788batch: iter_time=2.122e-04, forward_time=0.176, loss_ctc=9.062, loss=9.062, backward_time=0.160, optim_step_time=0.032, optim0_lr0=1.692e-04, train_time=2.011
[ALab02] 2023-06-07 17:05:26,798 (trainer:721) INFO: 14epoch:train:1789-1937batch: iter_time=2.284e-04, forward_time=0.175, loss_ctc=9.009, loss=9.009, backward_time=0.160, optim_step_time=0.034, optim0_lr0=1.698e-04, train_time=2.007
[ALab02] 2023-06-07 17:06:41,174 (trainer:721) INFO: 14epoch:train:1938-2086batch: iter_time=2.919e-04, forward_time=0.175, loss_ctc=8.179, loss=8.179, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.705e-04, train_time=1.992
[ALab02] 2023-06-07 17:07:56,407 (trainer:721) INFO: 14epoch:train:2087-2235batch: iter_time=2.236e-04, forward_time=0.177, loss_ctc=8.671, loss=8.671, backward_time=0.161, optim_step_time=0.032, optim0_lr0=1.711e-04, train_time=2.024
[ALab02] 2023-06-07 17:09:10,620 (trainer:721) INFO: 14epoch:train:2236-2384batch: iter_time=2.335e-04, forward_time=0.173, loss_ctc=9.169, loss=9.169, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.717e-04, train_time=1.988
[ALab02] 2023-06-07 17:10:25,051 (trainer:721) INFO: 14epoch:train:2385-2533batch: iter_time=1.970e-04, forward_time=0.173, loss_ctc=9.538, loss=9.538, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.723e-04, train_time=2.002
[ALab02] 2023-06-07 17:11:39,622 (trainer:721) INFO: 14epoch:train:2534-2682batch: iter_time=0.002, forward_time=0.175, loss_ctc=8.581, loss=8.581, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.729e-04, train_time=2.000
[ALab02] 2023-06-07 17:12:54,076 (trainer:721) INFO: 14epoch:train:2683-2831batch: iter_time=2.087e-04, forward_time=0.175, loss_ctc=8.649, loss=8.649, backward_time=0.158, optim_step_time=0.032, optim0_lr0=1.736e-04, train_time=2.004
[ALab02] 2023-06-07 17:14:09,286 (trainer:721) INFO: 14epoch:train:2832-2980batch: iter_time=0.010, forward_time=0.175, loss_ctc=9.238, loss=9.238, backward_time=0.158, optim_step_time=0.035, optim0_lr0=1.742e-04, train_time=2.010
[ALab02] 2023-06-07 17:14:57,241 (trainer:338) INFO: 14epoch results: [train] iter_time=0.002, forward_time=0.174, loss_ctc=8.930, loss=8.930, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.683e-04, train_time=2.001, time=24 minutes and 58.08 seconds, total_count=41916, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=26.061, cer_ctc=0.512, cer=0.512, loss=26.061, time=14.9 seconds, total_count=420, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.32 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 17:14:59,481 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 17:14:59,483 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/4epoch.pth
[ALab02] 2023-06-07 17:14:59,483 (trainer:272) INFO: 15/70epoch started. Estimated time to finish: 1 day, 2 hours and 15 minutes
[ALab02] 2023-06-07 17:16:13,787 (trainer:721) INFO: 15epoch:train:1-149batch: iter_time=0.007, forward_time=0.173, loss_ctc=8.510, loss=8.510, backward_time=0.156, optim_step_time=0.032, optim0_lr0=1.749e-04, train_time=1.998
[ALab02] 2023-06-07 17:17:27,086 (trainer:721) INFO: 15epoch:train:150-298batch: iter_time=0.006, forward_time=0.168, loss_ctc=8.305, loss=8.305, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.755e-04, train_time=1.970
[ALab02] 2023-06-07 17:18:40,000 (trainer:721) INFO: 15epoch:train:299-447batch: iter_time=2.428e-04, forward_time=0.167, loss_ctc=8.129, loss=8.129, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.761e-04, train_time=1.958
[ALab02] 2023-06-07 17:19:53,088 (trainer:721) INFO: 15epoch:train:448-596batch: iter_time=2.539e-04, forward_time=0.164, loss_ctc=8.728, loss=8.728, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.767e-04, train_time=1.956
[ALab02] 2023-06-07 17:21:06,707 (trainer:721) INFO: 15epoch:train:597-745batch: iter_time=2.294e-04, forward_time=0.167, loss_ctc=8.341, loss=8.341, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.774e-04, train_time=1.981
[ALab02] 2023-06-07 17:22:19,696 (trainer:721) INFO: 15epoch:train:746-894batch: iter_time=2.529e-04, forward_time=0.164, loss_ctc=8.093, loss=8.093, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.780e-04, train_time=1.958
[ALab02] 2023-06-07 17:23:32,714 (trainer:721) INFO: 15epoch:train:895-1043batch: iter_time=2.560e-04, forward_time=0.171, loss_ctc=8.025, loss=8.025, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.786e-04, train_time=1.962
[ALab02] 2023-06-07 17:24:47,373 (trainer:721) INFO: 15epoch:train:1044-1192batch: iter_time=2.447e-04, forward_time=0.176, loss_ctc=8.344, loss=8.344, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.792e-04, train_time=1.998
[ALab02] 2023-06-07 17:26:00,204 (trainer:721) INFO: 15epoch:train:1193-1341batch: iter_time=2.326e-04, forward_time=0.173, loss_ctc=7.686, loss=7.686, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.798e-04, train_time=1.961
[ALab02] 2023-06-07 17:27:15,490 (trainer:721) INFO: 15epoch:train:1342-1490batch: iter_time=2.528e-04, forward_time=0.177, loss_ctc=8.214, loss=8.214, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.804e-04, train_time=2.018
[ALab02] 2023-06-07 17:28:30,469 (trainer:721) INFO: 15epoch:train:1491-1639batch: iter_time=2.116e-04, forward_time=0.177, loss_ctc=7.809, loss=7.809, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.811e-04, train_time=2.014
[ALab02] 2023-06-07 17:29:46,040 (trainer:721) INFO: 15epoch:train:1640-1788batch: iter_time=2.636e-04, forward_time=0.179, loss_ctc=7.644, loss=7.644, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.817e-04, train_time=2.024
[ALab02] 2023-06-07 17:30:59,006 (trainer:721) INFO: 15epoch:train:1789-1937batch: iter_time=2.185e-04, forward_time=0.171, loss_ctc=8.146, loss=8.146, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.823e-04, train_time=1.963
[ALab02] 2023-06-07 17:32:11,973 (trainer:721) INFO: 15epoch:train:1938-2086batch: iter_time=2.488e-04, forward_time=0.170, loss_ctc=8.266, loss=8.266, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.829e-04, train_time=1.958
[ALab02] 2023-06-07 17:33:27,785 (trainer:721) INFO: 15epoch:train:2087-2235batch: iter_time=0.009, forward_time=0.179, loss_ctc=7.771, loss=7.771, backward_time=0.158, optim_step_time=0.036, optim0_lr0=1.835e-04, train_time=2.035
[ALab02] 2023-06-07 17:34:43,508 (trainer:721) INFO: 15epoch:train:2236-2384batch: iter_time=2.047e-04, forward_time=0.179, loss_ctc=7.731, loss=7.731, backward_time=0.160, optim_step_time=0.033, optim0_lr0=1.842e-04, train_time=2.028
[ALab02] 2023-06-07 17:35:57,758 (trainer:721) INFO: 15epoch:train:2385-2533batch: iter_time=2.472e-04, forward_time=0.177, loss_ctc=7.347, loss=7.347, backward_time=0.157, optim_step_time=0.033, optim0_lr0=1.848e-04, train_time=1.997
[ALab02] 2023-06-07 17:37:11,756 (trainer:721) INFO: 15epoch:train:2534-2682batch: iter_time=0.009, forward_time=0.172, loss_ctc=7.755, loss=7.755, backward_time=0.156, optim_step_time=0.034, optim0_lr0=1.854e-04, train_time=1.989
[ALab02] 2023-06-07 17:38:25,135 (trainer:721) INFO: 15epoch:train:2683-2831batch: iter_time=4.502e-04, forward_time=0.167, loss_ctc=7.487, loss=7.487, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.860e-04, train_time=1.964
[ALab02] 2023-06-07 17:39:39,826 (trainer:721) INFO: 15epoch:train:2832-2980batch: iter_time=0.014, forward_time=0.168, loss_ctc=7.896, loss=7.896, backward_time=0.159, optim_step_time=0.038, optim0_lr0=1.867e-04, train_time=2.003
[ALab02] 2023-06-07 17:40:27,167 (trainer:338) INFO: 15epoch results: [train] iter_time=0.002, forward_time=0.172, loss_ctc=8.003, loss=8.003, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.808e-04, train_time=1.987, time=24 minutes and 47.01 seconds, total_count=44910, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=22.489, cer_ctc=0.454, cer=0.454, loss=22.489, time=14.23 seconds, total_count=450, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.45 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 17:40:29,412 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 17:40:29,413 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/5epoch.pth
[ALab02] 2023-06-07 17:40:29,414 (trainer:272) INFO: 16/70epoch started. Estimated time to finish: 1 day, 1 hour and 37 minutes
[ALab02] 2023-06-07 17:41:43,233 (trainer:721) INFO: 16epoch:train:1-149batch: iter_time=0.011, forward_time=0.165, loss_ctc=7.498, loss=7.498, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.873e-04, train_time=1.987
[ALab02] 2023-06-07 17:42:55,820 (trainer:721) INFO: 16epoch:train:150-298batch: iter_time=2.677e-04, forward_time=0.165, loss_ctc=7.247, loss=7.247, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.879e-04, train_time=1.947
[ALab02] 2023-06-07 17:44:09,390 (trainer:721) INFO: 16epoch:train:299-447batch: iter_time=2.728e-04, forward_time=0.168, loss_ctc=7.472, loss=7.472, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.886e-04, train_time=1.976
[ALab02] 2023-06-07 17:45:23,112 (trainer:721) INFO: 16epoch:train:448-596batch: iter_time=2.670e-04, forward_time=0.167, loss_ctc=7.857, loss=7.857, backward_time=0.159, optim_step_time=0.034, optim0_lr0=1.892e-04, train_time=1.974
[ALab02] 2023-06-07 17:46:36,666 (trainer:721) INFO: 16epoch:train:597-745batch: iter_time=2.435e-04, forward_time=0.166, loss_ctc=7.652, loss=7.652, backward_time=0.160, optim_step_time=0.035, optim0_lr0=1.898e-04, train_time=1.978
[ALab02] 2023-06-07 17:47:49,376 (trainer:721) INFO: 16epoch:train:746-894batch: iter_time=3.411e-04, forward_time=0.164, loss_ctc=7.047, loss=7.047, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.904e-04, train_time=1.954
[ALab02] 2023-06-07 17:49:01,965 (trainer:721) INFO: 16epoch:train:895-1043batch: iter_time=2.140e-04, forward_time=0.165, loss_ctc=7.359, loss=7.359, backward_time=0.157, optim_step_time=0.033, optim0_lr0=1.910e-04, train_time=1.948
[ALab02] 2023-06-07 17:50:15,805 (trainer:721) INFO: 16epoch:train:1044-1192batch: iter_time=2.483e-04, forward_time=0.168, loss_ctc=7.295, loss=7.295, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.917e-04, train_time=1.976
[ALab02] 2023-06-07 17:51:29,037 (trainer:721) INFO: 16epoch:train:1193-1341batch: iter_time=0.015, forward_time=0.165, loss_ctc=7.164, loss=7.164, backward_time=0.155, optim_step_time=0.035, optim0_lr0=1.923e-04, train_time=1.969
[ALab02] 2023-06-07 17:52:41,960 (trainer:721) INFO: 16epoch:train:1342-1490batch: iter_time=2.533e-04, forward_time=0.166, loss_ctc=7.314, loss=7.314, backward_time=0.157, optim_step_time=0.035, optim0_lr0=1.929e-04, train_time=1.959
[ALab02] 2023-06-07 17:53:53,843 (trainer:721) INFO: 16epoch:train:1491-1639batch: iter_time=0.002, forward_time=0.163, loss_ctc=7.101, loss=7.101, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.935e-04, train_time=1.930
[ALab02] 2023-06-07 17:55:06,094 (trainer:721) INFO: 16epoch:train:1640-1788batch: iter_time=2.400e-04, forward_time=0.162, loss_ctc=7.480, loss=7.480, backward_time=0.156, optim_step_time=0.034, optim0_lr0=1.942e-04, train_time=1.934
[ALab02] 2023-06-07 17:56:18,414 (trainer:721) INFO: 16epoch:train:1789-1937batch: iter_time=3.703e-04, forward_time=0.163, loss_ctc=7.976, loss=7.976, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.948e-04, train_time=1.946
[ALab02] 2023-06-07 17:57:30,228 (trainer:721) INFO: 16epoch:train:1938-2086batch: iter_time=2.178e-04, forward_time=0.161, loss_ctc=7.309, loss=7.309, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.954e-04, train_time=1.928
[ALab02] 2023-06-07 17:58:41,980 (trainer:721) INFO: 16epoch:train:2087-2235batch: iter_time=2.239e-04, forward_time=0.162, loss_ctc=6.631, loss=6.631, backward_time=0.155, optim_step_time=0.033, optim0_lr0=1.960e-04, train_time=1.925
[ALab02] 2023-06-07 17:59:54,178 (trainer:721) INFO: 16epoch:train:2236-2384batch: iter_time=4.504e-04, forward_time=0.162, loss_ctc=7.328, loss=7.328, backward_time=0.155, optim_step_time=0.035, optim0_lr0=1.966e-04, train_time=1.934
[ALab02] 2023-06-07 18:01:07,330 (trainer:721) INFO: 16epoch:train:2385-2533batch: iter_time=2.002e-04, forward_time=0.166, loss_ctc=7.316, loss=7.316, backward_time=0.158, optim_step_time=0.034, optim0_lr0=1.973e-04, train_time=1.969
[ALab02] 2023-06-07 18:02:20,558 (trainer:721) INFO: 16epoch:train:2534-2682batch: iter_time=2.497e-04, forward_time=0.165, loss_ctc=7.444, loss=7.444, backward_time=0.159, optim_step_time=0.033, optim0_lr0=1.979e-04, train_time=1.966
[ALab02] 2023-06-07 18:03:33,622 (trainer:721) INFO: 16epoch:train:2683-2831batch: iter_time=2.438e-04, forward_time=0.167, loss_ctc=6.917, loss=6.917, backward_time=0.158, optim_step_time=0.033, optim0_lr0=1.985e-04, train_time=1.962
[ALab02] 2023-06-07 18:04:47,505 (trainer:721) INFO: 16epoch:train:2832-2980batch: iter_time=2.394e-04, forward_time=0.167, loss_ctc=7.530, loss=7.530, backward_time=0.161, optim_step_time=0.034, optim0_lr0=1.991e-04, train_time=1.976
[ALab02] 2023-06-07 18:05:34,821 (trainer:338) INFO: 16epoch results: [train] iter_time=0.002, forward_time=0.165, loss_ctc=7.334, loss=7.334, backward_time=0.157, optim_step_time=0.034, optim0_lr0=1.933e-04, train_time=1.957, time=24 minutes and 24.81 seconds, total_count=47904, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=20.855, cer_ctc=0.439, cer=0.439, loss=20.855, time=14.21 seconds, total_count=480, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.38 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 18:05:37,054 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 18:05:37,055 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/6epoch.pth
[ALab02] 2023-06-07 18:05:37,056 (trainer:272) INFO: 17/70epoch started. Estimated time to finish: 1 day, 59 minutes and 56.4 seconds
[ALab02] 2023-06-07 18:06:49,590 (trainer:721) INFO: 17epoch:train:1-149batch: iter_time=0.006, forward_time=0.163, loss_ctc=7.117, loss=7.117, backward_time=0.156, optim_step_time=0.034, optim0_lr0=1.998e-04, train_time=1.949
[ALab02] 2023-06-07 18:08:02,617 (trainer:721) INFO: 17epoch:train:150-298batch: iter_time=2.607e-04, forward_time=0.165, loss_ctc=7.004, loss=7.004, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.004e-04, train_time=1.960
[ALab02] 2023-06-07 18:09:15,967 (trainer:721) INFO: 17epoch:train:299-447batch: iter_time=0.004, forward_time=0.166, loss_ctc=7.361, loss=7.361, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.010e-04, train_time=1.968
[ALab02] 2023-06-07 18:10:29,847 (trainer:721) INFO: 17epoch:train:448-596batch: iter_time=0.012, forward_time=0.166, loss_ctc=6.631, loss=6.631, backward_time=0.157, optim_step_time=0.034, optim0_lr0=2.017e-04, train_time=1.981
[ALab02] 2023-06-07 18:11:42,219 (trainer:721) INFO: 17epoch:train:597-745batch: iter_time=2.193e-04, forward_time=0.163, loss_ctc=7.214, loss=7.214, backward_time=0.157, optim_step_time=0.034, optim0_lr0=2.023e-04, train_time=1.949
[ALab02] 2023-06-07 18:12:55,191 (trainer:721) INFO: 17epoch:train:746-894batch: iter_time=2.386e-04, forward_time=0.165, loss_ctc=6.858, loss=6.858, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.029e-04, train_time=1.955
[ALab02] 2023-06-07 18:14:07,440 (trainer:721) INFO: 17epoch:train:895-1043batch: iter_time=2.248e-04, forward_time=0.162, loss_ctc=7.475, loss=7.475, backward_time=0.156, optim_step_time=0.033, optim0_lr0=2.035e-04, train_time=1.943
[ALab02] 2023-06-07 18:15:21,032 (trainer:721) INFO: 17epoch:train:1044-1192batch: iter_time=2.442e-04, forward_time=0.167, loss_ctc=6.997, loss=6.997, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.041e-04, train_time=1.970
[ALab02] 2023-06-07 18:16:34,472 (trainer:721) INFO: 17epoch:train:1193-1341batch: iter_time=3.617e-04, forward_time=0.166, loss_ctc=7.586, loss=7.586, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.048e-04, train_time=1.977
[ALab02] 2023-06-07 18:17:48,203 (trainer:721) INFO: 17epoch:train:1342-1490batch: iter_time=2.345e-04, forward_time=0.168, loss_ctc=6.872, loss=6.872, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.054e-04, train_time=1.975
[ALab02] 2023-06-07 18:19:01,171 (trainer:721) INFO: 17epoch:train:1491-1639batch: iter_time=2.210e-04, forward_time=0.167, loss_ctc=6.464, loss=6.464, backward_time=0.157, optim_step_time=0.035, optim0_lr0=2.060e-04, train_time=1.960
[ALab02] 2023-06-07 18:20:13,955 (trainer:721) INFO: 17epoch:train:1640-1788batch: iter_time=2.418e-04, forward_time=0.165, loss_ctc=6.589, loss=6.589, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.066e-04, train_time=1.951
[ALab02] 2023-06-07 18:21:27,528 (trainer:721) INFO: 17epoch:train:1789-1937batch: iter_time=0.015, forward_time=0.167, loss_ctc=6.968, loss=6.968, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.072e-04, train_time=1.981
[ALab02] 2023-06-07 18:22:39,328 (trainer:721) INFO: 17epoch:train:1938-2086batch: iter_time=2.749e-04, forward_time=0.162, loss_ctc=6.879, loss=6.879, backward_time=0.156, optim_step_time=0.033, optim0_lr0=2.079e-04, train_time=1.927
[ALab02] 2023-06-07 18:23:52,565 (trainer:721) INFO: 17epoch:train:2087-2235batch: iter_time=0.003, forward_time=0.167, loss_ctc=6.632, loss=6.632, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.085e-04, train_time=1.965
[ALab02] 2023-06-07 18:25:05,915 (trainer:721) INFO: 17epoch:train:2236-2384batch: iter_time=2.681e-04, forward_time=0.166, loss_ctc=6.873, loss=6.873, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.091e-04, train_time=1.964
[ALab02] 2023-06-07 18:26:18,293 (trainer:721) INFO: 17epoch:train:2385-2533batch: iter_time=0.003, forward_time=0.162, loss_ctc=7.193, loss=7.193, backward_time=0.157, optim_step_time=0.034, optim0_lr0=2.097e-04, train_time=1.948
[ALab02] 2023-06-07 18:27:31,565 (trainer:721) INFO: 17epoch:train:2534-2682batch: iter_time=2.722e-04, forward_time=0.166, loss_ctc=6.503, loss=6.503, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.104e-04, train_time=1.967
[ALab02] 2023-06-07 18:28:46,246 (trainer:721) INFO: 17epoch:train:2683-2831batch: iter_time=0.020, forward_time=0.166, loss_ctc=6.688, loss=6.688, backward_time=0.159, optim_step_time=0.036, optim0_lr0=2.110e-04, train_time=2.001
[ALab02] 2023-06-07 18:29:59,854 (trainer:721) INFO: 17epoch:train:2832-2980batch: iter_time=2.313e-04, forward_time=0.165, loss_ctc=7.410, loss=7.410, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.116e-04, train_time=1.974
[ALab02] 2023-06-07 18:30:47,312 (trainer:338) INFO: 17epoch results: [train] iter_time=0.003, forward_time=0.165, loss_ctc=6.949, loss=6.949, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.057e-04, train_time=1.964, time=24 minutes and 29.85 seconds, total_count=50898, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=20.034, cer_ctc=0.422, cer=0.422, loss=20.034, time=14.17 seconds, total_count=510, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.24 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 18:30:49,840 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 18:30:49,842 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/7epoch.pth
[ALab02] 2023-06-07 18:30:49,843 (trainer:272) INFO: 18/70epoch started. Estimated time to finish: 1 day, 24 minutes and 10.27 seconds
[ALab02] 2023-06-07 18:32:02,695 (trainer:721) INFO: 18epoch:train:1-149batch: iter_time=0.009, forward_time=0.163, loss_ctc=6.454, loss=6.454, backward_time=0.155, optim_step_time=0.035, optim0_lr0=2.123e-04, train_time=1.960
[ALab02] 2023-06-07 18:33:16,399 (trainer:721) INFO: 18epoch:train:150-298batch: iter_time=2.905e-04, forward_time=0.168, loss_ctc=6.729, loss=6.729, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.129e-04, train_time=1.980
[ALab02] 2023-06-07 18:34:28,734 (trainer:721) INFO: 18epoch:train:299-447batch: iter_time=2.283e-04, forward_time=0.164, loss_ctc=6.786, loss=6.786, backward_time=0.156, optim_step_time=0.033, optim0_lr0=2.135e-04, train_time=1.943
[ALab02] 2023-06-07 18:35:42,097 (trainer:721) INFO: 18epoch:train:448-596batch: iter_time=0.001, forward_time=0.165, loss_ctc=7.100, loss=7.100, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.141e-04, train_time=1.962
[ALab02] 2023-06-07 18:36:53,915 (trainer:721) INFO: 18epoch:train:597-745batch: iter_time=2.171e-04, forward_time=0.162, loss_ctc=6.397, loss=6.397, backward_time=0.156, optim_step_time=0.033, optim0_lr0=2.147e-04, train_time=1.933
[ALab02] 2023-06-07 18:38:07,839 (trainer:721) INFO: 18epoch:train:746-894batch: iter_time=2.273e-04, forward_time=0.169, loss_ctc=6.479, loss=6.479, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.154e-04, train_time=1.987
[ALab02] 2023-06-07 18:39:21,131 (trainer:721) INFO: 18epoch:train:895-1043batch: iter_time=2.707e-04, forward_time=0.166, loss_ctc=6.818, loss=6.818, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.160e-04, train_time=1.962
[ALab02] 2023-06-07 18:40:34,207 (trainer:721) INFO: 18epoch:train:1044-1192batch: iter_time=2.262e-04, forward_time=0.165, loss_ctc=7.010, loss=7.010, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.166e-04, train_time=1.960
[ALab02] 2023-06-07 18:41:46,970 (trainer:721) INFO: 18epoch:train:1193-1341batch: iter_time=0.005, forward_time=0.167, loss_ctc=6.309, loss=6.309, backward_time=0.157, optim_step_time=0.036, optim0_lr0=2.172e-04, train_time=1.955
[ALab02] 2023-06-07 18:43:00,093 (trainer:721) INFO: 18epoch:train:1342-1490batch: iter_time=2.313e-04, forward_time=0.164, loss_ctc=6.970, loss=6.970, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.179e-04, train_time=1.964
[ALab02] 2023-06-07 18:44:12,345 (trainer:721) INFO: 18epoch:train:1491-1639batch: iter_time=2.486e-04, forward_time=0.163, loss_ctc=6.530, loss=6.530, backward_time=0.157, optim_step_time=0.034, optim0_lr0=2.185e-04, train_time=1.941
[ALab02] 2023-06-07 18:45:26,343 (trainer:721) INFO: 18epoch:train:1640-1788batch: iter_time=2.173e-04, forward_time=0.166, loss_ctc=7.102, loss=7.102, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.191e-04, train_time=1.981
[ALab02] 2023-06-07 18:46:39,900 (trainer:721) INFO: 18epoch:train:1789-1937batch: iter_time=2.357e-04, forward_time=0.167, loss_ctc=6.813, loss=6.813, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.197e-04, train_time=1.980
[ALab02] 2023-06-07 18:47:54,072 (trainer:721) INFO: 18epoch:train:1938-2086batch: iter_time=2.355e-04, forward_time=0.168, loss_ctc=6.959, loss=6.959, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.203e-04, train_time=1.990
[ALab02] 2023-06-07 18:49:08,374 (trainer:721) INFO: 18epoch:train:2087-2235batch: iter_time=0.021, forward_time=0.167, loss_ctc=6.448, loss=6.448, backward_time=0.158, optim_step_time=0.037, optim0_lr0=2.209e-04, train_time=1.996
[ALab02] 2023-06-07 18:50:22,172 (trainer:721) INFO: 18epoch:train:2236-2384batch: iter_time=2.232e-04, forward_time=0.165, loss_ctc=6.877, loss=6.877, backward_time=0.160, optim_step_time=0.033, optim0_lr0=2.216e-04, train_time=1.975
[ALab02] 2023-06-07 18:51:34,720 (trainer:721) INFO: 18epoch:train:2385-2533batch: iter_time=2.149e-04, forward_time=0.163, loss_ctc=6.699, loss=6.699, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.222e-04, train_time=1.953
[ALab02] 2023-06-07 18:52:46,576 (trainer:721) INFO: 18epoch:train:2534-2682batch: iter_time=2.173e-04, forward_time=0.162, loss_ctc=6.425, loss=6.425, backward_time=0.157, optim_step_time=0.033, optim0_lr0=2.228e-04, train_time=1.929
[ALab02] 2023-06-07 18:53:59,587 (trainer:721) INFO: 18epoch:train:2683-2831batch: iter_time=2.217e-04, forward_time=0.166, loss_ctc=6.445, loss=6.445, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.234e-04, train_time=1.961
[ALab02] 2023-06-07 18:55:12,356 (trainer:721) INFO: 18epoch:train:2832-2980batch: iter_time=2.353e-04, forward_time=0.164, loss_ctc=6.334, loss=6.334, backward_time=0.157, optim_step_time=0.036, optim0_lr0=2.241e-04, train_time=1.946
[ALab02] 2023-06-07 18:55:59,491 (trainer:338) INFO: 18epoch results: [train] iter_time=0.002, forward_time=0.165, loss_ctc=6.674, loss=6.674, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.182e-04, train_time=1.963, time=24 minutes and 29.3 seconds, total_count=53892, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=19.200, cer_ctc=0.417, cer=0.417, loss=19.200, time=14.58 seconds, total_count=540, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.76 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 18:56:01,931 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 18:56:01,933 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/8epoch.pth
[ALab02] 2023-06-07 18:56:01,933 (trainer:272) INFO: 19/70epoch started. Estimated time to finish: 23 hours, 49 minutes and 32.49 seconds
[ALab02] 2023-06-07 18:57:15,528 (trainer:721) INFO: 19epoch:train:1-149batch: iter_time=0.008, forward_time=0.164, loss_ctc=6.525, loss=6.525, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.247e-04, train_time=1.980
[ALab02] 2023-06-07 18:58:28,331 (trainer:721) INFO: 19epoch:train:150-298batch: iter_time=2.586e-04, forward_time=0.163, loss_ctc=6.960, loss=6.960, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.254e-04, train_time=1.955
[ALab02] 2023-06-07 18:59:41,226 (trainer:721) INFO: 19epoch:train:299-447batch: iter_time=3.087e-04, forward_time=0.166, loss_ctc=6.266, loss=6.266, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.260e-04, train_time=1.957
[ALab02] 2023-06-07 19:00:54,448 (trainer:721) INFO: 19epoch:train:448-596batch: iter_time=2.377e-04, forward_time=0.164, loss_ctc=6.260, loss=6.260, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.266e-04, train_time=1.959
[ALab02] 2023-06-07 19:02:07,240 (trainer:721) INFO: 19epoch:train:597-745batch: iter_time=0.007, forward_time=0.165, loss_ctc=6.761, loss=6.761, backward_time=0.157, optim_step_time=0.035, optim0_lr0=2.272e-04, train_time=1.958
[ALab02] 2023-06-07 19:03:19,519 (trainer:721) INFO: 19epoch:train:746-894batch: iter_time=6.509e-04, forward_time=0.163, loss_ctc=6.759, loss=6.759, backward_time=0.157, optim_step_time=0.033, optim0_lr0=2.278e-04, train_time=1.940
[ALab02] 2023-06-07 19:04:32,457 (trainer:721) INFO: 19epoch:train:895-1043batch: iter_time=0.001, forward_time=0.165, loss_ctc=6.309, loss=6.309, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.284e-04, train_time=1.957
[ALab02] 2023-06-07 19:05:45,237 (trainer:721) INFO: 19epoch:train:1044-1192batch: iter_time=2.467e-04, forward_time=0.165, loss_ctc=6.435, loss=6.435, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.291e-04, train_time=1.951
[ALab02] 2023-06-07 19:06:59,302 (trainer:721) INFO: 19epoch:train:1193-1341batch: iter_time=2.299e-04, forward_time=0.168, loss_ctc=6.411, loss=6.411, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.297e-04, train_time=1.991
[ALab02] 2023-06-07 19:08:12,890 (trainer:721) INFO: 19epoch:train:1342-1490batch: iter_time=0.017, forward_time=0.165, loss_ctc=6.287, loss=6.287, backward_time=0.158, optim_step_time=0.036, optim0_lr0=2.303e-04, train_time=1.979
[ALab02] 2023-06-07 19:09:24,798 (trainer:721) INFO: 19epoch:train:1491-1639batch: iter_time=0.002, forward_time=0.162, loss_ctc=6.334, loss=6.334, backward_time=0.156, optim_step_time=0.033, optim0_lr0=2.309e-04, train_time=1.928
[ALab02] 2023-06-07 19:10:38,983 (trainer:721) INFO: 19epoch:train:1640-1788batch: iter_time=2.379e-04, forward_time=0.167, loss_ctc=6.693, loss=6.693, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.316e-04, train_time=1.985
[ALab02] 2023-06-07 19:11:52,954 (trainer:721) INFO: 19epoch:train:1789-1937batch: iter_time=2.224e-04, forward_time=0.167, loss_ctc=6.231, loss=6.231, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.322e-04, train_time=1.989
[ALab02] 2023-06-07 19:13:06,258 (trainer:721) INFO: 19epoch:train:1938-2086batch: iter_time=2.280e-04, forward_time=0.170, loss_ctc=5.684, loss=5.684, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.328e-04, train_time=1.967
[ALab02] 2023-06-07 19:14:19,074 (trainer:721) INFO: 19epoch:train:2087-2235batch: iter_time=2.069e-04, forward_time=0.166, loss_ctc=6.111, loss=6.111, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.334e-04, train_time=1.955
[ALab02] 2023-06-07 19:15:32,650 (trainer:721) INFO: 19epoch:train:2236-2384batch: iter_time=2.161e-04, forward_time=0.165, loss_ctc=6.332, loss=6.332, backward_time=0.160, optim_step_time=0.032, optim0_lr0=2.340e-04, train_time=1.972
[ALab02] 2023-06-07 19:16:46,318 (trainer:721) INFO: 19epoch:train:2385-2533batch: iter_time=2.176e-04, forward_time=0.167, loss_ctc=6.863, loss=6.863, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.347e-04, train_time=1.983
[ALab02] 2023-06-07 19:17:58,797 (trainer:721) INFO: 19epoch:train:2534-2682batch: iter_time=3.005e-04, forward_time=0.162, loss_ctc=6.615, loss=6.615, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.353e-04, train_time=1.945
[ALab02] 2023-06-07 19:19:11,794 (trainer:721) INFO: 19epoch:train:2683-2831batch: iter_time=2.111e-04, forward_time=0.166, loss_ctc=6.351, loss=6.351, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.359e-04, train_time=1.961
[ALab02] 2023-06-07 19:20:24,089 (trainer:721) INFO: 19epoch:train:2832-2980batch: iter_time=2.310e-04, forward_time=0.162, loss_ctc=6.223, loss=6.223, backward_time=0.157, optim_step_time=0.032, optim0_lr0=2.365e-04, train_time=1.935
[ALab02] 2023-06-07 19:21:10,703 (trainer:338) INFO: 19epoch results: [train] iter_time=0.002, forward_time=0.165, loss_ctc=6.412, loss=6.412, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.307e-04, train_time=1.963, time=24 minutes and 29.12 seconds, total_count=56886, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=18.240, cer_ctc=0.404, cer=0.404, loss=18.240, time=14.34 seconds, total_count=570, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.31 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 19:21:13,142 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 19:21:13,148 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/9epoch.pth
[ALab02] 2023-06-07 19:21:13,148 (trainer:272) INFO: 20/70epoch started. Estimated time to finish: 23 hours, 15 minutes and 51.91 seconds
[ALab02] 2023-06-07 19:22:28,123 (trainer:721) INFO: 20epoch:train:1-149batch: iter_time=0.007, forward_time=0.168, loss_ctc=6.587, loss=6.587, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.372e-04, train_time=2.018
[ALab02] 2023-06-07 19:23:42,926 (trainer:721) INFO: 20epoch:train:150-298batch: iter_time=0.032, forward_time=0.168, loss_ctc=6.248, loss=6.248, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.378e-04, train_time=2.007
[ALab02] 2023-06-07 19:24:58,110 (trainer:721) INFO: 20epoch:train:299-447batch: iter_time=0.037, forward_time=0.168, loss_ctc=6.199, loss=6.199, backward_time=0.160, optim_step_time=0.036, optim0_lr0=2.384e-04, train_time=2.020
[ALab02] 2023-06-07 19:26:13,677 (trainer:721) INFO: 20epoch:train:448-596batch: iter_time=0.025, forward_time=0.168, loss_ctc=6.504, loss=6.504, backward_time=0.159, optim_step_time=0.035, optim0_lr0=2.391e-04, train_time=2.021
[ALab02] 2023-06-07 19:27:26,670 (trainer:721) INFO: 20epoch:train:597-745batch: iter_time=2.599e-04, forward_time=0.167, loss_ctc=6.031, loss=6.031, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.397e-04, train_time=1.964
[ALab02] 2023-06-07 19:28:39,731 (trainer:721) INFO: 20epoch:train:746-894batch: iter_time=2.557e-04, forward_time=0.165, loss_ctc=6.047, loss=6.047, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.403e-04, train_time=1.963
[ALab02] 2023-06-07 19:29:52,802 (trainer:721) INFO: 20epoch:train:895-1043batch: iter_time=2.402e-04, forward_time=0.167, loss_ctc=5.893, loss=5.893, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.409e-04, train_time=1.959
[ALab02] 2023-06-07 19:31:06,084 (trainer:721) INFO: 20epoch:train:1044-1192batch: iter_time=2.529e-04, forward_time=0.165, loss_ctc=6.053, loss=6.053, backward_time=0.159, optim_step_time=0.036, optim0_lr0=2.415e-04, train_time=1.963
[ALab02] 2023-06-07 19:32:19,390 (trainer:721) INFO: 20epoch:train:1193-1341batch: iter_time=2.341e-04, forward_time=0.166, loss_ctc=6.145, loss=6.145, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.422e-04, train_time=1.973
[ALab02] 2023-06-07 19:33:32,169 (trainer:721) INFO: 20epoch:train:1342-1490batch: iter_time=2.191e-04, forward_time=0.165, loss_ctc=6.000, loss=6.000, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.428e-04, train_time=1.952
[ALab02] 2023-06-07 19:34:44,037 (trainer:721) INFO: 20epoch:train:1491-1639batch: iter_time=2.247e-04, forward_time=0.161, loss_ctc=6.370, loss=6.370, backward_time=0.157, optim_step_time=0.034, optim0_lr0=2.434e-04, train_time=1.926
[ALab02] 2023-06-07 19:35:56,875 (trainer:721) INFO: 20epoch:train:1640-1788batch: iter_time=0.004, forward_time=0.165, loss_ctc=6.101, loss=6.101, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.440e-04, train_time=1.954
[ALab02] 2023-06-07 19:37:09,985 (trainer:721) INFO: 20epoch:train:1789-1937batch: iter_time=9.568e-04, forward_time=0.164, loss_ctc=6.735, loss=6.735, backward_time=0.160, optim_step_time=0.037, optim0_lr0=2.446e-04, train_time=1.967
[ALab02] 2023-06-07 19:38:24,218 (trainer:721) INFO: 20epoch:train:1938-2086batch: iter_time=3.212e-04, forward_time=0.167, loss_ctc=6.504, loss=6.504, backward_time=0.162, optim_step_time=0.035, optim0_lr0=2.453e-04, train_time=1.992
[ALab02] 2023-06-07 19:39:38,455 (trainer:721) INFO: 20epoch:train:2087-2235batch: iter_time=2.561e-04, forward_time=0.167, loss_ctc=6.478, loss=6.478, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.459e-04, train_time=1.992
[ALab02] 2023-06-07 19:40:51,923 (trainer:721) INFO: 20epoch:train:2236-2384batch: iter_time=2.289e-04, forward_time=0.165, loss_ctc=6.282, loss=6.282, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.465e-04, train_time=1.969
[ALab02] 2023-06-07 19:42:04,245 (trainer:721) INFO: 20epoch:train:2385-2533batch: iter_time=2.095e-04, forward_time=0.164, loss_ctc=6.380, loss=6.380, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.471e-04, train_time=1.945
[ALab02] 2023-06-07 19:43:17,611 (trainer:721) INFO: 20epoch:train:2534-2682batch: iter_time=5.127e-04, forward_time=0.165, loss_ctc=6.038, loss=6.038, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.477e-04, train_time=1.967
[ALab02] 2023-06-07 19:44:32,687 (trainer:721) INFO: 20epoch:train:2683-2831batch: iter_time=0.029, forward_time=0.167, loss_ctc=6.043, loss=6.043, backward_time=0.158, optim_step_time=0.037, optim0_lr0=2.484e-04, train_time=2.009
[ALab02] 2023-06-07 19:45:46,973 (trainer:721) INFO: 20epoch:train:2832-2980batch: iter_time=0.021, forward_time=0.166, loss_ctc=6.120, loss=6.120, backward_time=0.159, optim_step_time=0.035, optim0_lr0=2.490e-04, train_time=1.999
[ALab02] 2023-06-07 19:46:34,295 (trainer:338) INFO: 20epoch results: [train] iter_time=0.008, forward_time=0.166, loss_ctc=6.228, loss=6.228, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.431e-04, train_time=1.978, time=24 minutes and 40.69 seconds, total_count=59880, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=17.879, cer_ctc=0.384, cer=0.384, loss=17.879, time=14.25 seconds, total_count=600, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.2 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 19:46:36,591 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 19:46:36,595 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/10epoch.pth
[ALab02] 2023-06-07 19:46:36,595 (trainer:272) INFO: 21/70epoch started. Estimated time to finish: 22 hours, 43 minutes and 32.85 seconds
[ALab02] 2023-06-07 19:47:50,969 (trainer:721) INFO: 21epoch:train:1-149batch: iter_time=0.012, forward_time=0.164, loss_ctc=6.684, loss=6.684, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.497e-04, train_time=2.001
[ALab02] 2023-06-07 19:49:03,262 (trainer:721) INFO: 21epoch:train:150-298batch: iter_time=2.754e-04, forward_time=0.162, loss_ctc=6.191, loss=6.191, backward_time=0.157, optim_step_time=0.034, optim0_lr0=2.503e-04, train_time=1.940
[ALab02] 2023-06-07 19:50:16,999 (trainer:721) INFO: 21epoch:train:299-447batch: iter_time=2.364e-04, forward_time=0.166, loss_ctc=6.427, loss=6.427, backward_time=0.161, optim_step_time=0.035, optim0_lr0=2.509e-04, train_time=1.981
[ALab02] 2023-06-07 19:51:30,211 (trainer:721) INFO: 21epoch:train:448-596batch: iter_time=5.117e-04, forward_time=0.167, loss_ctc=5.813, loss=5.813, backward_time=0.158, optim_step_time=0.036, optim0_lr0=2.515e-04, train_time=1.958
[ALab02] 2023-06-07 19:52:43,390 (trainer:721) INFO: 21epoch:train:597-745batch: iter_time=2.688e-04, forward_time=0.168, loss_ctc=5.698, loss=5.698, backward_time=0.158, optim_step_time=0.036, optim0_lr0=2.521e-04, train_time=1.969
[ALab02] 2023-06-07 19:53:56,969 (trainer:721) INFO: 21epoch:train:746-894batch: iter_time=2.579e-04, forward_time=0.168, loss_ctc=5.890, loss=5.890, backward_time=0.159, optim_step_time=0.036, optim0_lr0=2.528e-04, train_time=1.978
[ALab02] 2023-06-07 19:55:10,658 (trainer:721) INFO: 21epoch:train:895-1043batch: iter_time=7.808e-04, forward_time=0.168, loss_ctc=6.183, loss=6.183, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.534e-04, train_time=1.972
[ALab02] 2023-06-07 19:56:24,263 (trainer:721) INFO: 21epoch:train:1044-1192batch: iter_time=2.624e-04, forward_time=0.168, loss_ctc=6.002, loss=6.002, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.540e-04, train_time=1.974
[ALab02] 2023-06-07 19:57:36,727 (trainer:721) INFO: 21epoch:train:1193-1341batch: iter_time=2.612e-04, forward_time=0.164, loss_ctc=6.155, loss=6.155, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.546e-04, train_time=1.949
[ALab02] 2023-06-07 19:58:50,387 (trainer:721) INFO: 21epoch:train:1342-1490batch: iter_time=2.730e-04, forward_time=0.167, loss_ctc=6.357, loss=6.357, backward_time=0.159, optim_step_time=0.036, optim0_lr0=2.552e-04, train_time=1.980
[ALab02] 2023-06-07 20:00:03,698 (trainer:721) INFO: 21epoch:train:1491-1639batch: iter_time=3.322e-04, forward_time=0.166, loss_ctc=6.121, loss=6.121, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.559e-04, train_time=1.966
[ALab02] 2023-06-07 20:01:17,446 (trainer:721) INFO: 21epoch:train:1640-1788batch: iter_time=2.477e-04, forward_time=0.165, loss_ctc=6.296, loss=6.296, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.565e-04, train_time=1.975
[ALab02] 2023-06-07 20:02:32,786 (trainer:721) INFO: 21epoch:train:1789-1937batch: iter_time=0.024, forward_time=0.168, loss_ctc=6.134, loss=6.134, backward_time=0.159, optim_step_time=0.037, optim0_lr0=2.571e-04, train_time=2.028
[ALab02] 2023-06-07 20:03:46,384 (trainer:721) INFO: 21epoch:train:1938-2086batch: iter_time=2.497e-04, forward_time=0.168, loss_ctc=6.017, loss=6.017, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.577e-04, train_time=1.976
[ALab02] 2023-06-07 20:04:59,998 (trainer:721) INFO: 21epoch:train:2087-2235batch: iter_time=2.468e-04, forward_time=0.165, loss_ctc=6.191, loss=6.191, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.584e-04, train_time=1.974
[ALab02] 2023-06-07 20:06:14,873 (trainer:721) INFO: 21epoch:train:2236-2384batch: iter_time=0.032, forward_time=0.166, loss_ctc=6.156, loss=6.156, backward_time=0.159, optim_step_time=0.036, optim0_lr0=2.590e-04, train_time=2.006
[ALab02] 2023-06-07 20:07:27,387 (trainer:721) INFO: 21epoch:train:2385-2533batch: iter_time=5.132e-04, forward_time=0.165, loss_ctc=5.929, loss=5.929, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.596e-04, train_time=1.951
[ALab02] 2023-06-07 20:08:41,683 (trainer:721) INFO: 21epoch:train:2534-2682batch: iter_time=2.303e-04, forward_time=0.168, loss_ctc=6.203, loss=6.203, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.602e-04, train_time=1.994
[ALab02] 2023-06-07 20:09:54,450 (trainer:721) INFO: 21epoch:train:2683-2831batch: iter_time=3.061e-04, forward_time=0.164, loss_ctc=5.923, loss=5.923, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.608e-04, train_time=1.958
[ALab02] 2023-06-07 20:11:07,649 (trainer:721) INFO: 21epoch:train:2832-2980batch: iter_time=2.446e-04, forward_time=0.166, loss_ctc=5.576, loss=5.576, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.615e-04, train_time=1.956
[ALab02] 2023-06-07 20:11:55,791 (trainer:338) INFO: 21epoch results: [train] iter_time=0.004, forward_time=0.166, loss_ctc=6.087, loss=6.087, backward_time=0.159, optim_step_time=0.035, optim0_lr0=2.556e-04, train_time=1.975, time=24 minutes and 38.07 seconds, total_count=62874, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=17.436, cer_ctc=0.376, cer=0.376, loss=17.436, time=14.2 seconds, total_count=630, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.93 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 20:11:58,195 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 20:11:58,197 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/11epoch.pth
[ALab02] 2023-06-07 20:11:58,197 (trainer:272) INFO: 22/70epoch started. Estimated time to finish: 22 hours, 11 minutes and 49.07 seconds
[ALab02] 2023-06-07 20:13:11,578 (trainer:721) INFO: 22epoch:train:1-149batch: iter_time=0.008, forward_time=0.165, loss_ctc=5.960, loss=5.960, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.621e-04, train_time=1.973
[ALab02] 2023-06-07 20:14:24,197 (trainer:721) INFO: 22epoch:train:150-298batch: iter_time=3.154e-04, forward_time=0.164, loss_ctc=5.720, loss=5.720, backward_time=0.158, optim_step_time=0.035, optim0_lr0=2.628e-04, train_time=1.951
[ALab02] 2023-06-07 20:15:37,330 (trainer:721) INFO: 22epoch:train:299-447batch: iter_time=2.627e-04, forward_time=0.166, loss_ctc=5.720, loss=5.720, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.634e-04, train_time=1.963
[ALab02] 2023-06-07 20:16:50,741 (trainer:721) INFO: 22epoch:train:448-596batch: iter_time=2.356e-04, forward_time=0.166, loss_ctc=5.686, loss=5.686, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.640e-04, train_time=1.965
[ALab02] 2023-06-07 20:18:04,040 (trainer:721) INFO: 22epoch:train:597-745batch: iter_time=2.595e-04, forward_time=0.166, loss_ctc=5.883, loss=5.883, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.646e-04, train_time=1.973
[ALab02] 2023-06-07 20:19:17,320 (trainer:721) INFO: 22epoch:train:746-894batch: iter_time=2.433e-04, forward_time=0.164, loss_ctc=6.125, loss=6.125, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.652e-04, train_time=1.966
[ALab02] 2023-06-07 20:20:31,089 (trainer:721) INFO: 22epoch:train:895-1043batch: iter_time=2.353e-04, forward_time=0.166, loss_ctc=6.091, loss=6.091, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.658e-04, train_time=1.983
[ALab02] 2023-06-07 20:21:45,100 (trainer:721) INFO: 22epoch:train:1044-1192batch: iter_time=0.004, forward_time=0.168, loss_ctc=5.682, loss=5.682, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.665e-04, train_time=1.979
[ALab02] 2023-06-07 20:22:57,982 (trainer:721) INFO: 22epoch:train:1193-1341batch: iter_time=0.005, forward_time=0.163, loss_ctc=6.195, loss=6.195, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.671e-04, train_time=1.960
[ALab02] 2023-06-07 20:24:12,072 (trainer:721) INFO: 22epoch:train:1342-1490batch: iter_time=0.016, forward_time=0.169, loss_ctc=5.773, loss=5.773, backward_time=0.159, optim_step_time=0.037, optim0_lr0=2.677e-04, train_time=1.989
[ALab02] 2023-06-07 20:25:25,450 (trainer:721) INFO: 22epoch:train:1491-1639batch: iter_time=2.013e-04, forward_time=0.166, loss_ctc=6.079, loss=6.079, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.683e-04, train_time=1.972
[ALab02] 2023-06-07 20:26:39,825 (trainer:721) INFO: 22epoch:train:1640-1788batch: iter_time=0.016, forward_time=0.167, loss_ctc=5.874, loss=5.874, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.690e-04, train_time=1.990
[ALab02] 2023-06-07 20:27:52,317 (trainer:721) INFO: 22epoch:train:1789-1937batch: iter_time=2.313e-04, forward_time=0.163, loss_ctc=6.177, loss=6.177, backward_time=0.158, optim_step_time=0.036, optim0_lr0=2.696e-04, train_time=1.950
[ALab02] 2023-06-07 20:29:04,757 (trainer:721) INFO: 22epoch:train:1938-2086batch: iter_time=5.702e-04, forward_time=0.163, loss_ctc=5.816, loss=5.816, backward_time=0.158, optim_step_time=0.033, optim0_lr0=2.702e-04, train_time=1.947
[ALab02] 2023-06-07 20:30:17,185 (trainer:721) INFO: 22epoch:train:2087-2235batch: iter_time=2.047e-04, forward_time=0.163, loss_ctc=5.531, loss=5.531, backward_time=0.159, optim_step_time=0.032, optim0_lr0=2.708e-04, train_time=1.944
[ALab02] 2023-06-07 20:31:30,411 (trainer:721) INFO: 22epoch:train:2236-2384batch: iter_time=2.203e-04, forward_time=0.165, loss_ctc=5.403, loss=5.403, backward_time=0.159, optim_step_time=0.035, optim0_lr0=2.714e-04, train_time=1.959
[ALab02] 2023-06-07 20:32:44,146 (trainer:721) INFO: 22epoch:train:2385-2533batch: iter_time=2.120e-04, forward_time=0.168, loss_ctc=5.655, loss=5.655, backward_time=0.161, optim_step_time=0.032, optim0_lr0=2.721e-04, train_time=1.984
[ALab02] 2023-06-07 20:33:56,031 (trainer:721) INFO: 22epoch:train:2534-2682batch: iter_time=2.133e-04, forward_time=0.161, loss_ctc=5.879, loss=5.879, backward_time=0.158, optim_step_time=0.031, optim0_lr0=2.727e-04, train_time=1.932
[ALab02] 2023-06-07 20:35:09,846 (trainer:721) INFO: 22epoch:train:2683-2831batch: iter_time=2.289e-04, forward_time=0.165, loss_ctc=6.213, loss=6.213, backward_time=0.162, optim_step_time=0.032, optim0_lr0=2.733e-04, train_time=1.978
[ALab02] 2023-06-07 20:36:23,005 (trainer:721) INFO: 22epoch:train:2832-2980batch: iter_time=2.347e-04, forward_time=0.165, loss_ctc=5.535, loss=5.535, backward_time=0.160, optim_step_time=0.032, optim0_lr0=2.739e-04, train_time=1.960
[ALab02] 2023-06-07 20:37:09,517 (trainer:338) INFO: 22epoch results: [train] iter_time=0.003, forward_time=0.165, loss_ctc=5.837, loss=5.837, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.681e-04, train_time=1.966, time=24 minutes and 31.45 seconds, total_count=65868, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=16.286, cer_ctc=0.386, cer=0.386, loss=16.286, time=14.17 seconds, total_count=660, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.71 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 20:37:11,973 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-07 20:37:11,974 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/12epoch.pth
[ALab02] 2023-06-07 20:37:11,974 (trainer:272) INFO: 23/70epoch started. Estimated time to finish: 21 hours, 40 minutes and 22.95 seconds
[ALab02] 2023-06-07 20:38:26,872 (trainer:721) INFO: 23epoch:train:1-149batch: iter_time=0.008, forward_time=0.167, loss_ctc=5.678, loss=5.678, backward_time=0.163, optim_step_time=0.033, optim0_lr0=2.746e-04, train_time=2.015
[ALab02] 2023-06-07 20:39:39,812 (trainer:721) INFO: 23epoch:train:150-298batch: iter_time=2.453e-04, forward_time=0.167, loss_ctc=5.393, loss=5.393, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.752e-04, train_time=1.961
[ALab02] 2023-06-07 20:40:53,838 (trainer:721) INFO: 23epoch:train:299-447batch: iter_time=2.634e-04, forward_time=0.167, loss_ctc=5.680, loss=5.680, backward_time=0.162, optim_step_time=0.033, optim0_lr0=2.758e-04, train_time=1.981
[ALab02] 2023-06-07 20:42:10,701 (trainer:721) INFO: 23epoch:train:448-596batch: iter_time=0.026, forward_time=0.169, loss_ctc=5.750, loss=5.750, backward_time=0.163, optim_step_time=0.036, optim0_lr0=2.765e-04, train_time=2.060
[ALab02] 2023-06-07 20:43:23,493 (trainer:721) INFO: 23epoch:train:597-745batch: iter_time=2.642e-04, forward_time=0.163, loss_ctc=5.719, loss=5.719, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.771e-04, train_time=1.958
[ALab02] 2023-06-07 20:44:36,398 (trainer:721) INFO: 23epoch:train:746-894batch: iter_time=2.506e-04, forward_time=0.165, loss_ctc=5.634, loss=5.634, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.777e-04, train_time=1.957
[ALab02] 2023-06-07 20:45:49,518 (trainer:721) INFO: 23epoch:train:895-1043batch: iter_time=3.060e-04, forward_time=0.165, loss_ctc=5.772, loss=5.772, backward_time=0.160, optim_step_time=0.032, optim0_lr0=2.783e-04, train_time=1.963
[ALab02] 2023-06-07 20:47:04,125 (trainer:721) INFO: 23epoch:train:1044-1192batch: iter_time=0.031, forward_time=0.165, loss_ctc=5.810, loss=5.810, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.789e-04, train_time=1.998
[ALab02] 2023-06-07 20:48:17,688 (trainer:721) INFO: 23epoch:train:1193-1341batch: iter_time=2.483e-04, forward_time=0.165, loss_ctc=5.699, loss=5.699, backward_time=0.162, optim_step_time=0.033, optim0_lr0=2.796e-04, train_time=1.979
[ALab02] 2023-06-07 20:49:30,618 (trainer:721) INFO: 23epoch:train:1342-1490batch: iter_time=2.310e-04, forward_time=0.163, loss_ctc=5.941, loss=5.941, backward_time=0.160, optim_step_time=0.035, optim0_lr0=2.802e-04, train_time=1.958
[ALab02] 2023-06-07 20:50:43,396 (trainer:721) INFO: 23epoch:train:1491-1639batch: iter_time=2.539e-04, forward_time=0.164, loss_ctc=5.738, loss=5.738, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.808e-04, train_time=1.954
[ALab02] 2023-06-07 20:51:57,575 (trainer:721) INFO: 23epoch:train:1640-1788batch: iter_time=2.477e-04, forward_time=0.167, loss_ctc=5.775, loss=5.775, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.814e-04, train_time=1.986
[ALab02] 2023-06-07 20:53:10,667 (trainer:721) INFO: 23epoch:train:1789-1937batch: iter_time=8.837e-04, forward_time=0.164, loss_ctc=5.913, loss=5.913, backward_time=0.160, optim_step_time=0.033, optim0_lr0=2.820e-04, train_time=1.967
[ALab02] 2023-06-07 20:54:24,030 (trainer:721) INFO: 23epoch:train:1938-2086batch: iter_time=2.576e-04, forward_time=0.164, loss_ctc=5.514, loss=5.514, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.827e-04, train_time=1.969
[ALab02] 2023-06-07 20:55:37,290 (trainer:721) INFO: 23epoch:train:2087-2235batch: iter_time=2.337e-04, forward_time=0.165, loss_ctc=5.606, loss=5.606, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.833e-04, train_time=1.965
[ALab02] 2023-06-07 20:56:49,508 (trainer:721) INFO: 23epoch:train:2236-2384batch: iter_time=2.293e-04, forward_time=0.164, loss_ctc=5.708, loss=5.708, backward_time=0.157, optim_step_time=0.033, optim0_lr0=2.839e-04, train_time=1.936
[ALab02] 2023-06-07 20:58:03,044 (trainer:721) INFO: 23epoch:train:2385-2533batch: iter_time=2.415e-04, forward_time=0.167, loss_ctc=5.357, loss=5.357, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.845e-04, train_time=1.978
[ALab02] 2023-06-07 20:59:17,582 (trainer:721) INFO: 23epoch:train:2534-2682batch: iter_time=0.004, forward_time=0.168, loss_ctc=5.676, loss=5.676, backward_time=0.163, optim_step_time=0.035, optim0_lr0=2.851e-04, train_time=2.002
[ALab02] 2023-06-07 21:00:32,218 (trainer:721) INFO: 23epoch:train:2683-2831batch: iter_time=0.028, forward_time=0.163, loss_ctc=5.449, loss=5.449, backward_time=0.158, optim_step_time=0.034, optim0_lr0=2.858e-04, train_time=2.006
[ALab02] 2023-06-07 21:01:46,487 (trainer:721) INFO: 23epoch:train:2832-2980batch: iter_time=2.445e-04, forward_time=0.168, loss_ctc=5.670, loss=5.670, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.864e-04, train_time=1.986
[ALab02] 2023-06-07 21:02:33,690 (trainer:338) INFO: 23epoch results: [train] iter_time=0.005, forward_time=0.166, loss_ctc=5.672, loss=5.672, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.805e-04, train_time=1.979, time=24 minutes and 41.4 seconds, total_count=68862, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=16.012, cer_ctc=0.369, cer=0.369, loss=16.012, time=14.19 seconds, total_count=690, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.11 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 21:02:35,927 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 21:02:35,930 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/13epoch.pth
[ALab02] 2023-06-07 21:02:35,930 (trainer:272) INFO: 24/70epoch started. Estimated time to finish: 21 hours, 9 minutes and 50.01 seconds
[ALab02] 2023-06-07 21:03:49,311 (trainer:721) INFO: 24epoch:train:1-149batch: iter_time=0.008, forward_time=0.163, loss_ctc=5.823, loss=5.823, backward_time=0.160, optim_step_time=0.032, optim0_lr0=2.871e-04, train_time=1.972
[ALab02] 2023-06-07 21:05:02,949 (trainer:721) INFO: 24epoch:train:150-298batch: iter_time=3.014e-04, forward_time=0.165, loss_ctc=5.611, loss=5.611, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.877e-04, train_time=1.977
[ALab02] 2023-06-07 21:06:16,128 (trainer:721) INFO: 24epoch:train:299-447batch: iter_time=2.614e-04, forward_time=0.166, loss_ctc=5.390, loss=5.390, backward_time=0.160, optim_step_time=0.032, optim0_lr0=2.883e-04, train_time=1.963
[ALab02] 2023-06-07 21:07:29,608 (trainer:721) INFO: 24epoch:train:448-596batch: iter_time=2.480e-04, forward_time=0.166, loss_ctc=5.383, loss=5.383, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.889e-04, train_time=1.971
[ALab02] 2023-06-07 21:08:44,685 (trainer:721) INFO: 24epoch:train:597-745batch: iter_time=0.011, forward_time=0.168, loss_ctc=5.710, loss=5.710, backward_time=0.162, optim_step_time=0.036, optim0_lr0=2.896e-04, train_time=2.020
[ALab02] 2023-06-07 21:09:57,612 (trainer:721) INFO: 24epoch:train:746-894batch: iter_time=0.001, forward_time=0.164, loss_ctc=5.454, loss=5.454, backward_time=0.159, optim_step_time=0.034, optim0_lr0=2.902e-04, train_time=1.959
[ALab02] 2023-06-07 21:11:11,137 (trainer:721) INFO: 24epoch:train:895-1043batch: iter_time=2.600e-04, forward_time=0.166, loss_ctc=5.331, loss=5.331, backward_time=0.161, optim_step_time=0.035, optim0_lr0=2.908e-04, train_time=1.970
[ALab02] 2023-06-07 21:12:24,381 (trainer:721) INFO: 24epoch:train:1044-1192batch: iter_time=2.191e-04, forward_time=0.164, loss_ctc=5.722, loss=5.722, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.914e-04, train_time=1.964
[ALab02] 2023-06-07 21:13:37,961 (trainer:721) INFO: 24epoch:train:1193-1341batch: iter_time=2.256e-04, forward_time=0.166, loss_ctc=5.505, loss=5.505, backward_time=0.162, optim_step_time=0.034, optim0_lr0=2.920e-04, train_time=1.979
[ALab02] 2023-06-07 21:14:51,050 (trainer:721) INFO: 24epoch:train:1342-1490batch: iter_time=2.482e-04, forward_time=0.163, loss_ctc=5.406, loss=5.406, backward_time=0.160, optim_step_time=0.033, optim0_lr0=2.926e-04, train_time=1.961
[ALab02] 2023-06-07 21:16:04,458 (trainer:721) INFO: 24epoch:train:1491-1639batch: iter_time=2.325e-04, forward_time=0.165, loss_ctc=5.729, loss=5.729, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.933e-04, train_time=1.974
[ALab02] 2023-06-07 21:17:17,964 (trainer:721) INFO: 24epoch:train:1640-1788batch: iter_time=2.134e-04, forward_time=0.166, loss_ctc=5.543, loss=5.543, backward_time=0.160, optim_step_time=0.032, optim0_lr0=2.939e-04, train_time=1.966
[ALab02] 2023-06-07 21:18:31,759 (trainer:721) INFO: 24epoch:train:1789-1937batch: iter_time=0.012, forward_time=0.167, loss_ctc=5.591, loss=5.591, backward_time=0.161, optim_step_time=0.035, optim0_lr0=2.945e-04, train_time=1.986
[ALab02] 2023-06-07 21:19:44,401 (trainer:721) INFO: 24epoch:train:1938-2086batch: iter_time=2.528e-04, forward_time=0.163, loss_ctc=5.732, loss=5.732, backward_time=0.159, optim_step_time=0.033, optim0_lr0=2.951e-04, train_time=1.950
[ALab02] 2023-06-07 21:20:57,606 (trainer:721) INFO: 24epoch:train:2087-2235batch: iter_time=2.410e-04, forward_time=0.165, loss_ctc=5.657, loss=5.657, backward_time=0.160, optim_step_time=0.034, optim0_lr0=2.958e-04, train_time=1.968
[ALab02] 2023-06-07 21:22:11,772 (trainer:721) INFO: 24epoch:train:2236-2384batch: iter_time=4.919e-04, forward_time=0.167, loss_ctc=5.539, loss=5.539, backward_time=0.162, optim_step_time=0.033, optim0_lr0=2.964e-04, train_time=1.982
[ALab02] 2023-06-07 21:23:25,268 (trainer:721) INFO: 24epoch:train:2385-2533batch: iter_time=2.779e-04, forward_time=0.167, loss_ctc=5.414, loss=5.414, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.970e-04, train_time=1.977
[ALab02] 2023-06-07 21:24:38,515 (trainer:721) INFO: 24epoch:train:2534-2682batch: iter_time=2.223e-04, forward_time=0.165, loss_ctc=5.649, loss=5.649, backward_time=0.161, optim_step_time=0.033, optim0_lr0=2.976e-04, train_time=1.966
[ALab02] 2023-06-07 21:25:51,997 (trainer:721) INFO: 24epoch:train:2683-2831batch: iter_time=2.436e-04, forward_time=0.165, loss_ctc=5.422, loss=5.422, backward_time=0.162, optim_step_time=0.033, optim0_lr0=2.982e-04, train_time=1.973
[ALab02] 2023-06-07 21:27:07,362 (trainer:721) INFO: 24epoch:train:2832-2980batch: iter_time=2.410e-04, forward_time=0.171, loss_ctc=5.391, loss=5.391, backward_time=0.165, optim_step_time=0.035, optim0_lr0=2.989e-04, train_time=2.018
[ALab02] 2023-06-07 21:27:54,683 (trainer:338) INFO: 24epoch results: [train] iter_time=0.002, forward_time=0.166, loss_ctc=5.547, loss=5.547, backward_time=0.161, optim_step_time=0.034, optim0_lr0=2.930e-04, train_time=1.975, time=24 minutes and 38.3 seconds, total_count=71856, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=16.393, cer_ctc=0.363, cer=0.363, loss=16.393, time=14.3 seconds, total_count=720, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.15 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 21:27:57,052 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 21:27:57,054 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/14epoch.pth
[ALab02] 2023-06-07 21:27:57,055 (trainer:272) INFO: 25/70epoch started. Estimated time to finish: 20 hours, 39 minutes and 37.4 seconds
[ALab02] 2023-06-07 21:29:11,184 (trainer:721) INFO: 25epoch:train:1-149batch: iter_time=0.010, forward_time=0.167, loss_ctc=5.122, loss=5.122, backward_time=0.160, optim_step_time=0.033, optim0_lr0=2.995e-04, train_time=1.995
[ALab02] 2023-06-07 21:30:25,513 (trainer:721) INFO: 25epoch:train:150-298batch: iter_time=0.015, forward_time=0.169, loss_ctc=4.919, loss=4.919, backward_time=0.161, optim_step_time=0.036, optim0_lr0=3.002e-04, train_time=1.993
[ALab02] 2023-06-07 21:31:38,693 (trainer:721) INFO: 25epoch:train:299-447batch: iter_time=2.760e-04, forward_time=0.165, loss_ctc=5.153, loss=5.153, backward_time=0.160, optim_step_time=0.034, optim0_lr0=3.008e-04, train_time=1.965
[ALab02] 2023-06-07 21:32:52,744 (trainer:721) INFO: 25epoch:train:448-596batch: iter_time=2.500e-04, forward_time=0.166, loss_ctc=5.418, loss=5.418, backward_time=0.162, optim_step_time=0.033, optim0_lr0=3.014e-04, train_time=1.984
[ALab02] 2023-06-07 21:34:06,897 (trainer:721) INFO: 25epoch:train:597-745batch: iter_time=2.630e-04, forward_time=0.167, loss_ctc=5.712, loss=5.712, backward_time=0.164, optim_step_time=0.034, optim0_lr0=3.020e-04, train_time=1.993
[ALab02] 2023-06-07 21:35:20,920 (trainer:721) INFO: 25epoch:train:746-894batch: iter_time=2.608e-04, forward_time=0.168, loss_ctc=5.185, loss=5.185, backward_time=0.162, optim_step_time=0.033, optim0_lr0=3.026e-04, train_time=1.988
[ALab02] 2023-06-07 21:36:33,530 (trainer:721) INFO: 25epoch:train:895-1043batch: iter_time=2.412e-04, forward_time=0.164, loss_ctc=5.140, loss=5.140, backward_time=0.159, optim_step_time=0.035, optim0_lr0=3.033e-04, train_time=1.951
[ALab02] 2023-06-07 21:37:47,570 (trainer:721) INFO: 25epoch:train:1044-1192batch: iter_time=0.013, forward_time=0.164, loss_ctc=5.313, loss=5.313, backward_time=0.159, optim_step_time=0.035, optim0_lr0=3.039e-04, train_time=1.982
[ALab02] 2023-06-07 21:39:01,091 (trainer:721) INFO: 25epoch:train:1193-1341batch: iter_time=2.332e-04, forward_time=0.165, loss_ctc=5.388, loss=5.388, backward_time=0.162, optim_step_time=0.033, optim0_lr0=3.045e-04, train_time=1.978
[ALab02] 2023-06-07 21:40:15,006 (trainer:721) INFO: 25epoch:train:1342-1490batch: iter_time=2.054e-04, forward_time=0.167, loss_ctc=5.522, loss=5.522, backward_time=0.162, optim_step_time=0.034, optim0_lr0=3.051e-04, train_time=1.984
[ALab02] 2023-06-07 21:41:28,441 (trainer:721) INFO: 25epoch:train:1491-1639batch: iter_time=2.523e-04, forward_time=0.167, loss_ctc=5.288, loss=5.288, backward_time=0.160, optim_step_time=0.035, optim0_lr0=3.057e-04, train_time=1.971
[ALab02] 2023-06-07 21:42:41,530 (trainer:721) INFO: 25epoch:train:1640-1788batch: iter_time=2.879e-04, forward_time=0.165, loss_ctc=5.289, loss=5.289, backward_time=0.159, optim_step_time=0.035, optim0_lr0=3.064e-04, train_time=1.958
[ALab02] 2023-06-07 21:44:02,584 (trainer:721) INFO: 25epoch:train:1789-1937batch: iter_time=0.075, forward_time=0.174, loss_ctc=5.220, loss=5.220, backward_time=0.161, optim_step_time=0.042, optim0_lr0=3.070e-04, train_time=2.178
[ALab02] 2023-06-07 21:45:43,238 (trainer:721) INFO: 25epoch:train:1938-2086batch: iter_time=0.266, forward_time=0.187, loss_ctc=4.985, loss=4.985, backward_time=0.160, optim_step_time=0.056, optim0_lr0=3.076e-04, train_time=2.697
[ALab02] 2023-06-07 21:47:27,286 (trainer:721) INFO: 25epoch:train:2087-2235batch: iter_time=0.283, forward_time=0.188, loss_ctc=5.329, loss=5.329, backward_time=0.163, optim_step_time=0.058, optim0_lr0=3.082e-04, train_time=2.803
[ALab02] 2023-06-07 21:49:07,451 (trainer:721) INFO: 25epoch:train:2236-2384batch: iter_time=0.252, forward_time=0.191, loss_ctc=5.261, loss=5.261, backward_time=0.162, optim_step_time=0.056, optim0_lr0=3.088e-04, train_time=2.678
[ALab02] 2023-06-07 21:50:51,857 (trainer:721) INFO: 25epoch:train:2385-2533batch: iter_time=0.289, forward_time=0.186, loss_ctc=5.441, loss=5.441, backward_time=0.160, optim_step_time=0.060, optim0_lr0=3.095e-04, train_time=2.814
[ALab02] 2023-06-07 21:52:32,554 (trainer:721) INFO: 25epoch:train:2534-2682batch: iter_time=0.256, forward_time=0.192, loss_ctc=5.095, loss=5.095, backward_time=0.164, optim_step_time=0.057, optim0_lr0=3.101e-04, train_time=2.696
[ALab02] 2023-06-07 21:54:19,780 (trainer:721) INFO: 25epoch:train:2683-2831batch: iter_time=0.296, forward_time=0.194, loss_ctc=5.418, loss=5.418, backward_time=0.166, optim_step_time=0.057, optim0_lr0=3.107e-04, train_time=2.888
[ALab02] 2023-06-07 21:56:00,662 (trainer:721) INFO: 25epoch:train:2832-2980batch: iter_time=0.255, forward_time=0.192, loss_ctc=5.429, loss=5.429, backward_time=0.164, optim_step_time=0.062, optim0_lr0=3.113e-04, train_time=2.695
[ALab02] 2023-06-07 21:57:15,075 (trainer:338) INFO: 25epoch results: [train] iter_time=0.101, forward_time=0.175, loss_ctc=5.269, loss=5.269, backward_time=0.161, optim_step_time=0.043, optim0_lr0=3.055e-04, train_time=2.262, time=28 minutes and 13.48 seconds, total_count=74850, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.543, cer_ctc=0.351, cer=0.351, loss=15.543, time=21.62 seconds, total_count=750, gpu_max_cached_mem_GB=52.041, [att_plot] time=42.91 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 21:57:18,712 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 21:57:18,714 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/15epoch.pth
[ALab02] 2023-06-07 21:57:18,714 (trainer:272) INFO: 26/70epoch started. Estimated time to finish: 20 hours, 17 minutes and 1.07 seconds
[ALab02] 2023-06-07 21:59:01,842 (trainer:721) INFO: 26epoch:train:1-149batch: iter_time=0.276, forward_time=0.191, loss_ctc=5.048, loss=5.048, backward_time=0.161, optim_step_time=0.056, optim0_lr0=3.120e-04, train_time=2.778
[ALab02] 2023-06-07 22:00:50,199 (trainer:721) INFO: 26epoch:train:150-298batch: iter_time=0.305, forward_time=0.192, loss_ctc=5.477, loss=5.477, backward_time=0.164, optim_step_time=0.062, optim0_lr0=3.126e-04, train_time=2.912
[ALab02] 2023-06-07 22:02:30,358 (trainer:721) INFO: 26epoch:train:299-447batch: iter_time=0.260, forward_time=0.187, loss_ctc=5.520, loss=5.520, backward_time=0.163, optim_step_time=0.053, optim0_lr0=3.132e-04, train_time=2.674
[ALab02] 2023-06-07 22:04:15,846 (trainer:721) INFO: 26epoch:train:448-596batch: iter_time=0.292, forward_time=0.192, loss_ctc=4.893, loss=4.893, backward_time=0.160, optim_step_time=0.059, optim0_lr0=3.139e-04, train_time=2.832
[ALab02] 2023-06-07 22:06:00,421 (trainer:721) INFO: 26epoch:train:597-745batch: iter_time=0.286, forward_time=0.188, loss_ctc=5.044, loss=5.044, backward_time=0.162, optim_step_time=0.060, optim0_lr0=3.145e-04, train_time=2.813
[ALab02] 2023-06-07 22:07:45,537 (trainer:721) INFO: 26epoch:train:746-894batch: iter_time=0.290, forward_time=0.190, loss_ctc=5.028, loss=5.028, backward_time=0.160, optim_step_time=0.056, optim0_lr0=3.151e-04, train_time=2.824
[ALab02] 2023-06-07 22:09:21,623 (trainer:721) INFO: 26epoch:train:895-1043batch: iter_time=0.232, forward_time=0.188, loss_ctc=5.303, loss=5.303, backward_time=0.162, optim_step_time=0.052, optim0_lr0=3.157e-04, train_time=2.575
[ALab02] 2023-06-07 22:11:07,765 (trainer:721) INFO: 26epoch:train:1044-1192batch: iter_time=0.297, forward_time=0.189, loss_ctc=5.361, loss=5.361, backward_time=0.160, optim_step_time=0.063, optim0_lr0=3.163e-04, train_time=2.842
[ALab02] 2023-06-07 22:12:50,457 (trainer:721) INFO: 26epoch:train:1193-1341batch: iter_time=0.276, forward_time=0.190, loss_ctc=5.091, loss=5.091, backward_time=0.162, optim_step_time=0.056, optim0_lr0=3.170e-04, train_time=2.758
[ALab02] 2023-06-07 22:14:35,000 (trainer:721) INFO: 26epoch:train:1342-1490batch: iter_time=0.284, forward_time=0.190, loss_ctc=5.236, loss=5.236, backward_time=0.163, optim_step_time=0.060, optim0_lr0=3.176e-04, train_time=2.809
[ALab02] 2023-06-07 22:16:19,035 (trainer:721) INFO: 26epoch:train:1491-1639batch: iter_time=0.281, forward_time=0.191, loss_ctc=5.142, loss=5.142, backward_time=0.161, optim_step_time=0.058, optim0_lr0=3.182e-04, train_time=2.795
[ALab02] 2023-06-07 22:18:01,576 (trainer:721) INFO: 26epoch:train:1640-1788batch: iter_time=0.269, forward_time=0.191, loss_ctc=5.009, loss=5.009, backward_time=0.163, optim_step_time=0.057, optim0_lr0=3.188e-04, train_time=2.746
[ALab02] 2023-06-07 22:19:40,072 (trainer:721) INFO: 26epoch:train:1789-1937batch: iter_time=0.248, forward_time=0.188, loss_ctc=5.142, loss=5.142, backward_time=0.162, optim_step_time=0.056, optim0_lr0=3.194e-04, train_time=2.650
[ALab02] 2023-06-07 22:21:21,809 (trainer:721) INFO: 26epoch:train:1938-2086batch: iter_time=0.268, forward_time=0.191, loss_ctc=5.324, loss=5.324, backward_time=0.161, optim_step_time=0.053, optim0_lr0=3.201e-04, train_time=2.734
[ALab02] 2023-06-07 22:23:05,815 (trainer:721) INFO: 26epoch:train:2087-2235batch: iter_time=0.278, forward_time=0.193, loss_ctc=4.916, loss=4.916, backward_time=0.161, optim_step_time=0.054, optim0_lr0=3.207e-04, train_time=2.774
[ALab02] 2023-06-07 22:24:50,529 (trainer:721) INFO: 26epoch:train:2236-2384batch: iter_time=0.281, forward_time=0.195, loss_ctc=5.043, loss=5.043, backward_time=0.163, optim_step_time=0.061, optim0_lr0=3.213e-04, train_time=2.817
[ALab02] 2023-06-07 22:26:35,621 (trainer:721) INFO: 26epoch:train:2385-2533batch: iter_time=0.281, forward_time=0.195, loss_ctc=5.093, loss=5.093, backward_time=0.163, optim_step_time=0.061, optim0_lr0=3.219e-04, train_time=2.821
[ALab02] 2023-06-07 22:28:21,149 (trainer:721) INFO: 26epoch:train:2534-2682batch: iter_time=0.294, forward_time=0.190, loss_ctc=4.919, loss=4.919, backward_time=0.161, optim_step_time=0.054, optim0_lr0=3.226e-04, train_time=2.843
[ALab02] 2023-06-07 22:30:06,491 (trainer:721) INFO: 26epoch:train:2683-2831batch: iter_time=0.287, forward_time=0.193, loss_ctc=5.347, loss=5.347, backward_time=0.162, optim_step_time=0.055, optim0_lr0=3.232e-04, train_time=2.826
[ALab02] 2023-06-07 22:31:47,187 (trainer:721) INFO: 26epoch:train:2832-2980batch: iter_time=0.257, forward_time=0.191, loss_ctc=4.675, loss=4.675, backward_time=0.161, optim_step_time=0.057, optim0_lr0=3.238e-04, train_time=2.696
[ALab02] 2023-06-07 22:32:58,979 (trainer:338) INFO: 26epoch results: [train] iter_time=0.277, forward_time=0.191, loss_ctc=5.122, loss=5.122, backward_time=0.162, optim_step_time=0.057, optim0_lr0=3.179e-04, train_time=2.777, time=34 minutes and 38.57 seconds, total_count=77844, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.031, cer_ctc=0.349, cer=0.349, loss=15.031, time=21.72 seconds, total_count=780, gpu_max_cached_mem_GB=52.041, [att_plot] time=39.97 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 22:33:03,183 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 22:33:03,188 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/16epoch.pth
[ALab02] 2023-06-07 22:33:03,188 (trainer:272) INFO: 27/70epoch started. Estimated time to finish: 20 hours, 4 minutes and 41.4 seconds
[ALab02] 2023-06-07 22:34:47,899 (trainer:721) INFO: 27epoch:train:1-149batch: iter_time=0.284, forward_time=0.191, loss_ctc=5.090, loss=5.090, backward_time=0.164, optim_step_time=0.058, optim0_lr0=3.245e-04, train_time=2.816
[ALab02] 2023-06-07 22:36:26,216 (trainer:721) INFO: 27epoch:train:150-298batch: iter_time=0.248, forward_time=0.188, loss_ctc=4.872, loss=4.872, backward_time=0.163, optim_step_time=0.055, optim0_lr0=3.251e-04, train_time=2.639
[ALab02] 2023-06-07 22:38:10,817 (trainer:721) INFO: 27epoch:train:299-447batch: iter_time=0.299, forward_time=0.185, loss_ctc=4.904, loss=4.904, backward_time=0.160, optim_step_time=0.052, optim0_lr0=3.257e-04, train_time=2.805
[ALab02] 2023-06-07 22:39:54,434 (trainer:721) INFO: 27epoch:train:448-596batch: iter_time=0.275, forward_time=0.194, loss_ctc=4.657, loss=4.657, backward_time=0.163, optim_step_time=0.059, optim0_lr0=3.263e-04, train_time=2.777
[ALab02] 2023-06-07 22:41:38,818 (trainer:721) INFO: 27epoch:train:597-745batch: iter_time=0.291, forward_time=0.188, loss_ctc=5.041, loss=5.041, backward_time=0.161, optim_step_time=0.055, optim0_lr0=3.270e-04, train_time=2.813
[ALab02] 2023-06-07 22:43:18,015 (trainer:721) INFO: 27epoch:train:746-894batch: iter_time=0.256, forward_time=0.186, loss_ctc=5.063, loss=5.063, backward_time=0.161, optim_step_time=0.057, optim0_lr0=3.276e-04, train_time=2.663
[ALab02] 2023-06-07 22:44:58,734 (trainer:721) INFO: 27epoch:train:895-1043batch: iter_time=0.256, forward_time=0.190, loss_ctc=5.354, loss=5.354, backward_time=0.163, optim_step_time=0.059, optim0_lr0=3.282e-04, train_time=2.692
[ALab02] 2023-06-07 22:46:43,988 (trainer:721) INFO: 27epoch:train:1044-1192batch: iter_time=0.293, forward_time=0.185, loss_ctc=5.267, loss=5.267, backward_time=0.162, optim_step_time=0.057, optim0_lr0=3.288e-04, train_time=2.823
[ALab02] 2023-06-07 22:48:22,236 (trainer:721) INFO: 27epoch:train:1193-1341batch: iter_time=0.246, forward_time=0.189, loss_ctc=5.171, loss=5.171, backward_time=0.162, optim_step_time=0.055, optim0_lr0=3.294e-04, train_time=2.641
[ALab02] 2023-06-07 22:50:08,020 (trainer:721) INFO: 27epoch:train:1342-1490batch: iter_time=0.286, forward_time=0.197, loss_ctc=4.842, loss=4.842, backward_time=0.162, optim_step_time=0.064, optim0_lr0=3.300e-04, train_time=2.836
[ALab02] 2023-06-07 22:51:53,753 (trainer:721) INFO: 27epoch:train:1491-1639batch: iter_time=0.299, forward_time=0.187, loss_ctc=4.730, loss=4.730, backward_time=0.160, optim_step_time=0.058, optim0_lr0=3.307e-04, train_time=2.844
[ALab02] 2023-06-07 22:53:33,559 (trainer:721) INFO: 27epoch:train:1640-1788batch: iter_time=0.257, forward_time=0.187, loss_ctc=4.859, loss=4.859, backward_time=0.162, optim_step_time=0.054, optim0_lr0=3.313e-04, train_time=2.674
[ALab02] 2023-06-07 22:55:13,732 (trainer:721) INFO: 27epoch:train:1789-1937batch: iter_time=0.265, forward_time=0.184, loss_ctc=5.200, loss=5.200, backward_time=0.161, optim_step_time=0.052, optim0_lr0=3.319e-04, train_time=2.695
[ALab02] 2023-06-07 22:56:51,254 (trainer:721) INFO: 27epoch:train:1938-2086batch: iter_time=0.238, forward_time=0.191, loss_ctc=4.829, loss=4.829, backward_time=0.161, optim_step_time=0.055, optim0_lr0=3.325e-04, train_time=2.613
[ALab02] 2023-06-07 22:58:24,972 (trainer:721) INFO: 27epoch:train:2087-2235batch: iter_time=0.219, forward_time=0.185, loss_ctc=4.780, loss=4.780, backward_time=0.161, optim_step_time=0.052, optim0_lr0=3.331e-04, train_time=2.523
[ALab02] 2023-06-07 22:59:55,333 (trainer:721) INFO: 27epoch:train:2236-2384batch: iter_time=0.197, forward_time=0.181, loss_ctc=5.152, loss=5.152, backward_time=0.162, optim_step_time=0.053, optim0_lr0=3.338e-04, train_time=2.420
[ALab02] 2023-06-07 23:01:23,691 (trainer:721) INFO: 27epoch:train:2385-2533batch: iter_time=0.186, forward_time=0.181, loss_ctc=4.710, loss=4.710, backward_time=0.161, optim_step_time=0.048, optim0_lr0=3.344e-04, train_time=2.373
[ALab02] 2023-06-07 23:02:49,864 (trainer:721) INFO: 27epoch:train:2534-2682batch: iter_time=0.170, forward_time=0.180, loss_ctc=4.891, loss=4.891, backward_time=0.160, optim_step_time=0.048, optim0_lr0=3.350e-04, train_time=2.308
[ALab02] 2023-06-07 23:04:14,434 (trainer:721) INFO: 27epoch:train:2683-2831batch: iter_time=0.149, forward_time=0.178, loss_ctc=5.414, loss=5.414, backward_time=0.162, optim_step_time=0.048, optim0_lr0=3.356e-04, train_time=2.287
[ALab02] 2023-06-07 23:05:39,601 (trainer:721) INFO: 27epoch:train:2832-2980batch: iter_time=0.157, forward_time=0.178, loss_ctc=4.730, loss=4.730, backward_time=0.159, optim_step_time=0.049, optim0_lr0=3.363e-04, train_time=2.274
[ALab02] 2023-06-07 23:06:38,460 (trainer:338) INFO: 27epoch results: [train] iter_time=0.243, forward_time=0.186, loss_ctc=4.967, loss=4.967, backward_time=0.162, optim_step_time=0.054, optim0_lr0=3.304e-04, train_time=2.625, time=32 minutes and 44.62 seconds, total_count=80838, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.544, cer_ctc=0.337, cer=0.337, loss=14.544, time=18.45 seconds, total_count=810, gpu_max_cached_mem_GB=52.041, [att_plot] time=32.2 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 23:06:41,161 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 23:06:41,165 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/17epoch.pth
[ALab02] 2023-06-07 23:06:41,165 (trainer:272) INFO: 28/70epoch started. Estimated time to finish: 19 hours, 47 minutes and 16.21 seconds
[ALab02] 2023-06-07 23:08:07,903 (trainer:721) INFO: 28epoch:train:1-149batch: iter_time=0.152, forward_time=0.178, loss_ctc=5.125, loss=5.125, backward_time=0.162, optim_step_time=0.046, optim0_lr0=3.369e-04, train_time=2.334
[ALab02] 2023-06-07 23:09:29,042 (trainer:721) INFO: 28epoch:train:150-298batch: iter_time=0.125, forward_time=0.176, loss_ctc=4.713, loss=4.713, backward_time=0.160, optim_step_time=0.042, optim0_lr0=3.375e-04, train_time=2.180
[ALab02] 2023-06-07 23:10:51,855 (trainer:721) INFO: 28epoch:train:299-447batch: iter_time=0.118, forward_time=0.176, loss_ctc=5.206, loss=5.206, backward_time=0.162, optim_step_time=0.044, optim0_lr0=3.382e-04, train_time=2.227
[ALab02] 2023-06-07 23:12:08,802 (trainer:721) INFO: 28epoch:train:448-596batch: iter_time=0.069, forward_time=0.174, loss_ctc=4.880, loss=4.880, backward_time=0.161, optim_step_time=0.042, optim0_lr0=3.388e-04, train_time=2.056
[ALab02] 2023-06-07 23:13:24,402 (trainer:721) INFO: 28epoch:train:597-745batch: iter_time=0.065, forward_time=0.170, loss_ctc=4.742, loss=4.742, backward_time=0.156, optim_step_time=0.043, optim0_lr0=3.394e-04, train_time=2.035
[ALab02] 2023-06-07 23:14:41,304 (trainer:721) INFO: 28epoch:train:746-894batch: iter_time=0.069, forward_time=0.176, loss_ctc=4.686, loss=4.686, backward_time=0.159, optim_step_time=0.045, optim0_lr0=3.400e-04, train_time=2.065
[ALab02] 2023-06-07 23:15:56,244 (trainer:721) INFO: 28epoch:train:895-1043batch: iter_time=0.040, forward_time=0.170, loss_ctc=4.950, loss=4.950, backward_time=0.159, optim_step_time=0.039, optim0_lr0=3.407e-04, train_time=2.011
[ALab02] 2023-06-07 23:17:13,176 (trainer:721) INFO: 28epoch:train:1044-1192batch: iter_time=0.067, forward_time=0.174, loss_ctc=4.791, loss=4.791, backward_time=0.160, optim_step_time=0.041, optim0_lr0=3.413e-04, train_time=2.059
[ALab02] 2023-06-07 23:18:29,999 (trainer:721) INFO: 28epoch:train:1193-1341batch: iter_time=0.028, forward_time=0.178, loss_ctc=4.787, loss=4.787, backward_time=0.164, optim_step_time=0.038, optim0_lr0=3.419e-04, train_time=2.066
[ALab02] 2023-06-07 23:19:46,193 (trainer:721) INFO: 28epoch:train:1342-1490batch: iter_time=0.011, forward_time=0.176, loss_ctc=5.034, loss=5.034, backward_time=0.163, optim_step_time=0.038, optim0_lr0=3.425e-04, train_time=2.047
[ALab02] 2023-06-07 23:21:00,420 (trainer:721) INFO: 28epoch:train:1491-1639batch: iter_time=0.005, forward_time=0.172, loss_ctc=4.938, loss=4.938, backward_time=0.158, optim_step_time=0.037, optim0_lr0=3.431e-04, train_time=1.991
[ALab02] 2023-06-07 23:22:15,931 (trainer:721) INFO: 28epoch:train:1640-1788batch: iter_time=3.016e-04, forward_time=0.177, loss_ctc=4.550, loss=4.550, backward_time=0.161, optim_step_time=0.035, optim0_lr0=3.438e-04, train_time=2.023
[ALab02] 2023-06-07 23:23:30,096 (trainer:721) INFO: 28epoch:train:1789-1937batch: iter_time=6.940e-04, forward_time=0.173, loss_ctc=4.760, loss=4.760, backward_time=0.160, optim_step_time=0.036, optim0_lr0=3.444e-04, train_time=1.995
[ALab02] 2023-06-07 23:24:44,832 (trainer:721) INFO: 28epoch:train:1938-2086batch: iter_time=0.002, forward_time=0.172, loss_ctc=4.978, loss=4.978, backward_time=0.160, optim_step_time=0.036, optim0_lr0=3.450e-04, train_time=2.005
[ALab02] 2023-06-07 23:25:58,298 (trainer:721) INFO: 28epoch:train:2087-2235batch: iter_time=8.467e-04, forward_time=0.167, loss_ctc=4.865, loss=4.865, backward_time=0.159, optim_step_time=0.036, optim0_lr0=3.456e-04, train_time=1.973
[ALab02] 2023-06-07 23:27:11,879 (trainer:721) INFO: 28epoch:train:2236-2384batch: iter_time=0.018, forward_time=0.165, loss_ctc=4.574, loss=4.574, backward_time=0.157, optim_step_time=0.035, optim0_lr0=3.462e-04, train_time=1.971
[ALab02] 2023-06-07 23:28:24,751 (trainer:721) INFO: 28epoch:train:2385-2533batch: iter_time=2.806e-04, forward_time=0.166, loss_ctc=4.858, loss=4.858, backward_time=0.159, optim_step_time=0.035, optim0_lr0=3.469e-04, train_time=1.959
[ALab02] 2023-06-07 23:29:54,425 (trainer:721) INFO: 28epoch:train:2534-2682batch: iter_time=0.173, forward_time=0.182, loss_ctc=4.706, loss=4.706, backward_time=0.159, optim_step_time=0.051, optim0_lr0=3.475e-04, train_time=2.403
[ALab02] 2023-06-07 23:31:39,878 (trainer:721) INFO: 28epoch:train:2683-2831batch: iter_time=0.292, forward_time=0.191, loss_ctc=4.658, loss=4.658, backward_time=0.159, optim_step_time=0.060, optim0_lr0=3.481e-04, train_time=2.826
[ALab02] 2023-06-07 23:33:23,491 (trainer:721) INFO: 28epoch:train:2832-2980batch: iter_time=0.278, forward_time=0.190, loss_ctc=4.839, loss=4.839, backward_time=0.162, optim_step_time=0.061, optim0_lr0=3.487e-04, train_time=2.779
[ALab02] 2023-06-07 23:34:33,005 (trainer:338) INFO: 28epoch results: [train] iter_time=0.076, forward_time=0.175, loss_ctc=4.827, loss=4.827, backward_time=0.160, optim_step_time=0.042, optim0_lr0=3.429e-04, train_time=2.152, time=26 minutes and 51.24 seconds, total_count=83832, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.522, cer_ctc=0.335, cer=0.335, loss=14.522, time=20.95 seconds, total_count=840, gpu_max_cached_mem_GB=52.041, [att_plot] time=39.65 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-07 23:34:37,307 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-07 23:34:37,311 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/18epoch.pth
[ALab02] 2023-06-07 23:34:37,311 (trainer:272) INFO: 29/70epoch started. Estimated time to finish: 19 hours, 20 minutes and 8.78 seconds
[ALab02] 2023-06-07 23:36:19,332 (trainer:721) INFO: 29epoch:train:1-149batch: iter_time=0.262, forward_time=0.195, loss_ctc=4.696, loss=4.696, backward_time=0.164, optim_step_time=0.056, optim0_lr0=3.494e-04, train_time=2.746
[ALab02] 2023-06-07 23:37:53,217 (trainer:721) INFO: 29epoch:train:150-298batch: iter_time=0.215, forward_time=0.188, loss_ctc=4.895, loss=4.895, backward_time=0.162, optim_step_time=0.052, optim0_lr0=3.500e-04, train_time=2.526
[ALab02] 2023-06-07 23:39:17,441 (trainer:721) INFO: 29epoch:train:299-447batch: iter_time=0.150, forward_time=0.178, loss_ctc=4.592, loss=4.592, backward_time=0.159, optim_step_time=0.045, optim0_lr0=3.506e-04, train_time=2.262
[ALab02] 2023-06-07 23:40:32,834 (trainer:721) INFO: 29epoch:train:448-596batch: iter_time=0.009, forward_time=0.172, loss_ctc=5.047, loss=5.047, backward_time=0.162, optim_step_time=0.037, optim0_lr0=3.513e-04, train_time=2.018
[ALab02] 2023-06-07 23:41:46,366 (trainer:721) INFO: 29epoch:train:597-745batch: iter_time=2.661e-04, forward_time=0.168, loss_ctc=4.941, loss=4.941, backward_time=0.158, optim_step_time=0.038, optim0_lr0=3.519e-04, train_time=1.979
[ALab02] 2023-06-07 23:42:59,716 (trainer:721) INFO: 29epoch:train:746-894batch: iter_time=2.224e-04, forward_time=0.165, loss_ctc=4.822, loss=4.822, backward_time=0.159, optim_step_time=0.034, optim0_lr0=3.525e-04, train_time=1.970
[ALab02] 2023-06-07 23:44:38,554 (trainer:721) INFO: 29epoch:train:895-1043batch: iter_time=0.231, forward_time=0.189, loss_ctc=4.670, loss=4.670, backward_time=0.162, optim_step_time=0.054, optim0_lr0=3.531e-04, train_time=2.637
[ALab02] 2023-06-07 23:46:24,117 (trainer:721) INFO: 29epoch:train:1044-1192batch: iter_time=0.284, forward_time=0.196, loss_ctc=4.617, loss=4.617, backward_time=0.163, optim_step_time=0.056, optim0_lr0=3.537e-04, train_time=2.830
[ALab02] 2023-06-07 23:48:12,320 (trainer:721) INFO: 29epoch:train:1193-1341batch: iter_time=0.309, forward_time=0.193, loss_ctc=4.827, loss=4.827, backward_time=0.161, optim_step_time=0.056, optim0_lr0=3.544e-04, train_time=2.909
[ALab02] 2023-06-07 23:49:56,851 (trainer:721) INFO: 29epoch:train:1342-1490batch: iter_time=0.288, forward_time=0.191, loss_ctc=4.777, loss=4.777, backward_time=0.161, optim_step_time=0.053, optim0_lr0=3.550e-04, train_time=2.797
[ALab02] 2023-06-07 23:51:57,449 (trainer:721) INFO: 29epoch:train:1491-1639batch: iter_time=0.377, forward_time=0.204, loss_ctc=4.718, loss=4.718, backward_time=0.163, optim_step_time=0.065, optim0_lr0=3.556e-04, train_time=3.231
[ALab02] 2023-06-07 23:53:43,607 (trainer:721) INFO: 29epoch:train:1640-1788batch: iter_time=0.292, forward_time=0.195, loss_ctc=4.681, loss=4.681, backward_time=0.161, optim_step_time=0.057, optim0_lr0=3.562e-04, train_time=2.862
[ALab02] 2023-06-07 23:55:08,875 (trainer:721) INFO: 29epoch:train:1789-1937batch: iter_time=0.141, forward_time=0.180, loss_ctc=4.673, loss=4.673, backward_time=0.163, optim_step_time=0.047, optim0_lr0=3.568e-04, train_time=2.295
[ALab02] 2023-06-07 23:56:25,965 (trainer:721) INFO: 29epoch:train:1938-2086batch: iter_time=0.042, forward_time=0.174, loss_ctc=4.503, loss=4.503, backward_time=0.161, optim_step_time=0.038, optim0_lr0=3.575e-04, train_time=2.071
[ALab02] 2023-06-07 23:57:39,525 (trainer:721) INFO: 29epoch:train:2087-2235batch: iter_time=2.717e-04, forward_time=0.168, loss_ctc=4.723, loss=4.723, backward_time=0.160, optim_step_time=0.036, optim0_lr0=3.581e-04, train_time=1.976
[ALab02] 2023-06-07 23:59:20,673 (trainer:721) INFO: 29epoch:train:2236-2384batch: iter_time=0.206, forward_time=0.186, loss_ctc=4.466, loss=4.466, backward_time=0.160, optim_step_time=0.050, optim0_lr0=3.587e-04, train_time=2.694
[ALab02] 2023-06-08 00:01:30,106 (trainer:721) INFO: 29epoch:train:2385-2533batch: iter_time=0.440, forward_time=0.201, loss_ctc=4.520, loss=4.520, backward_time=0.162, optim_step_time=0.067, optim0_lr0=3.593e-04, train_time=3.484
[ALab02] 2023-06-08 00:03:35,612 (trainer:721) INFO: 29epoch:train:2534-2682batch: iter_time=0.414, forward_time=0.200, loss_ctc=4.700, loss=4.700, backward_time=0.162, optim_step_time=0.067, optim0_lr0=3.600e-04, train_time=3.370
[ALab02] 2023-06-08 00:05:39,075 (trainer:721) INFO: 29epoch:train:2683-2831batch: iter_time=0.400, forward_time=0.202, loss_ctc=4.767, loss=4.767, backward_time=0.161, optim_step_time=0.064, optim0_lr0=3.606e-04, train_time=3.317
[ALab02] 2023-06-08 00:07:35,279 (trainer:721) INFO: 29epoch:train:2832-2980batch: iter_time=0.358, forward_time=0.197, loss_ctc=4.665, loss=4.665, backward_time=0.160, optim_step_time=0.060, optim0_lr0=3.612e-04, train_time=3.111
[ALab02] 2023-06-08 00:08:50,911 (trainer:338) INFO: 29epoch results: [train] iter_time=0.222, forward_time=0.187, loss_ctc=4.709, loss=4.709, backward_time=0.161, optim_step_time=0.052, optim0_lr0=3.553e-04, train_time=2.657, time=33 minutes and 9.21 seconds, total_count=86826, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.217, cer_ctc=0.323, cer=0.323, loss=14.217, time=20.15 seconds, total_count=870, gpu_max_cached_mem_GB=52.041, [att_plot] time=44.23 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 00:08:55,081 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 00:08:55,087 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/19epoch.pth
[ALab02] 2023-06-08 00:08:55,087 (trainer:272) INFO: 30/70epoch started. Estimated time to finish: 19 hours, 1 minute and 57.55 seconds
[ALab02] 2023-06-08 00:10:30,980 (trainer:721) INFO: 30epoch:train:1-149batch: iter_time=0.232, forward_time=0.183, loss_ctc=4.508, loss=4.508, backward_time=0.160, optim_step_time=0.048, optim0_lr0=3.619e-04, train_time=2.581
[ALab02] 2023-06-08 00:11:46,263 (trainer:721) INFO: 30epoch:train:150-298batch: iter_time=0.050, forward_time=0.171, loss_ctc=4.642, loss=4.642, backward_time=0.158, optim_step_time=0.038, optim0_lr0=3.625e-04, train_time=2.023
[ALab02] 2023-06-08 00:13:03,537 (trainer:721) INFO: 30epoch:train:299-447batch: iter_time=0.051, forward_time=0.170, loss_ctc=4.350, loss=4.350, backward_time=0.158, optim_step_time=0.039, optim0_lr0=3.631e-04, train_time=2.076
[ALab02] 2023-06-08 00:14:16,559 (trainer:721) INFO: 30epoch:train:448-596batch: iter_time=2.411e-04, forward_time=0.164, loss_ctc=4.682, loss=4.682, backward_time=0.159, optim_step_time=0.035, optim0_lr0=3.637e-04, train_time=1.953
[ALab02] 2023-06-08 00:16:24,083 (trainer:721) INFO: 30epoch:train:597-745batch: iter_time=0.400, forward_time=0.206, loss_ctc=4.602, loss=4.602, backward_time=0.164, optim_step_time=0.067, optim0_lr0=3.643e-04, train_time=3.427
[ALab02] 2023-06-08 00:18:35,400 (trainer:721) INFO: 30epoch:train:746-894batch: iter_time=0.432, forward_time=0.214, loss_ctc=4.684, loss=4.684, backward_time=0.165, optim_step_time=0.074, optim0_lr0=3.650e-04, train_time=3.532
[ALab02] 2023-06-08 00:20:35,788 (trainer:721) INFO: 30epoch:train:895-1043batch: iter_time=0.369, forward_time=0.211, loss_ctc=4.820, loss=4.820, backward_time=0.162, optim_step_time=0.066, optim0_lr0=3.656e-04, train_time=3.230
[ALab02] 2023-06-08 00:22:41,412 (trainer:721) INFO: 30epoch:train:1044-1192batch: iter_time=0.402, forward_time=0.209, loss_ctc=4.672, loss=4.672, backward_time=0.163, optim_step_time=0.066, optim0_lr0=3.662e-04, train_time=3.361
[ALab02] 2023-06-08 00:24:40,564 (trainer:721) INFO: 30epoch:train:1193-1341batch: iter_time=0.367, forward_time=0.204, loss_ctc=4.648, loss=4.648, backward_time=0.163, optim_step_time=0.065, optim0_lr0=3.668e-04, train_time=3.209
[ALab02] 2023-06-08 00:26:39,362 (trainer:721) INFO: 30epoch:train:1342-1490batch: iter_time=0.367, forward_time=0.202, loss_ctc=4.802, loss=4.802, backward_time=0.164, optim_step_time=0.064, optim0_lr0=3.675e-04, train_time=3.182
[ALab02] 2023-06-08 00:28:14,110 (trainer:721) INFO: 30epoch:train:1491-1639batch: iter_time=0.214, forward_time=0.192, loss_ctc=4.519, loss=4.519, backward_time=0.163, optim_step_time=0.051, optim0_lr0=3.681e-04, train_time=2.556
[ALab02] 2023-06-08 00:29:32,464 (trainer:721) INFO: 30epoch:train:1640-1788batch: iter_time=0.097, forward_time=0.174, loss_ctc=4.444, loss=4.444, backward_time=0.161, optim_step_time=0.042, optim0_lr0=3.687e-04, train_time=2.105
[ALab02] 2023-06-08 00:30:48,466 (trainer:721) INFO: 30epoch:train:1789-1937batch: iter_time=0.023, forward_time=0.174, loss_ctc=4.507, loss=4.507, backward_time=0.161, optim_step_time=0.038, optim0_lr0=3.693e-04, train_time=2.044
[ALab02] 2023-06-08 00:32:01,555 (trainer:721) INFO: 30epoch:train:1938-2086batch: iter_time=0.006, forward_time=0.165, loss_ctc=4.416, loss=4.416, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.699e-04, train_time=1.963
[ALab02] 2023-06-08 00:33:53,443 (trainer:721) INFO: 30epoch:train:2087-2235batch: iter_time=0.291, forward_time=0.200, loss_ctc=4.432, loss=4.432, backward_time=0.162, optim_step_time=0.065, optim0_lr0=3.705e-04, train_time=2.976
[ALab02] 2023-06-08 00:35:57,018 (trainer:721) INFO: 30epoch:train:2236-2384batch: iter_time=0.389, forward_time=0.210, loss_ctc=4.373, loss=4.373, backward_time=0.163, optim_step_time=0.065, optim0_lr0=3.712e-04, train_time=3.318
[ALab02] 2023-06-08 00:38:02,026 (trainer:721) INFO: 30epoch:train:2385-2533batch: iter_time=0.406, forward_time=0.205, loss_ctc=4.594, loss=4.594, backward_time=0.163, optim_step_time=0.067, optim0_lr0=3.718e-04, train_time=3.353
[ALab02] 2023-06-08 00:39:59,304 (trainer:721) INFO: 30epoch:train:2534-2682batch: iter_time=0.356, forward_time=0.203, loss_ctc=4.370, loss=4.370, backward_time=0.162, optim_step_time=0.063, optim0_lr0=3.724e-04, train_time=3.160
[ALab02] 2023-06-08 00:41:55,204 (trainer:721) INFO: 30epoch:train:2683-2831batch: iter_time=0.349, forward_time=0.201, loss_ctc=4.569, loss=4.569, backward_time=0.164, optim_step_time=0.058, optim0_lr0=3.730e-04, train_time=3.100
[ALab02] 2023-06-08 00:43:44,494 (trainer:721) INFO: 30epoch:train:2832-2980batch: iter_time=0.297, forward_time=0.203, loss_ctc=4.703, loss=4.703, backward_time=0.163, optim_step_time=0.067, optim0_lr0=3.737e-04, train_time=2.941
[ALab02] 2023-06-08 00:44:51,563 (trainer:338) INFO: 30epoch results: [train] iter_time=0.255, forward_time=0.193, loss_ctc=4.563, loss=4.563, backward_time=0.162, optim_step_time=0.056, optim0_lr0=3.678e-04, train_time=2.804, time=34 minutes and 59.52 seconds, total_count=89820, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.428, cer_ctc=0.325, cer=0.325, loss=14.428, time=20.62 seconds, total_count=900, gpu_max_cached_mem_GB=52.041, [att_plot] time=36.33 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 00:44:54,790 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 00:44:54,794 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/22epoch.pth
[ALab02] 2023-06-08 00:44:54,794 (trainer:272) INFO: 31/70epoch started. Estimated time to finish: 18 hours, 44 minutes and 57.79 seconds
[ALab02] 2023-06-08 00:46:12,640 (trainer:721) INFO: 31epoch:train:1-149batch: iter_time=0.075, forward_time=0.174, loss_ctc=4.525, loss=4.525, backward_time=0.159, optim_step_time=0.042, optim0_lr0=3.743e-04, train_time=2.095
[ALab02] 2023-06-08 00:47:26,307 (trainer:721) INFO: 31epoch:train:150-298batch: iter_time=0.011, forward_time=0.170, loss_ctc=4.334, loss=4.334, backward_time=0.157, optim_step_time=0.038, optim0_lr0=3.749e-04, train_time=1.977
[ALab02] 2023-06-08 00:48:39,533 (trainer:721) INFO: 31epoch:train:299-447batch: iter_time=2.573e-04, forward_time=0.165, loss_ctc=4.734, loss=4.734, backward_time=0.158, optim_step_time=0.035, optim0_lr0=3.756e-04, train_time=1.964
[ALab02] 2023-06-08 00:49:55,303 (trainer:721) INFO: 31epoch:train:448-596batch: iter_time=0.019, forward_time=0.169, loss_ctc=4.370, loss=4.370, backward_time=0.159, optim_step_time=0.036, optim0_lr0=3.762e-04, train_time=2.030
[ALab02] 2023-06-08 00:51:54,155 (trainer:721) INFO: 31epoch:train:597-745batch: iter_time=0.367, forward_time=0.203, loss_ctc=4.331, loss=4.331, backward_time=0.162, optim_step_time=0.068, optim0_lr0=3.768e-04, train_time=3.187
[ALab02] 2023-06-08 00:53:57,433 (trainer:721) INFO: 31epoch:train:746-894batch: iter_time=0.397, forward_time=0.204, loss_ctc=4.287, loss=4.287, backward_time=0.161, optim_step_time=0.063, optim0_lr0=3.774e-04, train_time=3.327
[ALab02] 2023-06-08 00:55:50,957 (trainer:721) INFO: 31epoch:train:895-1043batch: iter_time=0.342, forward_time=0.197, loss_ctc=4.426, loss=4.426, backward_time=0.159, optim_step_time=0.061, optim0_lr0=3.781e-04, train_time=3.040
[ALab02] 2023-06-08 00:57:50,392 (trainer:721) INFO: 31epoch:train:1044-1192batch: iter_time=0.366, forward_time=0.206, loss_ctc=4.416, loss=4.416, backward_time=0.163, optim_step_time=0.064, optim0_lr0=3.787e-04, train_time=3.198
[ALab02] 2023-06-08 00:59:36,055 (trainer:721) INFO: 31epoch:train:1193-1341batch: iter_time=0.287, forward_time=0.197, loss_ctc=4.435, loss=4.435, backward_time=0.162, optim_step_time=0.057, optim0_lr0=3.793e-04, train_time=2.842
[ALab02] 2023-06-08 01:01:19,119 (trainer:721) INFO: 31epoch:train:1342-1490batch: iter_time=0.277, forward_time=0.191, loss_ctc=4.429, loss=4.429, backward_time=0.161, optim_step_time=0.056, optim0_lr0=3.799e-04, train_time=2.767
[ALab02] 2023-06-08 01:02:39,685 (trainer:721) INFO: 31epoch:train:1491-1639batch: iter_time=0.107, forward_time=0.178, loss_ctc=4.305, loss=4.305, backward_time=0.159, optim_step_time=0.046, optim0_lr0=3.805e-04, train_time=2.175
[ALab02] 2023-06-08 01:03:55,397 (trainer:721) INFO: 31epoch:train:1640-1788batch: iter_time=0.032, forward_time=0.172, loss_ctc=4.482, loss=4.482, backward_time=0.159, optim_step_time=0.038, optim0_lr0=3.812e-04, train_time=2.025
[ALab02] 2023-06-08 01:05:11,989 (trainer:721) INFO: 31epoch:train:1789-1937batch: iter_time=0.025, forward_time=0.170, loss_ctc=4.293, loss=4.293, backward_time=0.159, optim_step_time=0.036, optim0_lr0=3.818e-04, train_time=2.056
[ALab02] 2023-06-08 01:07:28,037 (trainer:721) INFO: 31epoch:train:1938-2086batch: iter_time=0.466, forward_time=0.215, loss_ctc=4.547, loss=4.547, backward_time=0.164, optim_step_time=0.070, optim0_lr0=3.824e-04, train_time=3.639
[ALab02] 2023-06-08 01:09:16,507 (trainer:721) INFO: 31epoch:train:2087-2235batch: iter_time=0.303, forward_time=0.198, loss_ctc=4.483, loss=4.483, backward_time=0.162, optim_step_time=0.060, optim0_lr0=3.830e-04, train_time=2.932
[ALab02] 2023-06-08 01:11:00,558 (trainer:721) INFO: 31epoch:train:2236-2384batch: iter_time=0.279, forward_time=0.193, loss_ctc=4.443, loss=4.443, backward_time=0.161, optim_step_time=0.061, optim0_lr0=3.836e-04, train_time=2.787
[ALab02] 2023-06-08 01:12:42,259 (trainer:721) INFO: 31epoch:train:2385-2533batch: iter_time=0.267, forward_time=0.192, loss_ctc=4.542, loss=4.542, backward_time=0.160, optim_step_time=0.062, optim0_lr0=3.843e-04, train_time=2.738
[ALab02] 2023-06-08 01:14:25,681 (trainer:721) INFO: 31epoch:train:2534-2682batch: iter_time=0.283, forward_time=0.189, loss_ctc=4.533, loss=4.533, backward_time=0.160, optim_step_time=0.055, optim0_lr0=3.849e-04, train_time=2.775
[ALab02] 2023-06-08 01:16:03,101 (trainer:721) INFO: 31epoch:train:2683-2831batch: iter_time=0.236, forward_time=0.188, loss_ctc=4.505, loss=4.505, backward_time=0.160, optim_step_time=0.052, optim0_lr0=3.855e-04, train_time=2.624
[ALab02] 2023-06-08 01:17:21,927 (trainer:721) INFO: 31epoch:train:2832-2980batch: iter_time=0.091, forward_time=0.176, loss_ctc=4.323, loss=4.323, backward_time=0.158, optim_step_time=0.042, optim0_lr0=3.861e-04, train_time=2.112
[ALab02] 2023-06-08 01:18:15,364 (trainer:338) INFO: 31epoch results: [train] iter_time=0.211, forward_time=0.187, loss_ctc=4.432, loss=4.432, backward_time=0.160, optim_step_time=0.052, optim0_lr0=3.803e-04, train_time=2.611, time=32 minutes and 34.17 seconds, total_count=92814, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.326, cer_ctc=0.322, cer=0.322, loss=14.326, time=16.81 seconds, total_count=930, gpu_max_cached_mem_GB=52.041, [att_plot] time=29.58 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 01:18:17,905 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 01:18:17,907 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/20epoch.pth
[ALab02] 2023-06-08 01:18:17,907 (trainer:272) INFO: 32/70epoch started. Estimated time to finish: 18 hours, 23 minutes and 27.47 seconds
[ALab02] 2023-06-08 01:19:32,073 (trainer:721) INFO: 32epoch:train:1-149batch: iter_time=0.012, forward_time=0.166, loss_ctc=4.426, loss=4.426, backward_time=0.158, optim_step_time=0.035, optim0_lr0=3.868e-04, train_time=1.993
[ALab02] 2023-06-08 01:20:50,271 (trainer:721) INFO: 32epoch:train:150-298batch: iter_time=0.068, forward_time=0.170, loss_ctc=4.258, loss=4.258, backward_time=0.157, optim_step_time=0.039, optim0_lr0=3.874e-04, train_time=2.095
[ALab02] 2023-06-08 01:22:22,149 (trainer:721) INFO: 32epoch:train:299-447batch: iter_time=0.211, forward_time=0.181, loss_ctc=4.525, loss=4.525, backward_time=0.160, optim_step_time=0.055, optim0_lr0=3.880e-04, train_time=2.470
[ALab02] 2023-06-08 01:23:51,094 (trainer:721) INFO: 32epoch:train:448-596batch: iter_time=0.181, forward_time=0.188, loss_ctc=4.295, loss=4.295, backward_time=0.158, optim_step_time=0.052, optim0_lr0=3.887e-04, train_time=2.381
[ALab02] 2023-06-08 01:25:26,468 (trainer:721) INFO: 32epoch:train:597-745batch: iter_time=0.221, forward_time=0.197, loss_ctc=4.283, loss=4.283, backward_time=0.159, optim_step_time=0.049, optim0_lr0=3.893e-04, train_time=2.562
[ALab02] 2023-06-08 01:26:58,163 (trainer:721) INFO: 32epoch:train:746-894batch: iter_time=0.196, forward_time=0.196, loss_ctc=4.377, loss=4.377, backward_time=0.159, optim_step_time=0.052, optim0_lr0=3.899e-04, train_time=2.466
[ALab02] 2023-06-08 01:28:27,818 (trainer:721) INFO: 32epoch:train:895-1043batch: iter_time=0.186, forward_time=0.192, loss_ctc=4.302, loss=4.302, backward_time=0.158, optim_step_time=0.050, optim0_lr0=3.905e-04, train_time=2.399
[ALab02] 2023-06-08 01:29:55,237 (trainer:721) INFO: 32epoch:train:1044-1192batch: iter_time=0.160, forward_time=0.193, loss_ctc=4.116, loss=4.116, backward_time=0.158, optim_step_time=0.050, optim0_lr0=3.911e-04, train_time=2.350
[ALab02] 2023-06-08 01:31:17,723 (trainer:721) INFO: 32epoch:train:1193-1341batch: iter_time=0.069, forward_time=0.187, loss_ctc=4.332, loss=4.332, backward_time=0.162, optim_step_time=0.041, optim0_lr0=3.918e-04, train_time=2.221
[ALab02] 2023-06-08 01:32:33,072 (trainer:721) INFO: 32epoch:train:1342-1490batch: iter_time=0.006, forward_time=0.179, loss_ctc=4.264, loss=4.264, backward_time=0.159, optim_step_time=0.036, optim0_lr0=3.924e-04, train_time=2.024
[ALab02] 2023-06-08 01:33:47,879 (trainer:721) INFO: 32epoch:train:1491-1639batch: iter_time=2.477e-04, forward_time=0.176, loss_ctc=4.380, loss=4.380, backward_time=0.159, optim_step_time=0.035, optim0_lr0=3.930e-04, train_time=2.006
[ALab02] 2023-06-08 01:35:01,555 (trainer:721) INFO: 32epoch:train:1640-1788batch: iter_time=7.933e-04, forward_time=0.172, loss_ctc=4.250, loss=4.250, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.936e-04, train_time=1.975
[ALab02] 2023-06-08 01:36:15,117 (trainer:721) INFO: 32epoch:train:1789-1937batch: iter_time=0.002, forward_time=0.172, loss_ctc=4.204, loss=4.204, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.942e-04, train_time=1.979
[ALab02] 2023-06-08 01:37:31,498 (trainer:721) INFO: 32epoch:train:1938-2086batch: iter_time=0.011, forward_time=0.180, loss_ctc=4.305, loss=4.305, backward_time=0.161, optim_step_time=0.035, optim0_lr0=3.949e-04, train_time=2.048
[ALab02] 2023-06-08 01:38:46,366 (trainer:721) INFO: 32epoch:train:2087-2235batch: iter_time=0.009, forward_time=0.175, loss_ctc=4.308, loss=4.308, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.955e-04, train_time=2.010
[ALab02] 2023-06-08 01:40:00,842 (trainer:721) INFO: 32epoch:train:2236-2384batch: iter_time=2.455e-04, forward_time=0.174, loss_ctc=4.503, loss=4.503, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.961e-04, train_time=1.996
[ALab02] 2023-06-08 01:41:13,233 (trainer:721) INFO: 32epoch:train:2385-2533batch: iter_time=0.002, forward_time=0.164, loss_ctc=4.388, loss=4.388, backward_time=0.157, optim_step_time=0.033, optim0_lr0=3.967e-04, train_time=1.948
[ALab02] 2023-06-08 01:42:27,018 (trainer:721) INFO: 32epoch:train:2534-2682batch: iter_time=2.351e-04, forward_time=0.168, loss_ctc=4.390, loss=4.390, backward_time=0.160, optim_step_time=0.034, optim0_lr0=3.973e-04, train_time=1.983
[ALab02] 2023-06-08 01:43:39,955 (trainer:721) INFO: 32epoch:train:2683-2831batch: iter_time=2.160e-04, forward_time=0.165, loss_ctc=4.409, loss=4.409, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.980e-04, train_time=1.960
[ALab02] 2023-06-08 01:44:53,542 (trainer:721) INFO: 32epoch:train:2832-2980batch: iter_time=2.508e-04, forward_time=0.165, loss_ctc=4.490, loss=4.490, backward_time=0.160, optim_step_time=0.034, optim0_lr0=3.986e-04, train_time=1.966
[ALab02] 2023-06-08 01:45:40,550 (trainer:338) INFO: 32epoch results: [train] iter_time=0.067, forward_time=0.178, loss_ctc=4.335, loss=4.335, backward_time=0.159, optim_step_time=0.040, optim0_lr0=3.927e-04, train_time=2.141, time=26 minutes and 42.45 seconds, total_count=95808, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.016, cer_ctc=0.330, cer=0.330, loss=14.016, time=14.26 seconds, total_count=960, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.93 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 01:45:42,992 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 01:45:42,994 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/21epoch.pth
[ALab02] 2023-06-08 01:45:42,994 (trainer:272) INFO: 33/70epoch started. Estimated time to finish: 17 hours, 54 minutes and 7.45 seconds
[ALab02] 2023-06-08 01:46:56,773 (trainer:721) INFO: 33epoch:train:1-149batch: iter_time=0.011, forward_time=0.166, loss_ctc=3.985, loss=3.985, backward_time=0.158, optim_step_time=0.033, optim0_lr0=3.993e-04, train_time=1.983
[ALab02] 2023-06-08 01:48:09,123 (trainer:721) INFO: 33epoch:train:150-298batch: iter_time=2.488e-04, forward_time=0.164, loss_ctc=4.241, loss=4.241, backward_time=0.157, optim_step_time=0.033, optim0_lr0=3.999e-04, train_time=1.943
[ALab02] 2023-06-08 01:49:21,252 (trainer:721) INFO: 33epoch:train:299-447batch: iter_time=2.231e-04, forward_time=0.161, loss_ctc=4.323, loss=4.323, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.005e-04, train_time=1.936
[ALab02] 2023-06-08 01:50:34,584 (trainer:721) INFO: 33epoch:train:448-596batch: iter_time=2.289e-04, forward_time=0.166, loss_ctc=4.155, loss=4.155, backward_time=0.159, optim_step_time=0.035, optim0_lr0=4.011e-04, train_time=1.964
[ALab02] 2023-06-08 01:51:47,998 (trainer:721) INFO: 33epoch:train:597-745batch: iter_time=0.007, forward_time=0.166, loss_ctc=4.355, loss=4.355, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.017e-04, train_time=1.975
[ALab02] 2023-06-08 01:53:00,685 (trainer:721) INFO: 33epoch:train:746-894batch: iter_time=2.546e-04, forward_time=0.164, loss_ctc=4.288, loss=4.288, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.024e-04, train_time=1.953
[ALab02] 2023-06-08 01:54:12,751 (trainer:721) INFO: 33epoch:train:895-1043batch: iter_time=2.338e-04, forward_time=0.163, loss_ctc=4.228, loss=4.228, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.030e-04, train_time=1.932
[ALab02] 2023-06-08 01:55:26,045 (trainer:721) INFO: 33epoch:train:1044-1192batch: iter_time=2.118e-04, forward_time=0.163, loss_ctc=4.444, loss=4.444, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.036e-04, train_time=1.963
[ALab02] 2023-06-08 01:56:39,547 (trainer:721) INFO: 33epoch:train:1193-1341batch: iter_time=0.014, forward_time=0.165, loss_ctc=4.400, loss=4.400, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.042e-04, train_time=1.978
[ALab02] 2023-06-08 01:57:51,866 (trainer:721) INFO: 33epoch:train:1342-1490batch: iter_time=2.225e-04, forward_time=0.164, loss_ctc=4.119, loss=4.119, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.049e-04, train_time=1.942
[ALab02] 2023-06-08 01:59:04,347 (trainer:721) INFO: 33epoch:train:1491-1639batch: iter_time=0.002, forward_time=0.164, loss_ctc=4.206, loss=4.206, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.055e-04, train_time=1.945
[ALab02] 2023-06-08 02:00:16,323 (trainer:721) INFO: 33epoch:train:1640-1788batch: iter_time=2.246e-04, forward_time=0.161, loss_ctc=4.389, loss=4.389, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.061e-04, train_time=1.927
[ALab02] 2023-06-08 02:01:28,103 (trainer:721) INFO: 33epoch:train:1789-1937batch: iter_time=2.152e-04, forward_time=0.162, loss_ctc=4.285, loss=4.285, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.067e-04, train_time=1.931
[ALab02] 2023-06-08 02:02:41,070 (trainer:721) INFO: 33epoch:train:1938-2086batch: iter_time=2.257e-04, forward_time=0.166, loss_ctc=4.085, loss=4.085, backward_time=0.158, optim_step_time=0.032, optim0_lr0=4.073e-04, train_time=1.958
[ALab02] 2023-06-08 02:03:53,592 (trainer:721) INFO: 33epoch:train:2087-2235batch: iter_time=2.311e-04, forward_time=0.164, loss_ctc=4.178, loss=4.178, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.080e-04, train_time=1.944
[ALab02] 2023-06-08 02:05:05,857 (trainer:721) INFO: 33epoch:train:2236-2384batch: iter_time=8.616e-04, forward_time=0.163, loss_ctc=4.017, loss=4.017, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.086e-04, train_time=1.939
[ALab02] 2023-06-08 02:06:18,674 (trainer:721) INFO: 33epoch:train:2385-2533batch: iter_time=2.227e-04, forward_time=0.164, loss_ctc=4.271, loss=4.271, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.092e-04, train_time=1.959
[ALab02] 2023-06-08 02:07:32,117 (trainer:721) INFO: 33epoch:train:2534-2682batch: iter_time=2.073e-04, forward_time=0.165, loss_ctc=4.361, loss=4.361, backward_time=0.160, optim_step_time=0.034, optim0_lr0=4.098e-04, train_time=1.970
[ALab02] 2023-06-08 02:08:44,108 (trainer:721) INFO: 33epoch:train:2683-2831batch: iter_time=2.239e-04, forward_time=0.162, loss_ctc=4.275, loss=4.275, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.104e-04, train_time=1.936
[ALab02] 2023-06-08 02:09:57,868 (trainer:721) INFO: 33epoch:train:2832-2980batch: iter_time=2.033e-04, forward_time=0.165, loss_ctc=4.660, loss=4.660, backward_time=0.160, optim_step_time=0.034, optim0_lr0=4.111e-04, train_time=1.973
[ALab02] 2023-06-08 02:10:44,438 (trainer:338) INFO: 33epoch results: [train] iter_time=0.002, forward_time=0.164, loss_ctc=4.258, loss=4.258, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.052e-04, train_time=1.953, time=24 minutes and 21.58 seconds, total_count=98802, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=13.987, cer_ctc=0.310, cer=0.310, loss=13.987, time=14.16 seconds, total_count=990, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.7 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 02:10:46,843 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 02:10:46,845 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/23epoch.pth
[ALab02] 2023-06-08 02:10:46,845 (trainer:272) INFO: 34/70epoch started. Estimated time to finish: 17 hours, 22 minutes and 16.04 seconds
[ALab02] 2023-06-08 02:12:00,622 (trainer:721) INFO: 34epoch:train:1-149batch: iter_time=0.009, forward_time=0.165, loss_ctc=4.123, loss=4.123, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.117e-04, train_time=1.985
[ALab02] 2023-06-08 02:13:14,986 (trainer:721) INFO: 34epoch:train:150-298batch: iter_time=0.015, forward_time=0.167, loss_ctc=3.981, loss=3.981, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.124e-04, train_time=1.994
[ALab02] 2023-06-08 02:14:27,925 (trainer:721) INFO: 34epoch:train:299-447batch: iter_time=0.003, forward_time=0.167, loss_ctc=3.986, loss=3.986, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.130e-04, train_time=1.957
[ALab02] 2023-06-08 02:15:41,125 (trainer:721) INFO: 34epoch:train:448-596batch: iter_time=0.014, forward_time=0.163, loss_ctc=4.328, loss=4.328, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.136e-04, train_time=1.962
[ALab02] 2023-06-08 02:16:53,018 (trainer:721) INFO: 34epoch:train:597-745batch: iter_time=2.341e-04, forward_time=0.161, loss_ctc=4.096, loss=4.096, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.142e-04, train_time=1.934
[ALab02] 2023-06-08 02:18:05,670 (trainer:721) INFO: 34epoch:train:746-894batch: iter_time=2.403e-04, forward_time=0.165, loss_ctc=4.034, loss=4.034, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.148e-04, train_time=1.952
[ALab02] 2023-06-08 02:19:17,765 (trainer:721) INFO: 34epoch:train:895-1043batch: iter_time=2.218e-04, forward_time=0.163, loss_ctc=4.274, loss=4.274, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.155e-04, train_time=1.931
[ALab02] 2023-06-08 02:20:31,722 (trainer:721) INFO: 34epoch:train:1044-1192batch: iter_time=2.191e-04, forward_time=0.165, loss_ctc=4.025, loss=4.025, backward_time=0.161, optim_step_time=0.033, optim0_lr0=4.161e-04, train_time=1.983
[ALab02] 2023-06-08 02:21:44,653 (trainer:721) INFO: 34epoch:train:1193-1341batch: iter_time=2.295e-04, forward_time=0.164, loss_ctc=4.201, loss=4.201, backward_time=0.158, optim_step_time=0.032, optim0_lr0=4.167e-04, train_time=1.963
[ALab02] 2023-06-08 02:22:56,662 (trainer:721) INFO: 34epoch:train:1342-1490batch: iter_time=1.987e-04, forward_time=0.161, loss_ctc=4.317, loss=4.317, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.173e-04, train_time=1.932
[ALab02] 2023-06-08 02:24:08,570 (trainer:721) INFO: 34epoch:train:1491-1639batch: iter_time=2.287e-04, forward_time=0.161, loss_ctc=4.264, loss=4.264, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.179e-04, train_time=1.932
[ALab02] 2023-06-08 02:25:21,876 (trainer:721) INFO: 34epoch:train:1640-1788batch: iter_time=1.896e-04, forward_time=0.165, loss_ctc=4.301, loss=4.301, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.186e-04, train_time=1.961
[ALab02] 2023-06-08 02:26:34,783 (trainer:721) INFO: 34epoch:train:1789-1937batch: iter_time=2.056e-04, forward_time=0.165, loss_ctc=4.347, loss=4.347, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.192e-04, train_time=1.960
[ALab02] 2023-06-08 02:27:47,675 (trainer:721) INFO: 34epoch:train:1938-2086batch: iter_time=2.117e-04, forward_time=0.163, loss_ctc=4.314, loss=4.314, backward_time=0.158, optim_step_time=0.032, optim0_lr0=4.198e-04, train_time=1.960
[ALab02] 2023-06-08 02:29:00,116 (trainer:721) INFO: 34epoch:train:2087-2235batch: iter_time=2.076e-04, forward_time=0.166, loss_ctc=4.050, loss=4.050, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.204e-04, train_time=1.938
[ALab02] 2023-06-08 02:30:11,800 (trainer:721) INFO: 34epoch:train:2236-2384batch: iter_time=2.100e-04, forward_time=0.161, loss_ctc=4.174, loss=4.174, backward_time=0.154, optim_step_time=0.032, optim0_lr0=4.210e-04, train_time=1.925
[ALab02] 2023-06-08 02:31:24,161 (trainer:721) INFO: 34epoch:train:2385-2533batch: iter_time=5.718e-04, forward_time=0.163, loss_ctc=4.134, loss=4.134, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.217e-04, train_time=1.947
[ALab02] 2023-06-08 02:32:36,492 (trainer:721) INFO: 34epoch:train:2534-2682batch: iter_time=2.099e-04, forward_time=0.164, loss_ctc=4.152, loss=4.152, backward_time=0.157, optim_step_time=0.032, optim0_lr0=4.223e-04, train_time=1.943
[ALab02] 2023-06-08 02:33:49,529 (trainer:721) INFO: 34epoch:train:2683-2831batch: iter_time=0.025, forward_time=0.164, loss_ctc=4.258, loss=4.258, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.229e-04, train_time=1.962
[ALab02] 2023-06-08 02:35:01,989 (trainer:721) INFO: 34epoch:train:2832-2980batch: iter_time=2.012e-04, forward_time=0.163, loss_ctc=4.397, loss=4.397, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.235e-04, train_time=1.938
[ALab02] 2023-06-08 02:35:49,591 (trainer:338) INFO: 34epoch results: [train] iter_time=0.003, forward_time=0.164, loss_ctc=4.182, loss=4.182, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.177e-04, train_time=1.953, time=24 minutes and 21.84 seconds, total_count=101796, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.123, cer_ctc=0.319, cer=0.319, loss=14.123, time=14.09 seconds, total_count=1020, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.82 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 02:35:51,950 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 02:35:51,953 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/24epoch.pth
[ALab02] 2023-06-08 02:35:51,953 (trainer:272) INFO: 35/70epoch started. Estimated time to finish: 16 hours, 50 minutes and 49.94 seconds
[ALab02] 2023-06-08 02:37:04,622 (trainer:721) INFO: 35epoch:train:1-149batch: iter_time=0.009, forward_time=0.163, loss_ctc=3.907, loss=3.907, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.242e-04, train_time=1.954
[ALab02] 2023-06-08 02:38:16,554 (trainer:721) INFO: 35epoch:train:150-298batch: iter_time=2.285e-04, forward_time=0.161, loss_ctc=4.204, loss=4.204, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.248e-04, train_time=1.934
[ALab02] 2023-06-08 02:39:29,169 (trainer:721) INFO: 35epoch:train:299-447batch: iter_time=2.237e-04, forward_time=0.163, loss_ctc=4.216, loss=4.216, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.254e-04, train_time=1.950
[ALab02] 2023-06-08 02:40:41,717 (trainer:721) INFO: 35epoch:train:448-596batch: iter_time=2.253e-04, forward_time=0.164, loss_ctc=3.860, loss=3.860, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.261e-04, train_time=1.940
[ALab02] 2023-06-08 02:41:54,733 (trainer:721) INFO: 35epoch:train:597-745batch: iter_time=2.080e-04, forward_time=0.167, loss_ctc=4.056, loss=4.056, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.267e-04, train_time=1.964
[ALab02] 2023-06-08 02:43:07,317 (trainer:721) INFO: 35epoch:train:746-894batch: iter_time=0.001, forward_time=0.164, loss_ctc=4.064, loss=4.064, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.273e-04, train_time=1.948
[ALab02] 2023-06-08 02:44:19,959 (trainer:721) INFO: 35epoch:train:895-1043batch: iter_time=2.085e-04, forward_time=0.165, loss_ctc=3.722, loss=3.722, backward_time=0.157, optim_step_time=0.032, optim0_lr0=4.279e-04, train_time=1.952
[ALab02] 2023-06-08 02:45:30,628 (trainer:721) INFO: 35epoch:train:1044-1192batch: iter_time=2.190e-04, forward_time=0.158, loss_ctc=4.191, loss=4.191, backward_time=0.152, optim_step_time=0.034, optim0_lr0=4.285e-04, train_time=1.892
[ALab02] 2023-06-08 02:46:43,016 (trainer:721) INFO: 35epoch:train:1193-1341batch: iter_time=2.102e-04, forward_time=0.163, loss_ctc=4.169, loss=4.169, backward_time=0.157, optim_step_time=0.032, optim0_lr0=4.292e-04, train_time=1.947
[ALab02] 2023-06-08 02:47:56,218 (trainer:721) INFO: 35epoch:train:1342-1490batch: iter_time=2.009e-04, forward_time=0.164, loss_ctc=4.205, loss=4.205, backward_time=0.160, optim_step_time=0.032, optim0_lr0=4.298e-04, train_time=1.964
[ALab02] 2023-06-08 02:49:09,432 (trainer:721) INFO: 35epoch:train:1491-1639batch: iter_time=3.810e-04, forward_time=0.164, loss_ctc=4.288, loss=4.288, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.304e-04, train_time=1.969
[ALab02] 2023-06-08 02:50:22,177 (trainer:721) INFO: 35epoch:train:1640-1788batch: iter_time=2.307e-04, forward_time=0.165, loss_ctc=4.136, loss=4.136, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.310e-04, train_time=1.946
[ALab02] 2023-06-08 02:51:34,493 (trainer:721) INFO: 35epoch:train:1789-1937batch: iter_time=0.010, forward_time=0.163, loss_ctc=4.157, loss=4.157, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.317e-04, train_time=1.945
[ALab02] 2023-06-08 02:52:46,544 (trainer:721) INFO: 35epoch:train:1938-2086batch: iter_time=2.115e-04, forward_time=0.162, loss_ctc=4.127, loss=4.127, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.323e-04, train_time=1.932
[ALab02] 2023-06-08 02:53:59,693 (trainer:721) INFO: 35epoch:train:2087-2235batch: iter_time=2.377e-04, forward_time=0.165, loss_ctc=4.089, loss=4.089, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.329e-04, train_time=1.969
[ALab02] 2023-06-08 02:55:12,306 (trainer:721) INFO: 35epoch:train:2236-2384batch: iter_time=2.179e-04, forward_time=0.164, loss_ctc=4.037, loss=4.037, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.335e-04, train_time=1.941
[ALab02] 2023-06-08 02:56:25,385 (trainer:721) INFO: 35epoch:train:2385-2533batch: iter_time=2.162e-04, forward_time=0.165, loss_ctc=4.115, loss=4.115, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.341e-04, train_time=1.964
[ALab02] 2023-06-08 02:57:38,182 (trainer:721) INFO: 35epoch:train:2534-2682batch: iter_time=2.205e-04, forward_time=0.165, loss_ctc=4.160, loss=4.160, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.347e-04, train_time=1.956
[ALab02] 2023-06-08 02:58:51,108 (trainer:721) INFO: 35epoch:train:2683-2831batch: iter_time=0.002, forward_time=0.165, loss_ctc=3.990, loss=3.990, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.354e-04, train_time=1.954
[ALab02] 2023-06-08 03:00:04,513 (trainer:721) INFO: 35epoch:train:2832-2980batch: iter_time=2.401e-04, forward_time=0.164, loss_ctc=4.183, loss=4.183, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.360e-04, train_time=1.969
[ALab02] 2023-06-08 03:00:51,789 (trainer:338) INFO: 35epoch results: [train] iter_time=0.001, forward_time=0.164, loss_ctc=4.090, loss=4.090, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.301e-04, train_time=1.950, time=24 minutes and 19.53 seconds, total_count=104790, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=13.878, cer_ctc=0.311, cer=0.311, loss=13.878, time=14.02 seconds, total_count=1050, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.28 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 03:00:54,135 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 03:00:54,138 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/25epoch.pth
[ALab02] 2023-06-08 03:00:54,138 (trainer:272) INFO: 36/70epoch started. Estimated time to finish: 16 hours, 19 minutes and 42.68 seconds
[ALab02] 2023-06-08 03:02:07,726 (trainer:721) INFO: 36epoch:train:1-149batch: iter_time=0.013, forward_time=0.165, loss_ctc=4.139, loss=4.139, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.367e-04, train_time=1.979
[ALab02] 2023-06-08 03:03:20,324 (trainer:721) INFO: 36epoch:train:150-298batch: iter_time=3.618e-04, forward_time=0.166, loss_ctc=3.750, loss=3.750, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.373e-04, train_time=1.951
[ALab02] 2023-06-08 03:04:33,254 (trainer:721) INFO: 36epoch:train:299-447batch: iter_time=2.832e-04, forward_time=0.165, loss_ctc=4.022, loss=4.022, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.379e-04, train_time=1.955
[ALab02] 2023-06-08 03:05:45,925 (trainer:721) INFO: 36epoch:train:448-596batch: iter_time=2.807e-04, forward_time=0.166, loss_ctc=3.978, loss=3.978, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.385e-04, train_time=1.948
[ALab02] 2023-06-08 03:06:58,415 (trainer:721) INFO: 36epoch:train:597-745batch: iter_time=2.510e-04, forward_time=0.163, loss_ctc=4.086, loss=4.086, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.392e-04, train_time=1.950
[ALab02] 2023-06-08 03:08:11,178 (trainer:721) INFO: 36epoch:train:746-894batch: iter_time=2.380e-04, forward_time=0.165, loss_ctc=3.924, loss=3.924, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.398e-04, train_time=1.955
[ALab02] 2023-06-08 03:09:22,583 (trainer:721) INFO: 36epoch:train:895-1043batch: iter_time=2.235e-04, forward_time=0.161, loss_ctc=3.846, loss=3.846, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.404e-04, train_time=1.915
[ALab02] 2023-06-08 03:10:35,471 (trainer:721) INFO: 36epoch:train:1044-1192batch: iter_time=0.006, forward_time=0.164, loss_ctc=4.049, loss=4.049, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.410e-04, train_time=1.952
[ALab02] 2023-06-08 03:11:49,255 (trainer:721) INFO: 36epoch:train:1193-1341batch: iter_time=2.417e-04, forward_time=0.169, loss_ctc=3.959, loss=3.959, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.416e-04, train_time=1.984
[ALab02] 2023-06-08 03:13:04,096 (trainer:721) INFO: 36epoch:train:1342-1490batch: iter_time=0.019, forward_time=0.170, loss_ctc=4.241, loss=4.241, backward_time=0.158, optim_step_time=0.039, optim0_lr0=4.422e-04, train_time=2.011
[ALab02] 2023-06-08 03:14:17,157 (trainer:721) INFO: 36epoch:train:1491-1639batch: iter_time=2.335e-04, forward_time=0.165, loss_ctc=3.963, loss=3.963, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.429e-04, train_time=1.963
[ALab02] 2023-06-08 03:15:30,840 (trainer:721) INFO: 36epoch:train:1640-1788batch: iter_time=0.011, forward_time=0.167, loss_ctc=3.946, loss=3.946, backward_time=0.158, optim_step_time=0.036, optim0_lr0=4.435e-04, train_time=1.971
[ALab02] 2023-06-08 03:16:43,437 (trainer:721) INFO: 36epoch:train:1789-1937batch: iter_time=2.376e-04, forward_time=0.165, loss_ctc=3.932, loss=3.932, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.441e-04, train_time=1.953
[ALab02] 2023-06-08 03:17:56,950 (trainer:721) INFO: 36epoch:train:1938-2086batch: iter_time=2.481e-04, forward_time=0.166, loss_ctc=4.138, loss=4.138, backward_time=0.159, optim_step_time=0.034, optim0_lr0=4.447e-04, train_time=1.974
[ALab02] 2023-06-08 03:19:09,988 (trainer:721) INFO: 36epoch:train:2087-2235batch: iter_time=2.381e-04, forward_time=0.167, loss_ctc=3.733, loss=3.733, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.453e-04, train_time=1.957
[ALab02] 2023-06-08 03:20:23,002 (trainer:721) INFO: 36epoch:train:2236-2384batch: iter_time=2.763e-04, forward_time=0.165, loss_ctc=3.916, loss=3.916, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.460e-04, train_time=1.958
[ALab02] 2023-06-08 03:21:35,484 (trainer:721) INFO: 36epoch:train:2385-2533batch: iter_time=2.420e-04, forward_time=0.166, loss_ctc=4.147, loss=4.147, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.466e-04, train_time=1.951
[ALab02] 2023-06-08 03:22:48,626 (trainer:721) INFO: 36epoch:train:2534-2682batch: iter_time=2.508e-04, forward_time=0.167, loss_ctc=4.125, loss=4.125, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.472e-04, train_time=1.962
[ALab02] 2023-06-08 03:24:02,538 (trainer:721) INFO: 36epoch:train:2683-2831batch: iter_time=2.319e-04, forward_time=0.169, loss_ctc=3.907, loss=3.907, backward_time=0.159, optim_step_time=0.034, optim0_lr0=4.478e-04, train_time=1.986
[ALab02] 2023-06-08 03:25:15,279 (trainer:721) INFO: 36epoch:train:2832-2980batch: iter_time=2.599e-04, forward_time=0.164, loss_ctc=3.989, loss=3.989, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.485e-04, train_time=1.947
[ALab02] 2023-06-08 03:26:03,136 (trainer:338) INFO: 36epoch results: [train] iter_time=0.003, forward_time=0.166, loss_ctc=3.983, loss=3.983, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.426e-04, train_time=1.961, time=24 minutes and 28.08 seconds, total_count=107784, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.770, cer_ctc=0.317, cer=0.317, loss=14.770, time=14.29 seconds, total_count=1080, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.62 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 03:26:05,584 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 03:26:05,587 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/26epoch.pth
[ALab02] 2023-06-08 03:26:05,587 (trainer:272) INFO: 37/70epoch started. Estimated time to finish: 15 hours, 49 minutes and 4.46 seconds
[ALab02] 2023-06-08 03:27:19,576 (trainer:721) INFO: 37epoch:train:1-149batch: iter_time=0.006, forward_time=0.166, loss_ctc=4.088, loss=4.088, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.491e-04, train_time=1.991
[ALab02] 2023-06-08 03:28:32,286 (trainer:721) INFO: 37epoch:train:150-298batch: iter_time=3.028e-04, forward_time=0.166, loss_ctc=3.756, loss=3.756, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.497e-04, train_time=1.949
[ALab02] 2023-06-08 03:29:44,685 (trainer:721) INFO: 37epoch:train:299-447batch: iter_time=2.691e-04, forward_time=0.164, loss_ctc=3.937, loss=3.937, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.504e-04, train_time=1.946
[ALab02] 2023-06-08 03:30:59,974 (trainer:721) INFO: 37epoch:train:448-596batch: iter_time=0.019, forward_time=0.169, loss_ctc=3.847, loss=3.847, backward_time=0.159, optim_step_time=0.036, optim0_lr0=4.510e-04, train_time=2.015
[ALab02] 2023-06-08 03:32:12,788 (trainer:721) INFO: 37epoch:train:597-745batch: iter_time=0.003, forward_time=0.166, loss_ctc=3.758, loss=3.758, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.516e-04, train_time=1.958
[ALab02] 2023-06-08 03:33:24,859 (trainer:721) INFO: 37epoch:train:746-894batch: iter_time=2.810e-04, forward_time=0.163, loss_ctc=4.050, loss=4.050, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.522e-04, train_time=1.936
[ALab02] 2023-06-08 03:34:37,258 (trainer:721) INFO: 37epoch:train:895-1043batch: iter_time=2.422e-04, forward_time=0.165, loss_ctc=3.868, loss=3.868, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.528e-04, train_time=1.943
[ALab02] 2023-06-08 03:35:50,901 (trainer:721) INFO: 37epoch:train:1044-1192batch: iter_time=0.020, forward_time=0.168, loss_ctc=3.721, loss=3.721, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.535e-04, train_time=1.971
[ALab02] 2023-06-08 03:37:03,921 (trainer:721) INFO: 37epoch:train:1193-1341batch: iter_time=2.235e-04, forward_time=0.165, loss_ctc=3.930, loss=3.930, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.541e-04, train_time=1.964
[ALab02] 2023-06-08 03:38:16,532 (trainer:721) INFO: 37epoch:train:1342-1490batch: iter_time=2.747e-04, forward_time=0.163, loss_ctc=3.889, loss=3.889, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.547e-04, train_time=1.950
[ALab02] 2023-06-08 03:39:28,918 (trainer:721) INFO: 37epoch:train:1491-1639batch: iter_time=2.675e-04, forward_time=0.164, loss_ctc=3.873, loss=3.873, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.553e-04, train_time=1.942
[ALab02] 2023-06-08 03:40:41,271 (trainer:721) INFO: 37epoch:train:1640-1788batch: iter_time=2.713e-04, forward_time=0.164, loss_ctc=3.950, loss=3.950, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.560e-04, train_time=1.938
[ALab02] 2023-06-08 03:41:53,945 (trainer:721) INFO: 37epoch:train:1789-1937batch: iter_time=2.495e-04, forward_time=0.165, loss_ctc=3.872, loss=3.872, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.566e-04, train_time=1.954
[ALab02] 2023-06-08 03:43:07,024 (trainer:721) INFO: 37epoch:train:1938-2086batch: iter_time=2.434e-04, forward_time=0.166, loss_ctc=4.087, loss=4.087, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.572e-04, train_time=1.964
[ALab02] 2023-06-08 03:44:19,107 (trainer:721) INFO: 37epoch:train:2087-2235batch: iter_time=2.389e-04, forward_time=0.164, loss_ctc=3.979, loss=3.979, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.578e-04, train_time=1.935
[ALab02] 2023-06-08 03:45:31,572 (trainer:721) INFO: 37epoch:train:2236-2384batch: iter_time=2.447e-04, forward_time=0.164, loss_ctc=3.860, loss=3.860, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.584e-04, train_time=1.939
[ALab02] 2023-06-08 03:46:44,493 (trainer:721) INFO: 37epoch:train:2385-2533batch: iter_time=2.324e-04, forward_time=0.165, loss_ctc=4.143, loss=4.143, backward_time=0.158, optim_step_time=0.036, optim0_lr0=4.591e-04, train_time=1.963
[ALab02] 2023-06-08 03:47:56,912 (trainer:721) INFO: 37epoch:train:2534-2682batch: iter_time=2.593e-04, forward_time=0.164, loss_ctc=3.987, loss=3.987, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.597e-04, train_time=1.943
[ALab02] 2023-06-08 03:49:09,331 (trainer:721) INFO: 37epoch:train:2683-2831batch: iter_time=2.245e-04, forward_time=0.164, loss_ctc=4.010, loss=4.010, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.603e-04, train_time=1.945
[ALab02] 2023-06-08 03:50:24,359 (trainer:721) INFO: 37epoch:train:2832-2980batch: iter_time=0.013, forward_time=0.169, loss_ctc=3.874, loss=3.874, backward_time=0.159, optim_step_time=0.035, optim0_lr0=4.609e-04, train_time=2.007
[ALab02] 2023-06-08 03:51:12,912 (trainer:338) INFO: 37epoch results: [train] iter_time=0.003, forward_time=0.165, loss_ctc=3.921, loss=3.921, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.551e-04, train_time=1.958, time=24 minutes and 25.67 seconds, total_count=110778, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.199, cer_ctc=0.308, cer=0.308, loss=14.199, time=14.61 seconds, total_count=1110, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.04 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 03:51:15,431 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 03:51:15,434 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/27epoch.pth
[ALab02] 2023-06-08 03:51:15,434 (trainer:272) INFO: 38/70epoch started. Estimated time to finish: 15 hours, 18 minutes and 42.47 seconds
[ALab02] 2023-06-08 03:52:29,255 (trainer:721) INFO: 38epoch:train:1-149batch: iter_time=0.009, forward_time=0.166, loss_ctc=3.825, loss=3.825, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.616e-04, train_time=1.986
[ALab02] 2023-06-08 03:53:42,364 (trainer:721) INFO: 38epoch:train:150-298batch: iter_time=2.516e-04, forward_time=0.166, loss_ctc=3.826, loss=3.826, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.622e-04, train_time=1.962
[ALab02] 2023-06-08 03:54:55,232 (trainer:721) INFO: 38epoch:train:299-447batch: iter_time=2.597e-04, forward_time=0.165, loss_ctc=3.857, loss=3.857, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.628e-04, train_time=1.958
[ALab02] 2023-06-08 03:56:07,304 (trainer:721) INFO: 38epoch:train:448-596batch: iter_time=2.526e-04, forward_time=0.163, loss_ctc=3.785, loss=3.785, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.635e-04, train_time=1.928
[ALab02] 2023-06-08 03:57:20,053 (trainer:721) INFO: 38epoch:train:597-745batch: iter_time=0.017, forward_time=0.166, loss_ctc=3.783, loss=3.783, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.641e-04, train_time=1.957
[ALab02] 2023-06-08 03:58:33,245 (trainer:721) INFO: 38epoch:train:746-894batch: iter_time=2.583e-04, forward_time=0.167, loss_ctc=3.887, loss=3.887, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.647e-04, train_time=1.964
[ALab02] 2023-06-08 03:59:45,477 (trainer:721) INFO: 38epoch:train:895-1043batch: iter_time=2.380e-04, forward_time=0.166, loss_ctc=3.655, loss=3.655, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.653e-04, train_time=1.939
[ALab02] 2023-06-08 04:00:57,689 (trainer:721) INFO: 38epoch:train:1044-1192batch: iter_time=3.285e-04, forward_time=0.163, loss_ctc=3.916, loss=3.916, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.659e-04, train_time=1.934
[ALab02] 2023-06-08 04:02:10,438 (trainer:721) INFO: 38epoch:train:1193-1341batch: iter_time=2.467e-04, forward_time=0.164, loss_ctc=3.854, loss=3.854, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.666e-04, train_time=1.959
[ALab02] 2023-06-08 04:03:23,388 (trainer:721) INFO: 38epoch:train:1342-1490batch: iter_time=2.360e-04, forward_time=0.165, loss_ctc=3.856, loss=3.856, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.672e-04, train_time=1.958
[ALab02] 2023-06-08 04:04:35,631 (trainer:721) INFO: 38epoch:train:1491-1639batch: iter_time=2.445e-04, forward_time=0.164, loss_ctc=3.642, loss=3.642, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.678e-04, train_time=1.937
[ALab02] 2023-06-08 04:05:48,604 (trainer:721) INFO: 38epoch:train:1640-1788batch: iter_time=2.296e-04, forward_time=0.165, loss_ctc=3.854, loss=3.854, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.684e-04, train_time=1.955
[ALab02] 2023-06-08 04:07:01,478 (trainer:721) INFO: 38epoch:train:1789-1937batch: iter_time=2.762e-04, forward_time=0.166, loss_ctc=4.028, loss=4.028, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.691e-04, train_time=1.961
[ALab02] 2023-06-08 04:08:14,891 (trainer:721) INFO: 38epoch:train:1938-2086batch: iter_time=0.013, forward_time=0.166, loss_ctc=3.878, loss=3.878, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.697e-04, train_time=1.970
[ALab02] 2023-06-08 04:09:27,840 (trainer:721) INFO: 38epoch:train:2087-2235batch: iter_time=2.544e-04, forward_time=0.166, loss_ctc=3.892, loss=3.892, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.703e-04, train_time=1.958
[ALab02] 2023-06-08 04:10:40,691 (trainer:721) INFO: 38epoch:train:2236-2384batch: iter_time=2.257e-04, forward_time=0.165, loss_ctc=3.932, loss=3.932, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.709e-04, train_time=1.951
[ALab02] 2023-06-08 04:11:53,082 (trainer:721) INFO: 38epoch:train:2385-2533batch: iter_time=2.165e-04, forward_time=0.165, loss_ctc=3.893, loss=3.893, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.715e-04, train_time=1.947
[ALab02] 2023-06-08 04:13:06,225 (trainer:721) INFO: 38epoch:train:2534-2682batch: iter_time=2.434e-04, forward_time=0.166, loss_ctc=3.861, loss=3.861, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.722e-04, train_time=1.962
[ALab02] 2023-06-08 04:14:18,963 (trainer:721) INFO: 38epoch:train:2683-2831batch: iter_time=2.480e-04, forward_time=0.164, loss_ctc=3.943, loss=3.943, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.728e-04, train_time=1.954
[ALab02] 2023-06-08 04:15:31,915 (trainer:721) INFO: 38epoch:train:2832-2980batch: iter_time=4.624e-04, forward_time=0.165, loss_ctc=3.938, loss=3.938, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.734e-04, train_time=1.954
[ALab02] 2023-06-08 04:16:20,215 (trainer:338) INFO: 38epoch results: [train] iter_time=0.002, forward_time=0.165, loss_ctc=3.852, loss=3.852, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.675e-04, train_time=1.955, time=24 minutes and 23.29 seconds, total_count=113772, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.472, cer_ctc=0.313, cer=0.313, loss=14.472, time=14.26 seconds, total_count=1140, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.23 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 04:16:22,744 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 04:16:22,748 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/28epoch.pth
[ALab02] 2023-06-08 04:16:22,748 (trainer:272) INFO: 39/70epoch started. Estimated time to finish: 14 hours, 48 minutes and 34.77 seconds
[ALab02] 2023-06-08 04:17:34,879 (trainer:721) INFO: 39epoch:train:1-149batch: iter_time=0.006, forward_time=0.163, loss_ctc=3.721, loss=3.721, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.741e-04, train_time=1.941
[ALab02] 2023-06-08 04:18:48,066 (trainer:721) INFO: 39epoch:train:150-298batch: iter_time=0.004, forward_time=0.167, loss_ctc=3.750, loss=3.750, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.747e-04, train_time=1.962
[ALab02] 2023-06-08 04:20:00,626 (trainer:721) INFO: 39epoch:train:299-447batch: iter_time=2.417e-04, forward_time=0.164, loss_ctc=3.759, loss=3.759, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.753e-04, train_time=1.951
[ALab02] 2023-06-08 04:21:13,319 (trainer:721) INFO: 39epoch:train:448-596batch: iter_time=2.299e-04, forward_time=0.163, loss_ctc=3.761, loss=3.761, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.759e-04, train_time=1.945
[ALab02] 2023-06-08 04:22:25,368 (trainer:721) INFO: 39epoch:train:597-745batch: iter_time=2.368e-04, forward_time=0.162, loss_ctc=3.846, loss=3.846, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.766e-04, train_time=1.939
[ALab02] 2023-06-08 04:23:37,823 (trainer:721) INFO: 39epoch:train:746-894batch: iter_time=2.591e-04, forward_time=0.165, loss_ctc=3.697, loss=3.697, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.772e-04, train_time=1.945
[ALab02] 2023-06-08 04:24:51,633 (trainer:721) INFO: 39epoch:train:895-1043batch: iter_time=2.254e-04, forward_time=0.169, loss_ctc=3.669, loss=3.669, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.778e-04, train_time=1.981
[ALab02] 2023-06-08 04:26:04,385 (trainer:721) INFO: 39epoch:train:1044-1192batch: iter_time=2.475e-04, forward_time=0.163, loss_ctc=3.916, loss=3.916, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.784e-04, train_time=1.949
[ALab02] 2023-06-08 04:27:17,216 (trainer:721) INFO: 39epoch:train:1193-1341batch: iter_time=0.019, forward_time=0.164, loss_ctc=3.635, loss=3.635, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.790e-04, train_time=1.959
[ALab02] 2023-06-08 04:28:30,613 (trainer:721) INFO: 39epoch:train:1342-1490batch: iter_time=2.276e-04, forward_time=0.167, loss_ctc=3.686, loss=3.686, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.797e-04, train_time=1.971
[ALab02] 2023-06-08 04:29:42,758 (trainer:721) INFO: 39epoch:train:1491-1639batch: iter_time=0.001, forward_time=0.162, loss_ctc=3.682, loss=3.682, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.803e-04, train_time=1.934
[ALab02] 2023-06-08 04:30:55,495 (trainer:721) INFO: 39epoch:train:1640-1788batch: iter_time=2.483e-04, forward_time=0.163, loss_ctc=3.951, loss=3.951, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.809e-04, train_time=1.950
[ALab02] 2023-06-08 04:32:07,574 (trainer:721) INFO: 39epoch:train:1789-1937batch: iter_time=2.329e-04, forward_time=0.163, loss_ctc=3.780, loss=3.780, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.815e-04, train_time=1.939
[ALab02] 2023-06-08 04:33:20,301 (trainer:721) INFO: 39epoch:train:1938-2086batch: iter_time=3.980e-04, forward_time=0.163, loss_ctc=3.785, loss=3.785, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.821e-04, train_time=1.954
[ALab02] 2023-06-08 04:34:33,630 (trainer:721) INFO: 39epoch:train:2087-2235batch: iter_time=2.247e-04, forward_time=0.168, loss_ctc=3.586, loss=3.586, backward_time=0.158, optim_step_time=0.032, optim0_lr0=4.828e-04, train_time=1.964
[ALab02] 2023-06-08 04:35:46,042 (trainer:721) INFO: 39epoch:train:2236-2384batch: iter_time=2.195e-04, forward_time=0.163, loss_ctc=3.832, loss=3.832, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.834e-04, train_time=1.943
[ALab02] 2023-06-08 04:36:57,766 (trainer:721) INFO: 39epoch:train:2385-2533batch: iter_time=0.002, forward_time=0.161, loss_ctc=4.004, loss=4.004, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.840e-04, train_time=1.930
[ALab02] 2023-06-08 04:38:09,950 (trainer:721) INFO: 39epoch:train:2534-2682batch: iter_time=2.499e-04, forward_time=0.163, loss_ctc=3.880, loss=3.880, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.846e-04, train_time=1.935
[ALab02] 2023-06-08 04:39:23,346 (trainer:721) INFO: 39epoch:train:2683-2831batch: iter_time=0.010, forward_time=0.166, loss_ctc=3.855, loss=3.855, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.852e-04, train_time=1.968
[ALab02] 2023-06-08 04:40:35,962 (trainer:721) INFO: 39epoch:train:2832-2980batch: iter_time=1.981e-04, forward_time=0.165, loss_ctc=3.837, loss=3.837, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.859e-04, train_time=1.949
[ALab02] 2023-06-08 04:41:24,125 (trainer:338) INFO: 39epoch results: [train] iter_time=0.002, forward_time=0.164, loss_ctc=3.777, loss=3.777, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.800e-04, train_time=1.950, time=24 minutes and 20.14 seconds, total_count=116766, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.547, cer_ctc=0.310, cer=0.310, loss=14.547, time=15.23 seconds, total_count=1170, gpu_max_cached_mem_GB=52.041, [att_plot] time=26 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 04:41:26,616 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 04:41:26,617 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/32epoch.pth
[ALab02] 2023-06-08 04:41:26,617 (trainer:272) INFO: 40/70epoch started. Estimated time to finish: 14 hours, 18 minutes and 39.74 seconds
[ALab02] 2023-06-08 04:42:39,749 (trainer:721) INFO: 40epoch:train:1-149batch: iter_time=0.010, forward_time=0.165, loss_ctc=3.564, loss=3.564, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.865e-04, train_time=1.966
[ALab02] 2023-06-08 04:43:52,859 (trainer:721) INFO: 40epoch:train:150-298batch: iter_time=5.447e-04, forward_time=0.165, loss_ctc=3.681, loss=3.681, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.871e-04, train_time=1.962
[ALab02] 2023-06-08 04:45:05,897 (trainer:721) INFO: 40epoch:train:299-447batch: iter_time=0.004, forward_time=0.166, loss_ctc=3.755, loss=3.755, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.878e-04, train_time=1.962
[ALab02] 2023-06-08 04:46:18,174 (trainer:721) INFO: 40epoch:train:448-596batch: iter_time=2.507e-04, forward_time=0.163, loss_ctc=3.617, loss=3.617, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.884e-04, train_time=1.936
[ALab02] 2023-06-08 04:47:32,716 (trainer:721) INFO: 40epoch:train:597-745batch: iter_time=0.013, forward_time=0.169, loss_ctc=3.895, loss=3.895, backward_time=0.158, optim_step_time=0.038, optim0_lr0=4.890e-04, train_time=2.005
[ALab02] 2023-06-08 04:48:44,923 (trainer:721) INFO: 40epoch:train:746-894batch: iter_time=2.613e-04, forward_time=0.165, loss_ctc=3.717, loss=3.717, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.896e-04, train_time=1.939
[ALab02] 2023-06-08 04:49:57,370 (trainer:721) INFO: 40epoch:train:895-1043batch: iter_time=2.538e-04, forward_time=0.165, loss_ctc=3.642, loss=3.642, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.903e-04, train_time=1.942
[ALab02] 2023-06-08 04:51:10,961 (trainer:721) INFO: 40epoch:train:1044-1192batch: iter_time=2.992e-04, forward_time=0.166, loss_ctc=3.765, loss=3.765, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.909e-04, train_time=1.973
[ALab02] 2023-06-08 04:52:22,560 (trainer:721) INFO: 40epoch:train:1193-1341batch: iter_time=0.002, forward_time=0.163, loss_ctc=3.635, loss=3.635, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.915e-04, train_time=1.927
[ALab02] 2023-06-08 04:53:35,548 (trainer:721) INFO: 40epoch:train:1342-1490batch: iter_time=4.091e-04, forward_time=0.165, loss_ctc=3.709, loss=3.709, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.921e-04, train_time=1.958
[ALab02] 2023-06-08 04:54:47,331 (trainer:721) INFO: 40epoch:train:1491-1639batch: iter_time=2.458e-04, forward_time=0.163, loss_ctc=3.761, loss=3.761, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.927e-04, train_time=1.923
[ALab02] 2023-06-08 04:56:01,160 (trainer:721) INFO: 40epoch:train:1640-1788batch: iter_time=2.637e-04, forward_time=0.168, loss_ctc=3.498, loss=3.498, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.934e-04, train_time=1.980
[ALab02] 2023-06-08 04:57:12,665 (trainer:721) INFO: 40epoch:train:1789-1937batch: iter_time=2.514e-04, forward_time=0.162, loss_ctc=3.718, loss=3.718, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.940e-04, train_time=1.923
[ALab02] 2023-06-08 04:58:26,302 (trainer:721) INFO: 40epoch:train:1938-2086batch: iter_time=2.198e-04, forward_time=0.167, loss_ctc=3.688, loss=3.688, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.946e-04, train_time=1.978
[ALab02] 2023-06-08 04:59:39,154 (trainer:721) INFO: 40epoch:train:2087-2235batch: iter_time=0.019, forward_time=0.165, loss_ctc=3.788, loss=3.788, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.952e-04, train_time=1.957
[ALab02] 2023-06-08 05:00:51,984 (trainer:721) INFO: 40epoch:train:2236-2384batch: iter_time=2.503e-04, forward_time=0.166, loss_ctc=3.784, loss=3.784, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.958e-04, train_time=1.949
[ALab02] 2023-06-08 05:02:04,838 (trainer:721) INFO: 40epoch:train:2385-2533batch: iter_time=2.368e-04, forward_time=0.165, loss_ctc=3.717, loss=3.717, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.965e-04, train_time=1.960
[ALab02] 2023-06-08 05:03:17,864 (trainer:721) INFO: 40epoch:train:2534-2682batch: iter_time=2.631e-04, forward_time=0.166, loss_ctc=3.725, loss=3.725, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.971e-04, train_time=1.961
[ALab02] 2023-06-08 05:04:29,622 (trainer:721) INFO: 40epoch:train:2683-2831batch: iter_time=2.443e-04, forward_time=0.163, loss_ctc=3.464, loss=3.464, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.977e-04, train_time=1.929
[ALab02] 2023-06-08 05:05:43,645 (trainer:721) INFO: 40epoch:train:2832-2980batch: iter_time=0.006, forward_time=0.167, loss_ctc=3.719, loss=3.719, backward_time=0.158, optim_step_time=0.038, optim0_lr0=4.983e-04, train_time=1.978
[ALab02] 2023-06-08 05:06:32,653 (trainer:338) INFO: 40epoch results: [train] iter_time=0.003, forward_time=0.165, loss_ctc=3.689, loss=3.689, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.925e-04, train_time=1.957, time=24 minutes and 24.58 seconds, total_count=119760, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=13.823, cer_ctc=0.306, cer=0.306, loss=13.823, time=14.39 seconds, total_count=1200, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.07 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 05:06:35,064 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 05:06:35,068 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/30epoch.pth
[ALab02] 2023-06-08 05:06:35,068 (trainer:272) INFO: 41/70epoch started. Estimated time to finish: 13 hours, 49 minutes and 2.71 seconds
[ALab02] 2023-06-08 05:07:49,425 (trainer:721) INFO: 41epoch:train:1-149batch: iter_time=0.007, forward_time=0.167, loss_ctc=3.648, loss=3.648, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.990e-04, train_time=2.000
[ALab02] 2023-06-08 05:09:02,009 (trainer:721) INFO: 41epoch:train:150-298batch: iter_time=3.528e-04, forward_time=0.164, loss_ctc=3.720, loss=3.720, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.996e-04, train_time=1.951
[ALab02] 2023-06-08 05:10:15,292 (trainer:721) INFO: 41epoch:train:299-447batch: iter_time=2.583e-04, forward_time=0.168, loss_ctc=3.502, loss=3.502, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.999e-04, train_time=1.967
[ALab02] 2023-06-08 05:11:28,928 (trainer:721) INFO: 41epoch:train:448-596batch: iter_time=2.535e-04, forward_time=0.165, loss_ctc=3.825, loss=3.825, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.996e-04, train_time=1.970
[ALab02] 2023-06-08 05:12:41,187 (trainer:721) INFO: 41epoch:train:597-745batch: iter_time=2.598e-04, forward_time=0.165, loss_ctc=3.633, loss=3.633, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.993e-04, train_time=1.944
[ALab02] 2023-06-08 05:13:53,181 (trainer:721) INFO: 41epoch:train:746-894batch: iter_time=2.381e-04, forward_time=0.164, loss_ctc=3.494, loss=3.494, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.990e-04, train_time=1.933
[ALab02] 2023-06-08 05:15:06,113 (trainer:721) INFO: 41epoch:train:895-1043batch: iter_time=2.336e-04, forward_time=0.165, loss_ctc=3.498, loss=3.498, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.986e-04, train_time=1.956
[ALab02] 2023-06-08 05:16:19,230 (trainer:721) INFO: 41epoch:train:1044-1192batch: iter_time=6.274e-04, forward_time=0.166, loss_ctc=3.754, loss=3.754, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.983e-04, train_time=1.959
[ALab02] 2023-06-08 05:17:31,064 (trainer:721) INFO: 41epoch:train:1193-1341batch: iter_time=2.514e-04, forward_time=0.164, loss_ctc=3.713, loss=3.713, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.980e-04, train_time=1.932
[ALab02] 2023-06-08 05:18:42,577 (trainer:721) INFO: 41epoch:train:1342-1490batch: iter_time=0.002, forward_time=0.163, loss_ctc=3.426, loss=3.426, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.977e-04, train_time=1.920
[ALab02] 2023-06-08 05:19:55,338 (trainer:721) INFO: 41epoch:train:1491-1639batch: iter_time=0.001, forward_time=0.164, loss_ctc=3.665, loss=3.665, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.974e-04, train_time=1.950
[ALab02] 2023-06-08 05:21:10,278 (trainer:721) INFO: 41epoch:train:1640-1788batch: iter_time=0.028, forward_time=0.169, loss_ctc=3.540, loss=3.540, backward_time=0.157, optim_step_time=0.037, optim0_lr0=4.971e-04, train_time=2.008
[ALab02] 2023-06-08 05:22:22,589 (trainer:721) INFO: 41epoch:train:1789-1937batch: iter_time=2.694e-04, forward_time=0.164, loss_ctc=3.778, loss=3.778, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.968e-04, train_time=1.946
[ALab02] 2023-06-08 05:23:35,440 (trainer:721) INFO: 41epoch:train:1938-2086batch: iter_time=5.409e-04, forward_time=0.166, loss_ctc=3.712, loss=3.712, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.965e-04, train_time=1.954
[ALab02] 2023-06-08 05:24:49,145 (trainer:721) INFO: 41epoch:train:2087-2235batch: iter_time=0.014, forward_time=0.165, loss_ctc=3.668, loss=3.668, backward_time=0.156, optim_step_time=0.037, optim0_lr0=4.962e-04, train_time=1.983
[ALab02] 2023-06-08 05:26:02,174 (trainer:721) INFO: 41epoch:train:2236-2384batch: iter_time=2.911e-04, forward_time=0.166, loss_ctc=3.754, loss=3.754, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.959e-04, train_time=1.952
[ALab02] 2023-06-08 05:27:14,222 (trainer:721) INFO: 41epoch:train:2385-2533batch: iter_time=2.672e-04, forward_time=0.166, loss_ctc=3.510, loss=3.510, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.956e-04, train_time=1.939
[ALab02] 2023-06-08 05:28:27,052 (trainer:721) INFO: 41epoch:train:2534-2682batch: iter_time=2.364e-04, forward_time=0.165, loss_ctc=3.708, loss=3.708, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.953e-04, train_time=1.953
[ALab02] 2023-06-08 05:29:40,505 (trainer:721) INFO: 41epoch:train:2683-2831batch: iter_time=3.905e-04, forward_time=0.168, loss_ctc=3.601, loss=3.601, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.950e-04, train_time=1.975
[ALab02] 2023-06-08 05:30:53,193 (trainer:721) INFO: 41epoch:train:2832-2980batch: iter_time=9.157e-04, forward_time=0.165, loss_ctc=3.699, loss=3.699, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.947e-04, train_time=1.945
[ALab02] 2023-06-08 05:31:42,567 (trainer:338) INFO: 41epoch results: [train] iter_time=0.003, forward_time=0.165, loss_ctc=3.638, loss=3.638, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.975e-04, train_time=1.957, time=24 minutes and 25.06 seconds, total_count=122754, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.026, cer_ctc=0.306, cer=0.306, loss=14.026, time=14.72 seconds, total_count=1230, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.71 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 05:31:44,971 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 05:31:44,972 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/29epoch.pth
[ALab02] 2023-06-08 05:31:44,972 (trainer:272) INFO: 42/70epoch started. Estimated time to finish: 13 hours, 19 minutes and 39.81 seconds
[ALab02] 2023-06-08 05:32:59,248 (trainer:721) INFO: 42epoch:train:1-149batch: iter_time=0.007, forward_time=0.171, loss_ctc=3.493, loss=3.493, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.944e-04, train_time=2.000
[ALab02] 2023-06-08 05:34:12,658 (trainer:721) INFO: 42epoch:train:150-298batch: iter_time=2.981e-04, forward_time=0.167, loss_ctc=3.625, loss=3.625, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.941e-04, train_time=1.969
[ALab02] 2023-06-08 05:35:23,931 (trainer:721) INFO: 42epoch:train:299-447batch: iter_time=2.803e-04, forward_time=0.163, loss_ctc=3.613, loss=3.613, backward_time=0.152, optim_step_time=0.036, optim0_lr0=4.938e-04, train_time=1.913
[ALab02] 2023-06-08 05:36:37,080 (trainer:721) INFO: 42epoch:train:448-596batch: iter_time=2.537e-04, forward_time=0.166, loss_ctc=3.554, loss=3.554, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.935e-04, train_time=1.959
[ALab02] 2023-06-08 05:37:49,544 (trainer:721) INFO: 42epoch:train:597-745batch: iter_time=2.442e-04, forward_time=0.165, loss_ctc=3.510, loss=3.510, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.932e-04, train_time=1.949
[ALab02] 2023-06-08 05:39:02,120 (trainer:721) INFO: 42epoch:train:746-894batch: iter_time=2.667e-04, forward_time=0.165, loss_ctc=3.429, loss=3.429, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.929e-04, train_time=1.947
[ALab02] 2023-06-08 05:40:15,610 (trainer:721) INFO: 42epoch:train:895-1043batch: iter_time=2.106e-04, forward_time=0.167, loss_ctc=3.479, loss=3.479, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.926e-04, train_time=1.976
[ALab02] 2023-06-08 05:41:28,498 (trainer:721) INFO: 42epoch:train:1044-1192batch: iter_time=2.802e-04, forward_time=0.166, loss_ctc=3.584, loss=3.584, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.923e-04, train_time=1.951
[ALab02] 2023-06-08 05:42:44,297 (trainer:721) INFO: 42epoch:train:1193-1341batch: iter_time=0.029, forward_time=0.171, loss_ctc=3.431, loss=3.431, backward_time=0.157, optim_step_time=0.037, optim0_lr0=4.920e-04, train_time=2.040
[ALab02] 2023-06-08 05:43:55,951 (trainer:721) INFO: 42epoch:train:1342-1490batch: iter_time=5.931e-04, forward_time=0.163, loss_ctc=3.564, loss=3.564, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.917e-04, train_time=1.924
[ALab02] 2023-06-08 05:45:08,625 (trainer:721) INFO: 42epoch:train:1491-1639batch: iter_time=2.452e-04, forward_time=0.165, loss_ctc=3.508, loss=3.508, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.914e-04, train_time=1.952
[ALab02] 2023-06-08 05:46:20,036 (trainer:721) INFO: 42epoch:train:1640-1788batch: iter_time=2.024e-04, forward_time=0.162, loss_ctc=3.508, loss=3.508, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.911e-04, train_time=1.911
[ALab02] 2023-06-08 05:47:32,447 (trainer:721) INFO: 42epoch:train:1789-1937batch: iter_time=3.223e-04, forward_time=0.164, loss_ctc=3.701, loss=3.701, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.908e-04, train_time=1.948
[ALab02] 2023-06-08 05:48:45,781 (trainer:721) INFO: 42epoch:train:1938-2086batch: iter_time=2.511e-04, forward_time=0.173, loss_ctc=3.458, loss=3.458, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.905e-04, train_time=1.969
[ALab02] 2023-06-08 05:50:00,262 (trainer:721) INFO: 42epoch:train:2087-2235batch: iter_time=0.002, forward_time=0.176, loss_ctc=3.654, loss=3.654, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.902e-04, train_time=1.999
[ALab02] 2023-06-08 05:51:15,197 (trainer:721) INFO: 42epoch:train:2236-2384batch: iter_time=2.951e-04, forward_time=0.178, loss_ctc=3.630, loss=3.630, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.899e-04, train_time=2.006
[ALab02] 2023-06-08 05:52:28,873 (trainer:721) INFO: 42epoch:train:2385-2533batch: iter_time=2.840e-04, forward_time=0.175, loss_ctc=3.444, loss=3.444, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.896e-04, train_time=1.983
[ALab02] 2023-06-08 05:53:43,691 (trainer:721) INFO: 42epoch:train:2534-2682batch: iter_time=2.275e-04, forward_time=0.177, loss_ctc=3.534, loss=3.534, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.893e-04, train_time=2.012
[ALab02] 2023-06-08 05:54:57,973 (trainer:721) INFO: 42epoch:train:2683-2831batch: iter_time=2.453e-04, forward_time=0.177, loss_ctc=3.472, loss=3.472, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.891e-04, train_time=1.988
[ALab02] 2023-06-08 05:56:11,973 (trainer:721) INFO: 42epoch:train:2832-2980batch: iter_time=2.348e-04, forward_time=0.175, loss_ctc=3.516, loss=3.516, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.888e-04, train_time=1.984
[ALab02] 2023-06-08 05:57:00,125 (trainer:338) INFO: 42epoch results: [train] iter_time=0.002, forward_time=0.169, loss_ctc=3.534, loss=3.534, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.915e-04, train_time=1.969, time=24 minutes and 34.1 seconds, total_count=125748, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=13.603, cer_ctc=0.301, cer=0.301, loss=13.603, time=14.54 seconds, total_count=1260, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.51 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 05:57:02,676 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 05:57:02,679 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/31epoch.pth
[ALab02] 2023-06-08 05:57:02,679 (trainer:272) INFO: 43/70epoch started. Estimated time to finish: 12 hours, 50 minutes and 34.15 seconds
[ALab02] 2023-06-08 05:58:17,734 (trainer:721) INFO: 43epoch:train:1-149batch: iter_time=0.007, forward_time=0.177, loss_ctc=3.316, loss=3.316, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.884e-04, train_time=2.019
[ALab02] 2023-06-08 05:59:31,628 (trainer:721) INFO: 43epoch:train:150-298batch: iter_time=2.864e-04, forward_time=0.176, loss_ctc=3.430, loss=3.430, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.882e-04, train_time=1.979
[ALab02] 2023-06-08 06:00:46,556 (trainer:721) INFO: 43epoch:train:299-447batch: iter_time=2.322e-04, forward_time=0.178, loss_ctc=3.511, loss=3.511, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.879e-04, train_time=2.018
[ALab02] 2023-06-08 06:02:01,178 (trainer:721) INFO: 43epoch:train:448-596batch: iter_time=0.014, forward_time=0.175, loss_ctc=3.370, loss=3.370, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.876e-04, train_time=1.997
[ALab02] 2023-06-08 06:03:14,933 (trainer:721) INFO: 43epoch:train:597-745batch: iter_time=8.304e-04, forward_time=0.175, loss_ctc=3.692, loss=3.692, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.873e-04, train_time=1.985
[ALab02] 2023-06-08 06:04:28,962 (trainer:721) INFO: 43epoch:train:746-894batch: iter_time=2.705e-04, forward_time=0.174, loss_ctc=3.534, loss=3.534, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.870e-04, train_time=1.986
[ALab02] 2023-06-08 06:05:42,613 (trainer:721) INFO: 43epoch:train:895-1043batch: iter_time=0.003, forward_time=0.174, loss_ctc=3.543, loss=3.543, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.867e-04, train_time=1.980
[ALab02] 2023-06-08 06:06:56,653 (trainer:721) INFO: 43epoch:train:1044-1192batch: iter_time=2.302e-04, forward_time=0.175, loss_ctc=3.478, loss=3.478, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.864e-04, train_time=1.981
[ALab02] 2023-06-08 06:08:10,747 (trainer:721) INFO: 43epoch:train:1193-1341batch: iter_time=0.004, forward_time=0.175, loss_ctc=3.579, loss=3.579, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.861e-04, train_time=1.993
[ALab02] 2023-06-08 06:09:24,188 (trainer:721) INFO: 43epoch:train:1342-1490batch: iter_time=0.002, forward_time=0.175, loss_ctc=3.396, loss=3.396, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.859e-04, train_time=1.970
[ALab02] 2023-06-08 06:10:37,978 (trainer:721) INFO: 43epoch:train:1491-1639batch: iter_time=9.491e-04, forward_time=0.176, loss_ctc=3.562, loss=3.562, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.856e-04, train_time=1.985
[ALab02] 2023-06-08 06:11:52,017 (trainer:721) INFO: 43epoch:train:1640-1788batch: iter_time=2.323e-04, forward_time=0.173, loss_ctc=3.500, loss=3.500, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.853e-04, train_time=1.981
[ALab02] 2023-06-08 06:13:06,887 (trainer:721) INFO: 43epoch:train:1789-1937batch: iter_time=2.474e-04, forward_time=0.178, loss_ctc=3.601, loss=3.601, backward_time=0.157, optim_step_time=0.036, optim0_lr0=4.850e-04, train_time=2.012
[ALab02] 2023-06-08 06:14:21,560 (trainer:721) INFO: 43epoch:train:1938-2086batch: iter_time=2.431e-04, forward_time=0.178, loss_ctc=3.471, loss=3.471, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.847e-04, train_time=2.007
[ALab02] 2023-06-08 06:15:35,306 (trainer:721) INFO: 43epoch:train:2087-2235batch: iter_time=2.484e-04, forward_time=0.175, loss_ctc=3.542, loss=3.542, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.844e-04, train_time=1.979
[ALab02] 2023-06-08 06:16:50,644 (trainer:721) INFO: 43epoch:train:2236-2384batch: iter_time=3.220e-04, forward_time=0.179, loss_ctc=3.564, loss=3.564, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.842e-04, train_time=2.017
[ALab02] 2023-06-08 06:18:05,067 (trainer:721) INFO: 43epoch:train:2385-2533batch: iter_time=2.291e-04, forward_time=0.179, loss_ctc=3.344, loss=3.344, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.839e-04, train_time=2.001
[ALab02] 2023-06-08 06:19:19,952 (trainer:721) INFO: 43epoch:train:2534-2682batch: iter_time=2.605e-04, forward_time=0.178, loss_ctc=3.386, loss=3.386, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.836e-04, train_time=2.010
[ALab02] 2023-06-08 06:20:35,422 (trainer:721) INFO: 43epoch:train:2683-2831batch: iter_time=0.001, forward_time=0.179, loss_ctc=3.568, loss=3.568, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.833e-04, train_time=2.025
[ALab02] 2023-06-08 06:21:51,239 (trainer:721) INFO: 43epoch:train:2832-2980batch: iter_time=0.003, forward_time=0.181, loss_ctc=3.456, loss=3.456, backward_time=0.158, optim_step_time=0.036, optim0_lr0=4.830e-04, train_time=2.032
[ALab02] 2023-06-08 06:22:42,209 (trainer:338) INFO: 43epoch results: [train] iter_time=0.002, forward_time=0.177, loss_ctc=3.490, loss=3.490, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.857e-04, train_time=1.998, time=24 minutes and 55.5 seconds, total_count=128742, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.395, cer_ctc=0.318, cer=0.318, loss=14.395, time=17.38 seconds, total_count=1290, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.65 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 06:22:44,738 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 06:22:44,740 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/34epoch.pth
[ALab02] 2023-06-08 06:22:44,740 (trainer:272) INFO: 44/70epoch started. Estimated time to finish: 12 hours, 21 minutes and 54.39 seconds
[ALab02] 2023-06-08 06:23:59,686 (trainer:721) INFO: 44epoch:train:1-149batch: iter_time=0.022, forward_time=0.176, loss_ctc=3.436, loss=3.436, backward_time=0.154, optim_step_time=0.037, optim0_lr0=4.827e-04, train_time=2.015
[ALab02] 2023-06-08 06:25:13,267 (trainer:721) INFO: 44epoch:train:150-298batch: iter_time=3.194e-04, forward_time=0.173, loss_ctc=3.473, loss=3.473, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.825e-04, train_time=1.980
[ALab02] 2023-06-08 06:26:27,269 (trainer:721) INFO: 44epoch:train:299-447batch: iter_time=3.245e-04, forward_time=0.175, loss_ctc=3.404, loss=3.404, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.822e-04, train_time=1.986
[ALab02] 2023-06-08 06:27:40,316 (trainer:721) INFO: 44epoch:train:448-596batch: iter_time=2.279e-04, forward_time=0.172, loss_ctc=3.442, loss=3.442, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.819e-04, train_time=1.953
[ALab02] 2023-06-08 06:28:54,205 (trainer:721) INFO: 44epoch:train:597-745batch: iter_time=2.336e-04, forward_time=0.175, loss_ctc=3.515, loss=3.515, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.816e-04, train_time=1.987
[ALab02] 2023-06-08 06:30:07,974 (trainer:721) INFO: 44epoch:train:746-894batch: iter_time=2.399e-04, forward_time=0.174, loss_ctc=3.455, loss=3.455, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.813e-04, train_time=1.981
[ALab02] 2023-06-08 06:31:21,404 (trainer:721) INFO: 44epoch:train:895-1043batch: iter_time=2.743e-04, forward_time=0.172, loss_ctc=3.426, loss=3.426, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.811e-04, train_time=1.970
[ALab02] 2023-06-08 06:32:36,279 (trainer:721) INFO: 44epoch:train:1044-1192batch: iter_time=2.351e-04, forward_time=0.179, loss_ctc=3.209, loss=3.209, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.808e-04, train_time=2.007
[ALab02] 2023-06-08 06:33:50,004 (trainer:721) INFO: 44epoch:train:1193-1341batch: iter_time=2.459e-04, forward_time=0.176, loss_ctc=3.316, loss=3.316, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.805e-04, train_time=1.983
[ALab02] 2023-06-08 06:35:04,455 (trainer:721) INFO: 44epoch:train:1342-1490batch: iter_time=2.595e-04, forward_time=0.177, loss_ctc=3.520, loss=3.520, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.802e-04, train_time=1.998
[ALab02] 2023-06-08 06:36:19,141 (trainer:721) INFO: 44epoch:train:1491-1639batch: iter_time=2.476e-04, forward_time=0.179, loss_ctc=3.404, loss=3.404, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.800e-04, train_time=2.007
[ALab02] 2023-06-08 06:37:34,162 (trainer:721) INFO: 44epoch:train:1640-1788batch: iter_time=2.342e-04, forward_time=0.178, loss_ctc=3.406, loss=3.406, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.797e-04, train_time=2.009
[ALab02] 2023-06-08 06:38:48,014 (trainer:721) INFO: 44epoch:train:1789-1937batch: iter_time=2.163e-04, forward_time=0.175, loss_ctc=3.383, loss=3.383, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.794e-04, train_time=1.987
[ALab02] 2023-06-08 06:40:02,915 (trainer:721) INFO: 44epoch:train:1938-2086batch: iter_time=2.182e-04, forward_time=0.176, loss_ctc=3.376, loss=3.376, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.791e-04, train_time=2.013
[ALab02] 2023-06-08 06:41:17,230 (trainer:721) INFO: 44epoch:train:2087-2235batch: iter_time=0.015, forward_time=0.175, loss_ctc=3.301, loss=3.301, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.789e-04, train_time=1.994
[ALab02] 2023-06-08 06:42:31,275 (trainer:721) INFO: 44epoch:train:2236-2384batch: iter_time=2.485e-04, forward_time=0.176, loss_ctc=3.230, loss=3.230, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.786e-04, train_time=1.981
[ALab02] 2023-06-08 06:43:46,177 (trainer:721) INFO: 44epoch:train:2385-2533batch: iter_time=2.044e-04, forward_time=0.178, loss_ctc=3.458, loss=3.458, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.783e-04, train_time=2.015
[ALab02] 2023-06-08 06:45:00,113 (trainer:721) INFO: 44epoch:train:2534-2682batch: iter_time=0.002, forward_time=0.176, loss_ctc=3.322, loss=3.322, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.781e-04, train_time=1.986
[ALab02] 2023-06-08 06:46:15,131 (trainer:721) INFO: 44epoch:train:2683-2831batch: iter_time=2.511e-04, forward_time=0.178, loss_ctc=3.444, loss=3.444, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.778e-04, train_time=2.013
[ALab02] 2023-06-08 06:47:29,855 (trainer:721) INFO: 44epoch:train:2832-2980batch: iter_time=2.485e-04, forward_time=0.175, loss_ctc=3.460, loss=3.460, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.775e-04, train_time=2.001
[ALab02] 2023-06-08 06:48:18,509 (trainer:338) INFO: 44epoch results: [train] iter_time=0.002, forward_time=0.176, loss_ctc=3.395, loss=3.395, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.801e-04, train_time=1.993, time=24 minutes and 52.17 seconds, total_count=131736, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.313, cer_ctc=0.318, cer=0.318, loss=14.313, time=14.73 seconds, total_count=1320, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.86 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 06:48:21,167 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 06:48:21,168 (trainer:272) INFO: 45/70epoch started. Estimated time to finish: 11 hours, 53 minutes and 19.38 seconds
[ALab02] 2023-06-08 06:49:35,598 (trainer:721) INFO: 45epoch:train:1-149batch: iter_time=0.010, forward_time=0.175, loss_ctc=3.307, loss=3.307, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.772e-04, train_time=2.001
[ALab02] 2023-06-08 06:50:50,042 (trainer:721) INFO: 45epoch:train:150-298batch: iter_time=3.363e-04, forward_time=0.177, loss_ctc=3.190, loss=3.190, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.770e-04, train_time=1.998
[ALab02] 2023-06-08 06:52:03,445 (trainer:721) INFO: 45epoch:train:299-447batch: iter_time=2.309e-04, forward_time=0.173, loss_ctc=3.317, loss=3.317, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.767e-04, train_time=1.971
[ALab02] 2023-06-08 06:53:17,731 (trainer:721) INFO: 45epoch:train:448-596batch: iter_time=2.366e-04, forward_time=0.176, loss_ctc=3.282, loss=3.282, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.764e-04, train_time=1.990
[ALab02] 2023-06-08 06:54:32,051 (trainer:721) INFO: 45epoch:train:597-745batch: iter_time=2.226e-04, forward_time=0.178, loss_ctc=3.235, loss=3.235, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.761e-04, train_time=2.000
[ALab02] 2023-06-08 06:55:45,231 (trainer:721) INFO: 45epoch:train:746-894batch: iter_time=2.179e-04, forward_time=0.173, loss_ctc=3.236, loss=3.236, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.759e-04, train_time=1.964
[ALab02] 2023-06-08 06:56:59,561 (trainer:721) INFO: 45epoch:train:895-1043batch: iter_time=2.608e-04, forward_time=0.177, loss_ctc=3.182, loss=3.182, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.756e-04, train_time=1.996
[ALab02] 2023-06-08 06:58:13,421 (trainer:721) INFO: 45epoch:train:1044-1192batch: iter_time=2.200e-04, forward_time=0.174, loss_ctc=3.245, loss=3.245, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.753e-04, train_time=1.976
[ALab02] 2023-06-08 06:59:29,039 (trainer:721) INFO: 45epoch:train:1193-1341batch: iter_time=0.011, forward_time=0.180, loss_ctc=3.391, loss=3.391, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.751e-04, train_time=2.035
[ALab02] 2023-06-08 07:00:42,661 (trainer:721) INFO: 45epoch:train:1342-1490batch: iter_time=2.377e-04, forward_time=0.173, loss_ctc=3.320, loss=3.320, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.748e-04, train_time=1.976
[ALab02] 2023-06-08 07:02:07,574 (trainer:721) INFO: 45epoch:train:1491-1639batch: iter_time=0.090, forward_time=0.183, loss_ctc=3.229, loss=3.229, backward_time=0.154, optim_step_time=0.041, optim0_lr0=4.746e-04, train_time=2.245
[ALab02] 2023-06-08 07:03:24,894 (trainer:721) INFO: 45epoch:train:1640-1788batch: iter_time=0.032, forward_time=0.176, loss_ctc=3.201, loss=3.201, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.743e-04, train_time=2.104
[ALab02] 2023-06-08 07:04:37,289 (trainer:721) INFO: 45epoch:train:1789-1937batch: iter_time=4.454e-04, forward_time=0.165, loss_ctc=3.287, loss=3.287, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.740e-04, train_time=1.948
[ALab02] 2023-06-08 07:05:50,306 (trainer:721) INFO: 45epoch:train:1938-2086batch: iter_time=0.011, forward_time=0.165, loss_ctc=3.472, loss=3.472, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.738e-04, train_time=1.962
[ALab02] 2023-06-08 07:07:02,570 (trainer:721) INFO: 45epoch:train:2087-2235batch: iter_time=2.073e-04, forward_time=0.163, loss_ctc=3.402, loss=3.402, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.735e-04, train_time=1.936
[ALab02] 2023-06-08 07:08:15,513 (trainer:721) INFO: 45epoch:train:2236-2384batch: iter_time=2.198e-04, forward_time=0.164, loss_ctc=3.422, loss=3.422, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.732e-04, train_time=1.956
[ALab02] 2023-06-08 07:09:27,285 (trainer:721) INFO: 45epoch:train:2385-2533batch: iter_time=2.292e-04, forward_time=0.162, loss_ctc=3.371, loss=3.371, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.730e-04, train_time=1.929
[ALab02] 2023-06-08 07:10:39,958 (trainer:721) INFO: 45epoch:train:2534-2682batch: iter_time=2.405e-04, forward_time=0.164, loss_ctc=3.348, loss=3.348, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.727e-04, train_time=1.954
[ALab02] 2023-06-08 07:11:53,146 (trainer:721) INFO: 45epoch:train:2683-2831batch: iter_time=2.612e-04, forward_time=0.166, loss_ctc=3.161, loss=3.161, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.724e-04, train_time=1.961
[ALab02] 2023-06-08 07:13:06,295 (trainer:721) INFO: 45epoch:train:2832-2980batch: iter_time=2.418e-04, forward_time=0.168, loss_ctc=3.195, loss=3.195, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.722e-04, train_time=1.961
[ALab02] 2023-06-08 07:13:53,966 (trainer:338) INFO: 45epoch results: [train] iter_time=0.008, forward_time=0.172, loss_ctc=3.287, loss=3.287, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.747e-04, train_time=1.993, time=24 minutes and 52.08 seconds, total_count=134730, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.549, cer_ctc=0.299, cer=0.299, loss=14.549, time=14.14 seconds, total_count=1350, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.58 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 07:13:56,467 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 07:13:56,470 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/43epoch.pth, exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/44epoch.pth
[ALab02] 2023-06-08 07:13:56,470 (trainer:272) INFO: 46/70epoch started. Estimated time to finish: 11 hours, 24 minutes and 51.68 seconds
[ALab02] 2023-06-08 07:15:09,286 (trainer:721) INFO: 46epoch:train:1-149batch: iter_time=0.010, forward_time=0.163, loss_ctc=3.304, loss=3.304, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.719e-04, train_time=1.958
[ALab02] 2023-06-08 07:16:22,113 (trainer:721) INFO: 46epoch:train:150-298batch: iter_time=2.649e-04, forward_time=0.167, loss_ctc=3.136, loss=3.136, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.716e-04, train_time=1.954
[ALab02] 2023-06-08 07:17:34,697 (trainer:721) INFO: 46epoch:train:299-447batch: iter_time=0.008, forward_time=0.164, loss_ctc=3.097, loss=3.097, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.714e-04, train_time=1.945
[ALab02] 2023-06-08 07:18:49,061 (trainer:721) INFO: 46epoch:train:448-596batch: iter_time=0.015, forward_time=0.167, loss_ctc=3.248, loss=3.248, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.711e-04, train_time=1.995
[ALab02] 2023-06-08 07:20:00,736 (trainer:721) INFO: 46epoch:train:597-745batch: iter_time=2.333e-04, forward_time=0.163, loss_ctc=3.289, loss=3.289, backward_time=0.153, optim_step_time=0.032, optim0_lr0=4.709e-04, train_time=1.929
[ALab02] 2023-06-08 07:21:13,468 (trainer:721) INFO: 46epoch:train:746-894batch: iter_time=2.269e-04, forward_time=0.167, loss_ctc=3.195, loss=3.195, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.706e-04, train_time=1.952
[ALab02] 2023-06-08 07:22:25,528 (trainer:721) INFO: 46epoch:train:895-1043batch: iter_time=0.003, forward_time=0.161, loss_ctc=3.385, loss=3.385, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.703e-04, train_time=1.936
[ALab02] 2023-06-08 07:23:38,484 (trainer:721) INFO: 46epoch:train:1044-1192batch: iter_time=0.007, forward_time=0.165, loss_ctc=3.298, loss=3.298, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.701e-04, train_time=1.952
[ALab02] 2023-06-08 07:24:50,569 (trainer:721) INFO: 46epoch:train:1193-1341batch: iter_time=0.004, forward_time=0.164, loss_ctc=3.143, loss=3.143, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.698e-04, train_time=1.940
[ALab02] 2023-06-08 07:26:03,155 (trainer:721) INFO: 46epoch:train:1342-1490batch: iter_time=2.264e-04, forward_time=0.164, loss_ctc=3.267, loss=3.267, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.696e-04, train_time=1.947
[ALab02] 2023-06-08 07:27:18,386 (trainer:721) INFO: 46epoch:train:1491-1639batch: iter_time=0.038, forward_time=0.167, loss_ctc=3.365, loss=3.365, backward_time=0.157, optim_step_time=0.037, optim0_lr0=4.693e-04, train_time=2.021
[ALab02] 2023-06-08 07:28:30,120 (trainer:721) INFO: 46epoch:train:1640-1788batch: iter_time=0.002, forward_time=0.163, loss_ctc=3.201, loss=3.201, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.691e-04, train_time=1.921
[ALab02] 2023-06-08 07:29:43,005 (trainer:721) INFO: 46epoch:train:1789-1937batch: iter_time=2.120e-04, forward_time=0.164, loss_ctc=3.395, loss=3.395, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.688e-04, train_time=1.961
[ALab02] 2023-06-08 07:30:55,536 (trainer:721) INFO: 46epoch:train:1938-2086batch: iter_time=0.007, forward_time=0.164, loss_ctc=3.279, loss=3.279, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.685e-04, train_time=1.945
[ALab02] 2023-06-08 07:32:07,466 (trainer:721) INFO: 46epoch:train:2087-2235batch: iter_time=0.020, forward_time=0.162, loss_ctc=3.307, loss=3.307, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.683e-04, train_time=1.933
[ALab02] 2023-06-08 07:33:21,006 (trainer:721) INFO: 46epoch:train:2236-2384batch: iter_time=0.029, forward_time=0.164, loss_ctc=3.318, loss=3.318, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.680e-04, train_time=1.969
[ALab02] 2023-06-08 07:34:34,754 (trainer:721) INFO: 46epoch:train:2385-2533batch: iter_time=0.062, forward_time=0.166, loss_ctc=3.239, loss=3.239, backward_time=0.154, optim_step_time=0.032, optim0_lr0=4.678e-04, train_time=1.986
[ALab02] 2023-06-08 07:35:49,580 (trainer:721) INFO: 46epoch:train:2534-2682batch: iter_time=0.051, forward_time=0.166, loss_ctc=3.173, loss=3.173, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.675e-04, train_time=2.009
[ALab02] 2023-06-08 07:37:06,227 (trainer:721) INFO: 46epoch:train:2683-2831batch: iter_time=0.073, forward_time=0.165, loss_ctc=3.291, loss=3.291, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.673e-04, train_time=2.058
[ALab02] 2023-06-08 07:38:23,491 (trainer:721) INFO: 46epoch:train:2832-2980batch: iter_time=0.106, forward_time=0.164, loss_ctc=3.220, loss=3.220, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.670e-04, train_time=2.066
[ALab02] 2023-06-08 07:39:14,144 (trainer:338) INFO: 46epoch results: [train] iter_time=0.022, forward_time=0.164, loss_ctc=3.254, loss=3.254, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.694e-04, train_time=1.969, time=24 minutes and 34.49 seconds, total_count=137724, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.090, cer_ctc=0.315, cer=0.315, loss=14.090, time=16.84 seconds, total_count=1380, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.34 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 07:39:16,650 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 07:39:16,652 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/36epoch.pth
[ALab02] 2023-06-08 07:39:16,652 (trainer:272) INFO: 47/70epoch started. Estimated time to finish: 10 hours, 56 minutes and 23.58 seconds
[ALab02] 2023-06-08 07:40:29,604 (trainer:721) INFO: 47epoch:train:1-149batch: iter_time=0.007, forward_time=0.166, loss_ctc=3.178, loss=3.178, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.667e-04, train_time=1.963
[ALab02] 2023-06-08 07:41:41,713 (trainer:721) INFO: 47epoch:train:150-298batch: iter_time=2.606e-04, forward_time=0.164, loss_ctc=3.157, loss=3.157, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.665e-04, train_time=1.935
[ALab02] 2023-06-08 07:42:54,130 (trainer:721) INFO: 47epoch:train:299-447batch: iter_time=2.619e-04, forward_time=0.165, loss_ctc=3.225, loss=3.225, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.662e-04, train_time=1.946
[ALab02] 2023-06-08 07:44:06,505 (trainer:721) INFO: 47epoch:train:448-596batch: iter_time=8.546e-04, forward_time=0.162, loss_ctc=3.221, loss=3.221, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.660e-04, train_time=1.937
[ALab02] 2023-06-08 07:45:18,692 (trainer:721) INFO: 47epoch:train:597-745batch: iter_time=0.006, forward_time=0.163, loss_ctc=3.201, loss=3.201, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.657e-04, train_time=1.942
[ALab02] 2023-06-08 07:46:30,570 (trainer:721) INFO: 47epoch:train:746-894batch: iter_time=0.002, forward_time=0.161, loss_ctc=3.275, loss=3.275, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.655e-04, train_time=1.927
[ALab02] 2023-06-08 07:47:44,899 (trainer:721) INFO: 47epoch:train:895-1043batch: iter_time=0.038, forward_time=0.166, loss_ctc=3.190, loss=3.190, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.652e-04, train_time=1.998
[ALab02] 2023-06-08 07:48:58,371 (trainer:721) INFO: 47epoch:train:1044-1192batch: iter_time=0.034, forward_time=0.162, loss_ctc=3.250, loss=3.250, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.650e-04, train_time=1.967
[ALab02] 2023-06-08 07:50:12,433 (trainer:721) INFO: 47epoch:train:1193-1341batch: iter_time=0.055, forward_time=0.166, loss_ctc=3.150, loss=3.150, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.647e-04, train_time=1.993
[ALab02] 2023-06-08 07:51:27,209 (trainer:721) INFO: 47epoch:train:1342-1490batch: iter_time=0.088, forward_time=0.163, loss_ctc=3.230, loss=3.230, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.645e-04, train_time=2.001
[ALab02] 2023-06-08 07:52:43,773 (trainer:721) INFO: 47epoch:train:1491-1639batch: iter_time=0.095, forward_time=0.164, loss_ctc=3.220, loss=3.220, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.642e-04, train_time=2.050
[ALab02] 2023-06-08 07:54:00,942 (trainer:721) INFO: 47epoch:train:1640-1788batch: iter_time=0.104, forward_time=0.164, loss_ctc=3.284, loss=3.284, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.640e-04, train_time=2.077
[ALab02] 2023-06-08 07:55:20,353 (trainer:721) INFO: 47epoch:train:1789-1937batch: iter_time=0.131, forward_time=0.166, loss_ctc=3.243, loss=3.243, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.637e-04, train_time=2.138
[ALab02] 2023-06-08 07:56:39,504 (trainer:721) INFO: 47epoch:train:1938-2086batch: iter_time=0.134, forward_time=0.166, loss_ctc=3.130, loss=3.130, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.635e-04, train_time=2.126
[ALab02] 2023-06-08 07:58:01,495 (trainer:721) INFO: 47epoch:train:2087-2235batch: iter_time=0.159, forward_time=0.166, loss_ctc=3.234, loss=3.234, backward_time=0.154, optim_step_time=0.039, optim0_lr0=4.632e-04, train_time=2.195
[ALab02] 2023-06-08 07:59:21,769 (trainer:721) INFO: 47epoch:train:2236-2384batch: iter_time=0.127, forward_time=0.169, loss_ctc=3.127, loss=3.127, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.630e-04, train_time=2.153
[ALab02] 2023-06-08 08:00:40,283 (trainer:721) INFO: 47epoch:train:2385-2533batch: iter_time=0.138, forward_time=0.162, loss_ctc=3.236, loss=3.236, backward_time=0.152, optim_step_time=0.035, optim0_lr0=4.628e-04, train_time=2.114
[ALab02] 2023-06-08 08:02:00,299 (trainer:721) INFO: 47epoch:train:2534-2682batch: iter_time=0.143, forward_time=0.166, loss_ctc=3.069, loss=3.069, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.625e-04, train_time=2.146
[ALab02] 2023-06-08 08:03:23,204 (trainer:721) INFO: 47epoch:train:2683-2831batch: iter_time=0.168, forward_time=0.167, loss_ctc=3.061, loss=3.061, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.623e-04, train_time=2.230
[ALab02] 2023-06-08 08:04:44,990 (trainer:721) INFO: 47epoch:train:2832-2980batch: iter_time=0.157, forward_time=0.169, loss_ctc=3.117, loss=3.117, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.620e-04, train_time=2.186
[ALab02] 2023-06-08 08:05:34,127 (trainer:338) INFO: 47epoch results: [train] iter_time=0.080, forward_time=0.165, loss_ctc=3.188, loss=3.188, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.644e-04, train_time=2.052, time=25 minutes and 36.53 seconds, total_count=140718, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=13.655, cer_ctc=0.306, cer=0.306, loss=13.655, time=15.2 seconds, total_count=1410, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.74 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 08:05:36,709 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 08:05:36,711 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/46epoch.pth
[ALab02] 2023-06-08 08:05:36,712 (trainer:272) INFO: 48/70epoch started. Estimated time to finish: 10 hours, 28 minutes and 32.79 seconds
[ALab02] 2023-06-08 08:06:52,150 (trainer:721) INFO: 48epoch:train:1-149batch: iter_time=0.006, forward_time=0.176, loss_ctc=3.197, loss=3.197, backward_time=0.157, optim_step_time=0.032, optim0_lr0=4.618e-04, train_time=2.030
[ALab02] 2023-06-08 08:08:06,682 (trainer:721) INFO: 48epoch:train:150-298batch: iter_time=2.185e-04, forward_time=0.176, loss_ctc=3.132, loss=3.132, backward_time=0.157, optim_step_time=0.032, optim0_lr0=4.615e-04, train_time=1.998
[ALab02] 2023-06-08 08:09:20,777 (trainer:721) INFO: 48epoch:train:299-447batch: iter_time=0.011, forward_time=0.175, loss_ctc=3.034, loss=3.034, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.613e-04, train_time=1.993
[ALab02] 2023-06-08 08:10:35,138 (trainer:721) INFO: 48epoch:train:448-596batch: iter_time=2.193e-04, forward_time=0.177, loss_ctc=3.061, loss=3.061, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.610e-04, train_time=1.989
[ALab02] 2023-06-08 08:11:48,799 (trainer:721) INFO: 48epoch:train:597-745batch: iter_time=2.228e-04, forward_time=0.174, loss_ctc=3.082, loss=3.082, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.608e-04, train_time=1.981
[ALab02] 2023-06-08 08:13:02,087 (trainer:721) INFO: 48epoch:train:746-894batch: iter_time=2.255e-04, forward_time=0.174, loss_ctc=3.044, loss=3.044, backward_time=0.154, optim_step_time=0.032, optim0_lr0=4.605e-04, train_time=1.969
[ALab02] 2023-06-08 08:14:15,718 (trainer:721) INFO: 48epoch:train:895-1043batch: iter_time=2.310e-04, forward_time=0.173, loss_ctc=3.183, loss=3.183, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.603e-04, train_time=1.976
[ALab02] 2023-06-08 08:15:29,901 (trainer:721) INFO: 48epoch:train:1044-1192batch: iter_time=2.058e-04, forward_time=0.174, loss_ctc=3.106, loss=3.106, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.601e-04, train_time=1.985
[ALab02] 2023-06-08 08:16:45,802 (trainer:721) INFO: 48epoch:train:1193-1341batch: iter_time=0.021, forward_time=0.179, loss_ctc=3.010, loss=3.010, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.598e-04, train_time=2.043
[ALab02] 2023-06-08 08:18:00,609 (trainer:721) INFO: 48epoch:train:1342-1490batch: iter_time=0.006, forward_time=0.177, loss_ctc=3.095, loss=3.095, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.596e-04, train_time=2.008
[ALab02] 2023-06-08 08:19:14,563 (trainer:721) INFO: 48epoch:train:1491-1639batch: iter_time=0.003, forward_time=0.175, loss_ctc=3.044, loss=3.044, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.593e-04, train_time=1.984
[ALab02] 2023-06-08 08:20:29,665 (trainer:721) INFO: 48epoch:train:1640-1788batch: iter_time=0.029, forward_time=0.178, loss_ctc=3.015, loss=3.015, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.591e-04, train_time=2.011
[ALab02] 2023-06-08 08:21:43,661 (trainer:721) INFO: 48epoch:train:1789-1937batch: iter_time=0.015, forward_time=0.174, loss_ctc=3.102, loss=3.102, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.588e-04, train_time=1.992
[ALab02] 2023-06-08 08:22:58,512 (trainer:721) INFO: 48epoch:train:1938-2086batch: iter_time=0.049, forward_time=0.174, loss_ctc=3.055, loss=3.055, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.586e-04, train_time=2.010
[ALab02] 2023-06-08 08:24:14,104 (trainer:721) INFO: 48epoch:train:2087-2235batch: iter_time=0.039, forward_time=0.176, loss_ctc=3.048, loss=3.048, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.584e-04, train_time=2.025
[ALab02] 2023-06-08 08:25:28,396 (trainer:721) INFO: 48epoch:train:2236-2384batch: iter_time=0.011, forward_time=0.175, loss_ctc=3.199, loss=3.199, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.581e-04, train_time=1.992
[ALab02] 2023-06-08 08:26:44,487 (trainer:721) INFO: 48epoch:train:2385-2533batch: iter_time=0.052, forward_time=0.174, loss_ctc=3.062, loss=3.062, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.579e-04, train_time=2.049
[ALab02] 2023-06-08 08:28:03,602 (trainer:721) INFO: 48epoch:train:2534-2682batch: iter_time=0.115, forward_time=0.170, loss_ctc=3.026, loss=3.026, backward_time=0.157, optim_step_time=0.036, optim0_lr0=4.577e-04, train_time=2.124
[ALab02] 2023-06-08 08:29:23,241 (trainer:721) INFO: 48epoch:train:2683-2831batch: iter_time=0.127, forward_time=0.166, loss_ctc=3.208, loss=3.208, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.574e-04, train_time=2.142
[ALab02] 2023-06-08 08:30:43,780 (trainer:721) INFO: 48epoch:train:2832-2980batch: iter_time=0.154, forward_time=0.165, loss_ctc=3.121, loss=3.121, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.572e-04, train_time=2.150
[ALab02] 2023-06-08 08:31:34,501 (trainer:338) INFO: 48epoch results: [train] iter_time=0.032, forward_time=0.174, loss_ctc=3.090, loss=3.090, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.594e-04, train_time=2.023, time=25 minutes and 14.3 seconds, total_count=143712, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=13.917, cer_ctc=0.298, cer=0.298, loss=13.917, time=16.88 seconds, total_count=1440, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.61 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 08:31:37,128 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-08 08:31:37,130 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/38epoch.pth
[ALab02] 2023-06-08 08:31:37,130 (trainer:272) INFO: 49/70epoch started. Estimated time to finish: 10 hours and 36.77 seconds
[ALab02] 2023-06-08 08:32:51,364 (trainer:721) INFO: 49epoch:train:1-149batch: iter_time=0.015, forward_time=0.169, loss_ctc=3.029, loss=3.029, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.569e-04, train_time=1.995
[ALab02] 2023-06-08 08:34:03,826 (trainer:721) INFO: 49epoch:train:150-298batch: iter_time=2.418e-04, forward_time=0.164, loss_ctc=3.036, loss=3.036, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.567e-04, train_time=1.947
[ALab02] 2023-06-08 08:35:16,675 (trainer:721) INFO: 49epoch:train:299-447batch: iter_time=0.017, forward_time=0.162, loss_ctc=3.040, loss=3.040, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.564e-04, train_time=1.957
[ALab02] 2023-06-08 08:36:28,933 (trainer:721) INFO: 49epoch:train:448-596batch: iter_time=7.416e-04, forward_time=0.164, loss_ctc=3.058, loss=3.058, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.562e-04, train_time=1.933
[ALab02] 2023-06-08 08:37:40,134 (trainer:721) INFO: 49epoch:train:597-745batch: iter_time=0.001, forward_time=0.161, loss_ctc=3.091, loss=3.091, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.560e-04, train_time=1.915
[ALab02] 2023-06-08 08:38:53,634 (trainer:721) INFO: 49epoch:train:746-894batch: iter_time=0.013, forward_time=0.168, loss_ctc=2.936, loss=2.936, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.557e-04, train_time=1.972
[ALab02] 2023-06-08 08:40:07,141 (trainer:721) INFO: 49epoch:train:895-1043batch: iter_time=0.037, forward_time=0.164, loss_ctc=3.105, loss=3.105, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.555e-04, train_time=1.975
[ALab02] 2023-06-08 08:41:21,131 (trainer:721) INFO: 49epoch:train:1044-1192batch: iter_time=0.040, forward_time=0.166, loss_ctc=2.969, loss=2.969, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.553e-04, train_time=1.981
[ALab02] 2023-06-08 08:42:36,004 (trainer:721) INFO: 49epoch:train:1193-1341batch: iter_time=0.077, forward_time=0.165, loss_ctc=2.953, loss=2.953, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.550e-04, train_time=2.014
[ALab02] 2023-06-08 08:43:50,542 (trainer:721) INFO: 49epoch:train:1342-1490batch: iter_time=0.064, forward_time=0.162, loss_ctc=3.191, loss=3.191, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.548e-04, train_time=2.005
[ALab02] 2023-06-08 08:45:05,447 (trainer:721) INFO: 49epoch:train:1491-1639batch: iter_time=0.066, forward_time=0.164, loss_ctc=3.097, loss=3.097, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.546e-04, train_time=1.995
[ALab02] 2023-06-08 08:46:21,191 (trainer:721) INFO: 49epoch:train:1640-1788batch: iter_time=0.083, forward_time=0.164, loss_ctc=3.102, loss=3.102, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.543e-04, train_time=2.040
[ALab02] 2023-06-08 08:47:40,098 (trainer:721) INFO: 49epoch:train:1789-1937batch: iter_time=0.137, forward_time=0.167, loss_ctc=3.093, loss=3.093, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.541e-04, train_time=2.123
[ALab02] 2023-06-08 08:48:59,447 (trainer:721) INFO: 49epoch:train:1938-2086batch: iter_time=0.137, forward_time=0.167, loss_ctc=3.155, loss=3.155, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.539e-04, train_time=2.133
[ALab02] 2023-06-08 08:50:21,666 (trainer:721) INFO: 49epoch:train:2087-2235batch: iter_time=0.148, forward_time=0.170, loss_ctc=2.958, loss=2.958, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.536e-04, train_time=2.197
[ALab02] 2023-06-08 08:51:42,529 (trainer:721) INFO: 49epoch:train:2236-2384batch: iter_time=0.154, forward_time=0.165, loss_ctc=2.952, loss=2.952, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.534e-04, train_time=2.171
[ALab02] 2023-06-08 08:53:05,134 (trainer:721) INFO: 49epoch:train:2385-2533batch: iter_time=0.174, forward_time=0.166, loss_ctc=3.034, loss=3.034, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.532e-04, train_time=2.223
[ALab02] 2023-06-08 08:54:27,013 (trainer:721) INFO: 49epoch:train:2534-2682batch: iter_time=0.160, forward_time=0.167, loss_ctc=3.087, loss=3.087, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.529e-04, train_time=2.198
[ALab02] 2023-06-08 08:55:48,706 (trainer:721) INFO: 49epoch:train:2683-2831batch: iter_time=0.161, forward_time=0.165, loss_ctc=3.187, loss=3.187, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.527e-04, train_time=2.195
[ALab02] 2023-06-08 08:57:11,075 (trainer:721) INFO: 49epoch:train:2832-2980batch: iter_time=0.156, forward_time=0.166, loss_ctc=3.088, loss=3.088, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.525e-04, train_time=2.203
[ALab02] 2023-06-08 08:58:00,172 (trainer:338) INFO: 49epoch results: [train] iter_time=0.082, forward_time=0.165, loss_ctc=3.057, loss=3.057, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.547e-04, train_time=2.060, time=25 minutes and 41.66 seconds, total_count=146706, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.485, cer_ctc=0.305, cer=0.305, loss=14.485, time=14.94 seconds, total_count=1470, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.45 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 08:58:02,708 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 08:58:02,710 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/35epoch.pth
[ALab02] 2023-06-08 08:58:02,710 (trainer:272) INFO: 50/70epoch started. Estimated time to finish: 9 hours, 32 minutes and 56.25 seconds
[ALab02] 2023-06-08 08:59:15,957 (trainer:721) INFO: 50epoch:train:1-149batch: iter_time=0.008, forward_time=0.165, loss_ctc=3.013, loss=3.013, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.522e-04, train_time=1.971
[ALab02] 2023-06-08 09:00:28,282 (trainer:721) INFO: 50epoch:train:150-298batch: iter_time=0.008, forward_time=0.165, loss_ctc=2.966, loss=2.966, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.520e-04, train_time=1.939
[ALab02] 2023-06-08 09:01:41,190 (trainer:721) INFO: 50epoch:train:299-447batch: iter_time=9.664e-04, forward_time=0.165, loss_ctc=2.987, loss=2.987, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.518e-04, train_time=1.961
[ALab02] 2023-06-08 09:02:53,222 (trainer:721) INFO: 50epoch:train:448-596batch: iter_time=0.001, forward_time=0.163, loss_ctc=2.995, loss=2.995, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.515e-04, train_time=1.927
[ALab02] 2023-06-08 09:04:06,074 (trainer:721) INFO: 50epoch:train:597-745batch: iter_time=0.013, forward_time=0.165, loss_ctc=3.010, loss=3.010, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.513e-04, train_time=1.961
[ALab02] 2023-06-08 09:05:18,645 (trainer:721) INFO: 50epoch:train:746-894batch: iter_time=2.230e-04, forward_time=0.165, loss_ctc=3.006, loss=3.006, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.511e-04, train_time=1.945
[ALab02] 2023-06-08 09:06:31,309 (trainer:721) INFO: 50epoch:train:895-1043batch: iter_time=2.549e-04, forward_time=0.166, loss_ctc=3.024, loss=3.024, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.509e-04, train_time=1.955
[ALab02] 2023-06-08 09:07:44,233 (trainer:721) INFO: 50epoch:train:1044-1192batch: iter_time=0.002, forward_time=0.166, loss_ctc=2.962, loss=2.962, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.506e-04, train_time=1.951
[ALab02] 2023-06-08 09:08:56,117 (trainer:721) INFO: 50epoch:train:1193-1341batch: iter_time=2.388e-04, forward_time=0.163, loss_ctc=3.013, loss=3.013, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.504e-04, train_time=1.934
[ALab02] 2023-06-08 09:10:10,418 (trainer:721) INFO: 50epoch:train:1342-1490batch: iter_time=0.015, forward_time=0.167, loss_ctc=3.074, loss=3.074, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.502e-04, train_time=1.994
[ALab02] 2023-06-08 09:12:11,019 (trainer:721) INFO: 50epoch:train:1491-1639batch: iter_time=0.372, forward_time=0.202, loss_ctc=3.106, loss=3.106, backward_time=0.159, optim_step_time=0.061, optim0_lr0=4.500e-04, train_time=3.243
[ALab02] 2023-06-08 09:13:23,370 (trainer:721) INFO: 50epoch:train:1640-1788batch: iter_time=2.346e-04, forward_time=0.165, loss_ctc=2.951, loss=2.951, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.497e-04, train_time=1.940
[ALab02] 2023-06-08 09:14:35,039 (trainer:721) INFO: 50epoch:train:1789-1937batch: iter_time=2.314e-04, forward_time=0.162, loss_ctc=3.093, loss=3.093, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.495e-04, train_time=1.928
[ALab02] 2023-06-08 09:15:48,057 (trainer:721) INFO: 50epoch:train:1938-2086batch: iter_time=2.749e-04, forward_time=0.167, loss_ctc=2.903, loss=2.903, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.493e-04, train_time=1.961
[ALab02] 2023-06-08 09:17:00,670 (trainer:721) INFO: 50epoch:train:2087-2235batch: iter_time=2.538e-04, forward_time=0.166, loss_ctc=3.041, loss=3.041, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.491e-04, train_time=1.951
[ALab02] 2023-06-08 09:18:14,442 (trainer:721) INFO: 50epoch:train:2236-2384batch: iter_time=2.339e-04, forward_time=0.167, loss_ctc=2.976, loss=2.976, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.488e-04, train_time=1.973
[ALab02] 2023-06-08 09:19:26,736 (trainer:721) INFO: 50epoch:train:2385-2533batch: iter_time=2.358e-04, forward_time=0.163, loss_ctc=3.122, loss=3.122, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.486e-04, train_time=1.946
[ALab02] 2023-06-08 09:20:38,476 (trainer:721) INFO: 50epoch:train:2534-2682batch: iter_time=7.623e-04, forward_time=0.164, loss_ctc=2.917, loss=2.917, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.484e-04, train_time=1.928
[ALab02] 2023-06-08 09:21:50,138 (trainer:721) INFO: 50epoch:train:2683-2831batch: iter_time=4.221e-04, forward_time=0.162, loss_ctc=3.030, loss=3.030, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.482e-04, train_time=1.920
[ALab02] 2023-06-08 09:23:02,386 (trainer:721) INFO: 50epoch:train:2832-2980batch: iter_time=0.002, forward_time=0.162, loss_ctc=2.988, loss=2.988, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.479e-04, train_time=1.935
[ALab02] 2023-06-08 09:23:50,189 (trainer:338) INFO: 50epoch results: [train] iter_time=0.021, forward_time=0.166, loss_ctc=3.007, loss=3.007, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.501e-04, train_time=2.012, time=25 minutes and 6.38 seconds, total_count=149700, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.326, cer_ctc=0.325, cer=0.325, loss=14.326, time=14.39 seconds, total_count=1500, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.7 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 09:23:52,623 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 09:23:52,624 (trainer:272) INFO: 51/70epoch started. Estimated time to finish: 9 hours, 5 minutes and 4.47 seconds
[ALab02] 2023-06-08 09:25:06,743 (trainer:721) INFO: 51epoch:train:1-149batch: iter_time=0.010, forward_time=0.170, loss_ctc=2.811, loss=2.811, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.477e-04, train_time=1.995
[ALab02] 2023-06-08 09:26:19,325 (trainer:721) INFO: 51epoch:train:150-298batch: iter_time=2.458e-04, forward_time=0.166, loss_ctc=2.905, loss=2.905, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.475e-04, train_time=1.949
[ALab02] 2023-06-08 09:27:31,928 (trainer:721) INFO: 51epoch:train:299-447batch: iter_time=2.391e-04, forward_time=0.166, loss_ctc=2.922, loss=2.922, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.472e-04, train_time=1.949
[ALab02] 2023-06-08 09:28:44,264 (trainer:721) INFO: 51epoch:train:448-596batch: iter_time=2.472e-04, forward_time=0.165, loss_ctc=2.994, loss=2.994, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.470e-04, train_time=1.937
[ALab02] 2023-06-08 09:29:55,532 (trainer:721) INFO: 51epoch:train:597-745batch: iter_time=2.402e-04, forward_time=0.162, loss_ctc=2.972, loss=2.972, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.468e-04, train_time=1.918
[ALab02] 2023-06-08 09:31:08,535 (trainer:721) INFO: 51epoch:train:746-894batch: iter_time=0.008, forward_time=0.167, loss_ctc=2.813, loss=2.813, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.466e-04, train_time=1.958
[ALab02] 2023-06-08 09:32:21,585 (trainer:721) INFO: 51epoch:train:895-1043batch: iter_time=2.705e-04, forward_time=0.167, loss_ctc=2.940, loss=2.940, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.464e-04, train_time=1.961
[ALab02] 2023-06-08 09:33:37,231 (trainer:721) INFO: 51epoch:train:1044-1192batch: iter_time=0.039, forward_time=0.174, loss_ctc=2.975, loss=2.975, backward_time=0.155, optim_step_time=0.038, optim0_lr0=4.461e-04, train_time=2.025
[ALab02] 2023-06-08 09:34:50,583 (trainer:721) INFO: 51epoch:train:1193-1341batch: iter_time=2.313e-04, forward_time=0.175, loss_ctc=2.953, loss=2.953, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.459e-04, train_time=1.974
[ALab02] 2023-06-08 09:36:04,549 (trainer:721) INFO: 51epoch:train:1342-1490batch: iter_time=2.148e-04, forward_time=0.175, loss_ctc=2.939, loss=2.939, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.457e-04, train_time=1.986
[ALab02] 2023-06-08 09:37:17,838 (trainer:721) INFO: 51epoch:train:1491-1639batch: iter_time=1.982e-04, forward_time=0.173, loss_ctc=2.921, loss=2.921, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.455e-04, train_time=1.968
[ALab02] 2023-06-08 09:38:31,373 (trainer:721) INFO: 51epoch:train:1640-1788batch: iter_time=2.125e-04, forward_time=0.173, loss_ctc=2.993, loss=2.993, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.453e-04, train_time=1.968
[ALab02] 2023-06-08 09:39:44,503 (trainer:721) INFO: 51epoch:train:1789-1937batch: iter_time=2.248e-04, forward_time=0.172, loss_ctc=3.035, loss=3.035, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.450e-04, train_time=1.967
[ALab02] 2023-06-08 09:40:59,098 (trainer:721) INFO: 51epoch:train:1938-2086batch: iter_time=2.196e-04, forward_time=0.177, loss_ctc=2.893, loss=2.893, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.448e-04, train_time=2.001
[ALab02] 2023-06-08 09:42:13,801 (trainer:721) INFO: 51epoch:train:2087-2235batch: iter_time=0.005, forward_time=0.176, loss_ctc=2.973, loss=2.973, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.446e-04, train_time=2.010
[ALab02] 2023-06-08 09:43:27,801 (trainer:721) INFO: 51epoch:train:2236-2384batch: iter_time=2.557e-04, forward_time=0.173, loss_ctc=2.879, loss=2.879, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.444e-04, train_time=1.979
[ALab02] 2023-06-08 09:44:42,174 (trainer:721) INFO: 51epoch:train:2385-2533batch: iter_time=2.123e-04, forward_time=0.176, loss_ctc=2.994, loss=2.994, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.442e-04, train_time=2.002
[ALab02] 2023-06-08 09:45:56,784 (trainer:721) INFO: 51epoch:train:2534-2682batch: iter_time=2.110e-04, forward_time=0.176, loss_ctc=3.004, loss=3.004, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.440e-04, train_time=2.001
[ALab02] 2023-06-08 09:47:09,354 (trainer:721) INFO: 51epoch:train:2683-2831batch: iter_time=2.127e-04, forward_time=0.171, loss_ctc=2.968, loss=2.968, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.437e-04, train_time=1.946
[ALab02] 2023-06-08 09:48:24,285 (trainer:721) INFO: 51epoch:train:2832-2980batch: iter_time=2.571e-04, forward_time=0.178, loss_ctc=2.940, loss=2.940, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.435e-04, train_time=2.009
[ALab02] 2023-06-08 09:49:14,044 (trainer:338) INFO: 51epoch results: [train] iter_time=0.003, forward_time=0.171, loss_ctc=2.938, loss=2.938, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.456e-04, train_time=1.975, time=24 minutes and 38.74 seconds, total_count=152694, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.367, cer_ctc=0.318, cer=0.318, loss=14.367, time=15.21 seconds, total_count=1530, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.47 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 09:49:16,682 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 09:49:16,683 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/50epoch.pth
[ALab02] 2023-06-08 09:49:16,684 (trainer:272) INFO: 52/70epoch started. Estimated time to finish: 8 hours, 37 minutes and 7.83 seconds
[ALab02] 2023-06-08 09:50:31,591 (trainer:721) INFO: 52epoch:train:1-149batch: iter_time=0.009, forward_time=0.176, loss_ctc=2.921, loss=2.921, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.433e-04, train_time=2.015
[ALab02] 2023-06-08 09:51:45,778 (trainer:721) INFO: 52epoch:train:150-298batch: iter_time=2.581e-04, forward_time=0.174, loss_ctc=2.956, loss=2.956, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.431e-04, train_time=1.992
[ALab02] 2023-06-08 09:53:00,188 (trainer:721) INFO: 52epoch:train:299-447batch: iter_time=0.012, forward_time=0.178, loss_ctc=2.926, loss=2.926, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.429e-04, train_time=1.996
[ALab02] 2023-06-08 09:54:15,229 (trainer:721) INFO: 52epoch:train:448-596batch: iter_time=0.010, forward_time=0.176, loss_ctc=2.883, loss=2.883, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.426e-04, train_time=2.010
[ALab02] 2023-06-08 09:55:30,290 (trainer:721) INFO: 52epoch:train:597-745batch: iter_time=2.252e-04, forward_time=0.178, loss_ctc=2.995, loss=2.995, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.424e-04, train_time=2.020
[ALab02] 2023-06-08 09:56:45,089 (trainer:721) INFO: 52epoch:train:746-894batch: iter_time=8.952e-04, forward_time=0.178, loss_ctc=2.773, loss=2.773, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.422e-04, train_time=2.007
[ALab02] 2023-06-08 09:57:59,253 (trainer:721) INFO: 52epoch:train:895-1043batch: iter_time=4.629e-04, forward_time=0.175, loss_ctc=2.901, loss=2.901, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.420e-04, train_time=1.994
[ALab02] 2023-06-08 09:59:13,500 (trainer:721) INFO: 52epoch:train:1044-1192batch: iter_time=2.251e-04, forward_time=0.176, loss_ctc=2.824, loss=2.824, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.418e-04, train_time=1.986
[ALab02] 2023-06-08 10:00:27,194 (trainer:721) INFO: 52epoch:train:1193-1341batch: iter_time=2.194e-04, forward_time=0.174, loss_ctc=2.910, loss=2.910, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.416e-04, train_time=1.983
[ALab02] 2023-06-08 10:01:40,968 (trainer:721) INFO: 52epoch:train:1342-1490batch: iter_time=2.196e-04, forward_time=0.174, loss_ctc=2.918, loss=2.918, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.414e-04, train_time=1.980
[ALab02] 2023-06-08 10:02:55,375 (trainer:721) INFO: 52epoch:train:1491-1639batch: iter_time=2.340e-04, forward_time=0.177, loss_ctc=2.844, loss=2.844, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.411e-04, train_time=1.998
[ALab02] 2023-06-08 10:04:08,805 (trainer:721) INFO: 52epoch:train:1640-1788batch: iter_time=2.058e-04, forward_time=0.173, loss_ctc=2.841, loss=2.841, backward_time=0.154, optim_step_time=0.032, optim0_lr0=4.409e-04, train_time=1.967
[ALab02] 2023-06-08 10:05:23,049 (trainer:721) INFO: 52epoch:train:1789-1937batch: iter_time=2.059e-04, forward_time=0.177, loss_ctc=2.896, loss=2.896, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.407e-04, train_time=1.997
[ALab02] 2023-06-08 10:06:36,767 (trainer:721) INFO: 52epoch:train:1938-2086batch: iter_time=2.065e-04, forward_time=0.174, loss_ctc=2.829, loss=2.829, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.405e-04, train_time=1.980
[ALab02] 2023-06-08 10:07:48,287 (trainer:721) INFO: 52epoch:train:2087-2235batch: iter_time=2.302e-04, forward_time=0.162, loss_ctc=2.936, loss=2.936, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.403e-04, train_time=1.923
[ALab02] 2023-06-08 10:09:00,432 (trainer:721) INFO: 52epoch:train:2236-2384batch: iter_time=2.342e-04, forward_time=0.163, loss_ctc=2.756, loss=2.756, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.401e-04, train_time=1.929
[ALab02] 2023-06-08 10:10:11,237 (trainer:721) INFO: 52epoch:train:2385-2533batch: iter_time=2.156e-04, forward_time=0.161, loss_ctc=2.898, loss=2.898, backward_time=0.152, optim_step_time=0.033, optim0_lr0=4.399e-04, train_time=1.904
[ALab02] 2023-06-08 10:11:24,226 (trainer:721) INFO: 52epoch:train:2534-2682batch: iter_time=0.014, forward_time=0.162, loss_ctc=3.000, loss=3.000, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.397e-04, train_time=1.959
[ALab02] 2023-06-08 10:12:37,137 (trainer:721) INFO: 52epoch:train:2683-2831batch: iter_time=2.101e-04, forward_time=0.166, loss_ctc=2.798, loss=2.798, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.394e-04, train_time=1.962
[ALab02] 2023-06-08 10:13:49,513 (trainer:721) INFO: 52epoch:train:2832-2980batch: iter_time=0.004, forward_time=0.164, loss_ctc=2.885, loss=2.885, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.392e-04, train_time=1.935
[ALab02] 2023-06-08 10:14:40,625 (trainer:338) INFO: 52epoch results: [train] iter_time=0.003, forward_time=0.172, loss_ctc=2.880, loss=2.880, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.412e-04, train_time=1.977, time=24 minutes and 40.15 seconds, total_count=155688, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.542, cer_ctc=0.312, cer=0.312, loss=14.542, time=17.87 seconds, total_count=1560, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.92 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 10:14:43,183 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 10:14:43,193 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/51epoch.pth
[ALab02] 2023-06-08 10:14:43,193 (trainer:272) INFO: 53/70epoch started. Estimated time to finish: 8 hours, 9 minutes and 17.91 seconds
[ALab02] 2023-06-08 10:15:56,354 (trainer:721) INFO: 53epoch:train:1-149batch: iter_time=0.011, forward_time=0.163, loss_ctc=2.755, loss=2.755, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.390e-04, train_time=1.968
[ALab02] 2023-06-08 10:17:08,957 (trainer:721) INFO: 53epoch:train:150-298batch: iter_time=2.434e-04, forward_time=0.164, loss_ctc=2.829, loss=2.829, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.388e-04, train_time=1.947
[ALab02] 2023-06-08 10:18:20,409 (trainer:721) INFO: 53epoch:train:299-447batch: iter_time=2.470e-04, forward_time=0.162, loss_ctc=2.807, loss=2.807, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.386e-04, train_time=1.923
[ALab02] 2023-06-08 10:19:34,442 (trainer:721) INFO: 53epoch:train:448-596batch: iter_time=2.363e-04, forward_time=0.168, loss_ctc=2.858, loss=2.858, backward_time=0.159, optim_step_time=0.034, optim0_lr0=4.384e-04, train_time=1.980
[ALab02] 2023-06-08 10:20:46,695 (trainer:721) INFO: 53epoch:train:597-745batch: iter_time=2.299e-04, forward_time=0.164, loss_ctc=2.768, loss=2.768, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.382e-04, train_time=1.944
[ALab02] 2023-06-08 10:21:59,285 (trainer:721) INFO: 53epoch:train:746-894batch: iter_time=2.440e-04, forward_time=0.165, loss_ctc=2.944, loss=2.944, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.380e-04, train_time=1.950
[ALab02] 2023-06-08 10:23:10,418 (trainer:721) INFO: 53epoch:train:895-1043batch: iter_time=0.012, forward_time=0.161, loss_ctc=2.772, loss=2.772, backward_time=0.152, optim_step_time=0.034, optim0_lr0=4.377e-04, train_time=1.905
[ALab02] 2023-06-08 10:24:22,981 (trainer:721) INFO: 53epoch:train:1044-1192batch: iter_time=0.003, forward_time=0.164, loss_ctc=2.811, loss=2.811, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.375e-04, train_time=1.946
[ALab02] 2023-06-08 10:25:35,411 (trainer:721) INFO: 53epoch:train:1193-1341batch: iter_time=2.735e-04, forward_time=0.164, loss_ctc=2.918, loss=2.918, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.373e-04, train_time=1.950
[ALab02] 2023-06-08 10:26:47,238 (trainer:721) INFO: 53epoch:train:1342-1490batch: iter_time=2.431e-04, forward_time=0.164, loss_ctc=2.909, loss=2.909, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.371e-04, train_time=1.929
[ALab02] 2023-06-08 10:27:58,618 (trainer:721) INFO: 53epoch:train:1491-1639batch: iter_time=4.359e-04, forward_time=0.162, loss_ctc=2.825, loss=2.825, backward_time=0.152, optim_step_time=0.036, optim0_lr0=4.369e-04, train_time=1.917
[ALab02] 2023-06-08 10:29:12,045 (trainer:721) INFO: 53epoch:train:1640-1788batch: iter_time=0.003, forward_time=0.164, loss_ctc=2.896, loss=2.896, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.367e-04, train_time=1.963
[ALab02] 2023-06-08 10:30:24,996 (trainer:721) INFO: 53epoch:train:1789-1937batch: iter_time=0.016, forward_time=0.164, loss_ctc=2.940, loss=2.940, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.365e-04, train_time=1.964
[ALab02] 2023-06-08 10:31:38,058 (trainer:721) INFO: 53epoch:train:1938-2086batch: iter_time=2.204e-04, forward_time=0.166, loss_ctc=2.940, loss=2.940, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.363e-04, train_time=1.961
[ALab02] 2023-06-08 10:32:49,818 (trainer:721) INFO: 53epoch:train:2087-2235batch: iter_time=2.359e-04, forward_time=0.164, loss_ctc=2.888, loss=2.888, backward_time=0.152, optim_step_time=0.036, optim0_lr0=4.361e-04, train_time=1.928
[ALab02] 2023-06-08 10:34:02,342 (trainer:721) INFO: 53epoch:train:2236-2384batch: iter_time=2.222e-04, forward_time=0.164, loss_ctc=2.894, loss=2.894, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.359e-04, train_time=1.939
[ALab02] 2023-06-08 10:35:15,376 (trainer:721) INFO: 53epoch:train:2385-2533batch: iter_time=0.021, forward_time=0.166, loss_ctc=2.912, loss=2.912, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.357e-04, train_time=1.965
[ALab02] 2023-06-08 10:36:28,670 (trainer:721) INFO: 53epoch:train:2534-2682batch: iter_time=2.290e-04, forward_time=0.168, loss_ctc=2.814, loss=2.814, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.355e-04, train_time=1.967
[ALab02] 2023-06-08 10:37:40,811 (trainer:721) INFO: 53epoch:train:2683-2831batch: iter_time=2.369e-04, forward_time=0.166, loss_ctc=2.796, loss=2.796, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.353e-04, train_time=1.938
[ALab02] 2023-06-08 10:38:54,127 (trainer:721) INFO: 53epoch:train:2832-2980batch: iter_time=2.231e-04, forward_time=0.164, loss_ctc=3.107, loss=3.107, backward_time=0.158, optim_step_time=0.034, optim0_lr0=4.351e-04, train_time=1.963
[ALab02] 2023-06-08 10:39:43,082 (trainer:338) INFO: 53epoch results: [train] iter_time=0.003, forward_time=0.164, loss_ctc=2.865, loss=2.865, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.370e-04, train_time=1.947, time=24 minutes and 17.63 seconds, total_count=158682, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.283, cer_ctc=0.315, cer=0.315, loss=15.283, time=14.59 seconds, total_count=1590, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.66 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 10:39:45,423 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 10:39:45,426 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/52epoch.pth
[ALab02] 2023-06-08 10:39:45,426 (trainer:272) INFO: 54/70epoch started. Estimated time to finish: 7 hours, 41 minutes and 25.61 seconds
[ALab02] 2023-06-08 10:40:58,897 (trainer:721) INFO: 54epoch:train:1-149batch: iter_time=0.014, forward_time=0.165, loss_ctc=2.883, loss=2.883, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.348e-04, train_time=1.975
[ALab02] 2023-06-08 10:42:12,093 (trainer:721) INFO: 54epoch:train:150-298batch: iter_time=2.758e-04, forward_time=0.168, loss_ctc=2.706, loss=2.706, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.346e-04, train_time=1.968
[ALab02] 2023-06-08 10:43:25,328 (trainer:721) INFO: 54epoch:train:299-447batch: iter_time=0.001, forward_time=0.166, loss_ctc=2.835, loss=2.835, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.344e-04, train_time=1.964
[ALab02] 2023-06-08 10:44:38,082 (trainer:721) INFO: 54epoch:train:448-596batch: iter_time=0.006, forward_time=0.168, loss_ctc=2.608, loss=2.608, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.342e-04, train_time=1.948
[ALab02] 2023-06-08 10:45:50,152 (trainer:721) INFO: 54epoch:train:597-745batch: iter_time=2.556e-04, forward_time=0.164, loss_ctc=2.791, loss=2.791, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.340e-04, train_time=1.938
[ALab02] 2023-06-08 10:47:02,433 (trainer:721) INFO: 54epoch:train:746-894batch: iter_time=2.459e-04, forward_time=0.164, loss_ctc=2.865, loss=2.865, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.338e-04, train_time=1.940
[ALab02] 2023-06-08 10:48:17,384 (trainer:721) INFO: 54epoch:train:895-1043batch: iter_time=0.020, forward_time=0.168, loss_ctc=2.723, loss=2.723, backward_time=0.157, optim_step_time=0.037, optim0_lr0=4.336e-04, train_time=2.017
[ALab02] 2023-06-08 10:49:30,051 (trainer:721) INFO: 54epoch:train:1044-1192batch: iter_time=2.554e-04, forward_time=0.164, loss_ctc=2.905, loss=2.905, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.334e-04, train_time=1.943
[ALab02] 2023-06-08 10:50:43,027 (trainer:721) INFO: 54epoch:train:1193-1341batch: iter_time=5.090e-04, forward_time=0.167, loss_ctc=2.763, loss=2.763, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.332e-04, train_time=1.963
[ALab02] 2023-06-08 10:51:54,618 (trainer:721) INFO: 54epoch:train:1342-1490batch: iter_time=2.518e-04, forward_time=0.161, loss_ctc=2.833, loss=2.833, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.330e-04, train_time=1.924
[ALab02] 2023-06-08 10:53:07,415 (trainer:721) INFO: 54epoch:train:1491-1639batch: iter_time=5.978e-04, forward_time=0.166, loss_ctc=2.785, loss=2.785, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.328e-04, train_time=1.953
[ALab02] 2023-06-08 10:54:19,622 (trainer:721) INFO: 54epoch:train:1640-1788batch: iter_time=2.540e-04, forward_time=0.162, loss_ctc=2.831, loss=2.831, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.326e-04, train_time=1.933
[ALab02] 2023-06-08 10:55:31,954 (trainer:721) INFO: 54epoch:train:1789-1937batch: iter_time=2.527e-04, forward_time=0.166, loss_ctc=2.764, loss=2.764, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.324e-04, train_time=1.947
[ALab02] 2023-06-08 10:56:45,253 (trainer:721) INFO: 54epoch:train:1938-2086batch: iter_time=0.018, forward_time=0.168, loss_ctc=2.841, loss=2.841, backward_time=0.153, optim_step_time=0.037, optim0_lr0=4.322e-04, train_time=1.967
[ALab02] 2023-06-08 10:57:59,140 (trainer:721) INFO: 54epoch:train:2087-2235batch: iter_time=2.731e-04, forward_time=0.169, loss_ctc=2.777, loss=2.777, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.320e-04, train_time=1.986
[ALab02] 2023-06-08 10:59:11,777 (trainer:721) INFO: 54epoch:train:2236-2384batch: iter_time=2.376e-04, forward_time=0.165, loss_ctc=2.716, loss=2.716, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.318e-04, train_time=1.943
[ALab02] 2023-06-08 11:00:24,507 (trainer:721) INFO: 54epoch:train:2385-2533batch: iter_time=2.464e-04, forward_time=0.167, loss_ctc=2.825, loss=2.825, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.316e-04, train_time=1.956
[ALab02] 2023-06-08 11:01:36,648 (trainer:721) INFO: 54epoch:train:2534-2682batch: iter_time=0.003, forward_time=0.165, loss_ctc=2.891, loss=2.891, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.314e-04, train_time=1.938
[ALab02] 2023-06-08 11:02:50,106 (trainer:721) INFO: 54epoch:train:2683-2831batch: iter_time=0.002, forward_time=0.166, loss_ctc=2.852, loss=2.852, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.312e-04, train_time=1.970
[ALab02] 2023-06-08 11:04:02,683 (trainer:721) INFO: 54epoch:train:2832-2980batch: iter_time=0.003, forward_time=0.167, loss_ctc=2.778, loss=2.778, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.310e-04, train_time=1.945
[ALab02] 2023-06-08 11:04:51,566 (trainer:338) INFO: 54epoch results: [train] iter_time=0.003, forward_time=0.166, loss_ctc=2.797, loss=2.797, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.329e-04, train_time=1.956, time=24 minutes and 23.99 seconds, total_count=161676, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.726, cer_ctc=0.315, cer=0.315, loss=14.726, time=14.68 seconds, total_count=1620, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.47 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 11:04:54,103 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 11:04:54,121 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/53epoch.pth
[ALab02] 2023-06-08 11:04:54,121 (trainer:272) INFO: 55/70epoch started. Estimated time to finish: 7 hours, 13 minutes and 41.53 seconds
[ALab02] 2023-06-08 11:06:07,240 (trainer:721) INFO: 55epoch:train:1-149batch: iter_time=0.012, forward_time=0.164, loss_ctc=2.730, loss=2.730, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.308e-04, train_time=1.967
[ALab02] 2023-06-08 11:07:20,140 (trainer:721) INFO: 55epoch:train:150-298batch: iter_time=0.008, forward_time=0.167, loss_ctc=2.705, loss=2.705, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.306e-04, train_time=1.960
[ALab02] 2023-06-08 11:08:32,135 (trainer:721) INFO: 55epoch:train:299-447batch: iter_time=9.202e-04, forward_time=0.162, loss_ctc=2.788, loss=2.788, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.304e-04, train_time=1.933
[ALab02] 2023-06-08 11:09:46,745 (trainer:721) INFO: 55epoch:train:448-596batch: iter_time=0.020, forward_time=0.171, loss_ctc=2.700, loss=2.700, backward_time=0.157, optim_step_time=0.036, optim0_lr0=4.302e-04, train_time=1.994
[ALab02] 2023-06-08 11:10:58,701 (trainer:721) INFO: 55epoch:train:597-745batch: iter_time=2.158e-04, forward_time=0.163, loss_ctc=2.817, loss=2.817, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.300e-04, train_time=1.936
[ALab02] 2023-06-08 11:12:11,499 (trainer:721) INFO: 55epoch:train:746-894batch: iter_time=0.002, forward_time=0.165, loss_ctc=2.698, loss=2.698, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.298e-04, train_time=1.955
[ALab02] 2023-06-08 11:13:24,898 (trainer:721) INFO: 55epoch:train:895-1043batch: iter_time=2.168e-04, forward_time=0.167, loss_ctc=2.687, loss=2.687, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.296e-04, train_time=1.971
[ALab02] 2023-06-08 11:14:37,469 (trainer:721) INFO: 55epoch:train:1044-1192batch: iter_time=0.015, forward_time=0.165, loss_ctc=2.678, loss=2.678, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.294e-04, train_time=1.942
[ALab02] 2023-06-08 11:15:50,010 (trainer:721) INFO: 55epoch:train:1193-1341batch: iter_time=0.008, forward_time=0.165, loss_ctc=2.844, loss=2.844, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.292e-04, train_time=1.952
[ALab02] 2023-06-08 11:17:02,991 (trainer:721) INFO: 55epoch:train:1342-1490batch: iter_time=0.004, forward_time=0.166, loss_ctc=2.737, loss=2.737, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.290e-04, train_time=1.959
[ALab02] 2023-06-08 11:18:17,997 (trainer:721) INFO: 55epoch:train:1491-1639batch: iter_time=0.041, forward_time=0.168, loss_ctc=2.790, loss=2.790, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.288e-04, train_time=2.015
[ALab02] 2023-06-08 11:19:31,705 (trainer:721) INFO: 55epoch:train:1640-1788batch: iter_time=0.022, forward_time=0.166, loss_ctc=2.757, loss=2.757, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.286e-04, train_time=1.972
[ALab02] 2023-06-08 11:20:45,339 (trainer:721) INFO: 55epoch:train:1789-1937batch: iter_time=0.017, forward_time=0.168, loss_ctc=2.770, loss=2.770, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.284e-04, train_time=1.981
[ALab02] 2023-06-08 11:21:59,561 (trainer:721) INFO: 55epoch:train:1938-2086batch: iter_time=0.017, forward_time=0.169, loss_ctc=2.825, loss=2.825, backward_time=0.157, optim_step_time=0.036, optim0_lr0=4.282e-04, train_time=1.993
[ALab02] 2023-06-08 11:23:12,539 (trainer:721) INFO: 55epoch:train:2087-2235batch: iter_time=0.003, forward_time=0.165, loss_ctc=2.821, loss=2.821, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.280e-04, train_time=1.958
[ALab02] 2023-06-08 11:24:25,371 (trainer:721) INFO: 55epoch:train:2236-2384batch: iter_time=0.011, forward_time=0.165, loss_ctc=2.812, loss=2.812, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.279e-04, train_time=1.951
[ALab02] 2023-06-08 11:25:38,489 (trainer:721) INFO: 55epoch:train:2385-2533batch: iter_time=0.009, forward_time=0.165, loss_ctc=2.801, loss=2.801, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.277e-04, train_time=1.968
[ALab02] 2023-06-08 11:26:50,465 (trainer:721) INFO: 55epoch:train:2534-2682batch: iter_time=0.008, forward_time=0.164, loss_ctc=2.762, loss=2.762, backward_time=0.152, optim_step_time=0.034, optim0_lr0=4.275e-04, train_time=1.932
[ALab02] 2023-06-08 11:28:04,101 (trainer:721) INFO: 55epoch:train:2683-2831batch: iter_time=0.027, forward_time=0.167, loss_ctc=2.709, loss=2.709, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.273e-04, train_time=1.975
[ALab02] 2023-06-08 11:29:17,109 (trainer:721) INFO: 55epoch:train:2832-2980batch: iter_time=2.554e-04, forward_time=0.163, loss_ctc=2.854, loss=2.854, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.271e-04, train_time=1.956
[ALab02] 2023-06-08 11:30:05,661 (trainer:338) INFO: 55epoch results: [train] iter_time=0.011, forward_time=0.166, loss_ctc=2.763, loss=2.763, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.289e-04, train_time=1.963, time=24 minutes and 29.62 seconds, total_count=164670, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.954, cer_ctc=0.320, cer=0.320, loss=14.954, time=14.76 seconds, total_count=1650, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.16 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 11:30:08,022 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 11:30:08,025 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/54epoch.pth
[ALab02] 2023-06-08 11:30:08,026 (trainer:272) INFO: 56/70epoch started. Estimated time to finish: 6 hours, 46 minutes and 4.52 seconds
[ALab02] 2023-06-08 11:31:22,724 (trainer:721) INFO: 56epoch:train:1-149batch: iter_time=0.016, forward_time=0.171, loss_ctc=2.592, loss=2.592, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.269e-04, train_time=2.009
[ALab02] 2023-06-08 11:32:34,937 (trainer:721) INFO: 56epoch:train:150-298batch: iter_time=2.386e-04, forward_time=0.165, loss_ctc=2.692, loss=2.692, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.267e-04, train_time=1.943
[ALab02] 2023-06-08 11:33:46,278 (trainer:721) INFO: 56epoch:train:299-447batch: iter_time=2.443e-04, forward_time=0.162, loss_ctc=2.742, loss=2.742, backward_time=0.152, optim_step_time=0.032, optim0_lr0=4.265e-04, train_time=1.912
[ALab02] 2023-06-08 11:34:57,810 (trainer:721) INFO: 56epoch:train:448-596batch: iter_time=5.964e-04, forward_time=0.162, loss_ctc=2.749, loss=2.749, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.263e-04, train_time=1.916
[ALab02] 2023-06-08 11:36:10,589 (trainer:721) INFO: 56epoch:train:597-745batch: iter_time=5.698e-04, forward_time=0.165, loss_ctc=2.632, loss=2.632, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.261e-04, train_time=1.957
[ALab02] 2023-06-08 11:37:23,344 (trainer:721) INFO: 56epoch:train:746-894batch: iter_time=2.246e-04, forward_time=0.166, loss_ctc=2.683, loss=2.683, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.259e-04, train_time=1.951
[ALab02] 2023-06-08 11:38:36,166 (trainer:721) INFO: 56epoch:train:895-1043batch: iter_time=0.014, forward_time=0.165, loss_ctc=2.685, loss=2.685, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.257e-04, train_time=1.959
[ALab02] 2023-06-08 11:39:48,835 (trainer:721) INFO: 56epoch:train:1044-1192batch: iter_time=2.210e-04, forward_time=0.164, loss_ctc=2.668, loss=2.668, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.255e-04, train_time=1.945
[ALab02] 2023-06-08 11:41:01,687 (trainer:721) INFO: 56epoch:train:1193-1341batch: iter_time=2.283e-04, forward_time=0.164, loss_ctc=2.765, loss=2.765, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.253e-04, train_time=1.959
[ALab02] 2023-06-08 11:42:14,994 (trainer:721) INFO: 56epoch:train:1342-1490batch: iter_time=2.237e-04, forward_time=0.166, loss_ctc=2.702, loss=2.702, backward_time=0.158, optim_step_time=0.033, optim0_lr0=4.251e-04, train_time=1.968
[ALab02] 2023-06-08 11:43:27,126 (trainer:721) INFO: 56epoch:train:1491-1639batch: iter_time=2.204e-04, forward_time=0.164, loss_ctc=2.707, loss=2.707, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.250e-04, train_time=1.937
[ALab02] 2023-06-08 11:44:39,634 (trainer:721) INFO: 56epoch:train:1640-1788batch: iter_time=1.939e-04, forward_time=0.162, loss_ctc=2.746, loss=2.746, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.248e-04, train_time=1.942
[ALab02] 2023-06-08 11:45:52,521 (trainer:721) INFO: 56epoch:train:1789-1937batch: iter_time=0.012, forward_time=0.163, loss_ctc=2.798, loss=2.798, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.246e-04, train_time=1.961
[ALab02] 2023-06-08 11:47:04,213 (trainer:721) INFO: 56epoch:train:1938-2086batch: iter_time=0.001, forward_time=0.163, loss_ctc=2.659, loss=2.659, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.244e-04, train_time=1.924
[ALab02] 2023-06-08 11:48:16,668 (trainer:721) INFO: 56epoch:train:2087-2235batch: iter_time=1.902e-04, forward_time=0.164, loss_ctc=2.647, loss=2.647, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.242e-04, train_time=1.946
[ALab02] 2023-06-08 11:49:28,781 (trainer:721) INFO: 56epoch:train:2236-2384batch: iter_time=2.151e-04, forward_time=0.162, loss_ctc=2.753, loss=2.753, backward_time=0.155, optim_step_time=0.032, optim0_lr0=4.240e-04, train_time=1.930
[ALab02] 2023-06-08 11:50:41,310 (trainer:721) INFO: 56epoch:train:2385-2533batch: iter_time=2.336e-04, forward_time=0.163, loss_ctc=2.699, loss=2.699, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.238e-04, train_time=1.951
[ALab02] 2023-06-08 11:51:53,997 (trainer:721) INFO: 56epoch:train:2534-2682batch: iter_time=2.181e-04, forward_time=0.165, loss_ctc=2.640, loss=2.640, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.236e-04, train_time=1.953
[ALab02] 2023-06-08 11:53:07,159 (trainer:721) INFO: 56epoch:train:2683-2831batch: iter_time=2.217e-04, forward_time=0.165, loss_ctc=2.782, loss=2.782, backward_time=0.158, optim_step_time=0.032, optim0_lr0=4.234e-04, train_time=1.965
[ALab02] 2023-06-08 11:54:18,812 (trainer:721) INFO: 56epoch:train:2832-2980batch: iter_time=0.004, forward_time=0.162, loss_ctc=2.541, loss=2.541, backward_time=0.153, optim_step_time=0.035, optim0_lr0=4.232e-04, train_time=1.916
[ALab02] 2023-06-08 11:55:06,027 (trainer:338) INFO: 56epoch results: [train] iter_time=0.003, forward_time=0.164, loss_ctc=2.692, loss=2.692, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.250e-04, train_time=1.948, time=24 minutes and 18.05 seconds, total_count=167664, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.304, cer_ctc=0.319, cer=0.319, loss=15.304, time=14.12 seconds, total_count=1680, gpu_max_cached_mem_GB=52.041, [att_plot] time=25.82 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 11:55:08,445 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 11:55:08,448 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/55epoch.pth
[ALab02] 2023-06-08 11:55:08,448 (trainer:272) INFO: 57/70epoch started. Estimated time to finish: 6 hours, 18 minutes and 29.25 seconds
[ALab02] 2023-06-08 11:56:21,272 (trainer:721) INFO: 57epoch:train:1-149batch: iter_time=0.008, forward_time=0.163, loss_ctc=2.667, loss=2.667, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.230e-04, train_time=1.958
[ALab02] 2023-06-08 11:57:33,610 (trainer:721) INFO: 57epoch:train:150-298batch: iter_time=1.851e-04, forward_time=0.165, loss_ctc=2.530, loss=2.530, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.229e-04, train_time=1.942
[ALab02] 2023-06-08 11:58:47,502 (trainer:721) INFO: 57epoch:train:299-447batch: iter_time=0.018, forward_time=0.164, loss_ctc=2.723, loss=2.723, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.227e-04, train_time=1.969
[ALab02] 2023-06-08 12:00:00,524 (trainer:721) INFO: 57epoch:train:448-596batch: iter_time=0.006, forward_time=0.164, loss_ctc=2.654, loss=2.654, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.225e-04, train_time=1.970
[ALab02] 2023-06-08 12:01:13,000 (trainer:721) INFO: 57epoch:train:597-745batch: iter_time=2.533e-04, forward_time=0.164, loss_ctc=2.608, loss=2.608, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.223e-04, train_time=1.949
[ALab02] 2023-06-08 12:02:25,633 (trainer:721) INFO: 57epoch:train:746-894batch: iter_time=2.305e-04, forward_time=0.165, loss_ctc=2.742, loss=2.742, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.221e-04, train_time=1.947
[ALab02] 2023-06-08 12:03:38,017 (trainer:721) INFO: 57epoch:train:895-1043batch: iter_time=2.343e-04, forward_time=0.164, loss_ctc=2.623, loss=2.623, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.219e-04, train_time=1.948
[ALab02] 2023-06-08 12:04:51,537 (trainer:721) INFO: 57epoch:train:1044-1192batch: iter_time=0.012, forward_time=0.167, loss_ctc=2.646, loss=2.646, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.217e-04, train_time=1.967
[ALab02] 2023-06-08 12:06:04,287 (trainer:721) INFO: 57epoch:train:1193-1341batch: iter_time=2.474e-04, forward_time=0.163, loss_ctc=2.714, loss=2.714, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.215e-04, train_time=1.957
[ALab02] 2023-06-08 12:07:15,830 (trainer:721) INFO: 57epoch:train:1342-1490batch: iter_time=2.261e-04, forward_time=0.162, loss_ctc=2.682, loss=2.682, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.214e-04, train_time=1.920
[ALab02] 2023-06-08 12:08:28,689 (trainer:721) INFO: 57epoch:train:1491-1639batch: iter_time=2.229e-04, forward_time=0.164, loss_ctc=2.730, loss=2.730, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.212e-04, train_time=1.955
[ALab02] 2023-06-08 12:09:41,497 (trainer:721) INFO: 57epoch:train:1640-1788batch: iter_time=7.528e-04, forward_time=0.165, loss_ctc=2.638, loss=2.638, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.210e-04, train_time=1.951
[ALab02] 2023-06-08 12:10:54,388 (trainer:721) INFO: 57epoch:train:1789-1937batch: iter_time=2.266e-04, forward_time=0.164, loss_ctc=2.757, loss=2.757, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.208e-04, train_time=1.961
[ALab02] 2023-06-08 12:12:06,866 (trainer:721) INFO: 57epoch:train:1938-2086batch: iter_time=4.065e-04, forward_time=0.165, loss_ctc=2.624, loss=2.624, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.206e-04, train_time=1.945
[ALab02] 2023-06-08 12:13:38,386 (trainer:721) INFO: 57epoch:train:2087-2235batch: iter_time=0.150, forward_time=0.180, loss_ctc=2.634, loss=2.634, backward_time=0.157, optim_step_time=0.044, optim0_lr0=4.204e-04, train_time=2.420
[ALab02] 2023-06-08 12:14:56,631 (trainer:721) INFO: 57epoch:train:2236-2384batch: iter_time=0.046, forward_time=0.170, loss_ctc=2.591, loss=2.591, backward_time=0.156, optim_step_time=0.037, optim0_lr0=4.202e-04, train_time=2.132
[ALab02] 2023-06-08 12:16:09,037 (trainer:721) INFO: 57epoch:train:2385-2533batch: iter_time=2.281e-04, forward_time=0.165, loss_ctc=2.586, loss=2.586, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.201e-04, train_time=1.948
[ALab02] 2023-06-08 12:17:21,342 (trainer:721) INFO: 57epoch:train:2534-2682batch: iter_time=2.426e-04, forward_time=0.165, loss_ctc=2.613, loss=2.613, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.199e-04, train_time=1.940
[ALab02] 2023-06-08 12:18:33,610 (trainer:721) INFO: 57epoch:train:2683-2831batch: iter_time=2.094e-04, forward_time=0.163, loss_ctc=2.649, loss=2.649, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.197e-04, train_time=1.939
[ALab02] 2023-06-08 12:19:45,815 (trainer:721) INFO: 57epoch:train:2832-2980batch: iter_time=0.018, forward_time=0.162, loss_ctc=2.639, loss=2.639, backward_time=0.152, optim_step_time=0.035, optim0_lr0=4.195e-04, train_time=1.936
[ALab02] 2023-06-08 12:20:33,281 (trainer:338) INFO: 57epoch results: [train] iter_time=0.013, forward_time=0.165, loss_ctc=2.650, loss=2.650, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.213e-04, train_time=1.983, time=24 minutes and 44.14 seconds, total_count=170658, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.680, cer_ctc=0.315, cer=0.315, loss=14.680, time=14.16 seconds, total_count=1710, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.53 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 12:20:35,563 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 12:20:35,567 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/56epoch.pth
[ALab02] 2023-06-08 12:20:35,567 (trainer:272) INFO: 58/70epoch started. Estimated time to finish: 5 hours, 51 minutes and 5.5 seconds
[ALab02] 2023-06-08 12:21:48,617 (trainer:721) INFO: 58epoch:train:1-149batch: iter_time=0.007, forward_time=0.165, loss_ctc=2.614, loss=2.614, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.193e-04, train_time=1.964
[ALab02] 2023-06-08 12:23:02,186 (trainer:721) INFO: 58epoch:train:150-298batch: iter_time=0.017, forward_time=0.163, loss_ctc=2.636, loss=2.636, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.191e-04, train_time=1.979
[ALab02] 2023-06-08 12:24:14,135 (trainer:721) INFO: 58epoch:train:299-447batch: iter_time=2.263e-04, forward_time=0.163, loss_ctc=2.646, loss=2.646, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.190e-04, train_time=1.928
[ALab02] 2023-06-08 12:25:27,592 (trainer:721) INFO: 58epoch:train:448-596batch: iter_time=2.130e-04, forward_time=0.167, loss_ctc=2.560, loss=2.560, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.188e-04, train_time=1.967
[ALab02] 2023-06-08 12:26:55,346 (trainer:721) INFO: 58epoch:train:597-745batch: iter_time=0.118, forward_time=0.175, loss_ctc=2.555, loss=2.555, backward_time=0.159, optim_step_time=0.048, optim0_lr0=4.186e-04, train_time=2.363
[ALab02] 2023-06-08 12:28:43,462 (trainer:721) INFO: 58epoch:train:746-894batch: iter_time=0.308, forward_time=0.183, loss_ctc=2.646, loss=2.646, backward_time=0.158, optim_step_time=0.057, optim0_lr0=4.184e-04, train_time=2.908
[ALab02] 2023-06-08 12:29:56,418 (trainer:721) INFO: 58epoch:train:895-1043batch: iter_time=2.232e-04, forward_time=0.167, loss_ctc=2.602, loss=2.602, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.182e-04, train_time=1.961
[ALab02] 2023-06-08 12:31:09,365 (trainer:721) INFO: 58epoch:train:1044-1192batch: iter_time=2.593e-04, forward_time=0.164, loss_ctc=2.625, loss=2.625, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.180e-04, train_time=1.951
[ALab02] 2023-06-08 12:32:20,773 (trainer:721) INFO: 58epoch:train:1193-1341batch: iter_time=0.003, forward_time=0.162, loss_ctc=2.648, loss=2.648, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.179e-04, train_time=1.921
[ALab02] 2023-06-08 12:33:33,160 (trainer:721) INFO: 58epoch:train:1342-1490batch: iter_time=0.007, forward_time=0.164, loss_ctc=2.560, loss=2.560, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.177e-04, train_time=1.944
[ALab02] 2023-06-08 12:34:45,772 (trainer:721) INFO: 58epoch:train:1491-1639batch: iter_time=2.122e-04, forward_time=0.167, loss_ctc=2.457, loss=2.457, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.175e-04, train_time=1.948
[ALab02] 2023-06-08 12:35:57,989 (trainer:721) INFO: 58epoch:train:1640-1788batch: iter_time=2.100e-04, forward_time=0.162, loss_ctc=2.610, loss=2.610, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.173e-04, train_time=1.935
[ALab02] 2023-06-08 12:37:10,004 (trainer:721) INFO: 58epoch:train:1789-1937batch: iter_time=2.227e-04, forward_time=0.164, loss_ctc=2.520, loss=2.520, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.171e-04, train_time=1.937
[ALab02] 2023-06-08 12:38:21,829 (trainer:721) INFO: 58epoch:train:1938-2086batch: iter_time=0.003, forward_time=0.163, loss_ctc=2.629, loss=2.629, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.170e-04, train_time=1.926
[ALab02] 2023-06-08 12:39:34,274 (trainer:721) INFO: 58epoch:train:2087-2235batch: iter_time=2.156e-04, forward_time=0.164, loss_ctc=2.619, loss=2.619, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.168e-04, train_time=1.945
[ALab02] 2023-06-08 12:40:47,741 (trainer:721) INFO: 58epoch:train:2236-2384batch: iter_time=2.365e-04, forward_time=0.168, loss_ctc=2.621, loss=2.621, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.166e-04, train_time=1.968
[ALab02] 2023-06-08 12:42:02,744 (trainer:721) INFO: 58epoch:train:2385-2533batch: iter_time=0.031, forward_time=0.170, loss_ctc=2.729, loss=2.729, backward_time=0.156, optim_step_time=0.041, optim0_lr0=4.164e-04, train_time=2.018
[ALab02] 2023-06-08 12:43:15,572 (trainer:721) INFO: 58epoch:train:2534-2682batch: iter_time=2.547e-04, forward_time=0.166, loss_ctc=2.712, loss=2.712, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.162e-04, train_time=1.953
[ALab02] 2023-06-08 12:44:31,100 (trainer:721) INFO: 58epoch:train:2683-2831batch: iter_time=0.034, forward_time=0.168, loss_ctc=2.650, loss=2.650, backward_time=0.156, optim_step_time=0.037, optim0_lr0=4.161e-04, train_time=2.031
[ALab02] 2023-06-08 12:45:43,475 (trainer:721) INFO: 58epoch:train:2832-2980batch: iter_time=2.555e-04, forward_time=0.165, loss_ctc=2.646, loss=2.646, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.159e-04, train_time=1.938
[ALab02] 2023-06-08 12:46:33,605 (trainer:338) INFO: 58epoch results: [train] iter_time=0.026, forward_time=0.167, loss_ctc=2.611, loss=2.611, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.176e-04, train_time=2.023, time=25 minutes and 14.72 seconds, total_count=173652, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=14.341, cer_ctc=0.320, cer=0.320, loss=14.341, time=14.7 seconds, total_count=1740, gpu_max_cached_mem_GB=52.041, [att_plot] time=28.62 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 12:46:35,996 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 12:46:36,002 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/57epoch.pth
[ALab02] 2023-06-08 12:46:36,002 (trainer:272) INFO: 59/70epoch started. Estimated time to finish: 5 hours, 23 minutes and 52.67 seconds
[ALab02] 2023-06-08 12:47:49,241 (trainer:721) INFO: 59epoch:train:1-149batch: iter_time=0.009, forward_time=0.165, loss_ctc=2.544, loss=2.544, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.157e-04, train_time=1.969
[ALab02] 2023-06-08 12:49:02,471 (trainer:721) INFO: 59epoch:train:150-298batch: iter_time=2.605e-04, forward_time=0.167, loss_ctc=2.455, loss=2.455, backward_time=0.156, optim_step_time=0.037, optim0_lr0=4.155e-04, train_time=1.967
[ALab02] 2023-06-08 12:50:15,979 (trainer:721) INFO: 59epoch:train:299-447batch: iter_time=2.900e-04, forward_time=0.169, loss_ctc=2.546, loss=2.546, backward_time=0.157, optim_step_time=0.036, optim0_lr0=4.153e-04, train_time=1.970
[ALab02] 2023-06-08 12:51:28,431 (trainer:721) INFO: 59epoch:train:448-596batch: iter_time=0.001, forward_time=0.164, loss_ctc=2.657, loss=2.657, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.152e-04, train_time=1.944
[ALab02] 2023-06-08 12:52:41,048 (trainer:721) INFO: 59epoch:train:597-745batch: iter_time=0.006, forward_time=0.166, loss_ctc=2.477, loss=2.477, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.150e-04, train_time=1.953
[ALab02] 2023-06-08 12:53:54,608 (trainer:721) INFO: 59epoch:train:746-894batch: iter_time=2.647e-04, forward_time=0.167, loss_ctc=2.552, loss=2.552, backward_time=0.158, optim_step_time=0.035, optim0_lr0=4.148e-04, train_time=1.976
[ALab02] 2023-06-08 12:55:07,222 (trainer:721) INFO: 59epoch:train:895-1043batch: iter_time=3.152e-04, forward_time=0.166, loss_ctc=2.554, loss=2.554, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.146e-04, train_time=1.952
[ALab02] 2023-06-08 12:56:20,284 (trainer:721) INFO: 59epoch:train:1044-1192batch: iter_time=2.991e-04, forward_time=0.167, loss_ctc=2.592, loss=2.592, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.144e-04, train_time=1.953
[ALab02] 2023-06-08 12:57:33,645 (trainer:721) INFO: 59epoch:train:1193-1341batch: iter_time=2.668e-04, forward_time=0.167, loss_ctc=2.513, loss=2.513, backward_time=0.158, optim_step_time=0.037, optim0_lr0=4.143e-04, train_time=1.974
[ALab02] 2023-06-08 12:58:45,776 (trainer:721) INFO: 59epoch:train:1342-1490batch: iter_time=2.636e-04, forward_time=0.164, loss_ctc=2.659, loss=2.659, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.141e-04, train_time=1.934
[ALab02] 2023-06-08 12:59:58,077 (trainer:721) INFO: 59epoch:train:1491-1639batch: iter_time=2.858e-04, forward_time=0.166, loss_ctc=2.655, loss=2.655, backward_time=0.154, optim_step_time=0.037, optim0_lr0=4.139e-04, train_time=1.941
[ALab02] 2023-06-08 13:01:10,438 (trainer:721) INFO: 59epoch:train:1640-1788batch: iter_time=2.570e-04, forward_time=0.166, loss_ctc=2.506, loss=2.506, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.137e-04, train_time=1.940
[ALab02] 2023-06-08 13:02:24,808 (trainer:721) INFO: 59epoch:train:1789-1937batch: iter_time=0.031, forward_time=0.165, loss_ctc=2.631, loss=2.631, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.136e-04, train_time=1.996
[ALab02] 2023-06-08 13:03:37,901 (trainer:721) INFO: 59epoch:train:1938-2086batch: iter_time=0.013, forward_time=0.167, loss_ctc=2.453, loss=2.453, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.134e-04, train_time=1.970
[ALab02] 2023-06-08 13:04:50,597 (trainer:721) INFO: 59epoch:train:2087-2235batch: iter_time=2.238e-04, forward_time=0.165, loss_ctc=2.564, loss=2.564, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.132e-04, train_time=1.952
[ALab02] 2023-06-08 13:06:03,583 (trainer:721) INFO: 59epoch:train:2236-2384batch: iter_time=2.362e-04, forward_time=0.166, loss_ctc=2.540, loss=2.540, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.130e-04, train_time=1.951
[ALab02] 2023-06-08 13:07:16,022 (trainer:721) INFO: 59epoch:train:2385-2533batch: iter_time=2.505e-04, forward_time=0.165, loss_ctc=2.521, loss=2.521, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.129e-04, train_time=1.950
[ALab02] 2023-06-08 13:08:27,875 (trainer:721) INFO: 59epoch:train:2534-2682batch: iter_time=5.210e-04, forward_time=0.163, loss_ctc=2.565, loss=2.565, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.127e-04, train_time=1.930
[ALab02] 2023-06-08 13:09:40,643 (trainer:721) INFO: 59epoch:train:2683-2831batch: iter_time=3.713e-04, forward_time=0.166, loss_ctc=2.558, loss=2.558, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.125e-04, train_time=1.951
[ALab02] 2023-06-08 13:10:53,893 (trainer:721) INFO: 59epoch:train:2832-2980batch: iter_time=2.196e-04, forward_time=0.166, loss_ctc=2.562, loss=2.562, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.123e-04, train_time=1.962
[ALab02] 2023-06-08 13:11:42,518 (trainer:338) INFO: 59epoch results: [train] iter_time=0.003, forward_time=0.166, loss_ctc=2.554, loss=2.554, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.140e-04, train_time=1.957, time=24 minutes and 24.8 seconds, total_count=176646, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.284, cer_ctc=0.310, cer=0.310, loss=15.284, time=14.58 seconds, total_count=1770, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.13 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 13:11:44,905 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 13:11:44,909 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/33epoch.pth, exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/58epoch.pth
[ALab02] 2023-06-08 13:11:44,909 (trainer:272) INFO: 60/70epoch started. Estimated time to finish: 4 hours, 56 minutes and 32.68 seconds
[ALab02] 2023-06-08 13:12:58,204 (trainer:721) INFO: 60epoch:train:1-149batch: iter_time=0.011, forward_time=0.167, loss_ctc=2.477, loss=2.477, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.122e-04, train_time=1.972
[ALab02] 2023-06-08 13:14:10,032 (trainer:721) INFO: 60epoch:train:150-298batch: iter_time=2.980e-04, forward_time=0.163, loss_ctc=2.487, loss=2.487, backward_time=0.153, optim_step_time=0.036, optim0_lr0=4.120e-04, train_time=1.928
[ALab02] 2023-06-08 13:15:23,078 (trainer:721) INFO: 60epoch:train:299-447batch: iter_time=2.220e-04, forward_time=0.165, loss_ctc=2.606, loss=2.606, backward_time=0.157, optim_step_time=0.035, optim0_lr0=4.118e-04, train_time=1.962
[ALab02] 2023-06-08 13:16:36,668 (trainer:721) INFO: 60epoch:train:448-596batch: iter_time=7.962e-04, forward_time=0.166, loss_ctc=2.570, loss=2.570, backward_time=0.158, optim_step_time=0.036, optim0_lr0=4.116e-04, train_time=1.969
[ALab02] 2023-06-08 13:17:49,393 (trainer:721) INFO: 60epoch:train:597-745batch: iter_time=2.341e-04, forward_time=0.165, loss_ctc=2.544, loss=2.544, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.115e-04, train_time=1.956
[ALab02] 2023-06-08 13:19:01,742 (trainer:721) INFO: 60epoch:train:746-894batch: iter_time=2.664e-04, forward_time=0.164, loss_ctc=2.572, loss=2.572, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.113e-04, train_time=1.943
[ALab02] 2023-06-08 13:20:14,285 (trainer:721) INFO: 60epoch:train:895-1043batch: iter_time=0.002, forward_time=0.167, loss_ctc=2.460, loss=2.460, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.111e-04, train_time=1.947
[ALab02] 2023-06-08 13:21:28,939 (trainer:721) INFO: 60epoch:train:1044-1192batch: iter_time=0.027, forward_time=0.166, loss_ctc=2.494, loss=2.494, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.109e-04, train_time=1.998
[ALab02] 2023-06-08 13:22:42,114 (trainer:721) INFO: 60epoch:train:1193-1341batch: iter_time=2.160e-04, forward_time=0.168, loss_ctc=2.539, loss=2.539, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.108e-04, train_time=1.969
[ALab02] 2023-06-08 13:23:56,977 (trainer:721) INFO: 60epoch:train:1342-1490batch: iter_time=0.027, forward_time=0.168, loss_ctc=2.617, loss=2.617, backward_time=0.156, optim_step_time=0.037, optim0_lr0=4.106e-04, train_time=2.010
[ALab02] 2023-06-08 13:25:09,256 (trainer:721) INFO: 60epoch:train:1491-1639batch: iter_time=0.006, forward_time=0.165, loss_ctc=2.523, loss=2.523, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.104e-04, train_time=1.944
[ALab02] 2023-06-08 13:26:22,037 (trainer:721) INFO: 60epoch:train:1640-1788batch: iter_time=6.851e-04, forward_time=0.165, loss_ctc=2.520, loss=2.520, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.103e-04, train_time=1.946
[ALab02] 2023-06-08 13:27:34,784 (trainer:721) INFO: 60epoch:train:1789-1937batch: iter_time=5.574e-04, forward_time=0.168, loss_ctc=2.539, loss=2.539, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.101e-04, train_time=1.956
[ALab02] 2023-06-08 13:28:47,016 (trainer:721) INFO: 60epoch:train:1938-2086batch: iter_time=2.456e-04, forward_time=0.163, loss_ctc=2.564, loss=2.564, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.099e-04, train_time=1.938
[ALab02] 2023-06-08 13:29:59,084 (trainer:721) INFO: 60epoch:train:2087-2235batch: iter_time=2.625e-04, forward_time=0.164, loss_ctc=2.491, loss=2.491, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.097e-04, train_time=1.933
[ALab02] 2023-06-08 13:31:11,388 (trainer:721) INFO: 60epoch:train:2236-2384batch: iter_time=0.002, forward_time=0.164, loss_ctc=2.596, loss=2.596, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.096e-04, train_time=1.939
[ALab02] 2023-06-08 13:32:23,961 (trainer:721) INFO: 60epoch:train:2385-2533batch: iter_time=2.502e-04, forward_time=0.163, loss_ctc=2.554, loss=2.554, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.094e-04, train_time=1.953
[ALab02] 2023-06-08 13:33:36,113 (trainer:721) INFO: 60epoch:train:2534-2682batch: iter_time=2.297e-04, forward_time=0.163, loss_ctc=2.574, loss=2.574, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.092e-04, train_time=1.936
[ALab02] 2023-06-08 13:34:49,749 (trainer:721) INFO: 60epoch:train:2683-2831batch: iter_time=6.850e-04, forward_time=0.168, loss_ctc=2.543, loss=2.543, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.091e-04, train_time=1.980
[ALab02] 2023-06-08 13:36:03,022 (trainer:721) INFO: 60epoch:train:2832-2980batch: iter_time=2.784e-04, forward_time=0.167, loss_ctc=2.545, loss=2.545, backward_time=0.156, optim_step_time=0.035, optim0_lr0=4.089e-04, train_time=1.959
[ALab02] 2023-06-08 13:36:52,257 (trainer:338) INFO: 60epoch results: [train] iter_time=0.004, forward_time=0.165, loss_ctc=2.540, loss=2.540, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.105e-04, train_time=1.957, time=24 minutes and 24.78 seconds, total_count=179640, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.298, cer_ctc=0.333, cer=0.333, loss=15.298, time=14.61 seconds, total_count=1800, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.96 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 13:36:54,944 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 13:36:54,945 (trainer:272) INFO: 61/70epoch started. Estimated time to finish: 4 hours, 29 minutes and 17.25 seconds
[ALab02] 2023-06-08 13:38:08,111 (trainer:721) INFO: 61epoch:train:1-149batch: iter_time=0.013, forward_time=0.166, loss_ctc=2.451, loss=2.451, backward_time=0.154, optim_step_time=0.036, optim0_lr0=4.087e-04, train_time=1.969
[ALab02] 2023-06-08 13:39:20,726 (trainer:721) INFO: 61epoch:train:150-298batch: iter_time=0.018, forward_time=0.163, loss_ctc=2.541, loss=2.541, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.085e-04, train_time=1.950
[ALab02] 2023-06-08 13:40:33,577 (trainer:721) INFO: 61epoch:train:299-447batch: iter_time=2.353e-04, forward_time=0.165, loss_ctc=2.481, loss=2.481, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.084e-04, train_time=1.952
[ALab02] 2023-06-08 13:41:46,181 (trainer:721) INFO: 61epoch:train:448-596batch: iter_time=0.002, forward_time=0.165, loss_ctc=2.480, loss=2.480, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.082e-04, train_time=1.947
[ALab02] 2023-06-08 13:42:58,649 (trainer:721) INFO: 61epoch:train:597-745batch: iter_time=2.143e-04, forward_time=0.163, loss_ctc=2.570, loss=2.570, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.080e-04, train_time=1.951
[ALab02] 2023-06-08 13:44:11,506 (trainer:721) INFO: 61epoch:train:746-894batch: iter_time=0.017, forward_time=0.163, loss_ctc=2.545, loss=2.545, backward_time=0.155, optim_step_time=0.036, optim0_lr0=4.079e-04, train_time=1.953
[ALab02] 2023-06-08 13:45:22,744 (trainer:721) INFO: 61epoch:train:895-1043batch: iter_time=2.114e-04, forward_time=0.160, loss_ctc=2.564, loss=2.564, backward_time=0.153, optim_step_time=0.034, optim0_lr0=4.077e-04, train_time=1.916
[ALab02] 2023-06-08 13:46:36,224 (trainer:721) INFO: 61epoch:train:1044-1192batch: iter_time=2.147e-04, forward_time=0.165, loss_ctc=2.597, loss=2.597, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.075e-04, train_time=1.965
[ALab02] 2023-06-08 13:47:47,671 (trainer:721) INFO: 61epoch:train:1193-1341batch: iter_time=0.001, forward_time=0.162, loss_ctc=2.497, loss=2.497, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.074e-04, train_time=1.922
[ALab02] 2023-06-08 13:49:00,029 (trainer:721) INFO: 61epoch:train:1342-1490batch: iter_time=2.133e-04, forward_time=0.164, loss_ctc=2.533, loss=2.533, backward_time=0.156, optim_step_time=0.034, optim0_lr0=4.072e-04, train_time=1.943
[ALab02] 2023-06-08 13:50:12,855 (trainer:721) INFO: 61epoch:train:1491-1639batch: iter_time=2.088e-04, forward_time=0.165, loss_ctc=2.515, loss=2.515, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.070e-04, train_time=1.954
[ALab02] 2023-06-08 13:51:24,833 (trainer:721) INFO: 61epoch:train:1640-1788batch: iter_time=1.963e-04, forward_time=0.161, loss_ctc=2.561, loss=2.561, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.069e-04, train_time=1.928
[ALab02] 2023-06-08 13:52:38,372 (trainer:721) INFO: 61epoch:train:1789-1937batch: iter_time=1.790e-04, forward_time=0.166, loss_ctc=2.475, loss=2.475, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.067e-04, train_time=1.979
[ALab02] 2023-06-08 13:53:50,285 (trainer:721) INFO: 61epoch:train:1938-2086batch: iter_time=2.530e-04, forward_time=0.164, loss_ctc=2.446, loss=2.446, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.065e-04, train_time=1.931
[ALab02] 2023-06-08 13:55:01,927 (trainer:721) INFO: 61epoch:train:2087-2235batch: iter_time=1.906e-04, forward_time=0.163, loss_ctc=2.423, loss=2.423, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.064e-04, train_time=1.925
[ALab02] 2023-06-08 13:56:13,818 (trainer:721) INFO: 61epoch:train:2236-2384batch: iter_time=2.039e-04, forward_time=0.161, loss_ctc=2.547, loss=2.547, backward_time=0.154, optim_step_time=0.032, optim0_lr0=4.062e-04, train_time=1.922
[ALab02] 2023-06-08 13:57:26,409 (trainer:721) INFO: 61epoch:train:2385-2533batch: iter_time=0.014, forward_time=0.162, loss_ctc=2.560, loss=2.560, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.060e-04, train_time=1.952
[ALab02] 2023-06-08 13:58:39,153 (trainer:721) INFO: 61epoch:train:2534-2682batch: iter_time=2.340e-04, forward_time=0.163, loss_ctc=2.524, loss=2.524, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.059e-04, train_time=1.952
[ALab02] 2023-06-08 13:59:52,026 (trainer:721) INFO: 61epoch:train:2683-2831batch: iter_time=2.168e-04, forward_time=0.165, loss_ctc=2.558, loss=2.558, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.057e-04, train_time=1.958
[ALab02] 2023-06-08 14:01:04,811 (trainer:721) INFO: 61epoch:train:2832-2980batch: iter_time=2.477e-04, forward_time=0.166, loss_ctc=2.457, loss=2.457, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.055e-04, train_time=1.950
[ALab02] 2023-06-08 14:01:52,789 (trainer:338) INFO: 61epoch results: [train] iter_time=0.003, forward_time=0.164, loss_ctc=2.514, loss=2.514, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.071e-04, train_time=1.946, time=24 minutes and 16.45 seconds, total_count=182634, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.458, cer_ctc=0.311, cer=0.311, loss=15.458, time=14.8 seconds, total_count=1830, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.59 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 14:01:55,414 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 14:01:55,425 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/60epoch.pth
[ALab02] 2023-06-08 14:01:55,425 (trainer:272) INFO: 62/70epoch started. Estimated time to finish: 4 hours, 2 minutes and 4.52 seconds
[ALab02] 2023-06-08 14:03:08,256 (trainer:721) INFO: 62epoch:train:1-149batch: iter_time=0.006, forward_time=0.163, loss_ctc=2.539, loss=2.539, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.053e-04, train_time=1.958
[ALab02] 2023-06-08 14:04:20,092 (trainer:721) INFO: 62epoch:train:150-298batch: iter_time=2.039e-04, forward_time=0.162, loss_ctc=2.510, loss=2.510, backward_time=0.154, optim_step_time=0.034, optim0_lr0=4.052e-04, train_time=1.927
[ALab02] 2023-06-08 14:05:33,130 (trainer:721) INFO: 62epoch:train:299-447batch: iter_time=0.011, forward_time=0.166, loss_ctc=2.406, loss=2.406, backward_time=0.154, optim_step_time=0.035, optim0_lr0=4.050e-04, train_time=1.963
[ALab02] 2023-06-08 14:06:45,212 (trainer:721) INFO: 62epoch:train:448-596batch: iter_time=2.792e-04, forward_time=0.162, loss_ctc=2.456, loss=2.456, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.048e-04, train_time=1.931
[ALab02] 2023-06-08 14:07:57,249 (trainer:721) INFO: 62epoch:train:597-745batch: iter_time=2.190e-04, forward_time=0.162, loss_ctc=2.531, loss=2.531, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.047e-04, train_time=1.940
[ALab02] 2023-06-08 14:09:09,724 (trainer:721) INFO: 62epoch:train:746-894batch: iter_time=2.340e-04, forward_time=0.164, loss_ctc=2.467, loss=2.467, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.045e-04, train_time=1.945
[ALab02] 2023-06-08 14:10:22,772 (trainer:721) INFO: 62epoch:train:895-1043batch: iter_time=2.440e-04, forward_time=0.165, loss_ctc=2.528, loss=2.528, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.044e-04, train_time=1.963
[ALab02] 2023-06-08 14:11:35,487 (trainer:721) INFO: 62epoch:train:1044-1192batch: iter_time=2.120e-04, forward_time=0.165, loss_ctc=2.359, loss=2.359, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.042e-04, train_time=1.945
[ALab02] 2023-06-08 14:12:47,744 (trainer:721) INFO: 62epoch:train:1193-1341batch: iter_time=2.474e-04, forward_time=0.163, loss_ctc=2.511, loss=2.511, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.040e-04, train_time=1.944
[ALab02] 2023-06-08 14:14:00,137 (trainer:721) INFO: 62epoch:train:1342-1490batch: iter_time=2.637e-04, forward_time=0.164, loss_ctc=2.554, loss=2.554, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.039e-04, train_time=1.944
[ALab02] 2023-06-08 14:15:12,580 (trainer:721) INFO: 62epoch:train:1491-1639batch: iter_time=2.495e-04, forward_time=0.166, loss_ctc=2.492, loss=2.492, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.037e-04, train_time=1.942
[ALab02] 2023-06-08 14:16:26,135 (trainer:721) INFO: 62epoch:train:1640-1788batch: iter_time=0.009, forward_time=0.166, loss_ctc=2.440, loss=2.440, backward_time=0.156, optim_step_time=0.033, optim0_lr0=4.035e-04, train_time=1.972
[ALab02] 2023-06-08 14:17:38,936 (trainer:721) INFO: 62epoch:train:1789-1937batch: iter_time=2.179e-04, forward_time=0.165, loss_ctc=2.485, loss=2.485, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.034e-04, train_time=1.956
[ALab02] 2023-06-08 14:18:52,703 (trainer:721) INFO: 62epoch:train:1938-2086batch: iter_time=0.014, forward_time=0.167, loss_ctc=2.490, loss=2.490, backward_time=0.156, optim_step_time=0.036, optim0_lr0=4.032e-04, train_time=1.983
[ALab02] 2023-06-08 14:20:04,438 (trainer:721) INFO: 62epoch:train:2087-2235batch: iter_time=2.701e-04, forward_time=0.164, loss_ctc=2.445, loss=2.445, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.030e-04, train_time=1.924
[ALab02] 2023-06-08 14:21:16,737 (trainer:721) INFO: 62epoch:train:2236-2384batch: iter_time=2.317e-04, forward_time=0.165, loss_ctc=2.456, loss=2.456, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.029e-04, train_time=1.938
[ALab02] 2023-06-08 14:22:28,732 (trainer:721) INFO: 62epoch:train:2385-2533batch: iter_time=3.289e-04, forward_time=0.164, loss_ctc=2.507, loss=2.507, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.027e-04, train_time=1.938
[ALab02] 2023-06-08 14:23:40,738 (trainer:721) INFO: 62epoch:train:2534-2682batch: iter_time=2.354e-04, forward_time=0.163, loss_ctc=2.513, loss=2.513, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.026e-04, train_time=1.933
[ALab02] 2023-06-08 14:24:53,869 (trainer:721) INFO: 62epoch:train:2683-2831batch: iter_time=1.928e-04, forward_time=0.166, loss_ctc=2.459, loss=2.459, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.024e-04, train_time=1.961
[ALab02] 2023-06-08 14:26:05,574 (trainer:721) INFO: 62epoch:train:2832-2980batch: iter_time=2.684e-04, forward_time=0.164, loss_ctc=2.440, loss=2.440, backward_time=0.152, optim_step_time=0.035, optim0_lr0=4.022e-04, train_time=1.922
[ALab02] 2023-06-08 14:26:55,951 (trainer:338) INFO: 62epoch results: [train] iter_time=0.002, forward_time=0.164, loss_ctc=2.477, loss=2.477, backward_time=0.155, optim_step_time=0.034, optim0_lr0=4.038e-04, train_time=1.947, time=24 minutes and 17.44 seconds, total_count=185628, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.481, cer_ctc=0.319, cer=0.319, loss=15.481, time=16.49 seconds, total_count=1860, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.59 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 14:26:58,547 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 14:26:58,551 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/61epoch.pth
[ALab02] 2023-06-08 14:26:58,551 (trainer:272) INFO: 63/70epoch started. Estimated time to finish: 3 hours, 34 minutes and 56.4 seconds
[ALab02] 2023-06-08 14:28:10,351 (trainer:721) INFO: 63epoch:train:1-149batch: iter_time=0.006, forward_time=0.160, loss_ctc=2.421, loss=2.421, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.021e-04, train_time=1.932
[ALab02] 2023-06-08 14:29:22,611 (trainer:721) INFO: 63epoch:train:150-298batch: iter_time=2.377e-04, forward_time=0.164, loss_ctc=2.529, loss=2.529, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.019e-04, train_time=1.942
[ALab02] 2023-06-08 14:30:35,095 (trainer:721) INFO: 63epoch:train:299-447batch: iter_time=2.272e-04, forward_time=0.167, loss_ctc=2.403, loss=2.403, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.017e-04, train_time=1.942
[ALab02] 2023-06-08 14:31:49,065 (trainer:721) INFO: 63epoch:train:448-596batch: iter_time=2.219e-04, forward_time=0.167, loss_ctc=2.455, loss=2.455, backward_time=0.159, optim_step_time=0.033, optim0_lr0=4.016e-04, train_time=1.981
[ALab02] 2023-06-08 14:33:01,381 (trainer:721) INFO: 63epoch:train:597-745batch: iter_time=2.350e-04, forward_time=0.166, loss_ctc=2.403, loss=2.403, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.014e-04, train_time=1.946
[ALab02] 2023-06-08 14:34:14,152 (trainer:721) INFO: 63epoch:train:746-894batch: iter_time=2.485e-04, forward_time=0.165, loss_ctc=2.547, loss=2.547, backward_time=0.157, optim_step_time=0.034, optim0_lr0=4.013e-04, train_time=1.955
[ALab02] 2023-06-08 14:35:25,975 (trainer:721) INFO: 63epoch:train:895-1043batch: iter_time=2.398e-04, forward_time=0.161, loss_ctc=2.537, loss=2.537, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.011e-04, train_time=1.928
[ALab02] 2023-06-08 14:36:39,292 (trainer:721) INFO: 63epoch:train:1044-1192batch: iter_time=0.011, forward_time=0.165, loss_ctc=2.569, loss=2.569, backward_time=0.155, optim_step_time=0.035, optim0_lr0=4.009e-04, train_time=1.962
[ALab02] 2023-06-08 14:37:52,425 (trainer:721) INFO: 63epoch:train:1193-1341batch: iter_time=2.704e-04, forward_time=0.167, loss_ctc=2.465, loss=2.465, backward_time=0.157, optim_step_time=0.032, optim0_lr0=4.008e-04, train_time=1.968
[ALab02] 2023-06-08 14:39:04,869 (trainer:721) INFO: 63epoch:train:1342-1490batch: iter_time=2.249e-04, forward_time=0.164, loss_ctc=2.499, loss=2.499, backward_time=0.156, optim_step_time=0.032, optim0_lr0=4.006e-04, train_time=1.945
[ALab02] 2023-06-08 14:40:17,059 (trainer:721) INFO: 63epoch:train:1491-1639batch: iter_time=2.266e-04, forward_time=0.164, loss_ctc=2.426, loss=2.426, backward_time=0.154, optim_step_time=0.033, optim0_lr0=4.005e-04, train_time=1.938
[ALab02] 2023-06-08 14:41:29,770 (trainer:721) INFO: 63epoch:train:1640-1788batch: iter_time=0.003, forward_time=0.163, loss_ctc=2.557, loss=2.557, backward_time=0.157, optim_step_time=0.033, optim0_lr0=4.003e-04, train_time=1.946
[ALab02] 2023-06-08 14:42:42,380 (trainer:721) INFO: 63epoch:train:1789-1937batch: iter_time=2.262e-04, forward_time=0.169, loss_ctc=2.560, loss=2.560, backward_time=0.153, optim_step_time=0.032, optim0_lr0=4.001e-04, train_time=1.953
[ALab02] 2023-06-08 14:43:54,910 (trainer:721) INFO: 63epoch:train:1938-2086batch: iter_time=2.143e-04, forward_time=0.170, loss_ctc=2.494, loss=2.494, backward_time=0.153, optim_step_time=0.033, optim0_lr0=4.000e-04, train_time=1.951
[ALab02] 2023-06-08 14:45:08,163 (trainer:721) INFO: 63epoch:train:2087-2235batch: iter_time=2.108e-04, forward_time=0.171, loss_ctc=2.432, loss=2.432, backward_time=0.155, optim_step_time=0.032, optim0_lr0=3.998e-04, train_time=1.962
[ALab02] 2023-06-08 14:46:21,301 (trainer:721) INFO: 63epoch:train:2236-2384batch: iter_time=2.210e-04, forward_time=0.171, loss_ctc=2.427, loss=2.427, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.997e-04, train_time=1.960
[ALab02] 2023-06-08 14:47:35,633 (trainer:721) INFO: 63epoch:train:2385-2533batch: iter_time=0.022, forward_time=0.175, loss_ctc=2.353, loss=2.353, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.995e-04, train_time=1.998
[ALab02] 2023-06-08 14:48:49,417 (trainer:721) INFO: 63epoch:train:2534-2682batch: iter_time=2.114e-04, forward_time=0.172, loss_ctc=2.473, loss=2.473, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.993e-04, train_time=1.983
[ALab02] 2023-06-08 14:50:03,969 (trainer:721) INFO: 63epoch:train:2683-2831batch: iter_time=2.282e-04, forward_time=0.177, loss_ctc=2.360, loss=2.360, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.992e-04, train_time=2.000
[ALab02] 2023-06-08 14:51:18,035 (trainer:721) INFO: 63epoch:train:2832-2980batch: iter_time=2.470e-04, forward_time=0.177, loss_ctc=2.418, loss=2.418, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.990e-04, train_time=1.983
[ALab02] 2023-06-08 14:52:05,493 (trainer:338) INFO: 63epoch results: [train] iter_time=0.002, forward_time=0.168, loss_ctc=2.464, loss=2.464, backward_time=0.155, optim_step_time=0.033, optim0_lr0=4.005e-04, train_time=1.959, time=24 minutes and 26.22 seconds, total_count=188622, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.148, cer_ctc=0.326, cer=0.326, loss=15.148, time=14.42 seconds, total_count=1890, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.31 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 14:52:07,973 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 14:52:07,976 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/62epoch.pth
[ALab02] 2023-06-08 14:52:07,976 (trainer:272) INFO: 64/70epoch started. Estimated time to finish: 3 hours, 7 minutes and 52.95 seconds
[ALab02] 2023-06-08 14:53:23,053 (trainer:721) INFO: 64epoch:train:1-149batch: iter_time=0.008, forward_time=0.175, loss_ctc=2.336, loss=2.336, backward_time=0.157, optim_step_time=0.033, optim0_lr0=3.989e-04, train_time=2.019
[ALab02] 2023-06-08 14:54:36,383 (trainer:721) INFO: 64epoch:train:150-298batch: iter_time=3.063e-04, forward_time=0.173, loss_ctc=2.402, loss=2.402, backward_time=0.152, optim_step_time=0.033, optim0_lr0=3.987e-04, train_time=1.969
[ALab02] 2023-06-08 14:55:50,525 (trainer:721) INFO: 64epoch:train:299-447batch: iter_time=0.010, forward_time=0.174, loss_ctc=2.432, loss=2.432, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.985e-04, train_time=1.992
[ALab02] 2023-06-08 14:57:04,812 (trainer:721) INFO: 64epoch:train:448-596batch: iter_time=2.877e-04, forward_time=0.175, loss_ctc=2.323, loss=2.323, backward_time=0.156, optim_step_time=0.033, optim0_lr0=3.984e-04, train_time=1.988
[ALab02] 2023-06-08 14:58:18,212 (trainer:721) INFO: 64epoch:train:597-745batch: iter_time=2.413e-04, forward_time=0.172, loss_ctc=2.418, loss=2.418, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.982e-04, train_time=1.975
[ALab02] 2023-06-08 14:59:31,784 (trainer:721) INFO: 64epoch:train:746-894batch: iter_time=2.041e-04, forward_time=0.173, loss_ctc=2.409, loss=2.409, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.981e-04, train_time=1.974
[ALab02] 2023-06-08 15:00:45,051 (trainer:721) INFO: 64epoch:train:895-1043batch: iter_time=2.463e-04, forward_time=0.173, loss_ctc=2.329, loss=2.329, backward_time=0.153, optim_step_time=0.034, optim0_lr0=3.979e-04, train_time=1.963
[ALab02] 2023-06-08 15:01:59,131 (trainer:721) INFO: 64epoch:train:1044-1192batch: iter_time=2.314e-04, forward_time=0.175, loss_ctc=2.382, loss=2.382, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.978e-04, train_time=1.987
[ALab02] 2023-06-08 15:03:13,192 (trainer:721) INFO: 64epoch:train:1193-1341batch: iter_time=2.583e-04, forward_time=0.175, loss_ctc=2.428, loss=2.428, backward_time=0.156, optim_step_time=0.033, optim0_lr0=3.976e-04, train_time=1.993
[ALab02] 2023-06-08 15:04:27,901 (trainer:721) INFO: 64epoch:train:1342-1490batch: iter_time=2.636e-04, forward_time=0.178, loss_ctc=2.260, loss=2.260, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.974e-04, train_time=2.005
[ALab02] 2023-06-08 15:05:41,383 (trainer:721) INFO: 64epoch:train:1491-1639batch: iter_time=2.465e-04, forward_time=0.173, loss_ctc=2.429, loss=2.429, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.973e-04, train_time=1.972
[ALab02] 2023-06-08 15:06:55,204 (trainer:721) INFO: 64epoch:train:1640-1788batch: iter_time=2.198e-04, forward_time=0.174, loss_ctc=2.379, loss=2.379, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.971e-04, train_time=1.978
[ALab02] 2023-06-08 15:08:10,334 (trainer:721) INFO: 64epoch:train:1789-1937batch: iter_time=0.010, forward_time=0.179, loss_ctc=2.357, loss=2.357, backward_time=0.157, optim_step_time=0.035, optim0_lr0=3.970e-04, train_time=2.020
[ALab02] 2023-06-08 15:09:24,708 (trainer:721) INFO: 64epoch:train:1938-2086batch: iter_time=0.004, forward_time=0.176, loss_ctc=2.395, loss=2.395, backward_time=0.156, optim_step_time=0.035, optim0_lr0=3.968e-04, train_time=1.994
[ALab02] 2023-06-08 15:10:38,931 (trainer:721) INFO: 64epoch:train:2087-2235batch: iter_time=3.212e-04, forward_time=0.175, loss_ctc=2.344, loss=2.344, backward_time=0.156, optim_step_time=0.033, optim0_lr0=3.967e-04, train_time=1.999
[ALab02] 2023-06-08 15:11:52,882 (trainer:721) INFO: 64epoch:train:2236-2384batch: iter_time=2.379e-04, forward_time=0.173, loss_ctc=2.446, loss=2.446, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.965e-04, train_time=1.977
[ALab02] 2023-06-08 15:13:06,236 (trainer:721) INFO: 64epoch:train:2385-2533batch: iter_time=0.004, forward_time=0.170, loss_ctc=2.437, loss=2.437, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.964e-04, train_time=1.969
[ALab02] 2023-06-08 15:14:20,840 (trainer:721) INFO: 64epoch:train:2534-2682batch: iter_time=0.006, forward_time=0.176, loss_ctc=2.345, loss=2.345, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.962e-04, train_time=2.007
[ALab02] 2023-06-08 15:15:34,260 (trainer:721) INFO: 64epoch:train:2683-2831batch: iter_time=2.319e-04, forward_time=0.172, loss_ctc=2.369, loss=2.369, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.961e-04, train_time=1.970
[ALab02] 2023-06-08 15:16:48,887 (trainer:721) INFO: 64epoch:train:2832-2980batch: iter_time=2.338e-04, forward_time=0.176, loss_ctc=2.437, loss=2.437, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.959e-04, train_time=1.999
[ALab02] 2023-06-08 15:17:37,589 (trainer:338) INFO: 64epoch results: [train] iter_time=0.002, forward_time=0.174, loss_ctc=2.382, loss=2.382, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.974e-04, train_time=1.988, time=24 minutes and 48.07 seconds, total_count=191616, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.720, cer_ctc=0.307, cer=0.307, loss=15.720, time=14.51 seconds, total_count=1920, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.03 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 15:17:40,272 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 15:17:40,294 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/39epoch.pth, exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/63epoch.pth
[ALab02] 2023-06-08 15:17:40,294 (trainer:272) INFO: 65/70epoch started. Estimated time to finish: 2 hours, 40 minutes and 55.2 seconds
[ALab02] 2023-06-08 15:18:54,919 (trainer:721) INFO: 65epoch:train:1-149batch: iter_time=0.009, forward_time=0.175, loss_ctc=2.294, loss=2.294, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.957e-04, train_time=2.005
[ALab02] 2023-06-08 15:20:08,296 (trainer:721) INFO: 65epoch:train:150-298batch: iter_time=6.938e-04, forward_time=0.173, loss_ctc=2.309, loss=2.309, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.956e-04, train_time=1.971
[ALab02] 2023-06-08 15:21:22,709 (trainer:721) INFO: 65epoch:train:299-447batch: iter_time=2.864e-04, forward_time=0.176, loss_ctc=2.270, loss=2.270, backward_time=0.156, optim_step_time=0.035, optim0_lr0=3.954e-04, train_time=1.997
[ALab02] 2023-06-08 15:22:36,312 (trainer:721) INFO: 65epoch:train:448-596batch: iter_time=2.533e-04, forward_time=0.173, loss_ctc=2.378, loss=2.378, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.953e-04, train_time=1.973
[ALab02] 2023-06-08 15:23:49,160 (trainer:721) INFO: 65epoch:train:597-745batch: iter_time=2.613e-04, forward_time=0.171, loss_ctc=2.356, loss=2.356, backward_time=0.154, optim_step_time=0.035, optim0_lr0=3.951e-04, train_time=1.960
[ALab02] 2023-06-08 15:25:03,223 (trainer:721) INFO: 65epoch:train:746-894batch: iter_time=2.625e-04, forward_time=0.175, loss_ctc=2.374, loss=2.374, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.950e-04, train_time=1.986
[ALab02] 2023-06-08 15:26:17,063 (trainer:721) INFO: 65epoch:train:895-1043batch: iter_time=2.786e-04, forward_time=0.175, loss_ctc=2.382, loss=2.382, backward_time=0.156, optim_step_time=0.033, optim0_lr0=3.948e-04, train_time=1.983
[ALab02] 2023-06-08 15:27:31,668 (trainer:721) INFO: 65epoch:train:1044-1192batch: iter_time=2.925e-04, forward_time=0.174, loss_ctc=2.334, loss=2.334, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.947e-04, train_time=1.998
[ALab02] 2023-06-08 15:28:45,920 (trainer:721) INFO: 65epoch:train:1193-1341batch: iter_time=0.005, forward_time=0.176, loss_ctc=2.354, loss=2.354, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.945e-04, train_time=1.993
[ALab02] 2023-06-08 15:30:01,155 (trainer:721) INFO: 65epoch:train:1342-1490batch: iter_time=0.019, forward_time=0.177, loss_ctc=2.260, loss=2.260, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.944e-04, train_time=2.025
[ALab02] 2023-06-08 15:31:15,807 (trainer:721) INFO: 65epoch:train:1491-1639batch: iter_time=2.159e-04, forward_time=0.175, loss_ctc=2.409, loss=2.409, backward_time=0.158, optim_step_time=0.033, optim0_lr0=3.942e-04, train_time=2.001
[ALab02] 2023-06-08 15:32:30,630 (trainer:721) INFO: 65epoch:train:1640-1788batch: iter_time=0.014, forward_time=0.176, loss_ctc=2.365, loss=2.365, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.940e-04, train_time=2.006
[ALab02] 2023-06-08 15:33:43,997 (trainer:721) INFO: 65epoch:train:1789-1937batch: iter_time=2.180e-04, forward_time=0.173, loss_ctc=2.394, loss=2.394, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.939e-04, train_time=1.974
[ALab02] 2023-06-08 15:34:58,062 (trainer:721) INFO: 65epoch:train:1938-2086batch: iter_time=2.424e-04, forward_time=0.177, loss_ctc=2.308, loss=2.308, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.937e-04, train_time=1.987
[ALab02] 2023-06-08 15:36:12,451 (trainer:721) INFO: 65epoch:train:2087-2235batch: iter_time=2.477e-04, forward_time=0.175, loss_ctc=2.389, loss=2.389, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.936e-04, train_time=1.999
[ALab02] 2023-06-08 15:37:26,757 (trainer:721) INFO: 65epoch:train:2236-2384batch: iter_time=2.548e-04, forward_time=0.176, loss_ctc=2.268, loss=2.268, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.934e-04, train_time=1.989
[ALab02] 2023-06-08 15:38:39,478 (trainer:721) INFO: 65epoch:train:2385-2533batch: iter_time=2.289e-04, forward_time=0.171, loss_ctc=2.384, loss=2.384, backward_time=0.153, optim_step_time=0.034, optim0_lr0=3.933e-04, train_time=1.956
[ALab02] 2023-06-08 15:39:53,646 (trainer:721) INFO: 65epoch:train:2534-2682batch: iter_time=2.481e-04, forward_time=0.176, loss_ctc=2.310, loss=2.310, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.931e-04, train_time=1.990
[ALab02] 2023-06-08 15:41:08,198 (trainer:721) INFO: 65epoch:train:2683-2831batch: iter_time=2.379e-04, forward_time=0.175, loss_ctc=2.353, loss=2.353, backward_time=0.157, optim_step_time=0.033, optim0_lr0=3.930e-04, train_time=2.004
[ALab02] 2023-06-08 15:42:22,074 (trainer:721) INFO: 65epoch:train:2832-2980batch: iter_time=2.192e-04, forward_time=0.172, loss_ctc=2.401, loss=2.401, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.928e-04, train_time=1.977
[ALab02] 2023-06-08 15:43:10,776 (trainer:338) INFO: 65epoch results: [train] iter_time=0.003, forward_time=0.174, loss_ctc=2.343, loss=2.343, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.943e-04, train_time=1.989, time=24 minutes and 48.62 seconds, total_count=194610, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.462, cer_ctc=0.324, cer=0.324, loss=15.462, time=14.32 seconds, total_count=1950, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.54 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 15:43:13,274 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 15:43:13,275 (trainer:272) INFO: 66/70epoch started. Estimated time to finish: 2 hours, 14 minutes and 0.14 seconds
[ALab02] 2023-06-08 15:44:28,597 (trainer:721) INFO: 66epoch:train:1-149batch: iter_time=0.007, forward_time=0.176, loss_ctc=2.337, loss=2.337, backward_time=0.157, optim_step_time=0.032, optim0_lr0=3.927e-04, train_time=2.025
[ALab02] 2023-06-08 15:45:42,169 (trainer:721) INFO: 66epoch:train:150-298batch: iter_time=2.384e-04, forward_time=0.174, loss_ctc=2.260, loss=2.260, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.925e-04, train_time=1.978
[ALab02] 2023-06-08 15:46:54,933 (trainer:721) INFO: 66epoch:train:299-447batch: iter_time=2.293e-04, forward_time=0.171, loss_ctc=2.361, loss=2.361, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.924e-04, train_time=1.949
[ALab02] 2023-06-08 15:48:08,642 (trainer:721) INFO: 66epoch:train:448-596batch: iter_time=2.445e-04, forward_time=0.174, loss_ctc=2.285, loss=2.285, backward_time=0.155, optim_step_time=0.032, optim0_lr0=3.922e-04, train_time=1.976
[ALab02] 2023-06-08 15:49:21,819 (trainer:721) INFO: 66epoch:train:597-745batch: iter_time=2.518e-04, forward_time=0.172, loss_ctc=2.342, loss=2.342, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.921e-04, train_time=1.968
[ALab02] 2023-06-08 15:50:35,987 (trainer:721) INFO: 66epoch:train:746-894batch: iter_time=6.760e-04, forward_time=0.176, loss_ctc=2.344, loss=2.344, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.919e-04, train_time=1.992
[ALab02] 2023-06-08 15:51:49,426 (trainer:721) INFO: 66epoch:train:895-1043batch: iter_time=2.307e-04, forward_time=0.172, loss_ctc=2.353, loss=2.353, backward_time=0.154, optim_step_time=0.035, optim0_lr0=3.918e-04, train_time=1.973
[ALab02] 2023-06-08 15:53:06,390 (trainer:721) INFO: 66epoch:train:1044-1192batch: iter_time=0.031, forward_time=0.177, loss_ctc=2.350, loss=2.350, backward_time=0.156, optim_step_time=0.038, optim0_lr0=3.916e-04, train_time=2.058
[ALab02] 2023-06-08 15:54:20,835 (trainer:721) INFO: 66epoch:train:1193-1341batch: iter_time=2.204e-04, forward_time=0.175, loss_ctc=2.396, loss=2.396, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.915e-04, train_time=2.003
[ALab02] 2023-06-08 15:55:35,237 (trainer:721) INFO: 66epoch:train:1342-1490batch: iter_time=2.286e-04, forward_time=0.175, loss_ctc=2.308, loss=2.308, backward_time=0.156, optim_step_time=0.033, optim0_lr0=3.913e-04, train_time=1.996
[ALab02] 2023-06-08 15:56:48,192 (trainer:721) INFO: 66epoch:train:1491-1639batch: iter_time=2.701e-04, forward_time=0.171, loss_ctc=2.351, loss=2.351, backward_time=0.153, optim_step_time=0.034, optim0_lr0=3.912e-04, train_time=1.959
[ALab02] 2023-06-08 15:58:01,686 (trainer:721) INFO: 66epoch:train:1640-1788batch: iter_time=2.379e-04, forward_time=0.172, loss_ctc=2.318, loss=2.318, backward_time=0.154, optim_step_time=0.035, optim0_lr0=3.910e-04, train_time=1.969
[ALab02] 2023-06-08 15:59:15,161 (trainer:721) INFO: 66epoch:train:1789-1937batch: iter_time=0.002, forward_time=0.174, loss_ctc=2.294, loss=2.294, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.909e-04, train_time=1.975
[ALab02] 2023-06-08 16:00:29,810 (trainer:721) INFO: 66epoch:train:1938-2086batch: iter_time=4.957e-04, forward_time=0.176, loss_ctc=2.296, loss=2.296, backward_time=0.157, optim_step_time=0.033, optim0_lr0=3.907e-04, train_time=2.002
[ALab02] 2023-06-08 16:01:43,926 (trainer:721) INFO: 66epoch:train:2087-2235batch: iter_time=1.975e-04, forward_time=0.174, loss_ctc=2.324, loss=2.324, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.906e-04, train_time=1.992
[ALab02] 2023-06-08 16:02:57,785 (trainer:721) INFO: 66epoch:train:2236-2384batch: iter_time=2.013e-04, forward_time=0.174, loss_ctc=2.358, loss=2.358, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.904e-04, train_time=1.979
[ALab02] 2023-06-08 16:04:12,018 (trainer:721) INFO: 66epoch:train:2385-2533batch: iter_time=2.365e-04, forward_time=0.174, loss_ctc=2.375, loss=2.375, backward_time=0.157, optim_step_time=0.033, optim0_lr0=3.903e-04, train_time=1.998
[ALab02] 2023-06-08 16:05:25,402 (trainer:721) INFO: 66epoch:train:2534-2682batch: iter_time=3.109e-04, forward_time=0.172, loss_ctc=2.372, loss=2.372, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.901e-04, train_time=1.969
[ALab02] 2023-06-08 16:06:38,835 (trainer:721) INFO: 66epoch:train:2683-2831batch: iter_time=0.006, forward_time=0.170, loss_ctc=2.398, loss=2.398, backward_time=0.154, optim_step_time=0.035, optim0_lr0=3.900e-04, train_time=1.972
[ALab02] 2023-06-08 16:07:51,004 (trainer:721) INFO: 66epoch:train:2832-2980batch: iter_time=0.002, forward_time=0.165, loss_ctc=2.310, loss=2.310, backward_time=0.153, optim_step_time=0.035, optim0_lr0=3.899e-04, train_time=1.933
[ALab02] 2023-06-08 16:08:42,251 (trainer:338) INFO: 66epoch results: [train] iter_time=0.003, forward_time=0.173, loss_ctc=2.337, loss=2.337, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.913e-04, train_time=1.983, time=24 minutes and 44.86 seconds, total_count=197604, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.934, cer_ctc=0.316, cer=0.316, loss=15.934, time=17.49 seconds, total_count=1980, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.62 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 16:08:44,653 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 16:08:44,657 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/65epoch.pth
[ALab02] 2023-06-08 16:08:44,657 (trainer:272) INFO: 67/70epoch started. Estimated time to finish: 1 hour, 47 minutes and 7.47 seconds
[ALab02] 2023-06-08 16:09:57,209 (trainer:721) INFO: 67epoch:train:1-149batch: iter_time=0.007, forward_time=0.162, loss_ctc=2.326, loss=2.326, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.897e-04, train_time=1.952
[ALab02] 2023-06-08 16:11:11,393 (trainer:721) INFO: 67epoch:train:150-298batch: iter_time=0.014, forward_time=0.168, loss_ctc=2.318, loss=2.318, backward_time=0.156, optim_step_time=0.037, optim0_lr0=3.895e-04, train_time=1.991
[ALab02] 2023-06-08 16:12:27,198 (trainer:721) INFO: 67epoch:train:299-447batch: iter_time=0.040, forward_time=0.169, loss_ctc=2.275, loss=2.275, backward_time=0.155, optim_step_time=0.038, optim0_lr0=3.894e-04, train_time=2.034
[ALab02] 2023-06-08 16:13:39,557 (trainer:721) INFO: 67epoch:train:448-596batch: iter_time=0.008, forward_time=0.164, loss_ctc=2.250, loss=2.250, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.893e-04, train_time=1.939
[ALab02] 2023-06-08 16:14:51,482 (trainer:721) INFO: 67epoch:train:597-745batch: iter_time=0.002, forward_time=0.166, loss_ctc=2.267, loss=2.267, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.891e-04, train_time=1.933
[ALab02] 2023-06-08 16:16:05,142 (trainer:721) INFO: 67epoch:train:746-894batch: iter_time=2.285e-04, forward_time=0.168, loss_ctc=2.342, loss=2.342, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.890e-04, train_time=1.977
[ALab02] 2023-06-08 16:17:18,065 (trainer:721) INFO: 67epoch:train:895-1043batch: iter_time=2.575e-04, forward_time=0.167, loss_ctc=2.331, loss=2.331, backward_time=0.156, optim_step_time=0.034, optim0_lr0=3.888e-04, train_time=1.962
[ALab02] 2023-06-08 16:18:31,686 (trainer:721) INFO: 67epoch:train:1044-1192batch: iter_time=0.002, forward_time=0.168, loss_ctc=2.277, loss=2.277, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.887e-04, train_time=1.969
[ALab02] 2023-06-08 16:19:43,531 (trainer:721) INFO: 67epoch:train:1193-1341batch: iter_time=2.213e-04, forward_time=0.163, loss_ctc=2.310, loss=2.310, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.885e-04, train_time=1.932
[ALab02] 2023-06-08 16:20:55,462 (trainer:721) INFO: 67epoch:train:1342-1490batch: iter_time=2.425e-04, forward_time=0.163, loss_ctc=2.336, loss=2.336, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.884e-04, train_time=1.929
[ALab02] 2023-06-08 16:22:07,296 (trainer:721) INFO: 67epoch:train:1491-1639batch: iter_time=2.334e-04, forward_time=0.162, loss_ctc=2.340, loss=2.340, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.882e-04, train_time=1.930
[ALab02] 2023-06-08 16:23:19,344 (trainer:721) INFO: 67epoch:train:1640-1788batch: iter_time=2.550e-04, forward_time=0.163, loss_ctc=2.319, loss=2.319, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.881e-04, train_time=1.931
[ALab02] 2023-06-08 16:24:31,424 (trainer:721) INFO: 67epoch:train:1789-1937batch: iter_time=2.438e-04, forward_time=0.163, loss_ctc=2.301, loss=2.301, backward_time=0.154, optim_step_time=0.035, optim0_lr0=3.879e-04, train_time=1.941
[ALab02] 2023-06-08 16:25:43,235 (trainer:721) INFO: 67epoch:train:1938-2086batch: iter_time=2.531e-04, forward_time=0.162, loss_ctc=2.278, loss=2.278, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.878e-04, train_time=1.926
[ALab02] 2023-06-08 16:26:56,438 (trainer:721) INFO: 67epoch:train:2087-2235batch: iter_time=2.485e-04, forward_time=0.167, loss_ctc=2.287, loss=2.287, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.877e-04, train_time=1.966
[ALab02] 2023-06-08 16:28:08,421 (trainer:721) INFO: 67epoch:train:2236-2384batch: iter_time=2.426e-04, forward_time=0.164, loss_ctc=2.277, loss=2.277, backward_time=0.153, optim_step_time=0.033, optim0_lr0=3.875e-04, train_time=1.928
[ALab02] 2023-06-08 16:29:22,997 (trainer:721) INFO: 67epoch:train:2385-2533batch: iter_time=0.023, forward_time=0.167, loss_ctc=2.300, loss=2.300, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.874e-04, train_time=2.006
[ALab02] 2023-06-08 16:30:35,769 (trainer:721) INFO: 67epoch:train:2534-2682batch: iter_time=3.849e-04, forward_time=0.164, loss_ctc=2.338, loss=2.338, backward_time=0.156, optim_step_time=0.035, optim0_lr0=3.872e-04, train_time=1.954
[ALab02] 2023-06-08 16:31:47,882 (trainer:721) INFO: 67epoch:train:2683-2831batch: iter_time=2.513e-04, forward_time=0.163, loss_ctc=2.340, loss=2.340, backward_time=0.155, optim_step_time=0.033, optim0_lr0=3.871e-04, train_time=1.936
[ALab02] 2023-06-08 16:33:02,147 (trainer:721) INFO: 67epoch:train:2832-2980batch: iter_time=0.025, forward_time=0.168, loss_ctc=2.296, loss=2.296, backward_time=0.156, optim_step_time=0.035, optim0_lr0=3.869e-04, train_time=1.988
[ALab02] 2023-06-08 16:33:50,477 (trainer:338) INFO: 67epoch results: [train] iter_time=0.006, forward_time=0.165, loss_ctc=2.306, loss=2.306, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.883e-04, train_time=1.956, time=24 minutes and 24.39 seconds, total_count=200598, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=16.495, cer_ctc=0.320, cer=0.320, loss=16.495, time=14.27 seconds, total_count=2010, gpu_max_cached_mem_GB=52.041, [att_plot] time=27.16 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 16:33:52,799 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 16:33:52,802 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/66epoch.pth
[ALab02] 2023-06-08 16:33:52,802 (trainer:272) INFO: 68/70epoch started. Estimated time to finish: 1 hour, 20 minutes and 16.18 seconds
[ALab02] 2023-06-08 16:35:06,523 (trainer:721) INFO: 68epoch:train:1-149batch: iter_time=0.010, forward_time=0.166, loss_ctc=2.269, loss=2.269, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.868e-04, train_time=1.983
[ALab02] 2023-06-08 16:36:20,555 (trainer:721) INFO: 68epoch:train:150-298batch: iter_time=0.002, forward_time=0.175, loss_ctc=2.270, loss=2.270, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.866e-04, train_time=1.987
[ALab02] 2023-06-08 16:37:34,350 (trainer:721) INFO: 68epoch:train:299-447batch: iter_time=2.968e-04, forward_time=0.174, loss_ctc=2.224, loss=2.224, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.865e-04, train_time=1.975
[ALab02] 2023-06-08 16:38:48,179 (trainer:721) INFO: 68epoch:train:448-596batch: iter_time=0.002, forward_time=0.174, loss_ctc=2.282, loss=2.282, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.863e-04, train_time=1.983
[ALab02] 2023-06-08 16:40:01,519 (trainer:721) INFO: 68epoch:train:597-745batch: iter_time=2.710e-04, forward_time=0.172, loss_ctc=2.331, loss=2.331, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.862e-04, train_time=1.973
[ALab02] 2023-06-08 16:41:16,114 (trainer:721) INFO: 68epoch:train:746-894batch: iter_time=0.005, forward_time=0.176, loss_ctc=2.255, loss=2.255, backward_time=0.155, optim_step_time=0.037, optim0_lr0=3.861e-04, train_time=2.002
[ALab02] 2023-06-08 16:42:29,652 (trainer:721) INFO: 68epoch:train:895-1043batch: iter_time=0.003, forward_time=0.175, loss_ctc=2.277, loss=2.277, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.859e-04, train_time=1.978
[ALab02] 2023-06-08 16:43:44,469 (trainer:721) INFO: 68epoch:train:1044-1192batch: iter_time=0.002, forward_time=0.176, loss_ctc=2.388, loss=2.388, backward_time=0.156, optim_step_time=0.038, optim0_lr0=3.858e-04, train_time=1.999
[ALab02] 2023-06-08 16:44:58,987 (trainer:721) INFO: 68epoch:train:1193-1341batch: iter_time=2.762e-04, forward_time=0.176, loss_ctc=2.289, loss=2.289, backward_time=0.156, optim_step_time=0.035, optim0_lr0=3.856e-04, train_time=2.007
[ALab02] 2023-06-08 16:46:12,961 (trainer:721) INFO: 68epoch:train:1342-1490batch: iter_time=5.465e-04, forward_time=0.176, loss_ctc=2.258, loss=2.258, backward_time=0.154, optim_step_time=0.036, optim0_lr0=3.855e-04, train_time=1.983
[ALab02] 2023-06-08 16:47:27,702 (trainer:721) INFO: 68epoch:train:1491-1639batch: iter_time=0.010, forward_time=0.178, loss_ctc=2.243, loss=2.243, backward_time=0.154, optim_step_time=0.035, optim0_lr0=3.853e-04, train_time=2.007
[ALab02] 2023-06-08 16:48:44,774 (trainer:721) INFO: 68epoch:train:1640-1788batch: iter_time=0.046, forward_time=0.179, loss_ctc=2.301, loss=2.301, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.852e-04, train_time=2.063
[ALab02] 2023-06-08 16:49:58,627 (trainer:721) INFO: 68epoch:train:1789-1937batch: iter_time=0.012, forward_time=0.173, loss_ctc=2.305, loss=2.305, backward_time=0.154, optim_step_time=0.036, optim0_lr0=3.851e-04, train_time=1.986
[ALab02] 2023-06-08 16:51:12,585 (trainer:721) INFO: 68epoch:train:1938-2086batch: iter_time=0.014, forward_time=0.174, loss_ctc=2.333, loss=2.333, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.849e-04, train_time=1.990
[ALab02] 2023-06-08 16:52:25,685 (trainer:721) INFO: 68epoch:train:2087-2235batch: iter_time=0.004, forward_time=0.171, loss_ctc=2.317, loss=2.317, backward_time=0.154, optim_step_time=0.033, optim0_lr0=3.848e-04, train_time=1.959
[ALab02] 2023-06-08 16:53:42,149 (trainer:721) INFO: 68epoch:train:2236-2384batch: iter_time=0.032, forward_time=0.179, loss_ctc=2.225, loss=2.225, backward_time=0.156, optim_step_time=0.037, optim0_lr0=3.846e-04, train_time=2.046
[ALab02] 2023-06-08 16:54:56,072 (trainer:721) INFO: 68epoch:train:2385-2533batch: iter_time=2.880e-04, forward_time=0.175, loss_ctc=2.329, loss=2.329, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.845e-04, train_time=1.990
[ALab02] 2023-06-08 16:56:10,950 (trainer:721) INFO: 68epoch:train:2534-2682batch: iter_time=0.005, forward_time=0.177, loss_ctc=2.307, loss=2.307, backward_time=0.157, optim_step_time=0.035, optim0_lr0=3.844e-04, train_time=2.006
[ALab02] 2023-06-08 16:57:25,945 (trainer:721) INFO: 68epoch:train:2683-2831batch: iter_time=0.005, forward_time=0.180, loss_ctc=2.293, loss=2.293, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.842e-04, train_time=2.012
[ALab02] 2023-06-08 16:58:42,288 (trainer:721) INFO: 68epoch:train:2832-2980batch: iter_time=0.032, forward_time=0.180, loss_ctc=2.282, loss=2.282, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.841e-04, train_time=2.047
[ALab02] 2023-06-08 16:59:29,218 (trainer:338) INFO: 68epoch results: [train] iter_time=0.009, forward_time=0.175, loss_ctc=2.287, loss=2.287, backward_time=0.155, optim_step_time=0.035, optim0_lr0=3.854e-04, train_time=1.998, time=24 minutes and 56.03 seconds, total_count=203592, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=15.773, cer_ctc=0.317, cer=0.317, loss=15.773, time=14.3 seconds, total_count=2040, gpu_max_cached_mem_GB=52.041, [att_plot] time=26.09 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 16:59:31,539 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 16:59:31,554 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/67epoch.pth
[ALab02] 2023-06-08 16:59:31,555 (trainer:272) INFO: 69/70epoch started. Estimated time to finish: 53 minutes and 28.83 seconds
[ALab02] 2023-06-08 17:00:46,386 (trainer:721) INFO: 69epoch:train:1-149batch: iter_time=0.009, forward_time=0.176, loss_ctc=2.210, loss=2.210, backward_time=0.156, optim_step_time=0.035, optim0_lr0=3.839e-04, train_time=2.007
[ALab02] 2023-06-08 17:01:58,848 (trainer:721) INFO: 69epoch:train:150-298batch: iter_time=0.010, forward_time=0.170, loss_ctc=2.255, loss=2.255, backward_time=0.152, optim_step_time=0.034, optim0_lr0=3.838e-04, train_time=1.951
[ALab02] 2023-06-08 17:03:12,988 (trainer:721) INFO: 69epoch:train:299-447batch: iter_time=0.008, forward_time=0.175, loss_ctc=2.198, loss=2.198, backward_time=0.154, optim_step_time=0.036, optim0_lr0=3.836e-04, train_time=1.989
[ALab02] 2023-06-08 17:04:28,643 (trainer:721) INFO: 69epoch:train:448-596batch: iter_time=0.006, forward_time=0.178, loss_ctc=2.267, loss=2.267, backward_time=0.158, optim_step_time=0.036, optim0_lr0=3.835e-04, train_time=2.025
[ALab02] 2023-06-08 17:05:42,498 (trainer:721) INFO: 69epoch:train:597-745batch: iter_time=9.127e-04, forward_time=0.176, loss_ctc=2.304, loss=2.304, backward_time=0.154, optim_step_time=0.038, optim0_lr0=3.834e-04, train_time=1.987
[ALab02] 2023-06-08 17:07:01,689 (trainer:721) INFO: 69epoch:train:746-894batch: iter_time=0.073, forward_time=0.180, loss_ctc=2.221, loss=2.221, backward_time=0.156, optim_step_time=0.039, optim0_lr0=3.832e-04, train_time=2.125
[ALab02] 2023-06-08 17:08:17,699 (trainer:721) INFO: 69epoch:train:895-1043batch: iter_time=0.038, forward_time=0.180, loss_ctc=2.250, loss=2.250, backward_time=0.156, optim_step_time=0.037, optim0_lr0=3.831e-04, train_time=2.041
[ALab02] 2023-06-08 17:09:32,491 (trainer:721) INFO: 69epoch:train:1044-1192batch: iter_time=0.017, forward_time=0.177, loss_ctc=2.252, loss=2.252, backward_time=0.154, optim_step_time=0.034, optim0_lr0=3.829e-04, train_time=2.004
[ALab02] 2023-06-08 17:10:47,256 (trainer:721) INFO: 69epoch:train:1193-1341batch: iter_time=0.020, forward_time=0.176, loss_ctc=2.314, loss=2.314, backward_time=0.155, optim_step_time=0.036, optim0_lr0=3.828e-04, train_time=2.013
[ALab02] 2023-06-08 17:12:01,608 (trainer:721) INFO: 69epoch:train:1342-1490batch: iter_time=0.035, forward_time=0.173, loss_ctc=2.239, loss=2.239, backward_time=0.153, optim_step_time=0.038, optim0_lr0=3.827e-04, train_time=1.995
[ALab02] 2023-06-08 17:13:15,924 (trainer:721) INFO: 69epoch:train:1491-1639batch: iter_time=0.007, forward_time=0.174, loss_ctc=2.253, loss=2.253, backward_time=0.155, optim_step_time=0.034, optim0_lr0=3.825e-04, train_time=1.996
[ALab02] 2023-06-08 17:14:33,172 (trainer:721) INFO: 69epoch:train:1640-1788batch: iter_time=0.046, forward_time=0.175, loss_ctc=2.342, loss=2.342, backward_time=0.155, optim_step_time=0.038, optim0_lr0=3.824e-04, train_time=2.066
[ALab02] 2023-06-08 17:15:47,566 (trainer:721) INFO: 69epoch:train:1789-1937batch: iter_time=0.036, forward_time=0.176, loss_ctc=2.228, loss=2.228, backward_time=0.153, optim_step_time=0.035, optim0_lr0=3.822e-04, train_time=2.002
[ALab02] 2023-06-08 17:17:03,081 (trainer:721) INFO: 69epoch:train:1938-2086batch: iter_time=0.021, forward_time=0.179, loss_ctc=2.301, loss=2.301, backward_time=0.157, optim_step_time=0.035, optim0_lr0=3.821e-04, train_time=2.026
[ALab02] 2023-06-08 17:18:17,786 (trainer:721) INFO: 69epoch:train:2087-2235batch: iter_time=0.029, forward_time=0.175, loss_ctc=2.207, loss=2.207, backward_time=0.154, optim_step_time=0.036, optim0_lr0=3.820e-04, train_time=2.006
[ALab02] 2023-06-08 17:19:33,660 (trainer:721) INFO: 69epoch:train:2236-2384batch: iter_time=0.035, forward_time=0.179, loss_ctc=2.232, loss=2.232, backward_time=0.156, optim_step_time=0.038, optim0_lr0=3.818e-04, train_time=2.031
[ALab02] 2023-06-08 17:20:50,086 (trainer:721) INFO: 69epoch:train:2385-2533batch: iter_time=0.036, forward_time=0.179, loss_ctc=2.219, loss=2.219, backward_time=0.156, optim_step_time=0.038, optim0_lr0=3.817e-04, train_time=2.054
[ALab02] 2023-06-08 17:22:08,191 (trainer:721) INFO: 69epoch:train:2534-2682batch: iter_time=0.069, forward_time=0.183, loss_ctc=2.226, loss=2.226, backward_time=0.157, optim_step_time=0.037, optim0_lr0=3.816e-04, train_time=2.101
[ALab02] 2023-06-08 17:23:24,170 (trainer:721) INFO: 69epoch:train:2683-2831batch: iter_time=0.036, forward_time=0.178, loss_ctc=2.271, loss=2.271, backward_time=0.156, optim_step_time=0.039, optim0_lr0=3.814e-04, train_time=2.039
[ALab02] 2023-06-08 17:24:41,315 (trainer:721) INFO: 69epoch:train:2832-2980batch: iter_time=0.044, forward_time=0.179, loss_ctc=2.184, loss=2.184, backward_time=0.156, optim_step_time=0.039, optim0_lr0=3.813e-04, train_time=2.063
[ALab02] 2023-06-08 17:25:31,485 (trainer:338) INFO: 69epoch results: [train] iter_time=0.029, forward_time=0.177, loss_ctc=2.248, loss=2.248, backward_time=0.155, optim_step_time=0.037, optim0_lr0=3.826e-04, train_time=2.026, time=25 minutes and 16.89 seconds, total_count=206586, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=16.023, cer_ctc=0.332, cer=0.332, loss=16.023, time=14.79 seconds, total_count=2070, gpu_max_cached_mem_GB=52.041, [att_plot] time=28.25 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 17:25:34,126 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 17:25:34,128 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/68epoch.pth
[ALab02] 2023-06-08 17:25:34,128 (trainer:272) INFO: 70/70epoch started. Estimated time to finish: 26 minutes and 43.81 seconds
[ALab02] 2023-06-08 17:26:51,707 (trainer:721) INFO: 70epoch:train:1-149batch: iter_time=0.040, forward_time=0.179, loss_ctc=2.182, loss=2.182, backward_time=0.155, optim_step_time=0.040, optim0_lr0=3.811e-04, train_time=2.088
[ALab02] 2023-06-08 17:28:09,870 (trainer:721) INFO: 70epoch:train:150-298batch: iter_time=0.044, forward_time=0.180, loss_ctc=2.141, loss=2.141, backward_time=0.156, optim_step_time=0.040, optim0_lr0=3.810e-04, train_time=2.100
[ALab02] 2023-06-08 17:29:24,429 (trainer:721) INFO: 70epoch:train:299-447batch: iter_time=0.002, forward_time=0.177, loss_ctc=2.183, loss=2.183, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.809e-04, train_time=1.999
[ALab02] 2023-06-08 17:30:39,810 (trainer:721) INFO: 70epoch:train:448-596batch: iter_time=0.010, forward_time=0.180, loss_ctc=2.220, loss=2.220, backward_time=0.157, optim_step_time=0.036, optim0_lr0=3.807e-04, train_time=2.019
[ALab02] 2023-06-08 17:31:54,727 (trainer:721) INFO: 70epoch:train:597-745batch: iter_time=0.016, forward_time=0.178, loss_ctc=2.147, loss=2.147, backward_time=0.155, optim_step_time=0.037, optim0_lr0=3.806e-04, train_time=2.016
[ALab02] 2023-06-08 17:33:09,344 (trainer:721) INFO: 70epoch:train:746-894batch: iter_time=0.005, forward_time=0.178, loss_ctc=2.215, loss=2.215, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.804e-04, train_time=2.006
[ALab02] 2023-06-08 17:34:23,991 (trainer:721) INFO: 70epoch:train:895-1043batch: iter_time=3.247e-04, forward_time=0.176, loss_ctc=2.194, loss=2.194, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.803e-04, train_time=2.000
[ALab02] 2023-06-08 17:35:41,295 (trainer:721) INFO: 70epoch:train:1044-1192batch: iter_time=0.044, forward_time=0.176, loss_ctc=2.186, loss=2.186, backward_time=0.154, optim_step_time=0.040, optim0_lr0=3.802e-04, train_time=2.069
[ALab02] 2023-06-08 17:36:55,144 (trainer:721) INFO: 70epoch:train:1193-1341batch: iter_time=0.004, forward_time=0.174, loss_ctc=2.240, loss=2.240, backward_time=0.155, optim_step_time=0.037, optim0_lr0=3.800e-04, train_time=1.987
[ALab02] 2023-06-08 17:38:10,578 (trainer:721) INFO: 70epoch:train:1342-1490batch: iter_time=0.009, forward_time=0.180, loss_ctc=2.208, loss=2.208, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.799e-04, train_time=2.026
[ALab02] 2023-06-08 17:39:25,885 (trainer:721) INFO: 70epoch:train:1491-1639batch: iter_time=0.028, forward_time=0.176, loss_ctc=2.174, loss=2.174, backward_time=0.154, optim_step_time=0.036, optim0_lr0=3.798e-04, train_time=2.013
[ALab02] 2023-06-08 17:40:41,315 (trainer:721) INFO: 70epoch:train:1640-1788batch: iter_time=0.008, forward_time=0.178, loss_ctc=2.259, loss=2.259, backward_time=0.157, optim_step_time=0.034, optim0_lr0=3.796e-04, train_time=2.026
[ALab02] 2023-06-08 17:41:57,288 (trainer:721) INFO: 70epoch:train:1789-1937batch: iter_time=0.058, forward_time=0.177, loss_ctc=2.213, loss=2.213, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.795e-04, train_time=2.043
[ALab02] 2023-06-08 17:43:12,878 (trainer:721) INFO: 70epoch:train:1938-2086batch: iter_time=0.055, forward_time=0.173, loss_ctc=2.174, loss=2.174, backward_time=0.156, optim_step_time=0.037, optim0_lr0=3.794e-04, train_time=2.029
[ALab02] 2023-06-08 17:44:27,889 (trainer:721) INFO: 70epoch:train:2087-2235batch: iter_time=0.050, forward_time=0.168, loss_ctc=2.238, loss=2.238, backward_time=0.158, optim_step_time=0.034, optim0_lr0=3.792e-04, train_time=2.015
[ALab02] 2023-06-08 17:45:44,771 (trainer:721) INFO: 70epoch:train:2236-2384batch: iter_time=0.085, forward_time=0.166, loss_ctc=2.158, loss=2.158, backward_time=0.154, optim_step_time=0.037, optim0_lr0=3.791e-04, train_time=2.058
[ALab02] 2023-06-08 17:46:57,633 (trainer:721) INFO: 70epoch:train:2385-2533batch: iter_time=0.025, forward_time=0.165, loss_ctc=2.304, loss=2.304, backward_time=0.155, optim_step_time=0.036, optim0_lr0=3.789e-04, train_time=1.961
[ALab02] 2023-06-08 17:48:12,217 (trainer:721) INFO: 70epoch:train:2534-2682batch: iter_time=0.061, forward_time=0.166, loss_ctc=2.237, loss=2.237, backward_time=0.153, optim_step_time=0.037, optim0_lr0=3.788e-04, train_time=2.003
[ALab02] 2023-06-08 17:49:25,759 (trainer:721) INFO: 70epoch:train:2683-2831batch: iter_time=0.024, forward_time=0.165, loss_ctc=2.264, loss=2.264, backward_time=0.156, optim_step_time=0.036, optim0_lr0=3.787e-04, train_time=1.973
[ALab02] 2023-06-08 17:50:37,900 (trainer:721) INFO: 70epoch:train:2832-2980batch: iter_time=0.009, forward_time=0.164, loss_ctc=2.225, loss=2.225, backward_time=0.153, optim_step_time=0.035, optim0_lr0=3.785e-04, train_time=1.932
[ALab02] 2023-06-08 17:51:28,184 (trainer:338) INFO: 70epoch results: [train] iter_time=0.029, forward_time=0.174, loss_ctc=2.206, loss=2.206, backward_time=0.155, optim_step_time=0.037, optim0_lr0=3.798e-04, train_time=2.018, time=25 minutes and 10.9 seconds, total_count=209580, gpu_max_cached_mem_GB=52.041, [valid] loss_ctc=16.401, cer_ctc=0.318, cer=0.318, loss=16.401, time=15.03 seconds, total_count=2100, gpu_max_cached_mem_GB=52.041, [att_plot] time=28.13 seconds, total_count=0, gpu_max_cached_mem_GB=52.041
[ALab02] 2023-06-08 17:51:30,908 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-08 17:51:30,909 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/69epoch.pth
[ALab02] 2023-06-08 17:51:30,909 (trainer:458) INFO: The training was finished at 70 epochs 
[ALab02] 2023-06-08 17:51:30,931 (average_nbest_models:69) INFO: Averaging 10best models: criterion="valid.cer": exp_uma_conformer_12e_67/asr_train_asr_uma_conformer_raw_zh_char_sp/valid.cer.ave_10best.pth
# Accounting: time=112237 threads=1
# Ended (code 0) at Thu Jun  8 17:51:37 CST 2023, elapsed time 112237 seconds
