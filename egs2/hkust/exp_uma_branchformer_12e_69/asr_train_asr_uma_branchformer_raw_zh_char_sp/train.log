# python3 -m espnet2.bin.asr_unimodal_train --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/train_dev/wav.scp,speech,sound --valid_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp --config conf/train_asr_uma_branchformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_nodup_sp/wav.scp,speech,sound --train_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_nodup_sp/text,text,text --train_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/train_dev/text,text,text --valid_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Jun  9 12:10:32 CST 2023
#
/data/home/fangying/anaconda3/envs/espnet/bin/python3 /data/home/fangying/espnet/espnet2/bin/asr_unimodal_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/train_dev/wav.scp,speech,sound --valid_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp --config conf/train_asr_uma_branchformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_nodup_sp/wav.scp,speech,sound --train_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_nodup_sp/text,text,text --train_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/train_dev/text,text,text --valid_shape_file exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 1 --multiprocessing_distributed True
[ALab02] 2023-06-09 12:10:35,490 (asr_unimodal:512) INFO: Vocabulary size: 3655
[ALab02] 2023-06-09 12:10:38,098 (abs_task:1201) INFO: pytorch.version=1.12.1, cuda.available=True, cudnn.version=8302, cudnn.benchmark=False, cudnn.deterministic=True
[ALab02] 2023-06-09 12:10:38,105 (abs_task:1202) INFO: Model structure:
UAMASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=128, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 27], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): EBranchformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (1): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (2): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (3): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (4): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (5): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (6): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (7): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (8): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (9): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (10): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (11): EBranchformerEncoderLayer(
        (attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (cgmlp): ConvolutionalGatingMLP(
          (channel_proj1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate=none)
          )
          (csgu): ConvolutionalSpatialGatingUnit(
            (norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
            (act): Identity()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_proj2): Linear(in_features=512, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_mlp): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (depthwise_conv_fusion): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
        (merge_proj): Linear(in_features=512, out_features=256, bias=True)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (uma): UMA(
    (linear_sigmoid): Sequential(
      (0): Linear(in_features=256, out_features=1, bias=True)
      (1): Sigmoid()
    )
  )
  (decoder): UnimodalAttentionDecoder(
    (embed): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): ReLU()
      (4): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=3655, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: UAMASRModel
    Total Number of model parameters: 34.05 M
    Number of trainable parameters: 34.05 M (100.0%)
    Size: 136.18 MB
    Type: torch.float32
[ALab02] 2023-06-09 12:10:38,105 (abs_task:1205) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.001
    lr: 2.8571428571428575e-08
    maximize: False
    weight_decay: 1e-06
)
[ALab02] 2023-06-09 12:10:38,105 (abs_task:1206) INFO: Scheduler: WarmupLR(warmup_steps=35000)
[ALab02] 2023-06-09 12:10:38,105 (abs_task:1215) INFO: Saving the configuration in exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/config.yaml
[ALab02] 2023-06-09 12:10:39,266 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02] 2023-06-09 12:10:43,699 (abs_task:1570) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_nodup_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_nodup_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f99a33dfa60>)
[ALab02] 2023-06-09 12:10:43,699 (abs_task:1571) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=1553, batch_bins=40000000, sort_in_batch=descending, sort_batch=descending)
[ALab02] 2023-06-09 12:10:43,700 (abs_task:1572) INFO: [train] mini-batch sizes summary: N-batch=1553, mean=322.3, min=59, max=1630
[ALab02] 2023-06-09 12:10:43,727 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02] 2023-06-09 12:10:43,750 (abs_task:1570) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f99a33dfe50>)
[ALab02] 2023-06-09 12:10:43,750 (abs_task:1571) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=16, batch_bins=40000000, sort_in_batch=descending, sort_batch=descending)
[ALab02] 2023-06-09 12:10:43,750 (abs_task:1572) INFO: [valid] mini-batch sizes summary: N-batch=16, mean=250.0, min=111, max=508
[ALab02] 2023-06-09 12:10:43,757 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02] 2023-06-09 12:10:43,778 (abs_task:1570) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f99a33dfe20>)
[ALab02] 2023-06-09 12:10:43,778 (abs_task:1571) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=4000, batch_size=1, key_file=exp_uma_branchformer_12e_69/asr_stats_raw_zh_char_sp/valid/speech_shape, 
[ALab02] 2023-06-09 12:10:43,778 (abs_task:1572) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
[ALab02] 2023-06-09 12:10:43,971 (trainer:284) INFO: 1/70epoch started
[ALab02] 2023-06-09 12:11:34,833 (trainer:721) INFO: 1epoch:train:1-77batch: iter_time=0.013, forward_time=0.259, loss_ctc=283.813, loss=283.813, backward_time=0.306, optim_step_time=0.037, optim0_lr0=1.143e-06, train_time=0.660
[ALab02] 2023-06-09 12:12:22,660 (trainer:721) INFO: 1epoch:train:78-154batch: iter_time=1.337e-04, forward_time=0.236, loss_ctc=137.729, loss=137.729, backward_time=0.305, optim_step_time=0.038, optim0_lr0=3.343e-06, train_time=0.621
[ALab02] 2023-06-09 12:13:10,615 (trainer:721) INFO: 1epoch:train:155-231batch: iter_time=1.264e-04, forward_time=0.236, loss_ctc=123.050, loss=123.050, backward_time=0.308, optim_step_time=0.036, optim0_lr0=5.543e-06, train_time=0.623
[ALab02] 2023-06-09 12:13:56,773 (trainer:721) INFO: 1epoch:train:232-308batch: iter_time=1.520e-04, forward_time=0.224, loss_ctc=111.423, loss=111.423, backward_time=0.303, optim_step_time=0.035, optim0_lr0=7.743e-06, train_time=0.599
[ALab02] 2023-06-09 12:14:45,285 (trainer:721) INFO: 1epoch:train:309-385batch: iter_time=1.947e-04, forward_time=0.240, loss_ctc=95.923, loss=95.923, backward_time=0.307, optim_step_time=0.038, optim0_lr0=9.943e-06, train_time=0.630
[ALab02] 2023-06-09 12:15:32,642 (trainer:721) INFO: 1epoch:train:386-462batch: iter_time=1.335e-04, forward_time=0.231, loss_ctc=80.646, loss=80.646, backward_time=0.305, optim_step_time=0.036, optim0_lr0=1.214e-05, train_time=0.615
[ALab02] 2023-06-09 12:16:19,876 (trainer:721) INFO: 1epoch:train:463-539batch: iter_time=1.543e-04, forward_time=0.229, loss_ctc=82.104, loss=82.104, backward_time=0.307, optim_step_time=0.036, optim0_lr0=1.434e-05, train_time=0.613
[ALab02] 2023-06-09 12:17:06,796 (trainer:721) INFO: 1epoch:train:540-616batch: iter_time=1.311e-04, forward_time=0.227, loss_ctc=82.640, loss=82.640, backward_time=0.304, optim_step_time=0.037, optim0_lr0=1.654e-05, train_time=0.609
[ALab02] 2023-06-09 12:17:53,603 (trainer:721) INFO: 1epoch:train:617-693batch: iter_time=1.247e-04, forward_time=0.228, loss_ctc=72.482, loss=72.482, backward_time=0.303, optim_step_time=0.036, optim0_lr0=1.874e-05, train_time=0.608
[ALab02] 2023-06-09 12:18:41,433 (trainer:721) INFO: 1epoch:train:694-770batch: iter_time=1.348e-04, forward_time=0.235, loss_ctc=75.700, loss=75.700, backward_time=0.304, optim_step_time=0.037, optim0_lr0=2.094e-05, train_time=0.621
[ALab02] 2023-06-09 12:19:29,018 (trainer:721) INFO: 1epoch:train:771-847batch: iter_time=1.183e-04, forward_time=0.234, loss_ctc=64.365, loss=64.365, backward_time=0.305, optim_step_time=0.038, optim0_lr0=2.314e-05, train_time=0.618
[ALab02] 2023-06-09 12:20:16,605 (trainer:721) INFO: 1epoch:train:848-924batch: iter_time=1.366e-04, forward_time=0.233, loss_ctc=75.606, loss=75.606, backward_time=0.303, optim_step_time=0.037, optim0_lr0=2.534e-05, train_time=0.618
[ALab02] 2023-06-09 12:21:04,132 (trainer:721) INFO: 1epoch:train:925-1001batch: iter_time=1.108e-04, forward_time=0.232, loss_ctc=75.771, loss=75.771, backward_time=0.302, optim_step_time=0.037, optim0_lr0=2.754e-05, train_time=0.617
[ALab02] 2023-06-09 12:21:51,654 (trainer:721) INFO: 1epoch:train:1002-1078batch: iter_time=1.327e-04, forward_time=0.233, loss_ctc=79.779, loss=79.779, backward_time=0.304, optim_step_time=0.037, optim0_lr0=2.974e-05, train_time=0.617
[ALab02] 2023-06-09 12:22:38,221 (trainer:721) INFO: 1epoch:train:1079-1155batch: iter_time=1.209e-04, forward_time=0.226, loss_ctc=71.153, loss=71.153, backward_time=0.301, optim_step_time=0.037, optim0_lr0=3.194e-05, train_time=0.605
[ALab02] 2023-06-09 12:23:26,091 (trainer:721) INFO: 1epoch:train:1156-1232batch: iter_time=1.718e-04, forward_time=0.236, loss_ctc=60.122, loss=60.122, backward_time=0.306, optim_step_time=0.036, optim0_lr0=3.414e-05, train_time=0.621
[ALab02] 2023-06-09 12:24:13,519 (trainer:721) INFO: 1epoch:train:1233-1309batch: iter_time=1.400e-04, forward_time=0.233, loss_ctc=66.493, loss=66.493, backward_time=0.306, optim_step_time=0.037, optim0_lr0=3.634e-05, train_time=0.616
[ALab02] 2023-06-09 12:25:01,790 (trainer:721) INFO: 1epoch:train:1310-1386batch: iter_time=1.386e-04, forward_time=0.238, loss_ctc=62.624, loss=62.624, backward_time=0.309, optim_step_time=0.036, optim0_lr0=3.854e-05, train_time=0.627
[ALab02] 2023-06-09 12:25:49,838 (trainer:721) INFO: 1epoch:train:1387-1463batch: iter_time=3.369e-04, forward_time=0.236, loss_ctc=66.882, loss=66.882, backward_time=0.303, optim_step_time=0.042, optim0_lr0=4.074e-05, train_time=0.624
[ALab02] 2023-06-09 12:26:37,297 (trainer:721) INFO: 1epoch:train:1464-1540batch: iter_time=1.363e-04, forward_time=0.234, loss_ctc=62.245, loss=62.245, backward_time=0.304, optim_step_time=0.036, optim0_lr0=4.294e-05, train_time=0.616
[ALab02] 2023-06-09 12:27:25,362 (trainer:338) INFO: 1epoch results: [train] iter_time=8.083e-04, forward_time=0.234, loss_ctc=90.724, loss=90.724, backward_time=0.305, optim_step_time=0.037, optim0_lr0=2.223e-05, train_time=0.618, time=16 minutes and 0.97 seconds, total_count=1553, gpu_max_cached_mem_GB=50.539, [valid] loss_ctc=70.840, cer_ctc=0.999, cer=0.999, loss=70.840, time=9.79 seconds, total_count=16, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.61 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 12:27:27,410 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 12:27:27,411 (trainer:272) INFO: 2/70epoch started. Estimated time to finish: 19 hours, 13 minutes and 57.36 seconds
[ALab02] 2023-06-09 12:28:14,864 (trainer:721) INFO: 2epoch:train:1-77batch: iter_time=0.014, forward_time=0.224, loss_ctc=77.940, loss=77.940, backward_time=0.298, optim_step_time=0.037, optim0_lr0=4.551e-05, train_time=0.616
[ALab02] 2023-06-09 12:29:01,468 (trainer:721) INFO: 2epoch:train:78-154batch: iter_time=1.558e-04, forward_time=0.227, loss_ctc=69.217, loss=69.217, backward_time=0.301, optim_step_time=0.037, optim0_lr0=4.771e-05, train_time=0.605
[ALab02] 2023-06-09 12:29:49,027 (trainer:721) INFO: 2epoch:train:155-231batch: iter_time=1.231e-04, forward_time=0.233, loss_ctc=64.233, loss=64.233, backward_time=0.307, optim_step_time=0.038, optim0_lr0=4.991e-05, train_time=0.617
[ALab02] 2023-06-09 12:30:36,178 (trainer:721) INFO: 2epoch:train:232-308batch: iter_time=1.530e-04, forward_time=0.227, loss_ctc=69.278, loss=69.278, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.211e-05, train_time=0.612
[ALab02] 2023-06-09 12:31:23,339 (trainer:721) INFO: 2epoch:train:309-385batch: iter_time=1.590e-04, forward_time=0.231, loss_ctc=65.464, loss=65.464, backward_time=0.300, optim_step_time=0.037, optim0_lr0=5.431e-05, train_time=0.612
[ALab02] 2023-06-09 12:32:11,164 (trainer:721) INFO: 2epoch:train:386-462batch: iter_time=1.407e-04, forward_time=0.234, loss_ctc=60.243, loss=60.243, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.651e-05, train_time=0.621
[ALab02] 2023-06-09 12:32:58,794 (trainer:721) INFO: 2epoch:train:463-539batch: iter_time=1.496e-04, forward_time=0.232, loss_ctc=64.235, loss=64.235, backward_time=0.303, optim_step_time=0.037, optim0_lr0=5.871e-05, train_time=0.618
[ALab02] 2023-06-09 12:33:45,377 (trainer:721) INFO: 2epoch:train:540-616batch: iter_time=1.511e-04, forward_time=0.226, loss_ctc=67.903, loss=67.903, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.091e-05, train_time=0.605
[ALab02] 2023-06-09 12:34:32,475 (trainer:721) INFO: 2epoch:train:617-693batch: iter_time=1.429e-04, forward_time=0.228, loss_ctc=69.673, loss=69.673, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.311e-05, train_time=0.611
[ALab02] 2023-06-09 12:35:26,026 (trainer:721) INFO: 2epoch:train:694-770batch: iter_time=2.517e-04, forward_time=0.287, loss_ctc=66.794, loss=66.794, backward_time=0.318, optim_step_time=0.047, optim0_lr0=6.531e-05, train_time=0.695
[ALab02] 2023-06-09 12:36:30,051 (trainer:721) INFO: 2epoch:train:771-847batch: iter_time=4.862e-04, forward_time=0.384, loss_ctc=58.922, loss=58.922, backward_time=0.327, optim_step_time=0.063, optim0_lr0=6.751e-05, train_time=0.831
[ALab02] 2023-06-09 12:37:24,693 (trainer:721) INFO: 2epoch:train:848-924batch: iter_time=2.529e-04, forward_time=0.293, loss_ctc=62.562, loss=62.562, backward_time=0.315, optim_step_time=0.051, optim0_lr0=6.971e-05, train_time=0.709
[ALab02] 2023-06-09 12:38:12,273 (trainer:721) INFO: 2epoch:train:925-1001batch: iter_time=2.075e-04, forward_time=0.232, loss_ctc=62.825, loss=62.825, backward_time=0.302, optim_step_time=0.038, optim0_lr0=7.191e-05, train_time=0.618
[ALab02] 2023-06-09 12:38:59,020 (trainer:721) INFO: 2epoch:train:1002-1078batch: iter_time=1.424e-04, forward_time=0.226, loss_ctc=67.559, loss=67.559, backward_time=0.300, optim_step_time=0.038, optim0_lr0=7.411e-05, train_time=0.607
[ALab02] 2023-06-09 12:39:46,902 (trainer:721) INFO: 2epoch:train:1079-1155batch: iter_time=2.058e-04, forward_time=0.232, loss_ctc=67.381, loss=67.381, backward_time=0.306, optim_step_time=0.038, optim0_lr0=7.631e-05, train_time=0.622
[ALab02] 2023-06-09 12:40:34,494 (trainer:721) INFO: 2epoch:train:1156-1232batch: iter_time=1.910e-04, forward_time=0.231, loss_ctc=61.334, loss=61.334, backward_time=0.305, optim_step_time=0.039, optim0_lr0=7.851e-05, train_time=0.618
[ALab02] 2023-06-09 12:41:22,684 (trainer:721) INFO: 2epoch:train:1233-1309batch: iter_time=1.430e-04, forward_time=0.237, loss_ctc=62.419, loss=62.419, backward_time=0.307, optim_step_time=0.038, optim0_lr0=8.071e-05, train_time=0.626
[ALab02] 2023-06-09 12:42:10,717 (trainer:721) INFO: 2epoch:train:1310-1386batch: iter_time=1.762e-04, forward_time=0.234, loss_ctc=64.142, loss=64.142, backward_time=0.305, optim_step_time=0.039, optim0_lr0=8.291e-05, train_time=0.624
[ALab02] 2023-06-09 12:42:59,035 (trainer:721) INFO: 2epoch:train:1387-1463batch: iter_time=1.328e-04, forward_time=0.239, loss_ctc=53.660, loss=53.660, backward_time=0.309, optim_step_time=0.038, optim0_lr0=8.511e-05, train_time=0.627
[ALab02] 2023-06-09 12:43:47,275 (trainer:721) INFO: 2epoch:train:1464-1540batch: iter_time=1.644e-04, forward_time=0.240, loss_ctc=55.268, loss=55.268, backward_time=0.306, optim_step_time=0.038, optim0_lr0=8.731e-05, train_time=0.626
[ALab02] 2023-06-09 12:44:31,012 (trainer:338) INFO: 2epoch results: [train] iter_time=8.595e-04, forward_time=0.245, loss_ctc=64.348, loss=64.348, backward_time=0.306, optim_step_time=0.040, optim0_lr0=6.660e-05, train_time=0.636, time=16 minutes and 27.74 seconds, total_count=3106, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=55.179, cer_ctc=0.810, cer=0.810, loss=55.179, time=7.23 seconds, total_count=32, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.62 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 12:44:33,076 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 12:44:33,076 (trainer:272) INFO: 3/70epoch started. Estimated time to finish: 19 hours, 9 minutes and 49.59 seconds
[ALab02] 2023-06-09 12:45:21,163 (trainer:721) INFO: 3epoch:train:1-77batch: iter_time=0.017, forward_time=0.227, loss_ctc=60.116, loss=60.116, backward_time=0.297, optim_step_time=0.037, optim0_lr0=8.989e-05, train_time=0.624
[ALab02] 2023-06-09 12:46:09,470 (trainer:721) INFO: 3epoch:train:78-154batch: iter_time=1.600e-04, forward_time=0.241, loss_ctc=45.794, loss=45.794, backward_time=0.308, optim_step_time=0.036, optim0_lr0=9.209e-05, train_time=0.627
[ALab02] 2023-06-09 12:46:57,382 (trainer:721) INFO: 3epoch:train:155-231batch: iter_time=1.736e-04, forward_time=0.234, loss_ctc=57.667, loss=57.667, backward_time=0.305, optim_step_time=0.039, optim0_lr0=9.429e-05, train_time=0.622
[ALab02] 2023-06-09 12:47:45,603 (trainer:721) INFO: 3epoch:train:232-308batch: iter_time=1.853e-04, forward_time=0.235, loss_ctc=55.586, loss=55.586, backward_time=0.309, optim_step_time=0.038, optim0_lr0=9.649e-05, train_time=0.626
[ALab02] 2023-06-09 12:48:32,550 (trainer:721) INFO: 3epoch:train:309-385batch: iter_time=1.947e-04, forward_time=0.228, loss_ctc=62.298, loss=62.298, backward_time=0.300, optim_step_time=0.038, optim0_lr0=9.869e-05, train_time=0.609
[ALab02] 2023-06-09 12:49:20,010 (trainer:721) INFO: 3epoch:train:386-462batch: iter_time=1.858e-04, forward_time=0.232, loss_ctc=59.490, loss=59.490, backward_time=0.303, optim_step_time=0.039, optim0_lr0=1.009e-04, train_time=0.616
[ALab02] 2023-06-09 12:50:07,390 (trainer:721) INFO: 3epoch:train:463-539batch: iter_time=1.594e-04, forward_time=0.230, loss_ctc=60.149, loss=60.149, backward_time=0.304, optim_step_time=0.037, optim0_lr0=1.031e-04, train_time=0.615
[ALab02] 2023-06-09 12:50:55,301 (trainer:721) INFO: 3epoch:train:540-616batch: iter_time=1.979e-04, forward_time=0.238, loss_ctc=47.637, loss=47.637, backward_time=0.305, optim_step_time=0.038, optim0_lr0=1.053e-04, train_time=0.622
[ALab02] 2023-06-09 12:51:55,079 (trainer:721) INFO: 3epoch:train:617-693batch: iter_time=7.773e-04, forward_time=0.322, loss_ctc=49.743, loss=49.743, backward_time=0.318, optim_step_time=0.073, optim0_lr0=1.075e-04, train_time=0.776
[ALab02] 2023-06-09 12:52:50,485 (trainer:721) INFO: 3epoch:train:694-770batch: iter_time=6.986e-04, forward_time=0.288, loss_ctc=50.769, loss=50.769, backward_time=0.308, optim_step_time=0.063, optim0_lr0=1.097e-04, train_time=0.719
[ALab02] 2023-06-09 12:53:39,244 (trainer:721) INFO: 3epoch:train:771-847batch: iter_time=2.681e-04, forward_time=0.239, loss_ctc=50.072, loss=50.072, backward_time=0.304, optim_step_time=0.045, optim0_lr0=1.119e-04, train_time=0.633
[ALab02] 2023-06-09 12:54:44,759 (trainer:721) INFO: 3epoch:train:848-924batch: iter_time=9.423e-04, forward_time=0.374, loss_ctc=46.721, loss=46.721, backward_time=0.323, optim_step_time=0.087, optim0_lr0=1.141e-04, train_time=0.850
[ALab02] 2023-06-09 12:55:32,037 (trainer:721) INFO: 3epoch:train:925-1001batch: iter_time=2.326e-04, forward_time=0.233, loss_ctc=47.874, loss=47.874, backward_time=0.302, optim_step_time=0.040, optim0_lr0=1.163e-04, train_time=0.614
[ALab02] 2023-06-09 12:56:19,763 (trainer:721) INFO: 3epoch:train:1002-1078batch: iter_time=1.658e-04, forward_time=0.233, loss_ctc=50.097, loss=50.097, backward_time=0.304, optim_step_time=0.038, optim0_lr0=1.185e-04, train_time=0.620
[ALab02] 2023-06-09 12:57:07,095 (trainer:721) INFO: 3epoch:train:1079-1155batch: iter_time=1.411e-04, forward_time=0.233, loss_ctc=50.912, loss=50.912, backward_time=0.305, optim_step_time=0.036, optim0_lr0=1.207e-04, train_time=0.614
[ALab02] 2023-06-09 12:57:55,341 (trainer:721) INFO: 3epoch:train:1156-1232batch: iter_time=1.762e-04, forward_time=0.236, loss_ctc=57.686, loss=57.686, backward_time=0.307, optim_step_time=0.039, optim0_lr0=1.229e-04, train_time=0.626
[ALab02] 2023-06-09 12:58:43,146 (trainer:721) INFO: 3epoch:train:1233-1309batch: iter_time=1.513e-04, forward_time=0.236, loss_ctc=43.129, loss=43.129, backward_time=0.306, optim_step_time=0.038, optim0_lr0=1.251e-04, train_time=0.621
[ALab02] 2023-06-09 12:59:30,752 (trainer:721) INFO: 3epoch:train:1310-1386batch: iter_time=1.426e-04, forward_time=0.235, loss_ctc=48.438, loss=48.438, backward_time=0.303, optim_step_time=0.037, optim0_lr0=1.273e-04, train_time=0.618
[ALab02] 2023-06-09 13:00:18,051 (trainer:721) INFO: 3epoch:train:1387-1463batch: iter_time=1.250e-04, forward_time=0.229, loss_ctc=48.494, loss=48.494, backward_time=0.301, optim_step_time=0.037, optim0_lr0=1.295e-04, train_time=0.614
[ALab02] 2023-06-09 13:01:06,218 (trainer:721) INFO: 3epoch:train:1464-1540batch: iter_time=1.447e-04, forward_time=0.235, loss_ctc=45.362, loss=45.362, backward_time=0.309, optim_step_time=0.038, optim0_lr0=1.317e-04, train_time=0.625
[ALab02] 2023-06-09 13:01:48,583 (trainer:338) INFO: 3epoch results: [train] iter_time=0.001, forward_time=0.248, loss_ctc=51.500, loss=51.500, backward_time=0.306, optim_step_time=0.044, optim0_lr0=1.110e-04, train_time=0.644, time=16 minutes and 41.35 seconds, total_count=4659, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=37.891, cer_ctc=0.643, cer=0.643, loss=37.891, time=6.72 seconds, total_count=48, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.44 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 13:01:50,620 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 13:01:50,620 (trainer:272) INFO: 4/70epoch started. Estimated time to finish: 19 hours, 1 minute and 28.51 seconds
[ALab02] 2023-06-09 13:02:39,861 (trainer:721) INFO: 4epoch:train:1-77batch: iter_time=0.013, forward_time=0.239, loss_ctc=41.774, loss=41.774, backward_time=0.305, optim_step_time=0.037, optim0_lr0=1.343e-04, train_time=0.639
[ALab02] 2023-06-09 13:03:27,498 (trainer:721) INFO: 4epoch:train:78-154batch: iter_time=1.438e-04, forward_time=0.231, loss_ctc=42.156, loss=42.156, backward_time=0.308, optim_step_time=0.037, optim0_lr0=1.365e-04, train_time=0.618
[ALab02] 2023-06-09 13:04:13,785 (trainer:721) INFO: 4epoch:train:155-231batch: iter_time=1.473e-04, forward_time=0.222, loss_ctc=53.580, loss=53.580, backward_time=0.298, optim_step_time=0.037, optim0_lr0=1.387e-04, train_time=0.601
[ALab02] 2023-06-09 13:05:01,485 (trainer:721) INFO: 4epoch:train:232-308batch: iter_time=1.326e-04, forward_time=0.233, loss_ctc=41.807, loss=41.807, backward_time=0.303, optim_step_time=0.037, optim0_lr0=1.409e-04, train_time=0.619
[ALab02] 2023-06-09 13:05:47,608 (trainer:721) INFO: 4epoch:train:309-385batch: iter_time=1.448e-04, forward_time=0.222, loss_ctc=47.620, loss=47.620, backward_time=0.302, optim_step_time=0.036, optim0_lr0=1.431e-04, train_time=0.599
[ALab02] 2023-06-09 13:06:36,011 (trainer:721) INFO: 4epoch:train:386-462batch: iter_time=1.520e-04, forward_time=0.240, loss_ctc=43.646, loss=43.646, backward_time=0.306, optim_step_time=0.038, optim0_lr0=1.453e-04, train_time=0.628
[ALab02] 2023-06-09 13:07:21,769 (trainer:721) INFO: 4epoch:train:463-539batch: iter_time=2.053e-04, forward_time=0.220, loss_ctc=46.162, loss=46.162, backward_time=0.299, optim_step_time=0.036, optim0_lr0=1.475e-04, train_time=0.594
[ALab02] 2023-06-09 13:08:09,519 (trainer:721) INFO: 4epoch:train:540-616batch: iter_time=2.011e-04, forward_time=0.233, loss_ctc=44.073, loss=44.073, backward_time=0.305, optim_step_time=0.040, optim0_lr0=1.497e-04, train_time=0.620
[ALab02] 2023-06-09 13:08:57,011 (trainer:721) INFO: 4epoch:train:617-693batch: iter_time=1.438e-04, forward_time=0.230, loss_ctc=47.101, loss=47.101, backward_time=0.303, optim_step_time=0.038, optim0_lr0=1.519e-04, train_time=0.617
[ALab02] 2023-06-09 13:09:45,575 (trainer:721) INFO: 4epoch:train:694-770batch: iter_time=1.822e-04, forward_time=0.242, loss_ctc=36.213, loss=36.213, backward_time=0.310, optim_step_time=0.038, optim0_lr0=1.541e-04, train_time=0.630
[ALab02] 2023-06-09 13:10:31,762 (trainer:721) INFO: 4epoch:train:771-847batch: iter_time=1.705e-04, forward_time=0.221, loss_ctc=43.533, loss=43.533, backward_time=0.301, optim_step_time=0.036, optim0_lr0=1.563e-04, train_time=0.600
[ALab02] 2023-06-09 13:11:19,176 (trainer:721) INFO: 4epoch:train:848-924batch: iter_time=1.198e-04, forward_time=0.231, loss_ctc=36.964, loss=36.964, backward_time=0.305, optim_step_time=0.036, optim0_lr0=1.585e-04, train_time=0.616
[ALab02] 2023-06-09 13:12:08,132 (trainer:721) INFO: 4epoch:train:925-1001batch: iter_time=1.530e-04, forward_time=0.242, loss_ctc=37.523, loss=37.523, backward_time=0.312, optim_step_time=0.038, optim0_lr0=1.607e-04, train_time=0.636
[ALab02] 2023-06-09 13:12:55,957 (trainer:721) INFO: 4epoch:train:1002-1078batch: iter_time=1.479e-04, forward_time=0.230, loss_ctc=46.856, loss=46.856, backward_time=0.308, optim_step_time=0.037, optim0_lr0=1.629e-04, train_time=0.621
[ALab02] 2023-06-09 13:13:43,638 (trainer:721) INFO: 4epoch:train:1079-1155batch: iter_time=1.448e-04, forward_time=0.231, loss_ctc=48.083, loss=48.083, backward_time=0.307, optim_step_time=0.037, optim0_lr0=1.651e-04, train_time=0.619
[ALab02] 2023-06-09 13:14:31,122 (trainer:721) INFO: 4epoch:train:1156-1232batch: iter_time=1.389e-04, forward_time=0.232, loss_ctc=39.484, loss=39.484, backward_time=0.304, optim_step_time=0.037, optim0_lr0=1.673e-04, train_time=0.616
[ALab02] 2023-06-09 13:15:18,318 (trainer:721) INFO: 4epoch:train:1233-1309batch: iter_time=1.657e-04, forward_time=0.231, loss_ctc=40.954, loss=40.954, backward_time=0.303, optim_step_time=0.038, optim0_lr0=1.695e-04, train_time=0.613
[ALab02] 2023-06-09 13:16:10,752 (trainer:721) INFO: 4epoch:train:1310-1386batch: iter_time=2.582e-04, forward_time=0.273, loss_ctc=37.383, loss=37.383, backward_time=0.307, optim_step_time=0.051, optim0_lr0=1.717e-04, train_time=0.681
[ALab02] 2023-06-09 13:16:57,445 (trainer:721) INFO: 4epoch:train:1387-1463batch: iter_time=1.379e-04, forward_time=0.228, loss_ctc=38.037, loss=38.037, backward_time=0.299, optim_step_time=0.037, optim0_lr0=1.739e-04, train_time=0.606
[ALab02] 2023-06-09 13:17:44,985 (trainer:721) INFO: 4epoch:train:1464-1540batch: iter_time=1.450e-04, forward_time=0.232, loss_ctc=37.202, loss=37.202, backward_time=0.308, optim_step_time=0.036, optim0_lr0=1.761e-04, train_time=0.617
[ALab02] 2023-06-09 13:18:27,070 (trainer:338) INFO: 4epoch results: [train] iter_time=8.080e-04, forward_time=0.233, loss_ctc=42.222, loss=42.222, backward_time=0.304, optim_step_time=0.038, optim0_lr0=1.553e-04, train_time=0.619, time=16 minutes and 2.1 seconds, total_count=6212, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=29.374, cer_ctc=0.539, cer=0.539, loss=29.374, time=6.63 seconds, total_count=64, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.72 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 13:18:29,068 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 13:18:29,068 (trainer:272) INFO: 5/70epoch started. Estimated time to finish: 18 hours, 37 minutes and 54.11 seconds
[ALab02] 2023-06-09 13:19:18,645 (trainer:721) INFO: 5epoch:train:1-77batch: iter_time=0.014, forward_time=0.237, loss_ctc=39.183, loss=39.183, backward_time=0.310, optim_step_time=0.039, optim0_lr0=1.786e-04, train_time=0.644
[ALab02] 2023-06-09 13:20:07,129 (trainer:721) INFO: 5epoch:train:78-154batch: iter_time=3.171e-04, forward_time=0.241, loss_ctc=35.782, loss=35.782, backward_time=0.304, optim_step_time=0.040, optim0_lr0=1.808e-04, train_time=0.629
[ALab02] 2023-06-09 13:20:54,370 (trainer:721) INFO: 5epoch:train:155-231batch: iter_time=1.461e-04, forward_time=0.231, loss_ctc=35.588, loss=35.588, backward_time=0.303, optim_step_time=0.037, optim0_lr0=1.830e-04, train_time=0.613
[ALab02] 2023-06-09 13:21:42,100 (trainer:721) INFO: 5epoch:train:232-308batch: iter_time=1.450e-04, forward_time=0.234, loss_ctc=35.076, loss=35.076, backward_time=0.302, optim_step_time=0.037, optim0_lr0=1.852e-04, train_time=0.620
[ALab02] 2023-06-09 13:22:29,549 (trainer:721) INFO: 5epoch:train:309-385batch: iter_time=1.375e-04, forward_time=0.230, loss_ctc=35.091, loss=35.091, backward_time=0.306, optim_step_time=0.037, optim0_lr0=1.874e-04, train_time=0.616
[ALab02] 2023-06-09 13:23:16,302 (trainer:721) INFO: 5epoch:train:386-462batch: iter_time=1.571e-04, forward_time=0.224, loss_ctc=41.566, loss=41.566, backward_time=0.301, optim_step_time=0.038, optim0_lr0=1.896e-04, train_time=0.607
[ALab02] 2023-06-09 13:24:04,105 (trainer:721) INFO: 5epoch:train:463-539batch: iter_time=1.632e-04, forward_time=0.231, loss_ctc=36.462, loss=36.462, backward_time=0.306, optim_step_time=0.039, optim0_lr0=1.918e-04, train_time=0.621
[ALab02] 2023-06-09 13:24:52,856 (trainer:721) INFO: 5epoch:train:540-616batch: iter_time=1.880e-04, forward_time=0.242, loss_ctc=35.332, loss=35.332, backward_time=0.313, optim_step_time=0.038, optim0_lr0=1.940e-04, train_time=0.633
[ALab02] 2023-06-09 13:25:39,568 (trainer:721) INFO: 5epoch:train:617-693batch: iter_time=1.545e-04, forward_time=0.226, loss_ctc=39.333, loss=39.333, backward_time=0.303, optim_step_time=0.038, optim0_lr0=1.962e-04, train_time=0.606
[ALab02] 2023-06-09 13:26:26,897 (trainer:721) INFO: 5epoch:train:694-770batch: iter_time=1.931e-04, forward_time=0.229, loss_ctc=37.801, loss=37.801, backward_time=0.301, optim_step_time=0.039, optim0_lr0=1.984e-04, train_time=0.614
[ALab02] 2023-06-09 13:27:14,405 (trainer:721) INFO: 5epoch:train:771-847batch: iter_time=1.707e-04, forward_time=0.231, loss_ctc=36.227, loss=36.227, backward_time=0.307, optim_step_time=0.037, optim0_lr0=2.006e-04, train_time=0.617
[ALab02] 2023-06-09 13:28:01,132 (trainer:721) INFO: 5epoch:train:848-924batch: iter_time=1.502e-04, forward_time=0.225, loss_ctc=37.982, loss=37.982, backward_time=0.302, optim_step_time=0.037, optim0_lr0=2.028e-04, train_time=0.607
[ALab02] 2023-06-09 13:28:48,911 (trainer:721) INFO: 5epoch:train:925-1001batch: iter_time=1.432e-04, forward_time=0.232, loss_ctc=37.307, loss=37.307, backward_time=0.306, optim_step_time=0.038, optim0_lr0=2.050e-04, train_time=0.620
[ALab02] 2023-06-09 13:29:35,624 (trainer:721) INFO: 5epoch:train:1002-1078batch: iter_time=1.696e-04, forward_time=0.224, loss_ctc=37.574, loss=37.574, backward_time=0.303, optim_step_time=0.036, optim0_lr0=2.072e-04, train_time=0.606
[ALab02] 2023-06-09 13:30:23,700 (trainer:721) INFO: 5epoch:train:1079-1155batch: iter_time=1.933e-04, forward_time=0.240, loss_ctc=33.932, loss=33.932, backward_time=0.303, optim_step_time=0.038, optim0_lr0=2.094e-04, train_time=0.624
[ALab02] 2023-06-09 13:31:11,626 (trainer:721) INFO: 5epoch:train:1156-1232batch: iter_time=2.557e-04, forward_time=0.235, loss_ctc=37.692, loss=37.692, backward_time=0.307, optim_step_time=0.038, optim0_lr0=2.116e-04, train_time=0.622
[ALab02] 2023-06-09 13:31:58,995 (trainer:721) INFO: 5epoch:train:1233-1309batch: iter_time=1.463e-04, forward_time=0.231, loss_ctc=36.478, loss=36.478, backward_time=0.298, optim_step_time=0.037, optim0_lr0=2.138e-04, train_time=0.615
[ALab02] 2023-06-09 13:32:47,306 (trainer:721) INFO: 5epoch:train:1310-1386batch: iter_time=1.320e-04, forward_time=0.237, loss_ctc=37.075, loss=37.075, backward_time=0.310, optim_step_time=0.037, optim0_lr0=2.160e-04, train_time=0.627
[ALab02] 2023-06-09 13:33:33,984 (trainer:721) INFO: 5epoch:train:1387-1463batch: iter_time=1.708e-04, forward_time=0.225, loss_ctc=38.633, loss=38.633, backward_time=0.302, optim_step_time=0.039, optim0_lr0=2.182e-04, train_time=0.606
[ALab02] 2023-06-09 13:34:20,572 (trainer:721) INFO: 5epoch:train:1464-1540batch: iter_time=1.361e-04, forward_time=0.225, loss_ctc=38.242, loss=38.242, backward_time=0.297, optim_step_time=0.037, optim0_lr0=2.204e-04, train_time=0.605
[ALab02] 2023-06-09 13:35:01,822 (trainer:338) INFO: 5epoch results: [train] iter_time=8.399e-04, forward_time=0.232, loss_ctc=37.068, loss=37.068, backward_time=0.304, optim_step_time=0.038, optim0_lr0=1.997e-04, train_time=0.618, time=15 minutes and 59.62 seconds, total_count=7765, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=25.432, cer_ctc=0.473, cer=0.473, loss=25.432, time=6.74 seconds, total_count=80, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.39 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 13:35:03,806 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 13:35:03,807 (trainer:272) INFO: 6/70epoch started. Estimated time to finish: 18 hours, 16 minutes and 17.87 seconds
[ALab02] 2023-06-09 13:35:54,003 (trainer:721) INFO: 6epoch:train:1-77batch: iter_time=0.014, forward_time=0.243, loss_ctc=33.391, loss=33.391, backward_time=0.307, optim_step_time=0.039, optim0_lr0=2.230e-04, train_time=0.652
[ALab02] 2023-06-09 13:36:40,916 (trainer:721) INFO: 6epoch:train:78-154batch: iter_time=1.366e-04, forward_time=0.228, loss_ctc=34.656, loss=34.656, backward_time=0.304, optim_step_time=0.038, optim0_lr0=2.252e-04, train_time=0.609
[ALab02] 2023-06-09 13:37:28,398 (trainer:721) INFO: 6epoch:train:155-231batch: iter_time=1.551e-04, forward_time=0.230, loss_ctc=37.792, loss=37.792, backward_time=0.300, optim_step_time=0.038, optim0_lr0=2.274e-04, train_time=0.616
[ALab02] 2023-06-09 13:38:15,712 (trainer:721) INFO: 6epoch:train:232-308batch: iter_time=1.398e-04, forward_time=0.231, loss_ctc=34.739, loss=34.739, backward_time=0.304, optim_step_time=0.038, optim0_lr0=2.296e-04, train_time=0.614
[ALab02] 2023-06-09 13:39:04,408 (trainer:721) INFO: 6epoch:train:309-385batch: iter_time=1.614e-04, forward_time=0.243, loss_ctc=28.816, loss=28.816, backward_time=0.307, optim_step_time=0.038, optim0_lr0=2.318e-04, train_time=0.632
[ALab02] 2023-06-09 13:39:51,483 (trainer:721) INFO: 6epoch:train:386-462batch: iter_time=1.598e-04, forward_time=0.227, loss_ctc=35.065, loss=35.065, backward_time=0.306, optim_step_time=0.038, optim0_lr0=2.340e-04, train_time=0.611
[ALab02] 2023-06-09 13:40:39,308 (trainer:721) INFO: 6epoch:train:463-539batch: iter_time=2.014e-04, forward_time=0.233, loss_ctc=31.233, loss=31.233, backward_time=0.301, optim_step_time=0.042, optim0_lr0=2.362e-04, train_time=0.621
[ALab02] 2023-06-09 13:41:26,936 (trainer:721) INFO: 6epoch:train:540-616batch: iter_time=1.793e-04, forward_time=0.236, loss_ctc=35.452, loss=35.452, backward_time=0.302, optim_step_time=0.039, optim0_lr0=2.384e-04, train_time=0.618
[ALab02] 2023-06-09 13:42:14,246 (trainer:721) INFO: 6epoch:train:617-693batch: iter_time=1.408e-04, forward_time=0.231, loss_ctc=32.194, loss=32.194, backward_time=0.302, optim_step_time=0.038, optim0_lr0=2.406e-04, train_time=0.614
[ALab02] 2023-06-09 13:43:01,606 (trainer:721) INFO: 6epoch:train:694-770batch: iter_time=1.928e-04, forward_time=0.229, loss_ctc=35.473, loss=35.473, backward_time=0.302, optim_step_time=0.040, optim0_lr0=2.428e-04, train_time=0.615
[ALab02] 2023-06-09 13:43:49,838 (trainer:721) INFO: 6epoch:train:771-847batch: iter_time=1.784e-04, forward_time=0.238, loss_ctc=33.102, loss=33.102, backward_time=0.305, optim_step_time=0.039, optim0_lr0=2.450e-04, train_time=0.626
[ALab02] 2023-06-09 13:44:37,679 (trainer:721) INFO: 6epoch:train:848-924batch: iter_time=2.011e-04, forward_time=0.233, loss_ctc=34.383, loss=34.383, backward_time=0.306, optim_step_time=0.040, optim0_lr0=2.472e-04, train_time=0.621
[ALab02] 2023-06-09 13:45:25,802 (trainer:721) INFO: 6epoch:train:925-1001batch: iter_time=1.856e-04, forward_time=0.236, loss_ctc=33.985, loss=33.985, backward_time=0.309, optim_step_time=0.040, optim0_lr0=2.494e-04, train_time=0.625
[ALab02] 2023-06-09 13:46:12,887 (trainer:721) INFO: 6epoch:train:1002-1078batch: iter_time=1.743e-04, forward_time=0.230, loss_ctc=34.566, loss=34.566, backward_time=0.298, optim_step_time=0.039, optim0_lr0=2.516e-04, train_time=0.611
[ALab02] 2023-06-09 13:47:00,439 (trainer:721) INFO: 6epoch:train:1079-1155batch: iter_time=1.407e-04, forward_time=0.231, loss_ctc=39.280, loss=39.280, backward_time=0.302, optim_step_time=0.038, optim0_lr0=2.538e-04, train_time=0.617
[ALab02] 2023-06-09 13:47:47,944 (trainer:721) INFO: 6epoch:train:1156-1232batch: iter_time=1.711e-04, forward_time=0.234, loss_ctc=31.517, loss=31.517, backward_time=0.303, optim_step_time=0.038, optim0_lr0=2.560e-04, train_time=0.617
[ALab02] 2023-06-09 13:48:36,884 (trainer:721) INFO: 6epoch:train:1233-1309batch: iter_time=2.060e-04, forward_time=0.241, loss_ctc=32.149, loss=32.149, backward_time=0.309, optim_step_time=0.040, optim0_lr0=2.582e-04, train_time=0.635
[ALab02] 2023-06-09 13:49:24,229 (trainer:721) INFO: 6epoch:train:1310-1386batch: iter_time=1.428e-04, forward_time=0.232, loss_ctc=31.413, loss=31.413, backward_time=0.302, optim_step_time=0.038, optim0_lr0=2.604e-04, train_time=0.615
[ALab02] 2023-06-09 13:50:12,865 (trainer:721) INFO: 6epoch:train:1387-1463batch: iter_time=1.711e-04, forward_time=0.242, loss_ctc=30.190, loss=30.190, backward_time=0.308, optim_step_time=0.038, optim0_lr0=2.626e-04, train_time=0.631
[ALab02] 2023-06-09 13:51:00,867 (trainer:721) INFO: 6epoch:train:1464-1540batch: iter_time=1.777e-04, forward_time=0.233, loss_ctc=33.229, loss=33.229, backward_time=0.306, optim_step_time=0.039, optim0_lr0=2.648e-04, train_time=0.623
[ALab02] 2023-06-09 13:51:42,425 (trainer:338) INFO: 6epoch results: [train] iter_time=8.631e-04, forward_time=0.234, loss_ctc=33.489, loss=33.489, backward_time=0.304, optim_step_time=0.039, optim0_lr0=2.441e-04, train_time=0.621, time=16 minutes and 4.99 seconds, total_count=9318, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=23.870, cer_ctc=0.449, cer=0.449, loss=23.870, time=6.55 seconds, total_count=96, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.08 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 13:51:44,666 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 13:51:44,666 (trainer:272) INFO: 7/70epoch started. Estimated time to finish: 17 hours, 57 minutes and 27.42 seconds
[ALab02] 2023-06-09 13:52:33,839 (trainer:721) INFO: 7epoch:train:1-77batch: iter_time=0.014, forward_time=0.233, loss_ctc=34.918, loss=34.918, backward_time=0.308, optim_step_time=0.037, optim0_lr0=2.674e-04, train_time=0.638
[ALab02] 2023-06-09 13:53:20,518 (trainer:721) INFO: 7epoch:train:78-154batch: iter_time=1.371e-04, forward_time=0.225, loss_ctc=30.047, loss=30.047, backward_time=0.299, optim_step_time=0.036, optim0_lr0=2.696e-04, train_time=0.606
[ALab02] 2023-06-09 13:54:08,712 (trainer:721) INFO: 7epoch:train:155-231batch: iter_time=1.880e-04, forward_time=0.236, loss_ctc=34.426, loss=34.426, backward_time=0.305, optim_step_time=0.040, optim0_lr0=2.718e-04, train_time=0.626
[ALab02] 2023-06-09 13:54:56,813 (trainer:721) INFO: 7epoch:train:232-308batch: iter_time=1.297e-04, forward_time=0.236, loss_ctc=29.814, loss=29.814, backward_time=0.309, optim_step_time=0.037, optim0_lr0=2.740e-04, train_time=0.624
[ALab02] 2023-06-09 13:55:45,026 (trainer:721) INFO: 7epoch:train:309-385batch: iter_time=1.767e-04, forward_time=0.235, loss_ctc=29.453, loss=29.453, backward_time=0.309, optim_step_time=0.039, optim0_lr0=2.762e-04, train_time=0.626
[ALab02] 2023-06-09 13:56:50,298 (trainer:721) INFO: 7epoch:train:386-462batch: iter_time=0.001, forward_time=0.376, loss_ctc=32.310, loss=32.310, backward_time=0.331, optim_step_time=0.073, optim0_lr0=2.784e-04, train_time=0.847
[ALab02] 2023-06-09 13:57:45,105 (trainer:721) INFO: 7epoch:train:463-539batch: iter_time=9.450e-04, forward_time=0.286, loss_ctc=29.962, loss=29.962, backward_time=0.313, optim_step_time=0.056, optim0_lr0=2.806e-04, train_time=0.711
[ALab02] 2023-06-09 13:58:31,024 (trainer:721) INFO: 7epoch:train:540-616batch: iter_time=1.228e-04, forward_time=0.220, loss_ctc=35.727, loss=35.727, backward_time=0.298, optim_step_time=0.037, optim0_lr0=2.828e-04, train_time=0.596
[ALab02] 2023-06-09 13:59:17,438 (trainer:721) INFO: 7epoch:train:617-693batch: iter_time=1.261e-04, forward_time=0.226, loss_ctc=30.451, loss=30.451, backward_time=0.298, optim_step_time=0.036, optim0_lr0=2.850e-04, train_time=0.603
[ALab02] 2023-06-09 14:00:05,343 (trainer:721) INFO: 7epoch:train:694-770batch: iter_time=1.567e-04, forward_time=0.236, loss_ctc=32.749, loss=32.749, backward_time=0.305, optim_step_time=0.038, optim0_lr0=2.872e-04, train_time=0.622
[ALab02] 2023-06-09 14:00:52,693 (trainer:721) INFO: 7epoch:train:771-847batch: iter_time=1.504e-04, forward_time=0.231, loss_ctc=31.763, loss=31.763, backward_time=0.308, optim_step_time=0.037, optim0_lr0=2.894e-04, train_time=0.615
[ALab02] 2023-06-09 14:01:40,584 (trainer:721) INFO: 7epoch:train:848-924batch: iter_time=1.733e-04, forward_time=0.237, loss_ctc=27.346, loss=27.346, backward_time=0.302, optim_step_time=0.038, optim0_lr0=2.916e-04, train_time=0.622
[ALab02] 2023-06-09 14:02:27,715 (trainer:721) INFO: 7epoch:train:925-1001batch: iter_time=1.585e-04, forward_time=0.230, loss_ctc=29.478, loss=29.478, backward_time=0.303, optim_step_time=0.038, optim0_lr0=2.938e-04, train_time=0.612
[ALab02] 2023-06-09 14:03:14,469 (trainer:721) INFO: 7epoch:train:1002-1078batch: iter_time=1.721e-04, forward_time=0.228, loss_ctc=29.670, loss=29.670, backward_time=0.301, optim_step_time=0.037, optim0_lr0=2.960e-04, train_time=0.607
[ALab02] 2023-06-09 14:04:02,475 (trainer:721) INFO: 7epoch:train:1079-1155batch: iter_time=1.775e-04, forward_time=0.238, loss_ctc=27.645, loss=27.645, backward_time=0.304, optim_step_time=0.038, optim0_lr0=2.982e-04, train_time=0.623
[ALab02] 2023-06-09 14:04:48,879 (trainer:721) INFO: 7epoch:train:1156-1232batch: iter_time=1.745e-04, forward_time=0.224, loss_ctc=32.479, loss=32.479, backward_time=0.300, optim_step_time=0.037, optim0_lr0=3.004e-04, train_time=0.602
[ALab02] 2023-06-09 14:05:36,453 (trainer:721) INFO: 7epoch:train:1233-1309batch: iter_time=1.645e-04, forward_time=0.232, loss_ctc=30.884, loss=30.884, backward_time=0.305, optim_step_time=0.038, optim0_lr0=3.026e-04, train_time=0.618
[ALab02] 2023-06-09 14:06:25,058 (trainer:721) INFO: 7epoch:train:1310-1386batch: iter_time=1.538e-04, forward_time=0.241, loss_ctc=26.463, loss=26.463, backward_time=0.307, optim_step_time=0.038, optim0_lr0=3.048e-04, train_time=0.631
[ALab02] 2023-06-09 14:07:11,772 (trainer:721) INFO: 7epoch:train:1387-1463batch: iter_time=1.534e-04, forward_time=0.226, loss_ctc=34.801, loss=34.801, backward_time=0.299, optim_step_time=0.037, optim0_lr0=3.070e-04, train_time=0.606
[ALab02] 2023-06-09 14:07:58,592 (trainer:721) INFO: 7epoch:train:1464-1540batch: iter_time=1.688e-04, forward_time=0.226, loss_ctc=28.191, loss=28.191, backward_time=0.304, optim_step_time=0.037, optim0_lr0=3.092e-04, train_time=0.608
[ALab02] 2023-06-09 14:08:41,155 (trainer:338) INFO: 7epoch results: [train] iter_time=9.451e-04, forward_time=0.241, loss_ctc=30.768, loss=30.768, backward_time=0.306, optim_step_time=0.040, optim0_lr0=2.885e-04, train_time=0.632, time=16 minutes and 22.16 seconds, total_count=10871, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=21.328, cer_ctc=0.422, cer=0.422, loss=21.328, time=6.74 seconds, total_count=112, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.58 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 14:08:43,335 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 14:08:43,336 (trainer:272) INFO: 8/70epoch started. Estimated time to finish: 17 hours, 41 minutes and 54.29 seconds
[ALab02] 2023-06-09 14:09:32,036 (trainer:721) INFO: 8epoch:train:1-77batch: iter_time=0.015, forward_time=0.230, loss_ctc=30.426, loss=30.426, backward_time=0.304, optim_step_time=0.039, optim0_lr0=3.117e-04, train_time=0.632
[ALab02] 2023-06-09 14:10:19,040 (trainer:721) INFO: 8epoch:train:78-154batch: iter_time=1.453e-04, forward_time=0.226, loss_ctc=31.911, loss=31.911, backward_time=0.303, optim_step_time=0.036, optim0_lr0=3.139e-04, train_time=0.610
[ALab02] 2023-06-09 14:11:07,250 (trainer:721) INFO: 8epoch:train:155-231batch: iter_time=1.501e-04, forward_time=0.239, loss_ctc=28.807, loss=28.807, backward_time=0.306, optim_step_time=0.037, optim0_lr0=3.161e-04, train_time=0.626
[ALab02] 2023-06-09 14:11:53,506 (trainer:721) INFO: 8epoch:train:232-308batch: iter_time=1.384e-04, forward_time=0.222, loss_ctc=26.153, loss=26.153, backward_time=0.302, optim_step_time=0.036, optim0_lr0=3.183e-04, train_time=0.600
[ALab02] 2023-06-09 14:12:41,965 (trainer:721) INFO: 8epoch:train:309-385batch: iter_time=2.758e-04, forward_time=0.240, loss_ctc=30.590, loss=30.590, backward_time=0.304, optim_step_time=0.042, optim0_lr0=3.205e-04, train_time=0.629
[ALab02] 2023-06-09 14:13:29,111 (trainer:721) INFO: 8epoch:train:386-462batch: iter_time=1.717e-04, forward_time=0.229, loss_ctc=31.549, loss=31.549, backward_time=0.302, optim_step_time=0.038, optim0_lr0=3.227e-04, train_time=0.612
[ALab02] 2023-06-09 14:14:16,704 (trainer:721) INFO: 8epoch:train:463-539batch: iter_time=1.367e-04, forward_time=0.231, loss_ctc=30.775, loss=30.775, backward_time=0.302, optim_step_time=0.037, optim0_lr0=3.249e-04, train_time=0.618
[ALab02] 2023-06-09 14:15:04,110 (trainer:721) INFO: 8epoch:train:540-616batch: iter_time=1.713e-04, forward_time=0.234, loss_ctc=26.697, loss=26.697, backward_time=0.303, optim_step_time=0.037, optim0_lr0=3.271e-04, train_time=0.615
[ALab02] 2023-06-09 14:15:51,559 (trainer:721) INFO: 8epoch:train:617-693batch: iter_time=1.589e-04, forward_time=0.235, loss_ctc=28.500, loss=28.500, backward_time=0.302, optim_step_time=0.037, optim0_lr0=3.293e-04, train_time=0.616
[ALab02] 2023-06-09 14:16:38,566 (trainer:721) INFO: 8epoch:train:694-770batch: iter_time=1.446e-04, forward_time=0.226, loss_ctc=31.674, loss=31.674, backward_time=0.305, optim_step_time=0.036, optim0_lr0=3.315e-04, train_time=0.610
[ALab02] 2023-06-09 14:17:26,695 (trainer:721) INFO: 8epoch:train:771-847batch: iter_time=1.749e-04, forward_time=0.235, loss_ctc=27.504, loss=27.504, backward_time=0.309, optim_step_time=0.037, optim0_lr0=3.337e-04, train_time=0.625
[ALab02] 2023-06-09 14:18:13,861 (trainer:721) INFO: 8epoch:train:848-924batch: iter_time=1.446e-04, forward_time=0.227, loss_ctc=31.336, loss=31.336, backward_time=0.304, optim_step_time=0.038, optim0_lr0=3.359e-04, train_time=0.612
[ALab02] 2023-06-09 14:19:02,396 (trainer:721) INFO: 8epoch:train:925-1001batch: iter_time=1.412e-04, forward_time=0.241, loss_ctc=24.247, loss=24.247, backward_time=0.308, optim_step_time=0.038, optim0_lr0=3.381e-04, train_time=0.630
[ALab02] 2023-06-09 14:19:50,444 (trainer:721) INFO: 8epoch:train:1002-1078batch: iter_time=1.580e-04, forward_time=0.237, loss_ctc=26.587, loss=26.587, backward_time=0.306, optim_step_time=0.036, optim0_lr0=3.403e-04, train_time=0.624
[ALab02] 2023-06-09 14:20:38,276 (trainer:721) INFO: 8epoch:train:1079-1155batch: iter_time=1.874e-04, forward_time=0.237, loss_ctc=27.123, loss=27.123, backward_time=0.304, optim_step_time=0.038, optim0_lr0=3.425e-04, train_time=0.621
[ALab02] 2023-06-09 14:21:26,859 (trainer:721) INFO: 8epoch:train:1156-1232batch: iter_time=1.641e-04, forward_time=0.238, loss_ctc=28.074, loss=28.074, backward_time=0.306, optim_step_time=0.039, optim0_lr0=3.447e-04, train_time=0.631
[ALab02] 2023-06-09 14:22:13,719 (trainer:721) INFO: 8epoch:train:1233-1309batch: iter_time=1.477e-04, forward_time=0.229, loss_ctc=27.233, loss=27.233, backward_time=0.303, optim_step_time=0.037, optim0_lr0=3.469e-04, train_time=0.608
[ALab02] 2023-06-09 14:23:01,309 (trainer:721) INFO: 8epoch:train:1310-1386batch: iter_time=1.995e-04, forward_time=0.232, loss_ctc=28.798, loss=28.798, backward_time=0.304, optim_step_time=0.039, optim0_lr0=3.491e-04, train_time=0.618
[ALab02] 2023-06-09 14:23:48,205 (trainer:721) INFO: 8epoch:train:1387-1463batch: iter_time=1.676e-04, forward_time=0.227, loss_ctc=28.772, loss=28.772, backward_time=0.301, optim_step_time=0.038, optim0_lr0=3.513e-04, train_time=0.609
[ALab02] 2023-06-09 14:24:35,378 (trainer:721) INFO: 8epoch:train:1464-1540batch: iter_time=1.748e-04, forward_time=0.229, loss_ctc=28.671, loss=28.671, backward_time=0.301, optim_step_time=0.039, optim0_lr0=3.535e-04, train_time=0.612
[ALab02] 2023-06-09 14:25:18,103 (trainer:338) INFO: 8epoch results: [train] iter_time=9.065e-04, forward_time=0.232, loss_ctc=28.709, loss=28.709, backward_time=0.304, optim_step_time=0.038, optim0_lr0=3.328e-04, train_time=0.618, time=16 minutes and 0.12 seconds, total_count=12424, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=20.472, cer_ctc=0.394, cer=0.394, loss=20.472, time=6.7 seconds, total_count=128, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.94 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 14:25:20,420 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 14:25:20,421 (trainer:272) INFO: 9/70epoch started. Estimated time to finish: 17 hours, 23 minutes and 12.49 seconds
[ALab02] 2023-06-09 14:26:09,696 (trainer:721) INFO: 9epoch:train:1-77batch: iter_time=0.015, forward_time=0.235, loss_ctc=25.861, loss=25.861, backward_time=0.306, optim_step_time=0.039, optim0_lr0=3.561e-04, train_time=0.640
[ALab02] 2023-06-09 14:26:57,866 (trainer:721) INFO: 9epoch:train:78-154batch: iter_time=1.520e-04, forward_time=0.236, loss_ctc=25.457, loss=25.457, backward_time=0.308, optim_step_time=0.037, optim0_lr0=3.583e-04, train_time=0.625
[ALab02] 2023-06-09 14:27:44,665 (trainer:721) INFO: 9epoch:train:155-231batch: iter_time=1.896e-04, forward_time=0.227, loss_ctc=26.154, loss=26.154, backward_time=0.301, optim_step_time=0.038, optim0_lr0=3.605e-04, train_time=0.608
[ALab02] 2023-06-09 14:28:33,160 (trainer:721) INFO: 9epoch:train:232-308batch: iter_time=1.603e-04, forward_time=0.239, loss_ctc=24.861, loss=24.861, backward_time=0.307, optim_step_time=0.038, optim0_lr0=3.627e-04, train_time=0.630
[ALab02] 2023-06-09 14:29:19,718 (trainer:721) INFO: 9epoch:train:309-385batch: iter_time=1.345e-04, forward_time=0.228, loss_ctc=28.771, loss=28.771, backward_time=0.300, optim_step_time=0.036, optim0_lr0=3.649e-04, train_time=0.604
[ALab02] 2023-06-09 14:30:07,184 (trainer:721) INFO: 9epoch:train:386-462batch: iter_time=1.344e-04, forward_time=0.233, loss_ctc=26.297, loss=26.297, backward_time=0.302, optim_step_time=0.037, optim0_lr0=3.671e-04, train_time=0.616
[ALab02] 2023-06-09 14:30:54,023 (trainer:721) INFO: 9epoch:train:463-539batch: iter_time=1.515e-04, forward_time=0.228, loss_ctc=29.838, loss=29.838, backward_time=0.302, optim_step_time=0.038, optim0_lr0=3.693e-04, train_time=0.608
[ALab02] 2023-06-09 14:31:41,069 (trainer:721) INFO: 9epoch:train:540-616batch: iter_time=1.348e-04, forward_time=0.230, loss_ctc=26.246, loss=26.246, backward_time=0.302, optim_step_time=0.037, optim0_lr0=3.715e-04, train_time=0.611
[ALab02] 2023-06-09 14:32:27,641 (trainer:721) INFO: 9epoch:train:617-693batch: iter_time=1.444e-04, forward_time=0.224, loss_ctc=28.657, loss=28.657, backward_time=0.306, optim_step_time=0.035, optim0_lr0=3.737e-04, train_time=0.605
[ALab02] 2023-06-09 14:33:17,297 (trainer:721) INFO: 9epoch:train:694-770batch: iter_time=1.525e-04, forward_time=0.245, loss_ctc=29.078, loss=29.078, backward_time=0.318, optim_step_time=0.038, optim0_lr0=3.759e-04, train_time=0.645
[ALab02] 2023-06-09 14:34:22,896 (trainer:721) INFO: 9epoch:train:771-847batch: iter_time=1.229e-04, forward_time=0.333, loss_ctc=26.318, loss=26.318, backward_time=0.428, optim_step_time=0.037, optim0_lr0=3.781e-04, train_time=0.852
[ALab02] 2023-06-09 14:35:46,451 (trainer:721) INFO: 9epoch:train:848-924batch: iter_time=1.513e-04, forward_time=0.446, loss_ctc=26.644, loss=26.644, backward_time=0.538, optim_step_time=0.037, optim0_lr0=3.803e-04, train_time=1.085
[ALab02] 2023-06-09 14:37:09,909 (trainer:721) INFO: 9epoch:train:925-1001batch: iter_time=1.549e-04, forward_time=0.447, loss_ctc=28.446, loss=28.446, backward_time=0.525, optim_step_time=0.039, optim0_lr0=3.825e-04, train_time=1.084
[ALab02] 2023-06-09 14:38:31,232 (trainer:721) INFO: 9epoch:train:1002-1078batch: iter_time=1.542e-04, forward_time=0.430, loss_ctc=30.742, loss=30.742, backward_time=0.517, optim_step_time=0.037, optim0_lr0=3.847e-04, train_time=1.056
[ALab02] 2023-06-09 14:39:56,186 (trainer:721) INFO: 9epoch:train:1079-1155batch: iter_time=1.610e-04, forward_time=0.463, loss_ctc=27.976, loss=27.976, backward_time=0.535, optim_step_time=0.037, optim0_lr0=3.869e-04, train_time=1.103
[ALab02] 2023-06-09 14:41:19,650 (trainer:721) INFO: 9epoch:train:1156-1232batch: iter_time=1.310e-04, forward_time=0.457, loss_ctc=26.587, loss=26.587, backward_time=0.519, optim_step_time=0.038, optim0_lr0=3.891e-04, train_time=1.084
[ALab02] 2023-06-09 14:42:40,953 (trainer:721) INFO: 9epoch:train:1233-1309batch: iter_time=2.070e-04, forward_time=0.435, loss_ctc=29.012, loss=29.012, backward_time=0.519, optim_step_time=0.037, optim0_lr0=3.913e-04, train_time=1.056
[ALab02] 2023-06-09 14:44:06,003 (trainer:721) INFO: 9epoch:train:1310-1386batch: iter_time=1.567e-04, forward_time=0.467, loss_ctc=26.648, loss=26.648, backward_time=0.534, optim_step_time=0.039, optim0_lr0=3.935e-04, train_time=1.104
[ALab02] 2023-06-09 14:45:30,567 (trainer:721) INFO: 9epoch:train:1387-1463batch: iter_time=1.592e-04, forward_time=0.469, loss_ctc=24.413, loss=24.413, backward_time=0.529, optim_step_time=0.038, optim0_lr0=3.957e-04, train_time=1.098
[ALab02] 2023-06-09 14:46:57,414 (trainer:721) INFO: 9epoch:train:1464-1540batch: iter_time=1.308e-04, forward_time=0.482, loss_ctc=25.210, loss=25.210, backward_time=0.533, optim_step_time=0.040, optim0_lr0=3.979e-04, train_time=1.128
[ALab02] 2023-06-09 14:47:47,639 (trainer:338) INFO: 9epoch results: [train] iter_time=8.735e-04, forward_time=0.339, loss_ctc=27.122, loss=27.122, backward_time=0.413, optim_step_time=0.038, optim0_lr0=3.772e-04, train_time=0.844, time=21 minutes and 51.4 seconds, total_count=13977, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=18.342, cer_ctc=0.380, cer=0.380, loss=18.342, time=9.45 seconds, total_count=144, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.36 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 14:47:49,839 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 14:47:49,839 (trainer:272) INFO: 10/70epoch started. Estimated time to finish: 17 hours, 44 minutes and 46.44 seconds
[ALab02] 2023-06-09 14:49:14,807 (trainer:721) INFO: 10epoch:train:1-77batch: iter_time=0.014, forward_time=0.462, loss_ctc=24.536, loss=24.536, backward_time=0.517, optim_step_time=0.037, optim0_lr0=4.005e-04, train_time=1.103
[ALab02] 2023-06-09 14:50:39,776 (trainer:721) INFO: 10epoch:train:78-154batch: iter_time=1.495e-04, forward_time=0.467, loss_ctc=24.341, loss=24.341, backward_time=0.536, optim_step_time=0.037, optim0_lr0=4.027e-04, train_time=1.103
[ALab02] 2023-06-09 14:52:03,227 (trainer:721) INFO: 10epoch:train:155-231batch: iter_time=1.566e-04, forward_time=0.450, loss_ctc=29.965, loss=29.965, backward_time=0.523, optim_step_time=0.039, optim0_lr0=4.049e-04, train_time=1.084
[ALab02] 2023-06-09 14:53:26,770 (trainer:721) INFO: 10epoch:train:232-308batch: iter_time=1.897e-04, forward_time=0.465, loss_ctc=23.616, loss=23.616, backward_time=0.520, optim_step_time=0.039, optim0_lr0=4.071e-04, train_time=1.085
[ALab02] 2023-06-09 14:54:51,215 (trainer:721) INFO: 10epoch:train:309-385batch: iter_time=1.308e-04, forward_time=0.459, loss_ctc=25.117, loss=25.117, backward_time=0.533, optim_step_time=0.037, optim0_lr0=4.093e-04, train_time=1.096
[ALab02] 2023-06-09 14:56:13,331 (trainer:721) INFO: 10epoch:train:386-462batch: iter_time=1.543e-04, forward_time=0.447, loss_ctc=24.549, loss=24.549, backward_time=0.516, optim_step_time=0.038, optim0_lr0=4.115e-04, train_time=1.066
[ALab02] 2023-06-09 14:57:39,331 (trainer:721) INFO: 10epoch:train:463-539batch: iter_time=1.447e-04, forward_time=0.481, loss_ctc=24.974, loss=24.974, backward_time=0.530, optim_step_time=0.037, optim0_lr0=4.137e-04, train_time=1.117
[ALab02] 2023-06-09 14:59:04,436 (trainer:721) INFO: 10epoch:train:540-616batch: iter_time=1.671e-04, forward_time=0.466, loss_ctc=28.560, loss=28.560, backward_time=0.532, optim_step_time=0.038, optim0_lr0=4.159e-04, train_time=1.105
[ALab02] 2023-06-09 15:00:25,213 (trainer:721) INFO: 10epoch:train:617-693batch: iter_time=1.461e-04, forward_time=0.431, loss_ctc=26.082, loss=26.082, backward_time=0.515, optim_step_time=0.038, optim0_lr0=4.181e-04, train_time=1.049
[ALab02] 2023-06-09 15:01:49,914 (trainer:721) INFO: 10epoch:train:694-770batch: iter_time=1.848e-04, forward_time=0.463, loss_ctc=25.207, loss=25.207, backward_time=0.531, optim_step_time=0.036, optim0_lr0=4.203e-04, train_time=1.100
[ALab02] 2023-06-09 15:03:15,634 (trainer:721) INFO: 10epoch:train:771-847batch: iter_time=1.620e-04, forward_time=0.480, loss_ctc=26.878, loss=26.878, backward_time=0.527, optim_step_time=0.038, optim0_lr0=4.225e-04, train_time=1.113
[ALab02] 2023-06-09 15:04:36,933 (trainer:721) INFO: 10epoch:train:848-924batch: iter_time=1.977e-04, forward_time=0.430, loss_ctc=29.182, loss=29.182, backward_time=0.518, optim_step_time=0.041, optim0_lr0=4.247e-04, train_time=1.056
[ALab02] 2023-06-09 15:05:57,801 (trainer:721) INFO: 10epoch:train:925-1001batch: iter_time=1.756e-04, forward_time=0.430, loss_ctc=28.707, loss=28.707, backward_time=0.519, optim_step_time=0.039, optim0_lr0=4.269e-04, train_time=1.050
[ALab02] 2023-06-09 15:07:24,523 (trainer:721) INFO: 10epoch:train:1002-1078batch: iter_time=1.484e-04, forward_time=0.480, loss_ctc=22.686, loss=22.686, backward_time=0.549, optim_step_time=0.039, optim0_lr0=4.291e-04, train_time=1.126
[ALab02] 2023-06-09 15:08:46,907 (trainer:721) INFO: 10epoch:train:1079-1155batch: iter_time=1.420e-04, forward_time=0.443, loss_ctc=26.433, loss=26.433, backward_time=0.524, optim_step_time=0.038, optim0_lr0=4.313e-04, train_time=1.070
[ALab02] 2023-06-09 15:10:13,531 (trainer:721) INFO: 10epoch:train:1156-1232batch: iter_time=1.521e-04, forward_time=0.473, loss_ctc=27.464, loss=27.464, backward_time=0.539, optim_step_time=0.038, optim0_lr0=4.335e-04, train_time=1.125
[ALab02] 2023-06-09 15:11:37,668 (trainer:721) INFO: 10epoch:train:1233-1309batch: iter_time=1.826e-04, forward_time=0.456, loss_ctc=24.735, loss=24.735, backward_time=0.529, optim_step_time=0.038, optim0_lr0=4.357e-04, train_time=1.092
[ALab02] 2023-06-09 15:13:02,344 (trainer:721) INFO: 10epoch:train:1310-1386batch: iter_time=1.320e-04, forward_time=0.458, loss_ctc=28.839, loss=28.839, backward_time=0.528, optim_step_time=0.038, optim0_lr0=4.379e-04, train_time=1.099
[ALab02] 2023-06-09 15:14:27,324 (trainer:721) INFO: 10epoch:train:1387-1463batch: iter_time=1.612e-04, forward_time=0.465, loss_ctc=23.855, loss=23.855, backward_time=0.544, optim_step_time=0.037, optim0_lr0=4.401e-04, train_time=1.103
[ALab02] 2023-06-09 15:15:52,882 (trainer:721) INFO: 10epoch:train:1464-1540batch: iter_time=2.710e-04, forward_time=0.470, loss_ctc=24.649, loss=24.649, backward_time=0.527, optim_step_time=0.040, optim0_lr0=4.423e-04, train_time=1.111
[ALab02] 2023-06-09 15:16:49,658 (trainer:338) INFO: 10epoch results: [train] iter_time=8.447e-04, forward_time=0.460, loss_ctc=25.833, loss=25.833, backward_time=0.528, optim_step_time=0.038, optim0_lr0=4.216e-04, train_time=1.094, time=28 minutes and 19.44 seconds, total_count=15530, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=18.356, cer_ctc=0.368, cer=0.368, loss=18.356, time=9.39 seconds, total_count=160, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.99 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 15:16:52,158 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 15:16:52,158 (trainer:272) INFO: 11/70epoch started. Estimated time to finish: 18 hours, 36 minutes and 49.13 seconds
[ALab02] 2023-06-09 15:18:17,702 (trainer:721) INFO: 11epoch:train:1-77batch: iter_time=0.015, forward_time=0.458, loss_ctc=26.590, loss=26.590, backward_time=0.530, optim_step_time=0.040, optim0_lr0=4.449e-04, train_time=1.111
[ALab02] 2023-06-09 15:19:43,171 (trainer:721) INFO: 11epoch:train:78-154batch: iter_time=1.581e-04, forward_time=0.479, loss_ctc=24.915, loss=24.915, backward_time=0.525, optim_step_time=0.038, optim0_lr0=4.471e-04, train_time=1.110
[ALab02] 2023-06-09 15:21:07,346 (trainer:721) INFO: 11epoch:train:155-231batch: iter_time=2.077e-04, forward_time=0.457, loss_ctc=24.172, loss=24.172, backward_time=0.532, optim_step_time=0.038, optim0_lr0=4.493e-04, train_time=1.093
[ALab02] 2023-06-09 15:22:31,081 (trainer:721) INFO: 11epoch:train:232-308batch: iter_time=1.616e-04, forward_time=0.469, loss_ctc=23.779, loss=23.779, backward_time=0.516, optim_step_time=0.041, optim0_lr0=4.515e-04, train_time=1.087
[ALab02] 2023-06-09 15:23:57,936 (trainer:721) INFO: 11epoch:train:309-385batch: iter_time=1.369e-04, forward_time=0.479, loss_ctc=26.526, loss=26.526, backward_time=0.536, optim_step_time=0.038, optim0_lr0=4.537e-04, train_time=1.128
[ALab02] 2023-06-09 15:25:20,635 (trainer:721) INFO: 11epoch:train:386-462batch: iter_time=1.565e-04, forward_time=0.449, loss_ctc=25.252, loss=25.252, backward_time=0.522, optim_step_time=0.040, optim0_lr0=4.559e-04, train_time=1.074
[ALab02] 2023-06-09 15:26:47,101 (trainer:721) INFO: 11epoch:train:463-539batch: iter_time=1.629e-04, forward_time=0.481, loss_ctc=22.834, loss=22.834, backward_time=0.540, optim_step_time=0.039, optim0_lr0=4.581e-04, train_time=1.123
[ALab02] 2023-06-09 15:28:11,374 (trainer:721) INFO: 11epoch:train:540-616batch: iter_time=1.711e-04, forward_time=0.462, loss_ctc=25.257, loss=25.257, backward_time=0.532, optim_step_time=0.039, optim0_lr0=4.603e-04, train_time=1.094
[ALab02] 2023-06-09 15:29:34,159 (trainer:721) INFO: 11epoch:train:617-693batch: iter_time=1.741e-04, forward_time=0.447, loss_ctc=26.147, loss=26.147, backward_time=0.519, optim_step_time=0.040, optim0_lr0=4.625e-04, train_time=1.075
[ALab02] 2023-06-09 15:31:01,183 (trainer:721) INFO: 11epoch:train:694-770batch: iter_time=1.427e-04, forward_time=0.484, loss_ctc=25.460, loss=25.460, backward_time=0.538, optim_step_time=0.038, optim0_lr0=4.647e-04, train_time=1.130
[ALab02] 2023-06-09 15:32:25,687 (trainer:721) INFO: 11epoch:train:771-847batch: iter_time=1.762e-04, forward_time=0.469, loss_ctc=25.870, loss=25.870, backward_time=0.521, optim_step_time=0.038, optim0_lr0=4.669e-04, train_time=1.097
[ALab02] 2023-06-09 15:33:50,678 (trainer:721) INFO: 11epoch:train:848-924batch: iter_time=1.405e-04, forward_time=0.471, loss_ctc=23.740, loss=23.740, backward_time=0.531, optim_step_time=0.038, optim0_lr0=4.691e-04, train_time=1.103
[ALab02] 2023-06-09 15:35:15,523 (trainer:721) INFO: 11epoch:train:925-1001batch: iter_time=1.597e-04, forward_time=0.464, loss_ctc=25.881, loss=25.881, backward_time=0.525, optim_step_time=0.042, optim0_lr0=4.713e-04, train_time=1.102
[ALab02] 2023-06-09 15:36:42,038 (trainer:721) INFO: 11epoch:train:1002-1078batch: iter_time=2.300e-04, forward_time=0.479, loss_ctc=24.243, loss=24.243, backward_time=0.540, optim_step_time=0.039, optim0_lr0=4.735e-04, train_time=1.123
[ALab02] 2023-06-09 15:38:08,114 (trainer:721) INFO: 11epoch:train:1079-1155batch: iter_time=1.826e-04, forward_time=0.478, loss_ctc=25.285, loss=25.285, backward_time=0.534, optim_step_time=0.039, optim0_lr0=4.757e-04, train_time=1.118
[ALab02] 2023-06-09 15:39:35,444 (trainer:721) INFO: 11epoch:train:1156-1232batch: iter_time=1.761e-04, forward_time=0.483, loss_ctc=23.018, loss=23.018, backward_time=0.540, optim_step_time=0.041, optim0_lr0=4.779e-04, train_time=1.134
[ALab02] 2023-06-09 15:40:57,819 (trainer:721) INFO: 11epoch:train:1233-1309batch: iter_time=1.458e-04, forward_time=0.438, loss_ctc=25.959, loss=25.959, backward_time=0.529, optim_step_time=0.037, optim0_lr0=4.801e-04, train_time=1.070
[ALab02] 2023-06-09 15:42:21,445 (trainer:721) INFO: 11epoch:train:1310-1386batch: iter_time=1.690e-04, forward_time=0.459, loss_ctc=22.735, loss=22.735, backward_time=0.522, optim_step_time=0.039, optim0_lr0=4.823e-04, train_time=1.086
[ALab02] 2023-06-09 15:43:46,544 (trainer:721) INFO: 11epoch:train:1387-1463batch: iter_time=1.701e-04, forward_time=0.461, loss_ctc=25.575, loss=25.575, backward_time=0.531, optim_step_time=0.037, optim0_lr0=4.845e-04, train_time=1.105
[ALab02] 2023-06-09 15:45:12,776 (trainer:721) INFO: 11epoch:train:1464-1540batch: iter_time=1.936e-04, forward_time=0.485, loss_ctc=23.313, loss=23.313, backward_time=0.528, optim_step_time=0.039, optim0_lr0=4.867e-04, train_time=1.120
[ALab02] 2023-06-09 15:46:05,719 (trainer:338) INFO: 11epoch results: [train] iter_time=9.115e-04, forward_time=0.468, loss_ctc=24.760, loss=24.760, backward_time=0.529, optim_step_time=0.039, optim0_lr0=4.659e-04, train_time=1.104, time=28 minutes and 35.18 seconds, total_count=17083, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=16.438, cer_ctc=0.356, cer=0.356, loss=16.438, time=10.28 seconds, total_count=176, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.1 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 15:46:08,112 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 15:46:08,114 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/1epoch.pth
[ALab02] 2023-06-09 15:46:08,114 (trainer:272) INFO: 12/70epoch started. Estimated time to finish: 19 hours, 15 minutes and 20.41 seconds
[ALab02] 2023-06-09 15:47:34,609 (trainer:721) INFO: 12epoch:train:1-77batch: iter_time=0.013, forward_time=0.469, loss_ctc=24.369, loss=24.369, backward_time=0.532, optim_step_time=0.038, optim0_lr0=4.892e-04, train_time=1.123
[ALab02] 2023-06-09 15:48:56,703 (trainer:721) INFO: 12epoch:train:78-154batch: iter_time=1.821e-04, forward_time=0.439, loss_ctc=25.641, loss=25.641, backward_time=0.521, optim_step_time=0.038, optim0_lr0=4.914e-04, train_time=1.066
[ALab02] 2023-06-09 15:50:54,927 (trainer:721) INFO: 12epoch:train:155-231batch: iter_time=1.611e-04, forward_time=0.800, loss_ctc=22.012, loss=22.012, backward_time=0.615, optim_step_time=0.040, optim0_lr0=4.936e-04, train_time=1.535
[ALab02] 2023-06-09 15:53:54,730 (trainer:721) INFO: 12epoch:train:232-308batch: iter_time=1.829e-04, forward_time=1.356, loss_ctc=22.988, loss=22.988, backward_time=0.826, optim_step_time=0.042, optim0_lr0=4.958e-04, train_time=2.335
[ALab02] 2023-06-09 15:56:54,698 (trainer:721) INFO: 12epoch:train:309-385batch: iter_time=1.658e-04, forward_time=1.385, loss_ctc=20.870, loss=20.870, backward_time=0.806, optim_step_time=0.042, optim0_lr0=4.980e-04, train_time=2.337
[ALab02] 2023-06-09 15:59:44,267 (trainer:721) INFO: 12epoch:train:386-462batch: iter_time=1.609e-04, forward_time=1.254, loss_ctc=25.205, loss=25.205, backward_time=0.800, optim_step_time=0.042, optim0_lr0=5.002e-04, train_time=2.202
[ALab02] 2023-06-09 16:02:34,191 (trainer:721) INFO: 12epoch:train:463-539batch: iter_time=1.752e-04, forward_time=1.256, loss_ctc=23.455, loss=23.455, backward_time=0.812, optim_step_time=0.042, optim0_lr0=5.024e-04, train_time=2.207
[ALab02] 2023-06-09 16:05:28,857 (trainer:721) INFO: 12epoch:train:540-616batch: iter_time=1.695e-04, forward_time=1.317, loss_ctc=24.836, loss=24.836, backward_time=0.798, optim_step_time=0.042, optim0_lr0=5.046e-04, train_time=2.268
[ALab02] 2023-06-09 16:08:26,399 (trainer:721) INFO: 12epoch:train:617-693batch: iter_time=1.476e-04, forward_time=1.382, loss_ctc=22.152, loss=22.152, backward_time=0.793, optim_step_time=0.041, optim0_lr0=5.068e-04, train_time=2.305
[ALab02] 2023-06-09 16:11:13,415 (trainer:721) INFO: 12epoch:train:694-770batch: iter_time=1.450e-04, forward_time=1.223, loss_ctc=26.924, loss=26.924, backward_time=0.803, optim_step_time=0.042, optim0_lr0=5.090e-04, train_time=2.169
[ALab02] 2023-06-09 16:14:07,514 (trainer:721) INFO: 12epoch:train:771-847batch: iter_time=1.729e-04, forward_time=1.290, loss_ctc=25.048, loss=25.048, backward_time=0.814, optim_step_time=0.043, optim0_lr0=5.112e-04, train_time=2.261
[ALab02] 2023-06-09 16:16:56,242 (trainer:721) INFO: 12epoch:train:848-924batch: iter_time=1.599e-04, forward_time=1.220, loss_ctc=23.431, loss=23.431, backward_time=0.811, optim_step_time=0.043, optim0_lr0=5.134e-04, train_time=2.191
[ALab02] 2023-06-09 16:19:51,382 (trainer:721) INFO: 12epoch:train:925-1001batch: iter_time=1.342e-04, forward_time=1.304, loss_ctc=25.165, loss=25.165, backward_time=0.821, optim_step_time=0.041, optim0_lr0=5.156e-04, train_time=2.274
[ALab02] 2023-06-09 16:22:35,903 (trainer:721) INFO: 12epoch:train:1002-1078batch: iter_time=1.538e-04, forward_time=1.194, loss_ctc=26.249, loss=26.249, backward_time=0.794, optim_step_time=0.042, optim0_lr0=5.178e-04, train_time=2.136
[ALab02] 2023-06-09 16:25:20,538 (trainer:721) INFO: 12epoch:train:1079-1155batch: iter_time=1.469e-04, forward_time=1.193, loss_ctc=25.041, loss=25.041, backward_time=0.797, optim_step_time=0.043, optim0_lr0=5.200e-04, train_time=2.138
[ALab02] 2023-06-09 16:27:03,981 (trainer:721) INFO: 12epoch:train:1156-1232batch: iter_time=1.477e-04, forward_time=0.617, loss_ctc=24.561, loss=24.561, backward_time=0.608, optim_step_time=0.039, optim0_lr0=5.222e-04, train_time=1.343
[ALab02] 2023-06-09 16:28:36,640 (trainer:721) INFO: 12epoch:train:1233-1309batch: iter_time=1.612e-04, forward_time=0.528, loss_ctc=23.854, loss=23.854, backward_time=0.565, optim_step_time=0.037, optim0_lr0=5.244e-04, train_time=1.203
[ALab02] 2023-06-09 16:30:11,923 (trainer:721) INFO: 12epoch:train:1310-1386batch: iter_time=1.848e-04, forward_time=0.540, loss_ctc=24.534, loss=24.534, backward_time=0.583, optim_step_time=0.043, optim0_lr0=5.266e-04, train_time=1.237
[ALab02] 2023-06-09 16:31:47,231 (trainer:721) INFO: 12epoch:train:1387-1463batch: iter_time=1.742e-04, forward_time=0.549, loss_ctc=23.680, loss=23.680, backward_time=0.580, optim_step_time=0.037, optim0_lr0=5.288e-04, train_time=1.238
[ALab02] 2023-06-09 16:33:21,050 (trainer:721) INFO: 12epoch:train:1464-1540batch: iter_time=1.876e-04, forward_time=0.539, loss_ctc=25.616, loss=25.616, backward_time=0.570, optim_step_time=0.040, optim0_lr0=5.310e-04, train_time=1.218
[ALab02] 2023-06-09 16:34:16,237 (trainer:338) INFO: 12epoch results: [train] iter_time=8.214e-04, forward_time=0.990, loss_ctc=24.203, loss=24.203, backward_time=0.712, optim_step_time=0.041, optim0_lr0=5.103e-04, train_time=1.835, time=47 minutes and 30.29 seconds, total_count=18636, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=17.282, cer_ctc=0.345, cer=0.345, loss=17.282, time=10.97 seconds, total_count=192, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.86 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 16:34:18,422 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 16:34:18,425 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/2epoch.pth
[ALab02] 2023-06-09 16:34:18,425 (trainer:272) INFO: 13/70epoch started. Estimated time to finish: 21 hours, 13 minutes and 56.53 seconds
[ALab02] 2023-06-09 16:35:50,568 (trainer:721) INFO: 13epoch:train:1-77batch: iter_time=0.015, forward_time=0.512, loss_ctc=25.347, loss=25.347, backward_time=0.560, optim_step_time=0.036, optim0_lr0=5.336e-04, train_time=1.196
[ALab02] 2023-06-09 16:37:23,990 (trainer:721) INFO: 13epoch:train:78-154batch: iter_time=1.541e-04, forward_time=0.542, loss_ctc=22.286, loss=22.286, backward_time=0.564, optim_step_time=0.039, optim0_lr0=5.358e-04, train_time=1.213
[ALab02] 2023-06-09 16:38:57,744 (trainer:721) INFO: 13epoch:train:155-231batch: iter_time=1.952e-04, forward_time=0.536, loss_ctc=24.206, loss=24.206, backward_time=0.568, optim_step_time=0.039, optim0_lr0=5.380e-04, train_time=1.217
[ALab02] 2023-06-09 16:40:26,757 (trainer:721) INFO: 13epoch:train:232-308batch: iter_time=1.559e-04, forward_time=0.492, loss_ctc=27.949, loss=27.949, backward_time=0.546, optim_step_time=0.040, optim0_lr0=5.402e-04, train_time=1.156
[ALab02] 2023-06-09 16:42:01,207 (trainer:721) INFO: 13epoch:train:309-385batch: iter_time=1.686e-04, forward_time=0.527, loss_ctc=24.236, loss=24.236, backward_time=0.585, optim_step_time=0.038, optim0_lr0=5.424e-04, train_time=1.226
[ALab02] 2023-06-09 16:43:36,087 (trainer:721) INFO: 13epoch:train:386-462batch: iter_time=1.560e-04, forward_time=0.536, loss_ctc=25.183, loss=25.183, backward_time=0.575, optim_step_time=0.038, optim0_lr0=5.446e-04, train_time=1.232
[ALab02] 2023-06-09 16:45:08,228 (trainer:721) INFO: 13epoch:train:463-539batch: iter_time=1.829e-04, forward_time=0.524, loss_ctc=23.954, loss=23.954, backward_time=0.564, optim_step_time=0.039, optim0_lr0=5.468e-04, train_time=1.196
[ALab02] 2023-06-09 16:46:46,150 (trainer:721) INFO: 13epoch:train:540-616batch: iter_time=1.499e-04, forward_time=0.575, loss_ctc=20.879, loss=20.879, backward_time=0.587, optim_step_time=0.037, optim0_lr0=5.490e-04, train_time=1.271
[ALab02] 2023-06-09 16:48:19,770 (trainer:721) INFO: 13epoch:train:617-693batch: iter_time=1.983e-04, forward_time=0.541, loss_ctc=21.600, loss=21.600, backward_time=0.565, optim_step_time=0.037, optim0_lr0=5.512e-04, train_time=1.216
[ALab02] 2023-06-09 16:49:54,448 (trainer:721) INFO: 13epoch:train:694-770batch: iter_time=1.490e-04, forward_time=0.533, loss_ctc=24.269, loss=24.269, backward_time=0.584, optim_step_time=0.037, optim0_lr0=5.534e-04, train_time=1.229
[ALab02] 2023-06-09 16:51:25,693 (trainer:721) INFO: 13epoch:train:771-847batch: iter_time=1.835e-04, forward_time=0.519, loss_ctc=22.833, loss=22.833, backward_time=0.553, optim_step_time=0.041, optim0_lr0=5.556e-04, train_time=1.185
[ALab02] 2023-06-09 16:52:57,592 (trainer:721) INFO: 13epoch:train:848-924batch: iter_time=1.557e-04, forward_time=0.519, loss_ctc=22.219, loss=22.219, backward_time=0.572, optim_step_time=0.037, optim0_lr0=5.578e-04, train_time=1.193
[ALab02] 2023-06-09 16:54:18,015 (trainer:721) INFO: 13epoch:train:925-1001batch: iter_time=1.630e-04, forward_time=0.444, loss_ctc=22.921, loss=22.921, backward_time=0.498, optim_step_time=0.041, optim0_lr0=5.600e-04, train_time=1.044
[ALab02] 2023-06-09 16:55:58,126 (trainer:721) INFO: 13epoch:train:1002-1078batch: iter_time=1.858e-04, forward_time=0.593, loss_ctc=21.553, loss=21.553, backward_time=0.582, optim_step_time=0.039, optim0_lr0=5.622e-04, train_time=1.300
[ALab02] 2023-06-09 16:57:28,991 (trainer:721) INFO: 13epoch:train:1079-1155batch: iter_time=1.734e-04, forward_time=0.510, loss_ctc=22.609, loss=22.609, backward_time=0.559, optim_step_time=0.038, optim0_lr0=5.644e-04, train_time=1.180
[ALab02] 2023-06-09 16:59:08,029 (trainer:721) INFO: 13epoch:train:1156-1232batch: iter_time=1.673e-04, forward_time=0.579, loss_ctc=25.069, loss=25.069, backward_time=0.588, optim_step_time=0.040, optim0_lr0=5.666e-04, train_time=1.286
[ALab02] 2023-06-09 17:00:40,559 (trainer:721) INFO: 13epoch:train:1233-1309batch: iter_time=1.706e-04, forward_time=0.524, loss_ctc=23.174, loss=23.174, backward_time=0.574, optim_step_time=0.039, optim0_lr0=5.688e-04, train_time=1.201
[ALab02] 2023-06-09 17:02:16,717 (trainer:721) INFO: 13epoch:train:1310-1386batch: iter_time=2.652e-04, forward_time=0.565, loss_ctc=26.108, loss=26.108, backward_time=0.576, optim_step_time=0.039, optim0_lr0=5.710e-04, train_time=1.249
[ALab02] 2023-06-09 17:03:54,545 (trainer:721) INFO: 13epoch:train:1387-1463batch: iter_time=2.000e-04, forward_time=0.583, loss_ctc=21.617, loss=21.617, backward_time=0.573, optim_step_time=0.039, optim0_lr0=5.732e-04, train_time=1.270
[ALab02] 2023-06-09 17:05:39,157 (trainer:721) INFO: 13epoch:train:1464-1540batch: iter_time=1.993e-04, forward_time=0.648, loss_ctc=21.570, loss=21.570, backward_time=0.596, optim_step_time=0.037, optim0_lr0=5.754e-04, train_time=1.358
[ALab02] 2023-06-09 17:06:32,319 (trainer:338) INFO: 13epoch results: [train] iter_time=9.274e-04, forward_time=0.540, loss_ctc=23.404, loss=23.404, backward_time=0.569, optim_step_time=0.038, optim0_lr0=5.547e-04, train_time=1.221, time=31 minutes and 37.2 seconds, total_count=20189, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=15.793, cer_ctc=0.341, cer=0.341, loss=15.793, time=8.66 seconds, total_count=208, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.03 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 17:06:34,530 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 17:06:34,531 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/3epoch.pth
[ALab02] 2023-06-09 17:06:34,531 (trainer:272) INFO: 14/70epoch started. Estimated time to finish: 21 hours, 37 minutes and 9.38 seconds
[ALab02] 2023-06-09 17:08:13,192 (trainer:721) INFO: 14epoch:train:1-77batch: iter_time=0.013, forward_time=0.589, loss_ctc=23.928, loss=23.928, backward_time=0.564, optim_step_time=0.038, optim0_lr0=5.780e-04, train_time=1.281
[ALab02] 2023-06-09 17:09:49,634 (trainer:721) INFO: 14epoch:train:78-154batch: iter_time=4.546e-04, forward_time=0.566, loss_ctc=20.919, loss=20.919, backward_time=0.578, optim_step_time=0.040, optim0_lr0=5.802e-04, train_time=1.252
[ALab02] 2023-06-09 17:11:12,733 (trainer:721) INFO: 14epoch:train:155-231batch: iter_time=1.780e-04, forward_time=0.475, loss_ctc=22.603, loss=22.603, backward_time=0.504, optim_step_time=0.040, optim0_lr0=5.824e-04, train_time=1.079
[ALab02] 2023-06-09 17:12:45,145 (trainer:721) INFO: 14epoch:train:232-308batch: iter_time=1.820e-04, forward_time=0.533, loss_ctc=18.381, loss=18.381, backward_time=0.556, optim_step_time=0.038, optim0_lr0=5.846e-04, train_time=1.200
[ALab02] 2023-06-09 17:14:20,921 (trainer:721) INFO: 14epoch:train:309-385batch: iter_time=1.714e-04, forward_time=0.553, loss_ctc=22.319, loss=22.319, backward_time=0.583, optim_step_time=0.039, optim0_lr0=5.868e-04, train_time=1.244
[ALab02] 2023-06-09 17:15:50,371 (trainer:721) INFO: 14epoch:train:386-462batch: iter_time=3.289e-04, forward_time=0.498, loss_ctc=24.218, loss=24.218, backward_time=0.555, optim_step_time=0.039, optim0_lr0=5.890e-04, train_time=1.161
[ALab02] 2023-06-09 17:17:10,933 (trainer:721) INFO: 14epoch:train:463-539batch: iter_time=1.599e-04, forward_time=0.439, loss_ctc=24.192, loss=24.192, backward_time=0.505, optim_step_time=0.039, optim0_lr0=5.912e-04, train_time=1.046
[ALab02] 2023-06-09 17:18:42,948 (trainer:721) INFO: 14epoch:train:540-616batch: iter_time=1.200e-04, forward_time=0.518, loss_ctc=26.394, loss=26.394, backward_time=0.566, optim_step_time=0.036, optim0_lr0=5.934e-04, train_time=1.195
[ALab02] 2023-06-09 17:20:17,025 (trainer:721) INFO: 14epoch:train:617-693batch: iter_time=1.862e-04, forward_time=0.548, loss_ctc=19.506, loss=19.506, backward_time=0.566, optim_step_time=0.039, optim0_lr0=5.956e-04, train_time=1.222
[ALab02] 2023-06-09 17:21:28,756 (trainer:721) INFO: 14epoch:train:694-770batch: iter_time=1.507e-04, forward_time=0.380, loss_ctc=24.084, loss=24.084, backward_time=0.456, optim_step_time=0.038, optim0_lr0=5.978e-04, train_time=0.931
[ALab02] 2023-06-09 17:22:17,057 (trainer:721) INFO: 14epoch:train:771-847batch: iter_time=1.797e-04, forward_time=0.236, loss_ctc=21.411, loss=21.411, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.000e-04, train_time=0.627
[ALab02] 2023-06-09 17:23:04,080 (trainer:721) INFO: 14epoch:train:848-924batch: iter_time=1.699e-04, forward_time=0.227, loss_ctc=26.379, loss=26.379, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.022e-04, train_time=0.610
[ALab02] 2023-06-09 17:23:51,497 (trainer:721) INFO: 14epoch:train:925-1001batch: iter_time=1.314e-04, forward_time=0.233, loss_ctc=22.349, loss=22.349, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.044e-04, train_time=0.616
[ALab02] 2023-06-09 17:25:09,954 (trainer:721) INFO: 14epoch:train:1002-1078batch: iter_time=1.628e-04, forward_time=0.417, loss_ctc=21.620, loss=21.620, backward_time=0.497, optim_step_time=0.039, optim0_lr0=6.066e-04, train_time=1.019
[ALab02] 2023-06-09 17:26:44,077 (trainer:721) INFO: 14epoch:train:1079-1155batch: iter_time=1.384e-04, forward_time=0.538, loss_ctc=24.145, loss=24.145, backward_time=0.576, optim_step_time=0.037, optim0_lr0=6.088e-04, train_time=1.222
[ALab02] 2023-06-09 17:28:19,070 (trainer:721) INFO: 14epoch:train:1156-1232batch: iter_time=1.807e-04, forward_time=0.540, loss_ctc=20.476, loss=20.476, backward_time=0.576, optim_step_time=0.041, optim0_lr0=6.110e-04, train_time=1.233
[ALab02] 2023-06-09 17:29:52,195 (trainer:721) INFO: 14epoch:train:1233-1309batch: iter_time=1.998e-04, forward_time=0.536, loss_ctc=24.556, loss=24.556, backward_time=0.566, optim_step_time=0.040, optim0_lr0=6.132e-04, train_time=1.209
[ALab02] 2023-06-09 17:31:29,066 (trainer:721) INFO: 14epoch:train:1310-1386batch: iter_time=1.679e-04, forward_time=0.542, loss_ctc=23.341, loss=23.341, backward_time=0.598, optim_step_time=0.038, optim0_lr0=6.154e-04, train_time=1.258
[ALab02] 2023-06-09 17:33:02,324 (trainer:721) INFO: 14epoch:train:1387-1463batch: iter_time=1.788e-04, forward_time=0.536, loss_ctc=24.797, loss=24.797, backward_time=0.562, optim_step_time=0.038, optim0_lr0=6.176e-04, train_time=1.211
[ALab02] 2023-06-09 17:34:43,644 (trainer:721) INFO: 14epoch:train:1464-1540batch: iter_time=1.447e-04, forward_time=0.616, loss_ctc=21.794, loss=21.794, backward_time=0.581, optim_step_time=0.038, optim0_lr0=6.198e-04, train_time=1.316
[ALab02] 2023-06-09 17:35:35,962 (trainer:338) INFO: 14epoch results: [train] iter_time=8.351e-04, forward_time=0.476, loss_ctc=22.706, loss=22.706, backward_time=0.515, optim_step_time=0.038, optim0_lr0=5.991e-04, train_time=1.096, time=28 minutes and 22.72 seconds, total_count=21742, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=16.617, cer_ctc=0.327, cer=0.327, loss=16.617, time=10.95 seconds, total_count=224, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.76 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 17:35:38,223 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 17:35:38,225 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/4epoch.pth
[ALab02] 2023-06-09 17:35:38,225 (trainer:272) INFO: 15/70epoch started. Estimated time to finish: 21 hours, 39 minutes and 37.02 seconds
[ALab02] 2023-06-09 17:37:17,030 (trainer:721) INFO: 15epoch:train:1-77batch: iter_time=0.015, forward_time=0.568, loss_ctc=21.156, loss=21.156, backward_time=0.587, optim_step_time=0.039, optim0_lr0=6.223e-04, train_time=1.283
[ALab02] 2023-06-09 17:38:50,711 (trainer:721) INFO: 15epoch:train:78-154batch: iter_time=1.939e-04, forward_time=0.538, loss_ctc=22.134, loss=22.134, backward_time=0.567, optim_step_time=0.040, optim0_lr0=6.245e-04, train_time=1.216
[ALab02] 2023-06-09 17:40:28,863 (trainer:721) INFO: 15epoch:train:155-231batch: iter_time=1.836e-04, forward_time=0.572, loss_ctc=24.037, loss=24.037, backward_time=0.586, optim_step_time=0.041, optim0_lr0=6.267e-04, train_time=1.274
[ALab02] 2023-06-09 17:42:03,380 (trainer:721) INFO: 15epoch:train:232-308batch: iter_time=3.019e-04, forward_time=0.555, loss_ctc=20.242, loss=20.242, backward_time=0.558, optim_step_time=0.042, optim0_lr0=6.289e-04, train_time=1.227
[ALab02] 2023-06-09 17:43:39,516 (trainer:721) INFO: 15epoch:train:309-385batch: iter_time=1.741e-04, forward_time=0.554, loss_ctc=20.779, loss=20.779, backward_time=0.579, optim_step_time=0.041, optim0_lr0=6.311e-04, train_time=1.248
[ALab02] 2023-06-09 17:45:10,334 (trainer:721) INFO: 15epoch:train:386-462batch: iter_time=1.841e-04, forward_time=0.516, loss_ctc=22.165, loss=22.165, backward_time=0.555, optim_step_time=0.039, optim0_lr0=6.333e-04, train_time=1.179
[ALab02] 2023-06-09 17:46:33,951 (trainer:721) INFO: 15epoch:train:463-539batch: iter_time=2.571e-04, forward_time=0.471, loss_ctc=22.928, loss=22.928, backward_time=0.500, optim_step_time=0.040, optim0_lr0=6.355e-04, train_time=1.086
[ALab02] 2023-06-09 17:48:28,632 (trainer:721) INFO: 15epoch:train:540-616batch: iter_time=1.549e-04, forward_time=0.744, loss_ctc=24.887, loss=24.887, backward_time=0.627, optim_step_time=0.039, optim0_lr0=6.377e-04, train_time=1.489
[ALab02] 2023-06-09 17:51:45,141 (trainer:721) INFO: 15epoch:train:617-693batch: iter_time=1.951e-04, forward_time=1.556, loss_ctc=23.073, loss=23.073, backward_time=0.848, optim_step_time=0.042, optim0_lr0=6.399e-04, train_time=2.552
[ALab02] 2023-06-09 17:54:18,186 (trainer:721) INFO: 15epoch:train:694-770batch: iter_time=2.099e-04, forward_time=1.122, loss_ctc=21.013, loss=21.013, backward_time=0.726, optim_step_time=0.040, optim0_lr0=6.421e-04, train_time=1.987
[ALab02] 2023-06-09 17:57:23,391 (trainer:721) INFO: 15epoch:train:771-847batch: iter_time=1.436e-04, forward_time=1.419, loss_ctc=23.942, loss=23.942, backward_time=0.841, optim_step_time=0.040, optim0_lr0=6.443e-04, train_time=2.405
[ALab02] 2023-06-09 18:00:11,318 (trainer:721) INFO: 15epoch:train:848-924batch: iter_time=1.771e-04, forward_time=1.245, loss_ctc=23.587, loss=23.587, backward_time=0.795, optim_step_time=0.041, optim0_lr0=6.465e-04, train_time=2.181
[ALab02] 2023-06-09 18:02:00,165 (trainer:721) INFO: 15epoch:train:925-1001batch: iter_time=1.686e-04, forward_time=0.689, loss_ctc=20.640, loss=20.640, backward_time=0.603, optim_step_time=0.040, optim0_lr0=6.487e-04, train_time=1.413
[ALab02] 2023-06-09 18:03:29,700 (trainer:721) INFO: 15epoch:train:1002-1078batch: iter_time=1.486e-04, forward_time=0.511, loss_ctc=23.479, loss=23.479, backward_time=0.550, optim_step_time=0.037, optim0_lr0=6.509e-04, train_time=1.163
[ALab02] 2023-06-09 18:05:07,461 (trainer:721) INFO: 15epoch:train:1079-1155batch: iter_time=3.323e-04, forward_time=0.567, loss_ctc=20.401, loss=20.401, backward_time=0.591, optim_step_time=0.039, optim0_lr0=6.531e-04, train_time=1.269
[ALab02] 2023-06-09 18:06:36,800 (trainer:721) INFO: 15epoch:train:1156-1232batch: iter_time=1.732e-04, forward_time=0.495, loss_ctc=22.882, loss=22.882, backward_time=0.556, optim_step_time=0.039, optim0_lr0=6.553e-04, train_time=1.160
[ALab02] 2023-06-09 18:08:12,247 (trainer:721) INFO: 15epoch:train:1233-1309batch: iter_time=1.550e-04, forward_time=0.542, loss_ctc=22.140, loss=22.140, backward_time=0.578, optim_step_time=0.038, optim0_lr0=6.575e-04, train_time=1.239
[ALab02] 2023-06-09 18:09:42,744 (trainer:721) INFO: 15epoch:train:1310-1386batch: iter_time=1.222e-04, forward_time=0.497, loss_ctc=23.287, loss=23.287, backward_time=0.573, optim_step_time=0.037, optim0_lr0=6.597e-04, train_time=1.175
[ALab02] 2023-06-09 18:11:12,559 (trainer:721) INFO: 15epoch:train:1387-1463batch: iter_time=1.372e-04, forward_time=0.498, loss_ctc=25.723, loss=25.723, backward_time=0.557, optim_step_time=0.037, optim0_lr0=6.619e-04, train_time=1.166
[ALab02] 2023-06-09 18:12:45,916 (trainer:721) INFO: 15epoch:train:1464-1540batch: iter_time=1.315e-04, forward_time=0.523, loss_ctc=22.927, loss=22.927, backward_time=0.578, optim_step_time=0.037, optim0_lr0=6.641e-04, train_time=1.212
[ALab02] 2023-06-09 18:13:37,455 (trainer:338) INFO: 15epoch results: [train] iter_time=9.349e-04, forward_time=0.707, loss_ctc=22.517, loss=22.517, backward_time=0.617, optim_step_time=0.039, optim0_lr0=6.434e-04, train_time=1.444, time=37 minutes and 23.09 seconds, total_count=23295, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=15.887, cer_ctc=0.330, cer=0.330, loss=15.887, time=9.13 seconds, total_count=240, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.01 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 18:13:39,590 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-09 18:13:39,593 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/5epoch.pth
[ALab02] 2023-06-09 18:13:39,593 (trainer:272) INFO: 16/70epoch started. Estimated time to finish: 22 hours, 10 minutes and 43.95 seconds
[ALab02] 2023-06-09 18:15:13,453 (trainer:721) INFO: 16epoch:train:1-77batch: iter_time=0.016, forward_time=0.517, loss_ctc=22.119, loss=22.119, backward_time=0.569, optim_step_time=0.040, optim0_lr0=6.667e-04, train_time=1.219
[ALab02] 2023-06-09 18:16:48,771 (trainer:721) INFO: 16epoch:train:78-154batch: iter_time=1.633e-04, forward_time=0.540, loss_ctc=22.911, loss=22.911, backward_time=0.578, optim_step_time=0.038, optim0_lr0=6.689e-04, train_time=1.238
[ALab02] 2023-06-09 18:18:23,977 (trainer:721) INFO: 16epoch:train:155-231batch: iter_time=1.408e-04, forward_time=0.555, loss_ctc=20.654, loss=20.654, backward_time=0.563, optim_step_time=0.039, optim0_lr0=6.711e-04, train_time=1.236
[ALab02] 2023-06-09 18:19:57,519 (trainer:721) INFO: 16epoch:train:232-308batch: iter_time=1.594e-04, forward_time=0.533, loss_ctc=23.130, loss=23.130, backward_time=0.578, optim_step_time=0.038, optim0_lr0=6.733e-04, train_time=1.215
[ALab02] 2023-06-09 18:21:29,528 (trainer:721) INFO: 16epoch:train:309-385batch: iter_time=2.425e-04, forward_time=0.525, loss_ctc=19.429, loss=19.429, backward_time=0.563, optim_step_time=0.036, optim0_lr0=6.755e-04, train_time=1.195
[ALab02] 2023-06-09 18:23:02,493 (trainer:721) INFO: 16epoch:train:386-462batch: iter_time=2.677e-04, forward_time=0.516, loss_ctc=22.840, loss=22.840, backward_time=0.579, optim_step_time=0.039, optim0_lr0=6.777e-04, train_time=1.207
[ALab02] 2023-06-09 18:24:37,177 (trainer:721) INFO: 16epoch:train:463-539batch: iter_time=4.199e-04, forward_time=0.534, loss_ctc=21.607, loss=21.607, backward_time=0.575, optim_step_time=0.045, optim0_lr0=6.799e-04, train_time=1.229
[ALab02] 2023-06-09 18:26:06,374 (trainer:721) INFO: 16epoch:train:540-616batch: iter_time=1.549e-04, forward_time=0.494, loss_ctc=21.317, loss=21.317, backward_time=0.559, optim_step_time=0.038, optim0_lr0=6.821e-04, train_time=1.158
[ALab02] 2023-06-09 18:27:44,451 (trainer:721) INFO: 16epoch:train:617-693batch: iter_time=1.565e-04, forward_time=0.568, loss_ctc=23.035, loss=23.035, backward_time=0.591, optim_step_time=0.039, optim0_lr0=6.843e-04, train_time=1.274
[ALab02] 2023-06-09 18:29:15,891 (trainer:721) INFO: 16epoch:train:694-770batch: iter_time=1.465e-04, forward_time=0.516, loss_ctc=21.340, loss=21.340, backward_time=0.563, optim_step_time=0.038, optim0_lr0=6.865e-04, train_time=1.187
[ALab02] 2023-06-09 18:30:47,437 (trainer:721) INFO: 16epoch:train:771-847batch: iter_time=1.535e-04, forward_time=0.508, loss_ctc=24.913, loss=24.913, backward_time=0.568, optim_step_time=0.037, optim0_lr0=6.887e-04, train_time=1.189
[ALab02] 2023-06-09 18:32:20,719 (trainer:721) INFO: 16epoch:train:848-924batch: iter_time=1.884e-04, forward_time=0.529, loss_ctc=22.372, loss=22.372, backward_time=0.572, optim_step_time=0.038, optim0_lr0=6.909e-04, train_time=1.211
[ALab02] 2023-06-09 18:33:51,461 (trainer:721) INFO: 16epoch:train:925-1001batch: iter_time=1.966e-04, forward_time=0.504, loss_ctc=23.412, loss=23.412, backward_time=0.566, optim_step_time=0.040, optim0_lr0=6.931e-04, train_time=1.178
[ALab02] 2023-06-09 18:35:28,597 (trainer:721) INFO: 16epoch:train:1002-1078batch: iter_time=2.069e-04, forward_time=0.570, loss_ctc=22.750, loss=22.750, backward_time=0.583, optim_step_time=0.038, optim0_lr0=6.953e-04, train_time=1.261
[ALab02] 2023-06-09 18:36:58,273 (trainer:721) INFO: 16epoch:train:1079-1155batch: iter_time=1.373e-04, forward_time=0.503, loss_ctc=23.723, loss=23.723, backward_time=0.554, optim_step_time=0.037, optim0_lr0=6.975e-04, train_time=1.164
[ALab02] 2023-06-09 18:38:34,956 (trainer:721) INFO: 16epoch:train:1156-1232batch: iter_time=1.537e-04, forward_time=0.557, loss_ctc=22.111, loss=22.111, backward_time=0.589, optim_step_time=0.038, optim0_lr0=6.997e-04, train_time=1.255
[ALab02] 2023-06-09 18:40:06,334 (trainer:721) INFO: 16epoch:train:1233-1309batch: iter_time=1.278e-04, forward_time=0.517, loss_ctc=22.434, loss=22.434, backward_time=0.558, optim_step_time=0.038, optim0_lr0=7.019e-04, train_time=1.187
[ALab02] 2023-06-09 18:41:44,895 (trainer:721) INFO: 16epoch:train:1310-1386batch: iter_time=1.651e-04, forward_time=0.577, loss_ctc=21.038, loss=21.038, backward_time=0.591, optim_step_time=0.036, optim0_lr0=7.041e-04, train_time=1.280
[ALab02] 2023-06-09 18:43:19,057 (trainer:721) INFO: 16epoch:train:1387-1463batch: iter_time=3.246e-04, forward_time=0.545, loss_ctc=21.788, loss=21.788, backward_time=0.566, optim_step_time=0.038, optim0_lr0=7.063e-04, train_time=1.223
[ALab02] 2023-06-09 18:45:34,342 (trainer:721) INFO: 16epoch:train:1464-1540batch: iter_time=1.339e-04, forward_time=0.903, loss_ctc=20.158, loss=20.158, backward_time=0.721, optim_step_time=0.038, optim0_lr0=7.085e-04, train_time=1.757
[ALab02] 2023-06-09 18:46:31,594 (trainer:338) INFO: 16epoch results: [train] iter_time=9.509e-04, forward_time=0.551, loss_ctc=22.087, loss=22.087, backward_time=0.580, optim_step_time=0.038, optim0_lr0=6.878e-04, train_time=1.244, time=32 minutes and 12.63 seconds, total_count=24848, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.780, cer_ctc=0.325, cer=0.325, loss=14.780, time=11.71 seconds, total_count=256, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.67 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 18:46:33,941 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 18:46:33,945 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/6epoch.pth
[ALab02] 2023-06-09 18:46:33,945 (trainer:272) INFO: 17/70epoch started. Estimated time to finish: 22 hours, 15 minutes and 56.16 seconds
[ALab02] 2023-06-09 18:48:28,378 (trainer:721) INFO: 17epoch:train:1-77batch: iter_time=0.015, forward_time=0.688, loss_ctc=20.292, loss=20.292, backward_time=0.658, optim_step_time=0.037, optim0_lr0=7.111e-04, train_time=1.486
[ALab02] 2023-06-09 18:50:20,273 (trainer:721) INFO: 17epoch:train:78-154batch: iter_time=1.475e-04, forward_time=0.668, loss_ctc=20.833, loss=20.833, backward_time=0.666, optim_step_time=0.036, optim0_lr0=7.133e-04, train_time=1.453
[ALab02] 2023-06-09 18:52:10,405 (trainer:721) INFO: 17epoch:train:155-231batch: iter_time=1.421e-04, forward_time=0.655, loss_ctc=23.030, loss=23.030, backward_time=0.653, optim_step_time=0.037, optim0_lr0=7.155e-04, train_time=1.430
[ALab02] 2023-06-09 18:53:55,176 (trainer:721) INFO: 17epoch:train:232-308batch: iter_time=1.798e-04, forward_time=0.608, loss_ctc=20.967, loss=20.967, backward_time=0.638, optim_step_time=0.038, optim0_lr0=7.177e-04, train_time=1.360
[ALab02] 2023-06-09 18:55:46,858 (trainer:721) INFO: 17epoch:train:309-385batch: iter_time=1.373e-04, forward_time=0.685, loss_ctc=21.829, loss=21.829, backward_time=0.648, optim_step_time=0.037, optim0_lr0=7.199e-04, train_time=1.450
[ALab02] 2023-06-09 18:57:39,978 (trainer:721) INFO: 17epoch:train:386-462batch: iter_time=1.597e-04, forward_time=0.677, loss_ctc=23.417, loss=23.417, backward_time=0.665, optim_step_time=0.037, optim0_lr0=7.221e-04, train_time=1.469
[ALab02] 2023-06-09 18:59:33,002 (trainer:721) INFO: 17epoch:train:463-539batch: iter_time=1.395e-04, forward_time=0.687, loss_ctc=21.481, loss=21.481, backward_time=0.658, optim_step_time=0.038, optim0_lr0=7.243e-04, train_time=1.468
[ALab02] 2023-06-09 19:01:18,170 (trainer:721) INFO: 17epoch:train:540-616batch: iter_time=3.727e-04, forward_time=0.640, loss_ctc=20.719, loss=20.719, backward_time=0.612, optim_step_time=0.039, optim0_lr0=7.265e-04, train_time=1.366
[ALab02] 2023-06-09 19:03:07,878 (trainer:721) INFO: 17epoch:train:617-693batch: iter_time=1.287e-04, forward_time=0.650, loss_ctc=23.828, loss=23.828, backward_time=0.651, optim_step_time=0.037, optim0_lr0=7.287e-04, train_time=1.425
[ALab02] 2023-06-09 19:04:57,537 (trainer:721) INFO: 17epoch:train:694-770batch: iter_time=1.556e-04, forward_time=0.643, loss_ctc=24.144, loss=24.144, backward_time=0.659, optim_step_time=0.037, optim0_lr0=7.309e-04, train_time=1.424
[ALab02] 2023-06-09 19:06:50,143 (trainer:721) INFO: 17epoch:train:771-847batch: iter_time=1.276e-04, forward_time=0.664, loss_ctc=20.568, loss=20.568, backward_time=0.674, optim_step_time=0.039, optim0_lr0=7.331e-04, train_time=1.462
[ALab02] 2023-06-09 19:08:43,502 (trainer:721) INFO: 17epoch:train:848-924batch: iter_time=1.551e-04, forward_time=0.687, loss_ctc=19.375, loss=19.375, backward_time=0.667, optim_step_time=0.037, optim0_lr0=7.353e-04, train_time=1.472
[ALab02] 2023-06-09 19:10:27,913 (trainer:721) INFO: 17epoch:train:925-1001batch: iter_time=1.390e-04, forward_time=0.621, loss_ctc=20.641, loss=20.641, backward_time=0.621, optim_step_time=0.037, optim0_lr0=7.375e-04, train_time=1.356
[ALab02] 2023-06-09 19:12:17,919 (trainer:721) INFO: 17epoch:train:1002-1078batch: iter_time=1.339e-04, forward_time=0.646, loss_ctc=23.301, loss=23.301, backward_time=0.666, optim_step_time=0.037, optim0_lr0=7.397e-04, train_time=1.428
[ALab02] 2023-06-09 19:14:08,886 (trainer:721) INFO: 17epoch:train:1079-1155batch: iter_time=1.658e-04, forward_time=0.669, loss_ctc=19.136, loss=19.136, backward_time=0.656, optim_step_time=0.037, optim0_lr0=7.419e-04, train_time=1.441
[ALab02] 2023-06-09 19:15:59,112 (trainer:721) INFO: 17epoch:train:1156-1232batch: iter_time=1.424e-04, forward_time=0.661, loss_ctc=22.469, loss=22.469, backward_time=0.655, optim_step_time=0.039, optim0_lr0=7.441e-04, train_time=1.431
[ALab02] 2023-06-09 19:17:47,574 (trainer:721) INFO: 17epoch:train:1233-1309batch: iter_time=1.558e-04, forward_time=0.634, loss_ctc=22.057, loss=22.057, backward_time=0.661, optim_step_time=0.037, optim0_lr0=7.463e-04, train_time=1.408
[ALab02] 2023-06-09 19:19:30,383 (trainer:721) INFO: 17epoch:train:1310-1386batch: iter_time=1.539e-04, forward_time=0.593, loss_ctc=20.799, loss=20.799, backward_time=0.620, optim_step_time=0.039, optim0_lr0=7.485e-04, train_time=1.335
[ALab02] 2023-06-09 19:21:22,995 (trainer:721) INFO: 17epoch:train:1387-1463batch: iter_time=1.328e-04, forward_time=0.676, loss_ctc=20.826, loss=20.826, backward_time=0.673, optim_step_time=0.037, optim0_lr0=7.507e-04, train_time=1.462
[ALab02] 2023-06-09 19:23:12,929 (trainer:721) INFO: 17epoch:train:1464-1540batch: iter_time=1.630e-04, forward_time=0.644, loss_ctc=21.396, loss=21.396, backward_time=0.669, optim_step_time=0.037, optim0_lr0=7.529e-04, train_time=1.427
[ALab02] 2023-06-09 19:24:10,039 (trainer:338) INFO: 17epoch results: [train] iter_time=9.012e-04, forward_time=0.654, loss_ctc=21.504, loss=21.504, backward_time=0.653, optim_step_time=0.037, optim0_lr0=7.322e-04, train_time=1.427, time=36 minutes and 57.12 seconds, total_count=26401, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=16.052, cer_ctc=0.327, cer=0.327, loss=16.052, time=11.62 seconds, total_count=272, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.34 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 19:24:12,336 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-09 19:24:12,338 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/7epoch.pth
[ALab02] 2023-06-09 19:24:12,338 (trainer:272) INFO: 18/70epoch started. Estimated time to finish: 22 hours, 31 minutes and 24.91 seconds
[ALab02] 2023-06-09 19:26:08,591 (trainer:721) INFO: 18epoch:train:1-77batch: iter_time=0.014, forward_time=0.715, loss_ctc=19.135, loss=19.135, backward_time=0.647, optim_step_time=0.037, optim0_lr0=7.555e-04, train_time=1.509
[ALab02] 2023-06-09 19:27:55,242 (trainer:721) INFO: 18epoch:train:78-154batch: iter_time=1.706e-04, forward_time=0.663, loss_ctc=16.847, loss=16.847, backward_time=0.608, optim_step_time=0.037, optim0_lr0=7.577e-04, train_time=1.385
[ALab02] 2023-06-09 19:29:46,274 (trainer:721) INFO: 18epoch:train:155-231batch: iter_time=1.352e-04, forward_time=0.658, loss_ctc=22.121, loss=22.121, backward_time=0.661, optim_step_time=0.037, optim0_lr0=7.599e-04, train_time=1.442
[ALab02] 2023-06-09 19:31:37,229 (trainer:721) INFO: 18epoch:train:232-308batch: iter_time=1.348e-04, forward_time=0.664, loss_ctc=21.219, loss=21.219, backward_time=0.667, optim_step_time=0.037, optim0_lr0=7.621e-04, train_time=1.441
[ALab02] 2023-06-09 19:33:26,346 (trainer:721) INFO: 18epoch:train:309-385batch: iter_time=1.600e-04, forward_time=0.647, loss_ctc=21.606, loss=21.606, backward_time=0.657, optim_step_time=0.038, optim0_lr0=7.643e-04, train_time=1.417
[ALab02] 2023-06-09 19:35:18,483 (trainer:721) INFO: 18epoch:train:386-462batch: iter_time=1.468e-04, forward_time=0.672, loss_ctc=22.399, loss=22.399, backward_time=0.665, optim_step_time=0.037, optim0_lr0=7.665e-04, train_time=1.456
[ALab02] 2023-06-09 19:37:00,417 (trainer:721) INFO: 18epoch:train:463-539batch: iter_time=1.531e-04, forward_time=0.585, loss_ctc=24.720, loss=24.720, backward_time=0.613, optim_step_time=0.038, optim0_lr0=7.687e-04, train_time=1.324
[ALab02] 2023-06-09 19:38:54,412 (trainer:721) INFO: 18epoch:train:540-616batch: iter_time=1.597e-04, forward_time=0.706, loss_ctc=18.424, loss=18.424, backward_time=0.660, optim_step_time=0.038, optim0_lr0=7.709e-04, train_time=1.480
[ALab02] 2023-06-09 19:40:46,435 (trainer:721) INFO: 18epoch:train:617-693batch: iter_time=1.433e-04, forward_time=0.684, loss_ctc=21.448, loss=21.448, backward_time=0.650, optim_step_time=0.037, optim0_lr0=7.731e-04, train_time=1.455
[ALab02] 2023-06-09 19:42:35,380 (trainer:721) INFO: 18epoch:train:694-770batch: iter_time=1.497e-04, forward_time=0.632, loss_ctc=23.740, loss=23.740, backward_time=0.665, optim_step_time=0.037, optim0_lr0=7.753e-04, train_time=1.415
[ALab02] 2023-06-09 19:44:17,323 (trainer:721) INFO: 18epoch:train:771-847batch: iter_time=1.494e-04, forward_time=0.589, loss_ctc=23.081, loss=23.081, backward_time=0.624, optim_step_time=0.037, optim0_lr0=7.775e-04, train_time=1.324
[ALab02] 2023-06-09 19:46:08,549 (trainer:721) INFO: 18epoch:train:848-924batch: iter_time=1.577e-04, forward_time=0.675, loss_ctc=20.990, loss=20.990, backward_time=0.651, optim_step_time=0.037, optim0_lr0=7.797e-04, train_time=1.444
[ALab02] 2023-06-09 19:47:59,468 (trainer:721) INFO: 18epoch:train:925-1001batch: iter_time=1.592e-04, forward_time=0.657, loss_ctc=21.340, loss=21.340, backward_time=0.661, optim_step_time=0.037, optim0_lr0=7.819e-04, train_time=1.440
[ALab02] 2023-06-09 19:49:51,173 (trainer:721) INFO: 18epoch:train:1002-1078batch: iter_time=1.354e-04, forward_time=0.667, loss_ctc=20.673, loss=20.673, backward_time=0.657, optim_step_time=0.039, optim0_lr0=7.841e-04, train_time=1.450
[ALab02] 2023-06-09 19:51:43,522 (trainer:721) INFO: 18epoch:train:1079-1155batch: iter_time=1.720e-04, forward_time=0.671, loss_ctc=21.739, loss=21.739, backward_time=0.669, optim_step_time=0.039, optim0_lr0=7.863e-04, train_time=1.459
[ALab02] 2023-06-09 19:53:25,948 (trainer:721) INFO: 18epoch:train:1156-1232batch: iter_time=1.464e-04, forward_time=0.603, loss_ctc=22.088, loss=22.088, backward_time=0.610, optim_step_time=0.037, optim0_lr0=7.885e-04, train_time=1.330
[ALab02] 2023-06-09 19:55:20,878 (trainer:721) INFO: 18epoch:train:1233-1309batch: iter_time=1.780e-04, forward_time=0.692, loss_ctc=21.274, loss=21.274, backward_time=0.681, optim_step_time=0.037, optim0_lr0=7.907e-04, train_time=1.492
[ALab02] 2023-06-09 19:57:09,266 (trainer:721) INFO: 18epoch:train:1310-1386batch: iter_time=2.500e-04, forward_time=0.636, loss_ctc=20.759, loss=20.759, backward_time=0.653, optim_step_time=0.040, optim0_lr0=7.929e-04, train_time=1.407
[ALab02] 2023-06-09 19:59:06,106 (trainer:721) INFO: 18epoch:train:1387-1463batch: iter_time=1.631e-04, forward_time=0.719, loss_ctc=19.978, loss=19.978, backward_time=0.675, optim_step_time=0.036, optim0_lr0=7.951e-04, train_time=1.517
[ALab02] 2023-06-09 20:00:55,410 (trainer:721) INFO: 18epoch:train:1464-1540batch: iter_time=1.645e-04, forward_time=0.644, loss_ctc=19.805, loss=19.805, backward_time=0.664, optim_step_time=0.037, optim0_lr0=7.973e-04, train_time=1.419
[ALab02] 2023-06-09 20:01:54,046 (trainer:338) INFO: 18epoch results: [train] iter_time=8.591e-04, forward_time=0.659, loss_ctc=21.062, loss=21.062, backward_time=0.652, optim_step_time=0.038, optim0_lr0=7.765e-04, train_time=1.431, time=37 minutes and 2.37 seconds, total_count=27954, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=15.306, cer_ctc=0.314, cer=0.314, loss=15.306, time=11.59 seconds, total_count=288, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.74 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 20:01:56,275 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 20:01:56,277 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/8epoch.pth
[ALab02] 2023-06-09 20:01:56,277 (trainer:272) INFO: 19/70epoch started. Estimated time to finish: 22 hours, 41 minutes and 15.55 seconds
[ALab02] 2023-06-09 20:03:51,024 (trainer:721) INFO: 19epoch:train:1-77batch: iter_time=0.016, forward_time=0.684, loss_ctc=20.730, loss=20.730, backward_time=0.664, optim_step_time=0.037, optim0_lr0=7.998e-04, train_time=1.490
[ALab02] 2023-06-09 20:05:42,224 (trainer:721) INFO: 19epoch:train:78-154batch: iter_time=1.453e-04, forward_time=0.673, loss_ctc=20.502, loss=20.502, backward_time=0.650, optim_step_time=0.038, optim0_lr0=8.020e-04, train_time=1.444
[ALab02] 2023-06-09 20:07:33,864 (trainer:721) INFO: 19epoch:train:155-231batch: iter_time=1.207e-04, forward_time=0.666, loss_ctc=20.892, loss=20.892, backward_time=0.663, optim_step_time=0.037, optim0_lr0=8.042e-04, train_time=1.450
[ALab02] 2023-06-09 20:09:32,687 (trainer:721) INFO: 19epoch:train:232-308batch: iter_time=2.120e-04, forward_time=0.764, loss_ctc=17.993, loss=17.993, backward_time=0.655, optim_step_time=0.039, optim0_lr0=8.064e-04, train_time=1.543
[ALab02] 2023-06-09 20:11:15,724 (trainer:721) INFO: 19epoch:train:309-385batch: iter_time=1.602e-04, forward_time=0.627, loss_ctc=19.554, loss=19.554, backward_time=0.607, optim_step_time=0.040, optim0_lr0=8.086e-04, train_time=1.338
[ALab02] 2023-06-09 20:13:08,304 (trainer:721) INFO: 19epoch:train:386-462batch: iter_time=1.923e-04, forward_time=0.684, loss_ctc=19.665, loss=19.665, backward_time=0.660, optim_step_time=0.039, optim0_lr0=8.108e-04, train_time=1.462
[ALab02] 2023-06-09 20:15:01,510 (trainer:721) INFO: 19epoch:train:463-539batch: iter_time=1.448e-04, forward_time=0.680, loss_ctc=19.460, loss=19.460, backward_time=0.668, optim_step_time=0.036, optim0_lr0=8.130e-04, train_time=1.470
[ALab02] 2023-06-09 20:16:50,993 (trainer:721) INFO: 19epoch:train:540-616batch: iter_time=1.753e-04, forward_time=0.648, loss_ctc=20.431, loss=20.431, backward_time=0.660, optim_step_time=0.040, optim0_lr0=8.152e-04, train_time=1.422
[ALab02] 2023-06-09 20:18:42,749 (trainer:721) INFO: 19epoch:train:617-693batch: iter_time=1.504e-04, forward_time=0.678, loss_ctc=22.082, loss=22.082, backward_time=0.649, optim_step_time=0.039, optim0_lr0=8.174e-04, train_time=1.451
[ALab02] 2023-06-09 20:20:26,029 (trainer:721) INFO: 19epoch:train:694-770batch: iter_time=2.001e-04, forward_time=0.616, loss_ctc=20.088, loss=20.088, backward_time=0.602, optim_step_time=0.039, optim0_lr0=8.196e-04, train_time=1.341
[ALab02] 2023-06-09 20:22:19,434 (trainer:721) INFO: 19epoch:train:771-847batch: iter_time=2.061e-04, forward_time=0.681, loss_ctc=20.974, loss=20.974, backward_time=0.668, optim_step_time=0.038, optim0_lr0=8.218e-04, train_time=1.473
[ALab02] 2023-06-09 20:24:09,144 (trainer:721) INFO: 19epoch:train:848-924batch: iter_time=1.713e-04, forward_time=0.643, loss_ctc=20.808, loss=20.808, backward_time=0.659, optim_step_time=0.039, optim0_lr0=8.240e-04, train_time=1.425
[ALab02] 2023-06-09 20:25:32,476 (trainer:721) INFO: 19epoch:train:925-1001batch: iter_time=1.545e-04, forward_time=0.469, loss_ctc=22.590, loss=22.590, backward_time=0.502, optim_step_time=0.038, optim0_lr0=8.262e-04, train_time=1.082
[ALab02] 2023-06-09 20:26:20,390 (trainer:721) INFO: 19epoch:train:1002-1078batch: iter_time=1.407e-04, forward_time=0.232, loss_ctc=23.037, loss=23.037, backward_time=0.309, optim_step_time=0.038, optim0_lr0=8.284e-04, train_time=0.622
[ALab02] 2023-06-09 20:28:09,398 (trainer:721) INFO: 19epoch:train:1079-1155batch: iter_time=1.572e-04, forward_time=0.656, loss_ctc=22.143, loss=22.143, backward_time=0.644, optim_step_time=0.038, optim0_lr0=8.306e-04, train_time=1.415
[ALab02] 2023-06-09 20:29:58,193 (trainer:721) INFO: 19epoch:train:1156-1232batch: iter_time=1.470e-04, forward_time=0.632, loss_ctc=21.276, loss=21.276, backward_time=0.662, optim_step_time=0.038, optim0_lr0=8.328e-04, train_time=1.413
[ALab02] 2023-06-09 20:31:49,872 (trainer:721) INFO: 19epoch:train:1233-1309batch: iter_time=1.632e-04, forward_time=0.654, loss_ctc=22.876, loss=22.876, backward_time=0.674, optim_step_time=0.038, optim0_lr0=8.350e-04, train_time=1.450
[ALab02] 2023-06-09 20:33:44,359 (trainer:721) INFO: 19epoch:train:1310-1386batch: iter_time=1.921e-04, forward_time=0.708, loss_ctc=18.908, loss=18.908, backward_time=0.659, optim_step_time=0.038, optim0_lr0=8.372e-04, train_time=1.487
[ALab02] 2023-06-09 20:35:26,969 (trainer:721) INFO: 19epoch:train:1387-1463batch: iter_time=1.655e-04, forward_time=0.595, loss_ctc=22.087, loss=22.087, backward_time=0.618, optim_step_time=0.038, optim0_lr0=8.394e-04, train_time=1.332
[ALab02] 2023-06-09 20:37:18,801 (trainer:721) INFO: 19epoch:train:1464-1540batch: iter_time=1.518e-04, forward_time=0.671, loss_ctc=20.955, loss=20.955, backward_time=0.663, optim_step_time=0.038, optim0_lr0=8.416e-04, train_time=1.452
[ALab02] 2023-06-09 20:38:16,951 (trainer:338) INFO: 19epoch results: [train] iter_time=9.637e-04, forward_time=0.633, loss_ctc=20.794, loss=20.794, backward_time=0.627, optim_step_time=0.038, optim0_lr0=8.209e-04, train_time=1.378, time=35 minutes and 40.92 seconds, total_count=29507, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=15.224, cer_ctc=0.320, cer=0.320, loss=15.224, time=11.59 seconds, total_count=304, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.16 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 20:38:19,270 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-09 20:38:19,271 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/9epoch.pth
[ALab02] 2023-06-09 20:38:19,271 (trainer:272) INFO: 20/70epoch started. Estimated time to finish: 22 hours, 42 minutes and 28.44 seconds
[ALab02] 2023-06-09 20:40:10,290 (trainer:721) INFO: 20epoch:train:1-77batch: iter_time=0.016, forward_time=0.639, loss_ctc=21.118, loss=21.118, backward_time=0.666, optim_step_time=0.039, optim0_lr0=8.442e-04, train_time=1.441
[ALab02] 2023-06-09 20:42:06,216 (trainer:721) INFO: 20epoch:train:78-154batch: iter_time=1.619e-04, forward_time=0.709, loss_ctc=18.570, loss=18.570, backward_time=0.668, optim_step_time=0.039, optim0_lr0=8.464e-04, train_time=1.505
[ALab02] 2023-06-09 20:43:45,809 (trainer:721) INFO: 20epoch:train:155-231batch: iter_time=1.462e-04, forward_time=0.572, loss_ctc=21.631, loss=21.631, backward_time=0.608, optim_step_time=0.038, optim0_lr0=8.486e-04, train_time=1.293
[ALab02] 2023-06-09 20:45:36,889 (trainer:721) INFO: 20epoch:train:232-308batch: iter_time=1.727e-04, forward_time=0.673, loss_ctc=21.153, loss=21.153, backward_time=0.651, optim_step_time=0.038, optim0_lr0=8.508e-04, train_time=1.442
[ALab02] 2023-06-09 20:47:30,241 (trainer:721) INFO: 20epoch:train:309-385batch: iter_time=2.073e-04, forward_time=0.682, loss_ctc=20.578, loss=20.578, backward_time=0.663, optim_step_time=0.038, optim0_lr0=8.530e-04, train_time=1.472
[ALab02] 2023-06-09 20:49:23,616 (trainer:721) INFO: 20epoch:train:386-462batch: iter_time=1.504e-04, forward_time=0.684, loss_ctc=19.325, loss=19.325, backward_time=0.664, optim_step_time=0.037, optim0_lr0=8.552e-04, train_time=1.472
[ALab02] 2023-06-09 20:51:16,639 (trainer:721) INFO: 20epoch:train:463-539batch: iter_time=1.518e-04, forward_time=0.694, loss_ctc=21.056, loss=21.056, backward_time=0.646, optim_step_time=0.037, optim0_lr0=8.574e-04, train_time=1.468
[ALab02] 2023-06-09 20:53:03,811 (trainer:721) INFO: 20epoch:train:540-616batch: iter_time=1.361e-04, forward_time=0.679, loss_ctc=17.046, loss=17.046, backward_time=0.600, optim_step_time=0.039, optim0_lr0=8.596e-04, train_time=1.392
[ALab02] 2023-06-09 20:54:26,651 (trainer:721) INFO: 20epoch:train:617-693batch: iter_time=1.548e-04, forward_time=0.466, loss_ctc=20.638, loss=20.638, backward_time=0.500, optim_step_time=0.038, optim0_lr0=8.618e-04, train_time=1.076
[ALab02] 2023-06-09 20:56:10,028 (trainer:721) INFO: 20epoch:train:694-770batch: iter_time=1.912e-04, forward_time=0.591, loss_ctc=22.133, loss=22.133, backward_time=0.640, optim_step_time=0.040, optim0_lr0=8.640e-04, train_time=1.342
[ALab02] 2023-06-09 20:58:00,888 (trainer:721) INFO: 20epoch:train:771-847batch: iter_time=1.583e-04, forward_time=0.656, loss_ctc=21.368, loss=21.368, backward_time=0.669, optim_step_time=0.038, optim0_lr0=8.662e-04, train_time=1.439
[ALab02] 2023-06-09 20:59:53,494 (trainer:721) INFO: 20epoch:train:848-924batch: iter_time=1.670e-04, forward_time=0.671, loss_ctc=19.653, loss=19.653, backward_time=0.663, optim_step_time=0.038, optim0_lr0=8.684e-04, train_time=1.462
[ALab02] 2023-06-09 21:01:46,070 (trainer:721) INFO: 20epoch:train:925-1001batch: iter_time=1.409e-04, forward_time=0.659, loss_ctc=20.321, loss=20.321, backward_time=0.681, optim_step_time=0.038, optim0_lr0=8.706e-04, train_time=1.462
[ALab02] 2023-06-09 21:03:27,914 (trainer:721) INFO: 20epoch:train:1002-1078batch: iter_time=1.638e-04, forward_time=0.587, loss_ctc=22.161, loss=22.161, backward_time=0.619, optim_step_time=0.040, optim0_lr0=8.728e-04, train_time=1.322
[ALab02] 2023-06-09 21:05:19,449 (trainer:721) INFO: 20epoch:train:1079-1155batch: iter_time=1.762e-04, forward_time=0.678, loss_ctc=19.469, loss=19.469, backward_time=0.654, optim_step_time=0.038, optim0_lr0=8.750e-04, train_time=1.448
[ALab02] 2023-06-09 21:07:12,272 (trainer:721) INFO: 20epoch:train:1156-1232batch: iter_time=1.876e-04, forward_time=0.683, loss_ctc=19.165, loss=19.165, backward_time=0.666, optim_step_time=0.038, optim0_lr0=8.772e-04, train_time=1.465
[ALab02] 2023-06-09 21:09:01,588 (trainer:721) INFO: 20epoch:train:1233-1309batch: iter_time=1.388e-04, forward_time=0.641, loss_ctc=20.456, loss=20.456, backward_time=0.661, optim_step_time=0.039, optim0_lr0=8.794e-04, train_time=1.419
[ALab02] 2023-06-09 21:10:54,315 (trainer:721) INFO: 20epoch:train:1310-1386batch: iter_time=2.443e-04, forward_time=0.665, loss_ctc=21.223, loss=21.223, backward_time=0.673, optim_step_time=0.040, optim0_lr0=8.816e-04, train_time=1.464
[ALab02] 2023-06-09 21:12:48,515 (trainer:721) INFO: 20epoch:train:1387-1463batch: iter_time=7.232e-04, forward_time=0.705, loss_ctc=21.040, loss=21.040, backward_time=0.583, optim_step_time=0.098, optim0_lr0=8.838e-04, train_time=1.482
[ALab02] 2023-06-09 21:15:17,156 (trainer:721) INFO: 20epoch:train:1464-1540batch: iter_time=5.231e-04, forward_time=0.945, loss_ctc=20.707, loss=20.707, backward_time=0.722, optim_step_time=0.133, optim0_lr0=8.860e-04, train_time=1.930
[ALab02] 2023-06-09 21:17:54,570 (trainer:338) INFO: 20epoch results: [train] iter_time=0.001, forward_time=0.669, loss_ctc=20.347, loss=20.347, backward_time=0.646, optim_step_time=0.048, optim0_lr0=8.653e-04, train_time=1.449, time=37 minutes and 30.86 seconds, total_count=31060, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=15.084, cer_ctc=0.311, cer=0.311, loss=15.084, time=23.45 seconds, total_count=320, gpu_max_cached_mem_GB=77.078, [att_plot] time=1 minute and 40.99 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 21:17:57,418 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 21:17:57,420 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/10epoch.pth
[ALab02] 2023-06-09 21:17:57,420 (trainer:272) INFO: 21/70epoch started. Estimated time to finish: 22 hours, 48 minutes and 3.62 seconds
[ALab02] 2023-06-09 21:21:27,068 (trainer:721) INFO: 21epoch:train:1-77batch: iter_time=0.029, forward_time=1.270, loss_ctc=18.283, loss=18.283, backward_time=0.818, optim_step_time=0.354, optim0_lr0=8.886e-04, train_time=2.720
[ALab02] 2023-06-09 21:25:52,082 (trainer:721) INFO: 21epoch:train:78-154batch: iter_time=0.002, forward_time=1.673, loss_ctc=19.767, loss=19.767, backward_time=0.922, optim_step_time=0.507, optim0_lr0=8.908e-04, train_time=3.440
[ALab02] 2023-06-09 21:29:37,674 (trainer:721) INFO: 21epoch:train:155-231batch: iter_time=0.002, forward_time=1.473, loss_ctc=18.717, loss=18.717, backward_time=0.868, optim_step_time=0.340, optim0_lr0=8.930e-04, train_time=2.927
[ALab02] 2023-06-09 21:32:17,300 (trainer:721) INFO: 21epoch:train:232-308batch: iter_time=6.365e-04, forward_time=0.974, loss_ctc=19.546, loss=19.546, backward_time=0.862, optim_step_time=0.108, optim0_lr0=8.952e-04, train_time=2.073
[ALab02] 2023-06-09 21:34:01,497 (trainer:721) INFO: 21epoch:train:309-385batch: iter_time=3.762e-04, forward_time=0.610, loss_ctc=20.323, loss=20.323, backward_time=0.627, optim_step_time=0.043, optim0_lr0=8.974e-04, train_time=1.353
[ALab02] 2023-06-09 21:38:23,682 (trainer:721) INFO: 21epoch:train:386-462batch: iter_time=0.002, forward_time=1.702, loss_ctc=20.537, loss=20.537, backward_time=0.975, optim_step_time=0.385, optim0_lr0=8.996e-04, train_time=3.403
[ALab02] 2023-06-09 21:42:02,237 (trainer:721) INFO: 21epoch:train:463-539batch: iter_time=0.002, forward_time=1.509, loss_ctc=20.418, loss=20.418, backward_time=0.752, optim_step_time=0.287, optim0_lr0=9.018e-04, train_time=2.836
[ALab02] 2023-06-09 21:44:58,456 (trainer:721) INFO: 21epoch:train:540-616batch: iter_time=0.003, forward_time=1.058, loss_ctc=18.958, loss=18.958, backward_time=0.804, optim_step_time=0.255, optim0_lr0=9.040e-04, train_time=2.288
[ALab02] 2023-06-09 21:49:48,119 (trainer:721) INFO: 21epoch:train:617-693batch: iter_time=0.004, forward_time=2.112, loss_ctc=18.201, loss=18.201, backward_time=0.924, optim_step_time=0.414, optim0_lr0=9.062e-04, train_time=3.759
[ALab02] 2023-06-09 21:54:24,920 (trainer:721) INFO: 21epoch:train:694-770batch: iter_time=0.003, forward_time=1.635, loss_ctc=17.935, loss=17.935, backward_time=1.203, optim_step_time=0.415, optim0_lr0=9.084e-04, train_time=3.592
[ALab02] 2023-06-09 21:58:28,900 (trainer:721) INFO: 21epoch:train:771-847batch: iter_time=0.002, forward_time=1.623, loss_ctc=21.779, loss=21.779, backward_time=1.007, optim_step_time=0.314, optim0_lr0=9.106e-04, train_time=3.166
[ALab02] 2023-06-09 22:02:21,939 (trainer:721) INFO: 21epoch:train:848-924batch: iter_time=0.002, forward_time=1.574, loss_ctc=18.470, loss=18.470, backward_time=0.857, optim_step_time=0.363, optim0_lr0=9.128e-04, train_time=3.024
[ALab02] 2023-06-09 22:06:57,094 (trainer:721) INFO: 21epoch:train:925-1001batch: iter_time=0.003, forward_time=1.537, loss_ctc=21.909, loss=21.909, backward_time=1.013, optim_step_time=0.627, optim0_lr0=9.150e-04, train_time=3.570
[ALab02] 2023-06-09 22:10:52,391 (trainer:721) INFO: 21epoch:train:1002-1078batch: iter_time=0.002, forward_time=1.414, loss_ctc=22.266, loss=22.266, backward_time=0.940, optim_step_time=0.380, optim0_lr0=9.172e-04, train_time=3.053
[ALab02] 2023-06-09 22:14:33,987 (trainer:721) INFO: 21epoch:train:1079-1155batch: iter_time=0.002, forward_time=1.428, loss_ctc=19.958, loss=19.958, backward_time=0.854, optim_step_time=0.288, optim0_lr0=9.194e-04, train_time=2.877
[ALab02] 2023-06-09 22:17:09,428 (trainer:721) INFO: 21epoch:train:1156-1232batch: iter_time=8.492e-04, forward_time=0.903, loss_ctc=21.045, loss=21.045, backward_time=0.798, optim_step_time=0.163, optim0_lr0=9.216e-04, train_time=2.018
[ALab02] 2023-06-09 22:18:59,960 (trainer:721) INFO: 21epoch:train:1233-1309batch: iter_time=3.388e-04, forward_time=0.666, loss_ctc=19.594, loss=19.594, backward_time=0.601, optim_step_time=0.080, optim0_lr0=9.238e-04, train_time=1.435
[ALab02] 2023-06-09 22:21:01,902 (trainer:721) INFO: 21epoch:train:1310-1386batch: iter_time=5.066e-04, forward_time=0.777, loss_ctc=21.320, loss=21.320, backward_time=0.641, optim_step_time=0.074, optim0_lr0=9.260e-04, train_time=1.583
[ALab02] 2023-06-09 22:23:03,207 (trainer:721) INFO: 21epoch:train:1387-1463batch: iter_time=6.081e-04, forward_time=0.721, loss_ctc=18.844, loss=18.844, backward_time=0.701, optim_step_time=0.061, optim0_lr0=9.282e-04, train_time=1.575
[ALab02] 2023-06-09 22:25:08,785 (trainer:721) INFO: 21epoch:train:1464-1540batch: iter_time=5.724e-04, forward_time=0.757, loss_ctc=18.229, loss=18.229, backward_time=0.654, optim_step_time=0.112, optim0_lr0=9.304e-04, train_time=1.630
[ALab02] 2023-06-09 22:26:23,458 (trainer:338) INFO: 21epoch results: [train] iter_time=0.003, forward_time=1.266, loss_ctc=19.746, loss=19.746, backward_time=0.839, optim_step_time=0.277, optim0_lr0=9.097e-04, train_time=2.607, time=1 hour, 7 minutes and 31 seconds, total_count=32613, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.795, cer_ctc=0.306, cer=0.306, loss=13.795, time=12.58 seconds, total_count=336, gpu_max_cached_mem_GB=77.078, [att_plot] time=42.45 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 22:26:26,862 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 22:26:26,864 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/11epoch.pth
[ALab02] 2023-06-09 22:26:26,864 (trainer:272) INFO: 22/70epoch started. Estimated time to finish: 23 hours, 56 minutes and 40.08 seconds
[ALab02] 2023-06-09 22:28:46,088 (trainer:721) INFO: 22epoch:train:1-77batch: iter_time=0.021, forward_time=0.854, loss_ctc=19.544, loss=19.544, backward_time=0.678, optim_step_time=0.110, optim0_lr0=9.329e-04, train_time=1.807
[ALab02] 2023-06-09 22:31:01,822 (trainer:721) INFO: 22epoch:train:78-154batch: iter_time=5.479e-04, forward_time=0.876, loss_ctc=17.794, loss=17.794, backward_time=0.688, optim_step_time=0.091, optim0_lr0=9.351e-04, train_time=1.762
[ALab02] 2023-06-09 22:33:08,604 (trainer:721) INFO: 22epoch:train:155-231batch: iter_time=5.494e-04, forward_time=0.773, loss_ctc=19.670, loss=19.670, backward_time=0.654, optim_step_time=0.111, optim0_lr0=9.373e-04, train_time=1.646
[ALab02] 2023-06-09 22:35:07,230 (trainer:721) INFO: 22epoch:train:232-308batch: iter_time=5.012e-04, forward_time=0.714, loss_ctc=21.245, loss=21.245, backward_time=0.628, optim_step_time=0.090, optim0_lr0=9.395e-04, train_time=1.540
[ALab02] 2023-06-09 22:37:23,371 (trainer:721) INFO: 22epoch:train:309-385batch: iter_time=3.417e-04, forward_time=0.806, loss_ctc=21.054, loss=21.054, backward_time=0.737, optim_step_time=0.104, optim0_lr0=9.417e-04, train_time=1.768
[ALab02] 2023-06-09 22:39:39,876 (trainer:721) INFO: 22epoch:train:386-462batch: iter_time=8.826e-04, forward_time=0.901, loss_ctc=19.734, loss=19.734, backward_time=0.656, optim_step_time=0.102, optim0_lr0=9.439e-04, train_time=1.772
[ALab02] 2023-06-09 22:41:48,857 (trainer:721) INFO: 22epoch:train:463-539batch: iter_time=7.337e-04, forward_time=0.740, loss_ctc=19.085, loss=19.085, backward_time=0.690, optim_step_time=0.100, optim0_lr0=9.461e-04, train_time=1.675
[ALab02] 2023-06-09 22:44:17,012 (trainer:721) INFO: 22epoch:train:540-616batch: iter_time=0.001, forward_time=0.951, loss_ctc=16.296, loss=16.296, backward_time=0.683, optim_step_time=0.147, optim0_lr0=9.483e-04, train_time=1.923
[ALab02] 2023-06-09 22:46:47,202 (trainer:721) INFO: 22epoch:train:617-693batch: iter_time=9.052e-04, forward_time=0.948, loss_ctc=18.265, loss=18.265, backward_time=0.675, optim_step_time=0.194, optim0_lr0=9.505e-04, train_time=1.950
[ALab02] 2023-06-09 22:49:12,285 (trainer:721) INFO: 22epoch:train:694-770batch: iter_time=8.404e-04, forward_time=0.944, loss_ctc=18.838, loss=18.838, backward_time=0.670, optim_step_time=0.134, optim0_lr0=9.527e-04, train_time=1.883
[ALab02] 2023-06-09 22:50:56,530 (trainer:721) INFO: 22epoch:train:771-847batch: iter_time=4.402e-04, forward_time=0.622, loss_ctc=20.097, loss=20.097, backward_time=0.596, optim_step_time=0.053, optim0_lr0=9.549e-04, train_time=1.354
[ALab02] 2023-06-09 22:53:21,637 (trainer:721) INFO: 22epoch:train:848-924batch: iter_time=6.982e-04, forward_time=0.832, loss_ctc=21.053, loss=21.053, backward_time=0.783, optim_step_time=0.145, optim0_lr0=9.571e-04, train_time=1.884
[ALab02] 2023-06-09 22:55:23,856 (trainer:721) INFO: 22epoch:train:925-1001batch: iter_time=3.790e-04, forward_time=0.765, loss_ctc=20.105, loss=20.105, backward_time=0.642, optim_step_time=0.078, optim0_lr0=9.593e-04, train_time=1.587
[ALab02] 2023-06-09 22:57:17,670 (trainer:721) INFO: 22epoch:train:1002-1078batch: iter_time=2.848e-04, forward_time=0.684, loss_ctc=19.928, loss=19.928, backward_time=0.659, optim_step_time=0.048, optim0_lr0=9.615e-04, train_time=1.478
[ALab02] 2023-06-09 22:59:03,928 (trainer:721) INFO: 22epoch:train:1079-1155batch: iter_time=1.747e-04, forward_time=0.627, loss_ctc=19.906, loss=19.906, backward_time=0.628, optim_step_time=0.040, optim0_lr0=9.637e-04, train_time=1.380
[ALab02] 2023-06-09 23:00:58,411 (trainer:721) INFO: 22epoch:train:1156-1232batch: iter_time=2.026e-04, forward_time=0.709, loss_ctc=18.931, loss=18.931, backward_time=0.664, optim_step_time=0.041, optim0_lr0=9.659e-04, train_time=1.487
[ALab02] 2023-06-09 23:02:50,574 (trainer:721) INFO: 22epoch:train:1233-1309batch: iter_time=1.806e-04, forward_time=0.652, loss_ctc=20.281, loss=20.281, backward_time=0.677, optim_step_time=0.040, optim0_lr0=9.681e-04, train_time=1.456
[ALab02] 2023-06-09 23:04:43,472 (trainer:721) INFO: 22epoch:train:1310-1386batch: iter_time=1.816e-04, forward_time=0.681, loss_ctc=18.997, loss=18.997, backward_time=0.659, optim_step_time=0.041, optim0_lr0=9.703e-04, train_time=1.466
[ALab02] 2023-06-09 23:06:37,984 (trainer:721) INFO: 22epoch:train:1387-1463batch: iter_time=2.174e-04, forward_time=0.690, loss_ctc=19.682, loss=19.682, backward_time=0.666, optim_step_time=0.044, optim0_lr0=9.725e-04, train_time=1.487
[ALab02] 2023-06-09 23:08:18,504 (trainer:721) INFO: 22epoch:train:1464-1540batch: iter_time=2.107e-04, forward_time=0.600, loss_ctc=18.678, loss=18.678, backward_time=0.599, optim_step_time=0.041, optim0_lr0=9.747e-04, train_time=1.305
[ALab02] 2023-06-09 23:09:18,790 (trainer:338) INFO: 22epoch results: [train] iter_time=0.002, forward_time=0.767, loss_ctc=19.433, loss=19.433, backward_time=0.667, optim_step_time=0.087, optim0_lr0=9.540e-04, train_time=1.628, time=42 minutes and 9.77 seconds, total_count=34166, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.404, cer_ctc=0.308, cer=0.308, loss=14.404, time=12.13 seconds, total_count=352, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.02 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 23:09:21,407 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-09 23:09:21,409 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/12epoch.pth
[ALab02] 2023-06-09 23:09:21,410 (trainer:272) INFO: 23/70epoch started. Estimated time to finish: 23 hours, 56 minutes and 59.87 seconds
[ALab02] 2023-06-09 23:11:12,500 (trainer:721) INFO: 23epoch:train:1-77batch: iter_time=0.018, forward_time=0.645, loss_ctc=17.852, loss=17.852, backward_time=0.659, optim_step_time=0.042, optim0_lr0=9.773e-04, train_time=1.442
[ALab02] 2023-06-09 23:12:00,974 (trainer:721) INFO: 23epoch:train:78-154batch: iter_time=1.900e-04, forward_time=0.240, loss_ctc=16.919, loss=16.919, backward_time=0.305, optim_step_time=0.042, optim0_lr0=9.795e-04, train_time=0.629
[ALab02] 2023-06-09 23:12:49,850 (trainer:721) INFO: 23epoch:train:155-231batch: iter_time=1.918e-04, forward_time=0.239, loss_ctc=20.938, loss=20.938, backward_time=0.308, optim_step_time=0.041, optim0_lr0=9.817e-04, train_time=0.635
[ALab02] 2023-06-09 23:13:37,530 (trainer:721) INFO: 23epoch:train:232-308batch: iter_time=1.719e-04, forward_time=0.232, loss_ctc=21.082, loss=21.082, backward_time=0.304, optim_step_time=0.040, optim0_lr0=9.839e-04, train_time=0.619
[ALab02] 2023-06-09 23:14:25,014 (trainer:721) INFO: 23epoch:train:309-385batch: iter_time=1.564e-04, forward_time=0.231, loss_ctc=21.992, loss=21.992, backward_time=0.300, optim_step_time=0.039, optim0_lr0=9.861e-04, train_time=0.616
[ALab02] 2023-06-09 23:15:12,591 (trainer:721) INFO: 23epoch:train:386-462batch: iter_time=2.155e-04, forward_time=0.230, loss_ctc=18.019, loss=18.019, backward_time=0.301, optim_step_time=0.040, optim0_lr0=9.883e-04, train_time=0.618
[ALab02] 2023-06-09 23:16:00,762 (trainer:721) INFO: 23epoch:train:463-539batch: iter_time=2.103e-04, forward_time=0.235, loss_ctc=19.627, loss=19.627, backward_time=0.306, optim_step_time=0.041, optim0_lr0=9.905e-04, train_time=0.625
[ALab02] 2023-06-09 23:16:48,628 (trainer:721) INFO: 23epoch:train:540-616batch: iter_time=1.719e-04, forward_time=0.232, loss_ctc=19.846, loss=19.846, backward_time=0.307, optim_step_time=0.040, optim0_lr0=9.927e-04, train_time=0.621
[ALab02] 2023-06-09 23:17:36,105 (trainer:721) INFO: 23epoch:train:617-693batch: iter_time=1.801e-04, forward_time=0.233, loss_ctc=20.582, loss=20.582, backward_time=0.295, optim_step_time=0.042, optim0_lr0=9.949e-04, train_time=0.616
[ALab02] 2023-06-09 23:18:25,162 (trainer:721) INFO: 23epoch:train:694-770batch: iter_time=1.511e-04, forward_time=0.245, loss_ctc=16.116, loss=16.116, backward_time=0.308, optim_step_time=0.041, optim0_lr0=9.971e-04, train_time=0.637
[ALab02] 2023-06-09 23:19:13,009 (trainer:721) INFO: 23epoch:train:771-847batch: iter_time=1.635e-04, forward_time=0.235, loss_ctc=18.912, loss=18.912, backward_time=0.301, optim_step_time=0.040, optim0_lr0=9.993e-04, train_time=0.621
[ALab02] 2023-06-09 23:20:00,834 (trainer:721) INFO: 23epoch:train:848-924batch: iter_time=1.754e-04, forward_time=0.233, loss_ctc=20.928, loss=20.928, backward_time=0.307, optim_step_time=0.039, optim0_lr0=9.992e-04, train_time=0.621
[ALab02] 2023-06-09 23:20:49,036 (trainer:721) INFO: 23epoch:train:925-1001batch: iter_time=1.502e-04, forward_time=0.237, loss_ctc=18.601, loss=18.601, backward_time=0.303, optim_step_time=0.041, optim0_lr0=9.981e-04, train_time=0.626
[ALab02] 2023-06-09 23:21:38,221 (trainer:721) INFO: 23epoch:train:1002-1078batch: iter_time=1.690e-04, forward_time=0.242, loss_ctc=16.742, loss=16.742, backward_time=0.311, optim_step_time=0.041, optim0_lr0=9.971e-04, train_time=0.639
[ALab02] 2023-06-09 23:22:26,747 (trainer:721) INFO: 23epoch:train:1079-1155batch: iter_time=1.813e-04, forward_time=0.238, loss_ctc=18.313, loss=18.313, backward_time=0.306, optim_step_time=0.041, optim0_lr0=9.960e-04, train_time=0.630
[ALab02] 2023-06-09 23:23:14,326 (trainer:721) INFO: 23epoch:train:1156-1232batch: iter_time=1.868e-04, forward_time=0.235, loss_ctc=18.796, loss=18.796, backward_time=0.298, optim_step_time=0.042, optim0_lr0=9.949e-04, train_time=0.618
[ALab02] 2023-06-09 23:24:02,187 (trainer:721) INFO: 23epoch:train:1233-1309batch: iter_time=1.586e-04, forward_time=0.235, loss_ctc=20.403, loss=20.403, backward_time=0.304, optim_step_time=0.038, optim0_lr0=9.938e-04, train_time=0.621
[ALab02] 2023-06-09 23:24:51,524 (trainer:721) INFO: 23epoch:train:1310-1386batch: iter_time=2.616e-04, forward_time=0.244, loss_ctc=17.844, loss=17.844, backward_time=0.307, optim_step_time=0.045, optim0_lr0=9.927e-04, train_time=0.640
[ALab02] 2023-06-09 23:25:39,955 (trainer:721) INFO: 23epoch:train:1387-1463batch: iter_time=2.046e-04, forward_time=0.236, loss_ctc=19.162, loss=19.162, backward_time=0.308, optim_step_time=0.039, optim0_lr0=9.916e-04, train_time=0.629
[ALab02] 2023-06-09 23:26:27,590 (trainer:721) INFO: 23epoch:train:1464-1540batch: iter_time=1.464e-04, forward_time=0.231, loss_ctc=19.903, loss=19.903, backward_time=0.303, optim_step_time=0.039, optim0_lr0=9.906e-04, train_time=0.618
[ALab02] 2023-06-09 23:27:21,045 (trainer:338) INFO: 23epoch results: [train] iter_time=0.001, forward_time=0.257, loss_ctc=19.015, loss=19.015, backward_time=0.322, optim_step_time=0.041, optim0_lr0=9.913e-04, train_time=0.666, time=17 minutes and 14.97 seconds, total_count=35719, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.771, cer_ctc=0.297, cer=0.297, loss=14.771, time=8.74 seconds, total_count=368, gpu_max_cached_mem_GB=77.078, [att_plot] time=35.92 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 23:27:23,556 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-09 23:27:23,558 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/13epoch.pth
[ALab02] 2023-06-09 23:27:23,558 (trainer:272) INFO: 24/70epoch started. Estimated time to finish: 23 hours, 2 minutes and 44.37 seconds
[ALab02] 2023-06-09 23:28:13,190 (trainer:721) INFO: 24epoch:train:1-77batch: iter_time=0.018, forward_time=0.234, loss_ctc=18.674, loss=18.674, backward_time=0.305, optim_step_time=0.043, optim0_lr0=9.893e-04, train_time=0.644
[ALab02] 2023-06-09 23:29:02,022 (trainer:721) INFO: 24epoch:train:78-154batch: iter_time=1.670e-04, forward_time=0.239, loss_ctc=20.143, loss=20.143, backward_time=0.308, optim_step_time=0.041, optim0_lr0=9.883e-04, train_time=0.634
[ALab02] 2023-06-09 23:29:49,958 (trainer:721) INFO: 24epoch:train:155-231batch: iter_time=1.710e-04, forward_time=0.234, loss_ctc=18.208, loss=18.208, backward_time=0.303, optim_step_time=0.040, optim0_lr0=9.872e-04, train_time=0.622
[ALab02] 2023-06-09 23:30:38,441 (trainer:721) INFO: 24epoch:train:232-308batch: iter_time=1.672e-04, forward_time=0.238, loss_ctc=19.719, loss=19.719, backward_time=0.307, optim_step_time=0.039, optim0_lr0=9.862e-04, train_time=0.629
[ALab02] 2023-06-09 23:31:25,565 (trainer:721) INFO: 24epoch:train:309-385batch: iter_time=1.669e-04, forward_time=0.229, loss_ctc=17.667, loss=17.667, backward_time=0.301, optim_step_time=0.039, optim0_lr0=9.851e-04, train_time=0.612
[ALab02] 2023-06-09 23:32:13,376 (trainer:721) INFO: 24epoch:train:386-462batch: iter_time=1.793e-04, forward_time=0.232, loss_ctc=19.733, loss=19.733, backward_time=0.303, optim_step_time=0.041, optim0_lr0=9.840e-04, train_time=0.621
[ALab02] 2023-06-09 23:33:02,978 (trainer:721) INFO: 24epoch:train:463-539batch: iter_time=2.312e-04, forward_time=0.247, loss_ctc=16.901, loss=16.901, backward_time=0.305, optim_step_time=0.045, optim0_lr0=9.830e-04, train_time=0.644
[ALab02] 2023-06-09 23:33:51,095 (trainer:721) INFO: 24epoch:train:540-616batch: iter_time=1.861e-04, forward_time=0.233, loss_ctc=19.374, loss=19.374, backward_time=0.303, optim_step_time=0.042, optim0_lr0=9.820e-04, train_time=0.625
[ALab02] 2023-06-09 23:34:39,501 (trainer:721) INFO: 24epoch:train:617-693batch: iter_time=2.006e-04, forward_time=0.237, loss_ctc=19.351, loss=19.351, backward_time=0.306, optim_step_time=0.043, optim0_lr0=9.809e-04, train_time=0.628
[ALab02] 2023-06-09 23:35:28,171 (trainer:721) INFO: 24epoch:train:694-770batch: iter_time=1.932e-04, forward_time=0.236, loss_ctc=20.370, loss=20.370, backward_time=0.310, optim_step_time=0.041, optim0_lr0=9.799e-04, train_time=0.632
[ALab02] 2023-06-09 23:36:16,490 (trainer:721) INFO: 24epoch:train:771-847batch: iter_time=1.969e-04, forward_time=0.239, loss_ctc=19.086, loss=19.086, backward_time=0.304, optim_step_time=0.041, optim0_lr0=9.788e-04, train_time=0.627
[ALab02] 2023-06-09 23:37:05,078 (trainer:721) INFO: 24epoch:train:848-924batch: iter_time=1.768e-04, forward_time=0.241, loss_ctc=16.861, loss=16.861, backward_time=0.305, optim_step_time=0.041, optim0_lr0=9.778e-04, train_time=0.631
[ALab02] 2023-06-09 23:37:54,178 (trainer:721) INFO: 24epoch:train:925-1001batch: iter_time=1.643e-04, forward_time=0.244, loss_ctc=16.864, loss=16.864, backward_time=0.306, optim_step_time=0.042, optim0_lr0=9.768e-04, train_time=0.637
[ALab02] 2023-06-09 23:38:41,899 (trainer:721) INFO: 24epoch:train:1002-1078batch: iter_time=1.673e-04, forward_time=0.234, loss_ctc=18.561, loss=18.561, backward_time=0.303, optim_step_time=0.039, optim0_lr0=9.758e-04, train_time=0.620
[ALab02] 2023-06-09 23:39:30,965 (trainer:721) INFO: 24epoch:train:1079-1155batch: iter_time=1.939e-04, forward_time=0.243, loss_ctc=17.854, loss=17.854, backward_time=0.311, optim_step_time=0.040, optim0_lr0=9.747e-04, train_time=0.637
[ALab02] 2023-06-09 23:40:18,183 (trainer:721) INFO: 24epoch:train:1156-1232batch: iter_time=1.713e-04, forward_time=0.228, loss_ctc=21.640, loss=21.640, backward_time=0.302, optim_step_time=0.039, optim0_lr0=9.737e-04, train_time=0.613
[ALab02] 2023-06-09 23:41:06,306 (trainer:721) INFO: 24epoch:train:1233-1309batch: iter_time=1.802e-04, forward_time=0.236, loss_ctc=16.987, loss=16.987, backward_time=0.304, optim_step_time=0.042, optim0_lr0=9.727e-04, train_time=0.625
[ALab02] 2023-06-09 23:41:55,141 (trainer:721) INFO: 24epoch:train:1310-1386batch: iter_time=1.764e-04, forward_time=0.238, loss_ctc=19.227, loss=19.227, backward_time=0.307, optim_step_time=0.040, optim0_lr0=9.717e-04, train_time=0.634
[ALab02] 2023-06-09 23:42:43,374 (trainer:721) INFO: 24epoch:train:1387-1463batch: iter_time=1.598e-04, forward_time=0.238, loss_ctc=17.055, loss=17.055, backward_time=0.304, optim_step_time=0.039, optim0_lr0=9.707e-04, train_time=0.626
[ALab02] 2023-06-09 23:43:32,144 (trainer:721) INFO: 24epoch:train:1464-1540batch: iter_time=1.634e-04, forward_time=0.244, loss_ctc=17.426, loss=17.426, backward_time=0.307, optim_step_time=0.041, optim0_lr0=9.697e-04, train_time=0.633
[ALab02] 2023-06-09 23:44:17,623 (trainer:338) INFO: 24epoch results: [train] iter_time=0.001, forward_time=0.237, loss_ctc=18.554, loss=18.554, backward_time=0.305, optim_step_time=0.041, optim0_lr0=9.793e-04, train_time=0.629, time=16 minutes and 17.13 seconds, total_count=37272, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.607, cer_ctc=0.307, cer=0.307, loss=14.607, time=6.92 seconds, total_count=384, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.02 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-09 23:44:20,085 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-09 23:44:20,087 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/15epoch.pth
[ALab02] 2023-06-09 23:44:20,087 (trainer:272) INFO: 25/70epoch started. Estimated time to finish: 22 hours, 9 minutes and 24.22 seconds
[ALab02] 2023-06-09 23:45:31,193 (trainer:721) INFO: 25epoch:train:1-77batch: iter_time=0.017, forward_time=0.381, loss_ctc=17.891, loss=17.891, backward_time=0.425, optim_step_time=0.041, optim0_lr0=9.685e-04, train_time=0.923
[ALab02] 2023-06-09 23:47:12,376 (trainer:721) INFO: 25epoch:train:78-154batch: iter_time=2.017e-04, forward_time=0.600, loss_ctc=17.680, loss=17.680, backward_time=0.602, optim_step_time=0.043, optim0_lr0=9.675e-04, train_time=1.314
[ALab02] 2023-06-09 23:48:34,925 (trainer:721) INFO: 25epoch:train:155-231batch: iter_time=1.609e-04, forward_time=0.461, loss_ctc=17.560, loss=17.560, backward_time=0.510, optim_step_time=0.042, optim0_lr0=9.665e-04, train_time=1.072
[ALab02] 2023-06-09 23:49:45,674 (trainer:721) INFO: 25epoch:train:232-308batch: iter_time=1.897e-04, forward_time=0.396, loss_ctc=20.879, loss=20.879, backward_time=0.427, optim_step_time=0.040, optim0_lr0=9.655e-04, train_time=0.919
[ALab02] 2023-06-09 23:50:33,357 (trainer:721) INFO: 25epoch:train:309-385batch: iter_time=1.772e-04, forward_time=0.231, loss_ctc=16.587, loss=16.587, backward_time=0.306, optim_step_time=0.041, optim0_lr0=9.645e-04, train_time=0.619
[ALab02] 2023-06-09 23:51:25,061 (trainer:721) INFO: 25epoch:train:386-462batch: iter_time=1.936e-04, forward_time=0.254, loss_ctc=17.924, loss=17.924, backward_time=0.330, optim_step_time=0.040, optim0_lr0=9.636e-04, train_time=0.671
[ALab02] 2023-06-09 23:52:14,088 (trainer:721) INFO: 25epoch:train:463-539batch: iter_time=1.655e-04, forward_time=0.243, loss_ctc=18.319, loss=18.319, backward_time=0.306, optim_step_time=0.041, optim0_lr0=9.626e-04, train_time=0.636
[ALab02] 2023-06-09 23:53:01,683 (trainer:721) INFO: 25epoch:train:540-616batch: iter_time=1.685e-04, forward_time=0.233, loss_ctc=18.542, loss=18.542, backward_time=0.303, optim_step_time=0.040, optim0_lr0=9.616e-04, train_time=0.618
[ALab02] 2023-06-09 23:53:59,313 (trainer:721) INFO: 25epoch:train:617-693batch: iter_time=3.879e-04, forward_time=0.299, loss_ctc=18.369, loss=18.369, backward_time=0.357, optim_step_time=0.044, optim0_lr0=9.606e-04, train_time=0.748
[ALab02] 2023-06-09 23:54:47,512 (trainer:721) INFO: 25epoch:train:694-770batch: iter_time=1.793e-04, forward_time=0.239, loss_ctc=17.370, loss=17.370, backward_time=0.301, optim_step_time=0.040, optim0_lr0=9.597e-04, train_time=0.626
[ALab02] 2023-06-09 23:55:36,716 (trainer:721) INFO: 25epoch:train:771-847batch: iter_time=1.841e-04, forward_time=0.244, loss_ctc=17.058, loss=17.058, backward_time=0.310, optim_step_time=0.039, optim0_lr0=9.587e-04, train_time=0.639
[ALab02] 2023-06-09 23:56:51,434 (trainer:721) INFO: 25epoch:train:848-924batch: iter_time=2.118e-04, forward_time=0.418, loss_ctc=16.477, loss=16.477, backward_time=0.455, optim_step_time=0.041, optim0_lr0=9.577e-04, train_time=0.970
[ALab02] 2023-06-09 23:58:24,651 (trainer:721) INFO: 25epoch:train:925-1001batch: iter_time=2.230e-04, forward_time=0.543, loss_ctc=17.253, loss=17.253, backward_time=0.560, optim_step_time=0.041, optim0_lr0=9.567e-04, train_time=1.210
[ALab02] 2023-06-09 23:59:40,103 (trainer:721) INFO: 25epoch:train:1002-1078batch: iter_time=1.870e-04, forward_time=0.421, loss_ctc=20.042, loss=20.042, backward_time=0.455, optim_step_time=0.041, optim0_lr0=9.558e-04, train_time=0.980
[ALab02] 2023-06-10 00:01:09,708 (trainer:721) INFO: 25epoch:train:1079-1155batch: iter_time=2.380e-04, forward_time=0.506, loss_ctc=17.355, loss=17.355, backward_time=0.550, optim_step_time=0.040, optim0_lr0=9.548e-04, train_time=1.163
[ALab02] 2023-06-10 00:02:47,614 (trainer:721) INFO: 25epoch:train:1156-1232batch: iter_time=1.859e-04, forward_time=0.581, loss_ctc=17.146, loss=17.146, backward_time=0.579, optim_step_time=0.038, optim0_lr0=9.539e-04, train_time=1.271
[ALab02] 2023-06-10 00:03:59,417 (trainer:721) INFO: 25epoch:train:1233-1309batch: iter_time=1.658e-04, forward_time=0.388, loss_ctc=18.321, loss=18.321, backward_time=0.440, optim_step_time=0.040, optim0_lr0=9.529e-04, train_time=0.932
[ALab02] 2023-06-10 00:05:20,499 (trainer:721) INFO: 25epoch:train:1310-1386batch: iter_time=3.362e-04, forward_time=0.457, loss_ctc=17.722, loss=17.722, backward_time=0.480, optim_step_time=0.044, optim0_lr0=9.520e-04, train_time=1.053
[ALab02] 2023-06-10 00:06:56,873 (trainer:721) INFO: 25epoch:train:1387-1463batch: iter_time=2.075e-04, forward_time=0.566, loss_ctc=17.423, loss=17.423, backward_time=0.568, optim_step_time=0.042, optim0_lr0=9.510e-04, train_time=1.251
[ALab02] 2023-06-10 00:08:35,101 (trainer:721) INFO: 25epoch:train:1464-1540batch: iter_time=2.015e-04, forward_time=0.579, loss_ctc=17.841, loss=17.841, backward_time=0.579, optim_step_time=0.042, optim0_lr0=9.501e-04, train_time=1.275
[ALab02] 2023-06-10 00:09:29,486 (trainer:338) INFO: 25epoch results: [train] iter_time=0.001, forward_time=0.402, loss_ctc=17.843, loss=17.843, backward_time=0.442, optim_step_time=0.041, optim0_lr0=9.591e-04, train_time=0.945, time=24 minutes and 27.8 seconds, total_count=38825, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.800, cer_ctc=0.306, cer=0.306, loss=13.800, time=11.19 seconds, total_count=400, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.4 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 00:09:32,365 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 00:09:32,365 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/17epoch.pth
[ALab02] 2023-06-10 00:09:32,366 (trainer:272) INFO: 26/70epoch started. Estimated time to finish: 21 hours, 33 minutes and 51.11 seconds
[ALab02] 2023-06-10 00:11:14,626 (trainer:721) INFO: 26epoch:train:1-77batch: iter_time=0.020, forward_time=0.598, loss_ctc=14.812, loss=14.812, backward_time=0.591, optim_step_time=0.042, optim0_lr0=9.490e-04, train_time=1.328
[ALab02] 2023-06-10 00:12:46,577 (trainer:721) INFO: 26epoch:train:78-154batch: iter_time=2.608e-04, forward_time=0.526, loss_ctc=17.498, loss=17.498, backward_time=0.552, optim_step_time=0.041, optim0_lr0=9.480e-04, train_time=1.194
[ALab02] 2023-06-10 00:14:22,367 (trainer:721) INFO: 26epoch:train:155-231batch: iter_time=1.619e-04, forward_time=0.548, loss_ctc=16.953, loss=16.953, backward_time=0.582, optim_step_time=0.040, optim0_lr0=9.471e-04, train_time=1.244
[ALab02] 2023-06-10 00:15:56,695 (trainer:721) INFO: 26epoch:train:232-308batch: iter_time=3.069e-04, forward_time=0.547, loss_ctc=17.308, loss=17.308, backward_time=0.569, optim_step_time=0.042, optim0_lr0=9.462e-04, train_time=1.225
[ALab02] 2023-06-10 00:17:32,651 (trainer:721) INFO: 26epoch:train:309-385batch: iter_time=1.860e-04, forward_time=0.549, loss_ctc=18.185, loss=18.185, backward_time=0.583, optim_step_time=0.041, optim0_lr0=9.452e-04, train_time=1.246
[ALab02] 2023-06-10 00:19:08,536 (trainer:721) INFO: 26epoch:train:386-462batch: iter_time=2.257e-04, forward_time=0.563, loss_ctc=18.301, loss=18.301, backward_time=0.568, optim_step_time=0.043, optim0_lr0=9.443e-04, train_time=1.245
[ALab02] 2023-06-10 00:20:46,156 (trainer:721) INFO: 26epoch:train:463-539batch: iter_time=1.968e-04, forward_time=0.564, loss_ctc=17.941, loss=17.941, backward_time=0.591, optim_step_time=0.041, optim0_lr0=9.434e-04, train_time=1.268
[ALab02] 2023-06-10 00:22:22,381 (trainer:721) INFO: 26epoch:train:540-616batch: iter_time=2.418e-04, forward_time=0.566, loss_ctc=16.897, loss=16.897, backward_time=0.565, optim_step_time=0.042, optim0_lr0=9.425e-04, train_time=1.249
[ALab02] 2023-06-10 00:24:01,905 (trainer:721) INFO: 26epoch:train:617-693batch: iter_time=5.769e-04, forward_time=0.598, loss_ctc=16.999, loss=16.999, backward_time=0.575, optim_step_time=0.042, optim0_lr0=9.415e-04, train_time=1.292
[ALab02] 2023-06-10 00:25:39,091 (trainer:721) INFO: 26epoch:train:694-770batch: iter_time=1.753e-04, forward_time=0.570, loss_ctc=16.870, loss=16.870, backward_time=0.575, optim_step_time=0.040, optim0_lr0=9.406e-04, train_time=1.262
[ALab02] 2023-06-10 00:27:13,420 (trainer:721) INFO: 26epoch:train:771-847batch: iter_time=2.625e-04, forward_time=0.547, loss_ctc=16.420, loss=16.420, backward_time=0.570, optim_step_time=0.042, optim0_lr0=9.397e-04, train_time=1.225
[ALab02] 2023-06-10 00:28:51,445 (trainer:721) INFO: 26epoch:train:848-924batch: iter_time=1.978e-04, forward_time=0.564, loss_ctc=16.744, loss=16.744, backward_time=0.583, optim_step_time=0.044, optim0_lr0=9.388e-04, train_time=1.273
[ALab02] 2023-06-10 00:30:23,499 (trainer:721) INFO: 26epoch:train:925-1001batch: iter_time=1.882e-04, forward_time=0.521, loss_ctc=18.201, loss=18.201, backward_time=0.562, optim_step_time=0.042, optim0_lr0=9.379e-04, train_time=1.195
[ALab02] 2023-06-10 00:32:03,204 (trainer:721) INFO: 26epoch:train:1002-1078batch: iter_time=4.096e-04, forward_time=0.582, loss_ctc=18.089, loss=18.089, backward_time=0.597, optim_step_time=0.042, optim0_lr0=9.370e-04, train_time=1.295
[ALab02] 2023-06-10 00:33:36,891 (trainer:721) INFO: 26epoch:train:1079-1155batch: iter_time=1.844e-04, forward_time=0.541, loss_ctc=18.092, loss=18.092, backward_time=0.560, optim_step_time=0.044, optim0_lr0=9.361e-04, train_time=1.216
[ALab02] 2023-06-10 00:35:15,411 (trainer:721) INFO: 26epoch:train:1156-1232batch: iter_time=1.795e-04, forward_time=0.580, loss_ctc=16.190, loss=16.190, backward_time=0.586, optim_step_time=0.042, optim0_lr0=9.352e-04, train_time=1.279
[ALab02] 2023-06-10 00:36:45,707 (trainer:721) INFO: 26epoch:train:1233-1309batch: iter_time=1.834e-04, forward_time=0.499, loss_ctc=19.675, loss=19.675, backward_time=0.555, optim_step_time=0.043, optim0_lr0=9.343e-04, train_time=1.172
[ALab02] 2023-06-10 00:38:24,013 (trainer:721) INFO: 26epoch:train:1310-1386batch: iter_time=2.129e-04, forward_time=0.584, loss_ctc=17.988, loss=17.988, backward_time=0.579, optim_step_time=0.041, optim0_lr0=9.334e-04, train_time=1.276
[ALab02] 2023-06-10 00:39:58,414 (trainer:721) INFO: 26epoch:train:1387-1463batch: iter_time=1.962e-04, forward_time=0.550, loss_ctc=17.013, loss=17.013, backward_time=0.555, optim_step_time=0.040, optim0_lr0=9.325e-04, train_time=1.226
[ALab02] 2023-06-10 00:41:40,154 (trainer:721) INFO: 26epoch:train:1464-1540batch: iter_time=2.093e-04, forward_time=0.605, loss_ctc=17.358, loss=17.358, backward_time=0.591, optim_step_time=0.042, optim0_lr0=9.316e-04, train_time=1.321
[ALab02] 2023-06-10 00:42:37,498 (trainer:338) INFO: 26epoch results: [train] iter_time=0.001, forward_time=0.560, loss_ctc=17.315, loss=17.315, backward_time=0.574, optim_step_time=0.042, optim0_lr0=9.401e-04, train_time=1.251, time=32 minutes and 22.7 seconds, total_count=40378, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.173, cer_ctc=0.299, cer=0.299, loss=14.173, time=12.33 seconds, total_count=416, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.1 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 00:42:40,189 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 00:42:40,190 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/14epoch.pth
[ALab02] 2023-06-10 00:42:40,191 (trainer:272) INFO: 27/70epoch started. Estimated time to finish: 21 hours, 12 minutes and 30.53 seconds
[ALab02] 2023-06-10 00:44:17,040 (trainer:721) INFO: 27epoch:train:1-77batch: iter_time=0.018, forward_time=0.550, loss_ctc=18.488, loss=18.488, backward_time=0.568, optim_step_time=0.041, optim0_lr0=9.306e-04, train_time=1.257
[ALab02] 2023-06-10 00:45:50,001 (trainer:721) INFO: 27epoch:train:78-154batch: iter_time=1.886e-04, forward_time=0.531, loss_ctc=16.260, loss=16.260, backward_time=0.557, optim_step_time=0.043, optim0_lr0=9.297e-04, train_time=1.207
[ALab02] 2023-06-10 00:47:27,302 (trainer:721) INFO: 27epoch:train:155-231batch: iter_time=1.834e-04, forward_time=0.557, loss_ctc=18.093, loss=18.093, backward_time=0.592, optim_step_time=0.043, optim0_lr0=9.288e-04, train_time=1.263
[ALab02] 2023-06-10 00:48:59,626 (trainer:721) INFO: 27epoch:train:232-308batch: iter_time=2.045e-04, forward_time=0.529, loss_ctc=17.958, loss=17.958, backward_time=0.559, optim_step_time=0.044, optim0_lr0=9.279e-04, train_time=1.199
[ALab02] 2023-06-10 00:50:39,950 (trainer:721) INFO: 27epoch:train:309-385batch: iter_time=3.581e-04, forward_time=0.599, loss_ctc=16.036, loss=16.036, backward_time=0.586, optim_step_time=0.041, optim0_lr0=9.270e-04, train_time=1.303
[ALab02] 2023-06-10 00:52:16,794 (trainer:721) INFO: 27epoch:train:386-462batch: iter_time=1.940e-04, forward_time=0.577, loss_ctc=17.066, loss=17.066, backward_time=0.566, optim_step_time=0.040, optim0_lr0=9.262e-04, train_time=1.257
[ALab02] 2023-06-10 00:53:58,522 (trainer:721) INFO: 27epoch:train:463-539batch: iter_time=1.636e-04, forward_time=0.600, loss_ctc=16.323, loss=16.323, backward_time=0.603, optim_step_time=0.041, optim0_lr0=9.253e-04, train_time=1.321
[ALab02] 2023-06-10 00:55:33,622 (trainer:721) INFO: 27epoch:train:540-616batch: iter_time=1.940e-04, forward_time=0.549, loss_ctc=17.895, loss=17.895, backward_time=0.564, optim_step_time=0.043, optim0_lr0=9.244e-04, train_time=1.235
[ALab02] 2023-06-10 00:57:11,381 (trainer:721) INFO: 27epoch:train:617-693batch: iter_time=2.551e-04, forward_time=0.571, loss_ctc=16.211, loss=16.211, backward_time=0.581, optim_step_time=0.044, optim0_lr0=9.236e-04, train_time=1.269
[ALab02] 2023-06-10 00:58:49,669 (trainer:721) INFO: 27epoch:train:694-770batch: iter_time=4.523e-04, forward_time=0.577, loss_ctc=17.614, loss=17.614, backward_time=0.551, optim_step_time=0.064, optim0_lr0=9.227e-04, train_time=1.276
[ALab02] 2023-06-10 01:00:25,226 (trainer:721) INFO: 27epoch:train:771-847batch: iter_time=1.626e-04, forward_time=0.538, loss_ctc=16.785, loss=16.785, backward_time=0.586, optim_step_time=0.040, optim0_lr0=9.218e-04, train_time=1.241
[ALab02] 2023-06-10 01:02:00,864 (trainer:721) INFO: 27epoch:train:848-924batch: iter_time=3.620e-04, forward_time=0.560, loss_ctc=16.823, loss=16.823, backward_time=0.568, optim_step_time=0.041, optim0_lr0=9.210e-04, train_time=1.242
[ALab02] 2023-06-10 01:03:38,447 (trainer:721) INFO: 27epoch:train:925-1001batch: iter_time=6.433e-04, forward_time=0.581, loss_ctc=15.441, loss=15.441, backward_time=0.562, optim_step_time=0.044, optim0_lr0=9.201e-04, train_time=1.267
[ALab02] 2023-06-10 01:05:11,004 (trainer:721) INFO: 27epoch:train:1002-1078batch: iter_time=1.781e-04, forward_time=0.522, loss_ctc=14.953, loss=14.953, backward_time=0.564, optim_step_time=0.042, optim0_lr0=9.193e-04, train_time=1.202
[ALab02] 2023-06-10 01:06:49,350 (trainer:721) INFO: 27epoch:train:1079-1155batch: iter_time=2.020e-04, forward_time=0.575, loss_ctc=16.810, loss=16.810, backward_time=0.587, optim_step_time=0.043, optim0_lr0=9.184e-04, train_time=1.277
[ALab02] 2023-06-10 01:08:23,585 (trainer:721) INFO: 27epoch:train:1156-1232batch: iter_time=1.657e-04, forward_time=0.537, loss_ctc=18.422, loss=18.422, backward_time=0.569, optim_step_time=0.040, optim0_lr0=9.175e-04, train_time=1.224
[ALab02] 2023-06-10 01:10:02,347 (trainer:721) INFO: 27epoch:train:1233-1309batch: iter_time=1.570e-04, forward_time=0.598, loss_ctc=16.339, loss=16.339, backward_time=0.577, optim_step_time=0.040, optim0_lr0=9.167e-04, train_time=1.282
[ALab02] 2023-06-10 01:11:39,720 (trainer:721) INFO: 27epoch:train:1310-1386batch: iter_time=2.551e-04, forward_time=0.572, loss_ctc=17.083, loss=17.083, backward_time=0.579, optim_step_time=0.041, optim0_lr0=9.159e-04, train_time=1.264
[ALab02] 2023-06-10 01:13:12,396 (trainer:721) INFO: 27epoch:train:1387-1463batch: iter_time=1.669e-04, forward_time=0.532, loss_ctc=19.142, loss=19.142, backward_time=0.555, optim_step_time=0.042, optim0_lr0=9.150e-04, train_time=1.203
[ALab02] 2023-06-10 01:14:50,894 (trainer:721) INFO: 27epoch:train:1464-1540batch: iter_time=1.569e-04, forward_time=0.579, loss_ctc=15.117, loss=15.117, backward_time=0.589, optim_step_time=0.040, optim0_lr0=9.142e-04, train_time=1.279
[ALab02] 2023-06-10 01:15:45,950 (trainer:338) INFO: 27epoch results: [train] iter_time=0.001, forward_time=0.561, loss_ctc=16.909, loss=16.909, backward_time=0.573, optim_step_time=0.043, optim0_lr0=9.222e-04, train_time=1.253, time=32 minutes and 26.57 seconds, total_count=41931, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.283, cer_ctc=0.302, cer=0.302, loss=14.283, time=9.51 seconds, total_count=432, gpu_max_cached_mem_GB=77.078, [att_plot] time=29.68 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 01:15:48,357 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 01:15:48,358 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/16epoch.pth
[ALab02] 2023-06-10 01:15:48,359 (trainer:272) INFO: 28/70epoch started. Estimated time to finish: 20 hours, 50 minutes and 18.1 seconds
[ALab02] 2023-06-10 01:17:24,206 (trainer:721) INFO: 28epoch:train:1-77batch: iter_time=0.019, forward_time=0.538, loss_ctc=14.561, loss=14.561, backward_time=0.571, optim_step_time=0.043, optim0_lr0=9.132e-04, train_time=1.244
[ALab02] 2023-06-10 01:19:03,327 (trainer:721) INFO: 28epoch:train:78-154batch: iter_time=2.224e-04, forward_time=0.590, loss_ctc=16.585, loss=16.585, backward_time=0.571, optim_step_time=0.042, optim0_lr0=9.123e-04, train_time=1.287
[ALab02] 2023-06-10 01:20:41,411 (trainer:721) INFO: 28epoch:train:155-231batch: iter_time=4.017e-04, forward_time=0.573, loss_ctc=17.287, loss=17.287, backward_time=0.582, optim_step_time=0.041, optim0_lr0=9.115e-04, train_time=1.274
[ALab02] 2023-06-10 01:22:17,271 (trainer:721) INFO: 28epoch:train:232-308batch: iter_time=2.314e-04, forward_time=0.568, loss_ctc=16.546, loss=16.546, backward_time=0.564, optim_step_time=0.041, optim0_lr0=9.107e-04, train_time=1.245
[ALab02] 2023-06-10 01:23:54,018 (trainer:721) INFO: 28epoch:train:309-385batch: iter_time=2.336e-04, forward_time=0.562, loss_ctc=16.455, loss=16.455, backward_time=0.578, optim_step_time=0.043, optim0_lr0=9.099e-04, train_time=1.256
[ALab02] 2023-06-10 01:25:27,822 (trainer:721) INFO: 28epoch:train:386-462batch: iter_time=1.834e-04, forward_time=0.542, loss_ctc=15.804, loss=15.804, backward_time=0.566, optim_step_time=0.042, optim0_lr0=9.090e-04, train_time=1.218
[ALab02] 2023-06-10 01:27:07,312 (trainer:721) INFO: 28epoch:train:463-539batch: iter_time=2.032e-04, forward_time=0.581, loss_ctc=15.735, loss=15.735, backward_time=0.592, optim_step_time=0.042, optim0_lr0=9.082e-04, train_time=1.292
[ALab02] 2023-06-10 01:28:45,512 (trainer:721) INFO: 28epoch:train:540-616batch: iter_time=1.856e-04, forward_time=0.578, loss_ctc=16.059, loss=16.059, backward_time=0.571, optim_step_time=0.043, optim0_lr0=9.074e-04, train_time=1.275
[ALab02] 2023-06-10 01:30:22,158 (trainer:721) INFO: 28epoch:train:617-693batch: iter_time=2.382e-04, forward_time=0.568, loss_ctc=17.585, loss=17.585, backward_time=0.577, optim_step_time=0.039, optim0_lr0=9.066e-04, train_time=1.255
[ALab02] 2023-06-10 01:31:53,374 (trainer:721) INFO: 28epoch:train:694-770batch: iter_time=2.055e-04, forward_time=0.508, loss_ctc=17.558, loss=17.558, backward_time=0.563, optim_step_time=0.040, optim0_lr0=9.057e-04, train_time=1.184
[ALab02] 2023-06-10 01:33:32,814 (trainer:721) INFO: 28epoch:train:771-847batch: iter_time=1.740e-04, forward_time=0.605, loss_ctc=16.388, loss=16.388, backward_time=0.578, optim_step_time=0.041, optim0_lr0=9.049e-04, train_time=1.291
[ALab02] 2023-06-10 01:35:05,481 (trainer:721) INFO: 28epoch:train:848-924batch: iter_time=2.193e-04, forward_time=0.540, loss_ctc=16.530, loss=16.530, backward_time=0.553, optim_step_time=0.040, optim0_lr0=9.041e-04, train_time=1.203
[ALab02] 2023-06-10 01:36:43,165 (trainer:721) INFO: 28epoch:train:925-1001batch: iter_time=1.602e-04, forward_time=0.565, loss_ctc=16.292, loss=16.292, backward_time=0.589, optim_step_time=0.042, optim0_lr0=9.033e-04, train_time=1.268
[ALab02] 2023-06-10 01:38:16,465 (trainer:721) INFO: 28epoch:train:1002-1078batch: iter_time=1.994e-04, forward_time=0.531, loss_ctc=16.232, loss=16.232, backward_time=0.563, optim_step_time=0.041, optim0_lr0=9.025e-04, train_time=1.211
[ALab02] 2023-06-10 01:39:52,176 (trainer:721) INFO: 28epoch:train:1079-1155batch: iter_time=2.188e-04, forward_time=0.541, loss_ctc=16.900, loss=16.900, backward_time=0.583, optim_step_time=0.043, optim0_lr0=9.017e-04, train_time=1.243
[ALab02] 2023-06-10 01:41:25,930 (trainer:721) INFO: 28epoch:train:1156-1232batch: iter_time=1.717e-04, forward_time=0.546, loss_ctc=15.470, loss=15.470, backward_time=0.556, optim_step_time=0.044, optim0_lr0=9.009e-04, train_time=1.217
[ALab02] 2023-06-10 01:43:02,115 (trainer:721) INFO: 28epoch:train:1233-1309batch: iter_time=1.980e-04, forward_time=0.551, loss_ctc=17.204, loss=17.204, backward_time=0.584, optim_step_time=0.040, optim0_lr0=9.001e-04, train_time=1.249
[ALab02] 2023-06-10 01:44:35,387 (trainer:721) INFO: 28epoch:train:1310-1386batch: iter_time=1.965e-04, forward_time=0.541, loss_ctc=15.074, loss=15.074, backward_time=0.559, optim_step_time=0.043, optim0_lr0=8.993e-04, train_time=1.211
[ALab02] 2023-06-10 01:46:16,306 (trainer:721) INFO: 28epoch:train:1387-1463batch: iter_time=3.455e-04, forward_time=0.597, loss_ctc=16.572, loss=16.572, backward_time=0.592, optim_step_time=0.040, optim0_lr0=8.985e-04, train_time=1.310
[ALab02] 2023-06-10 01:47:47,499 (trainer:721) INFO: 28epoch:train:1464-1540batch: iter_time=2.008e-04, forward_time=0.515, loss_ctc=17.735, loss=17.735, backward_time=0.556, optim_step_time=0.041, optim0_lr0=8.977e-04, train_time=1.184
[ALab02] 2023-06-10 01:48:48,378 (trainer:338) INFO: 28epoch results: [train] iter_time=0.001, forward_time=0.558, loss_ctc=16.359, loss=16.359, backward_time=0.573, optim_step_time=0.042, optim0_lr0=9.053e-04, train_time=1.248, time=32 minutes and 18.12 seconds, total_count=43484, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.828, cer_ctc=0.291, cer=0.291, loss=12.828, time=11.59 seconds, total_count=448, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.31 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 01:48:51,173 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 01:48:51,175 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/19epoch.pth
[ALab02] 2023-06-10 01:48:51,175 (trainer:272) INFO: 29/70epoch started. Estimated time to finish: 20 hours, 27 minutes and 10.81 seconds
[ALab02] 2023-06-10 01:50:23,768 (trainer:721) INFO: 29epoch:train:1-77batch: iter_time=0.014, forward_time=0.517, loss_ctc=15.893, loss=15.893, backward_time=0.559, optim_step_time=0.040, optim0_lr0=8.967e-04, train_time=1.202
[ALab02] 2023-06-10 01:52:04,425 (trainer:721) INFO: 29epoch:train:78-154batch: iter_time=1.743e-04, forward_time=0.602, loss_ctc=14.986, loss=14.986, backward_time=0.585, optim_step_time=0.040, optim0_lr0=8.960e-04, train_time=1.307
[ALab02] 2023-06-10 01:53:37,056 (trainer:721) INFO: 29epoch:train:155-231batch: iter_time=1.915e-04, forward_time=0.533, loss_ctc=14.447, loss=14.447, backward_time=0.562, optim_step_time=0.041, optim0_lr0=8.952e-04, train_time=1.203
[ALab02] 2023-06-10 01:55:16,072 (trainer:721) INFO: 29epoch:train:232-308batch: iter_time=1.944e-04, forward_time=0.575, loss_ctc=15.816, loss=15.816, backward_time=0.596, optim_step_time=0.040, optim0_lr0=8.944e-04, train_time=1.286
[ALab02] 2023-06-10 01:56:52,184 (trainer:721) INFO: 29epoch:train:309-385batch: iter_time=1.716e-04, forward_time=0.565, loss_ctc=15.290, loss=15.290, backward_time=0.565, optim_step_time=0.040, optim0_lr0=8.936e-04, train_time=1.248
[ALab02] 2023-06-10 01:58:27,885 (trainer:721) INFO: 29epoch:train:386-462batch: iter_time=1.825e-04, forward_time=0.549, loss_ctc=16.683, loss=16.683, backward_time=0.584, optim_step_time=0.039, optim0_lr0=8.928e-04, train_time=1.243
[ALab02] 2023-06-10 02:00:01,981 (trainer:721) INFO: 29epoch:train:463-539batch: iter_time=3.843e-04, forward_time=0.544, loss_ctc=17.219, loss=17.219, backward_time=0.559, optim_step_time=0.043, optim0_lr0=8.920e-04, train_time=1.222
[ALab02] 2023-06-10 02:01:41,195 (trainer:721) INFO: 29epoch:train:540-616batch: iter_time=1.971e-04, forward_time=0.582, loss_ctc=14.937, loss=14.937, backward_time=0.592, optim_step_time=0.040, optim0_lr0=8.912e-04, train_time=1.288
[ALab02] 2023-06-10 02:03:11,116 (trainer:721) INFO: 29epoch:train:617-693batch: iter_time=3.046e-04, forward_time=0.502, loss_ctc=16.241, loss=16.241, backward_time=0.554, optim_step_time=0.040, optim0_lr0=8.905e-04, train_time=1.168
[ALab02] 2023-06-10 02:04:46,884 (trainer:721) INFO: 29epoch:train:694-770batch: iter_time=2.043e-04, forward_time=0.546, loss_ctc=16.639, loss=16.639, backward_time=0.585, optim_step_time=0.039, optim0_lr0=8.897e-04, train_time=1.243
[ALab02] 2023-06-10 02:06:19,328 (trainer:721) INFO: 29epoch:train:771-847batch: iter_time=2.076e-04, forward_time=0.525, loss_ctc=16.432, loss=16.432, backward_time=0.567, optim_step_time=0.038, optim0_lr0=8.889e-04, train_time=1.200
[ALab02] 2023-06-10 02:08:00,466 (trainer:721) INFO: 29epoch:train:848-924batch: iter_time=1.685e-04, forward_time=0.618, loss_ctc=13.215, loss=13.215, backward_time=0.583, optim_step_time=0.040, optim0_lr0=8.881e-04, train_time=1.313
[ALab02] 2023-06-10 02:09:34,730 (trainer:721) INFO: 29epoch:train:925-1001batch: iter_time=1.693e-04, forward_time=0.544, loss_ctc=16.034, loss=16.034, backward_time=0.565, optim_step_time=0.042, optim0_lr0=8.874e-04, train_time=1.224
[ALab02] 2023-06-10 02:11:11,372 (trainer:721) INFO: 29epoch:train:1002-1078batch: iter_time=1.985e-04, forward_time=0.559, loss_ctc=16.124, loss=16.124, backward_time=0.577, optim_step_time=0.041, optim0_lr0=8.866e-04, train_time=1.255
[ALab02] 2023-06-10 02:12:46,195 (trainer:721) INFO: 29epoch:train:1079-1155batch: iter_time=2.013e-04, forward_time=0.535, loss_ctc=17.673, loss=17.673, backward_time=0.579, optim_step_time=0.040, optim0_lr0=8.858e-04, train_time=1.231
[ALab02] 2023-06-10 02:14:22,526 (trainer:721) INFO: 29epoch:train:1156-1232batch: iter_time=2.152e-04, forward_time=0.569, loss_ctc=16.641, loss=16.641, backward_time=0.566, optim_step_time=0.043, optim0_lr0=8.851e-04, train_time=1.251
[ALab02] 2023-06-10 02:16:02,500 (trainer:721) INFO: 29epoch:train:1233-1309batch: iter_time=1.667e-04, forward_time=0.595, loss_ctc=16.495, loss=16.495, backward_time=0.586, optim_step_time=0.041, optim0_lr0=8.843e-04, train_time=1.298
[ALab02] 2023-06-10 02:17:38,402 (trainer:721) INFO: 29epoch:train:1310-1386batch: iter_time=1.652e-04, forward_time=0.560, loss_ctc=17.190, loss=17.190, backward_time=0.569, optim_step_time=0.042, optim0_lr0=8.836e-04, train_time=1.245
[ALab02] 2023-06-10 02:19:16,685 (trainer:721) INFO: 29epoch:train:1387-1463batch: iter_time=2.127e-04, forward_time=0.585, loss_ctc=16.293, loss=16.293, backward_time=0.572, optim_step_time=0.041, optim0_lr0=8.828e-04, train_time=1.276
[ALab02] 2023-06-10 02:20:51,785 (trainer:721) INFO: 29epoch:train:1464-1540batch: iter_time=3.867e-04, forward_time=0.546, loss_ctc=16.293, loss=16.293, backward_time=0.570, optim_step_time=0.044, optim0_lr0=8.820e-04, train_time=1.235
[ALab02] 2023-06-10 02:21:49,994 (trainer:338) INFO: 29epoch results: [train] iter_time=9.191e-04, forward_time=0.558, loss_ctc=15.969, loss=15.969, backward_time=0.574, optim_step_time=0.041, optim0_lr0=8.893e-04, train_time=1.247, time=32 minutes and 17.08 seconds, total_count=45037, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.283, cer_ctc=0.291, cer=0.291, loss=13.283, time=11.32 seconds, total_count=464, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.42 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 02:21:52,284 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 02:21:52,287 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/18epoch.pth
[ALab02] 2023-06-10 02:21:52,287 (trainer:272) INFO: 30/70epoch started. Estimated time to finish: 20 hours, 3 minutes and 20.03 seconds
[ALab02] 2023-06-10 02:23:31,152 (trainer:721) INFO: 30epoch:train:1-77batch: iter_time=0.017, forward_time=0.574, loss_ctc=15.407, loss=15.407, backward_time=0.576, optim_step_time=0.042, optim0_lr0=8.812e-04, train_time=1.284
[ALab02] 2023-06-10 02:25:10,133 (trainer:721) INFO: 30epoch:train:78-154batch: iter_time=2.340e-04, forward_time=0.587, loss_ctc=15.585, loss=15.585, backward_time=0.586, optim_step_time=0.041, optim0_lr0=8.804e-04, train_time=1.285
[ALab02] 2023-06-10 02:26:42,506 (trainer:721) INFO: 30epoch:train:155-231batch: iter_time=1.814e-04, forward_time=0.536, loss_ctc=14.129, loss=14.129, backward_time=0.549, optim_step_time=0.042, optim0_lr0=8.797e-04, train_time=1.199
[ALab02] 2023-06-10 02:28:20,853 (trainer:721) INFO: 30epoch:train:232-308batch: iter_time=2.165e-04, forward_time=0.576, loss_ctc=15.336, loss=15.336, backward_time=0.584, optim_step_time=0.042, optim0_lr0=8.789e-04, train_time=1.277
[ALab02] 2023-06-10 02:29:52,131 (trainer:721) INFO: 30epoch:train:309-385batch: iter_time=1.902e-04, forward_time=0.518, loss_ctc=16.925, loss=16.925, backward_time=0.557, optim_step_time=0.041, optim0_lr0=8.782e-04, train_time=1.185
[ALab02] 2023-06-10 02:31:33,938 (trainer:721) INFO: 30epoch:train:386-462batch: iter_time=2.003e-04, forward_time=0.605, loss_ctc=13.731, loss=13.731, backward_time=0.601, optim_step_time=0.041, optim0_lr0=8.774e-04, train_time=1.322
[ALab02] 2023-06-10 02:33:03,407 (trainer:721) INFO: 30epoch:train:463-539batch: iter_time=2.063e-04, forward_time=0.497, loss_ctc=14.791, loss=14.791, backward_time=0.555, optim_step_time=0.043, optim0_lr0=8.767e-04, train_time=1.162
[ALab02] 2023-06-10 02:34:41,063 (trainer:721) INFO: 30epoch:train:540-616batch: iter_time=2.045e-04, forward_time=0.568, loss_ctc=17.720, loss=17.720, backward_time=0.584, optim_step_time=0.042, optim0_lr0=8.759e-04, train_time=1.268
[ALab02] 2023-06-10 02:36:17,054 (trainer:721) INFO: 30epoch:train:617-693batch: iter_time=2.070e-04, forward_time=0.576, loss_ctc=14.961, loss=14.961, backward_time=0.562, optim_step_time=0.039, optim0_lr0=8.752e-04, train_time=1.246
[ALab02] 2023-06-10 02:37:56,042 (trainer:721) INFO: 30epoch:train:694-770batch: iter_time=1.891e-04, forward_time=0.582, loss_ctc=15.803, loss=15.803, backward_time=0.585, optim_step_time=0.039, optim0_lr0=8.745e-04, train_time=1.285
[ALab02] 2023-06-10 02:39:30,070 (trainer:721) INFO: 30epoch:train:771-847batch: iter_time=4.439e-04, forward_time=0.542, loss_ctc=16.669, loss=16.669, backward_time=0.566, optim_step_time=0.041, optim0_lr0=8.737e-04, train_time=1.221
[ALab02] 2023-06-10 02:41:07,131 (trainer:721) INFO: 30epoch:train:848-924batch: iter_time=3.158e-04, forward_time=0.563, loss_ctc=16.876, loss=16.876, backward_time=0.574, optim_step_time=0.049, optim0_lr0=8.730e-04, train_time=1.260
[ALab02] 2023-06-10 02:42:40,457 (trainer:721) INFO: 30epoch:train:925-1001batch: iter_time=4.094e-04, forward_time=0.538, loss_ctc=16.476, loss=16.476, backward_time=0.558, optim_step_time=0.041, optim0_lr0=8.723e-04, train_time=1.212
[ALab02] 2023-06-10 02:44:18,615 (trainer:721) INFO: 30epoch:train:1002-1078batch: iter_time=2.052e-04, forward_time=0.565, loss_ctc=18.395, loss=18.395, backward_time=0.592, optim_step_time=0.043, optim0_lr0=8.715e-04, train_time=1.275
[ALab02] 2023-06-10 02:45:52,090 (trainer:721) INFO: 30epoch:train:1079-1155batch: iter_time=2.208e-04, forward_time=0.532, loss_ctc=15.874, loss=15.874, backward_time=0.562, optim_step_time=0.042, optim0_lr0=8.708e-04, train_time=1.214
[ALab02] 2023-06-10 02:47:32,659 (trainer:721) INFO: 30epoch:train:1156-1232batch: iter_time=3.113e-04, forward_time=0.605, loss_ctc=13.380, loss=13.380, backward_time=0.581, optim_step_time=0.042, optim0_lr0=8.701e-04, train_time=1.306
[ALab02] 2023-06-10 02:49:10,796 (trainer:721) INFO: 30epoch:train:1233-1309batch: iter_time=2.126e-04, forward_time=0.576, loss_ctc=14.869, loss=14.869, backward_time=0.579, optim_step_time=0.041, optim0_lr0=8.694e-04, train_time=1.274
[ALab02] 2023-06-10 02:50:46,227 (trainer:721) INFO: 30epoch:train:1310-1386batch: iter_time=1.993e-04, forward_time=0.550, loss_ctc=16.633, loss=16.633, backward_time=0.572, optim_step_time=0.040, optim0_lr0=8.686e-04, train_time=1.239
[ALab02] 2023-06-10 02:52:23,157 (trainer:721) INFO: 30epoch:train:1387-1463batch: iter_time=1.871e-04, forward_time=0.559, loss_ctc=16.815, loss=16.815, backward_time=0.585, optim_step_time=0.041, optim0_lr0=8.679e-04, train_time=1.259
[ALab02] 2023-06-10 02:53:59,613 (trainer:721) INFO: 30epoch:train:1464-1540batch: iter_time=2.634e-04, forward_time=0.587, loss_ctc=13.202, loss=13.202, backward_time=0.560, optim_step_time=0.040, optim0_lr0=8.672e-04, train_time=1.252
[ALab02] 2023-06-10 02:54:58,332 (trainer:338) INFO: 30epoch results: [train] iter_time=0.001, forward_time=0.562, loss_ctc=15.583, loss=15.583, backward_time=0.574, optim_step_time=0.042, optim0_lr0=8.741e-04, train_time=1.252, time=32 minutes and 24.36 seconds, total_count=46590, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.986, cer_ctc=0.289, cer=0.289, loss=12.986, time=11.59 seconds, total_count=480, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.09 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 02:55:01,075 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 02:55:01,076 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/20epoch.pth
[ALab02] 2023-06-10 02:55:01,077 (trainer:272) INFO: 31/70epoch started. Estimated time to finish: 19 hours, 39 minutes and 2.81 seconds
[ALab02] 2023-06-10 02:56:35,200 (trainer:721) INFO: 31epoch:train:1-77batch: iter_time=0.016, forward_time=0.535, loss_ctc=15.667, loss=15.667, backward_time=0.554, optim_step_time=0.041, optim0_lr0=8.664e-04, train_time=1.222
[ALab02] 2023-06-10 02:58:16,433 (trainer:721) INFO: 31epoch:train:78-154batch: iter_time=1.433e-04, forward_time=0.603, loss_ctc=14.805, loss=14.805, backward_time=0.597, optim_step_time=0.039, optim0_lr0=8.657e-04, train_time=1.315
[ALab02] 2023-06-10 02:59:49,280 (trainer:721) INFO: 31epoch:train:155-231batch: iter_time=4.335e-04, forward_time=0.538, loss_ctc=15.825, loss=15.825, backward_time=0.551, optim_step_time=0.044, optim0_lr0=8.649e-04, train_time=1.206
[ALab02] 2023-06-10 03:01:25,961 (trainer:721) INFO: 31epoch:train:232-308batch: iter_time=2.198e-04, forward_time=0.554, loss_ctc=14.687, loss=14.687, backward_time=0.584, optim_step_time=0.044, optim0_lr0=8.642e-04, train_time=1.255
[ALab02] 2023-06-10 03:03:04,832 (trainer:721) INFO: 31epoch:train:309-385batch: iter_time=4.542e-04, forward_time=0.598, loss_ctc=13.034, loss=13.034, backward_time=0.564, optim_step_time=0.047, optim0_lr0=8.635e-04, train_time=1.284
[ALab02] 2023-06-10 03:04:44,342 (trainer:721) INFO: 31epoch:train:386-462batch: iter_time=1.672e-04, forward_time=0.586, loss_ctc=14.623, loss=14.623, backward_time=0.593, optim_step_time=0.040, optim0_lr0=8.628e-04, train_time=1.292
[ALab02] 2023-06-10 03:06:20,470 (trainer:721) INFO: 31epoch:train:463-539batch: iter_time=1.735e-04, forward_time=0.561, loss_ctc=15.899, loss=15.899, backward_time=0.571, optim_step_time=0.041, optim0_lr0=8.621e-04, train_time=1.248
[ALab02] 2023-06-10 03:07:54,316 (trainer:721) INFO: 31epoch:train:540-616batch: iter_time=1.823e-04, forward_time=0.524, loss_ctc=14.748, loss=14.748, backward_time=0.581, optim_step_time=0.041, optim0_lr0=8.614e-04, train_time=1.219
[ALab02] 2023-06-10 03:09:26,238 (trainer:721) INFO: 31epoch:train:617-693batch: iter_time=1.906e-04, forward_time=0.526, loss_ctc=15.627, loss=15.627, backward_time=0.551, optim_step_time=0.040, optim0_lr0=8.607e-04, train_time=1.194
[ALab02] 2023-06-10 03:11:07,583 (trainer:721) INFO: 31epoch:train:694-770batch: iter_time=2.669e-04, forward_time=0.602, loss_ctc=16.819, loss=16.819, backward_time=0.590, optim_step_time=0.041, optim0_lr0=8.600e-04, train_time=1.316
[ALab02] 2023-06-10 03:12:40,743 (trainer:721) INFO: 31epoch:train:771-847batch: iter_time=1.515e-04, forward_time=0.538, loss_ctc=15.860, loss=15.860, backward_time=0.559, optim_step_time=0.041, optim0_lr0=8.593e-04, train_time=1.210
[ALab02] 2023-06-10 03:14:18,167 (trainer:721) INFO: 31epoch:train:848-924batch: iter_time=2.131e-04, forward_time=0.563, loss_ctc=14.468, loss=14.468, backward_time=0.583, optim_step_time=0.044, optim0_lr0=8.586e-04, train_time=1.265
[ALab02] 2023-06-10 03:15:58,805 (trainer:721) INFO: 31epoch:train:925-1001batch: iter_time=1.734e-04, forward_time=0.597, loss_ctc=15.945, loss=15.945, backward_time=0.592, optim_step_time=0.042, optim0_lr0=8.579e-04, train_time=1.307
[ALab02] 2023-06-10 03:17:32,275 (trainer:721) INFO: 31epoch:train:1002-1078batch: iter_time=1.923e-04, forward_time=0.537, loss_ctc=14.518, loss=14.518, backward_time=0.566, optim_step_time=0.042, optim0_lr0=8.572e-04, train_time=1.214
[ALab02] 2023-06-10 03:19:09,087 (trainer:721) INFO: 31epoch:train:1079-1155batch: iter_time=1.974e-04, forward_time=0.553, loss_ctc=15.061, loss=15.061, backward_time=0.586, optim_step_time=0.042, optim0_lr0=8.565e-04, train_time=1.257
[ALab02] 2023-06-10 03:20:42,895 (trainer:721) INFO: 31epoch:train:1156-1232batch: iter_time=1.931e-04, forward_time=0.546, loss_ctc=16.268, loss=16.268, backward_time=0.563, optim_step_time=0.043, optim0_lr0=8.558e-04, train_time=1.218
[ALab02] 2023-06-10 03:22:20,797 (trainer:721) INFO: 31epoch:train:1233-1309batch: iter_time=2.069e-04, forward_time=0.568, loss_ctc=17.076, loss=17.076, backward_time=0.589, optim_step_time=0.041, optim0_lr0=8.551e-04, train_time=1.271
[ALab02] 2023-06-10 03:23:50,955 (trainer:721) INFO: 31epoch:train:1310-1386batch: iter_time=1.643e-04, forward_time=0.505, loss_ctc=14.998, loss=14.998, backward_time=0.560, optim_step_time=0.042, optim0_lr0=8.545e-04, train_time=1.171
[ALab02] 2023-06-10 03:25:25,745 (trainer:721) INFO: 31epoch:train:1387-1463batch: iter_time=1.941e-04, forward_time=0.536, loss_ctc=15.941, loss=15.941, backward_time=0.576, optim_step_time=0.041, optim0_lr0=8.538e-04, train_time=1.231
[ALab02] 2023-06-10 03:27:04,883 (trainer:721) INFO: 31epoch:train:1464-1540batch: iter_time=1.500e-04, forward_time=0.606, loss_ctc=14.357, loss=14.357, backward_time=0.564, optim_step_time=0.039, optim0_lr0=8.531e-04, train_time=1.287
[ALab02] 2023-06-10 03:28:01,029 (trainer:338) INFO: 31epoch results: [train] iter_time=9.778e-04, forward_time=0.558, loss_ctc=15.286, loss=15.286, backward_time=0.574, optim_step_time=0.042, optim0_lr0=8.596e-04, train_time=1.249, time=32 minutes and 19.78 seconds, total_count=48143, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.378, cer_ctc=0.290, cer=0.290, loss=13.378, time=11.22 seconds, total_count=496, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.95 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 03:28:03,432 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 03:28:03,446 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/22epoch.pth
[ALab02] 2023-06-10 03:28:03,447 (trainer:272) INFO: 32/70epoch started. Estimated time to finish: 19 hours, 14 minutes and 3.21 seconds
[ALab02] 2023-06-10 03:29:41,297 (trainer:721) INFO: 32epoch:train:1-77batch: iter_time=0.016, forward_time=0.553, loss_ctc=14.124, loss=14.124, backward_time=0.580, optim_step_time=0.039, optim0_lr0=8.523e-04, train_time=1.270
[ALab02] 2023-06-10 03:31:21,008 (trainer:721) INFO: 32epoch:train:78-154batch: iter_time=1.385e-04, forward_time=0.588, loss_ctc=15.468, loss=15.468, backward_time=0.591, optim_step_time=0.039, optim0_lr0=8.516e-04, train_time=1.295
[ALab02] 2023-06-10 03:32:20,639 (trainer:721) INFO: 32epoch:train:155-231batch: iter_time=1.883e-04, forward_time=0.322, loss_ctc=14.961, loss=14.961, backward_time=0.366, optim_step_time=0.039, optim0_lr0=8.509e-04, train_time=0.774
[ALab02] 2023-06-10 03:33:08,221 (trainer:721) INFO: 32epoch:train:232-308batch: iter_time=1.411e-04, forward_time=0.231, loss_ctc=16.008, loss=16.008, backward_time=0.305, optim_step_time=0.039, optim0_lr0=8.503e-04, train_time=0.618
[ALab02] 2023-06-10 03:33:55,426 (trainer:721) INFO: 32epoch:train:309-385batch: iter_time=1.698e-04, forward_time=0.229, loss_ctc=15.174, loss=15.174, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.496e-04, train_time=0.613
[ALab02] 2023-06-10 03:34:42,353 (trainer:721) INFO: 32epoch:train:386-462batch: iter_time=1.514e-04, forward_time=0.227, loss_ctc=15.951, loss=15.951, backward_time=0.299, optim_step_time=0.039, optim0_lr0=8.489e-04, train_time=0.609
[ALab02] 2023-06-10 03:35:28,597 (trainer:721) INFO: 32epoch:train:463-539batch: iter_time=1.028e-04, forward_time=0.222, loss_ctc=15.907, loss=15.907, backward_time=0.300, optim_step_time=0.035, optim0_lr0=8.482e-04, train_time=0.600
[ALab02] 2023-06-10 03:36:17,415 (trainer:721) INFO: 32epoch:train:540-616batch: iter_time=3.714e-04, forward_time=0.244, loss_ctc=14.839, loss=14.839, backward_time=0.304, optim_step_time=0.043, optim0_lr0=8.476e-04, train_time=0.634
[ALab02] 2023-06-10 03:37:04,331 (trainer:721) INFO: 32epoch:train:617-693batch: iter_time=1.291e-04, forward_time=0.230, loss_ctc=16.036, loss=16.036, backward_time=0.301, optim_step_time=0.037, optim0_lr0=8.469e-04, train_time=0.609
[ALab02] 2023-06-10 03:37:52,478 (trainer:721) INFO: 32epoch:train:694-770batch: iter_time=1.250e-04, forward_time=0.237, loss_ctc=14.314, loss=14.314, backward_time=0.306, optim_step_time=0.039, optim0_lr0=8.462e-04, train_time=0.625
[ALab02] 2023-06-10 03:38:39,955 (trainer:721) INFO: 32epoch:train:771-847batch: iter_time=1.831e-04, forward_time=0.233, loss_ctc=13.719, loss=13.719, backward_time=0.303, optim_step_time=0.038, optim0_lr0=8.456e-04, train_time=0.616
[ALab02] 2023-06-10 03:39:27,503 (trainer:721) INFO: 32epoch:train:848-924batch: iter_time=1.537e-04, forward_time=0.235, loss_ctc=14.291, loss=14.291, backward_time=0.303, optim_step_time=0.038, optim0_lr0=8.449e-04, train_time=0.617
[ALab02] 2023-06-10 03:40:14,830 (trainer:721) INFO: 32epoch:train:925-1001batch: iter_time=1.305e-04, forward_time=0.230, loss_ctc=14.616, loss=14.616, backward_time=0.306, optim_step_time=0.037, optim0_lr0=8.442e-04, train_time=0.614
[ALab02] 2023-06-10 03:41:03,005 (trainer:721) INFO: 32epoch:train:1002-1078batch: iter_time=1.516e-04, forward_time=0.237, loss_ctc=12.756, loss=12.756, backward_time=0.302, optim_step_time=0.039, optim0_lr0=8.436e-04, train_time=0.625
[ALab02] 2023-06-10 03:41:50,504 (trainer:721) INFO: 32epoch:train:1079-1155batch: iter_time=1.465e-04, forward_time=0.230, loss_ctc=18.196, loss=18.196, backward_time=0.305, optim_step_time=0.037, optim0_lr0=8.429e-04, train_time=0.617
[ALab02] 2023-06-10 03:42:38,137 (trainer:721) INFO: 32epoch:train:1156-1232batch: iter_time=1.456e-04, forward_time=0.231, loss_ctc=13.814, loss=13.814, backward_time=0.306, optim_step_time=0.037, optim0_lr0=8.423e-04, train_time=0.618
[ALab02] 2023-06-10 03:43:25,418 (trainer:721) INFO: 32epoch:train:1233-1309batch: iter_time=1.249e-04, forward_time=0.230, loss_ctc=15.030, loss=15.030, backward_time=0.304, optim_step_time=0.037, optim0_lr0=8.416e-04, train_time=0.614
[ALab02] 2023-06-10 03:44:13,004 (trainer:721) INFO: 32epoch:train:1310-1386batch: iter_time=1.540e-04, forward_time=0.232, loss_ctc=15.007, loss=15.007, backward_time=0.307, optim_step_time=0.039, optim0_lr0=8.409e-04, train_time=0.618
[ALab02] 2023-06-10 03:45:00,203 (trainer:721) INFO: 32epoch:train:1387-1463batch: iter_time=1.496e-04, forward_time=0.229, loss_ctc=14.743, loss=14.743, backward_time=0.305, optim_step_time=0.039, optim0_lr0=8.403e-04, train_time=0.613
[ALab02] 2023-06-10 03:45:47,533 (trainer:721) INFO: 32epoch:train:1464-1540batch: iter_time=1.587e-04, forward_time=0.229, loss_ctc=17.019, loss=17.019, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.396e-04, train_time=0.614
[ALab02] 2023-06-10 03:46:30,957 (trainer:338) INFO: 32epoch results: [train] iter_time=9.326e-04, forward_time=0.270, loss_ctc=15.038, loss=15.038, backward_time=0.335, optim_step_time=0.038, optim0_lr0=8.459e-04, train_time=0.690, time=17 minutes and 52.12 seconds, total_count=49696, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.884, cer_ctc=0.280, cer=0.280, loss=12.884, time=6.97 seconds, total_count=512, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.42 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 03:46:33,291 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 03:46:33,305 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/24epoch.pth
[ALab02] 2023-06-10 03:46:33,305 (trainer:272) INFO: 33/70epoch started. Estimated time to finish: 18 hours, 31 minutes and 17.33 seconds
[ALab02] 2023-06-10 03:47:22,389 (trainer:721) INFO: 33epoch:train:1-77batch: iter_time=0.015, forward_time=0.231, loss_ctc=14.405, loss=14.405, backward_time=0.306, optim_step_time=0.040, optim0_lr0=8.389e-04, train_time=0.637
[ALab02] 2023-06-10 03:48:09,499 (trainer:721) INFO: 33epoch:train:78-154batch: iter_time=1.526e-04, forward_time=0.231, loss_ctc=14.032, loss=14.032, backward_time=0.301, optim_step_time=0.037, optim0_lr0=8.382e-04, train_time=0.612
[ALab02] 2023-06-10 03:48:56,422 (trainer:721) INFO: 33epoch:train:155-231batch: iter_time=1.586e-04, forward_time=0.227, loss_ctc=16.480, loss=16.480, backward_time=0.302, optim_step_time=0.038, optim0_lr0=8.376e-04, train_time=0.609
[ALab02] 2023-06-10 03:49:44,450 (trainer:721) INFO: 33epoch:train:232-308batch: iter_time=2.083e-04, forward_time=0.236, loss_ctc=13.599, loss=13.599, backward_time=0.308, optim_step_time=0.038, optim0_lr0=8.369e-04, train_time=0.623
[ALab02] 2023-06-10 03:50:31,659 (trainer:721) INFO: 33epoch:train:309-385batch: iter_time=1.600e-04, forward_time=0.229, loss_ctc=14.270, loss=14.270, backward_time=0.306, optim_step_time=0.036, optim0_lr0=8.363e-04, train_time=0.613
[ALab02] 2023-06-10 03:51:19,415 (trainer:721) INFO: 33epoch:train:386-462batch: iter_time=1.428e-04, forward_time=0.234, loss_ctc=14.857, loss=14.857, backward_time=0.307, optim_step_time=0.037, optim0_lr0=8.356e-04, train_time=0.620
[ALab02] 2023-06-10 03:52:07,065 (trainer:721) INFO: 33epoch:train:463-539batch: iter_time=1.386e-04, forward_time=0.236, loss_ctc=13.860, loss=13.860, backward_time=0.304, optim_step_time=0.037, optim0_lr0=8.350e-04, train_time=0.619
[ALab02] 2023-06-10 03:52:54,417 (trainer:721) INFO: 33epoch:train:540-616batch: iter_time=1.749e-04, forward_time=0.229, loss_ctc=14.394, loss=14.394, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.344e-04, train_time=0.615
[ALab02] 2023-06-10 03:53:42,467 (trainer:721) INFO: 33epoch:train:617-693batch: iter_time=1.578e-04, forward_time=0.236, loss_ctc=14.087, loss=14.087, backward_time=0.307, optim_step_time=0.037, optim0_lr0=8.337e-04, train_time=0.624
[ALab02] 2023-06-10 03:54:31,333 (trainer:721) INFO: 33epoch:train:694-770batch: iter_time=2.486e-04, forward_time=0.239, loss_ctc=15.096, loss=15.096, backward_time=0.309, optim_step_time=0.043, optim0_lr0=8.331e-04, train_time=0.634
[ALab02] 2023-06-10 03:55:19,762 (trainer:721) INFO: 33epoch:train:771-847batch: iter_time=1.546e-04, forward_time=0.239, loss_ctc=13.897, loss=13.897, backward_time=0.310, optim_step_time=0.037, optim0_lr0=8.325e-04, train_time=0.629
[ALab02] 2023-06-10 03:56:07,179 (trainer:721) INFO: 33epoch:train:848-924batch: iter_time=1.668e-04, forward_time=0.233, loss_ctc=14.319, loss=14.319, backward_time=0.300, optim_step_time=0.038, optim0_lr0=8.318e-04, train_time=0.616
[ALab02] 2023-06-10 03:56:54,281 (trainer:721) INFO: 33epoch:train:925-1001batch: iter_time=1.516e-04, forward_time=0.227, loss_ctc=15.848, loss=15.848, backward_time=0.306, optim_step_time=0.037, optim0_lr0=8.312e-04, train_time=0.611
[ALab02] 2023-06-10 03:57:41,899 (trainer:721) INFO: 33epoch:train:1002-1078batch: iter_time=1.708e-04, forward_time=0.234, loss_ctc=14.322, loss=14.322, backward_time=0.301, optim_step_time=0.040, optim0_lr0=8.306e-04, train_time=0.618
[ALab02] 2023-06-10 03:58:29,318 (trainer:721) INFO: 33epoch:train:1079-1155batch: iter_time=1.394e-04, forward_time=0.231, loss_ctc=12.746, loss=12.746, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.299e-04, train_time=0.616
[ALab02] 2023-06-10 03:59:16,666 (trainer:721) INFO: 33epoch:train:1156-1232batch: iter_time=1.447e-04, forward_time=0.231, loss_ctc=14.519, loss=14.519, backward_time=0.302, optim_step_time=0.039, optim0_lr0=8.293e-04, train_time=0.615
[ALab02] 2023-06-10 04:00:03,018 (trainer:721) INFO: 33epoch:train:1233-1309batch: iter_time=1.258e-04, forward_time=0.224, loss_ctc=16.192, loss=16.192, backward_time=0.296, optim_step_time=0.038, optim0_lr0=8.287e-04, train_time=0.602
[ALab02] 2023-06-10 04:00:50,716 (trainer:721) INFO: 33epoch:train:1310-1386batch: iter_time=1.723e-04, forward_time=0.232, loss_ctc=15.879, loss=15.879, backward_time=0.301, optim_step_time=0.039, optim0_lr0=8.281e-04, train_time=0.619
[ALab02] 2023-06-10 04:01:38,212 (trainer:721) INFO: 33epoch:train:1387-1463batch: iter_time=1.433e-04, forward_time=0.230, loss_ctc=17.114, loss=17.114, backward_time=0.306, optim_step_time=0.039, optim0_lr0=8.274e-04, train_time=0.617
[ALab02] 2023-06-10 04:02:25,854 (trainer:721) INFO: 33epoch:train:1464-1540batch: iter_time=1.521e-04, forward_time=0.230, loss_ctc=16.279, loss=16.279, backward_time=0.304, optim_step_time=0.039, optim0_lr0=8.268e-04, train_time=0.618
[ALab02] 2023-06-10 04:03:07,943 (trainer:338) INFO: 33epoch results: [train] iter_time=8.841e-04, forward_time=0.232, loss_ctc=14.773, loss=14.773, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.327e-04, train_time=0.618, time=16 minutes and 0.67 seconds, total_count=51249, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.298, cer_ctc=0.292, cer=0.292, loss=13.298, time=6.73 seconds, total_count=528, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.24 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 04:03:10,108 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 04:03:10,109 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/21epoch.pth
[ALab02] 2023-06-10 04:03:10,109 (trainer:272) INFO: 34/70epoch started. Estimated time to finish: 17 hours, 47 minutes and 52.94 seconds
[ALab02] 2023-06-10 04:03:58,101 (trainer:721) INFO: 34epoch:train:1-77batch: iter_time=0.013, forward_time=0.224, loss_ctc=15.272, loss=15.272, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.261e-04, train_time=0.623
[ALab02] 2023-06-10 04:04:45,519 (trainer:721) INFO: 34epoch:train:78-154batch: iter_time=1.731e-04, forward_time=0.231, loss_ctc=14.044, loss=14.044, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.255e-04, train_time=0.616
[ALab02] 2023-06-10 04:05:32,342 (trainer:721) INFO: 34epoch:train:155-231batch: iter_time=1.766e-04, forward_time=0.228, loss_ctc=14.970, loss=14.970, backward_time=0.303, optim_step_time=0.038, optim0_lr0=8.248e-04, train_time=0.608
[ALab02] 2023-06-10 04:06:20,449 (trainer:721) INFO: 34epoch:train:232-308batch: iter_time=1.523e-04, forward_time=0.233, loss_ctc=15.731, loss=15.731, backward_time=0.306, optim_step_time=0.038, optim0_lr0=8.242e-04, train_time=0.625
[ALab02] 2023-06-10 04:07:07,149 (trainer:721) INFO: 34epoch:train:309-385batch: iter_time=1.109e-04, forward_time=0.226, loss_ctc=13.793, loss=13.793, backward_time=0.299, optim_step_time=0.038, optim0_lr0=8.236e-04, train_time=0.606
[ALab02] 2023-06-10 04:07:53,791 (trainer:721) INFO: 34epoch:train:386-462batch: iter_time=1.400e-04, forward_time=0.225, loss_ctc=15.771, loss=15.771, backward_time=0.301, optim_step_time=0.038, optim0_lr0=8.230e-04, train_time=0.605
[ALab02] 2023-06-10 04:08:40,741 (trainer:721) INFO: 34epoch:train:463-539batch: iter_time=1.770e-04, forward_time=0.229, loss_ctc=15.197, loss=15.197, backward_time=0.299, optim_step_time=0.038, optim0_lr0=8.224e-04, train_time=0.610
[ALab02] 2023-06-10 04:09:29,207 (trainer:721) INFO: 34epoch:train:540-616batch: iter_time=1.671e-04, forward_time=0.235, loss_ctc=14.444, loss=14.444, backward_time=0.313, optim_step_time=0.038, optim0_lr0=8.218e-04, train_time=0.629
[ALab02] 2023-06-10 04:10:16,969 (trainer:721) INFO: 34epoch:train:617-693batch: iter_time=1.476e-04, forward_time=0.234, loss_ctc=14.370, loss=14.370, backward_time=0.305, optim_step_time=0.037, optim0_lr0=8.212e-04, train_time=0.620
[ALab02] 2023-06-10 04:11:03,950 (trainer:721) INFO: 34epoch:train:694-770batch: iter_time=1.365e-04, forward_time=0.228, loss_ctc=12.846, loss=12.846, backward_time=0.302, optim_step_time=0.036, optim0_lr0=8.206e-04, train_time=0.610
[ALab02] 2023-06-10 04:11:50,353 (trainer:721) INFO: 34epoch:train:771-847batch: iter_time=1.208e-04, forward_time=0.223, loss_ctc=15.539, loss=15.539, backward_time=0.301, optim_step_time=0.036, optim0_lr0=8.199e-04, train_time=0.602
[ALab02] 2023-06-10 04:12:38,216 (trainer:721) INFO: 34epoch:train:848-924batch: iter_time=3.448e-04, forward_time=0.235, loss_ctc=15.099, loss=15.099, backward_time=0.303, optim_step_time=0.040, optim0_lr0=8.193e-04, train_time=0.621
[ALab02] 2023-06-10 04:13:25,068 (trainer:721) INFO: 34epoch:train:925-1001batch: iter_time=1.639e-04, forward_time=0.228, loss_ctc=15.643, loss=15.643, backward_time=0.302, optim_step_time=0.036, optim0_lr0=8.187e-04, train_time=0.608
[ALab02] 2023-06-10 04:14:12,859 (trainer:721) INFO: 34epoch:train:1002-1078batch: iter_time=1.390e-04, forward_time=0.236, loss_ctc=12.386, loss=12.386, backward_time=0.307, optim_step_time=0.037, optim0_lr0=8.181e-04, train_time=0.620
[ALab02] 2023-06-10 04:15:02,967 (trainer:721) INFO: 34epoch:train:1079-1155batch: iter_time=6.033e-04, forward_time=0.247, loss_ctc=14.580, loss=14.580, backward_time=0.307, optim_step_time=0.048, optim0_lr0=8.175e-04, train_time=0.651
[ALab02] 2023-06-10 04:15:50,592 (trainer:721) INFO: 34epoch:train:1156-1232batch: iter_time=1.508e-04, forward_time=0.234, loss_ctc=13.004, loss=13.004, backward_time=0.303, optim_step_time=0.037, optim0_lr0=8.169e-04, train_time=0.618
[ALab02] 2023-06-10 04:16:39,241 (trainer:721) INFO: 34epoch:train:1233-1309batch: iter_time=1.898e-04, forward_time=0.241, loss_ctc=13.494, loss=13.494, backward_time=0.306, optim_step_time=0.039, optim0_lr0=8.163e-04, train_time=0.632
[ALab02] 2023-06-10 04:17:27,075 (trainer:721) INFO: 34epoch:train:1310-1386batch: iter_time=1.282e-04, forward_time=0.232, loss_ctc=14.243, loss=14.243, backward_time=0.308, optim_step_time=0.038, optim0_lr0=8.157e-04, train_time=0.621
[ALab02] 2023-06-10 04:18:14,437 (trainer:721) INFO: 34epoch:train:1387-1463batch: iter_time=1.548e-04, forward_time=0.231, loss_ctc=13.393, loss=13.393, backward_time=0.307, optim_step_time=0.036, optim0_lr0=8.151e-04, train_time=0.615
[ALab02] 2023-06-10 04:19:01,188 (trainer:721) INFO: 34epoch:train:1464-1540batch: iter_time=1.195e-04, forward_time=0.224, loss_ctc=17.716, loss=17.716, backward_time=0.303, optim_step_time=0.037, optim0_lr0=8.145e-04, train_time=0.607
[ALab02] 2023-06-10 04:19:43,908 (trainer:338) INFO: 34epoch results: [train] iter_time=8.289e-04, forward_time=0.231, loss_ctc=14.493, loss=14.493, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.202e-04, train_time=0.617, time=15 minutes and 59.3 seconds, total_count=52802, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.910, cer_ctc=0.276, cer=0.276, loss=12.910, time=6.76 seconds, total_count=544, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.74 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 04:19:46,078 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 04:19:46,092 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/25epoch.pth
[ALab02] 2023-06-10 04:19:46,092 (trainer:272) INFO: 35/70epoch started. Estimated time to finish: 17 hours, 6 minutes and 2.25 seconds
[ALab02] 2023-06-10 04:20:35,327 (trainer:721) INFO: 35epoch:train:1-77batch: iter_time=0.017, forward_time=0.234, loss_ctc=13.629, loss=13.629, backward_time=0.306, optim_step_time=0.039, optim0_lr0=8.139e-04, train_time=0.639
[ALab02] 2023-06-10 04:21:23,248 (trainer:721) INFO: 35epoch:train:78-154batch: iter_time=1.249e-04, forward_time=0.233, loss_ctc=13.954, loss=13.954, backward_time=0.307, optim_step_time=0.038, optim0_lr0=8.133e-04, train_time=0.622
[ALab02] 2023-06-10 04:22:11,267 (trainer:721) INFO: 35epoch:train:155-231batch: iter_time=1.225e-04, forward_time=0.231, loss_ctc=14.959, loss=14.959, backward_time=0.308, optim_step_time=0.038, optim0_lr0=8.127e-04, train_time=0.623
[ALab02] 2023-06-10 04:22:58,315 (trainer:721) INFO: 35epoch:train:232-308batch: iter_time=1.465e-04, forward_time=0.230, loss_ctc=13.186, loss=13.186, backward_time=0.300, optim_step_time=0.037, optim0_lr0=8.121e-04, train_time=0.611
[ALab02] 2023-06-10 04:23:45,981 (trainer:721) INFO: 35epoch:train:309-385batch: iter_time=1.726e-04, forward_time=0.233, loss_ctc=13.837, loss=13.837, backward_time=0.307, optim_step_time=0.037, optim0_lr0=8.115e-04, train_time=0.619
[ALab02] 2023-06-10 04:24:32,983 (trainer:721) INFO: 35epoch:train:386-462batch: iter_time=1.454e-04, forward_time=0.226, loss_ctc=15.731, loss=15.731, backward_time=0.304, optim_step_time=0.037, optim0_lr0=8.109e-04, train_time=0.610
[ALab02] 2023-06-10 04:25:20,452 (trainer:721) INFO: 35epoch:train:463-539batch: iter_time=1.352e-04, forward_time=0.227, loss_ctc=14.353, loss=14.353, backward_time=0.306, optim_step_time=0.039, optim0_lr0=8.103e-04, train_time=0.616
[ALab02] 2023-06-10 04:26:08,956 (trainer:721) INFO: 35epoch:train:540-616batch: iter_time=2.321e-04, forward_time=0.240, loss_ctc=13.532, loss=13.532, backward_time=0.303, optim_step_time=0.042, optim0_lr0=8.097e-04, train_time=0.630
[ALab02] 2023-06-10 04:26:56,753 (trainer:721) INFO: 35epoch:train:617-693batch: iter_time=1.676e-04, forward_time=0.237, loss_ctc=13.645, loss=13.645, backward_time=0.301, optim_step_time=0.038, optim0_lr0=8.091e-04, train_time=0.621
[ALab02] 2023-06-10 04:27:44,222 (trainer:721) INFO: 35epoch:train:694-770batch: iter_time=1.321e-04, forward_time=0.230, loss_ctc=14.816, loss=14.816, backward_time=0.308, optim_step_time=0.037, optim0_lr0=8.086e-04, train_time=0.616
[ALab02] 2023-06-10 04:28:31,372 (trainer:721) INFO: 35epoch:train:771-847batch: iter_time=1.521e-04, forward_time=0.228, loss_ctc=16.509, loss=16.509, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.080e-04, train_time=0.612
[ALab02] 2023-06-10 04:29:18,961 (trainer:721) INFO: 35epoch:train:848-924batch: iter_time=1.361e-04, forward_time=0.232, loss_ctc=14.579, loss=14.579, backward_time=0.302, optim_step_time=0.038, optim0_lr0=8.074e-04, train_time=0.618
[ALab02] 2023-06-10 04:30:06,270 (trainer:721) INFO: 35epoch:train:925-1001batch: iter_time=1.660e-04, forward_time=0.235, loss_ctc=13.336, loss=13.336, backward_time=0.301, optim_step_time=0.037, optim0_lr0=8.068e-04, train_time=0.614
[ALab02] 2023-06-10 04:30:53,926 (trainer:721) INFO: 35epoch:train:1002-1078batch: iter_time=1.714e-04, forward_time=0.230, loss_ctc=13.443, loss=13.443, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.062e-04, train_time=0.619
[ALab02] 2023-06-10 04:31:40,542 (trainer:721) INFO: 35epoch:train:1079-1155batch: iter_time=1.511e-04, forward_time=0.226, loss_ctc=15.797, loss=15.797, backward_time=0.299, optim_step_time=0.038, optim0_lr0=8.057e-04, train_time=0.605
[ALab02] 2023-06-10 04:32:28,345 (trainer:721) INFO: 35epoch:train:1156-1232batch: iter_time=1.368e-04, forward_time=0.229, loss_ctc=14.386, loss=14.386, backward_time=0.310, optim_step_time=0.037, optim0_lr0=8.051e-04, train_time=0.621
[ALab02] 2023-06-10 04:33:16,802 (trainer:721) INFO: 35epoch:train:1233-1309batch: iter_time=1.653e-04, forward_time=0.236, loss_ctc=13.511, loss=13.511, backward_time=0.306, optim_step_time=0.042, optim0_lr0=8.045e-04, train_time=0.629
[ALab02] 2023-06-10 04:34:04,953 (trainer:721) INFO: 35epoch:train:1310-1386batch: iter_time=1.429e-04, forward_time=0.236, loss_ctc=13.199, loss=13.199, backward_time=0.308, optim_step_time=0.039, optim0_lr0=8.040e-04, train_time=0.625
[ALab02] 2023-06-10 04:34:52,090 (trainer:721) INFO: 35epoch:train:1387-1463batch: iter_time=1.913e-04, forward_time=0.229, loss_ctc=14.769, loss=14.769, backward_time=0.303, optim_step_time=0.038, optim0_lr0=8.034e-04, train_time=0.612
[ALab02] 2023-06-10 04:35:39,379 (trainer:721) INFO: 35epoch:train:1464-1540batch: iter_time=1.457e-04, forward_time=0.233, loss_ctc=12.765, loss=12.765, backward_time=0.302, optim_step_time=0.038, optim0_lr0=8.028e-04, train_time=0.614
[ALab02] 2023-06-10 04:36:21,266 (trainer:338) INFO: 35epoch results: [train] iter_time=9.696e-04, forward_time=0.232, loss_ctc=14.141, loss=14.141, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.082e-04, train_time=0.619, time=16 minutes and 1.16 seconds, total_count=54355, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.128, cer_ctc=0.282, cer=0.282, loss=13.128, time=6.67 seconds, total_count=560, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.34 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 04:36:23,527 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 04:36:23,541 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/27epoch.pth
[ALab02] 2023-06-10 04:36:23,541 (trainer:272) INFO: 36/70epoch started. Estimated time to finish: 16 hours, 25 minutes and 39.57 seconds
[ALab02] 2023-06-10 04:37:11,788 (trainer:721) INFO: 36epoch:train:1-77batch: iter_time=0.015, forward_time=0.226, loss_ctc=14.445, loss=14.445, backward_time=0.304, optim_step_time=0.038, optim0_lr0=8.021e-04, train_time=0.626
[ALab02] 2023-06-10 04:37:58,501 (trainer:721) INFO: 36epoch:train:78-154batch: iter_time=1.557e-04, forward_time=0.227, loss_ctc=13.565, loss=13.565, backward_time=0.301, optim_step_time=0.038, optim0_lr0=8.016e-04, train_time=0.606
[ALab02] 2023-06-10 04:38:45,158 (trainer:721) INFO: 36epoch:train:155-231batch: iter_time=1.740e-04, forward_time=0.225, loss_ctc=14.913, loss=14.913, backward_time=0.301, optim_step_time=0.039, optim0_lr0=8.010e-04, train_time=0.606
[ALab02] 2023-06-10 04:39:31,777 (trainer:721) INFO: 36epoch:train:232-308batch: iter_time=1.544e-04, forward_time=0.227, loss_ctc=14.728, loss=14.728, backward_time=0.296, optim_step_time=0.040, optim0_lr0=8.005e-04, train_time=0.605
[ALab02] 2023-06-10 04:40:19,313 (trainer:721) INFO: 36epoch:train:309-385batch: iter_time=1.529e-04, forward_time=0.233, loss_ctc=14.706, loss=14.706, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.999e-04, train_time=0.617
[ALab02] 2023-06-10 04:41:06,833 (trainer:721) INFO: 36epoch:train:386-462batch: iter_time=1.630e-04, forward_time=0.230, loss_ctc=12.972, loss=12.972, backward_time=0.308, optim_step_time=0.038, optim0_lr0=7.993e-04, train_time=0.617
[ALab02] 2023-06-10 04:41:55,900 (trainer:721) INFO: 36epoch:train:463-539batch: iter_time=1.511e-04, forward_time=0.244, loss_ctc=13.254, loss=13.254, backward_time=0.310, optim_step_time=0.038, optim0_lr0=7.988e-04, train_time=0.637
[ALab02] 2023-06-10 04:42:43,700 (trainer:721) INFO: 36epoch:train:540-616batch: iter_time=1.618e-04, forward_time=0.232, loss_ctc=13.632, loss=13.632, backward_time=0.306, optim_step_time=0.039, optim0_lr0=7.982e-04, train_time=0.621
[ALab02] 2023-06-10 04:43:30,947 (trainer:721) INFO: 36epoch:train:617-693batch: iter_time=1.699e-04, forward_time=0.226, loss_ctc=13.984, loss=13.984, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.976e-04, train_time=0.613
[ALab02] 2023-06-10 04:44:17,658 (trainer:721) INFO: 36epoch:train:694-770batch: iter_time=1.817e-04, forward_time=0.226, loss_ctc=15.330, loss=15.330, backward_time=0.301, optim_step_time=0.038, optim0_lr0=7.971e-04, train_time=0.606
[ALab02] 2023-06-10 04:45:05,295 (trainer:721) INFO: 36epoch:train:771-847batch: iter_time=1.459e-04, forward_time=0.231, loss_ctc=13.562, loss=13.562, backward_time=0.309, optim_step_time=0.037, optim0_lr0=7.965e-04, train_time=0.618
[ALab02] 2023-06-10 04:45:53,387 (trainer:721) INFO: 36epoch:train:848-924batch: iter_time=1.635e-04, forward_time=0.236, loss_ctc=13.056, loss=13.056, backward_time=0.308, optim_step_time=0.038, optim0_lr0=7.960e-04, train_time=0.624
[ALab02] 2023-06-10 04:46:42,488 (trainer:721) INFO: 36epoch:train:925-1001batch: iter_time=1.594e-04, forward_time=0.240, loss_ctc=13.025, loss=13.025, backward_time=0.308, optim_step_time=0.040, optim0_lr0=7.954e-04, train_time=0.637
[ALab02] 2023-06-10 04:47:30,288 (trainer:721) INFO: 36epoch:train:1002-1078batch: iter_time=1.629e-04, forward_time=0.232, loss_ctc=13.282, loss=13.282, backward_time=0.307, optim_step_time=0.038, optim0_lr0=7.949e-04, train_time=0.621
[ALab02] 2023-06-10 04:48:19,160 (trainer:721) INFO: 36epoch:train:1079-1155batch: iter_time=2.185e-04, forward_time=0.239, loss_ctc=16.712, loss=16.712, backward_time=0.304, optim_step_time=0.043, optim0_lr0=7.943e-04, train_time=0.634
[ALab02] 2023-06-10 04:49:07,352 (trainer:721) INFO: 36epoch:train:1156-1232batch: iter_time=2.026e-04, forward_time=0.233, loss_ctc=13.246, loss=13.246, backward_time=0.303, optim_step_time=0.043, optim0_lr0=7.938e-04, train_time=0.626
[ALab02] 2023-06-10 04:49:54,478 (trainer:721) INFO: 36epoch:train:1233-1309batch: iter_time=1.916e-04, forward_time=0.227, loss_ctc=13.006, loss=13.006, backward_time=0.301, optim_step_time=0.040, optim0_lr0=7.932e-04, train_time=0.612
[ALab02] 2023-06-10 04:50:41,672 (trainer:721) INFO: 36epoch:train:1310-1386batch: iter_time=1.317e-04, forward_time=0.230, loss_ctc=13.064, loss=13.064, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.927e-04, train_time=0.613
[ALab02] 2023-06-10 04:51:29,863 (trainer:721) INFO: 36epoch:train:1387-1463batch: iter_time=2.681e-04, forward_time=0.237, loss_ctc=13.778, loss=13.778, backward_time=0.304, optim_step_time=0.041, optim0_lr0=7.921e-04, train_time=0.626
[ALab02] 2023-06-10 04:52:16,800 (trainer:721) INFO: 36epoch:train:1464-1540batch: iter_time=1.445e-04, forward_time=0.230, loss_ctc=13.821, loss=13.821, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.916e-04, train_time=0.609
[ALab02] 2023-06-10 04:52:58,680 (trainer:338) INFO: 36epoch results: [train] iter_time=9.035e-04, forward_time=0.232, loss_ctc=13.865, loss=13.865, backward_time=0.304, optim_step_time=0.039, optim0_lr0=7.968e-04, train_time=0.619, time=16 minutes and 1.44 seconds, total_count=55908, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.332, cer_ctc=0.284, cer=0.284, loss=13.332, time=6.68 seconds, total_count=576, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.02 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 04:53:00,974 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 04:53:00,989 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/26epoch.pth
[ALab02] 2023-06-10 04:53:00,989 (trainer:272) INFO: 37/70epoch started. Estimated time to finish: 15 hours, 46 minutes and 36.07 seconds
[ALab02] 2023-06-10 04:53:49,821 (trainer:721) INFO: 37epoch:train:1-77batch: iter_time=0.016, forward_time=0.229, loss_ctc=11.886, loss=11.886, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.909e-04, train_time=0.634
[ALab02] 2023-06-10 04:54:37,037 (trainer:721) INFO: 37epoch:train:78-154batch: iter_time=1.497e-04, forward_time=0.229, loss_ctc=14.501, loss=14.501, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.904e-04, train_time=0.613
[ALab02] 2023-06-10 04:55:24,271 (trainer:721) INFO: 37epoch:train:155-231batch: iter_time=1.917e-04, forward_time=0.230, loss_ctc=14.483, loss=14.483, backward_time=0.301, optim_step_time=0.038, optim0_lr0=7.899e-04, train_time=0.613
[ALab02] 2023-06-10 04:56:10,391 (trainer:721) INFO: 37epoch:train:232-308batch: iter_time=1.442e-04, forward_time=0.223, loss_ctc=14.623, loss=14.623, backward_time=0.298, optim_step_time=0.038, optim0_lr0=7.893e-04, train_time=0.599
[ALab02] 2023-06-10 04:56:56,714 (trainer:721) INFO: 37epoch:train:309-385batch: iter_time=1.678e-04, forward_time=0.222, loss_ctc=13.948, loss=13.948, backward_time=0.301, optim_step_time=0.038, optim0_lr0=7.888e-04, train_time=0.601
[ALab02] 2023-06-10 04:57:43,705 (trainer:721) INFO: 37epoch:train:386-462batch: iter_time=1.732e-04, forward_time=0.230, loss_ctc=11.936, loss=11.936, backward_time=0.301, optim_step_time=0.038, optim0_lr0=7.882e-04, train_time=0.610
[ALab02] 2023-06-10 04:58:30,433 (trainer:721) INFO: 37epoch:train:463-539batch: iter_time=1.826e-04, forward_time=0.224, loss_ctc=14.708, loss=14.708, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.877e-04, train_time=0.607
[ALab02] 2023-06-10 04:59:17,899 (trainer:721) INFO: 37epoch:train:540-616batch: iter_time=1.740e-04, forward_time=0.229, loss_ctc=12.908, loss=12.908, backward_time=0.307, optim_step_time=0.039, optim0_lr0=7.872e-04, train_time=0.616
[ALab02] 2023-06-10 05:00:05,658 (trainer:721) INFO: 37epoch:train:617-693batch: iter_time=1.581e-04, forward_time=0.231, loss_ctc=14.254, loss=14.254, backward_time=0.308, optim_step_time=0.038, optim0_lr0=7.866e-04, train_time=0.620
[ALab02] 2023-06-10 05:00:54,051 (trainer:721) INFO: 37epoch:train:694-770batch: iter_time=1.667e-04, forward_time=0.238, loss_ctc=13.996, loss=13.996, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.861e-04, train_time=0.628
[ALab02] 2023-06-10 05:01:42,683 (trainer:721) INFO: 37epoch:train:771-847batch: iter_time=1.447e-04, forward_time=0.239, loss_ctc=12.017, loss=12.017, backward_time=0.312, optim_step_time=0.038, optim0_lr0=7.855e-04, train_time=0.631
[ALab02] 2023-06-10 05:02:30,430 (trainer:721) INFO: 37epoch:train:848-924batch: iter_time=1.565e-04, forward_time=0.233, loss_ctc=13.719, loss=13.719, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.850e-04, train_time=0.620
[ALab02] 2023-06-10 05:03:18,408 (trainer:721) INFO: 37epoch:train:925-1001batch: iter_time=1.363e-04, forward_time=0.237, loss_ctc=12.634, loss=12.634, backward_time=0.307, optim_step_time=0.036, optim0_lr0=7.845e-04, train_time=0.623
[ALab02] 2023-06-10 05:04:06,191 (trainer:721) INFO: 37epoch:train:1002-1078batch: iter_time=1.757e-04, forward_time=0.231, loss_ctc=14.672, loss=14.672, backward_time=0.307, optim_step_time=0.036, optim0_lr0=7.840e-04, train_time=0.620
[ALab02] 2023-06-10 05:04:53,268 (trainer:721) INFO: 37epoch:train:1079-1155batch: iter_time=1.640e-04, forward_time=0.228, loss_ctc=13.176, loss=13.176, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.834e-04, train_time=0.611
[ALab02] 2023-06-10 05:05:40,537 (trainer:721) INFO: 37epoch:train:1156-1232batch: iter_time=1.431e-04, forward_time=0.230, loss_ctc=12.924, loss=12.924, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.829e-04, train_time=0.614
[ALab02] 2023-06-10 05:06:28,247 (trainer:721) INFO: 37epoch:train:1233-1309batch: iter_time=1.756e-04, forward_time=0.234, loss_ctc=13.456, loss=13.456, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.824e-04, train_time=0.619
[ALab02] 2023-06-10 05:07:15,071 (trainer:721) INFO: 37epoch:train:1310-1386batch: iter_time=1.323e-04, forward_time=0.225, loss_ctc=14.252, loss=14.252, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.818e-04, train_time=0.608
[ALab02] 2023-06-10 05:08:01,191 (trainer:721) INFO: 37epoch:train:1387-1463batch: iter_time=1.109e-04, forward_time=0.223, loss_ctc=14.081, loss=14.081, backward_time=0.298, optim_step_time=0.035, optim0_lr0=7.813e-04, train_time=0.599
[ALab02] 2023-06-10 05:08:48,639 (trainer:721) INFO: 37epoch:train:1464-1540batch: iter_time=1.344e-04, forward_time=0.232, loss_ctc=13.028, loss=13.028, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.808e-04, train_time=0.616
[ALab02] 2023-06-10 05:09:34,143 (trainer:338) INFO: 37epoch results: [train] iter_time=9.357e-04, forward_time=0.230, loss_ctc=13.532, loss=13.532, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.858e-04, train_time=0.615, time=15 minutes and 56.02 seconds, total_count=57461, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.461, cer_ctc=0.274, cer=0.274, loss=12.461, time=6.76 seconds, total_count=592, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.38 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 05:09:36,472 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 05:09:36,487 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/23epoch.pth
[ALab02] 2023-06-10 05:09:36,487 (trainer:272) INFO: 38/70epoch started. Estimated time to finish: 15 hours, 8 minutes and 43.6 seconds
[ALab02] 2023-06-10 05:10:25,762 (trainer:721) INFO: 38epoch:train:1-77batch: iter_time=0.013, forward_time=0.234, loss_ctc=13.724, loss=13.724, backward_time=0.309, optim_step_time=0.037, optim0_lr0=7.802e-04, train_time=0.640
[ALab02] 2023-06-10 05:11:13,012 (trainer:721) INFO: 38epoch:train:78-154batch: iter_time=1.484e-04, forward_time=0.230, loss_ctc=14.001, loss=14.001, backward_time=0.302, optim_step_time=0.038, optim0_lr0=7.797e-04, train_time=0.613
[ALab02] 2023-06-10 05:12:00,373 (trainer:721) INFO: 38epoch:train:155-231batch: iter_time=1.658e-04, forward_time=0.231, loss_ctc=13.548, loss=13.548, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.791e-04, train_time=0.615
[ALab02] 2023-06-10 05:12:48,933 (trainer:721) INFO: 38epoch:train:232-308batch: iter_time=1.430e-04, forward_time=0.239, loss_ctc=12.538, loss=12.538, backward_time=0.308, optim_step_time=0.037, optim0_lr0=7.786e-04, train_time=0.630
[ALab02] 2023-06-10 05:13:35,865 (trainer:721) INFO: 38epoch:train:309-385batch: iter_time=1.583e-04, forward_time=0.228, loss_ctc=12.272, loss=12.272, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.781e-04, train_time=0.609
[ALab02] 2023-06-10 05:14:22,328 (trainer:721) INFO: 38epoch:train:386-462batch: iter_time=1.498e-04, forward_time=0.228, loss_ctc=11.603, loss=11.603, backward_time=0.301, optim_step_time=0.036, optim0_lr0=7.776e-04, train_time=0.603
[ALab02] 2023-06-10 05:15:10,074 (trainer:721) INFO: 38epoch:train:463-539batch: iter_time=1.473e-04, forward_time=0.233, loss_ctc=13.513, loss=13.513, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.771e-04, train_time=0.620
[ALab02] 2023-06-10 05:15:57,528 (trainer:721) INFO: 38epoch:train:540-616batch: iter_time=1.669e-04, forward_time=0.230, loss_ctc=13.579, loss=13.579, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.766e-04, train_time=0.616
[ALab02] 2023-06-10 05:16:44,408 (trainer:721) INFO: 38epoch:train:617-693batch: iter_time=1.461e-04, forward_time=0.226, loss_ctc=13.441, loss=13.441, backward_time=0.306, optim_step_time=0.036, optim0_lr0=7.760e-04, train_time=0.609
[ALab02] 2023-06-10 05:17:31,773 (trainer:721) INFO: 38epoch:train:694-770batch: iter_time=1.620e-04, forward_time=0.230, loss_ctc=13.765, loss=13.765, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.755e-04, train_time=0.615
[ALab02] 2023-06-10 05:18:18,602 (trainer:721) INFO: 38epoch:train:771-847batch: iter_time=1.425e-04, forward_time=0.225, loss_ctc=14.670, loss=14.670, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.750e-04, train_time=0.608
[ALab02] 2023-06-10 05:19:05,568 (trainer:721) INFO: 38epoch:train:848-924batch: iter_time=1.466e-04, forward_time=0.227, loss_ctc=14.676, loss=14.676, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.745e-04, train_time=0.610
[ALab02] 2023-06-10 05:19:52,521 (trainer:721) INFO: 38epoch:train:925-1001batch: iter_time=1.334e-04, forward_time=0.226, loss_ctc=13.558, loss=13.558, backward_time=0.305, optim_step_time=0.037, optim0_lr0=7.740e-04, train_time=0.610
[ALab02] 2023-06-10 05:20:39,671 (trainer:721) INFO: 38epoch:train:1002-1078batch: iter_time=1.764e-04, forward_time=0.227, loss_ctc=13.381, loss=13.381, backward_time=0.300, optim_step_time=0.040, optim0_lr0=7.735e-04, train_time=0.612
[ALab02] 2023-06-10 05:21:26,459 (trainer:721) INFO: 38epoch:train:1079-1155batch: iter_time=1.523e-04, forward_time=0.228, loss_ctc=13.487, loss=13.487, backward_time=0.302, optim_step_time=0.036, optim0_lr0=7.730e-04, train_time=0.607
[ALab02] 2023-06-10 05:22:14,153 (trainer:721) INFO: 38epoch:train:1156-1232batch: iter_time=1.411e-04, forward_time=0.233, loss_ctc=11.952, loss=11.952, backward_time=0.305, optim_step_time=0.037, optim0_lr0=7.725e-04, train_time=0.619
[ALab02] 2023-06-10 05:23:00,646 (trainer:721) INFO: 38epoch:train:1233-1309batch: iter_time=1.872e-04, forward_time=0.224, loss_ctc=13.572, loss=13.572, backward_time=0.300, optim_step_time=0.038, optim0_lr0=7.720e-04, train_time=0.604
[ALab02] 2023-06-10 05:23:48,378 (trainer:721) INFO: 38epoch:train:1310-1386batch: iter_time=1.468e-04, forward_time=0.233, loss_ctc=12.617, loss=12.617, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.715e-04, train_time=0.620
[ALab02] 2023-06-10 05:24:35,490 (trainer:721) INFO: 38epoch:train:1387-1463batch: iter_time=1.422e-04, forward_time=0.227, loss_ctc=13.896, loss=13.896, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.709e-04, train_time=0.612
[ALab02] 2023-06-10 05:25:22,426 (trainer:721) INFO: 38epoch:train:1464-1540batch: iter_time=1.529e-04, forward_time=0.228, loss_ctc=14.610, loss=14.610, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.704e-04, train_time=0.609
[ALab02] 2023-06-10 05:26:05,062 (trainer:338) INFO: 38epoch results: [train] iter_time=8.039e-04, forward_time=0.229, loss_ctc=13.378, loss=13.378, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.752e-04, train_time=0.614, time=15 minutes and 54.25 seconds, total_count=59014, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.693, cer_ctc=0.289, cer=0.289, loss=13.693, time=6.77 seconds, total_count=608, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.55 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 05:26:07,328 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 05:26:07,342 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/33epoch.pth
[ALab02] 2023-06-10 05:26:07,342 (trainer:272) INFO: 39/70epoch started. Estimated time to finish: 14 hours, 31 minutes and 54.42 seconds
[ALab02] 2023-06-10 05:26:55,063 (trainer:721) INFO: 39epoch:train:1-77batch: iter_time=0.014, forward_time=0.223, loss_ctc=14.294, loss=14.294, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.699e-04, train_time=0.619
[ALab02] 2023-06-10 05:27:42,573 (trainer:721) INFO: 39epoch:train:78-154batch: iter_time=2.001e-04, forward_time=0.233, loss_ctc=13.174, loss=13.174, backward_time=0.300, optim_step_time=0.041, optim0_lr0=7.694e-04, train_time=0.617
[ALab02] 2023-06-10 05:28:29,793 (trainer:721) INFO: 39epoch:train:155-231batch: iter_time=1.483e-04, forward_time=0.228, loss_ctc=14.611, loss=14.611, backward_time=0.307, optim_step_time=0.036, optim0_lr0=7.689e-04, train_time=0.613
[ALab02] 2023-06-10 05:29:16,836 (trainer:721) INFO: 39epoch:train:232-308batch: iter_time=1.306e-04, forward_time=0.230, loss_ctc=12.763, loss=12.763, backward_time=0.304, optim_step_time=0.035, optim0_lr0=7.684e-04, train_time=0.611
[ALab02] 2023-06-10 05:30:05,790 (trainer:721) INFO: 39epoch:train:309-385batch: iter_time=1.731e-04, forward_time=0.243, loss_ctc=12.414, loss=12.414, backward_time=0.306, optim_step_time=0.039, optim0_lr0=7.679e-04, train_time=0.636
[ALab02] 2023-06-10 05:30:52,986 (trainer:721) INFO: 39epoch:train:386-462batch: iter_time=1.801e-04, forward_time=0.229, loss_ctc=14.613, loss=14.613, backward_time=0.304, optim_step_time=0.036, optim0_lr0=7.674e-04, train_time=0.613
[ALab02] 2023-06-10 05:31:40,802 (trainer:721) INFO: 39epoch:train:463-539batch: iter_time=1.712e-04, forward_time=0.232, loss_ctc=14.129, loss=14.129, backward_time=0.309, optim_step_time=0.037, optim0_lr0=7.669e-04, train_time=0.621
[ALab02] 2023-06-10 05:32:28,745 (trainer:721) INFO: 39epoch:train:540-616batch: iter_time=1.878e-04, forward_time=0.235, loss_ctc=12.936, loss=12.936, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.664e-04, train_time=0.622
[ALab02] 2023-06-10 05:33:15,805 (trainer:721) INFO: 39epoch:train:617-693batch: iter_time=1.570e-04, forward_time=0.227, loss_ctc=14.407, loss=14.407, backward_time=0.305, optim_step_time=0.037, optim0_lr0=7.659e-04, train_time=0.611
[ALab02] 2023-06-10 05:34:03,771 (trainer:721) INFO: 39epoch:train:694-770batch: iter_time=1.355e-04, forward_time=0.237, loss_ctc=11.963, loss=11.963, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.654e-04, train_time=0.623
[ALab02] 2023-06-10 05:34:50,895 (trainer:721) INFO: 39epoch:train:771-847batch: iter_time=1.501e-04, forward_time=0.228, loss_ctc=13.489, loss=13.489, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.649e-04, train_time=0.612
[ALab02] 2023-06-10 05:35:37,636 (trainer:721) INFO: 39epoch:train:848-924batch: iter_time=1.409e-04, forward_time=0.227, loss_ctc=12.876, loss=12.876, backward_time=0.301, optim_step_time=0.038, optim0_lr0=7.644e-04, train_time=0.607
[ALab02] 2023-06-10 05:36:25,175 (trainer:721) INFO: 39epoch:train:925-1001batch: iter_time=1.591e-04, forward_time=0.229, loss_ctc=13.591, loss=13.591, backward_time=0.309, optim_step_time=0.037, optim0_lr0=7.639e-04, train_time=0.617
[ALab02] 2023-06-10 05:37:12,971 (trainer:721) INFO: 39epoch:train:1002-1078batch: iter_time=1.314e-04, forward_time=0.234, loss_ctc=13.921, loss=13.921, backward_time=0.310, optim_step_time=0.036, optim0_lr0=7.634e-04, train_time=0.621
[ALab02] 2023-06-10 05:37:59,834 (trainer:721) INFO: 39epoch:train:1079-1155batch: iter_time=1.418e-04, forward_time=0.230, loss_ctc=12.811, loss=12.811, backward_time=0.300, optim_step_time=0.037, optim0_lr0=7.629e-04, train_time=0.608
[ALab02] 2023-06-10 05:38:47,171 (trainer:721) INFO: 39epoch:train:1156-1232batch: iter_time=1.507e-04, forward_time=0.230, loss_ctc=13.448, loss=13.448, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.624e-04, train_time=0.615
[ALab02] 2023-06-10 05:39:33,933 (trainer:721) INFO: 39epoch:train:1233-1309batch: iter_time=1.200e-04, forward_time=0.225, loss_ctc=15.160, loss=15.160, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.619e-04, train_time=0.607
[ALab02] 2023-06-10 05:40:21,025 (trainer:721) INFO: 39epoch:train:1310-1386batch: iter_time=1.735e-04, forward_time=0.230, loss_ctc=13.048, loss=13.048, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.615e-04, train_time=0.611
[ALab02] 2023-06-10 05:41:09,308 (trainer:721) INFO: 39epoch:train:1387-1463batch: iter_time=1.717e-04, forward_time=0.238, loss_ctc=11.807, loss=11.807, backward_time=0.310, optim_step_time=0.037, optim0_lr0=7.610e-04, train_time=0.627
[ALab02] 2023-06-10 05:41:55,284 (trainer:721) INFO: 39epoch:train:1464-1540batch: iter_time=1.486e-04, forward_time=0.223, loss_ctc=12.697, loss=12.697, backward_time=0.293, optim_step_time=0.038, optim0_lr0=7.605e-04, train_time=0.597
[ALab02] 2023-06-10 05:42:37,588 (trainer:338) INFO: 39epoch results: [train] iter_time=8.206e-04, forward_time=0.230, loss_ctc=13.359, loss=13.359, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.651e-04, train_time=0.615, time=15 minutes and 55.71 seconds, total_count=60567, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.563, cer_ctc=0.276, cer=0.276, loss=12.563, time=6.71 seconds, total_count=624, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.82 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 05:42:39,770 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 05:42:39,784 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/29epoch.pth
[ALab02] 2023-06-10 05:42:39,785 (trainer:272) INFO: 40/70epoch started. Estimated time to finish: 13 hours, 56 minutes and 8.98 seconds
[ALab02] 2023-06-10 05:43:30,120 (trainer:721) INFO: 40epoch:train:1-77batch: iter_time=0.015, forward_time=0.244, loss_ctc=12.419, loss=12.419, backward_time=0.309, optim_step_time=0.040, optim0_lr0=7.599e-04, train_time=0.653
[ALab02] 2023-06-10 05:44:17,630 (trainer:721) INFO: 40epoch:train:78-154batch: iter_time=2.077e-04, forward_time=0.230, loss_ctc=14.123, loss=14.123, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.594e-04, train_time=0.617
[ALab02] 2023-06-10 05:45:04,263 (trainer:721) INFO: 40epoch:train:155-231batch: iter_time=1.426e-04, forward_time=0.223, loss_ctc=15.978, loss=15.978, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.590e-04, train_time=0.605
[ALab02] 2023-06-10 05:45:50,898 (trainer:721) INFO: 40epoch:train:232-308batch: iter_time=1.493e-04, forward_time=0.227, loss_ctc=12.890, loss=12.890, backward_time=0.299, optim_step_time=0.037, optim0_lr0=7.585e-04, train_time=0.605
[ALab02] 2023-06-10 05:46:37,727 (trainer:721) INFO: 40epoch:train:309-385batch: iter_time=1.558e-04, forward_time=0.225, loss_ctc=13.241, loss=13.241, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.580e-04, train_time=0.608
[ALab02] 2023-06-10 05:47:24,729 (trainer:721) INFO: 40epoch:train:386-462batch: iter_time=1.673e-04, forward_time=0.227, loss_ctc=14.068, loss=14.068, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.575e-04, train_time=0.610
[ALab02] 2023-06-10 05:48:13,667 (trainer:721) INFO: 40epoch:train:463-539batch: iter_time=3.110e-04, forward_time=0.239, loss_ctc=12.175, loss=12.175, backward_time=0.309, optim_step_time=0.044, optim0_lr0=7.570e-04, train_time=0.635
[ALab02] 2023-06-10 05:49:00,359 (trainer:721) INFO: 40epoch:train:540-616batch: iter_time=1.691e-04, forward_time=0.225, loss_ctc=12.255, loss=12.255, backward_time=0.302, optim_step_time=0.036, optim0_lr0=7.566e-04, train_time=0.606
[ALab02] 2023-06-10 05:49:46,765 (trainer:721) INFO: 40epoch:train:617-693batch: iter_time=1.471e-04, forward_time=0.223, loss_ctc=14.328, loss=14.328, backward_time=0.300, optim_step_time=0.036, optim0_lr0=7.561e-04, train_time=0.602
[ALab02] 2023-06-10 05:50:34,343 (trainer:721) INFO: 40epoch:train:694-770batch: iter_time=1.542e-04, forward_time=0.233, loss_ctc=13.187, loss=13.187, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.556e-04, train_time=0.618
[ALab02] 2023-06-10 05:51:22,209 (trainer:721) INFO: 40epoch:train:771-847batch: iter_time=1.863e-04, forward_time=0.236, loss_ctc=13.195, loss=13.195, backward_time=0.304, optim_step_time=0.039, optim0_lr0=7.551e-04, train_time=0.621
[ALab02] 2023-06-10 05:52:09,553 (trainer:721) INFO: 40epoch:train:848-924batch: iter_time=1.603e-04, forward_time=0.229, loss_ctc=12.582, loss=12.582, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.547e-04, train_time=0.615
[ALab02] 2023-06-10 05:52:55,773 (trainer:721) INFO: 40epoch:train:925-1001batch: iter_time=1.833e-04, forward_time=0.224, loss_ctc=13.145, loss=13.145, backward_time=0.299, optim_step_time=0.037, optim0_lr0=7.542e-04, train_time=0.600
[ALab02] 2023-06-10 05:53:42,996 (trainer:721) INFO: 40epoch:train:1002-1078batch: iter_time=1.341e-04, forward_time=0.227, loss_ctc=15.651, loss=15.651, backward_time=0.305, optim_step_time=0.036, optim0_lr0=7.537e-04, train_time=0.613
[ALab02] 2023-06-10 05:54:29,893 (trainer:721) INFO: 40epoch:train:1079-1155batch: iter_time=1.502e-04, forward_time=0.227, loss_ctc=12.930, loss=12.930, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.533e-04, train_time=0.609
[ALab02] 2023-06-10 05:55:16,622 (trainer:721) INFO: 40epoch:train:1156-1232batch: iter_time=1.719e-04, forward_time=0.227, loss_ctc=12.545, loss=12.545, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.528e-04, train_time=0.607
[ALab02] 2023-06-10 05:56:05,126 (trainer:721) INFO: 40epoch:train:1233-1309batch: iter_time=1.381e-04, forward_time=0.236, loss_ctc=13.967, loss=13.967, backward_time=0.309, optim_step_time=0.037, optim0_lr0=7.523e-04, train_time=0.630
[ALab02] 2023-06-10 05:56:52,448 (trainer:721) INFO: 40epoch:train:1310-1386batch: iter_time=1.394e-04, forward_time=0.232, loss_ctc=10.518, loss=10.518, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.519e-04, train_time=0.614
[ALab02] 2023-06-10 05:57:39,215 (trainer:721) INFO: 40epoch:train:1387-1463batch: iter_time=1.535e-04, forward_time=0.226, loss_ctc=12.981, loss=12.981, backward_time=0.299, optim_step_time=0.038, optim0_lr0=7.514e-04, train_time=0.607
[ALab02] 2023-06-10 05:58:27,513 (trainer:721) INFO: 40epoch:train:1464-1540batch: iter_time=1.369e-04, forward_time=0.238, loss_ctc=11.809, loss=11.809, backward_time=0.309, optim_step_time=0.036, optim0_lr0=7.509e-04, train_time=0.627
[ALab02] 2023-06-10 05:59:09,448 (trainer:338) INFO: 40epoch results: [train] iter_time=9.024e-04, forward_time=0.230, loss_ctc=13.119, loss=13.119, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.554e-04, train_time=0.615, time=15 minutes and 55.77 seconds, total_count=62120, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.120, cer_ctc=0.277, cer=0.277, loss=13.120, time=6.73 seconds, total_count=640, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.17 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 05:59:11,618 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 05:59:11,632 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/28epoch.pth
[ALab02] 2023-06-10 05:59:11,632 (trainer:272) INFO: 41/70epoch started. Estimated time to finish: 13 hours, 21 minutes and 20.75 seconds
[ALab02] 2023-06-10 05:59:59,890 (trainer:721) INFO: 41epoch:train:1-77batch: iter_time=0.014, forward_time=0.230, loss_ctc=12.675, loss=12.675, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.504e-04, train_time=0.626
[ALab02] 2023-06-10 06:00:46,016 (trainer:721) INFO: 41epoch:train:78-154batch: iter_time=1.497e-04, forward_time=0.222, loss_ctc=12.243, loss=12.243, backward_time=0.296, optim_step_time=0.038, optim0_lr0=7.499e-04, train_time=0.599
[ALab02] 2023-06-10 06:01:33,108 (trainer:721) INFO: 41epoch:train:155-231batch: iter_time=1.674e-04, forward_time=0.228, loss_ctc=11.539, loss=11.539, backward_time=0.302, optim_step_time=0.036, optim0_lr0=7.494e-04, train_time=0.611
[ALab02] 2023-06-10 06:02:19,797 (trainer:721) INFO: 41epoch:train:232-308batch: iter_time=1.518e-04, forward_time=0.226, loss_ctc=13.135, loss=13.135, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.490e-04, train_time=0.606
[ALab02] 2023-06-10 06:03:07,094 (trainer:721) INFO: 41epoch:train:309-385batch: iter_time=1.538e-04, forward_time=0.227, loss_ctc=14.487, loss=14.487, backward_time=0.308, optim_step_time=0.039, optim0_lr0=7.485e-04, train_time=0.614
[ALab02] 2023-06-10 06:03:53,609 (trainer:721) INFO: 41epoch:train:386-462batch: iter_time=1.334e-04, forward_time=0.224, loss_ctc=12.384, loss=12.384, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.481e-04, train_time=0.604
[ALab02] 2023-06-10 06:04:40,489 (trainer:721) INFO: 41epoch:train:463-539batch: iter_time=1.811e-04, forward_time=0.228, loss_ctc=12.249, loss=12.249, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.476e-04, train_time=0.609
[ALab02] 2023-06-10 06:05:27,382 (trainer:721) INFO: 41epoch:train:540-616batch: iter_time=1.531e-04, forward_time=0.224, loss_ctc=13.658, loss=13.658, backward_time=0.305, optim_step_time=0.036, optim0_lr0=7.471e-04, train_time=0.609
[ALab02] 2023-06-10 06:06:15,533 (trainer:721) INFO: 41epoch:train:617-693batch: iter_time=2.369e-04, forward_time=0.235, loss_ctc=13.151, loss=13.151, backward_time=0.305, optim_step_time=0.040, optim0_lr0=7.467e-04, train_time=0.625
[ALab02] 2023-06-10 06:07:02,457 (trainer:721) INFO: 41epoch:train:694-770batch: iter_time=1.614e-04, forward_time=0.228, loss_ctc=11.982, loss=11.982, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.462e-04, train_time=0.609
[ALab02] 2023-06-10 06:07:50,401 (trainer:721) INFO: 41epoch:train:771-847batch: iter_time=2.134e-04, forward_time=0.232, loss_ctc=13.910, loss=13.910, backward_time=0.307, optim_step_time=0.041, optim0_lr0=7.458e-04, train_time=0.622
[ALab02] 2023-06-10 06:08:37,684 (trainer:721) INFO: 41epoch:train:848-924batch: iter_time=1.438e-04, forward_time=0.228, loss_ctc=13.624, loss=13.624, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.453e-04, train_time=0.614
[ALab02] 2023-06-10 06:09:26,089 (trainer:721) INFO: 41epoch:train:925-1001batch: iter_time=2.037e-04, forward_time=0.236, loss_ctc=12.026, loss=12.026, backward_time=0.308, optim_step_time=0.040, optim0_lr0=7.449e-04, train_time=0.628
[ALab02] 2023-06-10 06:10:14,082 (trainer:721) INFO: 41epoch:train:1002-1078batch: iter_time=1.298e-04, forward_time=0.239, loss_ctc=11.233, loss=11.233, backward_time=0.305, optim_step_time=0.036, optim0_lr0=7.444e-04, train_time=0.623
[ALab02] 2023-06-10 06:11:01,226 (trainer:721) INFO: 41epoch:train:1079-1155batch: iter_time=1.348e-04, forward_time=0.226, loss_ctc=14.177, loss=14.177, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.440e-04, train_time=0.612
[ALab02] 2023-06-10 06:11:49,696 (trainer:721) INFO: 41epoch:train:1156-1232batch: iter_time=3.756e-04, forward_time=0.237, loss_ctc=13.837, loss=13.837, backward_time=0.307, optim_step_time=0.041, optim0_lr0=7.435e-04, train_time=0.629
[ALab02] 2023-06-10 06:12:38,092 (trainer:721) INFO: 41epoch:train:1233-1309batch: iter_time=1.504e-04, forward_time=0.237, loss_ctc=12.295, loss=12.295, backward_time=0.305, optim_step_time=0.039, optim0_lr0=7.430e-04, train_time=0.628
[ALab02] 2023-06-10 06:13:25,484 (trainer:721) INFO: 41epoch:train:1310-1386batch: iter_time=1.459e-04, forward_time=0.231, loss_ctc=13.962, loss=13.962, backward_time=0.306, optim_step_time=0.038, optim0_lr0=7.426e-04, train_time=0.615
[ALab02] 2023-06-10 06:14:13,383 (trainer:721) INFO: 41epoch:train:1387-1463batch: iter_time=1.681e-04, forward_time=0.234, loss_ctc=12.421, loss=12.421, backward_time=0.303, optim_step_time=0.039, optim0_lr0=7.421e-04, train_time=0.622
[ALab02] 2023-06-10 06:15:01,055 (trainer:721) INFO: 41epoch:train:1464-1540batch: iter_time=1.616e-04, forward_time=0.233, loss_ctc=12.387, loss=12.387, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.417e-04, train_time=0.619
[ALab02] 2023-06-10 06:15:43,289 (trainer:338) INFO: 41epoch results: [train] iter_time=8.530e-04, forward_time=0.230, loss_ctc=12.841, loss=12.841, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.460e-04, train_time=0.616, time=15 minutes and 57.66 seconds, total_count=63673, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.963, cer_ctc=0.287, cer=0.287, loss=12.963, time=6.72 seconds, total_count=656, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.28 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 06:15:45,586 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 06:15:45,601 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/31epoch.pth
[ALab02] 2023-06-10 06:15:45,601 (trainer:272) INFO: 42/70epoch started. Estimated time to finish: 12 hours, 47 minutes and 27.49 seconds
[ALab02] 2023-06-10 06:16:33,470 (trainer:721) INFO: 42epoch:train:1-77batch: iter_time=0.014, forward_time=0.226, loss_ctc=13.656, loss=13.656, backward_time=0.300, optim_step_time=0.037, optim0_lr0=7.412e-04, train_time=0.621
[ALab02] 2023-06-10 06:17:20,486 (trainer:721) INFO: 42epoch:train:78-154batch: iter_time=1.441e-04, forward_time=0.231, loss_ctc=12.831, loss=12.831, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.407e-04, train_time=0.610
[ALab02] 2023-06-10 06:18:07,890 (trainer:721) INFO: 42epoch:train:155-231batch: iter_time=1.617e-04, forward_time=0.230, loss_ctc=13.257, loss=13.257, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.403e-04, train_time=0.615
[ALab02] 2023-06-10 06:18:54,390 (trainer:721) INFO: 42epoch:train:232-308batch: iter_time=1.387e-04, forward_time=0.225, loss_ctc=11.837, loss=11.837, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.398e-04, train_time=0.604
[ALab02] 2023-06-10 06:19:42,327 (trainer:721) INFO: 42epoch:train:309-385batch: iter_time=1.782e-04, forward_time=0.236, loss_ctc=10.744, loss=10.744, backward_time=0.307, optim_step_time=0.039, optim0_lr0=7.394e-04, train_time=0.622
[ALab02] 2023-06-10 06:20:30,148 (trainer:721) INFO: 42epoch:train:386-462batch: iter_time=1.832e-04, forward_time=0.232, loss_ctc=12.141, loss=12.141, backward_time=0.307, optim_step_time=0.039, optim0_lr0=7.389e-04, train_time=0.621
[ALab02] 2023-06-10 06:21:17,329 (trainer:721) INFO: 42epoch:train:463-539batch: iter_time=1.545e-04, forward_time=0.228, loss_ctc=13.057, loss=13.057, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.385e-04, train_time=0.613
[ALab02] 2023-06-10 06:22:04,668 (trainer:721) INFO: 42epoch:train:540-616batch: iter_time=1.515e-04, forward_time=0.233, loss_ctc=11.732, loss=11.732, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.381e-04, train_time=0.615
[ALab02] 2023-06-10 06:22:52,678 (trainer:721) INFO: 42epoch:train:617-693batch: iter_time=1.766e-04, forward_time=0.234, loss_ctc=12.862, loss=12.862, backward_time=0.310, optim_step_time=0.037, optim0_lr0=7.376e-04, train_time=0.623
[ALab02] 2023-06-10 06:23:39,608 (trainer:721) INFO: 42epoch:train:694-770batch: iter_time=1.404e-04, forward_time=0.227, loss_ctc=15.685, loss=15.685, backward_time=0.299, optim_step_time=0.035, optim0_lr0=7.372e-04, train_time=0.609
[ALab02] 2023-06-10 06:24:27,474 (trainer:721) INFO: 42epoch:train:771-847batch: iter_time=4.339e-04, forward_time=0.234, loss_ctc=14.170, loss=14.170, backward_time=0.302, optim_step_time=0.040, optim0_lr0=7.367e-04, train_time=0.621
[ALab02] 2023-06-10 06:25:15,539 (trainer:721) INFO: 42epoch:train:848-924batch: iter_time=1.164e-04, forward_time=0.234, loss_ctc=12.567, loss=12.567, backward_time=0.307, optim_step_time=0.039, optim0_lr0=7.363e-04, train_time=0.624
[ALab02] 2023-06-10 06:26:02,417 (trainer:721) INFO: 42epoch:train:925-1001batch: iter_time=1.526e-04, forward_time=0.228, loss_ctc=13.924, loss=13.924, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.359e-04, train_time=0.609
[ALab02] 2023-06-10 06:26:50,036 (trainer:721) INFO: 42epoch:train:1002-1078batch: iter_time=1.473e-04, forward_time=0.231, loss_ctc=14.147, loss=14.147, backward_time=0.310, optim_step_time=0.038, optim0_lr0=7.354e-04, train_time=0.618
[ALab02] 2023-06-10 06:27:37,559 (trainer:721) INFO: 42epoch:train:1079-1155batch: iter_time=1.447e-04, forward_time=0.230, loss_ctc=11.994, loss=11.994, backward_time=0.308, optim_step_time=0.036, optim0_lr0=7.350e-04, train_time=0.617
[ALab02] 2023-06-10 06:28:24,520 (trainer:721) INFO: 42epoch:train:1156-1232batch: iter_time=1.269e-04, forward_time=0.226, loss_ctc=12.851, loss=12.851, backward_time=0.304, optim_step_time=0.036, optim0_lr0=7.345e-04, train_time=0.610
[ALab02] 2023-06-10 06:29:11,793 (trainer:721) INFO: 42epoch:train:1233-1309batch: iter_time=1.708e-04, forward_time=0.231, loss_ctc=11.187, loss=11.187, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.341e-04, train_time=0.614
[ALab02] 2023-06-10 06:29:59,885 (trainer:721) INFO: 42epoch:train:1310-1386batch: iter_time=1.530e-04, forward_time=0.236, loss_ctc=10.877, loss=10.877, backward_time=0.306, optim_step_time=0.039, optim0_lr0=7.337e-04, train_time=0.624
[ALab02] 2023-06-10 06:30:45,295 (trainer:721) INFO: 42epoch:train:1387-1463batch: iter_time=1.445e-04, forward_time=0.218, loss_ctc=14.618, loss=14.618, backward_time=0.297, optim_step_time=0.036, optim0_lr0=7.332e-04, train_time=0.590
[ALab02] 2023-06-10 06:31:32,493 (trainer:721) INFO: 42epoch:train:1464-1540batch: iter_time=1.119e-04, forward_time=0.229, loss_ctc=11.782, loss=11.782, backward_time=0.304, optim_step_time=0.036, optim0_lr0=7.328e-04, train_time=0.613
[ALab02] 2023-06-10 06:32:16,677 (trainer:338) INFO: 42epoch results: [train] iter_time=8.278e-04, forward_time=0.230, loss_ctc=12.684, loss=12.684, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.369e-04, train_time=0.615, time=15 minutes and 55.17 seconds, total_count=65226, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.250, cer_ctc=0.285, cer=0.285, loss=13.250, time=6.64 seconds, total_count=672, gpu_max_cached_mem_GB=77.078, [att_plot] time=29.26 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 06:32:19,247 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 06:32:19,262 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/38epoch.pth
[ALab02] 2023-06-10 06:32:19,262 (trainer:272) INFO: 43/70epoch started. Estimated time to finish: 12 hours, 14 minutes and 23.53 seconds
[ALab02] 2023-06-10 06:33:07,984 (trainer:721) INFO: 43epoch:train:1-77batch: iter_time=0.014, forward_time=0.229, loss_ctc=11.661, loss=11.661, backward_time=0.306, optim_step_time=0.038, optim0_lr0=7.323e-04, train_time=0.632
[ALab02] 2023-06-10 06:33:55,772 (trainer:721) INFO: 43epoch:train:78-154batch: iter_time=2.811e-04, forward_time=0.236, loss_ctc=12.571, loss=12.571, backward_time=0.301, optim_step_time=0.041, optim0_lr0=7.319e-04, train_time=0.621
[ALab02] 2023-06-10 06:34:42,494 (trainer:721) INFO: 43epoch:train:155-231batch: iter_time=1.652e-04, forward_time=0.225, loss_ctc=13.438, loss=13.438, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.314e-04, train_time=0.607
[ALab02] 2023-06-10 06:35:31,432 (trainer:721) INFO: 43epoch:train:232-308batch: iter_time=1.777e-04, forward_time=0.244, loss_ctc=9.885, loss=9.885, backward_time=0.310, optim_step_time=0.036, optim0_lr0=7.310e-04, train_time=0.635
[ALab02] 2023-06-10 06:36:18,257 (trainer:721) INFO: 43epoch:train:309-385batch: iter_time=1.780e-04, forward_time=0.227, loss_ctc=13.453, loss=13.453, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.306e-04, train_time=0.608
[ALab02] 2023-06-10 06:37:06,171 (trainer:721) INFO: 43epoch:train:386-462batch: iter_time=1.639e-04, forward_time=0.238, loss_ctc=12.239, loss=12.239, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.302e-04, train_time=0.622
[ALab02] 2023-06-10 06:37:52,411 (trainer:721) INFO: 43epoch:train:463-539batch: iter_time=1.422e-04, forward_time=0.223, loss_ctc=11.421, loss=11.421, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.297e-04, train_time=0.600
[ALab02] 2023-06-10 06:38:39,594 (trainer:721) INFO: 43epoch:train:540-616batch: iter_time=1.656e-04, forward_time=0.226, loss_ctc=13.399, loss=13.399, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.293e-04, train_time=0.613
[ALab02] 2023-06-10 06:39:27,116 (trainer:721) INFO: 43epoch:train:617-693batch: iter_time=1.609e-04, forward_time=0.230, loss_ctc=13.431, loss=13.431, backward_time=0.306, optim_step_time=0.038, optim0_lr0=7.289e-04, train_time=0.617
[ALab02] 2023-06-10 06:40:13,610 (trainer:721) INFO: 43epoch:train:694-770batch: iter_time=1.761e-04, forward_time=0.224, loss_ctc=13.321, loss=13.321, backward_time=0.299, optim_step_time=0.039, optim0_lr0=7.284e-04, train_time=0.604
[ALab02] 2023-06-10 06:40:59,944 (trainer:721) INFO: 43epoch:train:771-847batch: iter_time=1.363e-04, forward_time=0.223, loss_ctc=14.427, loss=14.427, backward_time=0.301, optim_step_time=0.036, optim0_lr0=7.280e-04, train_time=0.602
[ALab02] 2023-06-10 06:41:46,783 (trainer:721) INFO: 43epoch:train:848-924batch: iter_time=1.106e-04, forward_time=0.228, loss_ctc=13.086, loss=13.086, backward_time=0.303, optim_step_time=0.035, optim0_lr0=7.276e-04, train_time=0.608
[ALab02] 2023-06-10 06:42:34,338 (trainer:721) INFO: 43epoch:train:925-1001batch: iter_time=1.632e-04, forward_time=0.235, loss_ctc=10.905, loss=10.905, backward_time=0.301, optim_step_time=0.039, optim0_lr0=7.272e-04, train_time=0.617
[ALab02] 2023-06-10 06:43:22,197 (trainer:721) INFO: 43epoch:train:1002-1078batch: iter_time=1.842e-04, forward_time=0.234, loss_ctc=12.111, loss=12.111, backward_time=0.306, optim_step_time=0.036, optim0_lr0=7.268e-04, train_time=0.621
[ALab02] 2023-06-10 06:44:10,111 (trainer:721) INFO: 43epoch:train:1079-1155batch: iter_time=1.356e-04, forward_time=0.235, loss_ctc=13.270, loss=13.270, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.263e-04, train_time=0.622
[ALab02] 2023-06-10 06:44:57,234 (trainer:721) INFO: 43epoch:train:1156-1232batch: iter_time=1.374e-04, forward_time=0.229, loss_ctc=13.450, loss=13.450, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.259e-04, train_time=0.612
[ALab02] 2023-06-10 06:45:45,433 (trainer:721) INFO: 43epoch:train:1233-1309batch: iter_time=1.720e-04, forward_time=0.236, loss_ctc=11.500, loss=11.500, backward_time=0.309, optim_step_time=0.038, optim0_lr0=7.255e-04, train_time=0.626
[ALab02] 2023-06-10 06:46:32,532 (trainer:721) INFO: 43epoch:train:1310-1386batch: iter_time=1.594e-04, forward_time=0.228, loss_ctc=12.287, loss=12.287, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.251e-04, train_time=0.611
[ALab02] 2023-06-10 06:47:20,453 (trainer:721) INFO: 43epoch:train:1387-1463batch: iter_time=1.502e-04, forward_time=0.237, loss_ctc=12.376, loss=12.376, backward_time=0.307, optim_step_time=0.036, optim0_lr0=7.246e-04, train_time=0.622
[ALab02] 2023-06-10 06:48:07,153 (trainer:721) INFO: 43epoch:train:1464-1540batch: iter_time=1.436e-04, forward_time=0.225, loss_ctc=13.643, loss=13.643, backward_time=0.301, optim_step_time=0.038, optim0_lr0=7.242e-04, train_time=0.606
[ALab02] 2023-06-10 06:48:49,039 (trainer:338) INFO: 43epoch results: [train] iter_time=8.685e-04, forward_time=0.231, loss_ctc=12.538, loss=12.538, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.282e-04, train_time=0.615, time=15 minutes and 56.33 seconds, total_count=66779, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.241, cer_ctc=0.286, cer=0.286, loss=13.241, time=6.63 seconds, total_count=688, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.82 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 06:48:51,375 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 06:48:51,389 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/30epoch.pth
[ALab02] 2023-06-10 06:48:51,389 (trainer:272) INFO: 44/70epoch started. Estimated time to finish: 11 hours, 42 minutes and 4.66 seconds
[ALab02] 2023-06-10 06:49:40,274 (trainer:721) INFO: 44epoch:train:1-77batch: iter_time=0.015, forward_time=0.230, loss_ctc=13.327, loss=13.327, backward_time=0.305, optim_step_time=0.037, optim0_lr0=7.237e-04, train_time=0.635
[ALab02] 2023-06-10 06:50:27,353 (trainer:721) INFO: 44epoch:train:78-154batch: iter_time=1.628e-04, forward_time=0.228, loss_ctc=12.222, loss=12.222, backward_time=0.302, optim_step_time=0.038, optim0_lr0=7.233e-04, train_time=0.611
[ALab02] 2023-06-10 06:51:13,167 (trainer:721) INFO: 44epoch:train:155-231batch: iter_time=1.550e-04, forward_time=0.219, loss_ctc=13.774, loss=13.774, backward_time=0.297, optim_step_time=0.038, optim0_lr0=7.229e-04, train_time=0.595
[ALab02] 2023-06-10 06:52:01,041 (trainer:721) INFO: 44epoch:train:232-308batch: iter_time=1.627e-04, forward_time=0.231, loss_ctc=11.823, loss=11.823, backward_time=0.309, optim_step_time=0.038, optim0_lr0=7.225e-04, train_time=0.622
[ALab02] 2023-06-10 06:52:47,413 (trainer:721) INFO: 44epoch:train:309-385batch: iter_time=1.508e-04, forward_time=0.223, loss_ctc=12.175, loss=12.175, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.221e-04, train_time=0.602
[ALab02] 2023-06-10 06:53:34,033 (trainer:721) INFO: 44epoch:train:386-462batch: iter_time=1.600e-04, forward_time=0.226, loss_ctc=13.147, loss=13.147, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.217e-04, train_time=0.605
[ALab02] 2023-06-10 06:54:21,210 (trainer:721) INFO: 44epoch:train:463-539batch: iter_time=1.554e-04, forward_time=0.231, loss_ctc=10.477, loss=10.477, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.213e-04, train_time=0.612
[ALab02] 2023-06-10 06:55:08,285 (trainer:721) INFO: 44epoch:train:540-616batch: iter_time=1.738e-04, forward_time=0.228, loss_ctc=11.612, loss=11.612, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.208e-04, train_time=0.611
[ALab02] 2023-06-10 06:56:00,555 (trainer:721) INFO: 44epoch:train:617-693batch: iter_time=4.412e-04, forward_time=0.270, loss_ctc=10.738, loss=10.738, backward_time=0.306, optim_step_time=0.050, optim0_lr0=7.204e-04, train_time=0.678
[ALab02] 2023-06-10 06:57:02,956 (trainer:721) INFO: 44epoch:train:694-770batch: iter_time=0.001, forward_time=0.342, loss_ctc=11.006, loss=11.006, backward_time=0.320, optim_step_time=0.079, optim0_lr0=7.200e-04, train_time=0.810
[ALab02] 2023-06-10 06:57:50,366 (trainer:721) INFO: 44epoch:train:771-847batch: iter_time=1.614e-04, forward_time=0.232, loss_ctc=11.155, loss=11.155, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.196e-04, train_time=0.615
[ALab02] 2023-06-10 06:58:38,224 (trainer:721) INFO: 44epoch:train:848-924batch: iter_time=1.592e-04, forward_time=0.232, loss_ctc=12.485, loss=12.485, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.192e-04, train_time=0.621
[ALab02] 2023-06-10 06:59:24,973 (trainer:721) INFO: 44epoch:train:925-1001batch: iter_time=1.412e-04, forward_time=0.225, loss_ctc=13.770, loss=13.770, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.188e-04, train_time=0.607
[ALab02] 2023-06-10 07:00:12,228 (trainer:721) INFO: 44epoch:train:1002-1078batch: iter_time=1.146e-04, forward_time=0.229, loss_ctc=13.401, loss=13.401, backward_time=0.306, optim_step_time=0.036, optim0_lr0=7.184e-04, train_time=0.613
[ALab02] 2023-06-10 07:01:01,656 (trainer:721) INFO: 44epoch:train:1079-1155batch: iter_time=2.839e-04, forward_time=0.246, loss_ctc=11.667, loss=11.667, backward_time=0.308, optim_step_time=0.040, optim0_lr0=7.180e-04, train_time=0.642
[ALab02] 2023-06-10 07:01:48,713 (trainer:721) INFO: 44epoch:train:1156-1232batch: iter_time=1.475e-04, forward_time=0.228, loss_ctc=12.168, loss=12.168, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.176e-04, train_time=0.611
[ALab02] 2023-06-10 07:02:35,609 (trainer:721) INFO: 44epoch:train:1233-1309batch: iter_time=1.483e-04, forward_time=0.228, loss_ctc=12.903, loss=12.903, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.172e-04, train_time=0.609
[ALab02] 2023-06-10 07:03:22,554 (trainer:721) INFO: 44epoch:train:1310-1386batch: iter_time=1.522e-04, forward_time=0.228, loss_ctc=13.970, loss=13.970, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.168e-04, train_time=0.609
[ALab02] 2023-06-10 07:04:10,542 (trainer:721) INFO: 44epoch:train:1387-1463batch: iter_time=1.584e-04, forward_time=0.233, loss_ctc=11.700, loss=11.700, backward_time=0.308, optim_step_time=0.038, optim0_lr0=7.164e-04, train_time=0.623
[ALab02] 2023-06-10 07:04:58,443 (trainer:721) INFO: 44epoch:train:1464-1540batch: iter_time=1.264e-04, forward_time=0.234, loss_ctc=13.414, loss=13.414, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.159e-04, train_time=0.622
[ALab02] 2023-06-10 07:05:40,354 (trainer:338) INFO: 44epoch results: [train] iter_time=9.540e-04, forward_time=0.237, loss_ctc=12.296, loss=12.296, backward_time=0.305, optim_step_time=0.040, optim0_lr0=7.198e-04, train_time=0.628, time=16 minutes and 15.19 seconds, total_count=68332, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.703, cer_ctc=0.273, cer=0.273, loss=12.703, time=6.78 seconds, total_count=704, gpu_max_cached_mem_GB=77.078, [att_plot] time=27 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 07:05:42,532 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 07:05:42,545 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/41epoch.pth
[ALab02] 2023-06-10 07:05:42,546 (trainer:272) INFO: 45/70epoch started. Estimated time to finish: 11 hours, 10 minutes and 40.07 seconds
[ALab02] 2023-06-10 07:06:32,117 (trainer:721) INFO: 45epoch:train:1-77batch: iter_time=0.015, forward_time=0.237, loss_ctc=12.147, loss=12.147, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.155e-04, train_time=0.643
[ALab02] 2023-06-10 07:07:19,165 (trainer:721) INFO: 45epoch:train:78-154batch: iter_time=1.971e-04, forward_time=0.231, loss_ctc=12.179, loss=12.179, backward_time=0.301, optim_step_time=0.037, optim0_lr0=7.151e-04, train_time=0.611
[ALab02] 2023-06-10 07:08:06,366 (trainer:721) INFO: 45epoch:train:155-231batch: iter_time=1.307e-04, forward_time=0.229, loss_ctc=11.133, loss=11.133, backward_time=0.303, optim_step_time=0.037, optim0_lr0=7.147e-04, train_time=0.613
[ALab02] 2023-06-10 07:08:54,321 (trainer:721) INFO: 45epoch:train:232-308batch: iter_time=1.610e-04, forward_time=0.232, loss_ctc=12.241, loss=12.241, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.143e-04, train_time=0.623
[ALab02] 2023-06-10 07:09:41,146 (trainer:721) INFO: 45epoch:train:309-385batch: iter_time=1.790e-04, forward_time=0.228, loss_ctc=12.221, loss=12.221, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.139e-04, train_time=0.608
[ALab02] 2023-06-10 07:10:29,625 (trainer:721) INFO: 45epoch:train:386-462batch: iter_time=1.674e-04, forward_time=0.240, loss_ctc=10.697, loss=10.697, backward_time=0.308, optim_step_time=0.040, optim0_lr0=7.135e-04, train_time=0.629
[ALab02] 2023-06-10 07:11:17,044 (trainer:721) INFO: 45epoch:train:463-539batch: iter_time=1.870e-04, forward_time=0.230, loss_ctc=13.078, loss=13.078, backward_time=0.303, optim_step_time=0.039, optim0_lr0=7.131e-04, train_time=0.616
[ALab02] 2023-06-10 07:12:04,754 (trainer:721) INFO: 45epoch:train:540-616batch: iter_time=1.539e-04, forward_time=0.231, loss_ctc=12.090, loss=12.090, backward_time=0.307, optim_step_time=0.038, optim0_lr0=7.127e-04, train_time=0.619
[ALab02] 2023-06-10 07:12:52,944 (trainer:721) INFO: 45epoch:train:617-693batch: iter_time=1.346e-04, forward_time=0.235, loss_ctc=13.088, loss=13.088, backward_time=0.309, optim_step_time=0.037, optim0_lr0=7.123e-04, train_time=0.626
[ALab02] 2023-06-10 07:13:40,136 (trainer:721) INFO: 45epoch:train:694-770batch: iter_time=1.763e-04, forward_time=0.229, loss_ctc=12.509, loss=12.509, backward_time=0.300, optim_step_time=0.038, optim0_lr0=7.119e-04, train_time=0.613
[ALab02] 2023-06-10 07:14:27,666 (trainer:721) INFO: 45epoch:train:771-847batch: iter_time=1.270e-04, forward_time=0.231, loss_ctc=12.900, loss=12.900, backward_time=0.304, optim_step_time=0.036, optim0_lr0=7.115e-04, train_time=0.617
[ALab02] 2023-06-10 07:15:14,792 (trainer:721) INFO: 45epoch:train:848-924batch: iter_time=1.825e-04, forward_time=0.232, loss_ctc=11.621, loss=11.621, backward_time=0.300, optim_step_time=0.038, optim0_lr0=7.111e-04, train_time=0.612
[ALab02] 2023-06-10 07:16:02,799 (trainer:721) INFO: 45epoch:train:925-1001batch: iter_time=1.604e-04, forward_time=0.234, loss_ctc=13.010, loss=13.010, backward_time=0.309, optim_step_time=0.038, optim0_lr0=7.107e-04, train_time=0.623
[ALab02] 2023-06-10 07:16:49,781 (trainer:721) INFO: 45epoch:train:1002-1078batch: iter_time=1.615e-04, forward_time=0.227, loss_ctc=12.574, loss=12.574, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.103e-04, train_time=0.610
[ALab02] 2023-06-10 07:17:36,640 (trainer:721) INFO: 45epoch:train:1079-1155batch: iter_time=1.499e-04, forward_time=0.227, loss_ctc=13.322, loss=13.322, backward_time=0.303, optim_step_time=0.038, optim0_lr0=7.099e-04, train_time=0.608
[ALab02] 2023-06-10 07:18:23,148 (trainer:721) INFO: 45epoch:train:1156-1232batch: iter_time=1.236e-04, forward_time=0.224, loss_ctc=12.976, loss=12.976, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.095e-04, train_time=0.604
[ALab02] 2023-06-10 07:19:11,080 (trainer:721) INFO: 45epoch:train:1233-1309batch: iter_time=1.652e-04, forward_time=0.237, loss_ctc=10.509, loss=10.509, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.091e-04, train_time=0.622
[ALab02] 2023-06-10 07:19:57,932 (trainer:721) INFO: 45epoch:train:1310-1386batch: iter_time=1.570e-04, forward_time=0.230, loss_ctc=10.227, loss=10.227, backward_time=0.301, optim_step_time=0.036, optim0_lr0=7.087e-04, train_time=0.608
[ALab02] 2023-06-10 07:20:44,723 (trainer:721) INFO: 45epoch:train:1387-1463batch: iter_time=1.653e-04, forward_time=0.227, loss_ctc=11.152, loss=11.152, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.083e-04, train_time=0.607
[ALab02] 2023-06-10 07:21:34,444 (trainer:721) INFO: 45epoch:train:1464-1540batch: iter_time=5.428e-04, forward_time=0.246, loss_ctc=12.884, loss=12.884, backward_time=0.309, optim_step_time=0.045, optim0_lr0=7.079e-04, train_time=0.645
[ALab02] 2023-06-10 07:22:16,525 (trainer:338) INFO: 45epoch results: [train] iter_time=9.092e-04, forward_time=0.232, loss_ctc=12.091, loss=12.091, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.117e-04, train_time=0.618, time=15 minutes and 59.86 seconds, total_count=69885, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.009, cer_ctc=0.280, cer=0.280, loss=13.009, time=6.69 seconds, total_count=720, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.43 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 07:22:18,828 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 07:22:18,842 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/43epoch.pth
[ALab02] 2023-06-10 07:22:18,842 (trainer:272) INFO: 46/70epoch started. Estimated time to finish: 10 hours, 39 minutes and 46.04 seconds
[ALab02] 2023-06-10 07:23:08,227 (trainer:721) INFO: 46epoch:train:1-77batch: iter_time=0.014, forward_time=0.237, loss_ctc=11.223, loss=11.223, backward_time=0.308, optim_step_time=0.037, optim0_lr0=7.075e-04, train_time=0.641
[ALab02] 2023-06-10 07:23:55,287 (trainer:721) INFO: 46epoch:train:78-154batch: iter_time=1.406e-04, forward_time=0.228, loss_ctc=10.667, loss=10.667, backward_time=0.303, optim_step_time=0.036, optim0_lr0=7.071e-04, train_time=0.611
[ALab02] 2023-06-10 07:24:42,472 (trainer:721) INFO: 46epoch:train:155-231batch: iter_time=1.317e-04, forward_time=0.231, loss_ctc=11.086, loss=11.086, backward_time=0.304, optim_step_time=0.038, optim0_lr0=7.067e-04, train_time=0.613
[ALab02] 2023-06-10 07:25:29,855 (trainer:721) INFO: 46epoch:train:232-308batch: iter_time=1.331e-04, forward_time=0.229, loss_ctc=13.663, loss=13.663, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.063e-04, train_time=0.615
[ALab02] 2023-06-10 07:26:18,138 (trainer:721) INFO: 46epoch:train:309-385batch: iter_time=1.391e-04, forward_time=0.236, loss_ctc=10.356, loss=10.356, backward_time=0.308, optim_step_time=0.037, optim0_lr0=7.059e-04, train_time=0.627
[ALab02] 2023-06-10 07:27:04,585 (trainer:721) INFO: 46epoch:train:386-462batch: iter_time=1.322e-04, forward_time=0.223, loss_ctc=13.384, loss=13.384, backward_time=0.300, optim_step_time=0.037, optim0_lr0=7.055e-04, train_time=0.603
[ALab02] 2023-06-10 07:27:52,055 (trainer:721) INFO: 46epoch:train:463-539batch: iter_time=1.428e-04, forward_time=0.228, loss_ctc=12.879, loss=12.879, backward_time=0.306, optim_step_time=0.037, optim0_lr0=7.052e-04, train_time=0.616
[ALab02] 2023-06-10 07:28:39,285 (trainer:721) INFO: 46epoch:train:540-616batch: iter_time=1.921e-04, forward_time=0.229, loss_ctc=13.188, loss=13.188, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.048e-04, train_time=0.613
[ALab02] 2023-06-10 07:29:25,505 (trainer:721) INFO: 46epoch:train:617-693batch: iter_time=1.585e-04, forward_time=0.224, loss_ctc=13.603, loss=13.603, backward_time=0.301, optim_step_time=0.036, optim0_lr0=7.044e-04, train_time=0.600
[ALab02] 2023-06-10 07:30:13,135 (trainer:721) INFO: 46epoch:train:694-770batch: iter_time=1.540e-04, forward_time=0.233, loss_ctc=10.865, loss=10.865, backward_time=0.307, optim_step_time=0.037, optim0_lr0=7.040e-04, train_time=0.618
[ALab02] 2023-06-10 07:31:00,321 (trainer:721) INFO: 46epoch:train:771-847batch: iter_time=1.377e-04, forward_time=0.231, loss_ctc=12.366, loss=12.366, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.036e-04, train_time=0.613
[ALab02] 2023-06-10 07:31:48,944 (trainer:721) INFO: 46epoch:train:848-924batch: iter_time=1.637e-04, forward_time=0.237, loss_ctc=11.942, loss=11.942, backward_time=0.310, optim_step_time=0.039, optim0_lr0=7.032e-04, train_time=0.631
[ALab02] 2023-06-10 07:32:35,710 (trainer:721) INFO: 46epoch:train:925-1001batch: iter_time=1.153e-04, forward_time=0.228, loss_ctc=10.326, loss=10.326, backward_time=0.302, optim_step_time=0.037, optim0_lr0=7.029e-04, train_time=0.607
[ALab02] 2023-06-10 07:33:23,007 (trainer:721) INFO: 46epoch:train:1002-1078batch: iter_time=1.405e-04, forward_time=0.228, loss_ctc=12.217, loss=12.217, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.025e-04, train_time=0.614
[ALab02] 2023-06-10 07:34:10,684 (trainer:721) INFO: 46epoch:train:1079-1155batch: iter_time=1.301e-04, forward_time=0.232, loss_ctc=11.145, loss=11.145, backward_time=0.308, optim_step_time=0.037, optim0_lr0=7.021e-04, train_time=0.619
[ALab02] 2023-06-10 07:34:56,952 (trainer:721) INFO: 46epoch:train:1156-1232batch: iter_time=1.344e-04, forward_time=0.224, loss_ctc=12.524, loss=12.524, backward_time=0.299, optim_step_time=0.035, optim0_lr0=7.017e-04, train_time=0.601
[ALab02] 2023-06-10 07:35:43,106 (trainer:721) INFO: 46epoch:train:1233-1309batch: iter_time=1.172e-04, forward_time=0.221, loss_ctc=11.871, loss=11.871, backward_time=0.300, optim_step_time=0.036, optim0_lr0=7.013e-04, train_time=0.599
[ALab02] 2023-06-10 07:36:30,723 (trainer:721) INFO: 46epoch:train:1310-1386batch: iter_time=2.598e-04, forward_time=0.233, loss_ctc=11.895, loss=11.895, backward_time=0.304, optim_step_time=0.039, optim0_lr0=7.010e-04, train_time=0.618
[ALab02] 2023-06-10 07:37:18,282 (trainer:721) INFO: 46epoch:train:1387-1463batch: iter_time=1.493e-04, forward_time=0.230, loss_ctc=11.345, loss=11.345, backward_time=0.305, optim_step_time=0.038, optim0_lr0=7.006e-04, train_time=0.617
[ALab02] 2023-06-10 07:38:05,555 (trainer:721) INFO: 46epoch:train:1464-1540batch: iter_time=1.300e-04, forward_time=0.229, loss_ctc=12.011, loss=12.011, backward_time=0.305, optim_step_time=0.036, optim0_lr0=7.002e-04, train_time=0.614
[ALab02] 2023-06-10 07:38:46,933 (trainer:338) INFO: 46epoch results: [train] iter_time=8.555e-04, forward_time=0.229, loss_ctc=11.863, loss=11.863, backward_time=0.304, optim_step_time=0.037, optim0_lr0=7.038e-04, train_time=0.614, time=15 minutes and 54.61 seconds, total_count=71438, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.685, cer_ctc=0.282, cer=0.282, loss=13.685, time=6.65 seconds, total_count=736, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.83 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 07:38:49,219 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 07:38:49,233 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/42epoch.pth
[ALab02] 2023-06-10 07:38:49,234 (trainer:272) INFO: 47/70epoch started. Estimated time to finish: 10 hours, 9 minutes and 26.22 seconds
[ALab02] 2023-06-10 07:39:38,275 (trainer:721) INFO: 47epoch:train:1-77batch: iter_time=0.017, forward_time=0.235, loss_ctc=11.049, loss=11.049, backward_time=0.301, optim_step_time=0.039, optim0_lr0=6.998e-04, train_time=0.637
[ALab02] 2023-06-10 07:40:26,141 (trainer:721) INFO: 47epoch:train:78-154batch: iter_time=1.518e-04, forward_time=0.233, loss_ctc=11.786, loss=11.786, backward_time=0.304, optim_step_time=0.040, optim0_lr0=6.994e-04, train_time=0.621
[ALab02] 2023-06-10 07:41:13,600 (trainer:721) INFO: 47epoch:train:155-231batch: iter_time=1.419e-04, forward_time=0.230, loss_ctc=12.287, loss=12.287, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.990e-04, train_time=0.616
[ALab02] 2023-06-10 07:42:01,511 (trainer:721) INFO: 47epoch:train:232-308batch: iter_time=1.363e-04, forward_time=0.234, loss_ctc=11.277, loss=11.277, backward_time=0.308, optim_step_time=0.037, optim0_lr0=6.986e-04, train_time=0.622
[ALab02] 2023-06-10 07:42:47,727 (trainer:721) INFO: 47epoch:train:309-385batch: iter_time=1.856e-04, forward_time=0.221, loss_ctc=13.214, loss=13.214, backward_time=0.298, optim_step_time=0.038, optim0_lr0=6.983e-04, train_time=0.600
[ALab02] 2023-06-10 07:43:34,408 (trainer:721) INFO: 47epoch:train:386-462batch: iter_time=1.378e-04, forward_time=0.223, loss_ctc=12.947, loss=12.947, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.979e-04, train_time=0.606
[ALab02] 2023-06-10 07:44:21,971 (trainer:721) INFO: 47epoch:train:463-539batch: iter_time=1.521e-04, forward_time=0.231, loss_ctc=12.726, loss=12.726, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.975e-04, train_time=0.617
[ALab02] 2023-06-10 07:45:09,111 (trainer:721) INFO: 47epoch:train:540-616batch: iter_time=1.490e-04, forward_time=0.227, loss_ctc=12.922, loss=12.922, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.971e-04, train_time=0.612
[ALab02] 2023-06-10 07:45:56,861 (trainer:721) INFO: 47epoch:train:617-693batch: iter_time=1.266e-04, forward_time=0.232, loss_ctc=11.502, loss=11.502, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.968e-04, train_time=0.620
[ALab02] 2023-06-10 07:46:44,590 (trainer:721) INFO: 47epoch:train:694-770batch: iter_time=1.386e-04, forward_time=0.237, loss_ctc=9.822, loss=9.822, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.964e-04, train_time=0.620
[ALab02] 2023-06-10 07:47:31,687 (trainer:721) INFO: 47epoch:train:771-847batch: iter_time=1.164e-04, forward_time=0.229, loss_ctc=10.616, loss=10.616, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.960e-04, train_time=0.611
[ALab02] 2023-06-10 07:48:18,780 (trainer:721) INFO: 47epoch:train:848-924batch: iter_time=1.269e-04, forward_time=0.228, loss_ctc=13.413, loss=13.413, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.956e-04, train_time=0.611
[ALab02] 2023-06-10 07:49:05,853 (trainer:721) INFO: 47epoch:train:925-1001batch: iter_time=1.105e-04, forward_time=0.229, loss_ctc=11.515, loss=11.515, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.953e-04, train_time=0.611
[ALab02] 2023-06-10 07:49:52,873 (trainer:721) INFO: 47epoch:train:1002-1078batch: iter_time=1.632e-04, forward_time=0.231, loss_ctc=10.633, loss=10.633, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.949e-04, train_time=0.610
[ALab02] 2023-06-10 07:50:40,098 (trainer:721) INFO: 47epoch:train:1079-1155batch: iter_time=1.732e-04, forward_time=0.230, loss_ctc=12.026, loss=12.026, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.945e-04, train_time=0.613
[ALab02] 2023-06-10 07:51:26,971 (trainer:721) INFO: 47epoch:train:1156-1232batch: iter_time=1.256e-04, forward_time=0.227, loss_ctc=11.020, loss=11.020, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.942e-04, train_time=0.609
[ALab02] 2023-06-10 07:52:13,952 (trainer:721) INFO: 47epoch:train:1233-1309batch: iter_time=1.411e-04, forward_time=0.228, loss_ctc=12.517, loss=12.517, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.938e-04, train_time=0.610
[ALab02] 2023-06-10 07:53:00,852 (trainer:721) INFO: 47epoch:train:1310-1386batch: iter_time=1.215e-04, forward_time=0.225, loss_ctc=11.778, loss=11.778, backward_time=0.301, optim_step_time=0.036, optim0_lr0=6.934e-04, train_time=0.609
[ALab02] 2023-06-10 07:53:47,998 (trainer:721) INFO: 47epoch:train:1387-1463batch: iter_time=1.241e-04, forward_time=0.231, loss_ctc=11.835, loss=11.835, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.931e-04, train_time=0.612
[ALab02] 2023-06-10 07:54:35,564 (trainer:721) INFO: 47epoch:train:1464-1540batch: iter_time=1.278e-04, forward_time=0.229, loss_ctc=11.745, loss=11.745, backward_time=0.309, optim_step_time=0.037, optim0_lr0=6.927e-04, train_time=0.618
[ALab02] 2023-06-10 07:55:17,450 (trainer:338) INFO: 47epoch results: [train] iter_time=9.594e-04, forward_time=0.229, loss_ctc=11.784, loss=11.784, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.962e-04, train_time=0.614, time=15 minutes and 54.34 seconds, total_count=72991, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.654, cer_ctc=0.272, cer=0.272, loss=12.654, time=6.64 seconds, total_count=752, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.24 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 07:55:19,676 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02] 2023-06-10 07:55:19,690 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/36epoch.pth
[ALab02] 2023-06-10 07:55:19,690 (trainer:272) INFO: 48/70epoch started. Estimated time to finish: 9 hours, 39 minutes and 41.74 seconds
[ALab02] 2023-06-10 07:56:07,165 (trainer:721) INFO: 48epoch:train:1-77batch: iter_time=0.014, forward_time=0.223, loss_ctc=13.202, loss=13.202, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.923e-04, train_time=0.616
[ALab02] 2023-06-10 07:56:55,434 (trainer:721) INFO: 48epoch:train:78-154batch: iter_time=1.532e-04, forward_time=0.237, loss_ctc=10.728, loss=10.728, backward_time=0.311, optim_step_time=0.035, optim0_lr0=6.919e-04, train_time=0.627
[ALab02] 2023-06-10 07:57:44,969 (trainer:721) INFO: 48epoch:train:155-231batch: iter_time=1.693e-04, forward_time=0.248, loss_ctc=10.653, loss=10.653, backward_time=0.308, optim_step_time=0.041, optim0_lr0=6.915e-04, train_time=0.643
[ALab02] 2023-06-10 07:58:31,910 (trainer:721) INFO: 48epoch:train:232-308batch: iter_time=1.290e-04, forward_time=0.229, loss_ctc=10.152, loss=10.152, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.912e-04, train_time=0.609
[ALab02] 2023-06-10 07:59:18,726 (trainer:721) INFO: 48epoch:train:309-385batch: iter_time=1.529e-04, forward_time=0.227, loss_ctc=11.940, loss=11.940, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.908e-04, train_time=0.608
[ALab02] 2023-06-10 08:00:05,388 (trainer:721) INFO: 48epoch:train:386-462batch: iter_time=1.401e-04, forward_time=0.224, loss_ctc=11.350, loss=11.350, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.905e-04, train_time=0.606
[ALab02] 2023-06-10 08:00:53,258 (trainer:721) INFO: 48epoch:train:463-539batch: iter_time=1.272e-04, forward_time=0.235, loss_ctc=11.256, loss=11.256, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.901e-04, train_time=0.621
[ALab02] 2023-06-10 08:01:40,330 (trainer:721) INFO: 48epoch:train:540-616batch: iter_time=1.472e-04, forward_time=0.229, loss_ctc=12.193, loss=12.193, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.897e-04, train_time=0.611
[ALab02] 2023-06-10 08:02:28,663 (trainer:721) INFO: 48epoch:train:617-693batch: iter_time=1.301e-04, forward_time=0.240, loss_ctc=11.296, loss=11.296, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.894e-04, train_time=0.627
[ALab02] 2023-06-10 08:03:15,928 (trainer:721) INFO: 48epoch:train:694-770batch: iter_time=1.757e-04, forward_time=0.228, loss_ctc=11.159, loss=11.159, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.890e-04, train_time=0.614
[ALab02] 2023-06-10 08:04:03,008 (trainer:721) INFO: 48epoch:train:771-847batch: iter_time=1.415e-04, forward_time=0.229, loss_ctc=12.825, loss=12.825, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.887e-04, train_time=0.611
[ALab02] 2023-06-10 08:04:49,685 (trainer:721) INFO: 48epoch:train:848-924batch: iter_time=1.373e-04, forward_time=0.227, loss_ctc=12.825, loss=12.825, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.883e-04, train_time=0.606
[ALab02] 2023-06-10 08:05:37,306 (trainer:721) INFO: 48epoch:train:925-1001batch: iter_time=1.640e-04, forward_time=0.233, loss_ctc=10.635, loss=10.635, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.879e-04, train_time=0.618
[ALab02] 2023-06-10 08:06:23,987 (trainer:721) INFO: 48epoch:train:1002-1078batch: iter_time=1.239e-04, forward_time=0.227, loss_ctc=11.197, loss=11.197, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.876e-04, train_time=0.606
[ALab02] 2023-06-10 08:07:10,507 (trainer:721) INFO: 48epoch:train:1079-1155batch: iter_time=1.447e-04, forward_time=0.223, loss_ctc=12.311, loss=12.311, backward_time=0.300, optim_step_time=0.037, optim0_lr0=6.872e-04, train_time=0.604
[ALab02] 2023-06-10 08:07:57,252 (trainer:721) INFO: 48epoch:train:1156-1232batch: iter_time=1.187e-04, forward_time=0.225, loss_ctc=12.867, loss=12.867, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.869e-04, train_time=0.607
[ALab02] 2023-06-10 08:08:45,002 (trainer:721) INFO: 48epoch:train:1233-1309batch: iter_time=1.338e-04, forward_time=0.231, loss_ctc=12.063, loss=12.063, backward_time=0.302, optim_step_time=0.041, optim0_lr0=6.865e-04, train_time=0.620
[ALab02] 2023-06-10 08:09:33,456 (trainer:721) INFO: 48epoch:train:1310-1386batch: iter_time=1.217e-04, forward_time=0.236, loss_ctc=11.903, loss=11.903, backward_time=0.310, optim_step_time=0.037, optim0_lr0=6.862e-04, train_time=0.629
[ALab02] 2023-06-10 08:10:20,272 (trainer:721) INFO: 48epoch:train:1387-1463batch: iter_time=1.297e-04, forward_time=0.224, loss_ctc=11.967, loss=11.967, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.858e-04, train_time=0.608
[ALab02] 2023-06-10 08:11:07,215 (trainer:721) INFO: 48epoch:train:1464-1540batch: iter_time=1.315e-04, forward_time=0.229, loss_ctc=11.833, loss=11.833, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.854e-04, train_time=0.609
[ALab02] 2023-06-10 08:11:49,333 (trainer:338) INFO: 48epoch results: [train] iter_time=8.397e-04, forward_time=0.230, loss_ctc=11.668, loss=11.668, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.888e-04, train_time=0.615, time=15 minutes and 56.03 seconds, total_count=74544, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.008, cer_ctc=0.282, cer=0.282, loss=13.008, time=6.67 seconds, total_count=768, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.94 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 08:11:51,564 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 08:11:51,580 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/46epoch.pth
[ALab02] 2023-06-10 08:11:51,581 (trainer:272) INFO: 49/70epoch started. Estimated time to finish: 9 hours, 10 minutes and 30.99 seconds
[ALab02] 2023-06-10 08:12:40,085 (trainer:721) INFO: 49epoch:train:1-77batch: iter_time=0.013, forward_time=0.230, loss_ctc=11.903, loss=11.903, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.850e-04, train_time=0.630
[ALab02] 2023-06-10 08:13:27,837 (trainer:721) INFO: 49epoch:train:78-154batch: iter_time=1.399e-04, forward_time=0.234, loss_ctc=10.141, loss=10.141, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.847e-04, train_time=0.620
[ALab02] 2023-06-10 08:14:15,099 (trainer:721) INFO: 49epoch:train:155-231batch: iter_time=1.438e-04, forward_time=0.231, loss_ctc=11.180, loss=11.180, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.843e-04, train_time=0.614
[ALab02] 2023-06-10 08:15:02,218 (trainer:721) INFO: 49epoch:train:232-308batch: iter_time=1.224e-04, forward_time=0.226, loss_ctc=13.163, loss=13.163, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.840e-04, train_time=0.612
[ALab02] 2023-06-10 08:15:51,115 (trainer:721) INFO: 49epoch:train:309-385batch: iter_time=1.676e-04, forward_time=0.243, loss_ctc=11.734, loss=11.734, backward_time=0.308, optim_step_time=0.039, optim0_lr0=6.836e-04, train_time=0.635
[ALab02] 2023-06-10 08:16:37,910 (trainer:721) INFO: 49epoch:train:386-462batch: iter_time=1.442e-04, forward_time=0.224, loss_ctc=12.478, loss=12.478, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.833e-04, train_time=0.608
[ALab02] 2023-06-10 08:17:25,121 (trainer:721) INFO: 49epoch:train:463-539batch: iter_time=1.323e-04, forward_time=0.231, loss_ctc=10.053, loss=10.053, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.829e-04, train_time=0.613
[ALab02] 2023-06-10 08:18:11,461 (trainer:721) INFO: 49epoch:train:540-616batch: iter_time=1.675e-04, forward_time=0.220, loss_ctc=13.561, loss=13.561, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.826e-04, train_time=0.602
[ALab02] 2023-06-10 08:18:59,697 (trainer:721) INFO: 49epoch:train:617-693batch: iter_time=4.785e-04, forward_time=0.239, loss_ctc=11.172, loss=11.172, backward_time=0.303, optim_step_time=0.043, optim0_lr0=6.822e-04, train_time=0.626
[ALab02] 2023-06-10 08:19:46,793 (trainer:721) INFO: 49epoch:train:694-770batch: iter_time=1.427e-04, forward_time=0.228, loss_ctc=11.556, loss=11.556, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.819e-04, train_time=0.611
[ALab02] 2023-06-10 08:20:34,599 (trainer:721) INFO: 49epoch:train:771-847batch: iter_time=1.596e-04, forward_time=0.232, loss_ctc=11.534, loss=11.534, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.815e-04, train_time=0.621
[ALab02] 2023-06-10 08:21:22,599 (trainer:721) INFO: 49epoch:train:848-924batch: iter_time=1.668e-04, forward_time=0.234, loss_ctc=10.997, loss=10.997, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.812e-04, train_time=0.623
[ALab02] 2023-06-10 08:22:09,288 (trainer:721) INFO: 49epoch:train:925-1001batch: iter_time=1.735e-04, forward_time=0.226, loss_ctc=10.998, loss=10.998, backward_time=0.299, optim_step_time=0.038, optim0_lr0=6.808e-04, train_time=0.606
[ALab02] 2023-06-10 08:22:55,945 (trainer:721) INFO: 49epoch:train:1002-1078batch: iter_time=1.421e-04, forward_time=0.223, loss_ctc=12.523, loss=12.523, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.805e-04, train_time=0.606
[ALab02] 2023-06-10 08:23:43,281 (trainer:721) INFO: 49epoch:train:1079-1155batch: iter_time=1.474e-04, forward_time=0.232, loss_ctc=11.320, loss=11.320, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.801e-04, train_time=0.615
[ALab02] 2023-06-10 08:24:31,874 (trainer:721) INFO: 49epoch:train:1156-1232batch: iter_time=1.619e-04, forward_time=0.240, loss_ctc=11.043, loss=11.043, backward_time=0.309, optim_step_time=0.038, optim0_lr0=6.798e-04, train_time=0.631
[ALab02] 2023-06-10 08:25:19,170 (trainer:721) INFO: 49epoch:train:1233-1309batch: iter_time=1.128e-04, forward_time=0.234, loss_ctc=11.051, loss=11.051, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.794e-04, train_time=0.614
[ALab02] 2023-06-10 08:26:05,858 (trainer:721) INFO: 49epoch:train:1310-1386batch: iter_time=1.526e-04, forward_time=0.224, loss_ctc=12.901, loss=12.901, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.791e-04, train_time=0.606
[ALab02] 2023-06-10 08:26:52,539 (trainer:721) INFO: 49epoch:train:1387-1463batch: iter_time=1.517e-04, forward_time=0.222, loss_ctc=11.973, loss=11.973, backward_time=0.301, optim_step_time=0.039, optim0_lr0=6.788e-04, train_time=0.606
[ALab02] 2023-06-10 08:27:40,077 (trainer:721) INFO: 49epoch:train:1464-1540batch: iter_time=1.174e-04, forward_time=0.231, loss_ctc=12.676, loss=12.676, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.784e-04, train_time=0.617
[ALab02] 2023-06-10 08:28:22,670 (trainer:338) INFO: 49epoch results: [train] iter_time=8.041e-04, forward_time=0.230, loss_ctc=11.620, loss=11.620, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.817e-04, train_time=0.616, time=15 minutes and 57 seconds, total_count=76097, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=12.964, cer_ctc=0.277, cer=0.277, loss=12.964, time=6.7 seconds, total_count=784, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.39 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 08:28:24,958 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 08:28:24,972 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/35epoch.pth
[ALab02] 2023-06-10 08:28:24,972 (trainer:272) INFO: 50/70epoch started. Estimated time to finish: 8 hours, 41 minutes and 51.86 seconds
[ALab02] 2023-06-10 08:29:13,204 (trainer:721) INFO: 50epoch:train:1-77batch: iter_time=0.013, forward_time=0.228, loss_ctc=11.829, loss=11.829, backward_time=0.299, optim_step_time=0.040, optim0_lr0=6.780e-04, train_time=0.626
[ALab02] 2023-06-10 08:30:01,022 (trainer:721) INFO: 50epoch:train:78-154batch: iter_time=1.205e-04, forward_time=0.232, loss_ctc=11.559, loss=11.559, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.777e-04, train_time=0.621
[ALab02] 2023-06-10 08:30:49,317 (trainer:721) INFO: 50epoch:train:155-231batch: iter_time=1.573e-04, forward_time=0.238, loss_ctc=10.295, loss=10.295, backward_time=0.310, optim_step_time=0.036, optim0_lr0=6.773e-04, train_time=0.627
[ALab02] 2023-06-10 08:31:36,706 (trainer:721) INFO: 50epoch:train:232-308batch: iter_time=1.500e-04, forward_time=0.229, loss_ctc=12.056, loss=12.056, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.770e-04, train_time=0.615
[ALab02] 2023-06-10 08:32:23,332 (trainer:721) INFO: 50epoch:train:309-385batch: iter_time=1.342e-04, forward_time=0.225, loss_ctc=11.355, loss=11.355, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.766e-04, train_time=0.605
[ALab02] 2023-06-10 08:33:10,171 (trainer:721) INFO: 50epoch:train:386-462batch: iter_time=1.272e-04, forward_time=0.226, loss_ctc=11.979, loss=11.979, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.763e-04, train_time=0.608
[ALab02] 2023-06-10 08:33:59,161 (trainer:721) INFO: 50epoch:train:463-539batch: iter_time=1.332e-04, forward_time=0.246, loss_ctc=9.125, loss=9.125, backward_time=0.304, optim_step_time=0.040, optim0_lr0=6.760e-04, train_time=0.636
[ALab02] 2023-06-10 08:34:46,319 (trainer:721) INFO: 50epoch:train:540-616batch: iter_time=1.526e-04, forward_time=0.229, loss_ctc=11.226, loss=11.226, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.756e-04, train_time=0.612
[ALab02] 2023-06-10 08:35:33,654 (trainer:721) INFO: 50epoch:train:617-693batch: iter_time=1.421e-04, forward_time=0.230, loss_ctc=10.662, loss=10.662, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.753e-04, train_time=0.615
[ALab02] 2023-06-10 08:36:20,774 (trainer:721) INFO: 50epoch:train:694-770batch: iter_time=1.449e-04, forward_time=0.231, loss_ctc=12.092, loss=12.092, backward_time=0.300, optim_step_time=0.038, optim0_lr0=6.749e-04, train_time=0.612
[ALab02] 2023-06-10 08:37:08,636 (trainer:721) INFO: 50epoch:train:771-847batch: iter_time=1.755e-04, forward_time=0.233, loss_ctc=11.550, loss=11.550, backward_time=0.307, optim_step_time=0.038, optim0_lr0=6.746e-04, train_time=0.621
[ALab02] 2023-06-10 08:37:55,403 (trainer:721) INFO: 50epoch:train:848-924batch: iter_time=1.381e-04, forward_time=0.226, loss_ctc=11.770, loss=11.770, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.743e-04, train_time=0.607
[ALab02] 2023-06-10 08:38:42,148 (trainer:721) INFO: 50epoch:train:925-1001batch: iter_time=1.445e-04, forward_time=0.226, loss_ctc=11.237, loss=11.237, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.739e-04, train_time=0.607
[ALab02] 2023-06-10 08:39:29,497 (trainer:721) INFO: 50epoch:train:1002-1078batch: iter_time=1.131e-04, forward_time=0.229, loss_ctc=11.677, loss=11.677, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.736e-04, train_time=0.615
[ALab02] 2023-06-10 08:40:18,247 (trainer:721) INFO: 50epoch:train:1079-1155batch: iter_time=1.771e-04, forward_time=0.240, loss_ctc=11.732, loss=11.732, backward_time=0.309, optim_step_time=0.040, optim0_lr0=6.733e-04, train_time=0.633
[ALab02] 2023-06-10 08:41:06,007 (trainer:721) INFO: 50epoch:train:1156-1232batch: iter_time=1.464e-04, forward_time=0.232, loss_ctc=11.739, loss=11.739, backward_time=0.309, optim_step_time=0.037, optim0_lr0=6.729e-04, train_time=0.620
[ALab02] 2023-06-10 08:41:52,953 (trainer:721) INFO: 50epoch:train:1233-1309batch: iter_time=1.347e-04, forward_time=0.228, loss_ctc=11.192, loss=11.192, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.726e-04, train_time=0.609
[ALab02] 2023-06-10 08:42:39,551 (trainer:721) INFO: 50epoch:train:1310-1386batch: iter_time=1.230e-04, forward_time=0.223, loss_ctc=13.041, loss=13.041, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.723e-04, train_time=0.605
[ALab02] 2023-06-10 08:43:26,726 (trainer:721) INFO: 50epoch:train:1387-1463batch: iter_time=1.366e-04, forward_time=0.230, loss_ctc=9.996, loss=9.996, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.719e-04, train_time=0.612
[ALab02] 2023-06-10 08:44:13,360 (trainer:721) INFO: 50epoch:train:1464-1540batch: iter_time=1.423e-04, forward_time=0.225, loss_ctc=12.630, loss=12.630, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.716e-04, train_time=0.605
[ALab02] 2023-06-10 08:44:55,647 (trainer:338) INFO: 50epoch results: [train] iter_time=8.032e-04, forward_time=0.231, loss_ctc=11.369, loss=11.369, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.748e-04, train_time=0.616, time=15 minutes and 56.72 seconds, total_count=77650, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.570, cer_ctc=0.285, cer=0.285, loss=13.570, time=6.79 seconds, total_count=800, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.17 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 08:44:57,779 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 08:44:57,780 (trainer:272) INFO: 51/70epoch started. Estimated time to finish: 8 hours, 13 minutes and 41.52 seconds
[ALab02] 2023-06-10 08:45:46,274 (trainer:721) INFO: 51epoch:train:1-77batch: iter_time=0.015, forward_time=0.233, loss_ctc=10.954, loss=10.954, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.712e-04, train_time=0.630
[ALab02] 2023-06-10 08:46:33,677 (trainer:721) INFO: 51epoch:train:78-154batch: iter_time=1.379e-04, forward_time=0.230, loss_ctc=12.155, loss=12.155, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.709e-04, train_time=0.615
[ALab02] 2023-06-10 08:47:20,670 (trainer:721) INFO: 51epoch:train:155-231batch: iter_time=1.309e-04, forward_time=0.227, loss_ctc=10.051, loss=10.051, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.705e-04, train_time=0.610
[ALab02] 2023-06-10 08:48:07,839 (trainer:721) INFO: 51epoch:train:232-308batch: iter_time=1.446e-04, forward_time=0.229, loss_ctc=10.663, loss=10.663, backward_time=0.302, optim_step_time=0.038, optim0_lr0=6.702e-04, train_time=0.612
[ALab02] 2023-06-10 08:48:54,536 (trainer:721) INFO: 51epoch:train:309-385batch: iter_time=1.424e-04, forward_time=0.228, loss_ctc=12.016, loss=12.016, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.699e-04, train_time=0.606
[ALab02] 2023-06-10 08:49:42,472 (trainer:721) INFO: 51epoch:train:386-462batch: iter_time=1.382e-04, forward_time=0.234, loss_ctc=11.385, loss=11.385, backward_time=0.308, optim_step_time=0.037, optim0_lr0=6.695e-04, train_time=0.622
[ALab02] 2023-06-10 08:50:30,407 (trainer:721) INFO: 51epoch:train:463-539batch: iter_time=1.406e-04, forward_time=0.234, loss_ctc=10.658, loss=10.658, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.692e-04, train_time=0.622
[ALab02] 2023-06-10 08:51:18,427 (trainer:721) INFO: 51epoch:train:540-616batch: iter_time=1.485e-04, forward_time=0.233, loss_ctc=11.026, loss=11.026, backward_time=0.311, optim_step_time=0.035, optim0_lr0=6.689e-04, train_time=0.623
[ALab02] 2023-06-10 08:52:06,072 (trainer:721) INFO: 51epoch:train:617-693batch: iter_time=1.668e-04, forward_time=0.232, loss_ctc=11.521, loss=11.521, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.686e-04, train_time=0.619
[ALab02] 2023-06-10 08:52:52,246 (trainer:721) INFO: 51epoch:train:694-770batch: iter_time=1.295e-04, forward_time=0.223, loss_ctc=12.339, loss=12.339, backward_time=0.299, optim_step_time=0.036, optim0_lr0=6.682e-04, train_time=0.599
[ALab02] 2023-06-10 08:53:38,378 (trainer:721) INFO: 51epoch:train:771-847batch: iter_time=1.524e-04, forward_time=0.222, loss_ctc=11.174, loss=11.174, backward_time=0.302, optim_step_time=0.035, optim0_lr0=6.679e-04, train_time=0.599
[ALab02] 2023-06-10 08:54:27,256 (trainer:721) INFO: 51epoch:train:848-924batch: iter_time=3.997e-04, forward_time=0.242, loss_ctc=11.546, loss=11.546, backward_time=0.304, optim_step_time=0.042, optim0_lr0=6.676e-04, train_time=0.635
[ALab02] 2023-06-10 08:55:13,806 (trainer:721) INFO: 51epoch:train:925-1001batch: iter_time=1.224e-04, forward_time=0.224, loss_ctc=11.321, loss=11.321, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.672e-04, train_time=0.604
[ALab02] 2023-06-10 08:56:00,804 (trainer:721) INFO: 51epoch:train:1002-1078batch: iter_time=1.479e-04, forward_time=0.228, loss_ctc=12.270, loss=12.270, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.669e-04, train_time=0.610
[ALab02] 2023-06-10 08:56:46,969 (trainer:721) INFO: 51epoch:train:1079-1155batch: iter_time=1.583e-04, forward_time=0.221, loss_ctc=11.597, loss=11.597, backward_time=0.299, optim_step_time=0.036, optim0_lr0=6.666e-04, train_time=0.599
[ALab02] 2023-06-10 08:57:34,569 (trainer:721) INFO: 51epoch:train:1156-1232batch: iter_time=1.150e-04, forward_time=0.229, loss_ctc=10.704, loss=10.704, backward_time=0.309, optim_step_time=0.036, optim0_lr0=6.663e-04, train_time=0.618
[ALab02] 2023-06-10 08:58:22,230 (trainer:721) INFO: 51epoch:train:1233-1309batch: iter_time=1.363e-04, forward_time=0.231, loss_ctc=12.552, loss=12.552, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.659e-04, train_time=0.619
[ALab02] 2023-06-10 08:59:09,063 (trainer:721) INFO: 51epoch:train:1310-1386batch: iter_time=1.361e-04, forward_time=0.222, loss_ctc=11.515, loss=11.515, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.656e-04, train_time=0.608
[ALab02] 2023-06-10 08:59:56,376 (trainer:721) INFO: 51epoch:train:1387-1463batch: iter_time=1.452e-04, forward_time=0.230, loss_ctc=9.957, loss=9.957, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.653e-04, train_time=0.614
[ALab02] 2023-06-10 09:00:43,452 (trainer:721) INFO: 51epoch:train:1464-1540batch: iter_time=1.321e-04, forward_time=0.230, loss_ctc=10.705, loss=10.705, backward_time=0.306, optim_step_time=0.036, optim0_lr0=6.650e-04, train_time=0.611
[ALab02] 2023-06-10 09:01:25,585 (trainer:338) INFO: 51epoch results: [train] iter_time=8.931e-04, forward_time=0.229, loss_ctc=11.284, loss=11.284, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.680e-04, train_time=0.614, time=15 minutes and 54.02 seconds, total_count=79203, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.148, cer_ctc=0.286, cer=0.286, loss=13.148, time=7.1 seconds, total_count=816, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.68 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 09:01:27,714 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 09:01:27,733 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/50epoch.pth
[ALab02] 2023-06-10 09:01:27,733 (trainer:272) INFO: 52/70epoch started. Estimated time to finish: 7 hours, 45 minutes and 57.48 seconds
[ALab02] 2023-06-10 09:02:16,521 (trainer:721) INFO: 52epoch:train:1-77batch: iter_time=0.016, forward_time=0.226, loss_ctc=11.760, loss=11.760, backward_time=0.309, optim_step_time=0.036, optim0_lr0=6.646e-04, train_time=0.633
[ALab02] 2023-06-10 09:03:03,613 (trainer:721) INFO: 52epoch:train:78-154batch: iter_time=1.383e-04, forward_time=0.226, loss_ctc=11.520, loss=11.520, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.643e-04, train_time=0.611
[ALab02] 2023-06-10 09:03:52,638 (trainer:721) INFO: 52epoch:train:155-231batch: iter_time=1.664e-04, forward_time=0.243, loss_ctc=10.641, loss=10.641, backward_time=0.313, optim_step_time=0.037, optim0_lr0=6.639e-04, train_time=0.636
[ALab02] 2023-06-10 09:04:40,205 (trainer:721) INFO: 52epoch:train:232-308batch: iter_time=1.520e-04, forward_time=0.234, loss_ctc=10.321, loss=10.321, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.636e-04, train_time=0.618
[ALab02] 2023-06-10 09:05:26,668 (trainer:721) INFO: 52epoch:train:309-385batch: iter_time=1.551e-04, forward_time=0.223, loss_ctc=11.936, loss=11.936, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.633e-04, train_time=0.603
[ALab02] 2023-06-10 09:06:13,555 (trainer:721) INFO: 52epoch:train:386-462batch: iter_time=1.617e-04, forward_time=0.226, loss_ctc=11.828, loss=11.828, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.630e-04, train_time=0.609
[ALab02] 2023-06-10 09:07:00,513 (trainer:721) INFO: 52epoch:train:463-539batch: iter_time=1.404e-04, forward_time=0.225, loss_ctc=10.926, loss=10.926, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.627e-04, train_time=0.610
[ALab02] 2023-06-10 09:07:48,336 (trainer:721) INFO: 52epoch:train:540-616batch: iter_time=1.683e-04, forward_time=0.233, loss_ctc=11.467, loss=11.467, backward_time=0.304, optim_step_time=0.039, optim0_lr0=6.623e-04, train_time=0.621
[ALab02] 2023-06-10 09:08:35,033 (trainer:721) INFO: 52epoch:train:617-693batch: iter_time=1.369e-04, forward_time=0.226, loss_ctc=11.214, loss=11.214, backward_time=0.300, optim_step_time=0.037, optim0_lr0=6.620e-04, train_time=0.606
[ALab02] 2023-06-10 09:09:22,603 (trainer:721) INFO: 52epoch:train:694-770batch: iter_time=1.472e-04, forward_time=0.232, loss_ctc=11.195, loss=11.195, backward_time=0.304, optim_step_time=0.039, optim0_lr0=6.617e-04, train_time=0.618
[ALab02] 2023-06-10 09:10:09,675 (trainer:721) INFO: 52epoch:train:771-847batch: iter_time=1.136e-04, forward_time=0.228, loss_ctc=10.966, loss=10.966, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.614e-04, train_time=0.611
[ALab02] 2023-06-10 09:10:56,518 (trainer:721) INFO: 52epoch:train:848-924batch: iter_time=1.640e-04, forward_time=0.226, loss_ctc=11.147, loss=11.147, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.611e-04, train_time=0.608
[ALab02] 2023-06-10 09:11:43,777 (trainer:721) INFO: 52epoch:train:925-1001batch: iter_time=1.459e-04, forward_time=0.230, loss_ctc=9.229, loss=9.229, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.607e-04, train_time=0.614
[ALab02] 2023-06-10 09:12:31,770 (trainer:721) INFO: 52epoch:train:1002-1078batch: iter_time=1.482e-04, forward_time=0.237, loss_ctc=10.348, loss=10.348, backward_time=0.305, optim_step_time=0.040, optim0_lr0=6.604e-04, train_time=0.623
[ALab02] 2023-06-10 09:13:19,319 (trainer:721) INFO: 52epoch:train:1079-1155batch: iter_time=1.457e-04, forward_time=0.232, loss_ctc=10.732, loss=10.732, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.601e-04, train_time=0.617
[ALab02] 2023-06-10 09:14:06,174 (trainer:721) INFO: 52epoch:train:1156-1232batch: iter_time=1.316e-04, forward_time=0.226, loss_ctc=12.386, loss=12.386, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.598e-04, train_time=0.608
[ALab02] 2023-06-10 09:14:52,715 (trainer:721) INFO: 52epoch:train:1233-1309batch: iter_time=1.306e-04, forward_time=0.226, loss_ctc=11.158, loss=11.158, backward_time=0.300, optim_step_time=0.036, optim0_lr0=6.595e-04, train_time=0.604
[ALab02] 2023-06-10 09:15:40,585 (trainer:721) INFO: 52epoch:train:1310-1386batch: iter_time=1.558e-04, forward_time=0.234, loss_ctc=11.533, loss=11.533, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.592e-04, train_time=0.621
[ALab02] 2023-06-10 09:16:27,843 (trainer:721) INFO: 52epoch:train:1387-1463batch: iter_time=1.172e-04, forward_time=0.229, loss_ctc=10.474, loss=10.474, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.589e-04, train_time=0.614
[ALab02] 2023-06-10 09:17:14,716 (trainer:721) INFO: 52epoch:train:1464-1540batch: iter_time=1.258e-04, forward_time=0.227, loss_ctc=11.775, loss=11.775, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.585e-04, train_time=0.609
[ALab02] 2023-06-10 09:17:59,776 (trainer:338) INFO: 52epoch results: [train] iter_time=9.290e-04, forward_time=0.229, loss_ctc=11.093, loss=11.093, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.615e-04, train_time=0.615, time=15 minutes and 55.15 seconds, total_count=80756, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.587, cer_ctc=0.284, cer=0.284, loss=13.587, time=6.68 seconds, total_count=832, gpu_max_cached_mem_GB=77.078, [att_plot] time=30.21 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 09:18:02,037 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 09:18:02,051 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/51epoch.pth
[ALab02] 2023-06-10 09:18:02,051 (trainer:272) INFO: 53/70epoch started. Estimated time to finish: 7 hours, 18 minutes and 40.87 seconds
[ALab02] 2023-06-10 09:18:51,014 (trainer:721) INFO: 53epoch:train:1-77batch: iter_time=0.015, forward_time=0.232, loss_ctc=10.753, loss=10.753, backward_time=0.306, optim_step_time=0.038, optim0_lr0=6.582e-04, train_time=0.636
[ALab02] 2023-06-10 09:19:38,215 (trainer:721) INFO: 53epoch:train:78-154batch: iter_time=1.284e-04, forward_time=0.229, loss_ctc=11.496, loss=11.496, backward_time=0.300, optim_step_time=0.036, optim0_lr0=6.579e-04, train_time=0.613
[ALab02] 2023-06-10 09:20:25,930 (trainer:721) INFO: 53epoch:train:155-231batch: iter_time=1.377e-04, forward_time=0.233, loss_ctc=10.721, loss=10.721, backward_time=0.306, optim_step_time=0.036, optim0_lr0=6.575e-04, train_time=0.619
[ALab02] 2023-06-10 09:21:13,526 (trainer:721) INFO: 53epoch:train:232-308batch: iter_time=1.298e-04, forward_time=0.231, loss_ctc=9.302, loss=9.302, backward_time=0.311, optim_step_time=0.037, optim0_lr0=6.572e-04, train_time=0.618
[ALab02] 2023-06-10 09:22:02,781 (trainer:721) INFO: 53epoch:train:309-385batch: iter_time=5.024e-04, forward_time=0.241, loss_ctc=11.390, loss=11.390, backward_time=0.314, optim_step_time=0.040, optim0_lr0=6.569e-04, train_time=0.639
[ALab02] 2023-06-10 09:22:49,447 (trainer:721) INFO: 53epoch:train:386-462batch: iter_time=1.240e-04, forward_time=0.223, loss_ctc=12.123, loss=12.123, backward_time=0.306, optim_step_time=0.036, optim0_lr0=6.566e-04, train_time=0.606
[ALab02] 2023-06-10 09:23:36,896 (trainer:721) INFO: 53epoch:train:463-539batch: iter_time=1.382e-04, forward_time=0.230, loss_ctc=9.741, loss=9.741, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.563e-04, train_time=0.616
[ALab02] 2023-06-10 09:24:23,244 (trainer:721) INFO: 53epoch:train:540-616batch: iter_time=1.473e-04, forward_time=0.224, loss_ctc=10.516, loss=10.516, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.560e-04, train_time=0.602
[ALab02] 2023-06-10 09:25:10,105 (trainer:721) INFO: 53epoch:train:617-693batch: iter_time=1.176e-04, forward_time=0.226, loss_ctc=11.415, loss=11.415, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.557e-04, train_time=0.608
[ALab02] 2023-06-10 09:25:58,544 (trainer:721) INFO: 53epoch:train:694-770batch: iter_time=1.461e-04, forward_time=0.238, loss_ctc=9.376, loss=9.376, backward_time=0.309, optim_step_time=0.037, optim0_lr0=6.554e-04, train_time=0.629
[ALab02] 2023-06-10 09:26:44,929 (trainer:721) INFO: 53epoch:train:771-847batch: iter_time=1.285e-04, forward_time=0.223, loss_ctc=12.203, loss=12.203, backward_time=0.299, optim_step_time=0.038, optim0_lr0=6.551e-04, train_time=0.602
[ALab02] 2023-06-10 09:27:31,727 (trainer:721) INFO: 53epoch:train:848-924batch: iter_time=1.252e-04, forward_time=0.226, loss_ctc=10.453, loss=10.453, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.547e-04, train_time=0.608
[ALab02] 2023-06-10 09:28:19,341 (trainer:721) INFO: 53epoch:train:925-1001batch: iter_time=1.588e-04, forward_time=0.235, loss_ctc=10.889, loss=10.889, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.544e-04, train_time=0.618
[ALab02] 2023-06-10 09:29:06,465 (trainer:721) INFO: 53epoch:train:1002-1078batch: iter_time=1.390e-04, forward_time=0.228, loss_ctc=12.732, loss=12.732, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.541e-04, train_time=0.612
[ALab02] 2023-06-10 09:29:53,589 (trainer:721) INFO: 53epoch:train:1079-1155batch: iter_time=1.337e-04, forward_time=0.230, loss_ctc=10.528, loss=10.528, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.538e-04, train_time=0.612
[ALab02] 2023-06-10 09:30:41,756 (trainer:721) INFO: 53epoch:train:1156-1232batch: iter_time=1.731e-04, forward_time=0.237, loss_ctc=10.500, loss=10.500, backward_time=0.306, optim_step_time=0.039, optim0_lr0=6.535e-04, train_time=0.625
[ALab02] 2023-06-10 09:31:28,740 (trainer:721) INFO: 53epoch:train:1233-1309batch: iter_time=1.851e-04, forward_time=0.226, loss_ctc=12.073, loss=12.073, backward_time=0.301, optim_step_time=0.036, optim0_lr0=6.532e-04, train_time=0.610
[ALab02] 2023-06-10 09:32:15,618 (trainer:721) INFO: 53epoch:train:1310-1386batch: iter_time=1.515e-04, forward_time=0.226, loss_ctc=10.478, loss=10.478, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.529e-04, train_time=0.609
[ALab02] 2023-06-10 09:33:03,247 (trainer:721) INFO: 53epoch:train:1387-1463batch: iter_time=1.253e-04, forward_time=0.230, loss_ctc=12.967, loss=12.967, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.526e-04, train_time=0.618
[ALab02] 2023-06-10 09:33:49,394 (trainer:721) INFO: 53epoch:train:1464-1540batch: iter_time=1.356e-04, forward_time=0.222, loss_ctc=12.440, loss=12.440, backward_time=0.301, optim_step_time=0.036, optim0_lr0=6.523e-04, train_time=0.599
[ALab02] 2023-06-10 09:34:30,749 (trainer:338) INFO: 53epoch results: [train] iter_time=8.832e-04, forward_time=0.229, loss_ctc=11.032, loss=11.032, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.552e-04, train_time=0.615, time=15 minutes and 55.02 seconds, total_count=82309, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.521, cer_ctc=0.278, cer=0.278, loss=13.521, time=6.63 seconds, total_count=848, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.05 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 09:34:33,052 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 09:34:33,081 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/48epoch.pth, exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/52epoch.pth
[ALab02] 2023-06-10 09:34:33,081 (trainer:272) INFO: 54/70epoch started. Estimated time to finish: 6 hours, 51 minutes and 47.45 seconds
[ALab02] 2023-06-10 09:35:22,240 (trainer:721) INFO: 54epoch:train:1-77batch: iter_time=0.013, forward_time=0.236, loss_ctc=9.374, loss=9.374, backward_time=0.302, optim_step_time=0.038, optim0_lr0=6.519e-04, train_time=0.638
[ALab02] 2023-06-10 09:36:08,711 (trainer:721) INFO: 54epoch:train:78-154batch: iter_time=1.509e-04, forward_time=0.225, loss_ctc=11.454, loss=11.454, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.516e-04, train_time=0.603
[ALab02] 2023-06-10 09:36:55,475 (trainer:721) INFO: 54epoch:train:155-231batch: iter_time=1.279e-04, forward_time=0.225, loss_ctc=11.110, loss=11.110, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.513e-04, train_time=0.607
[ALab02] 2023-06-10 09:37:42,281 (trainer:721) INFO: 54epoch:train:232-308batch: iter_time=1.516e-04, forward_time=0.228, loss_ctc=11.773, loss=11.773, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.510e-04, train_time=0.608
[ALab02] 2023-06-10 09:38:30,305 (trainer:721) INFO: 54epoch:train:309-385batch: iter_time=1.629e-04, forward_time=0.233, loss_ctc=10.562, loss=10.562, backward_time=0.311, optim_step_time=0.038, optim0_lr0=6.507e-04, train_time=0.623
[ALab02] 2023-06-10 09:39:18,162 (trainer:721) INFO: 54epoch:train:386-462batch: iter_time=1.192e-04, forward_time=0.237, loss_ctc=9.630, loss=9.630, backward_time=0.308, optim_step_time=0.036, optim0_lr0=6.504e-04, train_time=0.621
[ALab02] 2023-06-10 09:40:05,401 (trainer:721) INFO: 54epoch:train:463-539batch: iter_time=1.554e-04, forward_time=0.230, loss_ctc=10.928, loss=10.928, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.501e-04, train_time=0.613
[ALab02] 2023-06-10 09:40:51,671 (trainer:721) INFO: 54epoch:train:540-616batch: iter_time=1.449e-04, forward_time=0.225, loss_ctc=9.896, loss=9.896, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.498e-04, train_time=0.601
[ALab02] 2023-06-10 09:41:39,474 (trainer:721) INFO: 54epoch:train:617-693batch: iter_time=1.464e-04, forward_time=0.230, loss_ctc=12.824, loss=12.824, backward_time=0.307, optim_step_time=0.040, optim0_lr0=6.495e-04, train_time=0.621
[ALab02] 2023-06-10 09:42:27,107 (trainer:721) INFO: 54epoch:train:694-770batch: iter_time=3.480e-04, forward_time=0.232, loss_ctc=11.868, loss=11.868, backward_time=0.308, optim_step_time=0.037, optim0_lr0=6.492e-04, train_time=0.618
[ALab02] 2023-06-10 09:43:14,496 (trainer:721) INFO: 54epoch:train:771-847batch: iter_time=1.696e-04, forward_time=0.231, loss_ctc=11.155, loss=11.155, backward_time=0.307, optim_step_time=0.038, optim0_lr0=6.489e-04, train_time=0.615
[ALab02] 2023-06-10 09:44:03,000 (trainer:721) INFO: 54epoch:train:848-924batch: iter_time=1.441e-04, forward_time=0.238, loss_ctc=9.937, loss=9.937, backward_time=0.311, optim_step_time=0.038, optim0_lr0=6.486e-04, train_time=0.630
[ALab02] 2023-06-10 09:44:51,348 (trainer:721) INFO: 54epoch:train:925-1001batch: iter_time=1.526e-04, forward_time=0.237, loss_ctc=10.212, loss=10.212, backward_time=0.309, optim_step_time=0.036, optim0_lr0=6.483e-04, train_time=0.628
[ALab02] 2023-06-10 09:45:38,420 (trainer:721) INFO: 54epoch:train:1002-1078batch: iter_time=1.519e-04, forward_time=0.228, loss_ctc=12.292, loss=12.292, backward_time=0.298, optim_step_time=0.038, optim0_lr0=6.480e-04, train_time=0.611
[ALab02] 2023-06-10 09:46:25,980 (trainer:721) INFO: 54epoch:train:1079-1155batch: iter_time=1.574e-04, forward_time=0.229, loss_ctc=10.785, loss=10.785, backward_time=0.307, optim_step_time=0.038, optim0_lr0=6.477e-04, train_time=0.617
[ALab02] 2023-06-10 09:47:12,509 (trainer:721) INFO: 54epoch:train:1156-1232batch: iter_time=1.056e-04, forward_time=0.226, loss_ctc=11.071, loss=11.071, backward_time=0.297, optim_step_time=0.037, optim0_lr0=6.474e-04, train_time=0.604
[ALab02] 2023-06-10 09:47:58,813 (trainer:721) INFO: 54epoch:train:1233-1309batch: iter_time=9.777e-05, forward_time=0.225, loss_ctc=10.439, loss=10.439, backward_time=0.300, optim_step_time=0.035, optim0_lr0=6.471e-04, train_time=0.601
[ALab02] 2023-06-10 09:48:46,119 (trainer:721) INFO: 54epoch:train:1310-1386batch: iter_time=1.458e-04, forward_time=0.229, loss_ctc=11.793, loss=11.793, backward_time=0.299, optim_step_time=0.041, optim0_lr0=6.468e-04, train_time=0.614
[ALab02] 2023-06-10 09:49:34,050 (trainer:721) INFO: 54epoch:train:1387-1463batch: iter_time=1.519e-04, forward_time=0.231, loss_ctc=10.841, loss=10.841, backward_time=0.307, optim_step_time=0.039, optim0_lr0=6.465e-04, train_time=0.622
[ALab02] 2023-06-10 09:50:21,696 (trainer:721) INFO: 54epoch:train:1464-1540batch: iter_time=1.368e-04, forward_time=0.231, loss_ctc=11.557, loss=11.557, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.462e-04, train_time=0.619
[ALab02] 2023-06-10 09:51:03,328 (trainer:338) INFO: 54epoch results: [train] iter_time=7.987e-04, forward_time=0.230, loss_ctc=10.891, loss=10.891, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.490e-04, train_time=0.616, time=15 minutes and 56.69 seconds, total_count=83862, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.178, cer_ctc=0.281, cer=0.281, loss=13.178, time=6.84 seconds, total_count=864, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.71 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 09:51:05,565 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 09:51:05,566 (trainer:272) INFO: 55/70epoch started. Estimated time to finish: 6 hours, 25 minutes and 17.51 seconds
[ALab02] 2023-06-10 09:51:53,498 (trainer:721) INFO: 55epoch:train:1-77batch: iter_time=0.013, forward_time=0.227, loss_ctc=10.453, loss=10.453, backward_time=0.301, optim_step_time=0.036, optim0_lr0=6.459e-04, train_time=0.622
[ALab02] 2023-06-10 09:52:40,838 (trainer:721) INFO: 55epoch:train:78-154batch: iter_time=1.471e-04, forward_time=0.231, loss_ctc=10.704, loss=10.704, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.456e-04, train_time=0.615
[ALab02] 2023-06-10 09:53:28,459 (trainer:721) INFO: 55epoch:train:155-231batch: iter_time=1.548e-04, forward_time=0.234, loss_ctc=9.548, loss=9.548, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.453e-04, train_time=0.618
[ALab02] 2023-06-10 09:54:15,643 (trainer:721) INFO: 55epoch:train:232-308batch: iter_time=1.513e-04, forward_time=0.229, loss_ctc=9.618, loss=9.618, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.450e-04, train_time=0.613
[ALab02] 2023-06-10 09:55:03,492 (trainer:721) INFO: 55epoch:train:309-385batch: iter_time=1.479e-04, forward_time=0.232, loss_ctc=11.410, loss=11.410, backward_time=0.312, optim_step_time=0.036, optim0_lr0=6.447e-04, train_time=0.621
[ALab02] 2023-06-10 09:55:50,094 (trainer:721) INFO: 55epoch:train:386-462batch: iter_time=1.735e-04, forward_time=0.225, loss_ctc=11.014, loss=11.014, backward_time=0.302, optim_step_time=0.038, optim0_lr0=6.444e-04, train_time=0.605
[ALab02] 2023-06-10 09:56:37,990 (trainer:721) INFO: 55epoch:train:463-539batch: iter_time=1.544e-04, forward_time=0.233, loss_ctc=10.024, loss=10.024, backward_time=0.310, optim_step_time=0.037, optim0_lr0=6.441e-04, train_time=0.622
[ALab02] 2023-06-10 09:57:25,444 (trainer:721) INFO: 55epoch:train:540-616batch: iter_time=1.302e-04, forward_time=0.230, loss_ctc=11.257, loss=11.257, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.438e-04, train_time=0.616
[ALab02] 2023-06-10 09:58:12,229 (trainer:721) INFO: 55epoch:train:617-693batch: iter_time=1.410e-04, forward_time=0.225, loss_ctc=10.899, loss=10.899, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.435e-04, train_time=0.607
[ALab02] 2023-06-10 09:58:58,428 (trainer:721) INFO: 55epoch:train:694-770batch: iter_time=1.358e-04, forward_time=0.223, loss_ctc=10.936, loss=10.936, backward_time=0.297, optim_step_time=0.037, optim0_lr0=6.432e-04, train_time=0.600
[ALab02] 2023-06-10 09:59:46,501 (trainer:721) INFO: 55epoch:train:771-847batch: iter_time=1.377e-04, forward_time=0.234, loss_ctc=11.052, loss=11.052, backward_time=0.309, optim_step_time=0.038, optim0_lr0=6.429e-04, train_time=0.624
[ALab02] 2023-06-10 10:00:34,871 (trainer:721) INFO: 55epoch:train:848-924batch: iter_time=1.535e-04, forward_time=0.236, loss_ctc=12.117, loss=12.117, backward_time=0.308, optim_step_time=0.037, optim0_lr0=6.426e-04, train_time=0.628
[ALab02] 2023-06-10 10:01:21,801 (trainer:721) INFO: 55epoch:train:925-1001batch: iter_time=1.326e-04, forward_time=0.230, loss_ctc=10.563, loss=10.563, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.423e-04, train_time=0.609
[ALab02] 2023-06-10 10:02:08,229 (trainer:721) INFO: 55epoch:train:1002-1078batch: iter_time=1.511e-04, forward_time=0.223, loss_ctc=12.035, loss=12.035, backward_time=0.300, optim_step_time=0.037, optim0_lr0=6.421e-04, train_time=0.603
[ALab02] 2023-06-10 10:02:55,615 (trainer:721) INFO: 55epoch:train:1079-1155batch: iter_time=1.158e-04, forward_time=0.232, loss_ctc=10.757, loss=10.757, backward_time=0.305, optim_step_time=0.035, optim0_lr0=6.418e-04, train_time=0.615
[ALab02] 2023-06-10 10:03:43,194 (trainer:721) INFO: 55epoch:train:1156-1232batch: iter_time=2.050e-04, forward_time=0.232, loss_ctc=9.932, loss=9.932, backward_time=0.305, optim_step_time=0.040, optim0_lr0=6.415e-04, train_time=0.618
[ALab02] 2023-06-10 10:04:30,632 (trainer:721) INFO: 55epoch:train:1233-1309batch: iter_time=1.668e-04, forward_time=0.230, loss_ctc=9.988, loss=9.988, backward_time=0.303, optim_step_time=0.040, optim0_lr0=6.412e-04, train_time=0.616
[ALab02] 2023-06-10 10:05:18,881 (trainer:721) INFO: 55epoch:train:1310-1386batch: iter_time=1.742e-04, forward_time=0.236, loss_ctc=9.954, loss=9.954, backward_time=0.304, optim_step_time=0.042, optim0_lr0=6.409e-04, train_time=0.626
[ALab02] 2023-06-10 10:06:06,165 (trainer:721) INFO: 55epoch:train:1387-1463batch: iter_time=1.271e-04, forward_time=0.228, loss_ctc=10.674, loss=10.674, backward_time=0.306, optim_step_time=0.036, optim0_lr0=6.406e-04, train_time=0.614
[ALab02] 2023-06-10 10:06:54,005 (trainer:721) INFO: 55epoch:train:1464-1540batch: iter_time=1.805e-04, forward_time=0.238, loss_ctc=11.182, loss=11.182, backward_time=0.300, optim_step_time=0.040, optim0_lr0=6.403e-04, train_time=0.621
[ALab02] 2023-06-10 10:07:36,297 (trainer:338) INFO: 55epoch results: [train] iter_time=7.691e-04, forward_time=0.230, loss_ctc=10.687, loss=10.687, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.431e-04, train_time=0.615, time=15 minutes and 56.38 seconds, total_count=85415, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.700, cer_ctc=0.284, cer=0.284, loss=13.700, time=6.73 seconds, total_count=880, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.63 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 10:07:38,481 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 10:07:38,495 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/54epoch.pth
[ALab02] 2023-06-10 10:07:38,495 (trainer:272) INFO: 56/70epoch started. Estimated time to finish: 5 hours, 59 minutes and 9.42 seconds
[ALab02] 2023-06-10 10:08:27,886 (trainer:721) INFO: 56epoch:train:1-77batch: iter_time=0.015, forward_time=0.235, loss_ctc=11.364, loss=11.364, backward_time=0.309, optim_step_time=0.040, optim0_lr0=6.400e-04, train_time=0.641
[ALab02] 2023-06-10 10:09:16,667 (trainer:721) INFO: 56epoch:train:78-154batch: iter_time=1.472e-04, forward_time=0.236, loss_ctc=11.869, loss=11.869, backward_time=0.307, optim_step_time=0.039, optim0_lr0=6.397e-04, train_time=0.633
[ALab02] 2023-06-10 10:10:04,591 (trainer:721) INFO: 56epoch:train:155-231batch: iter_time=1.564e-04, forward_time=0.234, loss_ctc=10.664, loss=10.664, backward_time=0.309, optim_step_time=0.037, optim0_lr0=6.394e-04, train_time=0.622
[ALab02] 2023-06-10 10:10:51,877 (trainer:721) INFO: 56epoch:train:232-308batch: iter_time=1.459e-04, forward_time=0.232, loss_ctc=12.247, loss=12.247, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.391e-04, train_time=0.614
[ALab02] 2023-06-10 10:11:39,183 (trainer:721) INFO: 56epoch:train:309-385batch: iter_time=1.409e-04, forward_time=0.228, loss_ctc=10.337, loss=10.337, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.388e-04, train_time=0.614
[ALab02] 2023-06-10 10:12:26,626 (trainer:721) INFO: 56epoch:train:386-462batch: iter_time=1.605e-04, forward_time=0.232, loss_ctc=11.324, loss=11.324, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.385e-04, train_time=0.616
[ALab02] 2023-06-10 10:13:13,050 (trainer:721) INFO: 56epoch:train:463-539batch: iter_time=1.288e-04, forward_time=0.224, loss_ctc=10.653, loss=10.653, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.383e-04, train_time=0.603
[ALab02] 2023-06-10 10:13:59,276 (trainer:721) INFO: 56epoch:train:540-616batch: iter_time=1.505e-04, forward_time=0.220, loss_ctc=10.836, loss=10.836, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.380e-04, train_time=0.600
[ALab02] 2023-06-10 10:14:48,346 (trainer:721) INFO: 56epoch:train:617-693batch: iter_time=1.867e-04, forward_time=0.242, loss_ctc=9.335, loss=9.335, backward_time=0.315, optim_step_time=0.037, optim0_lr0=6.377e-04, train_time=0.637
[ALab02] 2023-06-10 10:15:36,476 (trainer:721) INFO: 56epoch:train:694-770batch: iter_time=1.926e-04, forward_time=0.238, loss_ctc=8.819, loss=8.819, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.374e-04, train_time=0.625
[ALab02] 2023-06-10 10:16:22,320 (trainer:721) INFO: 56epoch:train:771-847batch: iter_time=1.473e-04, forward_time=0.218, loss_ctc=11.382, loss=11.382, backward_time=0.299, optim_step_time=0.036, optim0_lr0=6.371e-04, train_time=0.595
[ALab02] 2023-06-10 10:17:09,137 (trainer:721) INFO: 56epoch:train:848-924batch: iter_time=1.711e-04, forward_time=0.227, loss_ctc=9.008, loss=9.008, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.368e-04, train_time=0.608
[ALab02] 2023-06-10 10:17:56,204 (trainer:721) INFO: 56epoch:train:925-1001batch: iter_time=1.484e-04, forward_time=0.227, loss_ctc=11.225, loss=11.225, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.365e-04, train_time=0.611
[ALab02] 2023-06-10 10:18:42,588 (trainer:721) INFO: 56epoch:train:1002-1078batch: iter_time=1.649e-04, forward_time=0.224, loss_ctc=10.456, loss=10.456, backward_time=0.298, optim_step_time=0.037, optim0_lr0=6.363e-04, train_time=0.602
[ALab02] 2023-06-10 10:19:29,416 (trainer:721) INFO: 56epoch:train:1079-1155batch: iter_time=1.570e-04, forward_time=0.228, loss_ctc=9.572, loss=9.572, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.360e-04, train_time=0.608
[ALab02] 2023-06-10 10:20:16,219 (trainer:721) INFO: 56epoch:train:1156-1232batch: iter_time=1.759e-04, forward_time=0.228, loss_ctc=10.927, loss=10.927, backward_time=0.298, optim_step_time=0.040, optim0_lr0=6.357e-04, train_time=0.608
[ALab02] 2023-06-10 10:21:03,538 (trainer:721) INFO: 56epoch:train:1233-1309batch: iter_time=1.658e-04, forward_time=0.228, loss_ctc=10.918, loss=10.918, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.354e-04, train_time=0.614
[ALab02] 2023-06-10 10:21:51,139 (trainer:721) INFO: 56epoch:train:1310-1386batch: iter_time=1.441e-04, forward_time=0.230, loss_ctc=10.710, loss=10.710, backward_time=0.309, optim_step_time=0.037, optim0_lr0=6.351e-04, train_time=0.618
[ALab02] 2023-06-10 10:22:38,435 (trainer:721) INFO: 56epoch:train:1387-1463batch: iter_time=1.638e-04, forward_time=0.230, loss_ctc=10.158, loss=10.158, backward_time=0.308, optim_step_time=0.036, optim0_lr0=6.349e-04, train_time=0.614
[ALab02] 2023-06-10 10:23:25,570 (trainer:721) INFO: 56epoch:train:1464-1540batch: iter_time=1.715e-04, forward_time=0.226, loss_ctc=10.682, loss=10.682, backward_time=0.303, optim_step_time=0.039, optim0_lr0=6.346e-04, train_time=0.612
[ALab02] 2023-06-10 10:24:06,672 (trainer:338) INFO: 56epoch results: [train] iter_time=8.961e-04, forward_time=0.229, loss_ctc=10.571, loss=10.571, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.372e-04, train_time=0.615, time=15 minutes and 55.33 seconds, total_count=86968, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.112, cer_ctc=0.282, cer=0.282, loss=13.112, time=6.64 seconds, total_count=896, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.21 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 10:24:08,685 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 10:24:08,698 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/55epoch.pth
[ALab02] 2023-06-10 10:24:08,699 (trainer:272) INFO: 57/70epoch started. Estimated time to finish: 5 hours, 33 minutes and 21.18 seconds
[ALab02] 2023-06-10 10:24:56,404 (trainer:721) INFO: 57epoch:train:1-77batch: iter_time=0.014, forward_time=0.222, loss_ctc=11.415, loss=11.415, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.342e-04, train_time=0.619
[ALab02] 2023-06-10 10:25:44,504 (trainer:721) INFO: 57epoch:train:78-154batch: iter_time=2.095e-04, forward_time=0.235, loss_ctc=10.382, loss=10.382, backward_time=0.310, optim_step_time=0.037, optim0_lr0=6.340e-04, train_time=0.624
[ALab02] 2023-06-10 10:26:30,767 (trainer:721) INFO: 57epoch:train:155-231batch: iter_time=1.429e-04, forward_time=0.224, loss_ctc=11.339, loss=11.339, backward_time=0.301, optim_step_time=0.035, optim0_lr0=6.337e-04, train_time=0.601
[ALab02] 2023-06-10 10:27:20,185 (trainer:721) INFO: 57epoch:train:232-308batch: iter_time=7.933e-04, forward_time=0.246, loss_ctc=9.613, loss=9.613, backward_time=0.306, optim_step_time=0.043, optim0_lr0=6.334e-04, train_time=0.642
[ALab02] 2023-06-10 10:28:08,157 (trainer:721) INFO: 57epoch:train:309-385batch: iter_time=1.370e-04, forward_time=0.235, loss_ctc=10.461, loss=10.461, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.331e-04, train_time=0.623
[ALab02] 2023-06-10 10:28:56,097 (trainer:721) INFO: 57epoch:train:386-462batch: iter_time=1.548e-04, forward_time=0.232, loss_ctc=11.631, loss=11.631, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.328e-04, train_time=0.622
[ALab02] 2023-06-10 10:29:43,563 (trainer:721) INFO: 57epoch:train:463-539batch: iter_time=1.347e-04, forward_time=0.231, loss_ctc=10.177, loss=10.177, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.326e-04, train_time=0.616
[ALab02] 2023-06-10 10:30:30,408 (trainer:721) INFO: 57epoch:train:540-616batch: iter_time=1.337e-04, forward_time=0.225, loss_ctc=11.427, loss=11.427, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.323e-04, train_time=0.608
[ALab02] 2023-06-10 10:31:16,996 (trainer:721) INFO: 57epoch:train:617-693batch: iter_time=1.436e-04, forward_time=0.223, loss_ctc=11.194, loss=11.194, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.320e-04, train_time=0.605
[ALab02] 2023-06-10 10:32:04,098 (trainer:721) INFO: 57epoch:train:694-770batch: iter_time=1.243e-04, forward_time=0.230, loss_ctc=9.871, loss=9.871, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.317e-04, train_time=0.611
[ALab02] 2023-06-10 10:32:51,107 (trainer:721) INFO: 57epoch:train:771-847batch: iter_time=1.247e-04, forward_time=0.229, loss_ctc=9.362, loss=9.362, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.315e-04, train_time=0.610
[ALab02] 2023-06-10 10:33:39,002 (trainer:721) INFO: 57epoch:train:848-924batch: iter_time=1.102e-04, forward_time=0.234, loss_ctc=9.766, loss=9.766, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.312e-04, train_time=0.622
[ALab02] 2023-06-10 10:34:25,531 (trainer:721) INFO: 57epoch:train:925-1001batch: iter_time=1.114e-04, forward_time=0.224, loss_ctc=10.917, loss=10.917, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.309e-04, train_time=0.604
[ALab02] 2023-06-10 10:35:12,423 (trainer:721) INFO: 57epoch:train:1002-1078batch: iter_time=1.358e-04, forward_time=0.226, loss_ctc=10.955, loss=10.955, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.306e-04, train_time=0.609
[ALab02] 2023-06-10 10:36:00,475 (trainer:721) INFO: 57epoch:train:1079-1155batch: iter_time=1.531e-04, forward_time=0.235, loss_ctc=10.973, loss=10.973, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.303e-04, train_time=0.624
[ALab02] 2023-06-10 10:36:47,709 (trainer:721) INFO: 57epoch:train:1156-1232batch: iter_time=1.722e-04, forward_time=0.233, loss_ctc=9.630, loss=9.630, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.301e-04, train_time=0.613
[ALab02] 2023-06-10 10:37:34,640 (trainer:721) INFO: 57epoch:train:1233-1309batch: iter_time=1.727e-04, forward_time=0.227, loss_ctc=9.561, loss=9.561, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.298e-04, train_time=0.609
[ALab02] 2023-06-10 10:38:21,720 (trainer:721) INFO: 57epoch:train:1310-1386batch: iter_time=1.343e-04, forward_time=0.229, loss_ctc=10.131, loss=10.131, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.295e-04, train_time=0.611
[ALab02] 2023-06-10 10:39:08,273 (trainer:721) INFO: 57epoch:train:1387-1463batch: iter_time=1.344e-04, forward_time=0.225, loss_ctc=11.294, loss=11.294, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.292e-04, train_time=0.604
[ALab02] 2023-06-10 10:39:55,776 (trainer:721) INFO: 57epoch:train:1464-1540batch: iter_time=1.302e-04, forward_time=0.230, loss_ctc=10.832, loss=10.832, backward_time=0.309, optim_step_time=0.036, optim0_lr0=6.290e-04, train_time=0.617
[ALab02] 2023-06-10 10:40:38,077 (trainer:338) INFO: 57epoch results: [train] iter_time=8.834e-04, forward_time=0.230, loss_ctc=10.503, loss=10.503, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.316e-04, train_time=0.615, time=15 minutes and 54.9 seconds, total_count=88521, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.177, cer_ctc=0.277, cer=0.277, loss=14.177, time=6.75 seconds, total_count=912, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.72 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 10:40:40,281 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 10:40:40,308 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/32epoch.pth, exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/56epoch.pth
[ALab02] 2023-06-10 10:40:40,309 (trainer:272) INFO: 58/70epoch started. Estimated time to finish: 5 hours, 7 minutes and 52.85 seconds
[ALab02] 2023-06-10 10:41:29,406 (trainer:721) INFO: 58epoch:train:1-77batch: iter_time=0.015, forward_time=0.237, loss_ctc=9.906, loss=9.906, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.287e-04, train_time=0.637
[ALab02] 2023-06-10 10:42:16,442 (trainer:721) INFO: 58epoch:train:78-154batch: iter_time=1.641e-04, forward_time=0.230, loss_ctc=9.489, loss=9.489, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.284e-04, train_time=0.611
[ALab02] 2023-06-10 10:43:03,596 (trainer:721) INFO: 58epoch:train:155-231batch: iter_time=1.540e-04, forward_time=0.231, loss_ctc=11.230, loss=11.230, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.281e-04, train_time=0.612
[ALab02] 2023-06-10 10:43:51,110 (trainer:721) INFO: 58epoch:train:232-308batch: iter_time=1.430e-04, forward_time=0.229, loss_ctc=11.017, loss=11.017, backward_time=0.307, optim_step_time=0.038, optim0_lr0=6.278e-04, train_time=0.617
[ALab02] 2023-06-10 10:44:37,530 (trainer:721) INFO: 58epoch:train:309-385batch: iter_time=1.295e-04, forward_time=0.224, loss_ctc=10.235, loss=10.235, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.276e-04, train_time=0.603
[ALab02] 2023-06-10 10:45:25,420 (trainer:721) INFO: 58epoch:train:386-462batch: iter_time=3.042e-04, forward_time=0.232, loss_ctc=11.693, loss=11.693, backward_time=0.300, optim_step_time=0.043, optim0_lr0=6.273e-04, train_time=0.622
[ALab02] 2023-06-10 10:46:12,747 (trainer:721) INFO: 58epoch:train:463-539batch: iter_time=1.460e-04, forward_time=0.231, loss_ctc=9.861, loss=9.861, backward_time=0.306, optim_step_time=0.038, optim0_lr0=6.270e-04, train_time=0.614
[ALab02] 2023-06-10 10:47:00,180 (trainer:721) INFO: 58epoch:train:540-616batch: iter_time=1.609e-04, forward_time=0.231, loss_ctc=10.129, loss=10.129, backward_time=0.306, optim_step_time=0.038, optim0_lr0=6.268e-04, train_time=0.616
[ALab02] 2023-06-10 10:47:48,778 (trainer:721) INFO: 58epoch:train:617-693batch: iter_time=1.413e-04, forward_time=0.237, loss_ctc=8.440, loss=8.440, backward_time=0.311, optim_step_time=0.037, optim0_lr0=6.265e-04, train_time=0.631
[ALab02] 2023-06-10 10:48:36,321 (trainer:721) INFO: 58epoch:train:694-770batch: iter_time=1.494e-04, forward_time=0.232, loss_ctc=10.550, loss=10.550, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.262e-04, train_time=0.617
[ALab02] 2023-06-10 10:49:22,965 (trainer:721) INFO: 58epoch:train:771-847batch: iter_time=1.179e-04, forward_time=0.228, loss_ctc=10.754, loss=10.754, backward_time=0.298, optim_step_time=0.037, optim0_lr0=6.259e-04, train_time=0.606
[ALab02] 2023-06-10 10:50:10,556 (trainer:721) INFO: 58epoch:train:848-924batch: iter_time=1.301e-04, forward_time=0.230, loss_ctc=10.890, loss=10.890, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.257e-04, train_time=0.618
[ALab02] 2023-06-10 10:50:58,522 (trainer:721) INFO: 58epoch:train:925-1001batch: iter_time=1.489e-04, forward_time=0.235, loss_ctc=9.850, loss=9.850, backward_time=0.306, optim_step_time=0.038, optim0_lr0=6.254e-04, train_time=0.623
[ALab02] 2023-06-10 10:51:46,048 (trainer:721) INFO: 58epoch:train:1002-1078batch: iter_time=1.317e-04, forward_time=0.232, loss_ctc=10.158, loss=10.158, backward_time=0.306, optim_step_time=0.036, optim0_lr0=6.251e-04, train_time=0.617
[ALab02] 2023-06-10 10:52:32,858 (trainer:721) INFO: 58epoch:train:1079-1155batch: iter_time=1.336e-04, forward_time=0.226, loss_ctc=10.649, loss=10.649, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.249e-04, train_time=0.608
[ALab02] 2023-06-10 10:53:19,757 (trainer:721) INFO: 58epoch:train:1156-1232batch: iter_time=1.212e-04, forward_time=0.226, loss_ctc=11.690, loss=11.690, backward_time=0.304, optim_step_time=0.036, optim0_lr0=6.246e-04, train_time=0.609
[ALab02] 2023-06-10 10:54:07,330 (trainer:721) INFO: 58epoch:train:1233-1309batch: iter_time=1.323e-04, forward_time=0.230, loss_ctc=12.022, loss=12.022, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.243e-04, train_time=0.618
[ALab02] 2023-06-10 10:54:53,715 (trainer:721) INFO: 58epoch:train:1310-1386batch: iter_time=1.384e-04, forward_time=0.225, loss_ctc=9.084, loss=9.084, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.241e-04, train_time=0.602
[ALab02] 2023-06-10 10:55:40,840 (trainer:721) INFO: 58epoch:train:1387-1463batch: iter_time=1.306e-04, forward_time=0.229, loss_ctc=11.489, loss=11.489, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.238e-04, train_time=0.612
[ALab02] 2023-06-10 10:56:27,741 (trainer:721) INFO: 58epoch:train:1464-1540batch: iter_time=1.251e-04, forward_time=0.224, loss_ctc=10.663, loss=10.663, backward_time=0.306, optim_step_time=0.038, optim0_lr0=6.235e-04, train_time=0.609
[ALab02] 2023-06-10 10:57:09,245 (trainer:338) INFO: 58epoch results: [train] iter_time=8.885e-04, forward_time=0.230, loss_ctc=10.446, loss=10.446, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.261e-04, train_time=0.615, time=15 minutes and 55.48 seconds, total_count=90074, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.649, cer_ctc=0.282, cer=0.282, loss=13.649, time=6.72 seconds, total_count=928, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.73 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 10:57:11,473 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 10:57:11,474 (trainer:272) INFO: 59/70epoch started. Estimated time to finish: 4 hours, 42 minutes and 42.93 seconds
[ALab02] 2023-06-10 10:57:59,763 (trainer:721) INFO: 59epoch:train:1-77batch: iter_time=0.013, forward_time=0.228, loss_ctc=9.776, loss=9.776, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.232e-04, train_time=0.627
[ALab02] 2023-06-10 10:58:47,180 (trainer:721) INFO: 59epoch:train:78-154batch: iter_time=1.560e-04, forward_time=0.233, loss_ctc=11.543, loss=11.543, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.229e-04, train_time=0.616
[ALab02] 2023-06-10 10:59:34,119 (trainer:721) INFO: 59epoch:train:155-231batch: iter_time=1.572e-04, forward_time=0.229, loss_ctc=10.336, loss=10.336, backward_time=0.300, optim_step_time=0.038, optim0_lr0=6.227e-04, train_time=0.609
[ALab02] 2023-06-10 11:00:20,807 (trainer:721) INFO: 59epoch:train:232-308batch: iter_time=2.703e-04, forward_time=0.223, loss_ctc=11.768, loss=11.768, backward_time=0.302, optim_step_time=0.036, optim0_lr0=6.224e-04, train_time=0.606
[ALab02] 2023-06-10 11:01:08,848 (trainer:721) INFO: 59epoch:train:309-385batch: iter_time=1.472e-04, forward_time=0.235, loss_ctc=11.305, loss=11.305, backward_time=0.305, optim_step_time=0.039, optim0_lr0=6.222e-04, train_time=0.624
[ALab02] 2023-06-10 11:01:55,101 (trainer:721) INFO: 59epoch:train:386-462batch: iter_time=1.493e-04, forward_time=0.221, loss_ctc=10.353, loss=10.353, backward_time=0.300, optim_step_time=0.037, optim0_lr0=6.219e-04, train_time=0.600
[ALab02] 2023-06-10 11:02:42,872 (trainer:721) INFO: 59epoch:train:463-539batch: iter_time=1.691e-04, forward_time=0.231, loss_ctc=9.550, loss=9.550, backward_time=0.308, optim_step_time=0.037, optim0_lr0=6.216e-04, train_time=0.620
[ALab02] 2023-06-10 11:03:30,536 (trainer:721) INFO: 59epoch:train:540-616batch: iter_time=3.051e-04, forward_time=0.233, loss_ctc=11.179, loss=11.179, backward_time=0.303, optim_step_time=0.041, optim0_lr0=6.214e-04, train_time=0.619
[ALab02] 2023-06-10 11:04:18,185 (trainer:721) INFO: 59epoch:train:617-693batch: iter_time=1.793e-04, forward_time=0.235, loss_ctc=8.541, loss=8.541, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.211e-04, train_time=0.619
[ALab02] 2023-06-10 11:05:07,561 (trainer:721) INFO: 59epoch:train:694-770batch: iter_time=1.562e-04, forward_time=0.245, loss_ctc=9.604, loss=9.604, backward_time=0.313, optim_step_time=0.038, optim0_lr0=6.208e-04, train_time=0.641
[ALab02] 2023-06-10 11:05:54,888 (trainer:721) INFO: 59epoch:train:771-847batch: iter_time=1.359e-04, forward_time=0.234, loss_ctc=10.572, loss=10.572, backward_time=0.303, optim_step_time=0.036, optim0_lr0=6.206e-04, train_time=0.614
[ALab02] 2023-06-10 11:06:41,996 (trainer:721) INFO: 59epoch:train:848-924batch: iter_time=1.191e-04, forward_time=0.228, loss_ctc=11.019, loss=11.019, backward_time=0.300, optim_step_time=0.038, optim0_lr0=6.203e-04, train_time=0.612
[ALab02] 2023-06-10 11:07:29,911 (trainer:721) INFO: 59epoch:train:925-1001batch: iter_time=1.577e-04, forward_time=0.233, loss_ctc=10.581, loss=10.581, backward_time=0.308, optim_step_time=0.039, optim0_lr0=6.200e-04, train_time=0.622
[ALab02] 2023-06-10 11:08:16,902 (trainer:721) INFO: 59epoch:train:1002-1078batch: iter_time=1.540e-04, forward_time=0.231, loss_ctc=8.758, loss=8.758, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.198e-04, train_time=0.610
[ALab02] 2023-06-10 11:09:03,296 (trainer:721) INFO: 59epoch:train:1079-1155batch: iter_time=1.396e-04, forward_time=0.223, loss_ctc=10.241, loss=10.241, backward_time=0.301, optim_step_time=0.036, optim0_lr0=6.195e-04, train_time=0.602
[ALab02] 2023-06-10 11:09:51,071 (trainer:721) INFO: 59epoch:train:1156-1232batch: iter_time=1.463e-04, forward_time=0.233, loss_ctc=10.152, loss=10.152, backward_time=0.308, optim_step_time=0.037, optim0_lr0=6.193e-04, train_time=0.620
[ALab02] 2023-06-10 11:10:38,107 (trainer:721) INFO: 59epoch:train:1233-1309batch: iter_time=1.561e-04, forward_time=0.228, loss_ctc=10.025, loss=10.025, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.190e-04, train_time=0.611
[ALab02] 2023-06-10 11:11:25,815 (trainer:721) INFO: 59epoch:train:1310-1386batch: iter_time=1.544e-04, forward_time=0.233, loss_ctc=10.662, loss=10.662, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.187e-04, train_time=0.619
[ALab02] 2023-06-10 11:12:12,993 (trainer:721) INFO: 59epoch:train:1387-1463batch: iter_time=1.296e-04, forward_time=0.230, loss_ctc=10.667, loss=10.667, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.185e-04, train_time=0.612
[ALab02] 2023-06-10 11:13:01,064 (trainer:721) INFO: 59epoch:train:1464-1540batch: iter_time=1.619e-04, forward_time=0.231, loss_ctc=11.437, loss=11.437, backward_time=0.311, optim_step_time=0.037, optim0_lr0=6.182e-04, train_time=0.624
[ALab02] 2023-06-10 11:13:43,398 (trainer:338) INFO: 59epoch results: [train] iter_time=8.214e-04, forward_time=0.231, loss_ctc=10.357, loss=10.357, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.207e-04, train_time=0.616, time=15 minutes and 57.74 seconds, total_count=91627, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.973, cer_ctc=0.281, cer=0.281, loss=13.973, time=6.73 seconds, total_count=944, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.46 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 11:13:45,667 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 11:13:45,682 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/58epoch.pth
[ALab02] 2023-06-10 11:13:45,682 (trainer:272) INFO: 60/70epoch started. Estimated time to finish: 4 hours, 17 minutes and 51.17 seconds
[ALab02] 2023-06-10 11:14:35,090 (trainer:721) INFO: 60epoch:train:1-77batch: iter_time=0.015, forward_time=0.235, loss_ctc=9.142, loss=9.142, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.179e-04, train_time=0.641
[ALab02] 2023-06-10 11:15:23,409 (trainer:721) INFO: 60epoch:train:78-154batch: iter_time=1.999e-04, forward_time=0.236, loss_ctc=9.644, loss=9.644, backward_time=0.310, optim_step_time=0.039, optim0_lr0=6.177e-04, train_time=0.627
[ALab02] 2023-06-10 11:16:14,167 (trainer:721) INFO: 60epoch:train:155-231batch: iter_time=2.467e-04, forward_time=0.256, loss_ctc=10.223, loss=10.223, backward_time=0.304, optim_step_time=0.050, optim0_lr0=6.174e-04, train_time=0.659
[ALab02] 2023-06-10 11:17:06,682 (trainer:721) INFO: 60epoch:train:232-308batch: iter_time=3.469e-04, forward_time=0.266, loss_ctc=9.681, loss=9.681, backward_time=0.308, optim_step_time=0.055, optim0_lr0=6.171e-04, train_time=0.682
[ALab02] 2023-06-10 11:17:58,966 (trainer:721) INFO: 60epoch:train:309-385batch: iter_time=3.440e-04, forward_time=0.262, loss_ctc=10.360, loss=10.360, backward_time=0.305, optim_step_time=0.059, optim0_lr0=6.169e-04, train_time=0.679
[ALab02] 2023-06-10 11:18:52,822 (trainer:721) INFO: 60epoch:train:386-462batch: iter_time=3.306e-04, forward_time=0.277, loss_ctc=9.849, loss=9.849, backward_time=0.310, optim_step_time=0.059, optim0_lr0=6.166e-04, train_time=0.699
[ALab02] 2023-06-10 11:19:45,677 (trainer:721) INFO: 60epoch:train:463-539batch: iter_time=2.728e-04, forward_time=0.271, loss_ctc=10.972, loss=10.972, backward_time=0.312, optim_step_time=0.055, optim0_lr0=6.164e-04, train_time=0.686
[ALab02] 2023-06-10 11:20:38,580 (trainer:721) INFO: 60epoch:train:540-616batch: iter_time=3.115e-04, forward_time=0.271, loss_ctc=10.517, loss=10.517, backward_time=0.307, optim_step_time=0.060, optim0_lr0=6.161e-04, train_time=0.687
[ALab02] 2023-06-10 11:21:32,923 (trainer:721) INFO: 60epoch:train:617-693batch: iter_time=3.255e-04, forward_time=0.282, loss_ctc=9.891, loss=9.891, backward_time=0.313, optim_step_time=0.057, optim0_lr0=6.158e-04, train_time=0.705
[ALab02] 2023-06-10 11:22:28,768 (trainer:721) INFO: 60epoch:train:694-770batch: iter_time=6.231e-04, forward_time=0.293, loss_ctc=9.878, loss=9.878, backward_time=0.313, optim_step_time=0.064, optim0_lr0=6.156e-04, train_time=0.725
[ALab02] 2023-06-10 11:23:22,948 (trainer:721) INFO: 60epoch:train:771-847batch: iter_time=3.317e-04, forward_time=0.285, loss_ctc=8.896, loss=8.896, backward_time=0.303, optim_step_time=0.062, optim0_lr0=6.153e-04, train_time=0.703
[ALab02] 2023-06-10 11:24:16,622 (trainer:721) INFO: 60epoch:train:848-924batch: iter_time=3.430e-04, forward_time=0.276, loss_ctc=9.959, loss=9.959, backward_time=0.305, optim_step_time=0.061, optim0_lr0=6.151e-04, train_time=0.697
[ALab02] 2023-06-10 11:25:09,608 (trainer:721) INFO: 60epoch:train:925-1001batch: iter_time=5.432e-04, forward_time=0.272, loss_ctc=9.848, loss=9.848, backward_time=0.307, optim_step_time=0.059, optim0_lr0=6.148e-04, train_time=0.688
[ALab02] 2023-06-10 11:26:00,411 (trainer:721) INFO: 60epoch:train:1002-1078batch: iter_time=2.079e-04, forward_time=0.255, loss_ctc=11.743, loss=11.743, backward_time=0.308, optim_step_time=0.050, optim0_lr0=6.146e-04, train_time=0.659
[ALab02] 2023-06-10 11:26:50,409 (trainer:721) INFO: 60epoch:train:1079-1155batch: iter_time=2.530e-04, forward_time=0.251, loss_ctc=11.013, loss=11.013, backward_time=0.307, optim_step_time=0.047, optim0_lr0=6.143e-04, train_time=0.649
[ALab02] 2023-06-10 11:27:41,493 (trainer:721) INFO: 60epoch:train:1156-1232batch: iter_time=2.691e-04, forward_time=0.258, loss_ctc=10.924, loss=10.924, backward_time=0.307, optim_step_time=0.046, optim0_lr0=6.141e-04, train_time=0.663
[ALab02] 2023-06-10 11:28:29,943 (trainer:721) INFO: 60epoch:train:1233-1309batch: iter_time=1.736e-04, forward_time=0.237, loss_ctc=10.811, loss=10.811, backward_time=0.308, optim_step_time=0.041, optim0_lr0=6.138e-04, train_time=0.629
[ALab02] 2023-06-10 11:29:17,776 (trainer:721) INFO: 60epoch:train:1310-1386batch: iter_time=1.448e-04, forward_time=0.234, loss_ctc=10.486, loss=10.486, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.135e-04, train_time=0.621
[ALab02] 2023-06-10 11:30:05,283 (trainer:721) INFO: 60epoch:train:1387-1463batch: iter_time=2.084e-04, forward_time=0.231, loss_ctc=10.884, loss=10.884, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.133e-04, train_time=0.617
[ALab02] 2023-06-10 11:30:52,923 (trainer:721) INFO: 60epoch:train:1464-1540batch: iter_time=1.644e-04, forward_time=0.231, loss_ctc=9.097, loss=9.097, backward_time=0.306, optim_step_time=0.038, optim0_lr0=6.130e-04, train_time=0.618
[ALab02] 2023-06-10 11:31:35,301 (trainer:338) INFO: 60epoch results: [train] iter_time=0.001, forward_time=0.259, loss_ctc=10.176, loss=10.176, backward_time=0.307, optim_step_time=0.051, optim0_lr0=6.154e-04, train_time=0.666, time=17 minutes and 15.46 seconds, total_count=93180, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.803, cer_ctc=0.281, cer=0.281, loss=13.803, time=6.71 seconds, total_count=960, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.44 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 11:31:37,786 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 11:31:37,804 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/59epoch.pth
[ALab02] 2023-06-10 11:31:37,804 (trainer:272) INFO: 61/70epoch started. Estimated time to finish: 3 hours, 53 minutes and 28.97 seconds
[ALab02] 2023-06-10 11:32:26,612 (trainer:721) INFO: 61epoch:train:1-77batch: iter_time=0.014, forward_time=0.234, loss_ctc=9.178, loss=9.178, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.127e-04, train_time=0.634
[ALab02] 2023-06-10 11:33:14,760 (trainer:721) INFO: 61epoch:train:78-154batch: iter_time=1.385e-04, forward_time=0.236, loss_ctc=9.167, loss=9.167, backward_time=0.306, optim_step_time=0.040, optim0_lr0=6.125e-04, train_time=0.625
[ALab02] 2023-06-10 11:34:02,597 (trainer:721) INFO: 61epoch:train:155-231batch: iter_time=1.292e-04, forward_time=0.232, loss_ctc=10.794, loss=10.794, backward_time=0.304, optim_step_time=0.040, optim0_lr0=6.122e-04, train_time=0.621
[ALab02] 2023-06-10 11:34:50,152 (trainer:721) INFO: 61epoch:train:232-308batch: iter_time=1.490e-04, forward_time=0.230, loss_ctc=10.282, loss=10.282, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.120e-04, train_time=0.617
[ALab02] 2023-06-10 11:35:37,378 (trainer:721) INFO: 61epoch:train:309-385batch: iter_time=1.356e-04, forward_time=0.229, loss_ctc=11.379, loss=11.379, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.117e-04, train_time=0.613
[ALab02] 2023-06-10 11:36:25,972 (trainer:721) INFO: 61epoch:train:386-462batch: iter_time=1.963e-04, forward_time=0.238, loss_ctc=9.422, loss=9.422, backward_time=0.309, optim_step_time=0.038, optim0_lr0=6.115e-04, train_time=0.631
[ALab02] 2023-06-10 11:37:12,901 (trainer:721) INFO: 61epoch:train:463-539batch: iter_time=1.516e-04, forward_time=0.227, loss_ctc=11.142, loss=11.142, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.112e-04, train_time=0.609
[ALab02] 2023-06-10 11:38:00,326 (trainer:721) INFO: 61epoch:train:540-616batch: iter_time=1.642e-04, forward_time=0.229, loss_ctc=10.668, loss=10.668, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.110e-04, train_time=0.616
[ALab02] 2023-06-10 11:38:48,824 (trainer:721) INFO: 61epoch:train:617-693batch: iter_time=1.715e-04, forward_time=0.240, loss_ctc=9.870, loss=9.870, backward_time=0.306, optim_step_time=0.039, optim0_lr0=6.107e-04, train_time=0.630
[ALab02] 2023-06-10 11:39:36,049 (trainer:721) INFO: 61epoch:train:694-770batch: iter_time=1.467e-04, forward_time=0.230, loss_ctc=10.067, loss=10.067, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.105e-04, train_time=0.613
[ALab02] 2023-06-10 11:40:23,649 (trainer:721) INFO: 61epoch:train:771-847batch: iter_time=1.526e-04, forward_time=0.233, loss_ctc=8.245, loss=8.245, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.102e-04, train_time=0.618
[ALab02] 2023-06-10 11:41:12,632 (trainer:721) INFO: 61epoch:train:848-924batch: iter_time=2.987e-04, forward_time=0.237, loss_ctc=10.207, loss=10.207, backward_time=0.310, optim_step_time=0.043, optim0_lr0=6.100e-04, train_time=0.636
[ALab02] 2023-06-10 11:41:59,994 (trainer:721) INFO: 61epoch:train:925-1001batch: iter_time=1.591e-04, forward_time=0.231, loss_ctc=9.316, loss=9.316, backward_time=0.303, optim_step_time=0.038, optim0_lr0=6.097e-04, train_time=0.615
[ALab02] 2023-06-10 11:42:46,810 (trainer:721) INFO: 61epoch:train:1002-1078batch: iter_time=1.600e-04, forward_time=0.228, loss_ctc=9.772, loss=9.772, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.095e-04, train_time=0.608
[ALab02] 2023-06-10 11:43:33,994 (trainer:721) INFO: 61epoch:train:1079-1155batch: iter_time=1.593e-04, forward_time=0.228, loss_ctc=10.718, loss=10.718, backward_time=0.300, optim_step_time=0.040, optim0_lr0=6.092e-04, train_time=0.613
[ALab02] 2023-06-10 11:44:20,918 (trainer:721) INFO: 61epoch:train:1156-1232batch: iter_time=1.394e-04, forward_time=0.226, loss_ctc=11.559, loss=11.559, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.090e-04, train_time=0.609
[ALab02] 2023-06-10 11:45:08,753 (trainer:721) INFO: 61epoch:train:1233-1309batch: iter_time=1.373e-04, forward_time=0.235, loss_ctc=10.747, loss=10.747, backward_time=0.307, optim_step_time=0.038, optim0_lr0=6.087e-04, train_time=0.621
[ALab02] 2023-06-10 11:45:55,736 (trainer:721) INFO: 61epoch:train:1310-1386batch: iter_time=1.313e-04, forward_time=0.226, loss_ctc=10.390, loss=10.390, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.085e-04, train_time=0.610
[ALab02] 2023-06-10 11:46:42,202 (trainer:721) INFO: 61epoch:train:1387-1463batch: iter_time=1.509e-04, forward_time=0.221, loss_ctc=11.214, loss=11.214, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.082e-04, train_time=0.603
[ALab02] 2023-06-10 11:47:29,741 (trainer:721) INFO: 61epoch:train:1464-1540batch: iter_time=1.170e-04, forward_time=0.233, loss_ctc=8.963, loss=8.963, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.080e-04, train_time=0.617
[ALab02] 2023-06-10 11:48:12,365 (trainer:338) INFO: 61epoch results: [train] iter_time=8.434e-04, forward_time=0.231, loss_ctc=10.107, loss=10.107, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.103e-04, train_time=0.618, time=15 minutes and 59.81 seconds, total_count=94733, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.746, cer_ctc=0.281, cer=0.281, loss=13.746, time=6.84 seconds, total_count=976, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.91 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 11:48:14,781 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 11:48:14,783 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/60epoch.pth
[ALab02] 2023-06-10 11:48:14,783 (trainer:272) INFO: 62/70epoch started. Estimated time to finish: 3 hours, 29 minutes and 8.48 seconds
[ALab02] 2023-06-10 11:49:03,795 (trainer:721) INFO: 62epoch:train:1-77batch: iter_time=0.017, forward_time=0.230, loss_ctc=10.568, loss=10.568, backward_time=0.303, optim_step_time=0.039, optim0_lr0=6.077e-04, train_time=0.636
[ALab02] 2023-06-10 11:49:51,671 (trainer:721) INFO: 62epoch:train:78-154batch: iter_time=1.893e-04, forward_time=0.231, loss_ctc=11.059, loss=11.059, backward_time=0.304, optim_step_time=0.042, optim0_lr0=6.075e-04, train_time=0.621
[ALab02] 2023-06-10 11:50:38,725 (trainer:721) INFO: 62epoch:train:155-231batch: iter_time=1.625e-04, forward_time=0.228, loss_ctc=9.996, loss=9.996, backward_time=0.302, optim_step_time=0.039, optim0_lr0=6.072e-04, train_time=0.611
[ALab02] 2023-06-10 11:51:26,377 (trainer:721) INFO: 62epoch:train:232-308batch: iter_time=1.765e-04, forward_time=0.231, loss_ctc=11.208, loss=11.208, backward_time=0.301, optim_step_time=0.038, optim0_lr0=6.070e-04, train_time=0.619
[ALab02] 2023-06-10 11:52:12,862 (trainer:721) INFO: 62epoch:train:309-385batch: iter_time=1.844e-04, forward_time=0.224, loss_ctc=10.268, loss=10.268, backward_time=0.302, optim_step_time=0.037, optim0_lr0=6.067e-04, train_time=0.603
[ALab02] 2023-06-10 11:53:00,341 (trainer:721) INFO: 62epoch:train:386-462batch: iter_time=1.569e-04, forward_time=0.230, loss_ctc=10.401, loss=10.401, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.065e-04, train_time=0.616
[ALab02] 2023-06-10 11:53:48,242 (trainer:721) INFO: 62epoch:train:463-539batch: iter_time=1.602e-04, forward_time=0.237, loss_ctc=9.215, loss=9.215, backward_time=0.303, optim_step_time=0.037, optim0_lr0=6.062e-04, train_time=0.622
[ALab02] 2023-06-10 11:54:34,885 (trainer:721) INFO: 62epoch:train:540-616batch: iter_time=1.194e-04, forward_time=0.227, loss_ctc=9.638, loss=9.638, backward_time=0.297, optim_step_time=0.037, optim0_lr0=6.060e-04, train_time=0.606
[ALab02] 2023-06-10 11:55:22,784 (trainer:721) INFO: 62epoch:train:617-693batch: iter_time=1.380e-04, forward_time=0.229, loss_ctc=10.941, loss=10.941, backward_time=0.307, optim_step_time=0.040, optim0_lr0=6.057e-04, train_time=0.622
[ALab02] 2023-06-10 11:56:09,499 (trainer:721) INFO: 62epoch:train:694-770batch: iter_time=1.559e-04, forward_time=0.230, loss_ctc=9.212, loss=9.212, backward_time=0.299, optim_step_time=0.037, optim0_lr0=6.055e-04, train_time=0.606
[ALab02] 2023-06-10 11:56:58,127 (trainer:721) INFO: 62epoch:train:771-847batch: iter_time=1.477e-04, forward_time=0.239, loss_ctc=9.018, loss=9.018, backward_time=0.310, optim_step_time=0.039, optim0_lr0=6.052e-04, train_time=0.631
[ALab02] 2023-06-10 11:57:45,759 (trainer:721) INFO: 62epoch:train:848-924batch: iter_time=1.261e-04, forward_time=0.233, loss_ctc=9.513, loss=9.513, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.050e-04, train_time=0.618
[ALab02] 2023-06-10 11:58:31,762 (trainer:721) INFO: 62epoch:train:925-1001batch: iter_time=1.403e-04, forward_time=0.220, loss_ctc=9.975, loss=9.975, backward_time=0.301, optim_step_time=0.036, optim0_lr0=6.048e-04, train_time=0.597
[ALab02] 2023-06-10 11:59:19,426 (trainer:721) INFO: 62epoch:train:1002-1078batch: iter_time=1.387e-04, forward_time=0.234, loss_ctc=9.333, loss=9.333, backward_time=0.305, optim_step_time=0.038, optim0_lr0=6.045e-04, train_time=0.619
[ALab02] 2023-06-10 12:00:07,018 (trainer:721) INFO: 62epoch:train:1079-1155batch: iter_time=1.510e-04, forward_time=0.232, loss_ctc=9.892, loss=9.892, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.043e-04, train_time=0.618
[ALab02] 2023-06-10 12:00:54,437 (trainer:721) INFO: 62epoch:train:1156-1232batch: iter_time=1.272e-04, forward_time=0.231, loss_ctc=9.830, loss=9.830, backward_time=0.308, optim_step_time=0.036, optim0_lr0=6.040e-04, train_time=0.616
[ALab02] 2023-06-10 12:01:43,203 (trainer:721) INFO: 62epoch:train:1233-1309batch: iter_time=3.329e-04, forward_time=0.238, loss_ctc=9.686, loss=9.686, backward_time=0.304, optim_step_time=0.045, optim0_lr0=6.038e-04, train_time=0.633
[ALab02] 2023-06-10 12:02:31,157 (trainer:721) INFO: 62epoch:train:1310-1386batch: iter_time=2.139e-04, forward_time=0.232, loss_ctc=10.845, loss=10.845, backward_time=0.308, optim_step_time=0.040, optim0_lr0=6.035e-04, train_time=0.623
[ALab02] 2023-06-10 12:03:18,773 (trainer:721) INFO: 62epoch:train:1387-1463batch: iter_time=1.182e-04, forward_time=0.230, loss_ctc=9.892, loss=9.892, backward_time=0.306, optim_step_time=0.037, optim0_lr0=6.033e-04, train_time=0.618
[ALab02] 2023-06-10 12:04:06,395 (trainer:721) INFO: 62epoch:train:1464-1540batch: iter_time=1.514e-04, forward_time=0.233, loss_ctc=9.757, loss=9.757, backward_time=0.305, optim_step_time=0.036, optim0_lr0=6.031e-04, train_time=0.618
[ALab02] 2023-06-10 12:04:48,423 (trainer:338) INFO: 62epoch results: [train] iter_time=9.918e-04, forward_time=0.231, loss_ctc=10.000, loss=10.000, backward_time=0.304, optim_step_time=0.038, optim0_lr0=6.054e-04, train_time=0.618, time=15 minutes and 59.92 seconds, total_count=96286, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.588, cer_ctc=0.274, cer=0.274, loss=13.588, time=6.68 seconds, total_count=992, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.04 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 12:04:50,624 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 12:04:50,641 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/45epoch.pth, exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/61epoch.pth
[ALab02] 2023-06-10 12:04:50,642 (trainer:272) INFO: 63/70epoch started. Estimated time to finish: 3 hours, 5 minutes and 2.8 seconds
[ALab02] 2023-06-10 12:05:39,416 (trainer:721) INFO: 63epoch:train:1-77batch: iter_time=0.014, forward_time=0.235, loss_ctc=9.122, loss=9.122, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.028e-04, train_time=0.633
[ALab02] 2023-06-10 12:06:26,455 (trainer:721) INFO: 63epoch:train:78-154batch: iter_time=1.558e-04, forward_time=0.229, loss_ctc=10.575, loss=10.575, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.025e-04, train_time=0.611
[ALab02] 2023-06-10 12:07:14,217 (trainer:721) INFO: 63epoch:train:155-231batch: iter_time=1.532e-04, forward_time=0.234, loss_ctc=9.315, loss=9.315, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.023e-04, train_time=0.620
[ALab02] 2023-06-10 12:08:02,843 (trainer:721) INFO: 63epoch:train:232-308batch: iter_time=1.751e-04, forward_time=0.238, loss_ctc=8.760, loss=8.760, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.021e-04, train_time=0.631
[ALab02] 2023-06-10 12:08:49,955 (trainer:721) INFO: 63epoch:train:309-385batch: iter_time=1.394e-04, forward_time=0.227, loss_ctc=10.122, loss=10.122, backward_time=0.305, optim_step_time=0.037, optim0_lr0=6.018e-04, train_time=0.612
[ALab02] 2023-06-10 12:09:35,929 (trainer:721) INFO: 63epoch:train:386-462batch: iter_time=1.606e-04, forward_time=0.222, loss_ctc=9.154, loss=9.154, backward_time=0.297, optim_step_time=0.036, optim0_lr0=6.016e-04, train_time=0.597
[ALab02] 2023-06-10 12:10:22,955 (trainer:721) INFO: 63epoch:train:463-539batch: iter_time=1.259e-04, forward_time=0.226, loss_ctc=11.032, loss=11.032, backward_time=0.307, optim_step_time=0.036, optim0_lr0=6.013e-04, train_time=0.611
[ALab02] 2023-06-10 12:11:10,761 (trainer:721) INFO: 63epoch:train:540-616batch: iter_time=2.255e-04, forward_time=0.233, loss_ctc=11.435, loss=11.435, backward_time=0.306, optim_step_time=0.039, optim0_lr0=6.011e-04, train_time=0.621
[ALab02] 2023-06-10 12:11:58,299 (trainer:721) INFO: 63epoch:train:617-693batch: iter_time=1.686e-04, forward_time=0.233, loss_ctc=9.092, loss=9.092, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.009e-04, train_time=0.617
[ALab02] 2023-06-10 12:12:45,383 (trainer:721) INFO: 63epoch:train:694-770batch: iter_time=1.482e-04, forward_time=0.228, loss_ctc=11.058, loss=11.058, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.006e-04, train_time=0.611
[ALab02] 2023-06-10 12:13:32,182 (trainer:721) INFO: 63epoch:train:771-847batch: iter_time=1.476e-04, forward_time=0.227, loss_ctc=11.365, loss=11.365, backward_time=0.301, optim_step_time=0.037, optim0_lr0=6.004e-04, train_time=0.608
[ALab02] 2023-06-10 12:14:20,161 (trainer:721) INFO: 63epoch:train:848-924batch: iter_time=1.707e-04, forward_time=0.236, loss_ctc=9.334, loss=9.334, backward_time=0.307, optim_step_time=0.037, optim0_lr0=6.002e-04, train_time=0.623
[ALab02] 2023-06-10 12:15:07,211 (trainer:721) INFO: 63epoch:train:925-1001batch: iter_time=1.573e-04, forward_time=0.228, loss_ctc=10.634, loss=10.634, backward_time=0.301, optim_step_time=0.040, optim0_lr0=5.999e-04, train_time=0.611
[ALab02] 2023-06-10 12:15:54,953 (trainer:721) INFO: 63epoch:train:1002-1078batch: iter_time=1.311e-04, forward_time=0.233, loss_ctc=9.538, loss=9.538, backward_time=0.308, optim_step_time=0.038, optim0_lr0=5.997e-04, train_time=0.620
[ALab02] 2023-06-10 12:16:42,522 (trainer:721) INFO: 63epoch:train:1079-1155batch: iter_time=1.583e-04, forward_time=0.234, loss_ctc=9.660, loss=9.660, backward_time=0.304, optim_step_time=0.038, optim0_lr0=5.994e-04, train_time=0.618
[ALab02] 2023-06-10 12:17:29,218 (trainer:721) INFO: 63epoch:train:1156-1232batch: iter_time=1.458e-04, forward_time=0.225, loss_ctc=11.066, loss=11.066, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.992e-04, train_time=0.606
[ALab02] 2023-06-10 12:18:17,318 (trainer:721) INFO: 63epoch:train:1233-1309batch: iter_time=1.515e-04, forward_time=0.234, loss_ctc=9.770, loss=9.770, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.990e-04, train_time=0.624
[ALab02] 2023-06-10 12:19:04,806 (trainer:721) INFO: 63epoch:train:1310-1386batch: iter_time=1.110e-04, forward_time=0.232, loss_ctc=9.629, loss=9.629, backward_time=0.307, optim_step_time=0.036, optim0_lr0=5.987e-04, train_time=0.617
[ALab02] 2023-06-10 12:19:51,983 (trainer:721) INFO: 63epoch:train:1387-1463batch: iter_time=1.644e-04, forward_time=0.227, loss_ctc=10.477, loss=10.477, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.985e-04, train_time=0.612
[ALab02] 2023-06-10 12:20:40,476 (trainer:721) INFO: 63epoch:train:1464-1540batch: iter_time=2.006e-04, forward_time=0.239, loss_ctc=10.062, loss=10.062, backward_time=0.306, optim_step_time=0.040, optim0_lr0=5.983e-04, train_time=0.630
[ALab02] 2023-06-10 12:21:23,140 (trainer:338) INFO: 63epoch results: [train] iter_time=8.328e-04, forward_time=0.231, loss_ctc=10.013, loss=10.013, backward_time=0.304, optim_step_time=0.037, optim0_lr0=6.005e-04, train_time=0.616, time=15 minutes and 57.68 seconds, total_count=97839, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.707, cer_ctc=0.285, cer=0.285, loss=13.707, time=6.83 seconds, total_count=1008, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.99 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 12:21:25,563 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 12:21:25,564 (trainer:272) INFO: 64/70epoch started. Estimated time to finish: 2 hours, 41 minutes and 11.29 seconds
[ALab02] 2023-06-10 12:22:14,583 (trainer:721) INFO: 64epoch:train:1-77batch: iter_time=0.014, forward_time=0.234, loss_ctc=8.873, loss=8.873, backward_time=0.307, optim_step_time=0.037, optim0_lr0=5.980e-04, train_time=0.636
[ALab02] 2023-06-10 12:23:01,528 (trainer:721) INFO: 64epoch:train:78-154batch: iter_time=1.518e-04, forward_time=0.229, loss_ctc=8.682, loss=8.682, backward_time=0.302, optim_step_time=0.036, optim0_lr0=5.977e-04, train_time=0.609
[ALab02] 2023-06-10 12:23:48,823 (trainer:721) INFO: 64epoch:train:155-231batch: iter_time=1.540e-04, forward_time=0.228, loss_ctc=9.513, loss=9.513, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.975e-04, train_time=0.614
[ALab02] 2023-06-10 12:24:35,857 (trainer:721) INFO: 64epoch:train:232-308batch: iter_time=1.435e-04, forward_time=0.228, loss_ctc=11.063, loss=11.063, backward_time=0.300, optim_step_time=0.036, optim0_lr0=5.973e-04, train_time=0.611
[ALab02] 2023-06-10 12:25:23,994 (trainer:721) INFO: 64epoch:train:309-385batch: iter_time=1.521e-04, forward_time=0.239, loss_ctc=9.239, loss=9.239, backward_time=0.306, optim_step_time=0.036, optim0_lr0=5.970e-04, train_time=0.625
[ALab02] 2023-06-10 12:26:12,034 (trainer:721) INFO: 64epoch:train:386-462batch: iter_time=1.742e-04, forward_time=0.234, loss_ctc=8.981, loss=8.981, backward_time=0.309, optim_step_time=0.038, optim0_lr0=5.968e-04, train_time=0.624
[ALab02] 2023-06-10 12:26:59,678 (trainer:721) INFO: 64epoch:train:463-539batch: iter_time=1.529e-04, forward_time=0.233, loss_ctc=8.987, loss=8.987, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.966e-04, train_time=0.619
[ALab02] 2023-06-10 12:27:47,959 (trainer:721) INFO: 64epoch:train:540-616batch: iter_time=1.381e-04, forward_time=0.237, loss_ctc=9.333, loss=9.333, backward_time=0.307, optim_step_time=0.038, optim0_lr0=5.963e-04, train_time=0.627
[ALab02] 2023-06-10 12:28:35,254 (trainer:721) INFO: 64epoch:train:617-693batch: iter_time=1.301e-04, forward_time=0.230, loss_ctc=10.017, loss=10.017, backward_time=0.302, optim_step_time=0.039, optim0_lr0=5.961e-04, train_time=0.614
[ALab02] 2023-06-10 12:29:23,588 (trainer:721) INFO: 64epoch:train:694-770batch: iter_time=1.257e-04, forward_time=0.237, loss_ctc=9.340, loss=9.340, backward_time=0.309, optim_step_time=0.036, optim0_lr0=5.959e-04, train_time=0.627
[ALab02] 2023-06-10 12:30:11,496 (trainer:721) INFO: 64epoch:train:771-847batch: iter_time=1.238e-04, forward_time=0.231, loss_ctc=11.284, loss=11.284, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.956e-04, train_time=0.622
[ALab02] 2023-06-10 12:30:58,287 (trainer:721) INFO: 64epoch:train:848-924batch: iter_time=1.314e-04, forward_time=0.226, loss_ctc=10.488, loss=10.488, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.954e-04, train_time=0.607
[ALab02] 2023-06-10 12:31:45,248 (trainer:721) INFO: 64epoch:train:925-1001batch: iter_time=1.797e-04, forward_time=0.230, loss_ctc=10.027, loss=10.027, backward_time=0.301, optim_step_time=0.039, optim0_lr0=5.952e-04, train_time=0.610
[ALab02] 2023-06-10 12:32:32,236 (trainer:721) INFO: 64epoch:train:1002-1078batch: iter_time=1.636e-04, forward_time=0.226, loss_ctc=11.052, loss=11.052, backward_time=0.303, optim_step_time=0.039, optim0_lr0=5.949e-04, train_time=0.610
[ALab02] 2023-06-10 12:33:19,478 (trainer:721) INFO: 64epoch:train:1079-1155batch: iter_time=1.370e-04, forward_time=0.228, loss_ctc=9.824, loss=9.824, backward_time=0.307, optim_step_time=0.037, optim0_lr0=5.947e-04, train_time=0.613
[ALab02] 2023-06-10 12:34:06,861 (trainer:721) INFO: 64epoch:train:1156-1232batch: iter_time=1.557e-04, forward_time=0.232, loss_ctc=10.662, loss=10.662, backward_time=0.303, optim_step_time=0.037, optim0_lr0=5.945e-04, train_time=0.615
[ALab02] 2023-06-10 12:34:54,140 (trainer:721) INFO: 64epoch:train:1233-1309batch: iter_time=1.263e-04, forward_time=0.230, loss_ctc=11.482, loss=11.482, backward_time=0.305, optim_step_time=0.036, optim0_lr0=5.943e-04, train_time=0.614
[ALab02] 2023-06-10 12:35:41,560 (trainer:721) INFO: 64epoch:train:1310-1386batch: iter_time=1.747e-04, forward_time=0.232, loss_ctc=9.342, loss=9.342, backward_time=0.301, optim_step_time=0.037, optim0_lr0=5.940e-04, train_time=0.616
[ALab02] 2023-06-10 12:36:28,491 (trainer:721) INFO: 64epoch:train:1387-1463batch: iter_time=1.410e-04, forward_time=0.228, loss_ctc=11.121, loss=11.121, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.938e-04, train_time=0.609
[ALab02] 2023-06-10 12:37:14,501 (trainer:721) INFO: 64epoch:train:1464-1540batch: iter_time=1.277e-04, forward_time=0.223, loss_ctc=9.375, loss=9.375, backward_time=0.300, optim_step_time=0.036, optim0_lr0=5.936e-04, train_time=0.597
[ALab02] 2023-06-10 12:37:56,173 (trainer:338) INFO: 64epoch results: [train] iter_time=8.527e-04, forward_time=0.231, loss_ctc=9.895, loss=9.895, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.957e-04, train_time=0.616, time=15 minutes and 56.88 seconds, total_count=99392, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=13.911, cer_ctc=0.283, cer=0.283, loss=13.911, time=6.64 seconds, total_count=1024, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.09 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 12:37:59,585 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 12:37:59,590 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/63epoch.pth
[ALab02] 2023-06-10 12:37:59,591 (trainer:272) INFO: 65/70epoch started. Estimated time to finish: 2 hours, 17 minutes and 33.34 seconds
[ALab02] 2023-06-10 12:38:50,032 (trainer:721) INFO: 65epoch:train:1-77batch: iter_time=0.021, forward_time=0.236, loss_ctc=9.397, loss=9.397, backward_time=0.305, optim_step_time=0.040, optim0_lr0=5.933e-04, train_time=0.655
[ALab02] 2023-06-10 12:39:36,823 (trainer:721) INFO: 65epoch:train:78-154batch: iter_time=1.727e-04, forward_time=0.226, loss_ctc=10.759, loss=10.759, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.931e-04, train_time=0.607
[ALab02] 2023-06-10 12:40:24,561 (trainer:721) INFO: 65epoch:train:155-231batch: iter_time=1.726e-04, forward_time=0.233, loss_ctc=9.709, loss=9.709, backward_time=0.303, optim_step_time=0.039, optim0_lr0=5.928e-04, train_time=0.620
[ALab02] 2023-06-10 12:41:11,710 (trainer:721) INFO: 65epoch:train:232-308batch: iter_time=1.719e-04, forward_time=0.228, loss_ctc=9.084, loss=9.084, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.926e-04, train_time=0.612
[ALab02] 2023-06-10 12:41:58,648 (trainer:721) INFO: 65epoch:train:309-385batch: iter_time=1.673e-04, forward_time=0.228, loss_ctc=10.153, loss=10.153, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.924e-04, train_time=0.609
[ALab02] 2023-06-10 12:42:45,176 (trainer:721) INFO: 65epoch:train:386-462batch: iter_time=1.646e-04, forward_time=0.227, loss_ctc=10.768, loss=10.768, backward_time=0.298, optim_step_time=0.036, optim0_lr0=5.922e-04, train_time=0.604
[ALab02] 2023-06-10 12:43:33,446 (trainer:721) INFO: 65epoch:train:463-539batch: iter_time=1.484e-04, forward_time=0.236, loss_ctc=9.053, loss=9.053, backward_time=0.308, optim_step_time=0.038, optim0_lr0=5.919e-04, train_time=0.627
[ALab02] 2023-06-10 12:44:20,941 (trainer:721) INFO: 65epoch:train:540-616batch: iter_time=1.613e-04, forward_time=0.231, loss_ctc=9.928, loss=9.928, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.917e-04, train_time=0.617
[ALab02] 2023-06-10 12:45:08,913 (trainer:721) INFO: 65epoch:train:617-693batch: iter_time=1.591e-04, forward_time=0.234, loss_ctc=10.014, loss=10.014, backward_time=0.307, optim_step_time=0.038, optim0_lr0=5.915e-04, train_time=0.623
[ALab02] 2023-06-10 12:45:55,855 (trainer:721) INFO: 65epoch:train:694-770batch: iter_time=1.399e-04, forward_time=0.228, loss_ctc=10.468, loss=10.468, backward_time=0.304, optim_step_time=0.038, optim0_lr0=5.912e-04, train_time=0.609
[ALab02] 2023-06-10 12:46:43,490 (trainer:721) INFO: 65epoch:train:771-847batch: iter_time=1.294e-04, forward_time=0.231, loss_ctc=9.434, loss=9.434, backward_time=0.308, optim_step_time=0.036, optim0_lr0=5.910e-04, train_time=0.618
[ALab02] 2023-06-10 12:47:31,587 (trainer:721) INFO: 65epoch:train:848-924batch: iter_time=1.330e-04, forward_time=0.237, loss_ctc=11.132, loss=11.132, backward_time=0.308, optim_step_time=0.037, optim0_lr0=5.908e-04, train_time=0.624
[ALab02] 2023-06-10 12:48:19,097 (trainer:721) INFO: 65epoch:train:925-1001batch: iter_time=1.433e-04, forward_time=0.228, loss_ctc=9.451, loss=9.451, backward_time=0.307, optim_step_time=0.037, optim0_lr0=5.906e-04, train_time=0.617
[ALab02] 2023-06-10 12:49:06,990 (trainer:721) INFO: 65epoch:train:1002-1078batch: iter_time=1.604e-04, forward_time=0.235, loss_ctc=8.861, loss=8.861, backward_time=0.307, optim_step_time=0.037, optim0_lr0=5.903e-04, train_time=0.622
[ALab02] 2023-06-10 12:49:54,439 (trainer:721) INFO: 65epoch:train:1079-1155batch: iter_time=1.523e-04, forward_time=0.231, loss_ctc=9.050, loss=9.050, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.901e-04, train_time=0.616
[ALab02] 2023-06-10 12:50:42,231 (trainer:721) INFO: 65epoch:train:1156-1232batch: iter_time=1.359e-04, forward_time=0.235, loss_ctc=8.255, loss=8.255, backward_time=0.308, optim_step_time=0.036, optim0_lr0=5.899e-04, train_time=0.620
[ALab02] 2023-06-10 12:51:29,318 (trainer:721) INFO: 65epoch:train:1233-1309batch: iter_time=1.342e-04, forward_time=0.231, loss_ctc=9.777, loss=9.777, backward_time=0.301, optim_step_time=0.036, optim0_lr0=5.897e-04, train_time=0.611
[ALab02] 2023-06-10 12:52:16,183 (trainer:721) INFO: 65epoch:train:1310-1386batch: iter_time=1.918e-04, forward_time=0.227, loss_ctc=10.511, loss=10.511, backward_time=0.301, optim_step_time=0.037, optim0_lr0=5.894e-04, train_time=0.608
[ALab02] 2023-06-10 12:53:04,047 (trainer:721) INFO: 65epoch:train:1387-1463batch: iter_time=1.843e-04, forward_time=0.234, loss_ctc=10.315, loss=10.315, backward_time=0.305, optim_step_time=0.040, optim0_lr0=5.892e-04, train_time=0.621
[ALab02] 2023-06-10 12:53:50,645 (trainer:721) INFO: 65epoch:train:1464-1540batch: iter_time=1.396e-04, forward_time=0.227, loss_ctc=9.891, loss=9.891, backward_time=0.300, optim_step_time=0.036, optim0_lr0=5.890e-04, train_time=0.605
[ALab02] 2023-06-10 12:54:33,094 (trainer:338) INFO: 65epoch results: [train] iter_time=0.001, forward_time=0.231, loss_ctc=9.774, loss=9.774, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.911e-04, train_time=0.617, time=15 minutes and 59.29 seconds, total_count=100945, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.650, cer_ctc=0.283, cer=0.283, loss=14.650, time=6.78 seconds, total_count=1040, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.43 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 12:54:35,683 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 12:54:35,697 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/64epoch.pth
[ALab02] 2023-06-10 12:54:35,698 (trainer:272) INFO: 66/70epoch started. Estimated time to finish: 1 hour, 54 minutes and 8.59 seconds
[ALab02] 2023-06-10 12:55:25,294 (trainer:721) INFO: 66epoch:train:1-77batch: iter_time=0.012, forward_time=0.239, loss_ctc=7.658, loss=7.658, backward_time=0.311, optim_step_time=0.037, optim0_lr0=5.887e-04, train_time=0.644
[ALab02] 2023-06-10 12:56:12,667 (trainer:721) INFO: 66epoch:train:78-154batch: iter_time=1.700e-04, forward_time=0.229, loss_ctc=10.348, loss=10.348, backward_time=0.300, optim_step_time=0.039, optim0_lr0=5.885e-04, train_time=0.615
[ALab02] 2023-06-10 12:56:59,460 (trainer:721) INFO: 66epoch:train:155-231batch: iter_time=1.440e-04, forward_time=0.228, loss_ctc=9.522, loss=9.522, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.883e-04, train_time=0.607
[ALab02] 2023-06-10 12:57:46,770 (trainer:721) INFO: 66epoch:train:232-308batch: iter_time=2.043e-04, forward_time=0.230, loss_ctc=10.025, loss=10.025, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.880e-04, train_time=0.614
[ALab02] 2023-06-10 12:58:35,237 (trainer:721) INFO: 66epoch:train:309-385batch: iter_time=1.245e-04, forward_time=0.238, loss_ctc=9.430, loss=9.430, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.878e-04, train_time=0.629
[ALab02] 2023-06-10 12:59:21,699 (trainer:721) INFO: 66epoch:train:386-462batch: iter_time=1.364e-04, forward_time=0.225, loss_ctc=9.833, loss=9.833, backward_time=0.299, optim_step_time=0.037, optim0_lr0=5.876e-04, train_time=0.603
[ALab02] 2023-06-10 13:00:08,746 (trainer:721) INFO: 66epoch:train:463-539batch: iter_time=1.806e-04, forward_time=0.232, loss_ctc=9.302, loss=9.302, backward_time=0.300, optim_step_time=0.038, optim0_lr0=5.874e-04, train_time=0.611
[ALab02] 2023-06-10 13:00:56,766 (trainer:721) INFO: 66epoch:train:540-616batch: iter_time=1.410e-04, forward_time=0.233, loss_ctc=9.806, loss=9.806, backward_time=0.306, optim_step_time=0.038, optim0_lr0=5.872e-04, train_time=0.623
[ALab02] 2023-06-10 13:01:44,261 (trainer:721) INFO: 66epoch:train:617-693batch: iter_time=1.395e-04, forward_time=0.232, loss_ctc=9.304, loss=9.304, backward_time=0.303, optim_step_time=0.037, optim0_lr0=5.869e-04, train_time=0.617
[ALab02] 2023-06-10 13:02:31,508 (trainer:721) INFO: 66epoch:train:694-770batch: iter_time=1.136e-04, forward_time=0.229, loss_ctc=10.338, loss=10.338, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.867e-04, train_time=0.613
[ALab02] 2023-06-10 13:03:18,650 (trainer:721) INFO: 66epoch:train:771-847batch: iter_time=1.271e-04, forward_time=0.227, loss_ctc=10.326, loss=10.326, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.865e-04, train_time=0.612
[ALab02] 2023-06-10 13:04:06,785 (trainer:721) INFO: 66epoch:train:848-924batch: iter_time=1.504e-04, forward_time=0.236, loss_ctc=10.439, loss=10.439, backward_time=0.307, optim_step_time=0.038, optim0_lr0=5.863e-04, train_time=0.625
[ALab02] 2023-06-10 13:04:54,742 (trainer:721) INFO: 66epoch:train:925-1001batch: iter_time=1.666e-04, forward_time=0.234, loss_ctc=10.060, loss=10.060, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.860e-04, train_time=0.623
[ALab02] 2023-06-10 13:05:41,749 (trainer:721) INFO: 66epoch:train:1002-1078batch: iter_time=1.454e-04, forward_time=0.228, loss_ctc=10.558, loss=10.558, backward_time=0.303, optim_step_time=0.036, optim0_lr0=5.858e-04, train_time=0.610
[ALab02] 2023-06-10 13:06:28,976 (trainer:721) INFO: 66epoch:train:1079-1155batch: iter_time=1.380e-04, forward_time=0.229, loss_ctc=9.788, loss=9.788, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.856e-04, train_time=0.613
[ALab02] 2023-06-10 13:07:16,072 (trainer:721) INFO: 66epoch:train:1156-1232batch: iter_time=1.446e-04, forward_time=0.230, loss_ctc=9.807, loss=9.807, backward_time=0.303, optim_step_time=0.037, optim0_lr0=5.854e-04, train_time=0.611
[ALab02] 2023-06-10 13:08:02,767 (trainer:721) INFO: 66epoch:train:1233-1309batch: iter_time=1.524e-04, forward_time=0.226, loss_ctc=9.091, loss=9.091, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.852e-04, train_time=0.606
[ALab02] 2023-06-10 13:08:50,485 (trainer:721) INFO: 66epoch:train:1310-1386batch: iter_time=1.424e-04, forward_time=0.233, loss_ctc=10.148, loss=10.148, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.849e-04, train_time=0.619
[ALab02] 2023-06-10 13:09:37,077 (trainer:721) INFO: 66epoch:train:1387-1463batch: iter_time=1.494e-04, forward_time=0.225, loss_ctc=9.424, loss=9.424, backward_time=0.303, optim_step_time=0.036, optim0_lr0=5.847e-04, train_time=0.605
[ALab02] 2023-06-10 13:10:24,329 (trainer:721) INFO: 66epoch:train:1464-1540batch: iter_time=1.234e-04, forward_time=0.228, loss_ctc=9.916, loss=9.916, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.845e-04, train_time=0.613
[ALab02] 2023-06-10 13:11:06,308 (trainer:338) INFO: 66epoch results: [train] iter_time=7.525e-04, forward_time=0.231, loss_ctc=9.735, loss=9.735, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.866e-04, train_time=0.616, time=15 minutes and 56.63 seconds, total_count=102498, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.488, cer_ctc=0.285, cer=0.285, loss=14.488, time=6.67 seconds, total_count=1056, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.31 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 13:11:08,636 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 13:11:08,649 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/65epoch.pth
[ALab02] 2023-06-10 13:11:08,649 (trainer:272) INFO: 67/70epoch started. Estimated time to finish: 1 hour, 30 minutes and 56.04 seconds
[ALab02] 2023-06-10 13:11:57,269 (trainer:721) INFO: 67epoch:train:1-77batch: iter_time=0.014, forward_time=0.230, loss_ctc=9.860, loss=9.860, backward_time=0.306, optim_step_time=0.036, optim0_lr0=5.842e-04, train_time=0.631
[ALab02] 2023-06-10 13:12:44,151 (trainer:721) INFO: 67epoch:train:78-154batch: iter_time=1.384e-04, forward_time=0.226, loss_ctc=9.067, loss=9.067, backward_time=0.305, optim_step_time=0.036, optim0_lr0=5.840e-04, train_time=0.609
[ALab02] 2023-06-10 13:13:32,320 (trainer:721) INFO: 67epoch:train:155-231batch: iter_time=3.459e-04, forward_time=0.238, loss_ctc=8.872, loss=8.872, backward_time=0.301, optim_step_time=0.038, optim0_lr0=5.838e-04, train_time=0.625
[ALab02] 2023-06-10 13:14:20,969 (trainer:721) INFO: 67epoch:train:232-308batch: iter_time=2.261e-04, forward_time=0.239, loss_ctc=9.198, loss=9.198, backward_time=0.306, optim_step_time=0.040, optim0_lr0=5.836e-04, train_time=0.632
[ALab02] 2023-06-10 13:15:08,243 (trainer:721) INFO: 67epoch:train:309-385batch: iter_time=1.782e-04, forward_time=0.229, loss_ctc=11.233, loss=11.233, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.834e-04, train_time=0.614
[ALab02] 2023-06-10 13:15:56,908 (trainer:721) INFO: 67epoch:train:386-462batch: iter_time=1.761e-04, forward_time=0.240, loss_ctc=10.158, loss=10.158, backward_time=0.308, optim_step_time=0.038, optim0_lr0=5.831e-04, train_time=0.632
[ALab02] 2023-06-10 13:16:44,349 (trainer:721) INFO: 67epoch:train:463-539batch: iter_time=1.565e-04, forward_time=0.234, loss_ctc=10.405, loss=10.405, backward_time=0.301, optim_step_time=0.038, optim0_lr0=5.829e-04, train_time=0.616
[ALab02] 2023-06-10 13:17:31,758 (trainer:721) INFO: 67epoch:train:540-616batch: iter_time=1.265e-04, forward_time=0.229, loss_ctc=10.248, loss=10.248, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.827e-04, train_time=0.615
[ALab02] 2023-06-10 13:18:19,289 (trainer:721) INFO: 67epoch:train:617-693batch: iter_time=1.456e-04, forward_time=0.231, loss_ctc=8.966, loss=8.966, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.825e-04, train_time=0.617
[ALab02] 2023-06-10 13:19:06,904 (trainer:721) INFO: 67epoch:train:694-770batch: iter_time=1.409e-04, forward_time=0.231, loss_ctc=9.448, loss=9.448, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.823e-04, train_time=0.618
[ALab02] 2023-06-10 13:19:54,660 (trainer:721) INFO: 67epoch:train:771-847batch: iter_time=1.218e-04, forward_time=0.235, loss_ctc=8.884, loss=8.884, backward_time=0.305, optim_step_time=0.039, optim0_lr0=5.821e-04, train_time=0.620
[ALab02] 2023-06-10 13:20:42,505 (trainer:721) INFO: 67epoch:train:848-924batch: iter_time=1.650e-04, forward_time=0.234, loss_ctc=9.052, loss=9.052, backward_time=0.306, optim_step_time=0.039, optim0_lr0=5.818e-04, train_time=0.621
[ALab02] 2023-06-10 13:21:30,067 (trainer:721) INFO: 67epoch:train:925-1001batch: iter_time=1.672e-04, forward_time=0.235, loss_ctc=9.228, loss=9.228, backward_time=0.302, optim_step_time=0.038, optim0_lr0=5.816e-04, train_time=0.617
[ALab02] 2023-06-10 13:22:17,027 (trainer:721) INFO: 67epoch:train:1002-1078batch: iter_time=1.536e-04, forward_time=0.226, loss_ctc=10.363, loss=10.363, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.814e-04, train_time=0.610
[ALab02] 2023-06-10 13:23:05,231 (trainer:721) INFO: 67epoch:train:1079-1155batch: iter_time=1.632e-04, forward_time=0.236, loss_ctc=8.761, loss=8.761, backward_time=0.307, optim_step_time=0.039, optim0_lr0=5.812e-04, train_time=0.626
[ALab02] 2023-06-10 13:23:52,369 (trainer:721) INFO: 67epoch:train:1156-1232batch: iter_time=1.496e-04, forward_time=0.228, loss_ctc=10.728, loss=10.728, backward_time=0.303, optim_step_time=0.039, optim0_lr0=5.810e-04, train_time=0.612
[ALab02] 2023-06-10 13:24:39,002 (trainer:721) INFO: 67epoch:train:1233-1309batch: iter_time=1.254e-04, forward_time=0.221, loss_ctc=10.069, loss=10.069, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.808e-04, train_time=0.605
[ALab02] 2023-06-10 13:25:25,454 (trainer:721) INFO: 67epoch:train:1310-1386batch: iter_time=1.388e-04, forward_time=0.224, loss_ctc=9.605, loss=9.605, backward_time=0.301, optim_step_time=0.036, optim0_lr0=5.805e-04, train_time=0.603
[ALab02] 2023-06-10 13:26:11,612 (trainer:721) INFO: 67epoch:train:1387-1463batch: iter_time=1.336e-04, forward_time=0.224, loss_ctc=9.544, loss=9.544, backward_time=0.299, optim_step_time=0.036, optim0_lr0=5.803e-04, train_time=0.599
[ALab02] 2023-06-10 13:26:59,411 (trainer:721) INFO: 67epoch:train:1464-1540batch: iter_time=1.449e-04, forward_time=0.235, loss_ctc=10.015, loss=10.015, backward_time=0.306, optim_step_time=0.036, optim0_lr0=5.801e-04, train_time=0.621
[ALab02] 2023-06-10 13:27:41,112 (trainer:338) INFO: 67epoch results: [train] iter_time=8.361e-04, forward_time=0.231, loss_ctc=9.654, loss=9.654, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.822e-04, train_time=0.617, time=15 minutes and 58.54 seconds, total_count=104051, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.993, cer_ctc=0.276, cer=0.276, loss=14.993, time=6.75 seconds, total_count=1072, gpu_max_cached_mem_GB=77.078, [att_plot] time=27.17 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 13:27:43,315 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 13:27:43,320 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/53epoch.pth, exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/66epoch.pth
[ALab02] 2023-06-10 13:27:43,320 (trainer:272) INFO: 68/70epoch started. Estimated time to finish: 1 hour, 7 minutes and 55.49 seconds
[ALab02] 2023-06-10 13:28:32,272 (trainer:721) INFO: 68epoch:train:1-77batch: iter_time=0.014, forward_time=0.234, loss_ctc=9.713, loss=9.713, backward_time=0.303, optim_step_time=0.037, optim0_lr0=5.799e-04, train_time=0.635
[ALab02] 2023-06-10 13:29:19,627 (trainer:721) INFO: 68epoch:train:78-154batch: iter_time=1.292e-04, forward_time=0.231, loss_ctc=8.407, loss=8.407, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.797e-04, train_time=0.615
[ALab02] 2023-06-10 13:30:07,384 (trainer:721) INFO: 68epoch:train:155-231batch: iter_time=1.259e-04, forward_time=0.236, loss_ctc=8.748, loss=8.748, backward_time=0.302, optim_step_time=0.036, optim0_lr0=5.794e-04, train_time=0.620
[ALab02] 2023-06-10 13:30:54,988 (trainer:721) INFO: 68epoch:train:232-308batch: iter_time=1.596e-04, forward_time=0.233, loss_ctc=10.102, loss=10.102, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.792e-04, train_time=0.618
[ALab02] 2023-06-10 13:31:41,617 (trainer:721) INFO: 68epoch:train:309-385batch: iter_time=1.449e-04, forward_time=0.224, loss_ctc=9.135, loss=9.135, backward_time=0.306, optim_step_time=0.036, optim0_lr0=5.790e-04, train_time=0.605
[ALab02] 2023-06-10 13:32:29,845 (trainer:721) INFO: 68epoch:train:386-462batch: iter_time=1.649e-04, forward_time=0.234, loss_ctc=8.443, loss=8.443, backward_time=0.311, optim_step_time=0.036, optim0_lr0=5.788e-04, train_time=0.626
[ALab02] 2023-06-10 13:33:16,816 (trainer:721) INFO: 68epoch:train:463-539batch: iter_time=1.894e-04, forward_time=0.225, loss_ctc=10.180, loss=10.180, backward_time=0.309, optim_step_time=0.035, optim0_lr0=5.786e-04, train_time=0.610
[ALab02] 2023-06-10 13:34:03,692 (trainer:721) INFO: 68epoch:train:540-616batch: iter_time=2.048e-04, forward_time=0.227, loss_ctc=9.178, loss=9.178, backward_time=0.304, optim_step_time=0.038, optim0_lr0=5.784e-04, train_time=0.609
[ALab02] 2023-06-10 13:34:52,070 (trainer:721) INFO: 68epoch:train:617-693batch: iter_time=1.893e-04, forward_time=0.240, loss_ctc=10.241, loss=10.241, backward_time=0.303, optim_step_time=0.043, optim0_lr0=5.782e-04, train_time=0.628
[ALab02] 2023-06-10 13:35:41,135 (trainer:721) INFO: 68epoch:train:694-770batch: iter_time=3.448e-04, forward_time=0.240, loss_ctc=10.186, loss=10.186, backward_time=0.306, optim_step_time=0.045, optim0_lr0=5.779e-04, train_time=0.637
[ALab02] 2023-06-10 13:36:28,209 (trainer:721) INFO: 68epoch:train:771-847batch: iter_time=1.612e-04, forward_time=0.232, loss_ctc=8.745, loss=8.745, backward_time=0.301, optim_step_time=0.037, optim0_lr0=5.777e-04, train_time=0.611
[ALab02] 2023-06-10 13:37:16,207 (trainer:721) INFO: 68epoch:train:848-924batch: iter_time=1.324e-04, forward_time=0.231, loss_ctc=9.670, loss=9.670, backward_time=0.309, optim_step_time=0.038, optim0_lr0=5.775e-04, train_time=0.623
[ALab02] 2023-06-10 13:38:03,240 (trainer:721) INFO: 68epoch:train:925-1001batch: iter_time=1.525e-04, forward_time=0.227, loss_ctc=10.488, loss=10.488, backward_time=0.301, optim_step_time=0.038, optim0_lr0=5.773e-04, train_time=0.611
[ALab02] 2023-06-10 13:38:51,443 (trainer:721) INFO: 68epoch:train:1002-1078batch: iter_time=1.473e-04, forward_time=0.238, loss_ctc=8.459, loss=8.459, backward_time=0.304, optim_step_time=0.038, optim0_lr0=5.771e-04, train_time=0.626
[ALab02] 2023-06-10 13:39:38,443 (trainer:721) INFO: 68epoch:train:1079-1155batch: iter_time=1.281e-04, forward_time=0.227, loss_ctc=10.011, loss=10.011, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.769e-04, train_time=0.610
[ALab02] 2023-06-10 13:40:25,202 (trainer:721) INFO: 68epoch:train:1156-1232batch: iter_time=1.785e-04, forward_time=0.226, loss_ctc=9.584, loss=9.584, backward_time=0.300, optim_step_time=0.038, optim0_lr0=5.767e-04, train_time=0.607
[ALab02] 2023-06-10 13:41:13,300 (trainer:721) INFO: 68epoch:train:1233-1309batch: iter_time=2.010e-04, forward_time=0.240, loss_ctc=9.016, loss=9.016, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.765e-04, train_time=0.624
[ALab02] 2023-06-10 13:42:00,308 (trainer:721) INFO: 68epoch:train:1310-1386batch: iter_time=1.356e-04, forward_time=0.226, loss_ctc=10.161, loss=10.161, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.763e-04, train_time=0.610
[ALab02] 2023-06-10 13:42:47,690 (trainer:721) INFO: 68epoch:train:1387-1463batch: iter_time=1.377e-04, forward_time=0.229, loss_ctc=10.411, loss=10.411, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.760e-04, train_time=0.615
[ALab02] 2023-06-10 13:43:35,257 (trainer:721) INFO: 68epoch:train:1464-1540batch: iter_time=1.790e-04, forward_time=0.230, loss_ctc=9.824, loss=9.824, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.758e-04, train_time=0.618
[ALab02] 2023-06-10 13:44:18,007 (trainer:338) INFO: 68epoch results: [train] iter_time=8.412e-04, forward_time=0.231, loss_ctc=9.490, loss=9.490, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.778e-04, train_time=0.618, time=15 minutes and 59.78 seconds, total_count=105604, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.005, cer_ctc=0.282, cer=0.282, loss=14.005, time=6.73 seconds, total_count=1088, gpu_max_cached_mem_GB=77.078, [att_plot] time=28.16 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 13:44:20,500 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 13:44:20,501 (trainer:272) INFO: 69/70epoch started. Estimated time to finish: 45 minutes and 6.37 seconds
[ALab02] 2023-06-10 13:45:08,935 (trainer:721) INFO: 69epoch:train:1-77batch: iter_time=0.013, forward_time=0.230, loss_ctc=9.469, loss=9.469, backward_time=0.301, optim_step_time=0.040, optim0_lr0=5.756e-04, train_time=0.629
[ALab02] 2023-06-10 13:45:56,393 (trainer:721) INFO: 69epoch:train:78-154batch: iter_time=1.844e-04, forward_time=0.230, loss_ctc=9.059, loss=9.059, backward_time=0.305, optim_step_time=0.037, optim0_lr0=5.754e-04, train_time=0.616
[ALab02] 2023-06-10 13:46:43,904 (trainer:721) INFO: 69epoch:train:155-231batch: iter_time=1.566e-04, forward_time=0.230, loss_ctc=10.383, loss=10.383, backward_time=0.302, optim_step_time=0.039, optim0_lr0=5.752e-04, train_time=0.617
[ALab02] 2023-06-10 13:47:31,678 (trainer:721) INFO: 69epoch:train:232-308batch: iter_time=1.338e-04, forward_time=0.232, loss_ctc=9.410, loss=9.410, backward_time=0.307, optim_step_time=0.036, optim0_lr0=5.750e-04, train_time=0.620
[ALab02] 2023-06-10 13:48:19,960 (trainer:721) INFO: 69epoch:train:309-385batch: iter_time=1.632e-04, forward_time=0.238, loss_ctc=9.012, loss=9.012, backward_time=0.309, optim_step_time=0.038, optim0_lr0=5.748e-04, train_time=0.627
[ALab02] 2023-06-10 13:49:07,749 (trainer:721) INFO: 69epoch:train:386-462batch: iter_time=1.568e-04, forward_time=0.232, loss_ctc=8.853, loss=8.853, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.745e-04, train_time=0.620
[ALab02] 2023-06-10 13:49:54,396 (trainer:721) INFO: 69epoch:train:463-539batch: iter_time=1.405e-04, forward_time=0.228, loss_ctc=10.403, loss=10.403, backward_time=0.299, optim_step_time=0.038, optim0_lr0=5.743e-04, train_time=0.606
[ALab02] 2023-06-10 13:50:41,313 (trainer:721) INFO: 69epoch:train:540-616batch: iter_time=1.636e-04, forward_time=0.227, loss_ctc=9.770, loss=9.770, backward_time=0.302, optim_step_time=0.037, optim0_lr0=5.741e-04, train_time=0.609
[ALab02] 2023-06-10 13:51:29,778 (trainer:721) INFO: 69epoch:train:617-693batch: iter_time=1.423e-04, forward_time=0.241, loss_ctc=9.392, loss=9.392, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.739e-04, train_time=0.629
[ALab02] 2023-06-10 13:52:16,919 (trainer:721) INFO: 69epoch:train:694-770batch: iter_time=1.282e-04, forward_time=0.230, loss_ctc=10.056, loss=10.056, backward_time=0.303, optim_step_time=0.037, optim0_lr0=5.737e-04, train_time=0.612
[ALab02] 2023-06-10 13:53:04,481 (trainer:721) INFO: 69epoch:train:771-847batch: iter_time=1.960e-04, forward_time=0.232, loss_ctc=10.570, loss=10.570, backward_time=0.305, optim_step_time=0.039, optim0_lr0=5.735e-04, train_time=0.617
[ALab02] 2023-06-10 13:53:52,334 (trainer:721) INFO: 69epoch:train:848-924batch: iter_time=1.444e-04, forward_time=0.234, loss_ctc=9.074, loss=9.074, backward_time=0.305, optim_step_time=0.038, optim0_lr0=5.733e-04, train_time=0.621
[ALab02] 2023-06-10 13:54:40,399 (trainer:721) INFO: 69epoch:train:925-1001batch: iter_time=1.388e-04, forward_time=0.236, loss_ctc=9.562, loss=9.562, backward_time=0.309, optim_step_time=0.037, optim0_lr0=5.731e-04, train_time=0.624
[ALab02] 2023-06-10 13:55:27,702 (trainer:721) INFO: 69epoch:train:1002-1078batch: iter_time=1.354e-04, forward_time=0.230, loss_ctc=9.105, loss=9.105, backward_time=0.304, optim_step_time=0.036, optim0_lr0=5.729e-04, train_time=0.614
[ALab02] 2023-06-10 13:56:15,161 (trainer:721) INFO: 69epoch:train:1079-1155batch: iter_time=1.731e-04, forward_time=0.233, loss_ctc=9.967, loss=9.967, backward_time=0.301, optim_step_time=0.038, optim0_lr0=5.727e-04, train_time=0.616
[ALab02] 2023-06-10 13:57:02,983 (trainer:721) INFO: 69epoch:train:1156-1232batch: iter_time=1.705e-04, forward_time=0.233, loss_ctc=9.290, loss=9.290, backward_time=0.304, optim_step_time=0.038, optim0_lr0=5.725e-04, train_time=0.621
[ALab02] 2023-06-10 13:57:50,199 (trainer:721) INFO: 69epoch:train:1233-1309batch: iter_time=1.528e-04, forward_time=0.230, loss_ctc=9.606, loss=9.606, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.723e-04, train_time=0.613
[ALab02] 2023-06-10 13:58:36,390 (trainer:721) INFO: 69epoch:train:1310-1386batch: iter_time=1.203e-04, forward_time=0.221, loss_ctc=10.583, loss=10.583, backward_time=0.302, optim_step_time=0.036, optim0_lr0=5.721e-04, train_time=0.600
[ALab02] 2023-06-10 13:59:24,448 (trainer:721) INFO: 69epoch:train:1387-1463batch: iter_time=1.151e-04, forward_time=0.237, loss_ctc=8.131, loss=8.131, backward_time=0.308, optim_step_time=0.037, optim0_lr0=5.718e-04, train_time=0.624
[ALab02] 2023-06-10 14:00:11,589 (trainer:721) INFO: 69epoch:train:1464-1540batch: iter_time=1.360e-04, forward_time=0.227, loss_ctc=10.644, loss=10.644, backward_time=0.305, optim_step_time=0.036, optim0_lr0=5.716e-04, train_time=0.612
[ALab02] 2023-06-10 14:00:53,106 (trainer:338) INFO: 69epoch results: [train] iter_time=7.969e-04, forward_time=0.231, loss_ctc=9.579, loss=9.579, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.736e-04, train_time=0.617, time=15 minutes and 59.14 seconds, total_count=107157, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.400, cer_ctc=0.279, cer=0.279, loss=14.400, time=6.65 seconds, total_count=1104, gpu_max_cached_mem_GB=77.078, [att_plot] time=26.82 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 14:00:55,346 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 14:00:55,363 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/68epoch.pth
[ALab02] 2023-06-10 14:00:55,363 (trainer:272) INFO: 70/70epoch started. Estimated time to finish: 22 minutes and 27.99 seconds
[ALab02] 2023-06-10 14:01:44,554 (trainer:721) INFO: 70epoch:train:1-77batch: iter_time=0.015, forward_time=0.235, loss_ctc=9.153, loss=9.153, backward_time=0.306, optim_step_time=0.037, optim0_lr0=5.714e-04, train_time=0.639
[ALab02] 2023-06-10 14:02:33,218 (trainer:721) INFO: 70epoch:train:78-154batch: iter_time=1.423e-04, forward_time=0.238, loss_ctc=9.826, loss=9.826, backward_time=0.309, optim_step_time=0.038, optim0_lr0=5.712e-04, train_time=0.632
[ALab02] 2023-06-10 14:03:20,395 (trainer:721) INFO: 70epoch:train:155-231batch: iter_time=1.443e-04, forward_time=0.230, loss_ctc=10.597, loss=10.597, backward_time=0.300, optim_step_time=0.038, optim0_lr0=5.710e-04, train_time=0.612
[ALab02] 2023-06-10 14:04:08,192 (trainer:721) INFO: 70epoch:train:232-308batch: iter_time=1.493e-04, forward_time=0.232, loss_ctc=9.729, loss=9.729, backward_time=0.308, optim_step_time=0.038, optim0_lr0=5.708e-04, train_time=0.621
[ALab02] 2023-06-10 14:04:55,781 (trainer:721) INFO: 70epoch:train:309-385batch: iter_time=1.428e-04, forward_time=0.232, loss_ctc=8.183, loss=8.183, backward_time=0.307, optim_step_time=0.039, optim0_lr0=5.706e-04, train_time=0.618
[ALab02] 2023-06-10 14:05:43,611 (trainer:721) INFO: 70epoch:train:386-462batch: iter_time=1.326e-04, forward_time=0.234, loss_ctc=9.910, loss=9.910, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.704e-04, train_time=0.621
[ALab02] 2023-06-10 14:06:31,360 (trainer:721) INFO: 70epoch:train:463-539batch: iter_time=1.708e-04, forward_time=0.229, loss_ctc=9.176, loss=9.176, backward_time=0.306, optim_step_time=0.040, optim0_lr0=5.702e-04, train_time=0.620
[ALab02] 2023-06-10 14:07:18,788 (trainer:721) INFO: 70epoch:train:540-616batch: iter_time=1.620e-04, forward_time=0.230, loss_ctc=10.397, loss=10.397, backward_time=0.303, optim_step_time=0.039, optim0_lr0=5.700e-04, train_time=0.616
[ALab02] 2023-06-10 14:08:06,281 (trainer:721) INFO: 70epoch:train:617-693batch: iter_time=1.422e-04, forward_time=0.232, loss_ctc=9.448, loss=9.448, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.698e-04, train_time=0.617
[ALab02] 2023-06-10 14:08:54,302 (trainer:721) INFO: 70epoch:train:694-770batch: iter_time=1.403e-04, forward_time=0.235, loss_ctc=8.966, loss=8.966, backward_time=0.308, optim_step_time=0.037, optim0_lr0=5.696e-04, train_time=0.623
[ALab02] 2023-06-10 14:09:41,368 (trainer:721) INFO: 70epoch:train:771-847batch: iter_time=1.322e-04, forward_time=0.230, loss_ctc=9.472, loss=9.472, backward_time=0.302, optim_step_time=0.039, optim0_lr0=5.694e-04, train_time=0.611
[ALab02] 2023-06-10 14:10:28,325 (trainer:721) INFO: 70epoch:train:848-924batch: iter_time=1.354e-04, forward_time=0.226, loss_ctc=8.645, loss=8.645, backward_time=0.304, optim_step_time=0.036, optim0_lr0=5.692e-04, train_time=0.610
[ALab02] 2023-06-10 14:11:15,458 (trainer:721) INFO: 70epoch:train:925-1001batch: iter_time=1.789e-04, forward_time=0.230, loss_ctc=10.945, loss=10.945, backward_time=0.296, optim_step_time=0.040, optim0_lr0=5.690e-04, train_time=0.612
[ALab02] 2023-06-10 14:12:03,093 (trainer:721) INFO: 70epoch:train:1002-1078batch: iter_time=1.425e-04, forward_time=0.232, loss_ctc=9.059, loss=9.059, backward_time=0.307, optim_step_time=0.038, optim0_lr0=5.688e-04, train_time=0.618
[ALab02] 2023-06-10 14:12:50,515 (trainer:721) INFO: 70epoch:train:1079-1155batch: iter_time=1.414e-04, forward_time=0.229, loss_ctc=8.874, loss=8.874, backward_time=0.309, optim_step_time=0.038, optim0_lr0=5.686e-04, train_time=0.616
[ALab02] 2023-06-10 14:13:37,620 (trainer:721) INFO: 70epoch:train:1156-1232batch: iter_time=1.255e-04, forward_time=0.230, loss_ctc=9.333, loss=9.333, backward_time=0.303, optim_step_time=0.038, optim0_lr0=5.683e-04, train_time=0.612
[ALab02] 2023-06-10 14:14:25,095 (trainer:721) INFO: 70epoch:train:1233-1309batch: iter_time=1.370e-04, forward_time=0.233, loss_ctc=9.324, loss=9.324, backward_time=0.304, optim_step_time=0.037, optim0_lr0=5.681e-04, train_time=0.616
[ALab02] 2023-06-10 14:15:11,955 (trainer:721) INFO: 70epoch:train:1310-1386batch: iter_time=1.488e-04, forward_time=0.228, loss_ctc=9.547, loss=9.547, backward_time=0.301, optim_step_time=0.037, optim0_lr0=5.679e-04, train_time=0.608
[ALab02] 2023-06-10 14:16:00,267 (trainer:721) INFO: 70epoch:train:1387-1463batch: iter_time=1.371e-04, forward_time=0.236, loss_ctc=8.545, loss=8.545, backward_time=0.307, optim_step_time=0.039, optim0_lr0=5.677e-04, train_time=0.627
[ALab02] 2023-06-10 14:16:47,472 (trainer:721) INFO: 70epoch:train:1464-1540batch: iter_time=1.342e-04, forward_time=0.230, loss_ctc=9.170, loss=9.170, backward_time=0.303, optim_step_time=0.036, optim0_lr0=5.675e-04, train_time=0.613
[ALab02] 2023-06-10 14:17:31,755 (trainer:338) INFO: 70epoch results: [train] iter_time=8.720e-04, forward_time=0.232, loss_ctc=9.379, loss=9.379, backward_time=0.304, optim_step_time=0.038, optim0_lr0=5.695e-04, train_time=0.618, time=16 minutes and 0.11 seconds, total_count=108710, gpu_max_cached_mem_GB=77.078, [valid] loss_ctc=14.245, cer_ctc=0.280, cer=0.280, loss=14.245, time=7.01 seconds, total_count=1120, gpu_max_cached_mem_GB=77.078, [att_plot] time=29.27 seconds, total_count=0, gpu_max_cached_mem_GB=77.078
[ALab02] 2023-06-10 14:17:34,067 (trainer:384) INFO: There are no improvements in this epoch
[ALab02] 2023-06-10 14:17:34,069 (trainer:440) INFO: The model files were removed: exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/69epoch.pth
[ALab02] 2023-06-10 14:17:34,070 (trainer:458) INFO: The training was finished at 70 epochs 
[ALab02] 2023-06-10 14:17:34,094 (average_nbest_models:69) INFO: Averaging 10best models: criterion="valid.cer": exp_uma_branchformer_12e_69/asr_train_asr_uma_branchformer_raw_zh_char_sp/valid.cer.ave_10best.pth
# Accounting: time=94027 threads=1
# Ended (code 0) at Sat Jun 10 14:17:39 CST 2023, elapsed time 94027 seconds
