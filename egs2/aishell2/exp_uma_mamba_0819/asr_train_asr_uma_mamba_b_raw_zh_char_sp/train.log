# python3 -m espnet2.bin.asr_unimodal_train --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev_ios/wav.scp,speech,sound --valid_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 51200 --output_dir exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp --config conf/train_asr_uma_mamba_b.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_noeng_sp/wav.scp,speech,sound --train_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_noeng_sp/text,text,text --train_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/dev_ios/text,text,text --valid_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Tue Aug 27 10:55:44 CST 2024
#
/data/home/fangying/anaconda3/envs/espnet/bin/python3 /data/home/fangying/espnet/espnet2/bin/asr_unimodal_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev_ios/wav.scp,speech,sound --valid_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 51200 --output_dir exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp --config conf/train_asr_uma_mamba_b.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_noeng_sp/wav.scp,speech,sound --train_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_noeng_sp/text,text,text --train_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/dev_ios/text,text,text --valid_shape_file exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 1 --multiprocessing_distributed True
[alab02] 2024-08-27 10:55:49,405 (asr_unimodal:530) INFO: Vocabulary size: 5179
[alab02] 2024-08-27 10:55:53,161 (abs_task:1202) INFO: pytorch.version=1.12.1, cuda.available=True, cudnn.version=8302, cudnn.benchmark=False, cudnn.deterministic=True
[alab02] 2024-08-27 10:55:53,167 (abs_task:1203) INFO: Model structure:
UAMASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=128, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 27], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): MambaEncoder(
    (embed): CausalConv2dSubsampling(
      (subsample1): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(2, 0))
        (1): ReLU()
      )
      (subsample2): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(2, 0))
        (1): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=9728, out_features=512, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (norm_before_mamba): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (layers): ModuleList(
      (0): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (1): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (2): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (3): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (4): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (5): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (6): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (7): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (8): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (9): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (10): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (11): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (12): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (13): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (14): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (15): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (16): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (17): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (18): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (19): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (20): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (21): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (22): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (23): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (24): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (25): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (26): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (27): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (28): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (29): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (30): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (31): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (32): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (33): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (34): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
      (35): Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=512, out_features=2048, bias=False)
          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          (act): SiLU()
          (x_proj): Linear(in_features=1024, out_features=96, bias=False)
          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=512, bias=False)
        )
        (norm): RMSNorm()
      )
    )
    (norm_f): RMSNorm()
    (lookahead_cnn): Conv1d(512, 512, kernel_size=(29,), stride=(1,), padding=(14,))
    (activation): Swish()
    (lookahead_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (uma): UMA(
    (linear_sigmoid): Sequential(
      (0): Linear(in_features=512, out_features=1, bias=True)
      (1): Sigmoid()
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): UnimodalAttentionDecoder(
    (embed): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): Swish()
      (4): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): StreamingMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): StreamingMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): StreamingMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): StreamingMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): StreamingMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): StreamingMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=5179, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: UAMASRModel
    Total Number of model parameters: 99.59 M
    Number of trainable parameters: 99.59 M (100.0%)
    Size: 398.35 MB
    Type: torch.float32
[alab02] 2024-08-27 10:55:53,167 (abs_task:1206) INFO: Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0005
    lr: 1.6666666666666667e-08
    maximize: False
    weight_decay: 0.1
)
[alab02] 2024-08-27 10:55:53,167 (abs_task:1207) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[alab02] 2024-08-27 10:55:53,167 (abs_task:1216) INFO: Saving the configuration in exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/config.yaml
[alab02] 2024-08-27 10:56:00,154 (asr_unimodal:501) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[alab02] 2024-08-27 10:56:23,226 (abs_task:1571) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_noeng_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_noeng_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fc67c388e80>)
[alab02] 2024-08-27 10:56:23,226 (abs_task:1572) INFO: [train] Batch sampler: FoldedBatchSampler(N-batch=35633, batch_size=128, shape_files=['exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/speech_shape', 'exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/train/text_shape.char'], sort_in_batch=descending, sort_batch=descending)
[alab02] 2024-08-27 10:56:23,231 (abs_task:1573) INFO: [train] mini-batch sizes summary: N-batch=35633, mean=81.1, min=1, max=128
[alab02] 2024-08-27 10:56:23,352 (asr_unimodal:501) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[alab02] 2024-08-27 10:56:23,362 (abs_task:1571) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev_ios/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev_ios/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fc694453490>)
[alab02] 2024-08-27 10:56:23,362 (abs_task:1572) INFO: [valid] Batch sampler: FoldedBatchSampler(N-batch=26, batch_size=128, shape_files=['exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/speech_shape', 'exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/text_shape.char'], sort_in_batch=descending, sort_batch=descending)
[alab02] 2024-08-27 10:56:23,362 (abs_task:1573) INFO: [valid] mini-batch sizes summary: N-batch=26, mean=96.2, min=4, max=128
[alab02] 2024-08-27 10:56:23,368 (asr_unimodal:501) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[alab02] 2024-08-27 10:56:23,406 (abs_task:1571) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev_ios/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev_ios/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fc694453190>)
[alab02] 2024-08-27 10:56:23,406 (abs_task:1572) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=2500, batch_size=1, key_file=exp_uma_mamba_0819/asr_stats_raw_zh_char_sp/valid/speech_shape, 
[alab02] 2024-08-27 10:56:23,406 (abs_task:1573) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
[alab02] 2024-08-27 10:56:23,568 (trainer:284) INFO: 1/150epoch started
[alab02] 2024-08-27 10:57:59,783 (trainer:720) INFO: 1epoch:train:1-200batch: iter_time=0.002, forward_time=0.156, uma_reduction=0.319, text_vs_uma=0.300, loss_ctc=184.436, loss=92.218, backward_time=0.197, optim_step_time=0.033, optim0_lr0=8.583e-07, train_time=0.961
[alab02] 2024-08-27 10:59:27,465 (trainer:720) INFO: 1epoch:train:201-400batch: iter_time=2.029e-04, forward_time=0.135, uma_reduction=0.322, text_vs_uma=0.304, loss_ctc=97.701, loss=48.851, backward_time=0.176, optim_step_time=0.033, optim0_lr0=2.525e-06, train_time=0.877
[alab02] 2024-08-27 11:00:54,668 (trainer:720) INFO: 1epoch:train:401-600batch: iter_time=2.395e-04, forward_time=0.135, uma_reduction=0.322, text_vs_uma=0.298, loss_ctc=89.325, loss=44.662, backward_time=0.179, optim_step_time=0.032, optim0_lr0=4.192e-06, train_time=0.872
[alab02] 2024-08-27 11:02:23,395 (trainer:720) INFO: 1epoch:train:601-800batch: iter_time=1.891e-04, forward_time=0.138, uma_reduction=0.322, text_vs_uma=0.300, loss_ctc=87.246, loss=43.623, backward_time=0.181, optim_step_time=0.032, optim0_lr0=5.858e-06, train_time=0.887
[alab02] 2024-08-27 11:03:52,135 (trainer:720) INFO: 1epoch:train:801-1000batch: iter_time=1.908e-04, forward_time=0.136, uma_reduction=0.321, text_vs_uma=0.307, loss_ctc=87.163, loss=43.582, backward_time=0.181, optim_step_time=0.032, optim0_lr0=7.525e-06, train_time=0.887
[alab02] 2024-08-27 11:05:18,325 (trainer:720) INFO: 1epoch:train:1001-1200batch: iter_time=1.845e-04, forward_time=0.133, uma_reduction=0.320, text_vs_uma=0.296, loss_ctc=77.213, loss=38.606, backward_time=0.175, optim_step_time=0.031, optim0_lr0=9.192e-06, train_time=0.862
[alab02] 2024-08-27 11:06:58,877 (trainer:720) INFO: 1epoch:train:1201-1400batch: iter_time=4.619e-04, forward_time=0.168, uma_reduction=0.319, text_vs_uma=0.296, loss_ctc=74.219, loss=37.110, backward_time=0.202, optim_step_time=0.060, optim0_lr0=1.086e-05, train_time=1.005
[alab02] 2024-08-27 11:08:46,969 (trainer:720) INFO: 1epoch:train:1401-1600batch: iter_time=7.800e-04, forward_time=0.187, uma_reduction=0.319, text_vs_uma=0.302, loss_ctc=79.606, loss=39.803, backward_time=0.212, optim_step_time=0.074, optim0_lr0=1.252e-05, train_time=1.080
[alab02] 2024-08-27 11:10:36,288 (trainer:720) INFO: 1epoch:train:1601-1800batch: iter_time=7.793e-04, forward_time=0.186, uma_reduction=0.319, text_vs_uma=0.295, loss_ctc=69.415, loss=34.708, backward_time=0.223, optim_step_time=0.072, optim0_lr0=1.419e-05, train_time=1.092
[alab02] 2024-08-27 11:12:19,105 (trainer:720) INFO: 1epoch:train:1801-2000batch: iter_time=6.954e-04, forward_time=0.172, uma_reduction=0.319, text_vs_uma=0.294, loss_ctc=72.673, loss=36.337, backward_time=0.204, optim_step_time=0.068, optim0_lr0=1.586e-05, train_time=1.028
[alab02] 2024-08-27 11:13:59,561 (trainer:720) INFO: 1epoch:train:2001-2200batch: iter_time=8.093e-04, forward_time=0.166, uma_reduction=0.318, text_vs_uma=0.311, loss_ctc=76.639, loss=38.320, backward_time=0.196, optim_step_time=0.062, optim0_lr0=1.752e-05, train_time=1.004
[alab02] 2024-08-27 11:15:42,921 (trainer:720) INFO: 1epoch:train:2201-2400batch: iter_time=7.651e-04, forward_time=0.170, uma_reduction=0.315, text_vs_uma=0.312, loss_ctc=71.621, loss=35.811, backward_time=0.209, optim_step_time=0.063, optim0_lr0=1.919e-05, train_time=1.033
[alab02] 2024-08-27 11:17:26,112 (trainer:720) INFO: 1epoch:train:2401-2600batch: iter_time=6.173e-04, forward_time=0.169, uma_reduction=0.311, text_vs_uma=0.307, loss_ctc=72.702, loss=36.351, backward_time=0.205, optim_step_time=0.066, optim0_lr0=2.086e-05, train_time=1.031
[alab02] 2024-08-27 11:19:08,206 (trainer:720) INFO: 1epoch:train:2601-2800batch: iter_time=6.279e-04, forward_time=0.170, uma_reduction=0.303, text_vs_uma=0.320, loss_ctc=74.983, loss=37.492, backward_time=0.200, optim_step_time=0.067, optim0_lr0=2.253e-05, train_time=1.020
[alab02] 2024-08-27 11:20:51,330 (trainer:720) INFO: 1epoch:train:2801-3000batch: iter_time=6.429e-04, forward_time=0.169, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=70.886, loss=35.443, backward_time=0.208, optim_step_time=0.064, optim0_lr0=2.419e-05, train_time=1.031
[alab02] 2024-08-27 11:22:32,836 (trainer:720) INFO: 1epoch:train:3001-3200batch: iter_time=7.430e-04, forward_time=0.167, uma_reduction=0.189, text_vs_uma=0.522, loss_ctc=71.117, loss=35.559, backward_time=0.201, optim_step_time=0.067, optim0_lr0=2.586e-05, train_time=1.014
[alab02] 2024-08-27 11:24:14,872 (trainer:720) INFO: 1epoch:train:3201-3400batch: iter_time=7.646e-04, forward_time=0.168, uma_reduction=0.177, text_vs_uma=0.544, loss_ctc=63.912, loss=31.956, backward_time=0.208, optim_step_time=0.063, optim0_lr0=2.753e-05, train_time=1.020
[alab02] 2024-08-27 11:25:55,864 (trainer:720) INFO: 1epoch:train:3401-3600batch: iter_time=7.224e-04, forward_time=0.166, uma_reduction=0.201, text_vs_uma=0.492, loss_ctc=64.807, loss=32.404, backward_time=0.203, optim_step_time=0.063, optim0_lr0=2.919e-05, train_time=1.009
[alab02] 2024-08-27 11:27:37,402 (trainer:720) INFO: 1epoch:train:3601-3800batch: iter_time=6.464e-04, forward_time=0.168, uma_reduction=0.217, text_vs_uma=0.439, loss_ctc=63.167, loss=31.583, backward_time=0.201, optim_step_time=0.062, optim0_lr0=3.086e-05, train_time=1.015
[alab02] 2024-08-27 11:29:17,284 (trainer:720) INFO: 1epoch:train:3801-4000batch: iter_time=8.364e-04, forward_time=0.163, uma_reduction=0.210, text_vs_uma=0.456, loss_ctc=64.996, loss=32.498, backward_time=0.196, optim_step_time=0.062, optim0_lr0=3.252e-05, train_time=0.998
[alab02] 2024-08-27 11:31:00,017 (trainer:720) INFO: 1epoch:train:4001-4200batch: iter_time=6.229e-04, forward_time=0.172, uma_reduction=0.214, text_vs_uma=0.444, loss_ctc=60.510, loss=30.255, backward_time=0.207, optim_step_time=0.063, optim0_lr0=3.419e-05, train_time=1.027
[alab02] 2024-08-27 11:32:42,132 (trainer:720) INFO: 1epoch:train:4201-4400batch: iter_time=7.227e-04, forward_time=0.170, uma_reduction=0.212, text_vs_uma=0.460, loss_ctc=58.588, loss=29.294, backward_time=0.202, optim_step_time=0.068, optim0_lr0=3.586e-05, train_time=1.021
[alab02] 2024-08-27 11:34:24,290 (trainer:720) INFO: 1epoch:train:4401-4600batch: iter_time=8.652e-04, forward_time=0.167, uma_reduction=0.219, text_vs_uma=0.444, loss_ctc=60.468, loss=30.234, backward_time=0.203, optim_step_time=0.071, optim0_lr0=3.753e-05, train_time=1.021
[alab02] 2024-08-27 11:36:07,296 (trainer:720) INFO: 1epoch:train:4601-4800batch: iter_time=8.016e-04, forward_time=0.171, uma_reduction=0.224, text_vs_uma=0.428, loss_ctc=59.873, loss=29.936, backward_time=0.202, optim_step_time=0.069, optim0_lr0=3.919e-05, train_time=1.029
[alab02] 2024-08-27 11:37:51,257 (trainer:720) INFO: 1epoch:train:4801-5000batch: iter_time=9.326e-04, forward_time=0.173, uma_reduction=0.214, text_vs_uma=0.456, loss_ctc=60.470, loss=30.235, backward_time=0.204, optim_step_time=0.067, optim0_lr0=4.086e-05, train_time=1.039
[alab02] 2024-08-27 11:39:35,608 (trainer:720) INFO: 1epoch:train:5001-5200batch: iter_time=5.704e-04, forward_time=0.176, uma_reduction=0.225, text_vs_uma=0.432, loss_ctc=57.343, loss=28.672, backward_time=0.206, optim_step_time=0.069, optim0_lr0=4.252e-05, train_time=1.043
[alab02] 2024-08-27 11:41:20,281 (trainer:720) INFO: 1epoch:train:5201-5400batch: iter_time=5.802e-04, forward_time=0.177, uma_reduction=0.229, text_vs_uma=0.421, loss_ctc=54.170, loss=27.085, backward_time=0.211, optim_step_time=0.069, optim0_lr0=4.419e-05, train_time=1.046
[alab02] 2024-08-27 11:43:03,835 (trainer:720) INFO: 1epoch:train:5401-5600batch: iter_time=5.224e-04, forward_time=0.174, uma_reduction=0.228, text_vs_uma=0.416, loss_ctc=53.952, loss=26.976, backward_time=0.203, optim_step_time=0.066, optim0_lr0=4.586e-05, train_time=1.035
[alab02] 2024-08-27 11:44:48,952 (trainer:720) INFO: 1epoch:train:5601-5800batch: iter_time=5.070e-04, forward_time=0.177, uma_reduction=0.239, text_vs_uma=0.404, loss_ctc=53.902, loss=26.951, backward_time=0.210, optim_step_time=0.067, optim0_lr0=4.752e-05, train_time=1.051
[alab02] 2024-08-27 11:46:34,283 (trainer:720) INFO: 1epoch:train:5801-6000batch: iter_time=4.661e-04, forward_time=0.180, uma_reduction=0.247, text_vs_uma=0.400, loss_ctc=54.344, loss=27.172, backward_time=0.206, optim_step_time=0.066, optim0_lr0=4.919e-05, train_time=1.053
[alab02] 2024-08-27 11:48:18,450 (trainer:720) INFO: 1epoch:train:6001-6200batch: iter_time=5.674e-04, forward_time=0.175, uma_reduction=0.253, text_vs_uma=0.382, loss_ctc=50.635, loss=25.318, backward_time=0.207, optim_step_time=0.066, optim0_lr0=5.086e-05, train_time=1.041
[alab02] 2024-08-27 11:50:00,908 (trainer:720) INFO: 1epoch:train:6201-6400batch: iter_time=5.079e-04, forward_time=0.172, uma_reduction=0.257, text_vs_uma=0.371, loss_ctc=52.317, loss=26.159, backward_time=0.199, optim_step_time=0.066, optim0_lr0=5.253e-05, train_time=1.024
[alab02] 2024-08-27 11:51:42,813 (trainer:720) INFO: 1epoch:train:6401-6600batch: iter_time=4.968e-04, forward_time=0.169, uma_reduction=0.259, text_vs_uma=0.378, loss_ctc=49.615, loss=24.807, backward_time=0.202, optim_step_time=0.063, optim0_lr0=5.419e-05, train_time=1.018
[alab02] 2024-08-27 11:53:26,746 (trainer:720) INFO: 1epoch:train:6601-6800batch: iter_time=5.221e-04, forward_time=0.175, uma_reduction=0.261, text_vs_uma=0.361, loss_ctc=49.661, loss=24.830, backward_time=0.206, optim_step_time=0.068, optim0_lr0=5.586e-05, train_time=1.039
[alab02] 2024-08-27 11:55:10,822 (trainer:720) INFO: 1epoch:train:6801-7000batch: iter_time=5.319e-04, forward_time=0.177, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=51.439, loss=25.720, backward_time=0.207, optim_step_time=0.066, optim0_lr0=5.752e-05, train_time=1.040
[alab02] 2024-08-27 11:57:02,735 (trainer:338) INFO: 1epoch results: [train] iter_time=6.297e-04, forward_time=0.167, uma_reduction=0.264, text_vs_uma=0.378, loss_ctc=69.375, loss=34.688, backward_time=0.201, optim_step_time=0.061, optim0_lr0=2.972e-05, train_time=1.008, time=59 minutes and 54.72 seconds, total_count=7126, gpu_max_cached_mem_GB=26.838, [valid] uma_reduction=0.261, text_vs_uma=0.415, loss_ctc=49.981, cer_ctc=0.798, cer=0.798, loss=49.981, time=12.24 seconds, total_count=26, gpu_max_cached_mem_GB=35.895, [att_plot] time=32.17 seconds, total_count=0, gpu_max_cached_mem_GB=35.895
[alab02] 2024-08-27 11:57:13,452 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 11:57:13,453 (trainer:272) INFO: 2/150epoch started. Estimated time to finish: 6 days, 7 hours and 3 minutes
[alab02] 2024-08-27 11:59:03,224 (trainer:720) INFO: 2epoch:train:1-200batch: iter_time=0.004, forward_time=0.180, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=48.838, loss=24.419, backward_time=0.219, optim_step_time=0.071, optim0_lr0=6.024e-05, train_time=1.096
[alab02] 2024-08-27 12:00:49,722 (trainer:720) INFO: 2epoch:train:201-400batch: iter_time=5.868e-04, forward_time=0.181, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=47.547, loss=23.774, backward_time=0.213, optim_step_time=0.069, optim0_lr0=6.191e-05, train_time=1.064
[alab02] 2024-08-27 12:02:36,873 (trainer:720) INFO: 2epoch:train:401-600batch: iter_time=8.408e-04, forward_time=0.177, uma_reduction=0.271, text_vs_uma=0.350, loss_ctc=46.532, loss=23.266, backward_time=0.220, optim_step_time=0.067, optim0_lr0=6.358e-05, train_time=1.071
[alab02] 2024-08-27 12:04:20,790 (trainer:720) INFO: 2epoch:train:601-800batch: iter_time=5.577e-04, forward_time=0.172, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=45.455, loss=22.727, backward_time=0.210, optim_step_time=0.068, optim0_lr0=6.524e-05, train_time=1.039
[alab02] 2024-08-27 12:06:06,869 (trainer:720) INFO: 2epoch:train:801-1000batch: iter_time=5.346e-04, forward_time=0.177, uma_reduction=0.268, text_vs_uma=0.376, loss_ctc=47.872, loss=23.936, backward_time=0.210, optim_step_time=0.068, optim0_lr0=6.691e-05, train_time=1.060
[alab02] 2024-08-27 12:07:51,637 (trainer:720) INFO: 2epoch:train:1001-1200batch: iter_time=6.571e-04, forward_time=0.177, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=43.212, loss=21.606, backward_time=0.208, optim_step_time=0.068, optim0_lr0=6.857e-05, train_time=1.047
[alab02] 2024-08-27 12:09:35,615 (trainer:720) INFO: 2epoch:train:1201-1400batch: iter_time=6.160e-04, forward_time=0.173, uma_reduction=0.254, text_vs_uma=0.376, loss_ctc=40.935, loss=20.468, backward_time=0.208, optim_step_time=0.068, optim0_lr0=7.024e-05, train_time=1.039
[alab02] 2024-08-27 12:11:16,622 (trainer:720) INFO: 2epoch:train:1401-1600batch: iter_time=5.779e-04, forward_time=0.167, uma_reduction=0.256, text_vs_uma=0.378, loss_ctc=41.868, loss=20.934, backward_time=0.204, optim_step_time=0.063, optim0_lr0=7.191e-05, train_time=1.009
[alab02] 2024-08-27 12:12:58,287 (trainer:720) INFO: 2epoch:train:1601-1800batch: iter_time=5.582e-04, forward_time=0.168, uma_reduction=0.254, text_vs_uma=0.382, loss_ctc=40.153, loss=20.077, backward_time=0.204, optim_step_time=0.065, optim0_lr0=7.357e-05, train_time=1.016
[alab02] 2024-08-27 12:14:39,954 (trainer:720) INFO: 2epoch:train:1801-2000batch: iter_time=4.996e-04, forward_time=0.167, uma_reduction=0.246, text_vs_uma=0.393, loss_ctc=39.749, loss=19.874, backward_time=0.202, optim_step_time=0.063, optim0_lr0=7.524e-05, train_time=1.016
[alab02] 2024-08-27 12:16:19,124 (trainer:720) INFO: 2epoch:train:2001-2200batch: iter_time=4.175e-04, forward_time=0.162, uma_reduction=0.244, text_vs_uma=0.401, loss_ctc=39.105, loss=19.553, backward_time=0.197, optim_step_time=0.058, optim0_lr0=7.691e-05, train_time=0.991
[alab02] 2024-08-27 12:17:54,948 (trainer:720) INFO: 2epoch:train:2201-2400batch: iter_time=2.912e-04, forward_time=0.151, uma_reduction=0.241, text_vs_uma=0.400, loss_ctc=35.357, loss=17.678, backward_time=0.198, optim_step_time=0.045, optim0_lr0=7.857e-05, train_time=0.958
[alab02] 2024-08-27 12:19:25,653 (trainer:720) INFO: 2epoch:train:2401-2600batch: iter_time=2.732e-04, forward_time=0.142, uma_reduction=0.233, text_vs_uma=0.416, loss_ctc=33.656, loss=16.828, backward_time=0.188, optim_step_time=0.041, optim0_lr0=8.024e-05, train_time=0.907
[alab02] 2024-08-27 12:20:56,069 (trainer:720) INFO: 2epoch:train:2601-2800batch: iter_time=2.723e-04, forward_time=0.139, uma_reduction=0.231, text_vs_uma=0.431, loss_ctc=37.460, loss=18.730, backward_time=0.180, optim_step_time=0.039, optim0_lr0=8.191e-05, train_time=0.904
[alab02] 2024-08-27 12:22:26,242 (trainer:720) INFO: 2epoch:train:2801-3000batch: iter_time=2.640e-04, forward_time=0.141, uma_reduction=0.232, text_vs_uma=0.413, loss_ctc=34.595, loss=17.298, backward_time=0.178, optim_step_time=0.040, optim0_lr0=8.357e-05, train_time=0.901
[alab02] 2024-08-27 12:23:54,448 (trainer:720) INFO: 2epoch:train:3001-3200batch: iter_time=2.362e-04, forward_time=0.135, uma_reduction=0.223, text_vs_uma=0.435, loss_ctc=32.517, loss=16.259, backward_time=0.178, optim_step_time=0.039, optim0_lr0=8.524e-05, train_time=0.882
[alab02] 2024-08-27 12:25:24,141 (trainer:720) INFO: 2epoch:train:3201-3400batch: iter_time=2.562e-04, forward_time=0.137, uma_reduction=0.217, text_vs_uma=0.439, loss_ctc=29.445, loss=14.722, backward_time=0.185, optim_step_time=0.040, optim0_lr0=8.691e-05, train_time=0.897
[alab02] 2024-08-27 12:26:54,868 (trainer:720) INFO: 2epoch:train:3401-3600batch: iter_time=2.811e-04, forward_time=0.138, uma_reduction=0.212, text_vs_uma=0.452, loss_ctc=29.606, loss=14.803, backward_time=0.189, optim_step_time=0.039, optim0_lr0=8.857e-05, train_time=0.907
[alab02] 2024-08-27 12:28:25,013 (trainer:720) INFO: 2epoch:train:3601-3800batch: iter_time=2.349e-04, forward_time=0.137, uma_reduction=0.210, text_vs_uma=0.453, loss_ctc=28.585, loss=14.293, backward_time=0.188, optim_step_time=0.038, optim0_lr0=9.024e-05, train_time=0.901
[alab02] 2024-08-27 12:29:53,619 (trainer:720) INFO: 2epoch:train:3801-4000batch: iter_time=2.474e-04, forward_time=0.134, uma_reduction=0.213, text_vs_uma=0.451, loss_ctc=28.686, loss=14.343, backward_time=0.183, optim_step_time=0.037, optim0_lr0=9.191e-05, train_time=0.886
[alab02] 2024-08-27 12:31:22,067 (trainer:720) INFO: 2epoch:train:4001-4200batch: iter_time=2.480e-04, forward_time=0.134, uma_reduction=0.209, text_vs_uma=0.462, loss_ctc=27.666, loss=13.833, backward_time=0.181, optim_step_time=0.038, optim0_lr0=9.357e-05, train_time=0.884
[alab02] 2024-08-27 12:32:52,343 (trainer:720) INFO: 2epoch:train:4201-4400batch: iter_time=2.434e-04, forward_time=0.138, uma_reduction=0.199, text_vs_uma=0.497, loss_ctc=29.614, loss=14.807, backward_time=0.183, optim_step_time=0.038, optim0_lr0=9.524e-05, train_time=0.902
[alab02] 2024-08-27 12:34:21,338 (trainer:720) INFO: 2epoch:train:4401-4600batch: iter_time=2.435e-04, forward_time=0.136, uma_reduction=0.200, text_vs_uma=0.485, loss_ctc=27.898, loss=13.949, backward_time=0.181, optim_step_time=0.037, optim0_lr0=9.691e-05, train_time=0.890
[alab02] 2024-08-27 12:35:51,173 (trainer:720) INFO: 2epoch:train:4601-4800batch: iter_time=2.158e-04, forward_time=0.136, uma_reduction=0.196, text_vs_uma=0.490, loss_ctc=26.582, loss=13.291, backward_time=0.186, optim_step_time=0.036, optim0_lr0=9.857e-05, train_time=0.898
[alab02] 2024-08-27 12:37:18,896 (trainer:720) INFO: 2epoch:train:4801-5000batch: iter_time=2.155e-04, forward_time=0.132, uma_reduction=0.192, text_vs_uma=0.503, loss_ctc=25.703, loss=12.852, backward_time=0.181, optim_step_time=0.037, optim0_lr0=1.002e-04, train_time=0.877
[alab02] 2024-08-27 12:38:46,060 (trainer:720) INFO: 2epoch:train:5001-5200batch: iter_time=2.166e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.498, loss_ctc=24.804, loss=12.402, backward_time=0.177, optim_step_time=0.039, optim0_lr0=1.019e-04, train_time=0.871
[alab02] 2024-08-27 12:40:15,678 (trainer:720) INFO: 2epoch:train:5201-5400batch: iter_time=2.112e-04, forward_time=0.135, uma_reduction=0.192, text_vs_uma=0.493, loss_ctc=24.036, loss=12.018, backward_time=0.187, optim_step_time=0.036, optim0_lr0=1.036e-04, train_time=0.896
[alab02] 2024-08-27 12:41:43,462 (trainer:720) INFO: 2epoch:train:5401-5600batch: iter_time=2.166e-04, forward_time=0.132, uma_reduction=0.187, text_vs_uma=0.521, loss_ctc=25.790, loss=12.895, backward_time=0.178, optim_step_time=0.037, optim0_lr0=1.052e-04, train_time=0.878
[alab02] 2024-08-27 12:43:11,395 (trainer:720) INFO: 2epoch:train:5601-5800batch: iter_time=2.154e-04, forward_time=0.134, uma_reduction=0.188, text_vs_uma=0.503, loss_ctc=23.409, loss=11.704, backward_time=0.180, optim_step_time=0.037, optim0_lr0=1.069e-04, train_time=0.879
[alab02] 2024-08-27 12:44:42,295 (trainer:720) INFO: 2epoch:train:5801-6000batch: iter_time=2.408e-04, forward_time=0.138, uma_reduction=0.186, text_vs_uma=0.519, loss_ctc=23.883, loss=11.941, backward_time=0.187, optim_step_time=0.037, optim0_lr0=1.086e-04, train_time=0.909
[alab02] 2024-08-27 12:46:11,566 (trainer:720) INFO: 2epoch:train:6001-6200batch: iter_time=2.188e-04, forward_time=0.135, uma_reduction=0.185, text_vs_uma=0.519, loss_ctc=22.994, loss=11.497, backward_time=0.185, optim_step_time=0.037, optim0_lr0=1.102e-04, train_time=0.892
[alab02] 2024-08-27 12:47:42,848 (trainer:720) INFO: 2epoch:train:6201-6400batch: iter_time=2.427e-04, forward_time=0.140, uma_reduction=0.183, text_vs_uma=0.522, loss_ctc=23.913, loss=11.956, backward_time=0.185, optim_step_time=0.039, optim0_lr0=1.119e-04, train_time=0.912
[alab02] 2024-08-27 12:49:11,898 (trainer:720) INFO: 2epoch:train:6401-6600batch: iter_time=2.267e-04, forward_time=0.137, uma_reduction=0.184, text_vs_uma=0.518, loss_ctc=20.665, loss=10.333, backward_time=0.187, optim_step_time=0.037, optim0_lr0=1.136e-04, train_time=0.890
[alab02] 2024-08-27 12:50:41,525 (trainer:720) INFO: 2epoch:train:6601-6800batch: iter_time=2.125e-04, forward_time=0.136, uma_reduction=0.181, text_vs_uma=0.523, loss_ctc=20.329, loss=10.165, backward_time=0.189, optim_step_time=0.036, optim0_lr0=1.152e-04, train_time=0.896
[alab02] 2024-08-27 12:52:10,669 (trainer:720) INFO: 2epoch:train:6801-7000batch: iter_time=2.142e-04, forward_time=0.135, uma_reduction=0.180, text_vs_uma=0.521, loss_ctc=21.166, loss=10.583, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.169e-04, train_time=0.891
[alab02] 2024-08-27 12:53:26,906 (trainer:338) INFO: 2epoch results: [train] iter_time=4.455e-04, forward_time=0.148, uma_reduction=0.220, text_vs_uma=0.446, loss_ctc=32.331, loss=16.165, backward_time=0.192, optim_step_time=0.047, optim0_lr0=8.910e-05, train_time=0.940, time=55 minutes and 52.25 seconds, total_count=14252, gpu_max_cached_mem_GB=35.895, [valid] uma_reduction=0.144, text_vs_uma=0.755, loss_ctc=14.680, cer_ctc=0.310, cer=0.310, loss=14.680, time=6.28 seconds, total_count=52, gpu_max_cached_mem_GB=35.895, [att_plot] time=14.92 seconds, total_count=0, gpu_max_cached_mem_GB=35.895
[alab02] 2024-08-27 12:53:40,045 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 12:53:40,048 (trainer:272) INFO: 3/150epoch started. Estimated time to finish: 6 days, 38 minutes and 19.45 seconds
[alab02] 2024-08-27 12:55:30,783 (trainer:720) INFO: 3epoch:train:1-200batch: iter_time=0.005, forward_time=0.186, uma_reduction=0.180, text_vs_uma=0.530, loss_ctc=21.081, loss=10.541, backward_time=0.218, optim_step_time=0.073, optim0_lr0=1.196e-04, train_time=1.106
[alab02] 2024-08-27 12:57:17,847 (trainer:720) INFO: 3epoch:train:201-400batch: iter_time=7.151e-04, forward_time=0.180, uma_reduction=0.181, text_vs_uma=0.528, loss_ctc=21.103, loss=10.551, backward_time=0.216, optim_step_time=0.070, optim0_lr0=1.213e-04, train_time=1.070
[alab02] 2024-08-27 12:59:04,136 (trainer:720) INFO: 3epoch:train:401-600batch: iter_time=9.651e-04, forward_time=0.179, uma_reduction=0.178, text_vs_uma=0.551, loss_ctc=21.117, loss=10.558, backward_time=0.213, optim_step_time=0.072, optim0_lr0=1.230e-04, train_time=1.062
[alab02] 2024-08-27 13:00:51,199 (trainer:720) INFO: 3epoch:train:601-800batch: iter_time=7.085e-04, forward_time=0.178, uma_reduction=0.174, text_vs_uma=0.555, loss_ctc=21.307, loss=10.654, backward_time=0.211, optim_step_time=0.073, optim0_lr0=1.246e-04, train_time=1.070
[alab02] 2024-08-27 13:02:35,627 (trainer:720) INFO: 3epoch:train:801-1000batch: iter_time=6.979e-04, forward_time=0.174, uma_reduction=0.178, text_vs_uma=0.544, loss_ctc=20.788, loss=10.394, backward_time=0.207, optim_step_time=0.070, optim0_lr0=1.263e-04, train_time=1.044
[alab02] 2024-08-27 13:04:17,200 (trainer:720) INFO: 3epoch:train:1001-1200batch: iter_time=5.755e-04, forward_time=0.164, uma_reduction=0.176, text_vs_uma=0.546, loss_ctc=19.600, loss=9.800, backward_time=0.210, optim_step_time=0.061, optim0_lr0=1.280e-04, train_time=1.015
[alab02] 2024-08-27 13:05:53,464 (trainer:720) INFO: 3epoch:train:1201-1400batch: iter_time=4.068e-04, forward_time=0.154, uma_reduction=0.177, text_vs_uma=0.550, loss_ctc=19.423, loss=9.711, backward_time=0.195, optim_step_time=0.056, optim0_lr0=1.296e-04, train_time=0.962
[alab02] 2024-08-27 13:07:23,543 (trainer:720) INFO: 3epoch:train:1401-1600batch: iter_time=3.736e-04, forward_time=0.138, uma_reduction=0.177, text_vs_uma=0.559, loss_ctc=20.617, loss=10.309, backward_time=0.184, optim_step_time=0.043, optim0_lr0=1.313e-04, train_time=0.900
[alab02] 2024-08-27 13:08:51,719 (trainer:720) INFO: 3epoch:train:1601-1800batch: iter_time=2.135e-04, forward_time=0.132, uma_reduction=0.175, text_vs_uma=0.544, loss_ctc=19.839, loss=9.919, backward_time=0.182, optim_step_time=0.037, optim0_lr0=1.330e-04, train_time=0.881
[alab02] 2024-08-27 13:10:21,026 (trainer:720) INFO: 3epoch:train:1801-2000batch: iter_time=2.212e-04, forward_time=0.135, uma_reduction=0.175, text_vs_uma=0.557, loss_ctc=21.426, loss=10.713, backward_time=0.180, optim_step_time=0.037, optim0_lr0=1.346e-04, train_time=0.893
[alab02] 2024-08-27 13:11:51,313 (trainer:720) INFO: 3epoch:train:2001-2200batch: iter_time=2.296e-04, forward_time=0.136, uma_reduction=0.177, text_vs_uma=0.547, loss_ctc=19.820, loss=9.910, backward_time=0.186, optim_step_time=0.037, optim0_lr0=1.363e-04, train_time=0.903
[alab02] 2024-08-27 13:13:21,207 (trainer:720) INFO: 3epoch:train:2201-2400batch: iter_time=2.174e-04, forward_time=0.135, uma_reduction=0.176, text_vs_uma=0.551, loss_ctc=19.949, loss=9.974, backward_time=0.184, optim_step_time=0.038, optim0_lr0=1.380e-04, train_time=0.899
[alab02] 2024-08-27 13:14:49,530 (trainer:720) INFO: 3epoch:train:2401-2600batch: iter_time=2.364e-04, forward_time=0.133, uma_reduction=0.179, text_vs_uma=0.542, loss_ctc=20.273, loss=10.137, backward_time=0.179, optim_step_time=0.038, optim0_lr0=1.396e-04, train_time=0.883
[alab02] 2024-08-27 13:16:19,210 (trainer:720) INFO: 3epoch:train:2601-2800batch: iter_time=2.159e-04, forward_time=0.135, uma_reduction=0.179, text_vs_uma=0.524, loss_ctc=17.608, loss=8.804, backward_time=0.188, optim_step_time=0.037, optim0_lr0=1.413e-04, train_time=0.896
[alab02] 2024-08-27 13:17:46,280 (trainer:720) INFO: 3epoch:train:2801-3000batch: iter_time=2.072e-04, forward_time=0.131, uma_reduction=0.178, text_vs_uma=0.548, loss_ctc=18.819, loss=9.409, backward_time=0.179, optim_step_time=0.037, optim0_lr0=1.430e-04, train_time=0.870
[alab02] 2024-08-27 13:19:23,772 (trainer:720) INFO: 3epoch:train:3001-3200batch: iter_time=4.115e-04, forward_time=0.155, uma_reduction=0.177, text_vs_uma=0.530, loss_ctc=17.354, loss=8.677, backward_time=0.201, optim_step_time=0.054, optim0_lr0=1.446e-04, train_time=0.974
[alab02] 2024-08-27 13:21:07,211 (trainer:720) INFO: 3epoch:train:3201-3400batch: iter_time=5.637e-04, forward_time=0.176, uma_reduction=0.174, text_vs_uma=0.545, loss_ctc=17.364, loss=8.682, backward_time=0.206, optim_step_time=0.068, optim0_lr0=1.463e-04, train_time=1.034
[alab02] 2024-08-27 13:22:52,333 (trainer:720) INFO: 3epoch:train:3401-3600batch: iter_time=6.861e-04, forward_time=0.175, uma_reduction=0.175, text_vs_uma=0.549, loss_ctc=18.368, loss=9.184, backward_time=0.211, optim_step_time=0.068, optim0_lr0=1.480e-04, train_time=1.050
[alab02] 2024-08-27 13:24:39,326 (trainer:720) INFO: 3epoch:train:3601-3800batch: iter_time=5.670e-04, forward_time=0.178, uma_reduction=0.175, text_vs_uma=0.551, loss_ctc=19.690, loss=9.845, backward_time=0.214, optim_step_time=0.071, optim0_lr0=1.496e-04, train_time=1.069
[alab02] 2024-08-27 13:26:26,336 (trainer:720) INFO: 3epoch:train:3801-4000batch: iter_time=4.918e-04, forward_time=0.182, uma_reduction=0.178, text_vs_uma=0.534, loss_ctc=16.226, loss=8.113, backward_time=0.217, optim_step_time=0.073, optim0_lr0=1.513e-04, train_time=1.069
[alab02] 2024-08-27 13:28:10,456 (trainer:720) INFO: 3epoch:train:4001-4200batch: iter_time=5.172e-04, forward_time=0.172, uma_reduction=0.176, text_vs_uma=0.531, loss_ctc=17.878, loss=8.939, backward_time=0.212, optim_step_time=0.065, optim0_lr0=1.530e-04, train_time=1.041
[alab02] 2024-08-27 13:29:59,014 (trainer:720) INFO: 3epoch:train:4201-4400batch: iter_time=5.313e-04, forward_time=0.182, uma_reduction=0.175, text_vs_uma=0.548, loss_ctc=18.052, loss=9.026, backward_time=0.219, optim_step_time=0.071, optim0_lr0=1.546e-04, train_time=1.085
[alab02] 2024-08-27 13:31:43,543 (trainer:720) INFO: 3epoch:train:4401-4600batch: iter_time=5.083e-04, forward_time=0.174, uma_reduction=0.176, text_vs_uma=0.539, loss_ctc=17.249, loss=8.625, backward_time=0.208, optim_step_time=0.070, optim0_lr0=1.563e-04, train_time=1.045
[alab02] 2024-08-27 13:33:28,706 (trainer:720) INFO: 3epoch:train:4601-4800batch: iter_time=4.445e-04, forward_time=0.176, uma_reduction=0.178, text_vs_uma=0.541, loss_ctc=16.936, loss=8.468, backward_time=0.217, optim_step_time=0.067, optim0_lr0=1.580e-04, train_time=1.051
[alab02] 2024-08-27 13:35:15,205 (trainer:720) INFO: 3epoch:train:4801-5000batch: iter_time=5.564e-04, forward_time=0.177, uma_reduction=0.179, text_vs_uma=0.549, loss_ctc=18.449, loss=9.225, backward_time=0.220, optim_step_time=0.069, optim0_lr0=1.596e-04, train_time=1.064
[alab02] 2024-08-27 13:37:01,137 (trainer:720) INFO: 3epoch:train:5001-5200batch: iter_time=5.410e-04, forward_time=0.175, uma_reduction=0.182, text_vs_uma=0.540, loss_ctc=17.269, loss=8.634, backward_time=0.213, optim_step_time=0.071, optim0_lr0=1.613e-04, train_time=1.059
[alab02] 2024-08-27 13:38:41,797 (trainer:720) INFO: 3epoch:train:5201-5400batch: iter_time=7.127e-04, forward_time=0.164, uma_reduction=0.181, text_vs_uma=0.531, loss_ctc=16.330, loss=8.165, backward_time=0.203, optim_step_time=0.064, optim0_lr0=1.630e-04, train_time=1.006
[alab02] 2024-08-27 13:40:27,354 (trainer:720) INFO: 3epoch:train:5401-5600batch: iter_time=4.822e-04, forward_time=0.174, uma_reduction=0.181, text_vs_uma=0.533, loss_ctc=16.243, loss=8.121, backward_time=0.215, optim_step_time=0.065, optim0_lr0=1.646e-04, train_time=1.055
[alab02] 2024-08-27 13:42:08,676 (trainer:720) INFO: 3epoch:train:5601-5800batch: iter_time=5.029e-04, forward_time=0.165, uma_reduction=0.181, text_vs_uma=0.531, loss_ctc=16.206, loss=8.103, backward_time=0.206, optim_step_time=0.061, optim0_lr0=1.663e-04, train_time=1.013
[alab02] 2024-08-27 13:43:43,740 (trainer:720) INFO: 3epoch:train:5801-6000batch: iter_time=3.926e-04, forward_time=0.150, uma_reduction=0.182, text_vs_uma=0.513, loss_ctc=15.288, loss=7.644, backward_time=0.193, optim_step_time=0.053, optim0_lr0=1.680e-04, train_time=0.950
[alab02] 2024-08-27 13:45:14,172 (trainer:720) INFO: 3epoch:train:6001-6200batch: iter_time=2.511e-04, forward_time=0.139, uma_reduction=0.182, text_vs_uma=0.521, loss_ctc=15.599, loss=7.800, backward_time=0.187, optim_step_time=0.041, optim0_lr0=1.696e-04, train_time=0.904
[alab02] 2024-08-27 13:46:41,398 (trainer:720) INFO: 3epoch:train:6201-6400batch: iter_time=2.019e-04, forward_time=0.130, uma_reduction=0.181, text_vs_uma=0.543, loss_ctc=17.211, loss=8.606, backward_time=0.177, optim_step_time=0.037, optim0_lr0=1.713e-04, train_time=0.872
[alab02] 2024-08-27 13:48:10,133 (trainer:720) INFO: 3epoch:train:6401-6600batch: iter_time=2.043e-04, forward_time=0.134, uma_reduction=0.183, text_vs_uma=0.519, loss_ctc=16.003, loss=8.002, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.730e-04, train_time=0.887
[alab02] 2024-08-27 13:49:37,500 (trainer:720) INFO: 3epoch:train:6601-6800batch: iter_time=1.939e-04, forward_time=0.131, uma_reduction=0.187, text_vs_uma=0.518, loss_ctc=15.877, loss=7.938, backward_time=0.180, optim_step_time=0.036, optim0_lr0=1.746e-04, train_time=0.873
[alab02] 2024-08-27 13:51:07,883 (trainer:720) INFO: 3epoch:train:6801-7000batch: iter_time=2.096e-04, forward_time=0.136, uma_reduction=0.184, text_vs_uma=0.508, loss_ctc=15.134, loss=7.567, backward_time=0.189, optim_step_time=0.036, optim0_lr0=1.763e-04, train_time=0.904
[alab02] 2024-08-27 13:52:44,415 (trainer:338) INFO: 3epoch results: [train] iter_time=5.777e-04, forward_time=0.158, uma_reduction=0.179, text_vs_uma=0.538, loss_ctc=18.263, loss=9.132, backward_time=0.200, optim_step_time=0.056, optim0_lr0=1.485e-04, train_time=0.985, time=58 minutes and 34.08 seconds, total_count=21378, gpu_max_cached_mem_GB=35.895, [valid] uma_reduction=0.143, text_vs_uma=0.757, loss_ctc=10.074, cer_ctc=0.226, cer=0.226, loss=10.074, time=8.46 seconds, total_count=78, gpu_max_cached_mem_GB=35.895, [att_plot] time=21.82 seconds, total_count=0, gpu_max_cached_mem_GB=35.895
[alab02] 2024-08-27 13:52:56,894 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 13:52:56,895 (trainer:272) INFO: 4/150epoch started. Estimated time to finish: 6 days, 11 minutes and 13.03 seconds
[alab02] 2024-08-27 13:54:44,912 (trainer:720) INFO: 4epoch:train:1-200batch: iter_time=0.004, forward_time=0.178, uma_reduction=0.180, text_vs_uma=0.528, loss_ctc=15.922, loss=7.961, backward_time=0.216, optim_step_time=0.070, optim0_lr0=1.790e-04, train_time=1.079
[alab02] 2024-08-27 13:56:35,407 (trainer:720) INFO: 4epoch:train:201-400batch: iter_time=6.073e-04, forward_time=0.184, uma_reduction=0.184, text_vs_uma=0.523, loss_ctc=15.427, loss=7.714, backward_time=0.229, optim_step_time=0.075, optim0_lr0=1.807e-04, train_time=1.104
[alab02] 2024-08-27 13:58:19,620 (trainer:720) INFO: 4epoch:train:401-600batch: iter_time=5.198e-04, forward_time=0.175, uma_reduction=0.182, text_vs_uma=0.525, loss_ctc=15.675, loss=7.837, backward_time=0.212, optim_step_time=0.065, optim0_lr0=1.823e-04, train_time=1.042
[alab02] 2024-08-27 14:00:04,905 (trainer:720) INFO: 4epoch:train:601-800batch: iter_time=6.454e-04, forward_time=0.176, uma_reduction=0.182, text_vs_uma=0.527, loss_ctc=15.840, loss=7.920, backward_time=0.210, optim_step_time=0.066, optim0_lr0=1.840e-04, train_time=1.052
[alab02] 2024-08-27 14:01:50,981 (trainer:720) INFO: 4epoch:train:801-1000batch: iter_time=9.244e-04, forward_time=0.177, uma_reduction=0.183, text_vs_uma=0.531, loss_ctc=15.834, loss=7.917, backward_time=0.210, optim_step_time=0.070, optim0_lr0=1.857e-04, train_time=1.060
[alab02] 2024-08-27 14:03:36,445 (trainer:720) INFO: 4epoch:train:1001-1200batch: iter_time=7.636e-04, forward_time=0.172, uma_reduction=0.184, text_vs_uma=0.509, loss_ctc=14.620, loss=7.310, backward_time=0.215, optim_step_time=0.071, optim0_lr0=1.873e-04, train_time=1.054
[alab02] 2024-08-27 14:05:25,029 (trainer:720) INFO: 4epoch:train:1201-1400batch: iter_time=9.405e-04, forward_time=0.183, uma_reduction=0.185, text_vs_uma=0.516, loss_ctc=14.810, loss=7.405, backward_time=0.218, optim_step_time=0.075, optim0_lr0=1.890e-04, train_time=1.085
[alab02] 2024-08-27 14:07:10,120 (trainer:720) INFO: 4epoch:train:1401-1600batch: iter_time=5.309e-04, forward_time=0.176, uma_reduction=0.183, text_vs_uma=0.515, loss_ctc=14.943, loss=7.471, backward_time=0.211, optim_step_time=0.066, optim0_lr0=1.907e-04, train_time=1.050
[alab02] 2024-08-27 14:08:56,273 (trainer:720) INFO: 4epoch:train:1601-1800batch: iter_time=7.018e-04, forward_time=0.176, uma_reduction=0.185, text_vs_uma=0.521, loss_ctc=14.370, loss=7.185, backward_time=0.218, optim_step_time=0.068, optim0_lr0=1.923e-04, train_time=1.061
[alab02] 2024-08-27 14:10:44,703 (trainer:720) INFO: 4epoch:train:1801-2000batch: iter_time=7.439e-04, forward_time=0.184, uma_reduction=0.188, text_vs_uma=0.524, loss_ctc=14.529, loss=7.265, backward_time=0.221, optim_step_time=0.071, optim0_lr0=1.940e-04, train_time=1.084
[alab02] 2024-08-27 14:12:29,915 (trainer:720) INFO: 4epoch:train:2001-2200batch: iter_time=5.681e-04, forward_time=0.176, uma_reduction=0.186, text_vs_uma=0.518, loss_ctc=15.485, loss=7.743, backward_time=0.209, optim_step_time=0.065, optim0_lr0=1.957e-04, train_time=1.052
[alab02] 2024-08-27 14:14:11,241 (trainer:720) INFO: 4epoch:train:2201-2400batch: iter_time=5.674e-04, forward_time=0.165, uma_reduction=0.185, text_vs_uma=0.513, loss_ctc=14.266, loss=7.133, backward_time=0.205, optim_step_time=0.065, optim0_lr0=1.973e-04, train_time=1.013
[alab02] 2024-08-27 14:15:54,325 (trainer:720) INFO: 4epoch:train:2401-2600batch: iter_time=6.791e-04, forward_time=0.168, uma_reduction=0.185, text_vs_uma=0.511, loss_ctc=14.369, loss=7.185, backward_time=0.208, optim_step_time=0.067, optim0_lr0=1.990e-04, train_time=1.030
[alab02] 2024-08-27 14:17:35,737 (trainer:720) INFO: 4epoch:train:2601-2800batch: iter_time=7.135e-04, forward_time=0.164, uma_reduction=0.184, text_vs_uma=0.521, loss_ctc=14.914, loss=7.457, backward_time=0.202, optim_step_time=0.065, optim0_lr0=2.007e-04, train_time=1.013
[alab02] 2024-08-27 14:19:13,313 (trainer:720) INFO: 4epoch:train:2801-3000batch: iter_time=5.319e-04, forward_time=0.157, uma_reduction=0.186, text_vs_uma=0.511, loss_ctc=13.812, loss=6.906, backward_time=0.196, optim_step_time=0.056, optim0_lr0=2.023e-04, train_time=0.976
[alab02] 2024-08-27 14:20:45,757 (trainer:720) INFO: 4epoch:train:3001-3200batch: iter_time=2.288e-04, forward_time=0.139, uma_reduction=0.186, text_vs_uma=0.508, loss_ctc=14.675, loss=7.338, backward_time=0.191, optim_step_time=0.041, optim0_lr0=2.040e-04, train_time=0.924
[alab02] 2024-08-27 14:22:15,787 (trainer:720) INFO: 4epoch:train:3201-3400batch: iter_time=2.052e-04, forward_time=0.135, uma_reduction=0.183, text_vs_uma=0.525, loss_ctc=14.786, loss=7.393, backward_time=0.185, optim_step_time=0.038, optim0_lr0=2.057e-04, train_time=0.900
[alab02] 2024-08-27 14:23:45,649 (trainer:720) INFO: 4epoch:train:3401-3600batch: iter_time=2.176e-04, forward_time=0.135, uma_reduction=0.184, text_vs_uma=0.514, loss_ctc=13.774, loss=6.887, backward_time=0.188, optim_step_time=0.038, optim0_lr0=2.073e-04, train_time=0.898
[alab02] 2024-08-27 14:25:13,560 (trainer:720) INFO: 4epoch:train:3601-3800batch: iter_time=2.095e-04, forward_time=0.132, uma_reduction=0.188, text_vs_uma=0.521, loss_ctc=14.425, loss=7.212, backward_time=0.181, optim_step_time=0.038, optim0_lr0=2.090e-04, train_time=0.879
[alab02] 2024-08-27 14:26:41,495 (trainer:720) INFO: 4epoch:train:3801-4000batch: iter_time=1.803e-04, forward_time=0.132, uma_reduction=0.184, text_vs_uma=0.521, loss_ctc=13.832, loss=6.916, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.107e-04, train_time=0.879
[alab02] 2024-08-27 14:28:09,056 (trainer:720) INFO: 4epoch:train:4001-4200batch: iter_time=1.812e-04, forward_time=0.130, uma_reduction=0.186, text_vs_uma=0.525, loss_ctc=14.138, loss=7.069, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.123e-04, train_time=0.875
[alab02] 2024-08-27 14:29:35,953 (trainer:720) INFO: 4epoch:train:4201-4400batch: iter_time=2.142e-04, forward_time=0.129, uma_reduction=0.186, text_vs_uma=0.506, loss_ctc=13.221, loss=6.610, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.140e-04, train_time=0.869
[alab02] 2024-08-27 14:31:04,480 (trainer:720) INFO: 4epoch:train:4401-4600batch: iter_time=1.947e-04, forward_time=0.131, uma_reduction=0.185, text_vs_uma=0.532, loss_ctc=15.347, loss=7.674, backward_time=0.181, optim_step_time=0.037, optim0_lr0=2.157e-04, train_time=0.885
[alab02] 2024-08-27 14:32:31,120 (trainer:720) INFO: 4epoch:train:4601-4800batch: iter_time=2.061e-04, forward_time=0.130, uma_reduction=0.187, text_vs_uma=0.520, loss_ctc=13.639, loss=6.820, backward_time=0.179, optim_step_time=0.037, optim0_lr0=2.173e-04, train_time=0.866
[alab02] 2024-08-27 14:34:00,062 (trainer:720) INFO: 4epoch:train:4801-5000batch: iter_time=2.218e-04, forward_time=0.134, uma_reduction=0.189, text_vs_uma=0.511, loss_ctc=14.777, loss=7.388, backward_time=0.180, optim_step_time=0.037, optim0_lr0=2.190e-04, train_time=0.889
[alab02] 2024-08-27 14:35:31,406 (trainer:720) INFO: 4epoch:train:5001-5200batch: iter_time=2.092e-04, forward_time=0.137, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=13.398, loss=6.699, backward_time=0.194, optim_step_time=0.037, optim0_lr0=2.207e-04, train_time=0.913
[alab02] 2024-08-27 14:37:00,858 (trainer:720) INFO: 4epoch:train:5201-5400batch: iter_time=2.023e-04, forward_time=0.134, uma_reduction=0.187, text_vs_uma=0.511, loss_ctc=13.637, loss=6.819, backward_time=0.184, optim_step_time=0.037, optim0_lr0=2.223e-04, train_time=0.894
[alab02] 2024-08-27 14:38:27,620 (trainer:720) INFO: 4epoch:train:5401-5600batch: iter_time=1.892e-04, forward_time=0.129, uma_reduction=0.188, text_vs_uma=0.516, loss_ctc=13.525, loss=6.762, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.240e-04, train_time=0.867
[alab02] 2024-08-27 14:39:54,803 (trainer:720) INFO: 4epoch:train:5601-5800batch: iter_time=1.846e-04, forward_time=0.131, uma_reduction=0.185, text_vs_uma=0.522, loss_ctc=13.440, loss=6.720, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.257e-04, train_time=0.872
[alab02] 2024-08-27 14:41:23,990 (trainer:720) INFO: 4epoch:train:5801-6000batch: iter_time=2.017e-04, forward_time=0.134, uma_reduction=0.183, text_vs_uma=0.518, loss_ctc=13.563, loss=6.781, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.273e-04, train_time=0.892
[alab02] 2024-08-27 14:42:54,125 (trainer:720) INFO: 4epoch:train:6001-6200batch: iter_time=2.300e-04, forward_time=0.135, uma_reduction=0.188, text_vs_uma=0.507, loss_ctc=12.993, loss=6.497, backward_time=0.190, optim_step_time=0.037, optim0_lr0=2.290e-04, train_time=0.901
[alab02] 2024-08-27 14:44:21,971 (trainer:720) INFO: 4epoch:train:6201-6400batch: iter_time=2.010e-04, forward_time=0.132, uma_reduction=0.188, text_vs_uma=0.516, loss_ctc=12.897, loss=6.449, backward_time=0.183, optim_step_time=0.037, optim0_lr0=2.307e-04, train_time=0.878
[alab02] 2024-08-27 14:45:51,328 (trainer:720) INFO: 4epoch:train:6401-6600batch: iter_time=2.016e-04, forward_time=0.133, uma_reduction=0.186, text_vs_uma=0.513, loss_ctc=13.932, loss=6.966, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.323e-04, train_time=0.893
[alab02] 2024-08-27 14:47:20,076 (trainer:720) INFO: 4epoch:train:6601-6800batch: iter_time=2.086e-04, forward_time=0.134, uma_reduction=0.184, text_vs_uma=0.509, loss_ctc=12.985, loss=6.493, backward_time=0.184, optim_step_time=0.037, optim0_lr0=2.340e-04, train_time=0.887
[alab02] 2024-08-27 14:48:49,833 (trainer:720) INFO: 4epoch:train:6801-7000batch: iter_time=1.995e-04, forward_time=0.134, uma_reduction=0.185, text_vs_uma=0.521, loss_ctc=13.634, loss=6.817, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.357e-04, train_time=0.897
[alab02] 2024-08-27 14:50:07,445 (trainer:338) INFO: 4epoch results: [train] iter_time=5.017e-04, forward_time=0.150, uma_reduction=0.185, text_vs_uma=0.517, loss_ctc=14.284, loss=7.142, backward_time=0.196, optim_step_time=0.050, optim0_lr0=2.079e-04, train_time=0.957, time=56 minutes and 50.36 seconds, total_count=28504, gpu_max_cached_mem_GB=35.895, [valid] uma_reduction=0.147, text_vs_uma=0.740, loss_ctc=8.277, cer_ctc=0.194, cer=0.194, loss=8.277, time=5.9 seconds, total_count=104, gpu_max_cached_mem_GB=35.895, [att_plot] time=14.28 seconds, total_count=0, gpu_max_cached_mem_GB=35.895
[alab02] 2024-08-27 14:50:12,390 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 14:50:12,390 (trainer:272) INFO: 5/150epoch started. Estimated time to finish: 5 days, 22 hours and 14 minutes
[alab02] 2024-08-27 14:51:42,598 (trainer:720) INFO: 5epoch:train:1-200batch: iter_time=0.002, forward_time=0.134, uma_reduction=0.186, text_vs_uma=0.519, loss_ctc=13.631, loss=6.815, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.384e-04, train_time=0.902
[alab02] 2024-08-27 14:53:09,282 (trainer:720) INFO: 5epoch:train:201-400batch: iter_time=1.913e-04, forward_time=0.130, uma_reduction=0.185, text_vs_uma=0.515, loss_ctc=12.804, loss=6.402, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.401e-04, train_time=0.867
[alab02] 2024-08-27 14:54:36,783 (trainer:720) INFO: 5epoch:train:401-600batch: iter_time=2.355e-04, forward_time=0.131, uma_reduction=0.188, text_vs_uma=0.518, loss_ctc=13.675, loss=6.837, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.417e-04, train_time=0.875
[alab02] 2024-08-27 14:56:04,863 (trainer:720) INFO: 5epoch:train:601-800batch: iter_time=2.697e-04, forward_time=0.132, uma_reduction=0.187, text_vs_uma=0.519, loss_ctc=13.491, loss=6.746, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.434e-04, train_time=0.881
[alab02] 2024-08-27 14:57:32,267 (trainer:720) INFO: 5epoch:train:801-1000batch: iter_time=2.113e-04, forward_time=0.130, uma_reduction=0.186, text_vs_uma=0.531, loss_ctc=13.125, loss=6.563, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.451e-04, train_time=0.874
[alab02] 2024-08-27 14:58:58,849 (trainer:720) INFO: 5epoch:train:1001-1200batch: iter_time=2.057e-04, forward_time=0.130, uma_reduction=0.188, text_vs_uma=0.517, loss_ctc=12.816, loss=6.408, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.467e-04, train_time=0.866
[alab02] 2024-08-27 15:00:28,765 (trainer:720) INFO: 5epoch:train:1201-1400batch: iter_time=2.497e-04, forward_time=0.137, uma_reduction=0.186, text_vs_uma=0.507, loss_ctc=12.408, loss=6.204, backward_time=0.186, optim_step_time=0.039, optim0_lr0=2.484e-04, train_time=0.899
[alab02] 2024-08-27 15:02:12,335 (trainer:720) INFO: 5epoch:train:1401-1600batch: iter_time=4.845e-04, forward_time=0.170, uma_reduction=0.190, text_vs_uma=0.501, loss_ctc=13.196, loss=6.598, backward_time=0.210, optim_step_time=0.066, optim0_lr0=2.501e-04, train_time=1.035
[alab02] 2024-08-27 15:03:52,168 (trainer:720) INFO: 5epoch:train:1601-1800batch: iter_time=5.722e-04, forward_time=0.163, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=14.051, loss=7.025, backward_time=0.199, optim_step_time=0.060, optim0_lr0=2.517e-04, train_time=0.998
[alab02] 2024-08-27 15:05:35,203 (trainer:720) INFO: 5epoch:train:1801-2000batch: iter_time=6.148e-04, forward_time=0.172, uma_reduction=0.187, text_vs_uma=0.502, loss_ctc=13.194, loss=6.597, backward_time=0.203, optim_step_time=0.062, optim0_lr0=2.534e-04, train_time=1.030
[alab02] 2024-08-27 15:07:19,751 (trainer:720) INFO: 5epoch:train:2001-2200batch: iter_time=5.630e-04, forward_time=0.177, uma_reduction=0.186, text_vs_uma=0.510, loss_ctc=12.682, loss=6.341, backward_time=0.208, optim_step_time=0.067, optim0_lr0=2.551e-04, train_time=1.045
[alab02] 2024-08-27 15:09:03,906 (trainer:720) INFO: 5epoch:train:2201-2400batch: iter_time=4.887e-04, forward_time=0.171, uma_reduction=0.186, text_vs_uma=0.511, loss_ctc=13.160, loss=6.580, backward_time=0.213, optim_step_time=0.066, optim0_lr0=2.567e-04, train_time=1.041
[alab02] 2024-08-27 15:10:49,706 (trainer:720) INFO: 5epoch:train:2401-2600batch: iter_time=5.284e-04, forward_time=0.178, uma_reduction=0.188, text_vs_uma=0.508, loss_ctc=12.488, loss=6.244, backward_time=0.214, optim_step_time=0.071, optim0_lr0=2.584e-04, train_time=1.057
[alab02] 2024-08-27 15:12:33,238 (trainer:720) INFO: 5epoch:train:2601-2800batch: iter_time=5.854e-04, forward_time=0.172, uma_reduction=0.188, text_vs_uma=0.509, loss_ctc=13.709, loss=6.855, backward_time=0.207, optim_step_time=0.070, optim0_lr0=2.601e-04, train_time=1.035
[alab02] 2024-08-27 15:14:20,312 (trainer:720) INFO: 5epoch:train:2801-3000batch: iter_time=5.991e-04, forward_time=0.179, uma_reduction=0.188, text_vs_uma=0.516, loss_ctc=13.205, loss=6.603, backward_time=0.212, optim_step_time=0.074, optim0_lr0=2.617e-04, train_time=1.070
[alab02] 2024-08-27 15:16:07,903 (trainer:720) INFO: 5epoch:train:3001-3200batch: iter_time=4.868e-04, forward_time=0.180, uma_reduction=0.188, text_vs_uma=0.508, loss_ctc=12.289, loss=6.144, backward_time=0.217, optim_step_time=0.072, optim0_lr0=2.634e-04, train_time=1.075
[alab02] 2024-08-27 15:17:51,924 (trainer:720) INFO: 5epoch:train:3201-3400batch: iter_time=5.073e-04, forward_time=0.172, uma_reduction=0.188, text_vs_uma=0.522, loss_ctc=13.427, loss=6.714, backward_time=0.210, optim_step_time=0.069, optim0_lr0=2.651e-04, train_time=1.040
[alab02] 2024-08-27 15:19:35,424 (trainer:720) INFO: 5epoch:train:3401-3600batch: iter_time=5.602e-04, forward_time=0.172, uma_reduction=0.187, text_vs_uma=0.505, loss_ctc=11.749, loss=5.874, backward_time=0.212, optim_step_time=0.071, optim0_lr0=2.667e-04, train_time=1.034
[alab02] 2024-08-27 15:21:20,916 (trainer:720) INFO: 5epoch:train:3601-3800batch: iter_time=5.266e-04, forward_time=0.175, uma_reduction=0.184, text_vs_uma=0.505, loss_ctc=12.110, loss=6.055, backward_time=0.216, optim_step_time=0.069, optim0_lr0=2.684e-04, train_time=1.054
[alab02] 2024-08-27 15:23:07,895 (trainer:720) INFO: 5epoch:train:3801-4000batch: iter_time=6.601e-04, forward_time=0.177, uma_reduction=0.185, text_vs_uma=0.519, loss_ctc=13.164, loss=6.582, backward_time=0.216, optim_step_time=0.072, optim0_lr0=2.701e-04, train_time=1.069
[alab02] 2024-08-27 15:24:52,349 (trainer:720) INFO: 5epoch:train:4001-4200batch: iter_time=5.207e-04, forward_time=0.174, uma_reduction=0.188, text_vs_uma=0.494, loss_ctc=11.526, loss=5.763, backward_time=0.214, optim_step_time=0.069, optim0_lr0=2.717e-04, train_time=1.044
[alab02] 2024-08-27 15:26:37,742 (trainer:720) INFO: 5epoch:train:4201-4400batch: iter_time=5.232e-04, forward_time=0.174, uma_reduction=0.187, text_vs_uma=0.521, loss_ctc=12.760, loss=6.380, backward_time=0.214, optim_step_time=0.069, optim0_lr0=2.734e-04, train_time=1.053
[alab02] 2024-08-27 15:28:22,222 (trainer:720) INFO: 5epoch:train:4401-4600batch: iter_time=5.249e-04, forward_time=0.172, uma_reduction=0.184, text_vs_uma=0.520, loss_ctc=12.276, loss=6.138, backward_time=0.215, optim_step_time=0.069, optim0_lr0=2.751e-04, train_time=1.044
[alab02] 2024-08-27 15:30:10,222 (trainer:720) INFO: 5epoch:train:4601-4800batch: iter_time=4.875e-04, forward_time=0.180, uma_reduction=0.183, text_vs_uma=0.536, loss_ctc=13.467, loss=6.734, backward_time=0.217, optim_step_time=0.071, optim0_lr0=2.767e-04, train_time=1.079
[alab02] 2024-08-27 15:31:52,353 (trainer:720) INFO: 5epoch:train:4801-5000batch: iter_time=4.687e-04, forward_time=0.170, uma_reduction=0.187, text_vs_uma=0.513, loss_ctc=12.501, loss=6.251, backward_time=0.206, optim_step_time=0.067, optim0_lr0=2.784e-04, train_time=1.021
[alab02] 2024-08-27 15:33:36,717 (trainer:720) INFO: 5epoch:train:5001-5200batch: iter_time=4.749e-04, forward_time=0.170, uma_reduction=0.188, text_vs_uma=0.500, loss_ctc=12.490, loss=6.245, backward_time=0.212, optim_step_time=0.069, optim0_lr0=2.801e-04, train_time=1.043
[alab02] 2024-08-27 15:35:20,668 (trainer:720) INFO: 5epoch:train:5201-5400batch: iter_time=6.749e-04, forward_time=0.168, uma_reduction=0.186, text_vs_uma=0.513, loss_ctc=12.941, loss=6.471, backward_time=0.208, optim_step_time=0.068, optim0_lr0=2.817e-04, train_time=1.039
[alab02] 2024-08-27 15:37:01,954 (trainer:720) INFO: 5epoch:train:5401-5600batch: iter_time=6.465e-04, forward_time=0.166, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=12.332, loss=6.166, backward_time=0.201, optim_step_time=0.068, optim0_lr0=2.834e-04, train_time=1.012
[alab02] 2024-08-27 15:38:42,483 (trainer:720) INFO: 5epoch:train:5601-5800batch: iter_time=5.479e-04, forward_time=0.162, uma_reduction=0.186, text_vs_uma=0.513, loss_ctc=12.871, loss=6.436, backward_time=0.203, optim_step_time=0.065, optim0_lr0=2.851e-04, train_time=1.005
[alab02] 2024-08-27 15:40:21,439 (trainer:720) INFO: 5epoch:train:5801-6000batch: iter_time=4.363e-04, forward_time=0.162, uma_reduction=0.187, text_vs_uma=0.509, loss_ctc=11.729, loss=5.865, backward_time=0.201, optim_step_time=0.064, optim0_lr0=2.867e-04, train_time=0.989
[alab02] 2024-08-27 15:42:06,869 (trainer:720) INFO: 5epoch:train:6001-6200batch: iter_time=6.303e-04, forward_time=0.173, uma_reduction=0.185, text_vs_uma=0.524, loss_ctc=13.282, loss=6.641, backward_time=0.209, optim_step_time=0.069, optim0_lr0=2.884e-04, train_time=1.054
[alab02] 2024-08-27 15:43:49,999 (trainer:720) INFO: 5epoch:train:6201-6400batch: iter_time=7.507e-04, forward_time=0.170, uma_reduction=0.185, text_vs_uma=0.524, loss_ctc=12.474, loss=6.237, backward_time=0.205, optim_step_time=0.066, optim0_lr0=2.901e-04, train_time=1.031
[alab02] 2024-08-27 15:45:33,404 (trainer:720) INFO: 5epoch:train:6401-6600batch: iter_time=4.651e-04, forward_time=0.169, uma_reduction=0.186, text_vs_uma=0.504, loss_ctc=11.061, loss=5.530, backward_time=0.214, optim_step_time=0.062, optim0_lr0=2.917e-04, train_time=1.033
[alab02] 2024-08-27 15:47:19,268 (trainer:720) INFO: 5epoch:train:6601-6800batch: iter_time=7.729e-04, forward_time=0.172, uma_reduction=0.185, text_vs_uma=0.524, loss_ctc=12.854, loss=6.427, backward_time=0.210, optim_step_time=0.070, optim0_lr0=2.934e-04, train_time=1.058
[alab02] 2024-08-27 15:49:00,775 (trainer:720) INFO: 5epoch:train:6801-7000batch: iter_time=6.487e-04, forward_time=0.167, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=11.877, loss=5.938, backward_time=0.200, optim_step_time=0.067, optim0_lr0=2.951e-04, train_time=1.015
[alab02] 2024-08-27 15:50:43,304 (trainer:338) INFO: 5epoch results: [train] iter_time=5.484e-04, forward_time=0.164, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=12.752, loss=6.376, backward_time=0.204, optim_step_time=0.062, optim0_lr0=2.672e-04, train_time=1.008, time=59 minutes and 53.52 seconds, total_count=35630, gpu_max_cached_mem_GB=35.895, [valid] uma_reduction=0.156, text_vs_uma=0.697, loss_ctc=7.535, cer_ctc=0.175, cer=0.175, loss=7.535, time=8.23 seconds, total_count=130, gpu_max_cached_mem_GB=35.895, [att_plot] time=29.16 seconds, total_count=0, gpu_max_cached_mem_GB=35.895
[alab02] 2024-08-27 15:50:54,109 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 15:50:54,112 (trainer:272) INFO: 6/150epoch started. Estimated time to finish: 5 days, 22 hours and 20 minutes
[alab02] 2024-08-27 15:52:41,408 (trainer:720) INFO: 6epoch:train:1-200batch: iter_time=0.006, forward_time=0.178, uma_reduction=0.186, text_vs_uma=0.526, loss_ctc=13.023, loss=6.511, backward_time=0.202, optim_step_time=0.070, optim0_lr0=2.978e-04, train_time=1.072
[alab02] 2024-08-27 15:54:25,323 (trainer:720) INFO: 6epoch:train:201-400batch: iter_time=6.861e-04, forward_time=0.171, uma_reduction=0.184, text_vs_uma=0.513, loss_ctc=12.351, loss=6.176, backward_time=0.208, optim_step_time=0.067, optim0_lr0=2.994e-04, train_time=1.038
[alab02] 2024-08-27 15:56:06,568 (trainer:720) INFO: 6epoch:train:401-600batch: iter_time=6.280e-04, forward_time=0.166, uma_reduction=0.186, text_vs_uma=0.519, loss_ctc=12.435, loss=6.218, backward_time=0.205, optim_step_time=0.068, optim0_lr0=3.011e-04, train_time=1.012
[alab02] 2024-08-27 15:57:51,754 (trainer:720) INFO: 6epoch:train:601-800batch: iter_time=6.241e-04, forward_time=0.176, uma_reduction=0.188, text_vs_uma=0.509, loss_ctc=11.737, loss=5.869, backward_time=0.212, optim_step_time=0.066, optim0_lr0=3.028e-04, train_time=1.051
[alab02] 2024-08-27 15:59:36,384 (trainer:720) INFO: 6epoch:train:801-1000batch: iter_time=8.983e-04, forward_time=0.174, uma_reduction=0.189, text_vs_uma=0.509, loss_ctc=11.891, loss=5.946, backward_time=0.209, optim_step_time=0.064, optim0_lr0=3.044e-04, train_time=1.046
[alab02] 2024-08-27 16:01:24,699 (trainer:720) INFO: 6epoch:train:1001-1200batch: iter_time=7.842e-04, forward_time=0.182, uma_reduction=0.189, text_vs_uma=0.497, loss_ctc=11.836, loss=5.918, backward_time=0.215, optim_step_time=0.073, optim0_lr0=3.061e-04, train_time=1.082
[alab02] 2024-08-27 16:03:08,887 (trainer:720) INFO: 6epoch:train:1201-1400batch: iter_time=7.285e-04, forward_time=0.170, uma_reduction=0.186, text_vs_uma=0.507, loss_ctc=12.081, loss=6.041, backward_time=0.206, optim_step_time=0.069, optim0_lr0=3.078e-04, train_time=1.041
[alab02] 2024-08-27 16:04:50,715 (trainer:720) INFO: 6epoch:train:1401-1600batch: iter_time=5.881e-04, forward_time=0.168, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=11.996, loss=5.998, backward_time=0.203, optim_step_time=0.064, optim0_lr0=3.094e-04, train_time=1.018
[alab02] 2024-08-27 16:06:30,448 (trainer:720) INFO: 6epoch:train:1601-1800batch: iter_time=5.094e-04, forward_time=0.160, uma_reduction=0.188, text_vs_uma=0.509, loss_ctc=11.826, loss=5.913, backward_time=0.200, optim_step_time=0.063, optim0_lr0=3.111e-04, train_time=0.997
[alab02] 2024-08-27 16:08:09,473 (trainer:720) INFO: 6epoch:train:1801-2000batch: iter_time=4.517e-04, forward_time=0.159, uma_reduction=0.190, text_vs_uma=0.503, loss_ctc=11.946, loss=5.973, backward_time=0.198, optim_step_time=0.062, optim0_lr0=3.128e-04, train_time=0.990
[alab02] 2024-08-27 16:09:52,164 (trainer:720) INFO: 6epoch:train:2001-2200batch: iter_time=4.744e-04, forward_time=0.165, uma_reduction=0.190, text_vs_uma=0.501, loss_ctc=11.690, loss=5.845, backward_time=0.210, optim_step_time=0.063, optim0_lr0=3.144e-04, train_time=1.026
[alab02] 2024-08-27 16:11:30,668 (trainer:720) INFO: 6epoch:train:2201-2400batch: iter_time=3.604e-04, forward_time=0.154, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=11.752, loss=5.876, backward_time=0.202, optim_step_time=0.056, optim0_lr0=3.161e-04, train_time=0.984
[alab02] 2024-08-27 16:13:07,651 (trainer:720) INFO: 6epoch:train:2401-2600batch: iter_time=3.654e-04, forward_time=0.151, uma_reduction=0.185, text_vs_uma=0.518, loss_ctc=12.008, loss=6.004, backward_time=0.198, optim_step_time=0.054, optim0_lr0=3.178e-04, train_time=0.969
[alab02] 2024-08-27 16:14:42,756 (trainer:720) INFO: 6epoch:train:2601-2800batch: iter_time=3.125e-04, forward_time=0.146, uma_reduction=0.187, text_vs_uma=0.512, loss_ctc=12.188, loss=6.094, backward_time=0.196, optim_step_time=0.046, optim0_lr0=3.194e-04, train_time=0.951
[alab02] 2024-08-27 16:16:13,223 (trainer:720) INFO: 6epoch:train:2801-3000batch: iter_time=2.833e-04, forward_time=0.138, uma_reduction=0.186, text_vs_uma=0.521, loss_ctc=12.208, loss=6.104, backward_time=0.182, optim_step_time=0.043, optim0_lr0=3.211e-04, train_time=0.904
[alab02] 2024-08-27 16:17:40,484 (trainer:720) INFO: 6epoch:train:3001-3200batch: iter_time=2.302e-04, forward_time=0.132, uma_reduction=0.190, text_vs_uma=0.517, loss_ctc=12.361, loss=6.180, backward_time=0.175, optim_step_time=0.039, optim0_lr0=3.228e-04, train_time=0.872
[alab02] 2024-08-27 16:19:07,935 (trainer:720) INFO: 6epoch:train:3201-3400batch: iter_time=2.052e-04, forward_time=0.133, uma_reduction=0.190, text_vs_uma=0.501, loss_ctc=11.355, loss=5.677, backward_time=0.179, optim_step_time=0.038, optim0_lr0=3.244e-04, train_time=0.874
[alab02] 2024-08-27 16:20:38,821 (trainer:720) INFO: 6epoch:train:3401-3600batch: iter_time=2.088e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=12.003, loss=6.002, backward_time=0.188, optim_step_time=0.038, optim0_lr0=3.261e-04, train_time=0.909
[alab02] 2024-08-27 16:22:06,156 (trainer:720) INFO: 6epoch:train:3601-3800batch: iter_time=2.013e-04, forward_time=0.131, uma_reduction=0.185, text_vs_uma=0.519, loss_ctc=12.451, loss=6.226, backward_time=0.178, optim_step_time=0.036, optim0_lr0=3.278e-04, train_time=0.873
[alab02] 2024-08-27 16:23:33,292 (trainer:720) INFO: 6epoch:train:3801-4000batch: iter_time=2.041e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.501, loss_ctc=11.561, loss=5.781, backward_time=0.179, optim_step_time=0.036, optim0_lr0=3.294e-04, train_time=0.871
[alab02] 2024-08-27 16:25:02,604 (trainer:720) INFO: 6epoch:train:4001-4200batch: iter_time=1.918e-04, forward_time=0.134, uma_reduction=0.190, text_vs_uma=0.494, loss_ctc=11.444, loss=5.722, backward_time=0.185, optim_step_time=0.036, optim0_lr0=3.311e-04, train_time=0.893
[alab02] 2024-08-27 16:26:32,602 (trainer:720) INFO: 6epoch:train:4201-4400batch: iter_time=2.312e-04, forward_time=0.136, uma_reduction=0.192, text_vs_uma=0.509, loss_ctc=12.199, loss=6.099, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.328e-04, train_time=0.900
[alab02] 2024-08-27 16:28:04,410 (trainer:720) INFO: 6epoch:train:4401-4600batch: iter_time=2.655e-04, forward_time=0.141, uma_reduction=0.192, text_vs_uma=0.505, loss_ctc=11.415, loss=5.707, backward_time=0.188, optim_step_time=0.041, optim0_lr0=3.344e-04, train_time=0.918
[alab02] 2024-08-27 16:29:33,747 (trainer:720) INFO: 6epoch:train:4601-4800batch: iter_time=2.884e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.510, loss_ctc=11.669, loss=5.835, backward_time=0.180, optim_step_time=0.042, optim0_lr0=3.361e-04, train_time=0.893
[alab02] 2024-08-27 16:31:01,920 (trainer:720) INFO: 6epoch:train:4801-5000batch: iter_time=2.368e-04, forward_time=0.134, uma_reduction=0.184, text_vs_uma=0.514, loss_ctc=11.409, loss=5.705, backward_time=0.179, optim_step_time=0.040, optim0_lr0=3.378e-04, train_time=0.881
[alab02] 2024-08-27 16:32:31,436 (trainer:720) INFO: 6epoch:train:5001-5200batch: iter_time=2.330e-04, forward_time=0.136, uma_reduction=0.184, text_vs_uma=0.515, loss_ctc=11.723, loss=5.861, backward_time=0.185, optim_step_time=0.038, optim0_lr0=3.394e-04, train_time=0.895
[alab02] 2024-08-27 16:34:00,445 (trainer:720) INFO: 6epoch:train:5201-5400batch: iter_time=2.213e-04, forward_time=0.134, uma_reduction=0.186, text_vs_uma=0.522, loss_ctc=11.965, loss=5.982, backward_time=0.183, optim_step_time=0.038, optim0_lr0=3.411e-04, train_time=0.890
[alab02] 2024-08-27 16:35:27,931 (trainer:720) INFO: 6epoch:train:5401-5600batch: iter_time=1.998e-04, forward_time=0.132, uma_reduction=0.187, text_vs_uma=0.526, loss_ctc=11.795, loss=5.898, backward_time=0.181, optim_step_time=0.035, optim0_lr0=3.428e-04, train_time=0.875
[alab02] 2024-08-27 16:36:56,410 (trainer:720) INFO: 6epoch:train:5601-5800batch: iter_time=2.391e-04, forward_time=0.135, uma_reduction=0.186, text_vs_uma=0.508, loss_ctc=11.278, loss=5.639, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.444e-04, train_time=0.885
[alab02] 2024-08-27 16:38:24,771 (trainer:720) INFO: 6epoch:train:5801-6000batch: iter_time=2.036e-04, forward_time=0.134, uma_reduction=0.188, text_vs_uma=0.510, loss_ctc=11.589, loss=5.795, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.461e-04, train_time=0.883
[alab02] 2024-08-27 16:39:55,650 (trainer:720) INFO: 6epoch:train:6001-6200batch: iter_time=2.743e-04, forward_time=0.139, uma_reduction=0.187, text_vs_uma=0.507, loss_ctc=12.059, loss=6.029, backward_time=0.184, optim_step_time=0.040, optim0_lr0=3.478e-04, train_time=0.908
[alab02] 2024-08-27 16:41:39,902 (trainer:720) INFO: 6epoch:train:6201-6400batch: iter_time=5.071e-04, forward_time=0.174, uma_reduction=0.190, text_vs_uma=0.509, loss_ctc=12.004, loss=6.002, backward_time=0.209, optim_step_time=0.068, optim0_lr0=3.494e-04, train_time=1.042
[alab02] 2024-08-27 16:43:22,926 (trainer:720) INFO: 6epoch:train:6401-6600batch: iter_time=6.075e-04, forward_time=0.173, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=11.383, loss=5.691, backward_time=0.208, optim_step_time=0.069, optim0_lr0=3.511e-04, train_time=1.030
[alab02] 2024-08-27 16:45:07,035 (trainer:720) INFO: 6epoch:train:6601-6800batch: iter_time=4.846e-04, forward_time=0.172, uma_reduction=0.185, text_vs_uma=0.513, loss_ctc=11.820, loss=5.910, backward_time=0.207, optim_step_time=0.066, optim0_lr0=3.528e-04, train_time=1.040
[alab02] 2024-08-27 16:46:52,756 (trainer:720) INFO: 6epoch:train:6801-7000batch: iter_time=5.372e-04, forward_time=0.178, uma_reduction=0.187, text_vs_uma=0.515, loss_ctc=11.610, loss=5.805, backward_time=0.211, optim_step_time=0.069, optim0_lr0=3.544e-04, train_time=1.057
[alab02] 2024-08-27 16:48:41,657 (trainer:338) INFO: 6epoch results: [train] iter_time=5.618e-04, forward_time=0.152, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=11.889, loss=5.944, backward_time=0.194, optim_step_time=0.052, optim0_lr0=3.266e-04, train_time=0.961, time=57 minutes and 5.46 seconds, total_count=42756, gpu_max_cached_mem_GB=35.895, [valid] uma_reduction=0.146, text_vs_uma=0.740, loss_ctc=8.347, cer_ctc=0.188, cer=0.188, loss=8.347, time=8.6 seconds, total_count=156, gpu_max_cached_mem_GB=35.895, [att_plot] time=33.48 seconds, total_count=0, gpu_max_cached_mem_GB=35.895
[alab02] 2024-08-27 16:48:53,352 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-27 16:48:53,353 (trainer:272) INFO: 7/150epoch started. Estimated time to finish: 5 days, 20 hours and 59 minutes
[alab02] 2024-08-27 16:50:42,705 (trainer:720) INFO: 7epoch:train:1-200batch: iter_time=0.005, forward_time=0.179, uma_reduction=0.184, text_vs_uma=0.518, loss_ctc=12.172, loss=6.086, backward_time=0.214, optim_step_time=0.072, optim0_lr0=3.572e-04, train_time=1.093
[alab02] 2024-08-27 16:52:27,585 (trainer:720) INFO: 7epoch:train:201-400batch: iter_time=5.930e-04, forward_time=0.172, uma_reduction=0.189, text_vs_uma=0.513, loss_ctc=12.077, loss=6.038, backward_time=0.213, optim_step_time=0.071, optim0_lr0=3.588e-04, train_time=1.048
[alab02] 2024-08-27 16:54:16,971 (trainer:720) INFO: 7epoch:train:401-600batch: iter_time=7.090e-04, forward_time=0.183, uma_reduction=0.189, text_vs_uma=0.516, loss_ctc=12.877, loss=6.439, backward_time=0.216, optim_step_time=0.072, optim0_lr0=3.605e-04, train_time=1.093
[alab02] 2024-08-27 16:56:02,696 (trainer:720) INFO: 7epoch:train:601-800batch: iter_time=7.436e-04, forward_time=0.175, uma_reduction=0.186, text_vs_uma=0.510, loss_ctc=11.003, loss=5.501, backward_time=0.214, optim_step_time=0.074, optim0_lr0=3.622e-04, train_time=1.057
[alab02] 2024-08-27 16:57:46,809 (trainer:720) INFO: 7epoch:train:801-1000batch: iter_time=7.379e-04, forward_time=0.173, uma_reduction=0.185, text_vs_uma=0.518, loss_ctc=11.271, loss=5.636, backward_time=0.212, optim_step_time=0.066, optim0_lr0=3.638e-04, train_time=1.041
[alab02] 2024-08-27 16:59:30,977 (trainer:720) INFO: 7epoch:train:1001-1200batch: iter_time=6.868e-04, forward_time=0.172, uma_reduction=0.186, text_vs_uma=0.516, loss_ctc=11.439, loss=5.720, backward_time=0.209, optim_step_time=0.069, optim0_lr0=3.655e-04, train_time=1.041
[alab02] 2024-08-27 17:01:13,327 (trainer:720) INFO: 7epoch:train:1201-1400batch: iter_time=5.205e-04, forward_time=0.167, uma_reduction=0.185, text_vs_uma=0.507, loss_ctc=11.255, loss=5.627, backward_time=0.208, optim_step_time=0.067, optim0_lr0=3.672e-04, train_time=1.023
[alab02] 2024-08-27 17:02:55,367 (trainer:720) INFO: 7epoch:train:1401-1600batch: iter_time=5.103e-04, forward_time=0.170, uma_reduction=0.188, text_vs_uma=0.518, loss_ctc=11.653, loss=5.827, backward_time=0.205, optim_step_time=0.067, optim0_lr0=3.688e-04, train_time=1.020
[alab02] 2024-08-27 17:04:37,521 (trainer:720) INFO: 7epoch:train:1601-1800batch: iter_time=7.155e-04, forward_time=0.166, uma_reduction=0.193, text_vs_uma=0.503, loss_ctc=11.213, loss=5.607, backward_time=0.207, optim_step_time=0.068, optim0_lr0=3.705e-04, train_time=1.021
[alab02] 2024-08-27 17:06:15,699 (trainer:720) INFO: 7epoch:train:1801-2000batch: iter_time=4.910e-04, forward_time=0.158, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=11.851, loss=5.925, backward_time=0.195, optim_step_time=0.060, optim0_lr0=3.722e-04, train_time=0.981
[alab02] 2024-08-27 17:07:49,375 (trainer:720) INFO: 7epoch:train:2001-2200batch: iter_time=2.843e-04, forward_time=0.145, uma_reduction=0.187, text_vs_uma=0.515, loss_ctc=11.643, loss=5.821, backward_time=0.190, optim_step_time=0.049, optim0_lr0=3.738e-04, train_time=0.936
[alab02] 2024-08-27 17:09:21,259 (trainer:720) INFO: 7epoch:train:2201-2400batch: iter_time=2.611e-04, forward_time=0.139, uma_reduction=0.185, text_vs_uma=0.518, loss_ctc=11.656, loss=5.828, backward_time=0.188, optim_step_time=0.041, optim0_lr0=3.755e-04, train_time=0.919
[alab02] 2024-08-27 17:10:49,334 (trainer:720) INFO: 7epoch:train:2401-2600batch: iter_time=2.245e-04, forward_time=0.132, uma_reduction=0.186, text_vs_uma=0.518, loss_ctc=11.755, loss=5.878, backward_time=0.180, optim_step_time=0.037, optim0_lr0=3.772e-04, train_time=0.881
[alab02] 2024-08-27 17:12:16,796 (trainer:720) INFO: 7epoch:train:2601-2800batch: iter_time=2.094e-04, forward_time=0.131, uma_reduction=0.187, text_vs_uma=0.513, loss_ctc=11.413, loss=5.707, backward_time=0.180, optim_step_time=0.038, optim0_lr0=3.788e-04, train_time=0.874
[alab02] 2024-08-27 17:13:43,625 (trainer:720) INFO: 7epoch:train:2801-3000batch: iter_time=1.922e-04, forward_time=0.129, uma_reduction=0.190, text_vs_uma=0.515, loss_ctc=12.184, loss=6.092, backward_time=0.178, optim_step_time=0.037, optim0_lr0=3.805e-04, train_time=0.868
[alab02] 2024-08-27 17:15:11,673 (trainer:720) INFO: 7epoch:train:3001-3200batch: iter_time=1.874e-04, forward_time=0.132, uma_reduction=0.188, text_vs_uma=0.502, loss_ctc=11.409, loss=5.704, backward_time=0.180, optim_step_time=0.037, optim0_lr0=3.822e-04, train_time=0.880
[alab02] 2024-08-27 17:16:41,460 (trainer:720) INFO: 7epoch:train:3201-3400batch: iter_time=2.122e-04, forward_time=0.135, uma_reduction=0.188, text_vs_uma=0.520, loss_ctc=12.252, loss=6.126, backward_time=0.184, optim_step_time=0.038, optim0_lr0=3.838e-04, train_time=0.898
[alab02] 2024-08-27 17:18:24,985 (trainer:720) INFO: 7epoch:train:3401-3600batch: iter_time=5.067e-04, forward_time=0.167, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=11.873, loss=5.936, backward_time=0.213, optim_step_time=0.068, optim0_lr0=3.855e-04, train_time=1.035
[alab02] 2024-08-27 17:20:09,789 (trainer:720) INFO: 7epoch:train:3601-3800batch: iter_time=5.429e-04, forward_time=0.171, uma_reduction=0.188, text_vs_uma=0.509, loss_ctc=11.607, loss=5.804, backward_time=0.216, optim_step_time=0.072, optim0_lr0=3.872e-04, train_time=1.047
[alab02] 2024-08-27 17:21:54,911 (trainer:720) INFO: 7epoch:train:3801-4000batch: iter_time=5.888e-04, forward_time=0.175, uma_reduction=0.190, text_vs_uma=0.495, loss_ctc=11.088, loss=5.544, backward_time=0.216, optim_step_time=0.072, optim0_lr0=3.888e-04, train_time=1.051
[alab02] 2024-08-27 17:23:37,919 (trainer:720) INFO: 7epoch:train:4001-4200batch: iter_time=4.648e-04, forward_time=0.170, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=11.272, loss=5.636, backward_time=0.208, optim_step_time=0.068, optim0_lr0=3.905e-04, train_time=1.030
[alab02] 2024-08-27 17:25:23,138 (trainer:720) INFO: 7epoch:train:4201-4400batch: iter_time=5.051e-04, forward_time=0.175, uma_reduction=0.189, text_vs_uma=0.497, loss_ctc=11.364, loss=5.682, backward_time=0.212, optim_step_time=0.071, optim0_lr0=3.922e-04, train_time=1.052
[alab02] 2024-08-27 17:27:06,547 (trainer:720) INFO: 7epoch:train:4401-4600batch: iter_time=4.876e-04, forward_time=0.170, uma_reduction=0.189, text_vs_uma=0.511, loss_ctc=11.782, loss=5.891, backward_time=0.206, optim_step_time=0.072, optim0_lr0=3.938e-04, train_time=1.033
[alab02] 2024-08-27 17:28:49,853 (trainer:720) INFO: 7epoch:train:4601-4800batch: iter_time=4.513e-04, forward_time=0.169, uma_reduction=0.193, text_vs_uma=0.490, loss_ctc=10.910, loss=5.455, backward_time=0.210, optim_step_time=0.069, optim0_lr0=3.955e-04, train_time=1.032
[alab02] 2024-08-27 17:30:32,989 (trainer:720) INFO: 7epoch:train:4801-5000batch: iter_time=4.516e-04, forward_time=0.170, uma_reduction=0.190, text_vs_uma=0.493, loss_ctc=11.090, loss=5.545, backward_time=0.210, optim_step_time=0.069, optim0_lr0=3.972e-04, train_time=1.031
[alab02] 2024-08-27 17:32:14,906 (trainer:720) INFO: 7epoch:train:5001-5200batch: iter_time=6.366e-04, forward_time=0.166, uma_reduction=0.188, text_vs_uma=0.512, loss_ctc=11.790, loss=5.895, backward_time=0.206, optim_step_time=0.067, optim0_lr0=3.988e-04, train_time=1.019
[alab02] 2024-08-27 17:33:58,440 (trainer:720) INFO: 7epoch:train:5201-5400batch: iter_time=5.008e-04, forward_time=0.169, uma_reduction=0.189, text_vs_uma=0.505, loss_ctc=11.081, loss=5.540, backward_time=0.210, optim_step_time=0.070, optim0_lr0=4.005e-04, train_time=1.035
[alab02] 2024-08-27 17:35:39,365 (trainer:720) INFO: 7epoch:train:5401-5600batch: iter_time=4.216e-04, forward_time=0.161, uma_reduction=0.187, text_vs_uma=0.515, loss_ctc=11.951, loss=5.975, backward_time=0.206, optim_step_time=0.065, optim0_lr0=4.022e-04, train_time=1.009
[alab02] 2024-08-27 17:37:24,849 (trainer:720) INFO: 7epoch:train:5601-5800batch: iter_time=4.917e-04, forward_time=0.171, uma_reduction=0.190, text_vs_uma=0.511, loss_ctc=10.951, loss=5.475, backward_time=0.216, optim_step_time=0.067, optim0_lr0=4.038e-04, train_time=1.054
[alab02] 2024-08-27 17:39:07,211 (trainer:720) INFO: 7epoch:train:5801-6000batch: iter_time=4.717e-04, forward_time=0.167, uma_reduction=0.191, text_vs_uma=0.500, loss_ctc=11.134, loss=5.567, backward_time=0.206, optim_step_time=0.070, optim0_lr0=4.055e-04, train_time=1.023
[alab02] 2024-08-27 17:40:51,437 (trainer:720) INFO: 7epoch:train:6001-6200batch: iter_time=4.679e-04, forward_time=0.171, uma_reduction=0.190, text_vs_uma=0.511, loss_ctc=11.955, loss=5.977, backward_time=0.212, optim_step_time=0.069, optim0_lr0=4.072e-04, train_time=1.042
[alab02] 2024-08-27 17:42:34,496 (trainer:720) INFO: 7epoch:train:6201-6400batch: iter_time=4.264e-04, forward_time=0.167, uma_reduction=0.193, text_vs_uma=0.487, loss_ctc=11.213, loss=5.606, backward_time=0.209, optim_step_time=0.071, optim0_lr0=4.088e-04, train_time=1.030
[alab02] 2024-08-27 17:44:15,556 (trainer:720) INFO: 7epoch:train:6401-6600batch: iter_time=4.832e-04, forward_time=0.163, uma_reduction=0.189, text_vs_uma=0.498, loss_ctc=10.524, loss=5.262, backward_time=0.209, optim_step_time=0.068, optim0_lr0=4.105e-04, train_time=1.010
[alab02] 2024-08-27 17:45:58,676 (trainer:720) INFO: 7epoch:train:6601-6800batch: iter_time=3.821e-04, forward_time=0.169, uma_reduction=0.186, text_vs_uma=0.518, loss_ctc=12.058, loss=6.029, backward_time=0.207, optim_step_time=0.067, optim0_lr0=4.122e-04, train_time=1.030
[alab02] 2024-08-27 17:47:40,998 (trainer:720) INFO: 7epoch:train:6801-7000batch: iter_time=4.415e-04, forward_time=0.166, uma_reduction=0.188, text_vs_uma=0.510, loss_ctc=11.249, loss=5.624, backward_time=0.209, optim_step_time=0.067, optim0_lr0=4.138e-04, train_time=1.023
[alab02] 2024-08-27 17:49:21,541 (trainer:338) INFO: 7epoch results: [train] iter_time=6.026e-04, forward_time=0.163, uma_reduction=0.188, text_vs_uma=0.509, loss_ctc=11.553, loss=5.776, backward_time=0.204, optim_step_time=0.063, optim0_lr0=3.860e-04, train_time=1.008, time=59 minutes and 52.88 seconds, total_count=49882, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.151, text_vs_uma=0.718, loss_ctc=8.301, cer_ctc=0.179, cer=0.179, loss=8.301, time=8.26 seconds, total_count=182, gpu_max_cached_mem_GB=35.900, [att_plot] time=27.04 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 17:49:30,375 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-27 17:49:30,376 (trainer:272) INFO: 8/150epoch started. Estimated time to finish: 5 days, 20 hours and 39 minutes
[alab02] 2024-08-27 17:51:11,734 (trainer:720) INFO: 8epoch:train:1-200batch: iter_time=0.004, forward_time=0.162, uma_reduction=0.188, text_vs_uma=0.516, loss_ctc=10.678, loss=5.339, backward_time=0.207, optim_step_time=0.065, optim0_lr0=4.165e-04, train_time=1.013
[alab02] 2024-08-27 17:52:50,830 (trainer:720) INFO: 8epoch:train:201-400batch: iter_time=3.971e-04, forward_time=0.158, uma_reduction=0.188, text_vs_uma=0.503, loss_ctc=11.109, loss=5.554, backward_time=0.202, optim_step_time=0.061, optim0_lr0=4.182e-04, train_time=0.990
[alab02] 2024-08-27 17:54:27,503 (trainer:720) INFO: 8epoch:train:401-600batch: iter_time=3.690e-04, forward_time=0.152, uma_reduction=0.185, text_vs_uma=0.527, loss_ctc=11.556, loss=5.778, backward_time=0.194, optim_step_time=0.056, optim0_lr0=4.199e-04, train_time=0.966
[alab02] 2024-08-27 17:56:02,196 (trainer:720) INFO: 8epoch:train:601-800batch: iter_time=3.021e-04, forward_time=0.149, uma_reduction=0.186, text_vs_uma=0.516, loss_ctc=11.125, loss=5.563, backward_time=0.194, optim_step_time=0.051, optim0_lr0=4.215e-04, train_time=0.946
[alab02] 2024-08-27 17:57:35,692 (trainer:720) INFO: 8epoch:train:801-1000batch: iter_time=3.404e-04, forward_time=0.146, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=10.911, loss=5.455, backward_time=0.189, optim_step_time=0.048, optim0_lr0=4.232e-04, train_time=0.935
[alab02] 2024-08-27 17:59:07,479 (trainer:720) INFO: 8epoch:train:1001-1200batch: iter_time=2.818e-04, forward_time=0.142, uma_reduction=0.189, text_vs_uma=0.509, loss_ctc=11.749, loss=5.874, backward_time=0.182, optim_step_time=0.046, optim0_lr0=4.249e-04, train_time=0.918
[alab02] 2024-08-27 18:00:39,571 (trainer:720) INFO: 8epoch:train:1201-1400batch: iter_time=2.743e-04, forward_time=0.141, uma_reduction=0.191, text_vs_uma=0.516, loss_ctc=11.135, loss=5.568, backward_time=0.187, optim_step_time=0.044, optim0_lr0=4.265e-04, train_time=0.921
[alab02] 2024-08-27 18:02:11,481 (trainer:720) INFO: 8epoch:train:1401-1600batch: iter_time=2.588e-04, forward_time=0.142, uma_reduction=0.189, text_vs_uma=0.502, loss_ctc=10.589, loss=5.295, backward_time=0.190, optim_step_time=0.044, optim0_lr0=4.282e-04, train_time=0.919
[alab02] 2024-08-27 18:03:44,205 (trainer:720) INFO: 8epoch:train:1601-1800batch: iter_time=2.520e-04, forward_time=0.141, uma_reduction=0.187, text_vs_uma=0.520, loss_ctc=11.878, loss=5.939, backward_time=0.187, optim_step_time=0.045, optim0_lr0=4.299e-04, train_time=0.927
[alab02] 2024-08-27 18:05:18,731 (trainer:720) INFO: 8epoch:train:1801-2000batch: iter_time=2.649e-04, forward_time=0.146, uma_reduction=0.190, text_vs_uma=0.501, loss_ctc=10.403, loss=5.202, backward_time=0.195, optim_step_time=0.046, optim0_lr0=4.315e-04, train_time=0.945
[alab02] 2024-08-27 18:06:49,019 (trainer:720) INFO: 8epoch:train:2001-2200batch: iter_time=2.624e-04, forward_time=0.139, uma_reduction=0.187, text_vs_uma=0.518, loss_ctc=11.598, loss=5.799, backward_time=0.181, optim_step_time=0.044, optim0_lr0=4.332e-04, train_time=0.903
[alab02] 2024-08-27 18:08:22,154 (trainer:720) INFO: 8epoch:train:2201-2400batch: iter_time=2.856e-04, forward_time=0.142, uma_reduction=0.187, text_vs_uma=0.505, loss_ctc=10.885, loss=5.442, backward_time=0.190, optim_step_time=0.047, optim0_lr0=4.349e-04, train_time=0.931
[alab02] 2024-08-27 18:09:55,086 (trainer:720) INFO: 8epoch:train:2401-2600batch: iter_time=2.516e-04, forward_time=0.142, uma_reduction=0.184, text_vs_uma=0.511, loss_ctc=11.153, loss=5.576, backward_time=0.190, optim_step_time=0.043, optim0_lr0=4.365e-04, train_time=0.929
[alab02] 2024-08-27 18:11:25,569 (trainer:720) INFO: 8epoch:train:2601-2800batch: iter_time=2.269e-04, forward_time=0.137, uma_reduction=0.184, text_vs_uma=0.529, loss_ctc=12.033, loss=6.017, backward_time=0.183, optim_step_time=0.039, optim0_lr0=4.382e-04, train_time=0.905
[alab02] 2024-08-27 18:12:55,649 (trainer:720) INFO: 8epoch:train:2801-3000batch: iter_time=2.242e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.513, loss_ctc=11.030, loss=5.515, backward_time=0.184, optim_step_time=0.041, optim0_lr0=4.399e-04, train_time=0.901
[alab02] 2024-08-27 18:14:27,639 (trainer:720) INFO: 8epoch:train:3001-3200batch: iter_time=2.194e-04, forward_time=0.140, uma_reduction=0.187, text_vs_uma=0.517, loss_ctc=10.938, loss=5.469, backward_time=0.191, optim_step_time=0.042, optim0_lr0=4.415e-04, train_time=0.920
[alab02] 2024-08-27 18:15:59,192 (trainer:720) INFO: 8epoch:train:3201-3400batch: iter_time=2.464e-04, forward_time=0.140, uma_reduction=0.185, text_vs_uma=0.520, loss_ctc=11.251, loss=5.626, backward_time=0.186, optim_step_time=0.043, optim0_lr0=4.432e-04, train_time=0.915
[alab02] 2024-08-27 18:17:32,085 (trainer:720) INFO: 8epoch:train:3401-3600batch: iter_time=2.485e-04, forward_time=0.144, uma_reduction=0.185, text_vs_uma=0.522, loss_ctc=11.294, loss=5.647, backward_time=0.191, optim_step_time=0.041, optim0_lr0=4.449e-04, train_time=0.929
[alab02] 2024-08-27 18:19:03,138 (trainer:720) INFO: 8epoch:train:3601-3800batch: iter_time=2.185e-04, forward_time=0.137, uma_reduction=0.184, text_vs_uma=0.518, loss_ctc=11.045, loss=5.523, backward_time=0.187, optim_step_time=0.040, optim0_lr0=4.465e-04, train_time=0.910
[alab02] 2024-08-27 18:20:32,419 (trainer:720) INFO: 8epoch:train:3801-4000batch: iter_time=2.267e-04, forward_time=0.135, uma_reduction=0.185, text_vs_uma=0.522, loss_ctc=10.808, loss=5.404, backward_time=0.183, optim_step_time=0.039, optim0_lr0=4.482e-04, train_time=0.893
[alab02] 2024-08-27 18:22:04,085 (trainer:720) INFO: 8epoch:train:4001-4200batch: iter_time=2.313e-04, forward_time=0.139, uma_reduction=0.187, text_vs_uma=0.503, loss_ctc=10.495, loss=5.248, backward_time=0.190, optim_step_time=0.041, optim0_lr0=4.499e-04, train_time=0.916
[alab02] 2024-08-27 18:23:32,838 (trainer:720) INFO: 8epoch:train:4201-4400batch: iter_time=2.005e-04, forward_time=0.134, uma_reduction=0.187, text_vs_uma=0.511, loss_ctc=10.970, loss=5.485, backward_time=0.182, optim_step_time=0.040, optim0_lr0=4.515e-04, train_time=0.887
[alab02] 2024-08-27 18:25:03,076 (trainer:720) INFO: 8epoch:train:4401-4600batch: iter_time=1.942e-04, forward_time=0.137, uma_reduction=0.188, text_vs_uma=0.510, loss_ctc=11.376, loss=5.688, backward_time=0.185, optim_step_time=0.040, optim0_lr0=4.532e-04, train_time=0.902
[alab02] 2024-08-27 18:26:32,035 (trainer:720) INFO: 8epoch:train:4601-4800batch: iter_time=2.224e-04, forward_time=0.135, uma_reduction=0.186, text_vs_uma=0.520, loss_ctc=11.316, loss=5.658, backward_time=0.180, optim_step_time=0.041, optim0_lr0=4.549e-04, train_time=0.889
[alab02] 2024-08-27 18:28:01,906 (trainer:720) INFO: 8epoch:train:4801-5000batch: iter_time=2.085e-04, forward_time=0.138, uma_reduction=0.189, text_vs_uma=0.502, loss_ctc=10.143, loss=5.072, backward_time=0.188, optim_step_time=0.040, optim0_lr0=4.565e-04, train_time=0.898
[alab02] 2024-08-27 18:29:33,439 (trainer:720) INFO: 8epoch:train:5001-5200batch: iter_time=2.064e-04, forward_time=0.139, uma_reduction=0.186, text_vs_uma=0.509, loss_ctc=10.728, loss=5.364, backward_time=0.191, optim_step_time=0.041, optim0_lr0=4.582e-04, train_time=0.915
[alab02] 2024-08-27 18:31:04,967 (trainer:720) INFO: 8epoch:train:5201-5400batch: iter_time=2.382e-04, forward_time=0.139, uma_reduction=0.186, text_vs_uma=0.511, loss_ctc=10.729, loss=5.365, backward_time=0.188, optim_step_time=0.043, optim0_lr0=4.599e-04, train_time=0.915
[alab02] 2024-08-27 18:32:36,834 (trainer:720) INFO: 8epoch:train:5401-5600batch: iter_time=2.360e-04, forward_time=0.141, uma_reduction=0.188, text_vs_uma=0.516, loss_ctc=10.881, loss=5.441, backward_time=0.190, optim_step_time=0.041, optim0_lr0=4.615e-04, train_time=0.918
[alab02] 2024-08-27 18:34:06,057 (trainer:720) INFO: 8epoch:train:5601-5800batch: iter_time=2.206e-04, forward_time=0.137, uma_reduction=0.186, text_vs_uma=0.503, loss_ctc=10.713, loss=5.356, backward_time=0.180, optim_step_time=0.042, optim0_lr0=4.632e-04, train_time=0.892
[alab02] 2024-08-27 18:35:36,310 (trainer:720) INFO: 8epoch:train:5801-6000batch: iter_time=2.670e-04, forward_time=0.138, uma_reduction=0.188, text_vs_uma=0.519, loss_ctc=11.111, loss=5.556, backward_time=0.183, optim_step_time=0.043, optim0_lr0=4.649e-04, train_time=0.902
[alab02] 2024-08-27 18:37:05,686 (trainer:720) INFO: 8epoch:train:6001-6200batch: iter_time=2.745e-04, forward_time=0.136, uma_reduction=0.186, text_vs_uma=0.521, loss_ctc=10.794, loss=5.397, backward_time=0.183, optim_step_time=0.041, optim0_lr0=4.665e-04, train_time=0.893
[alab02] 2024-08-27 18:38:37,084 (trainer:720) INFO: 8epoch:train:6201-6400batch: iter_time=3.127e-04, forward_time=0.141, uma_reduction=0.187, text_vs_uma=0.515, loss_ctc=10.146, loss=5.073, backward_time=0.188, optim_step_time=0.044, optim0_lr0=4.682e-04, train_time=0.914
[alab02] 2024-08-27 18:40:20,060 (trainer:720) INFO: 8epoch:train:6401-6600batch: iter_time=5.072e-04, forward_time=0.169, uma_reduction=0.185, text_vs_uma=0.521, loss_ctc=10.243, loss=5.122, backward_time=0.210, optim_step_time=0.064, optim0_lr0=4.699e-04, train_time=1.029
[alab02] 2024-08-27 18:42:05,986 (trainer:720) INFO: 8epoch:train:6601-6800batch: iter_time=9.315e-04, forward_time=0.173, uma_reduction=0.184, text_vs_uma=0.535, loss_ctc=11.323, loss=5.662, backward_time=0.213, optim_step_time=0.072, optim0_lr0=4.715e-04, train_time=1.059
[alab02] 2024-08-27 18:43:50,506 (trainer:720) INFO: 8epoch:train:6801-7000batch: iter_time=6.468e-04, forward_time=0.170, uma_reduction=0.189, text_vs_uma=0.519, loss_ctc=11.030, loss=5.515, backward_time=0.208, optim_step_time=0.074, optim0_lr0=4.732e-04, train_time=1.045
[alab02] 2024-08-27 18:45:38,267 (trainer:338) INFO: 8epoch results: [train] iter_time=4.080e-04, forward_time=0.144, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=10.984, loss=5.492, backward_time=0.191, optim_step_time=0.047, optim0_lr0=4.454e-04, train_time=0.934, time=55 minutes and 29.01 seconds, total_count=57008, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.142, text_vs_uma=0.762, loss_ctc=7.219, cer_ctc=0.170, cer=0.170, loss=7.219, time=8.43 seconds, total_count=208, gpu_max_cached_mem_GB=35.900, [att_plot] time=30.45 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 18:45:48,358 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 18:45:48,359 (trainer:272) INFO: 9/150epoch started. Estimated time to finish: 5 days, 18 hours and 52 minutes
[alab02] 2024-08-27 18:47:35,474 (trainer:720) INFO: 9epoch:train:1-200batch: iter_time=0.005, forward_time=0.174, uma_reduction=0.187, text_vs_uma=0.517, loss_ctc=10.631, loss=5.315, backward_time=0.210, optim_step_time=0.076, optim0_lr0=4.759e-04, train_time=1.070
[alab02] 2024-08-27 18:49:21,302 (trainer:720) INFO: 9epoch:train:201-400batch: iter_time=8.485e-04, forward_time=0.176, uma_reduction=0.182, text_vs_uma=0.532, loss_ctc=11.040, loss=5.520, backward_time=0.211, optim_step_time=0.068, optim0_lr0=4.776e-04, train_time=1.058
[alab02] 2024-08-27 18:51:10,947 (trainer:720) INFO: 9epoch:train:401-600batch: iter_time=7.592e-04, forward_time=0.180, uma_reduction=0.182, text_vs_uma=0.524, loss_ctc=10.781, loss=5.391, backward_time=0.225, optim_step_time=0.078, optim0_lr0=4.793e-04, train_time=1.096
[alab02] 2024-08-27 18:53:00,189 (trainer:720) INFO: 9epoch:train:601-800batch: iter_time=8.019e-04, forward_time=0.181, uma_reduction=0.183, text_vs_uma=0.540, loss_ctc=11.631, loss=5.815, backward_time=0.223, optim_step_time=0.076, optim0_lr0=4.809e-04, train_time=1.092
[alab02] 2024-08-27 18:54:47,399 (trainer:720) INFO: 9epoch:train:801-1000batch: iter_time=0.001, forward_time=0.178, uma_reduction=0.186, text_vs_uma=0.509, loss_ctc=10.006, loss=5.003, backward_time=0.220, optim_step_time=0.077, optim0_lr0=4.826e-04, train_time=1.072
[alab02] 2024-08-27 18:56:36,326 (trainer:720) INFO: 9epoch:train:1001-1200batch: iter_time=8.164e-04, forward_time=0.177, uma_reduction=0.184, text_vs_uma=0.513, loss_ctc=10.499, loss=5.250, backward_time=0.226, optim_step_time=0.074, optim0_lr0=4.843e-04, train_time=1.089
[alab02] 2024-08-27 18:58:23,933 (trainer:720) INFO: 9epoch:train:1201-1400batch: iter_time=5.784e-04, forward_time=0.180, uma_reduction=0.186, text_vs_uma=0.512, loss_ctc=11.266, loss=5.633, backward_time=0.218, optim_step_time=0.069, optim0_lr0=4.859e-04, train_time=1.075
[alab02] 2024-08-27 19:00:12,139 (trainer:720) INFO: 9epoch:train:1401-1600batch: iter_time=7.809e-04, forward_time=0.184, uma_reduction=0.185, text_vs_uma=0.516, loss_ctc=10.189, loss=5.094, backward_time=0.217, optim_step_time=0.070, optim0_lr0=4.876e-04, train_time=1.081
[alab02] 2024-08-27 19:01:57,283 (trainer:720) INFO: 9epoch:train:1601-1800batch: iter_time=6.234e-04, forward_time=0.177, uma_reduction=0.186, text_vs_uma=0.529, loss_ctc=11.189, loss=5.594, backward_time=0.212, optim_step_time=0.064, optim0_lr0=4.893e-04, train_time=1.051
[alab02] 2024-08-27 19:03:43,935 (trainer:720) INFO: 9epoch:train:1801-2000batch: iter_time=6.268e-04, forward_time=0.179, uma_reduction=0.186, text_vs_uma=0.522, loss_ctc=11.266, loss=5.633, backward_time=0.214, optim_step_time=0.066, optim0_lr0=4.909e-04, train_time=1.066
[alab02] 2024-08-27 19:05:30,021 (trainer:720) INFO: 9epoch:train:2001-2200batch: iter_time=5.997e-04, forward_time=0.179, uma_reduction=0.185, text_vs_uma=0.511, loss_ctc=11.043, loss=5.521, backward_time=0.213, optim_step_time=0.064, optim0_lr0=4.926e-04, train_time=1.060
[alab02] 2024-08-27 19:07:15,878 (trainer:720) INFO: 9epoch:train:2201-2400batch: iter_time=6.080e-04, forward_time=0.179, uma_reduction=0.187, text_vs_uma=0.513, loss_ctc=10.361, loss=5.180, backward_time=0.214, optim_step_time=0.066, optim0_lr0=4.943e-04, train_time=1.058
[alab02] 2024-08-27 19:08:59,983 (trainer:720) INFO: 9epoch:train:2401-2600batch: iter_time=6.139e-04, forward_time=0.176, uma_reduction=0.188, text_vs_uma=0.508, loss_ctc=9.893, loss=4.946, backward_time=0.210, optim_step_time=0.068, optim0_lr0=4.959e-04, train_time=1.040
[alab02] 2024-08-27 19:10:46,312 (trainer:720) INFO: 9epoch:train:2601-2800batch: iter_time=6.446e-04, forward_time=0.179, uma_reduction=0.186, text_vs_uma=0.516, loss_ctc=10.600, loss=5.300, backward_time=0.213, optim_step_time=0.064, optim0_lr0=4.976e-04, train_time=1.063
[alab02] 2024-08-27 19:12:31,061 (trainer:720) INFO: 9epoch:train:2801-3000batch: iter_time=5.144e-04, forward_time=0.176, uma_reduction=0.186, text_vs_uma=0.516, loss_ctc=10.573, loss=5.287, backward_time=0.210, optim_step_time=0.064, optim0_lr0=4.993e-04, train_time=1.047
[alab02] 2024-08-27 19:14:14,082 (trainer:720) INFO: 9epoch:train:3001-3200batch: iter_time=6.160e-04, forward_time=0.170, uma_reduction=0.187, text_vs_uma=0.521, loss_ctc=10.972, loss=5.486, backward_time=0.210, optim_step_time=0.065, optim0_lr0=4.995e-04, train_time=1.029
[alab02] 2024-08-27 19:15:58,530 (trainer:720) INFO: 9epoch:train:3201-3400batch: iter_time=6.164e-04, forward_time=0.175, uma_reduction=0.186, text_vs_uma=0.510, loss_ctc=10.491, loss=5.245, backward_time=0.210, optim_step_time=0.065, optim0_lr0=4.987e-04, train_time=1.044
[alab02] 2024-08-27 19:17:39,042 (trainer:720) INFO: 9epoch:train:3401-3600batch: iter_time=5.086e-04, forward_time=0.165, uma_reduction=0.185, text_vs_uma=0.515, loss_ctc=11.287, loss=5.643, backward_time=0.204, optim_step_time=0.057, optim0_lr0=4.979e-04, train_time=1.005
[alab02] 2024-08-27 19:19:17,364 (trainer:720) INFO: 9epoch:train:3601-3800batch: iter_time=3.863e-04, forward_time=0.159, uma_reduction=0.184, text_vs_uma=0.509, loss_ctc=10.405, loss=5.203, backward_time=0.203, optim_step_time=0.050, optim0_lr0=4.971e-04, train_time=0.983
[alab02] 2024-08-27 19:20:52,792 (trainer:720) INFO: 9epoch:train:3801-4000batch: iter_time=3.289e-04, forward_time=0.153, uma_reduction=0.186, text_vs_uma=0.518, loss_ctc=10.999, loss=5.500, backward_time=0.194, optim_step_time=0.045, optim0_lr0=4.962e-04, train_time=0.954
[alab02] 2024-08-27 19:22:24,288 (trainer:720) INFO: 9epoch:train:4001-4200batch: iter_time=3.083e-04, forward_time=0.145, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=10.494, loss=5.247, backward_time=0.185, optim_step_time=0.042, optim0_lr0=4.954e-04, train_time=0.915
[alab02] 2024-08-27 19:23:58,029 (trainer:720) INFO: 9epoch:train:4201-4400batch: iter_time=3.041e-04, forward_time=0.146, uma_reduction=0.186, text_vs_uma=0.521, loss_ctc=11.137, loss=5.569, backward_time=0.191, optim_step_time=0.039, optim0_lr0=4.946e-04, train_time=0.937
[alab02] 2024-08-27 19:25:29,585 (trainer:720) INFO: 9epoch:train:4401-4600batch: iter_time=3.030e-04, forward_time=0.142, uma_reduction=0.186, text_vs_uma=0.530, loss_ctc=10.740, loss=5.370, backward_time=0.188, optim_step_time=0.040, optim0_lr0=4.938e-04, train_time=0.915
[alab02] 2024-08-27 19:27:00,470 (trainer:720) INFO: 9epoch:train:4601-4800batch: iter_time=2.941e-04, forward_time=0.141, uma_reduction=0.183, text_vs_uma=0.521, loss_ctc=10.518, loss=5.259, backward_time=0.185, optim_step_time=0.038, optim0_lr0=4.930e-04, train_time=0.909
[alab02] 2024-08-27 19:28:30,989 (trainer:720) INFO: 9epoch:train:4801-5000batch: iter_time=2.481e-04, forward_time=0.140, uma_reduction=0.183, text_vs_uma=0.521, loss_ctc=10.203, loss=5.102, backward_time=0.187, optim_step_time=0.038, optim0_lr0=4.922e-04, train_time=0.905
[alab02] 2024-08-27 19:30:02,507 (trainer:720) INFO: 9epoch:train:5001-5200batch: iter_time=2.486e-04, forward_time=0.141, uma_reduction=0.185, text_vs_uma=0.534, loss_ctc=11.180, loss=5.590, backward_time=0.187, optim_step_time=0.037, optim0_lr0=4.914e-04, train_time=0.915
[alab02] 2024-08-27 19:31:33,486 (trainer:720) INFO: 9epoch:train:5201-5400batch: iter_time=2.415e-04, forward_time=0.142, uma_reduction=0.186, text_vs_uma=0.510, loss_ctc=10.181, loss=5.090, backward_time=0.187, optim_step_time=0.039, optim0_lr0=4.906e-04, train_time=0.909
[alab02] 2024-08-27 19:33:05,693 (trainer:720) INFO: 9epoch:train:5401-5600batch: iter_time=2.321e-04, forward_time=0.143, uma_reduction=0.185, text_vs_uma=0.516, loss_ctc=11.004, loss=5.502, backward_time=0.185, optim_step_time=0.039, optim0_lr0=4.899e-04, train_time=0.922
[alab02] 2024-08-27 19:34:37,374 (trainer:720) INFO: 9epoch:train:5601-5800batch: iter_time=3.149e-04, forward_time=0.143, uma_reduction=0.185, text_vs_uma=0.513, loss_ctc=10.126, loss=5.063, backward_time=0.187, optim_step_time=0.041, optim0_lr0=4.891e-04, train_time=0.917
[alab02] 2024-08-27 19:36:07,561 (trainer:720) INFO: 9epoch:train:5801-6000batch: iter_time=2.782e-04, forward_time=0.141, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=10.577, loss=5.288, backward_time=0.180, optim_step_time=0.041, optim0_lr0=4.883e-04, train_time=0.902
[alab02] 2024-08-27 19:37:39,551 (trainer:720) INFO: 9epoch:train:6001-6200batch: iter_time=3.025e-04, forward_time=0.143, uma_reduction=0.187, text_vs_uma=0.505, loss_ctc=10.266, loss=5.133, backward_time=0.188, optim_step_time=0.040, optim0_lr0=4.875e-04, train_time=0.920
[alab02] 2024-08-27 19:39:10,667 (trainer:720) INFO: 9epoch:train:6201-6400batch: iter_time=2.984e-04, forward_time=0.141, uma_reduction=0.189, text_vs_uma=0.497, loss_ctc=9.785, loss=4.892, backward_time=0.186, optim_step_time=0.040, optim0_lr0=4.868e-04, train_time=0.911
[alab02] 2024-08-27 19:40:43,198 (trainer:720) INFO: 9epoch:train:6401-6600batch: iter_time=3.368e-04, forward_time=0.145, uma_reduction=0.189, text_vs_uma=0.512, loss_ctc=9.657, loss=4.829, backward_time=0.190, optim_step_time=0.043, optim0_lr0=4.860e-04, train_time=0.925
[alab02] 2024-08-27 19:42:14,969 (trainer:720) INFO: 9epoch:train:6601-6800batch: iter_time=2.920e-04, forward_time=0.143, uma_reduction=0.188, text_vs_uma=0.506, loss_ctc=10.091, loss=5.045, backward_time=0.187, optim_step_time=0.040, optim0_lr0=4.852e-04, train_time=0.917
[alab02] 2024-08-27 19:43:46,141 (trainer:720) INFO: 9epoch:train:6801-7000batch: iter_time=2.826e-04, forward_time=0.140, uma_reduction=0.188, text_vs_uma=0.513, loss_ctc=10.897, loss=5.448, backward_time=0.183, optim_step_time=0.040, optim0_lr0=4.845e-04, train_time=0.911
[alab02] 2024-08-27 19:45:06,469 (trainer:338) INFO: 9epoch results: [train] iter_time=6.053e-04, forward_time=0.161, uma_reduction=0.186, text_vs_uma=0.516, loss_ctc=10.614, loss=5.307, backward_time=0.201, optim_step_time=0.055, optim0_lr0=4.899e-04, train_time=0.992, time=58 minutes and 56.95 seconds, total_count=64134, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.147, text_vs_uma=0.736, loss_ctc=7.914, cer_ctc=0.168, cer=0.168, loss=7.914, time=6.66 seconds, total_count=234, gpu_max_cached_mem_GB=35.900, [att_plot] time=14.49 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 19:45:13,695 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 19:45:13,696 (trainer:272) INFO: 10/150epoch started. Estimated time to finish: 5 days, 18 hours and 5 minutes
[alab02] 2024-08-27 19:46:47,449 (trainer:720) INFO: 10epoch:train:1-200batch: iter_time=0.003, forward_time=0.144, uma_reduction=0.188, text_vs_uma=0.506, loss_ctc=9.737, loss=4.869, backward_time=0.192, optim_step_time=0.041, optim0_lr0=4.832e-04, train_time=0.937
[alab02] 2024-08-27 19:48:19,099 (trainer:720) INFO: 10epoch:train:201-400batch: iter_time=2.524e-04, forward_time=0.141, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=10.070, loss=5.035, backward_time=0.190, optim_step_time=0.040, optim0_lr0=4.825e-04, train_time=0.916
[alab02] 2024-08-27 19:49:47,912 (trainer:720) INFO: 10epoch:train:401-600batch: iter_time=2.881e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.510, loss_ctc=10.140, loss=5.070, backward_time=0.180, optim_step_time=0.040, optim0_lr0=4.817e-04, train_time=0.888
[alab02] 2024-08-27 19:51:22,034 (trainer:720) INFO: 10epoch:train:601-800batch: iter_time=3.753e-04, forward_time=0.147, uma_reduction=0.187, text_vs_uma=0.520, loss_ctc=9.977, loss=4.989, backward_time=0.194, optim_step_time=0.044, optim0_lr0=4.810e-04, train_time=0.941
[alab02] 2024-08-27 19:52:53,758 (trainer:720) INFO: 10epoch:train:801-1000batch: iter_time=3.500e-04, forward_time=0.143, uma_reduction=0.185, text_vs_uma=0.514, loss_ctc=10.313, loss=5.156, backward_time=0.187, optim_step_time=0.041, optim0_lr0=4.802e-04, train_time=0.917
[alab02] 2024-08-27 19:54:24,321 (trainer:720) INFO: 10epoch:train:1001-1200batch: iter_time=2.790e-04, forward_time=0.140, uma_reduction=0.185, text_vs_uma=0.524, loss_ctc=10.668, loss=5.334, backward_time=0.183, optim_step_time=0.040, optim0_lr0=4.795e-04, train_time=0.905
[alab02] 2024-08-27 19:55:53,555 (trainer:720) INFO: 10epoch:train:1201-1400batch: iter_time=3.141e-04, forward_time=0.139, uma_reduction=0.188, text_vs_uma=0.508, loss_ctc=9.734, loss=4.867, backward_time=0.180, optim_step_time=0.039, optim0_lr0=4.788e-04, train_time=0.892
[alab02] 2024-08-27 19:57:23,672 (trainer:720) INFO: 10epoch:train:1401-1600batch: iter_time=3.644e-04, forward_time=0.140, uma_reduction=0.188, text_vs_uma=0.517, loss_ctc=10.053, loss=5.026, backward_time=0.181, optim_step_time=0.040, optim0_lr0=4.780e-04, train_time=0.901
[alab02] 2024-08-27 19:58:55,640 (trainer:720) INFO: 10epoch:train:1601-1800batch: iter_time=2.697e-04, forward_time=0.142, uma_reduction=0.190, text_vs_uma=0.514, loss_ctc=10.478, loss=5.239, backward_time=0.187, optim_step_time=0.037, optim0_lr0=4.773e-04, train_time=0.919
[alab02] 2024-08-27 20:00:32,514 (trainer:720) INFO: 10epoch:train:1801-2000batch: iter_time=5.319e-04, forward_time=0.155, uma_reduction=0.187, text_vs_uma=0.509, loss_ctc=9.732, loss=4.866, backward_time=0.198, optim_step_time=0.053, optim0_lr0=4.766e-04, train_time=0.968
[alab02] 2024-08-27 20:02:14,020 (trainer:720) INFO: 10epoch:train:2001-2200batch: iter_time=7.111e-04, forward_time=0.168, uma_reduction=0.185, text_vs_uma=0.521, loss_ctc=10.029, loss=5.015, backward_time=0.202, optim_step_time=0.060, optim0_lr0=4.759e-04, train_time=1.015
[alab02] 2024-08-27 20:03:57,940 (trainer:720) INFO: 10epoch:train:2201-2400batch: iter_time=8.726e-04, forward_time=0.173, uma_reduction=0.186, text_vs_uma=0.525, loss_ctc=10.647, loss=5.323, backward_time=0.207, optim_step_time=0.062, optim0_lr0=4.752e-04, train_time=1.038
[alab02] 2024-08-27 20:05:39,870 (trainer:720) INFO: 10epoch:train:2401-2600batch: iter_time=9.182e-04, forward_time=0.169, uma_reduction=0.187, text_vs_uma=0.505, loss_ctc=9.678, loss=4.839, backward_time=0.203, optim_step_time=0.060, optim0_lr0=4.744e-04, train_time=1.019
[alab02] 2024-08-27 20:07:20,374 (trainer:720) INFO: 10epoch:train:2601-2800batch: iter_time=5.674e-04, forward_time=0.165, uma_reduction=0.188, text_vs_uma=0.517, loss_ctc=10.327, loss=5.163, backward_time=0.200, optim_step_time=0.059, optim0_lr0=4.737e-04, train_time=1.004
[alab02] 2024-08-27 20:09:05,011 (trainer:720) INFO: 10epoch:train:2801-3000batch: iter_time=7.357e-04, forward_time=0.174, uma_reduction=0.191, text_vs_uma=0.505, loss_ctc=9.280, loss=4.640, backward_time=0.212, optim_step_time=0.061, optim0_lr0=4.730e-04, train_time=1.046
[alab02] 2024-08-27 20:10:47,515 (trainer:720) INFO: 10epoch:train:3001-3200batch: iter_time=4.675e-04, forward_time=0.169, uma_reduction=0.189, text_vs_uma=0.506, loss_ctc=9.247, loss=4.623, backward_time=0.210, optim_step_time=0.064, optim0_lr0=4.723e-04, train_time=1.024
[alab02] 2024-08-27 20:12:31,536 (trainer:720) INFO: 10epoch:train:3201-3400batch: iter_time=5.502e-04, forward_time=0.175, uma_reduction=0.190, text_vs_uma=0.500, loss_ctc=9.520, loss=4.760, backward_time=0.211, optim_step_time=0.062, optim0_lr0=4.716e-04, train_time=1.040
[alab02] 2024-08-27 20:14:15,180 (trainer:720) INFO: 10epoch:train:3401-3600batch: iter_time=5.042e-04, forward_time=0.173, uma_reduction=0.188, text_vs_uma=0.503, loss_ctc=9.799, loss=4.899, backward_time=0.207, optim_step_time=0.065, optim0_lr0=4.709e-04, train_time=1.036
[alab02] 2024-08-27 20:15:59,578 (trainer:720) INFO: 10epoch:train:3601-3800batch: iter_time=5.386e-04, forward_time=0.174, uma_reduction=0.189, text_vs_uma=0.508, loss_ctc=9.428, loss=4.714, backward_time=0.212, optim_step_time=0.063, optim0_lr0=4.702e-04, train_time=1.043
[alab02] 2024-08-27 20:17:42,113 (trainer:720) INFO: 10epoch:train:3801-4000batch: iter_time=5.682e-04, forward_time=0.171, uma_reduction=0.186, text_vs_uma=0.520, loss_ctc=9.997, loss=4.999, backward_time=0.208, optim_step_time=0.062, optim0_lr0=4.695e-04, train_time=1.025
[alab02] 2024-08-27 20:19:23,172 (trainer:720) INFO: 10epoch:train:4001-4200batch: iter_time=5.045e-04, forward_time=0.168, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=9.233, loss=4.616, backward_time=0.207, optim_step_time=0.059, optim0_lr0=4.689e-04, train_time=1.010
[alab02] 2024-08-27 20:21:01,076 (trainer:720) INFO: 10epoch:train:4201-4400batch: iter_time=3.736e-04, forward_time=0.159, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=9.925, loss=4.963, backward_time=0.200, optim_step_time=0.058, optim0_lr0=4.682e-04, train_time=0.978
[alab02] 2024-08-27 20:22:39,653 (trainer:720) INFO: 10epoch:train:4401-4600batch: iter_time=4.245e-04, forward_time=0.160, uma_reduction=0.190, text_vs_uma=0.507, loss_ctc=9.741, loss=4.870, backward_time=0.199, optim_step_time=0.060, optim0_lr0=4.675e-04, train_time=0.985
[alab02] 2024-08-27 20:24:17,669 (trainer:720) INFO: 10epoch:train:4601-4800batch: iter_time=3.965e-04, forward_time=0.157, uma_reduction=0.187, text_vs_uma=0.506, loss_ctc=9.765, loss=4.882, backward_time=0.197, optim_step_time=0.056, optim0_lr0=4.668e-04, train_time=0.980
[alab02] 2024-08-27 20:25:53,836 (trainer:720) INFO: 10epoch:train:4801-5000batch: iter_time=3.907e-04, forward_time=0.152, uma_reduction=0.187, text_vs_uma=0.522, loss_ctc=10.327, loss=5.164, backward_time=0.193, optim_step_time=0.052, optim0_lr0=4.661e-04, train_time=0.961
[alab02] 2024-08-27 20:27:30,423 (trainer:720) INFO: 10epoch:train:5001-5200batch: iter_time=3.260e-04, forward_time=0.156, uma_reduction=0.188, text_vs_uma=0.509, loss_ctc=9.475, loss=4.738, backward_time=0.195, optim_step_time=0.053, optim0_lr0=4.655e-04, train_time=0.965
[alab02] 2024-08-27 20:29:09,277 (trainer:720) INFO: 10epoch:train:5201-5400batch: iter_time=4.609e-04, forward_time=0.157, uma_reduction=0.186, text_vs_uma=0.505, loss_ctc=9.139, loss=4.569, backward_time=0.204, optim_step_time=0.056, optim0_lr0=4.648e-04, train_time=0.988
[alab02] 2024-08-27 20:30:46,614 (trainer:720) INFO: 10epoch:train:5401-5600batch: iter_time=3.602e-04, forward_time=0.156, uma_reduction=0.188, text_vs_uma=0.500, loss_ctc=9.737, loss=4.868, backward_time=0.196, optim_step_time=0.054, optim0_lr0=4.641e-04, train_time=0.973
[alab02] 2024-08-27 20:32:21,358 (trainer:720) INFO: 10epoch:train:5601-5800batch: iter_time=2.932e-04, forward_time=0.148, uma_reduction=0.188, text_vs_uma=0.508, loss_ctc=9.764, loss=4.882, backward_time=0.196, optim_step_time=0.046, optim0_lr0=4.635e-04, train_time=0.947
[alab02] 2024-08-27 20:33:52,403 (trainer:720) INFO: 10epoch:train:5801-6000batch: iter_time=2.468e-04, forward_time=0.141, uma_reduction=0.186, text_vs_uma=0.499, loss_ctc=9.248, loss=4.624, backward_time=0.188, optim_step_time=0.041, optim0_lr0=4.628e-04, train_time=0.910
[alab02] 2024-08-27 20:35:22,459 (trainer:720) INFO: 10epoch:train:6001-6200batch: iter_time=2.163e-04, forward_time=0.136, uma_reduction=0.187, text_vs_uma=0.518, loss_ctc=9.697, loss=4.849, backward_time=0.186, optim_step_time=0.037, optim0_lr0=4.621e-04, train_time=0.900
[alab02] 2024-08-27 20:36:51,223 (trainer:720) INFO: 10epoch:train:6201-6400batch: iter_time=2.033e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.502, loss_ctc=9.139, loss=4.569, backward_time=0.189, optim_step_time=0.033, optim0_lr0=4.615e-04, train_time=0.887
[alab02] 2024-08-27 20:38:24,997 (trainer:720) INFO: 10epoch:train:6401-6600batch: iter_time=3.241e-04, forward_time=0.146, uma_reduction=0.187, text_vs_uma=0.513, loss_ctc=9.344, loss=4.672, backward_time=0.193, optim_step_time=0.047, optim0_lr0=4.608e-04, train_time=0.937
[alab02] 2024-08-27 20:39:59,512 (trainer:720) INFO: 10epoch:train:6601-6800batch: iter_time=3.361e-04, forward_time=0.149, uma_reduction=0.188, text_vs_uma=0.514, loss_ctc=9.151, loss=4.575, backward_time=0.194, optim_step_time=0.049, optim0_lr0=4.602e-04, train_time=0.945
[alab02] 2024-08-27 20:41:36,003 (trainer:720) INFO: 10epoch:train:6801-7000batch: iter_time=3.504e-04, forward_time=0.153, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=9.608, loss=4.804, backward_time=0.199, optim_step_time=0.048, optim0_lr0=4.595e-04, train_time=0.964
[alab02] 2024-08-27 20:43:01,941 (trainer:338) INFO: 10epoch results: [train] iter_time=5.101e-04, forward_time=0.154, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=9.761, loss=4.880, backward_time=0.197, optim_step_time=0.051, optim0_lr0=4.709e-04, train_time=0.966, time=57 minutes and 22.88 seconds, total_count=71260, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.145, text_vs_uma=0.745, loss_ctc=6.553, cer_ctc=0.144, cer=0.144, loss=6.553, time=7.73 seconds, total_count=260, gpu_max_cached_mem_GB=35.900, [att_plot] time=17.63 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 20:43:09,882 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 20:43:09,883 (trainer:272) INFO: 11/150epoch started. Estimated time to finish: 5 days, 16 hours and 54 minutes
[alab02] 2024-08-27 20:44:46,085 (trainer:720) INFO: 11epoch:train:1-200batch: iter_time=0.003, forward_time=0.151, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=9.479, loss=4.739, backward_time=0.194, optim_step_time=0.048, optim0_lr0=4.585e-04, train_time=0.961
[alab02] 2024-08-27 20:46:24,261 (trainer:720) INFO: 11epoch:train:201-400batch: iter_time=4.307e-04, forward_time=0.154, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=9.318, loss=4.659, backward_time=0.203, optim_step_time=0.051, optim0_lr0=4.578e-04, train_time=0.981
[alab02] 2024-08-27 20:48:01,496 (trainer:720) INFO: 11epoch:train:401-600batch: iter_time=4.733e-04, forward_time=0.157, uma_reduction=0.192, text_vs_uma=0.501, loss_ctc=8.686, loss=4.343, backward_time=0.199, optim_step_time=0.055, optim0_lr0=4.572e-04, train_time=0.972
[alab02] 2024-08-27 20:49:45,519 (trainer:720) INFO: 11epoch:train:601-800batch: iter_time=5.466e-04, forward_time=0.171, uma_reduction=0.191, text_vs_uma=0.511, loss_ctc=9.373, loss=4.686, backward_time=0.213, optim_step_time=0.065, optim0_lr0=4.566e-04, train_time=1.039
[alab02] 2024-08-27 20:51:27,408 (trainer:720) INFO: 11epoch:train:801-1000batch: iter_time=4.577e-04, forward_time=0.166, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=8.379, loss=4.189, backward_time=0.213, optim_step_time=0.061, optim0_lr0=4.559e-04, train_time=1.018
[alab02] 2024-08-27 20:53:09,993 (trainer:720) INFO: 11epoch:train:1001-1200batch: iter_time=5.463e-04, forward_time=0.169, uma_reduction=0.189, text_vs_uma=0.500, loss_ctc=8.974, loss=4.487, backward_time=0.210, optim_step_time=0.065, optim0_lr0=4.553e-04, train_time=1.025
[alab02] 2024-08-27 20:54:50,074 (trainer:720) INFO: 11epoch:train:1201-1400batch: iter_time=5.175e-04, forward_time=0.165, uma_reduction=0.191, text_vs_uma=0.489, loss_ctc=8.009, loss=4.004, backward_time=0.209, optim_step_time=0.063, optim0_lr0=4.547e-04, train_time=1.000
[alab02] 2024-08-27 20:56:32,127 (trainer:720) INFO: 11epoch:train:1401-1600batch: iter_time=4.767e-04, forward_time=0.170, uma_reduction=0.192, text_vs_uma=0.496, loss_ctc=8.687, loss=4.343, backward_time=0.207, optim_step_time=0.063, optim0_lr0=4.540e-04, train_time=1.020
[alab02] 2024-08-27 20:58:11,832 (trainer:720) INFO: 11epoch:train:1601-1800batch: iter_time=4.426e-04, forward_time=0.162, uma_reduction=0.192, text_vs_uma=0.500, loss_ctc=9.286, loss=4.643, backward_time=0.202, optim_step_time=0.058, optim0_lr0=4.534e-04, train_time=0.996
[alab02] 2024-08-27 20:59:53,967 (trainer:720) INFO: 11epoch:train:1801-2000batch: iter_time=4.950e-04, forward_time=0.168, uma_reduction=0.191, text_vs_uma=0.507, loss_ctc=9.230, loss=4.615, backward_time=0.206, optim_step_time=0.062, optim0_lr0=4.528e-04, train_time=1.021
[alab02] 2024-08-27 21:01:33,824 (trainer:720) INFO: 11epoch:train:2001-2200batch: iter_time=4.510e-04, forward_time=0.162, uma_reduction=0.192, text_vs_uma=0.513, loss_ctc=9.570, loss=4.785, backward_time=0.201, optim_step_time=0.062, optim0_lr0=4.522e-04, train_time=0.998
[alab02] 2024-08-27 21:03:16,310 (trainer:720) INFO: 11epoch:train:2201-2400batch: iter_time=5.422e-04, forward_time=0.171, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=8.969, loss=4.485, backward_time=0.206, optim_step_time=0.064, optim0_lr0=4.516e-04, train_time=1.024
[alab02] 2024-08-27 21:04:55,643 (trainer:720) INFO: 11epoch:train:2401-2600batch: iter_time=5.540e-04, forward_time=0.162, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=9.375, loss=4.687, backward_time=0.201, optim_step_time=0.061, optim0_lr0=4.509e-04, train_time=0.993
[alab02] 2024-08-27 21:06:35,547 (trainer:720) INFO: 11epoch:train:2601-2800batch: iter_time=5.130e-04, forward_time=0.163, uma_reduction=0.192, text_vs_uma=0.508, loss_ctc=9.306, loss=4.653, backward_time=0.202, optim_step_time=0.059, optim0_lr0=4.503e-04, train_time=0.998
[alab02] 2024-08-27 21:08:16,925 (trainer:720) INFO: 11epoch:train:2801-3000batch: iter_time=6.494e-04, forward_time=0.165, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=9.083, loss=4.542, backward_time=0.205, optim_step_time=0.059, optim0_lr0=4.497e-04, train_time=1.013
[alab02] 2024-08-27 21:10:01,154 (trainer:720) INFO: 11epoch:train:3001-3200batch: iter_time=6.144e-04, forward_time=0.172, uma_reduction=0.190, text_vs_uma=0.505, loss_ctc=9.090, loss=4.545, backward_time=0.207, optim_step_time=0.060, optim0_lr0=4.491e-04, train_time=1.042
[alab02] 2024-08-27 21:11:39,993 (trainer:720) INFO: 11epoch:train:3201-3400batch: iter_time=4.416e-04, forward_time=0.159, uma_reduction=0.189, text_vs_uma=0.494, loss_ctc=8.619, loss=4.310, backward_time=0.202, optim_step_time=0.056, optim0_lr0=4.485e-04, train_time=0.988
[alab02] 2024-08-27 21:13:19,046 (trainer:720) INFO: 11epoch:train:3401-3600batch: iter_time=5.109e-04, forward_time=0.158, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=9.527, loss=4.764, backward_time=0.197, optim_step_time=0.057, optim0_lr0=4.479e-04, train_time=0.990
[alab02] 2024-08-27 21:14:55,932 (trainer:720) INFO: 11epoch:train:3601-3800batch: iter_time=4.411e-04, forward_time=0.153, uma_reduction=0.191, text_vs_uma=0.516, loss_ctc=9.877, loss=4.939, backward_time=0.194, optim_step_time=0.053, optim0_lr0=4.473e-04, train_time=0.968
[alab02] 2024-08-27 21:16:27,465 (trainer:720) INFO: 11epoch:train:3801-4000batch: iter_time=2.577e-04, forward_time=0.142, uma_reduction=0.190, text_vs_uma=0.513, loss_ctc=9.286, loss=4.643, backward_time=0.183, optim_step_time=0.043, optim0_lr0=4.467e-04, train_time=0.915
[alab02] 2024-08-27 21:17:58,901 (trainer:720) INFO: 11epoch:train:4001-4200batch: iter_time=2.346e-04, forward_time=0.143, uma_reduction=0.190, text_vs_uma=0.496, loss_ctc=8.526, loss=4.263, backward_time=0.191, optim_step_time=0.038, optim0_lr0=4.461e-04, train_time=0.914
[alab02] 2024-08-27 21:19:27,627 (trainer:720) INFO: 11epoch:train:4201-4400batch: iter_time=2.165e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.506, loss_ctc=8.914, loss=4.457, backward_time=0.182, optim_step_time=0.037, optim0_lr0=4.455e-04, train_time=0.887
[alab02] 2024-08-27 21:20:54,288 (trainer:720) INFO: 11epoch:train:4401-4600batch: iter_time=1.963e-04, forward_time=0.132, uma_reduction=0.189, text_vs_uma=0.503, loss_ctc=9.377, loss=4.689, backward_time=0.175, optim_step_time=0.035, optim0_lr0=4.450e-04, train_time=0.866
[alab02] 2024-08-27 21:22:30,352 (trainer:720) INFO: 11epoch:train:4601-4800batch: iter_time=2.789e-04, forward_time=0.151, uma_reduction=0.191, text_vs_uma=0.489, loss_ctc=8.746, loss=4.373, backward_time=0.201, optim_step_time=0.045, optim0_lr0=4.444e-04, train_time=0.960
[alab02] 2024-08-27 21:24:08,013 (trainer:720) INFO: 11epoch:train:4801-5000batch: iter_time=3.745e-04, forward_time=0.158, uma_reduction=0.191, text_vs_uma=0.508, loss_ctc=8.970, loss=4.485, backward_time=0.200, optim_step_time=0.055, optim0_lr0=4.438e-04, train_time=0.976
[alab02] 2024-08-27 21:25:49,466 (trainer:720) INFO: 11epoch:train:5001-5200batch: iter_time=5.782e-04, forward_time=0.165, uma_reduction=0.189, text_vs_uma=0.514, loss_ctc=9.237, loss=4.619, backward_time=0.204, optim_step_time=0.061, optim0_lr0=4.432e-04, train_time=1.014
[alab02] 2024-08-27 21:27:32,696 (trainer:720) INFO: 11epoch:train:5201-5400batch: iter_time=6.022e-04, forward_time=0.175, uma_reduction=0.189, text_vs_uma=0.501, loss_ctc=8.479, loss=4.239, backward_time=0.208, optim_step_time=0.065, optim0_lr0=4.426e-04, train_time=1.032
[alab02] 2024-08-27 21:29:15,771 (trainer:720) INFO: 11epoch:train:5401-5600batch: iter_time=5.362e-04, forward_time=0.168, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=9.048, loss=4.524, backward_time=0.211, optim_step_time=0.063, optim0_lr0=4.420e-04, train_time=1.030
[alab02] 2024-08-27 21:30:58,153 (trainer:720) INFO: 11epoch:train:5601-5800batch: iter_time=4.886e-04, forward_time=0.167, uma_reduction=0.191, text_vs_uma=0.512, loss_ctc=8.417, loss=4.209, backward_time=0.215, optim_step_time=0.063, optim0_lr0=4.415e-04, train_time=1.023
[alab02] 2024-08-27 21:32:41,457 (trainer:720) INFO: 11epoch:train:5801-6000batch: iter_time=3.798e-04, forward_time=0.169, uma_reduction=0.192, text_vs_uma=0.519, loss_ctc=9.241, loss=4.620, backward_time=0.211, optim_step_time=0.064, optim0_lr0=4.409e-04, train_time=1.032
[alab02] 2024-08-27 21:34:24,311 (trainer:720) INFO: 11epoch:train:6001-6200batch: iter_time=4.951e-04, forward_time=0.169, uma_reduction=0.191, text_vs_uma=0.501, loss_ctc=8.217, loss=4.109, backward_time=0.213, optim_step_time=0.065, optim0_lr0=4.403e-04, train_time=1.028
[alab02] 2024-08-27 21:36:08,146 (trainer:720) INFO: 11epoch:train:6201-6400batch: iter_time=5.166e-04, forward_time=0.170, uma_reduction=0.188, text_vs_uma=0.500, loss_ctc=8.722, loss=4.361, backward_time=0.210, optim_step_time=0.065, optim0_lr0=4.398e-04, train_time=1.038
[alab02] 2024-08-27 21:37:50,137 (trainer:720) INFO: 11epoch:train:6401-6600batch: iter_time=4.220e-04, forward_time=0.165, uma_reduction=0.186, text_vs_uma=0.526, loss_ctc=10.155, loss=5.078, backward_time=0.202, optim_step_time=0.064, optim0_lr0=4.392e-04, train_time=1.019
[alab02] 2024-08-27 21:39:34,122 (trainer:720) INFO: 11epoch:train:6601-6800batch: iter_time=7.362e-04, forward_time=0.169, uma_reduction=0.189, text_vs_uma=0.504, loss_ctc=8.602, loss=4.301, backward_time=0.210, optim_step_time=0.068, optim0_lr0=4.386e-04, train_time=1.039
[alab02] 2024-08-27 21:41:15,596 (trainer:720) INFO: 11epoch:train:6801-7000batch: iter_time=6.494e-04, forward_time=0.169, uma_reduction=0.190, text_vs_uma=0.503, loss_ctc=8.370, loss=4.185, backward_time=0.203, optim_step_time=0.066, optim0_lr0=4.381e-04, train_time=1.014
[alab02] 2024-08-27 21:42:54,892 (trainer:338) INFO: 11epoch results: [train] iter_time=5.592e-04, forward_time=0.161, uma_reduction=0.190, text_vs_uma=0.505, loss_ctc=8.985, loss=4.492, backward_time=0.203, optim_step_time=0.058, optim0_lr0=4.479e-04, train_time=0.996, time=59 minutes and 10.62 seconds, total_count=78386, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.151, text_vs_uma=0.718, loss_ctc=6.196, cer_ctc=0.133, cer=0.133, loss=6.196, time=8.08 seconds, total_count=286, gpu_max_cached_mem_GB=35.900, [att_plot] time=26.29 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 21:43:04,923 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 21:43:04,937 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/1epoch.pth
[alab02] 2024-08-27 21:43:04,939 (trainer:272) INFO: 12/150epoch started. Estimated time to finish: 5 days, 16 hours and 11 minutes
[alab02] 2024-08-27 21:44:49,837 (trainer:720) INFO: 12epoch:train:1-200batch: iter_time=0.006, forward_time=0.168, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=9.090, loss=4.545, backward_time=0.208, optim_step_time=0.065, optim0_lr0=4.372e-04, train_time=1.048
[alab02] 2024-08-27 21:46:31,811 (trainer:720) INFO: 12epoch:train:201-400batch: iter_time=5.743e-04, forward_time=0.163, uma_reduction=0.192, text_vs_uma=0.505, loss_ctc=8.896, loss=4.448, backward_time=0.210, optim_step_time=0.063, optim0_lr0=4.366e-04, train_time=1.019
[alab02] 2024-08-27 21:48:19,633 (trainer:720) INFO: 12epoch:train:401-600batch: iter_time=7.023e-04, forward_time=0.179, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=9.695, loss=4.847, backward_time=0.216, optim_step_time=0.068, optim0_lr0=4.361e-04, train_time=1.078
[alab02] 2024-08-27 21:50:03,039 (trainer:720) INFO: 12epoch:train:601-800batch: iter_time=6.421e-04, forward_time=0.171, uma_reduction=0.190, text_vs_uma=0.505, loss_ctc=8.955, loss=4.478, backward_time=0.208, optim_step_time=0.065, optim0_lr0=4.355e-04, train_time=1.033
[alab02] 2024-08-27 21:51:46,090 (trainer:720) INFO: 12epoch:train:801-1000batch: iter_time=7.959e-04, forward_time=0.168, uma_reduction=0.190, text_vs_uma=0.497, loss_ctc=8.682, loss=4.341, backward_time=0.208, optim_step_time=0.064, optim0_lr0=4.349e-04, train_time=1.030
[alab02] 2024-08-27 21:53:29,705 (trainer:720) INFO: 12epoch:train:1001-1200batch: iter_time=5.785e-04, forward_time=0.170, uma_reduction=0.193, text_vs_uma=0.497, loss_ctc=8.620, loss=4.310, backward_time=0.210, optim_step_time=0.066, optim0_lr0=4.344e-04, train_time=1.036
[alab02] 2024-08-27 21:55:07,756 (trainer:720) INFO: 12epoch:train:1201-1400batch: iter_time=5.708e-04, forward_time=0.158, uma_reduction=0.193, text_vs_uma=0.517, loss_ctc=9.092, loss=4.546, backward_time=0.197, optim_step_time=0.061, optim0_lr0=4.339e-04, train_time=0.980
[alab02] 2024-08-27 21:56:49,678 (trainer:720) INFO: 12epoch:train:1401-1600batch: iter_time=5.933e-04, forward_time=0.166, uma_reduction=0.193, text_vs_uma=0.507, loss_ctc=8.481, loss=4.240, backward_time=0.208, optim_step_time=0.059, optim0_lr0=4.333e-04, train_time=1.019
[alab02] 2024-08-27 21:58:27,507 (trainer:720) INFO: 12epoch:train:1601-1800batch: iter_time=6.172e-04, forward_time=0.155, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=8.479, loss=4.240, backward_time=0.202, optim_step_time=0.057, optim0_lr0=4.328e-04, train_time=0.978
[alab02] 2024-08-27 22:00:04,649 (trainer:720) INFO: 12epoch:train:1801-2000batch: iter_time=3.611e-04, forward_time=0.154, uma_reduction=0.194, text_vs_uma=0.494, loss_ctc=8.288, loss=4.144, backward_time=0.200, optim_step_time=0.050, optim0_lr0=4.322e-04, train_time=0.971
[alab02] 2024-08-27 22:01:37,530 (trainer:720) INFO: 12epoch:train:2001-2200batch: iter_time=2.681e-04, forward_time=0.145, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=8.569, loss=4.285, backward_time=0.189, optim_step_time=0.045, optim0_lr0=4.317e-04, train_time=0.928
[alab02] 2024-08-27 22:03:09,356 (trainer:720) INFO: 12epoch:train:2201-2400batch: iter_time=2.249e-04, forward_time=0.142, uma_reduction=0.190, text_vs_uma=0.514, loss_ctc=8.984, loss=4.492, backward_time=0.187, optim_step_time=0.038, optim0_lr0=4.312e-04, train_time=0.918
[alab02] 2024-08-27 22:04:39,144 (trainer:720) INFO: 12epoch:train:2401-2600batch: iter_time=2.043e-04, forward_time=0.137, uma_reduction=0.190, text_vs_uma=0.512, loss_ctc=9.024, loss=4.512, backward_time=0.184, optim_step_time=0.036, optim0_lr0=4.306e-04, train_time=0.898
[alab02] 2024-08-27 22:06:06,008 (trainer:720) INFO: 12epoch:train:2601-2800batch: iter_time=2.030e-04, forward_time=0.133, uma_reduction=0.190, text_vs_uma=0.497, loss_ctc=8.845, loss=4.423, backward_time=0.174, optim_step_time=0.036, optim0_lr0=4.301e-04, train_time=0.868
[alab02] 2024-08-27 22:07:33,431 (trainer:720) INFO: 12epoch:train:2801-3000batch: iter_time=1.935e-04, forward_time=0.132, uma_reduction=0.192, text_vs_uma=0.517, loss_ctc=8.415, loss=4.207, backward_time=0.181, optim_step_time=0.035, optim0_lr0=4.296e-04, train_time=0.874
[alab02] 2024-08-27 22:09:04,515 (trainer:720) INFO: 12epoch:train:3001-3200batch: iter_time=1.963e-04, forward_time=0.138, uma_reduction=0.192, text_vs_uma=0.512, loss_ctc=9.380, loss=4.690, backward_time=0.185, optim_step_time=0.036, optim0_lr0=4.290e-04, train_time=0.911
[alab02] 2024-08-27 22:10:33,603 (trainer:720) INFO: 12epoch:train:3201-3400batch: iter_time=1.994e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.501, loss_ctc=8.961, loss=4.480, backward_time=0.178, optim_step_time=0.036, optim0_lr0=4.285e-04, train_time=0.891
[alab02] 2024-08-27 22:12:04,616 (trainer:720) INFO: 12epoch:train:3401-3600batch: iter_time=2.162e-04, forward_time=0.139, uma_reduction=0.194, text_vs_uma=0.495, loss_ctc=8.285, loss=4.143, backward_time=0.190, optim_step_time=0.035, optim0_lr0=4.280e-04, train_time=0.910
[alab02] 2024-08-27 22:13:32,752 (trainer:720) INFO: 12epoch:train:3601-3800batch: iter_time=2.099e-04, forward_time=0.134, uma_reduction=0.193, text_vs_uma=0.499, loss_ctc=8.698, loss=4.349, backward_time=0.180, optim_step_time=0.036, optim0_lr0=4.275e-04, train_time=0.881
[alab02] 2024-08-27 22:15:03,012 (trainer:720) INFO: 12epoch:train:3801-4000batch: iter_time=2.176e-04, forward_time=0.138, uma_reduction=0.193, text_vs_uma=0.509, loss_ctc=8.468, loss=4.234, backward_time=0.187, optim_step_time=0.036, optim0_lr0=4.269e-04, train_time=0.902
[alab02] 2024-08-27 22:16:34,234 (trainer:720) INFO: 12epoch:train:4001-4200batch: iter_time=2.170e-04, forward_time=0.141, uma_reduction=0.191, text_vs_uma=0.497, loss_ctc=8.470, loss=4.235, backward_time=0.188, optim_step_time=0.037, optim0_lr0=4.264e-04, train_time=0.912
[alab02] 2024-08-27 22:18:03,507 (trainer:720) INFO: 12epoch:train:4201-4400batch: iter_time=2.051e-04, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.509, loss_ctc=8.496, loss=4.248, backward_time=0.184, optim_step_time=0.036, optim0_lr0=4.259e-04, train_time=0.892
[alab02] 2024-08-27 22:19:31,422 (trainer:720) INFO: 12epoch:train:4401-4600batch: iter_time=2.082e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.518, loss_ctc=9.318, loss=4.659, backward_time=0.176, optim_step_time=0.036, optim0_lr0=4.254e-04, train_time=0.879
[alab02] 2024-08-27 22:21:00,367 (trainer:720) INFO: 12epoch:train:4601-4800batch: iter_time=2.031e-04, forward_time=0.137, uma_reduction=0.190, text_vs_uma=0.501, loss_ctc=8.291, loss=4.146, backward_time=0.184, optim_step_time=0.035, optim0_lr0=4.249e-04, train_time=0.889
[alab02] 2024-08-27 22:22:31,525 (trainer:720) INFO: 12epoch:train:4801-5000batch: iter_time=2.101e-04, forward_time=0.140, uma_reduction=0.189, text_vs_uma=0.492, loss_ctc=8.283, loss=4.141, backward_time=0.190, optim_step_time=0.036, optim0_lr0=4.244e-04, train_time=0.911
[alab02] 2024-08-27 22:24:03,508 (trainer:720) INFO: 12epoch:train:5001-5200batch: iter_time=2.293e-04, forward_time=0.141, uma_reduction=0.189, text_vs_uma=0.505, loss_ctc=8.834, loss=4.417, backward_time=0.190, optim_step_time=0.038, optim0_lr0=4.239e-04, train_time=0.920
[alab02] 2024-08-27 22:25:30,712 (trainer:720) INFO: 12epoch:train:5201-5400batch: iter_time=2.005e-04, forward_time=0.134, uma_reduction=0.188, text_vs_uma=0.519, loss_ctc=8.947, loss=4.474, backward_time=0.176, optim_step_time=0.035, optim0_lr0=4.234e-04, train_time=0.872
[alab02] 2024-08-27 22:27:00,368 (trainer:720) INFO: 12epoch:train:5401-5600batch: iter_time=2.163e-04, forward_time=0.138, uma_reduction=0.188, text_vs_uma=0.501, loss_ctc=8.687, loss=4.344, backward_time=0.184, optim_step_time=0.036, optim0_lr0=4.229e-04, train_time=0.896
[alab02] 2024-08-27 22:28:30,034 (trainer:720) INFO: 12epoch:train:5601-5800batch: iter_time=1.854e-04, forward_time=0.138, uma_reduction=0.194, text_vs_uma=0.494, loss_ctc=7.777, loss=3.889, backward_time=0.186, optim_step_time=0.035, optim0_lr0=4.224e-04, train_time=0.896
[alab02] 2024-08-27 22:29:59,282 (trainer:720) INFO: 12epoch:train:5801-6000batch: iter_time=2.087e-04, forward_time=0.137, uma_reduction=0.194, text_vs_uma=0.482, loss_ctc=7.669, loss=3.835, backward_time=0.186, optim_step_time=0.036, optim0_lr0=4.219e-04, train_time=0.892
[alab02] 2024-08-27 22:31:30,615 (trainer:720) INFO: 12epoch:train:6001-6200batch: iter_time=2.163e-04, forward_time=0.141, uma_reduction=0.194, text_vs_uma=0.489, loss_ctc=8.316, loss=4.158, backward_time=0.188, optim_step_time=0.037, optim0_lr0=4.214e-04, train_time=0.913
[alab02] 2024-08-27 22:33:01,579 (trainer:720) INFO: 12epoch:train:6201-6400batch: iter_time=2.375e-04, forward_time=0.139, uma_reduction=0.192, text_vs_uma=0.510, loss_ctc=8.966, loss=4.483, backward_time=0.185, optim_step_time=0.036, optim0_lr0=4.209e-04, train_time=0.909
[alab02] 2024-08-27 22:34:34,014 (trainer:720) INFO: 12epoch:train:6401-6600batch: iter_time=2.697e-04, forward_time=0.142, uma_reduction=0.192, text_vs_uma=0.481, loss_ctc=8.044, loss=4.022, backward_time=0.193, optim_step_time=0.039, optim0_lr0=4.204e-04, train_time=0.924
[alab02] 2024-08-27 22:36:05,959 (trainer:720) INFO: 12epoch:train:6601-6800batch: iter_time=2.527e-04, forward_time=0.141, uma_reduction=0.189, text_vs_uma=0.514, loss_ctc=8.790, loss=4.395, backward_time=0.187, optim_step_time=0.039, optim0_lr0=4.199e-04, train_time=0.919
[alab02] 2024-08-27 22:37:37,346 (trainer:720) INFO: 12epoch:train:6801-7000batch: iter_time=2.625e-04, forward_time=0.141, uma_reduction=0.190, text_vs_uma=0.523, loss_ctc=9.089, loss=4.545, backward_time=0.187, optim_step_time=0.040, optim0_lr0=4.194e-04, train_time=0.914
[alab02] 2024-08-27 22:38:57,393 (trainer:338) INFO: 12epoch results: [train] iter_time=4.841e-04, forward_time=0.146, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=8.665, loss=4.332, backward_time=0.191, optim_step_time=0.044, optim0_lr0=4.279e-04, train_time=0.934, time=55 minutes and 30.15 seconds, total_count=85512, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.154, text_vs_uma=0.705, loss_ctc=6.057, cer_ctc=0.129, cer=0.129, loss=6.057, time=6.72 seconds, total_count=312, gpu_max_cached_mem_GB=35.900, [att_plot] time=15.58 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 22:39:03,414 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 22:39:03,420 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/2epoch.pth
[alab02] 2024-08-27 22:39:03,420 (trainer:272) INFO: 13/150epoch started. Estimated time to finish: 5 days, 14 hours and 40 minutes
[alab02] 2024-08-27 22:40:33,636 (trainer:720) INFO: 13epoch:train:1-200batch: iter_time=0.002, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.506, loss_ctc=8.429, loss=4.214, backward_time=0.182, optim_step_time=0.039, optim0_lr0=4.186e-04, train_time=0.902
[alab02] 2024-08-27 22:42:04,000 (trainer:720) INFO: 13epoch:train:201-400batch: iter_time=2.350e-04, forward_time=0.138, uma_reduction=0.187, text_vs_uma=0.507, loss_ctc=8.601, loss=4.300, backward_time=0.186, optim_step_time=0.037, optim0_lr0=4.181e-04, train_time=0.903
[alab02] 2024-08-27 22:43:33,198 (trainer:720) INFO: 13epoch:train:401-600batch: iter_time=2.485e-04, forward_time=0.136, uma_reduction=0.190, text_vs_uma=0.506, loss_ctc=8.685, loss=4.342, backward_time=0.181, optim_step_time=0.037, optim0_lr0=4.176e-04, train_time=0.892
[alab02] 2024-08-27 22:45:04,493 (trainer:720) INFO: 13epoch:train:601-800batch: iter_time=2.592e-04, forward_time=0.141, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=8.317, loss=4.159, backward_time=0.189, optim_step_time=0.038, optim0_lr0=4.171e-04, train_time=0.913
[alab02] 2024-08-27 22:46:36,296 (trainer:720) INFO: 13epoch:train:801-1000batch: iter_time=2.517e-04, forward_time=0.140, uma_reduction=0.190, text_vs_uma=0.491, loss_ctc=8.514, loss=4.257, backward_time=0.188, optim_step_time=0.036, optim0_lr0=4.166e-04, train_time=0.918
[alab02] 2024-08-27 22:48:05,534 (trainer:720) INFO: 13epoch:train:1001-1200batch: iter_time=2.606e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.503, loss_ctc=8.822, loss=4.411, backward_time=0.181, optim_step_time=0.038, optim0_lr0=4.161e-04, train_time=0.892
[alab02] 2024-08-27 22:49:34,591 (trainer:720) INFO: 13epoch:train:1201-1400batch: iter_time=2.793e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=7.753, loss=3.877, backward_time=0.186, optim_step_time=0.037, optim0_lr0=4.157e-04, train_time=0.890
[alab02] 2024-08-27 22:51:03,608 (trainer:720) INFO: 13epoch:train:1401-1600batch: iter_time=2.283e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.503, loss_ctc=8.223, loss=4.111, backward_time=0.180, optim_step_time=0.039, optim0_lr0=4.152e-04, train_time=0.890
[alab02] 2024-08-27 22:52:32,666 (trainer:720) INFO: 13epoch:train:1601-1800batch: iter_time=2.298e-04, forward_time=0.136, uma_reduction=0.190, text_vs_uma=0.497, loss_ctc=8.326, loss=4.163, backward_time=0.184, optim_step_time=0.037, optim0_lr0=4.147e-04, train_time=0.890
[alab02] 2024-08-27 22:54:03,547 (trainer:720) INFO: 13epoch:train:1801-2000batch: iter_time=2.575e-04, forward_time=0.138, uma_reduction=0.191, text_vs_uma=0.503, loss_ctc=8.341, loss=4.170, backward_time=0.186, optim_step_time=0.038, optim0_lr0=4.142e-04, train_time=0.909
[alab02] 2024-08-27 22:55:33,711 (trainer:720) INFO: 13epoch:train:2001-2200batch: iter_time=2.569e-04, forward_time=0.138, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=7.960, loss=3.980, backward_time=0.186, optim_step_time=0.038, optim0_lr0=4.138e-04, train_time=0.901
[alab02] 2024-08-27 22:57:01,650 (trainer:720) INFO: 13epoch:train:2201-2400batch: iter_time=2.276e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.510, loss_ctc=8.548, loss=4.274, backward_time=0.177, optim_step_time=0.037, optim0_lr0=4.133e-04, train_time=0.879
[alab02] 2024-08-27 22:58:31,695 (trainer:720) INFO: 13epoch:train:2401-2600batch: iter_time=2.237e-04, forward_time=0.137, uma_reduction=0.193, text_vs_uma=0.479, loss_ctc=7.416, loss=3.708, backward_time=0.190, optim_step_time=0.036, optim0_lr0=4.128e-04, train_time=0.900
[alab02] 2024-08-27 22:59:59,873 (trainer:720) INFO: 13epoch:train:2601-2800batch: iter_time=2.217e-04, forward_time=0.134, uma_reduction=0.188, text_vs_uma=0.513, loss_ctc=8.634, loss=4.317, backward_time=0.180, optim_step_time=0.035, optim0_lr0=4.124e-04, train_time=0.882
[alab02] 2024-08-27 23:01:27,603 (trainer:720) INFO: 13epoch:train:2801-3000batch: iter_time=2.017e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=8.225, loss=4.112, backward_time=0.180, optim_step_time=0.035, optim0_lr0=4.119e-04, train_time=0.877
[alab02] 2024-08-27 23:02:57,741 (trainer:720) INFO: 13epoch:train:3001-3200batch: iter_time=2.097e-04, forward_time=0.137, uma_reduction=0.188, text_vs_uma=0.497, loss_ctc=7.962, loss=3.981, backward_time=0.188, optim_step_time=0.034, optim0_lr0=4.114e-04, train_time=0.901
[alab02] 2024-08-27 23:04:28,580 (trainer:720) INFO: 13epoch:train:3201-3400batch: iter_time=2.023e-04, forward_time=0.139, uma_reduction=0.192, text_vs_uma=0.504, loss_ctc=8.096, loss=4.048, backward_time=0.188, optim_step_time=0.036, optim0_lr0=4.110e-04, train_time=0.908
[alab02] 2024-08-27 23:05:57,040 (trainer:720) INFO: 13epoch:train:3401-3600batch: iter_time=1.913e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.502, loss_ctc=8.068, loss=4.034, backward_time=0.181, optim_step_time=0.035, optim0_lr0=4.105e-04, train_time=0.884
[alab02] 2024-08-27 23:07:23,481 (trainer:720) INFO: 13epoch:train:3601-3800batch: iter_time=1.879e-04, forward_time=0.131, uma_reduction=0.194, text_vs_uma=0.495, loss_ctc=7.666, loss=3.833, backward_time=0.180, optim_step_time=0.035, optim0_lr0=4.100e-04, train_time=0.864
[alab02] 2024-08-27 23:08:52,396 (trainer:720) INFO: 13epoch:train:3801-4000batch: iter_time=2.105e-04, forward_time=0.134, uma_reduction=0.190, text_vs_uma=0.507, loss_ctc=8.269, loss=4.135, backward_time=0.183, optim_step_time=0.037, optim0_lr0=4.096e-04, train_time=0.889
[alab02] 2024-08-27 23:10:21,305 (trainer:720) INFO: 13epoch:train:4001-4200batch: iter_time=1.981e-04, forward_time=0.135, uma_reduction=0.190, text_vs_uma=0.498, loss_ctc=7.862, loss=3.931, backward_time=0.183, optim_step_time=0.035, optim0_lr0=4.091e-04, train_time=0.889
[alab02] 2024-08-27 23:11:51,398 (trainer:720) INFO: 13epoch:train:4201-4400batch: iter_time=2.113e-04, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.508, loss_ctc=7.935, loss=3.968, backward_time=0.189, optim_step_time=0.036, optim0_lr0=4.087e-04, train_time=0.901
[alab02] 2024-08-27 23:13:20,178 (trainer:720) INFO: 13epoch:train:4401-4600batch: iter_time=2.042e-04, forward_time=0.136, uma_reduction=0.190, text_vs_uma=0.495, loss_ctc=7.834, loss=3.917, backward_time=0.183, optim_step_time=0.035, optim0_lr0=4.082e-04, train_time=0.888
[alab02] 2024-08-27 23:14:48,278 (trainer:720) INFO: 13epoch:train:4601-4800batch: iter_time=2.114e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.498, loss_ctc=8.023, loss=4.012, backward_time=0.181, optim_step_time=0.035, optim0_lr0=4.078e-04, train_time=0.881
[alab02] 2024-08-27 23:16:18,114 (trainer:720) INFO: 13epoch:train:4801-5000batch: iter_time=2.043e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.497, loss_ctc=7.768, loss=3.884, backward_time=0.187, optim_step_time=0.036, optim0_lr0=4.073e-04, train_time=0.898
[alab02] 2024-08-27 23:17:46,523 (trainer:720) INFO: 13epoch:train:5001-5200batch: iter_time=2.101e-04, forward_time=0.136, uma_reduction=0.193, text_vs_uma=0.513, loss_ctc=8.122, loss=4.061, backward_time=0.182, optim_step_time=0.035, optim0_lr0=4.069e-04, train_time=0.884
[alab02] 2024-08-27 23:19:18,746 (trainer:720) INFO: 13epoch:train:5201-5400batch: iter_time=1.981e-04, forward_time=0.141, uma_reduction=0.192, text_vs_uma=0.503, loss_ctc=8.167, loss=4.083, backward_time=0.193, optim_step_time=0.036, optim0_lr0=4.064e-04, train_time=0.922
[alab02] 2024-08-27 23:20:51,163 (trainer:720) INFO: 13epoch:train:5401-5600batch: iter_time=2.092e-04, forward_time=0.141, uma_reduction=0.190, text_vs_uma=0.505, loss_ctc=8.343, loss=4.172, backward_time=0.193, optim_step_time=0.036, optim0_lr0=4.060e-04, train_time=0.924
[alab02] 2024-08-27 23:22:20,016 (trainer:720) INFO: 13epoch:train:5601-5800batch: iter_time=2.080e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.500, loss_ctc=8.086, loss=4.043, backward_time=0.182, optim_step_time=0.036, optim0_lr0=4.055e-04, train_time=0.888
[alab02] 2024-08-27 23:23:49,497 (trainer:720) INFO: 13epoch:train:5801-6000batch: iter_time=1.833e-04, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=8.247, loss=4.124, backward_time=0.184, optim_step_time=0.035, optim0_lr0=4.051e-04, train_time=0.895
[alab02] 2024-08-27 23:25:18,296 (trainer:720) INFO: 13epoch:train:6001-6200batch: iter_time=1.979e-04, forward_time=0.136, uma_reduction=0.190, text_vs_uma=0.503, loss_ctc=8.188, loss=4.094, backward_time=0.181, optim_step_time=0.036, optim0_lr0=4.046e-04, train_time=0.888
[alab02] 2024-08-27 23:26:45,495 (trainer:720) INFO: 13epoch:train:6201-6400batch: iter_time=1.961e-04, forward_time=0.133, uma_reduction=0.190, text_vs_uma=0.511, loss_ctc=8.084, loss=4.042, backward_time=0.180, optim_step_time=0.035, optim0_lr0=4.042e-04, train_time=0.872
[alab02] 2024-08-27 23:28:14,980 (trainer:720) INFO: 13epoch:train:6401-6600batch: iter_time=1.938e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.510, loss_ctc=8.338, loss=4.169, backward_time=0.184, optim_step_time=0.035, optim0_lr0=4.038e-04, train_time=0.895
[alab02] 2024-08-27 23:29:43,601 (trainer:720) INFO: 13epoch:train:6601-6800batch: iter_time=2.025e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.507, loss_ctc=8.170, loss=4.085, backward_time=0.183, optim_step_time=0.036, optim0_lr0=4.033e-04, train_time=0.886
[alab02] 2024-08-27 23:31:11,590 (trainer:720) INFO: 13epoch:train:6801-7000batch: iter_time=1.991e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.483, loss_ctc=7.656, loss=3.828, backward_time=0.182, optim_step_time=0.036, optim0_lr0=4.029e-04, train_time=0.880
[alab02] 2024-08-27 23:32:31,441 (trainer:338) INFO: 13epoch results: [train] iter_time=2.786e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.502, loss_ctc=8.150, loss=4.075, backward_time=0.184, optim_step_time=0.036, optim0_lr0=4.104e-04, train_time=0.894, time=53 minutes and 6.23 seconds, total_count=92638, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.153, text_vs_uma=0.710, loss_ctc=5.821, cer_ctc=0.126, cer=0.126, loss=5.821, time=6.66 seconds, total_count=338, gpu_max_cached_mem_GB=35.900, [att_plot] time=15.13 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-27 23:32:38,996 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-27 23:32:39,002 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/3epoch.pth
[alab02] 2024-08-27 23:32:39,002 (trainer:272) INFO: 14/150epoch started. Estimated time to finish: 5 days, 12 hours and 49 minutes
[alab02] 2024-08-27 23:34:10,479 (trainer:720) INFO: 14epoch:train:1-200batch: iter_time=0.003, forward_time=0.138, uma_reduction=0.190, text_vs_uma=0.506, loss_ctc=7.673, loss=3.836, backward_time=0.185, optim_step_time=0.036, optim0_lr0=4.022e-04, train_time=0.914
[alab02] 2024-08-27 23:35:39,458 (trainer:720) INFO: 14epoch:train:201-400batch: iter_time=2.306e-04, forward_time=0.136, uma_reduction=0.192, text_vs_uma=0.504, loss_ctc=7.731, loss=3.866, backward_time=0.185, optim_step_time=0.037, optim0_lr0=4.017e-04, train_time=0.890
[alab02] 2024-08-27 23:37:07,924 (trainer:720) INFO: 14epoch:train:401-600batch: iter_time=2.183e-04, forward_time=0.135, uma_reduction=0.189, text_vs_uma=0.506, loss_ctc=8.413, loss=4.207, backward_time=0.180, optim_step_time=0.035, optim0_lr0=4.013e-04, train_time=0.884
[alab02] 2024-08-27 23:38:37,017 (trainer:720) INFO: 14epoch:train:601-800batch: iter_time=2.292e-04, forward_time=0.137, uma_reduction=0.190, text_vs_uma=0.502, loss_ctc=7.482, loss=3.741, backward_time=0.184, optim_step_time=0.036, optim0_lr0=4.009e-04, train_time=0.891
[alab02] 2024-08-27 23:40:04,924 (trainer:720) INFO: 14epoch:train:801-1000batch: iter_time=2.256e-04, forward_time=0.135, uma_reduction=0.189, text_vs_uma=0.501, loss_ctc=7.689, loss=3.844, backward_time=0.180, optim_step_time=0.035, optim0_lr0=4.004e-04, train_time=0.879
[alab02] 2024-08-27 23:41:32,223 (trainer:720) INFO: 14epoch:train:1001-1200batch: iter_time=2.152e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.502, loss_ctc=7.765, loss=3.882, backward_time=0.178, optim_step_time=0.036, optim0_lr0=4.000e-04, train_time=0.873
[alab02] 2024-08-27 23:43:01,680 (trainer:720) INFO: 14epoch:train:1201-1400batch: iter_time=2.196e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.503, loss_ctc=7.931, loss=3.966, backward_time=0.183, optim_step_time=0.036, optim0_lr0=3.996e-04, train_time=0.894
[alab02] 2024-08-27 23:44:30,867 (trainer:720) INFO: 14epoch:train:1401-1600batch: iter_time=2.192e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.512, loss_ctc=8.174, loss=4.087, backward_time=0.183, optim_step_time=0.036, optim0_lr0=3.992e-04, train_time=0.892
[alab02] 2024-08-27 23:45:59,153 (trainer:720) INFO: 14epoch:train:1601-1800batch: iter_time=2.292e-04, forward_time=0.134, uma_reduction=0.190, text_vs_uma=0.512, loss_ctc=8.100, loss=4.050, backward_time=0.182, optim_step_time=0.036, optim0_lr0=3.987e-04, train_time=0.883
[alab02] 2024-08-27 23:47:29,149 (trainer:720) INFO: 14epoch:train:1801-2000batch: iter_time=2.202e-04, forward_time=0.137, uma_reduction=0.188, text_vs_uma=0.500, loss_ctc=8.211, loss=4.106, backward_time=0.185, optim_step_time=0.036, optim0_lr0=3.983e-04, train_time=0.900
[alab02] 2024-08-27 23:48:58,324 (trainer:720) INFO: 14epoch:train:2001-2200batch: iter_time=3.614e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=8.011, loss=4.005, backward_time=0.183, optim_step_time=0.038, optim0_lr0=3.979e-04, train_time=0.891
[alab02] 2024-08-27 23:50:27,233 (trainer:720) INFO: 14epoch:train:2201-2400batch: iter_time=2.247e-04, forward_time=0.136, uma_reduction=0.189, text_vs_uma=0.515, loss_ctc=8.519, loss=4.259, backward_time=0.179, optim_step_time=0.036, optim0_lr0=3.975e-04, train_time=0.889
[alab02] 2024-08-27 23:51:55,925 (trainer:720) INFO: 14epoch:train:2401-2600batch: iter_time=3.101e-04, forward_time=0.135, uma_reduction=0.193, text_vs_uma=0.501, loss_ctc=7.477, loss=3.739, backward_time=0.185, optim_step_time=0.036, optim0_lr0=3.971e-04, train_time=0.887
[alab02] 2024-08-27 23:53:24,819 (trainer:720) INFO: 14epoch:train:2601-2800batch: iter_time=2.073e-04, forward_time=0.135, uma_reduction=0.192, text_vs_uma=0.488, loss_ctc=8.008, loss=4.004, backward_time=0.182, optim_step_time=0.035, optim0_lr0=3.966e-04, train_time=0.889
[alab02] 2024-08-27 23:54:52,332 (trainer:720) INFO: 14epoch:train:2801-3000batch: iter_time=1.995e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.486, loss_ctc=7.345, loss=3.672, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.962e-04, train_time=0.875
[alab02] 2024-08-27 23:56:20,676 (trainer:720) INFO: 14epoch:train:3001-3200batch: iter_time=1.892e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.511, loss_ctc=8.363, loss=4.182, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.958e-04, train_time=0.883
[alab02] 2024-08-27 23:57:49,230 (trainer:720) INFO: 14epoch:train:3201-3400batch: iter_time=1.873e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.483, loss_ctc=7.344, loss=3.672, backward_time=0.186, optim_step_time=0.033, optim0_lr0=3.954e-04, train_time=0.885
[alab02] 2024-08-27 23:59:18,325 (trainer:720) INFO: 14epoch:train:3401-3600batch: iter_time=1.819e-04, forward_time=0.135, uma_reduction=0.193, text_vs_uma=0.484, loss_ctc=7.681, loss=3.841, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.950e-04, train_time=0.891
[alab02] 2024-08-28 00:00:44,531 (trainer:720) INFO: 14epoch:train:3601-3800batch: iter_time=1.884e-04, forward_time=0.130, uma_reduction=0.193, text_vs_uma=0.494, loss_ctc=7.745, loss=3.873, backward_time=0.177, optim_step_time=0.034, optim0_lr0=3.946e-04, train_time=0.862
[alab02] 2024-08-28 00:02:10,929 (trainer:720) INFO: 14epoch:train:3801-4000batch: iter_time=1.846e-04, forward_time=0.130, uma_reduction=0.193, text_vs_uma=0.510, loss_ctc=8.268, loss=4.134, backward_time=0.176, optim_step_time=0.033, optim0_lr0=3.942e-04, train_time=0.864
[alab02] 2024-08-28 00:03:39,284 (trainer:720) INFO: 14epoch:train:4001-4200batch: iter_time=1.787e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.508, loss_ctc=8.033, loss=4.016, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.938e-04, train_time=0.883
[alab02] 2024-08-28 00:05:06,461 (trainer:720) INFO: 14epoch:train:4201-4400batch: iter_time=1.889e-04, forward_time=0.132, uma_reduction=0.195, text_vs_uma=0.491, loss_ctc=7.738, loss=3.869, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.934e-04, train_time=0.872
[alab02] 2024-08-28 00:06:35,078 (trainer:720) INFO: 14epoch:train:4401-4600batch: iter_time=1.743e-04, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.505, loss_ctc=8.494, loss=4.247, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.930e-04, train_time=0.886
[alab02] 2024-08-28 00:08:01,421 (trainer:720) INFO: 14epoch:train:4601-4800batch: iter_time=1.926e-04, forward_time=0.130, uma_reduction=0.192, text_vs_uma=0.491, loss_ctc=7.398, loss=3.699, backward_time=0.180, optim_step_time=0.035, optim0_lr0=3.926e-04, train_time=0.863
[alab02] 2024-08-28 00:09:30,193 (trainer:720) INFO: 14epoch:train:4801-5000batch: iter_time=2.131e-04, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.498, loss_ctc=7.985, loss=3.992, backward_time=0.182, optim_step_time=0.035, optim0_lr0=3.921e-04, train_time=0.887
[alab02] 2024-08-28 00:11:00,861 (trainer:720) INFO: 14epoch:train:5001-5200batch: iter_time=2.562e-04, forward_time=0.139, uma_reduction=0.192, text_vs_uma=0.493, loss_ctc=8.106, loss=4.053, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.917e-04, train_time=0.906
[alab02] 2024-08-28 00:12:31,866 (trainer:720) INFO: 14epoch:train:5201-5400batch: iter_time=2.405e-04, forward_time=0.141, uma_reduction=0.194, text_vs_uma=0.505, loss_ctc=8.178, loss=4.089, backward_time=0.185, optim_step_time=0.039, optim0_lr0=3.913e-04, train_time=0.910
[alab02] 2024-08-28 00:14:01,126 (trainer:720) INFO: 14epoch:train:5401-5600batch: iter_time=2.465e-04, forward_time=0.138, uma_reduction=0.192, text_vs_uma=0.493, loss_ctc=7.631, loss=3.815, backward_time=0.183, optim_step_time=0.037, optim0_lr0=3.909e-04, train_time=0.892
[alab02] 2024-08-28 00:15:31,976 (trainer:720) INFO: 14epoch:train:5601-5800batch: iter_time=2.257e-04, forward_time=0.139, uma_reduction=0.191, text_vs_uma=0.507, loss_ctc=8.202, loss=4.101, backward_time=0.187, optim_step_time=0.037, optim0_lr0=3.906e-04, train_time=0.908
[alab02] 2024-08-28 00:17:01,110 (trainer:720) INFO: 14epoch:train:5801-6000batch: iter_time=2.682e-04, forward_time=0.136, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=7.689, loss=3.844, backward_time=0.184, optim_step_time=0.037, optim0_lr0=3.902e-04, train_time=0.891
[alab02] 2024-08-28 00:18:31,446 (trainer:720) INFO: 14epoch:train:6001-6200batch: iter_time=2.579e-04, forward_time=0.138, uma_reduction=0.190, text_vs_uma=0.511, loss_ctc=8.122, loss=4.061, backward_time=0.184, optim_step_time=0.039, optim0_lr0=3.898e-04, train_time=0.903
[alab02] 2024-08-28 00:20:00,671 (trainer:720) INFO: 14epoch:train:6201-6400batch: iter_time=2.226e-04, forward_time=0.136, uma_reduction=0.192, text_vs_uma=0.493, loss_ctc=7.526, loss=3.763, backward_time=0.183, optim_step_time=0.038, optim0_lr0=3.894e-04, train_time=0.892
[alab02] 2024-08-28 00:21:30,681 (trainer:720) INFO: 14epoch:train:6401-6600batch: iter_time=2.389e-04, forward_time=0.138, uma_reduction=0.194, text_vs_uma=0.492, loss_ctc=7.580, loss=3.790, backward_time=0.185, optim_step_time=0.036, optim0_lr0=3.890e-04, train_time=0.900
[alab02] 2024-08-28 00:22:59,033 (trainer:720) INFO: 14epoch:train:6601-6800batch: iter_time=2.207e-04, forward_time=0.135, uma_reduction=0.190, text_vs_uma=0.505, loss_ctc=7.937, loss=3.968, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.886e-04, train_time=0.883
[alab02] 2024-08-28 00:24:28,198 (trainer:720) INFO: 14epoch:train:6801-7000batch: iter_time=2.057e-04, forward_time=0.136, uma_reduction=0.188, text_vs_uma=0.517, loss_ctc=8.342, loss=4.171, backward_time=0.181, optim_step_time=0.035, optim0_lr0=3.882e-04, train_time=0.891
[alab02] 2024-08-28 00:25:45,580 (trainer:338) INFO: 14epoch results: [train] iter_time=3.050e-04, forward_time=0.135, uma_reduction=0.192, text_vs_uma=0.501, loss_ctc=7.903, loss=3.952, backward_time=0.183, optim_step_time=0.036, optim0_lr0=3.949e-04, train_time=0.888, time=52 minutes and 45.83 seconds, total_count=99764, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.156, text_vs_uma=0.695, loss_ctc=6.230, cer_ctc=0.132, cer=0.132, loss=6.230, time=6.48 seconds, total_count=364, gpu_max_cached_mem_GB=35.900, [att_plot] time=14.26 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-28 00:25:54,911 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 00:25:54,917 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/4epoch.pth
[alab02] 2024-08-28 00:25:54,918 (trainer:272) INFO: 15/150epoch started. Estimated time to finish: 5 days, 11 hours and 3 minutes
[alab02] 2024-08-28 00:27:25,135 (trainer:720) INFO: 15epoch:train:1-200batch: iter_time=0.002, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=7.812, loss=3.906, backward_time=0.182, optim_step_time=0.037, optim0_lr0=3.876e-04, train_time=0.902
[alab02] 2024-08-28 00:28:54,956 (trainer:720) INFO: 15epoch:train:201-400batch: iter_time=2.301e-04, forward_time=0.138, uma_reduction=0.188, text_vs_uma=0.517, loss_ctc=7.863, loss=3.932, backward_time=0.188, optim_step_time=0.036, optim0_lr0=3.872e-04, train_time=0.898
[alab02] 2024-08-28 00:30:24,805 (trainer:720) INFO: 15epoch:train:401-600batch: iter_time=2.260e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=7.982, loss=3.991, backward_time=0.186, optim_step_time=0.036, optim0_lr0=3.868e-04, train_time=0.898
[alab02] 2024-08-28 00:31:54,282 (trainer:720) INFO: 15epoch:train:601-800batch: iter_time=2.503e-04, forward_time=0.138, uma_reduction=0.192, text_vs_uma=0.490, loss_ctc=7.508, loss=3.754, backward_time=0.185, optim_step_time=0.035, optim0_lr0=3.864e-04, train_time=0.895
[alab02] 2024-08-28 00:33:22,215 (trainer:720) INFO: 15epoch:train:801-1000batch: iter_time=2.112e-04, forward_time=0.133, uma_reduction=0.193, text_vs_uma=0.501, loss_ctc=8.253, loss=4.127, backward_time=0.178, optim_step_time=0.035, optim0_lr0=3.860e-04, train_time=0.879
[alab02] 2024-08-28 00:34:51,030 (trainer:720) INFO: 15epoch:train:1001-1200batch: iter_time=2.520e-04, forward_time=0.135, uma_reduction=0.193, text_vs_uma=0.481, loss_ctc=6.873, loss=3.436, backward_time=0.186, optim_step_time=0.035, optim0_lr0=3.856e-04, train_time=0.888
[alab02] 2024-08-28 00:36:19,438 (trainer:720) INFO: 15epoch:train:1201-1400batch: iter_time=2.189e-04, forward_time=0.136, uma_reduction=0.190, text_vs_uma=0.509, loss_ctc=7.815, loss=3.907, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.852e-04, train_time=0.884
[alab02] 2024-08-28 00:37:49,153 (trainer:720) INFO: 15epoch:train:1401-1600batch: iter_time=2.149e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.517, loss_ctc=8.280, loss=4.140, backward_time=0.183, optim_step_time=0.036, optim0_lr0=3.849e-04, train_time=0.897
[alab02] 2024-08-28 00:39:20,915 (trainer:720) INFO: 15epoch:train:1601-1800batch: iter_time=2.288e-04, forward_time=0.141, uma_reduction=0.190, text_vs_uma=0.502, loss_ctc=8.723, loss=4.361, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.845e-04, train_time=0.917
[alab02] 2024-08-28 00:40:52,618 (trainer:720) INFO: 15epoch:train:1801-2000batch: iter_time=2.258e-04, forward_time=0.141, uma_reduction=0.193, text_vs_uma=0.504, loss_ctc=7.868, loss=3.934, backward_time=0.188, optim_step_time=0.038, optim0_lr0=3.841e-04, train_time=0.917
[alab02] 2024-08-28 00:42:22,393 (trainer:720) INFO: 15epoch:train:2001-2200batch: iter_time=2.329e-04, forward_time=0.137, uma_reduction=0.194, text_vs_uma=0.503, loss_ctc=7.766, loss=3.883, backward_time=0.186, optim_step_time=0.037, optim0_lr0=3.837e-04, train_time=0.897
[alab02] 2024-08-28 00:43:52,241 (trainer:720) INFO: 15epoch:train:2201-2400batch: iter_time=2.093e-04, forward_time=0.138, uma_reduction=0.194, text_vs_uma=0.494, loss_ctc=7.947, loss=3.973, backward_time=0.184, optim_step_time=0.036, optim0_lr0=3.834e-04, train_time=0.898
[alab02] 2024-08-28 00:45:22,558 (trainer:720) INFO: 15epoch:train:2401-2600batch: iter_time=2.174e-04, forward_time=0.139, uma_reduction=0.196, text_vs_uma=0.497, loss_ctc=7.746, loss=3.873, backward_time=0.184, optim_step_time=0.037, optim0_lr0=3.830e-04, train_time=0.903
[alab02] 2024-08-28 00:46:52,975 (trainer:720) INFO: 15epoch:train:2601-2800batch: iter_time=2.220e-04, forward_time=0.138, uma_reduction=0.195, text_vs_uma=0.484, loss_ctc=7.034, loss=3.517, backward_time=0.189, optim_step_time=0.037, optim0_lr0=3.826e-04, train_time=0.904
[alab02] 2024-08-28 00:48:22,249 (trainer:720) INFO: 15epoch:train:2801-3000batch: iter_time=2.143e-04, forward_time=0.136, uma_reduction=0.195, text_vs_uma=0.493, loss_ctc=8.181, loss=4.091, backward_time=0.182, optim_step_time=0.035, optim0_lr0=3.822e-04, train_time=0.892
[alab02] 2024-08-28 00:49:52,656 (trainer:720) INFO: 15epoch:train:3001-3200batch: iter_time=2.134e-04, forward_time=0.139, uma_reduction=0.197, text_vs_uma=0.492, loss_ctc=7.496, loss=3.748, backward_time=0.187, optim_step_time=0.036, optim0_lr0=3.819e-04, train_time=0.904
[alab02] 2024-08-28 00:51:23,796 (trainer:720) INFO: 15epoch:train:3201-3400batch: iter_time=3.046e-04, forward_time=0.140, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=7.522, loss=3.761, backward_time=0.187, optim_step_time=0.037, optim0_lr0=3.815e-04, train_time=0.911
[alab02] 2024-08-28 00:52:54,761 (trainer:720) INFO: 15epoch:train:3401-3600batch: iter_time=2.248e-04, forward_time=0.140, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=7.018, loss=3.509, backward_time=0.191, optim_step_time=0.036, optim0_lr0=3.811e-04, train_time=0.909
[alab02] 2024-08-28 00:54:23,980 (trainer:720) INFO: 15epoch:train:3601-3800batch: iter_time=2.160e-04, forward_time=0.137, uma_reduction=0.196, text_vs_uma=0.478, loss_ctc=7.153, loss=3.577, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.808e-04, train_time=0.892
[alab02] 2024-08-28 00:55:53,943 (trainer:720) INFO: 15epoch:train:3801-4000batch: iter_time=2.278e-04, forward_time=0.136, uma_reduction=0.195, text_vs_uma=0.492, loss_ctc=7.556, loss=3.778, backward_time=0.186, optim_step_time=0.036, optim0_lr0=3.804e-04, train_time=0.899
[alab02] 2024-08-28 00:57:23,922 (trainer:720) INFO: 15epoch:train:4001-4200batch: iter_time=2.167e-04, forward_time=0.138, uma_reduction=0.196, text_vs_uma=0.493, loss_ctc=7.451, loss=3.725, backward_time=0.186, optim_step_time=0.037, optim0_lr0=3.800e-04, train_time=0.900
[alab02] 2024-08-28 00:58:52,990 (trainer:720) INFO: 15epoch:train:4201-4400batch: iter_time=2.234e-04, forward_time=0.136, uma_reduction=0.194, text_vs_uma=0.490, loss_ctc=7.426, loss=3.713, backward_time=0.183, optim_step_time=0.035, optim0_lr0=3.797e-04, train_time=0.890
[alab02] 2024-08-28 01:00:25,183 (trainer:720) INFO: 15epoch:train:4401-4600batch: iter_time=2.573e-04, forward_time=0.140, uma_reduction=0.194, text_vs_uma=0.501, loss_ctc=7.654, loss=3.827, backward_time=0.189, optim_step_time=0.039, optim0_lr0=3.793e-04, train_time=0.922
[alab02] 2024-08-28 01:01:53,324 (trainer:720) INFO: 15epoch:train:4601-4800batch: iter_time=2.370e-04, forward_time=0.134, uma_reduction=0.193, text_vs_uma=0.498, loss_ctc=7.379, loss=3.689, backward_time=0.181, optim_step_time=0.037, optim0_lr0=3.789e-04, train_time=0.881
[alab02] 2024-08-28 01:03:23,773 (trainer:720) INFO: 15epoch:train:4801-5000batch: iter_time=2.344e-04, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.492, loss_ctc=7.800, loss=3.900, backward_time=0.184, optim_step_time=0.037, optim0_lr0=3.786e-04, train_time=0.904
[alab02] 2024-08-28 01:04:51,071 (trainer:720) INFO: 15epoch:train:5001-5200batch: iter_time=2.046e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.496, loss_ctc=7.493, loss=3.747, backward_time=0.179, optim_step_time=0.036, optim0_lr0=3.782e-04, train_time=0.873
[alab02] 2024-08-28 01:06:18,880 (trainer:720) INFO: 15epoch:train:5201-5400batch: iter_time=2.135e-04, forward_time=0.134, uma_reduction=0.195, text_vs_uma=0.487, loss_ctc=7.171, loss=3.586, backward_time=0.183, optim_step_time=0.036, optim0_lr0=3.778e-04, train_time=0.878
[alab02] 2024-08-28 01:07:47,273 (trainer:720) INFO: 15epoch:train:5401-5600batch: iter_time=0.004, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.499, loss_ctc=7.317, loss=3.659, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.775e-04, train_time=0.884
[alab02] 2024-08-28 01:09:17,360 (trainer:720) INFO: 15epoch:train:5601-5800batch: iter_time=1.958e-04, forward_time=0.136, uma_reduction=0.193, text_vs_uma=0.517, loss_ctc=7.975, loss=3.988, backward_time=0.185, optim_step_time=0.035, optim0_lr0=3.771e-04, train_time=0.901
[alab02] 2024-08-28 01:10:45,475 (trainer:720) INFO: 15epoch:train:5801-6000batch: iter_time=2.569e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.495, loss_ctc=7.871, loss=3.936, backward_time=0.179, optim_step_time=0.036, optim0_lr0=3.768e-04, train_time=0.881
[alab02] 2024-08-28 01:12:16,330 (trainer:720) INFO: 15epoch:train:6001-6200batch: iter_time=2.160e-04, forward_time=0.140, uma_reduction=0.196, text_vs_uma=0.485, loss_ctc=7.344, loss=3.672, backward_time=0.188, optim_step_time=0.037, optim0_lr0=3.764e-04, train_time=0.908
[alab02] 2024-08-28 01:13:46,233 (trainer:720) INFO: 15epoch:train:6201-6400batch: iter_time=2.256e-04, forward_time=0.136, uma_reduction=0.194, text_vs_uma=0.504, loss_ctc=7.727, loss=3.864, backward_time=0.187, optim_step_time=0.035, optim0_lr0=3.761e-04, train_time=0.899
[alab02] 2024-08-28 01:15:15,899 (trainer:720) INFO: 15epoch:train:6401-6600batch: iter_time=2.754e-04, forward_time=0.136, uma_reduction=0.193, text_vs_uma=0.506, loss_ctc=7.796, loss=3.898, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.757e-04, train_time=0.896
[alab02] 2024-08-28 01:16:44,107 (trainer:720) INFO: 15epoch:train:6601-6800batch: iter_time=1.944e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.510, loss_ctc=7.340, loss=3.670, backward_time=0.183, optim_step_time=0.034, optim0_lr0=3.754e-04, train_time=0.882
[alab02] 2024-08-28 01:18:11,846 (trainer:720) INFO: 15epoch:train:6801-7000batch: iter_time=2.162e-04, forward_time=0.135, uma_reduction=0.190, text_vs_uma=0.498, loss_ctc=7.448, loss=3.724, backward_time=0.180, optim_step_time=0.036, optim0_lr0=3.750e-04, train_time=0.877
[alab02] 2024-08-28 01:19:28,402 (trainer:338) INFO: 15epoch results: [train] iter_time=3.836e-04, forward_time=0.137, uma_reduction=0.193, text_vs_uma=0.497, loss_ctc=7.638, loss=3.819, backward_time=0.184, optim_step_time=0.036, optim0_lr0=3.811e-04, train_time=0.896, time=53 minutes and 12.9 seconds, total_count=106890, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.157, text_vs_uma=0.692, loss_ctc=5.717, cer_ctc=0.120, cer=0.120, loss=5.717, time=6.47 seconds, total_count=390, gpu_max_cached_mem_GB=35.900, [att_plot] time=14.11 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-28 01:19:34,365 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 01:19:34,371 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/6epoch.pth
[alab02] 2024-08-28 01:19:34,372 (trainer:272) INFO: 16/150epoch started. Estimated time to finish: 5 days, 9 hours and 28 minutes
[alab02] 2024-08-28 01:21:03,990 (trainer:720) INFO: 16epoch:train:1-200batch: iter_time=0.003, forward_time=0.138, uma_reduction=0.190, text_vs_uma=0.494, loss_ctc=7.108, loss=3.554, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.744e-04, train_time=0.896
[alab02] 2024-08-28 01:22:33,414 (trainer:720) INFO: 16epoch:train:201-400batch: iter_time=2.321e-04, forward_time=0.138, uma_reduction=0.191, text_vs_uma=0.516, loss_ctc=7.766, loss=3.883, backward_time=0.181, optim_step_time=0.037, optim0_lr0=3.741e-04, train_time=0.894
[alab02] 2024-08-28 01:24:04,980 (trainer:720) INFO: 16epoch:train:401-600batch: iter_time=2.361e-04, forward_time=0.141, uma_reduction=0.189, text_vs_uma=0.503, loss_ctc=7.348, loss=3.674, backward_time=0.187, optim_step_time=0.037, optim0_lr0=3.737e-04, train_time=0.915
[alab02] 2024-08-28 01:25:33,515 (trainer:720) INFO: 16epoch:train:601-800batch: iter_time=2.322e-04, forward_time=0.137, uma_reduction=0.187, text_vs_uma=0.521, loss_ctc=7.833, loss=3.916, backward_time=0.178, optim_step_time=0.037, optim0_lr0=3.734e-04, train_time=0.885
[alab02] 2024-08-28 01:27:04,447 (trainer:720) INFO: 16epoch:train:801-1000batch: iter_time=2.147e-04, forward_time=0.141, uma_reduction=0.190, text_vs_uma=0.510, loss_ctc=7.420, loss=3.710, backward_time=0.186, optim_step_time=0.038, optim0_lr0=3.730e-04, train_time=0.909
[alab02] 2024-08-28 01:28:34,991 (trainer:720) INFO: 16epoch:train:1001-1200batch: iter_time=2.296e-04, forward_time=0.140, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=7.117, loss=3.559, backward_time=0.187, optim_step_time=0.037, optim0_lr0=3.727e-04, train_time=0.905
[alab02] 2024-08-28 01:30:08,033 (trainer:720) INFO: 16epoch:train:1201-1400batch: iter_time=2.159e-04, forward_time=0.143, uma_reduction=0.191, text_vs_uma=0.501, loss_ctc=7.945, loss=3.973, backward_time=0.190, optim_step_time=0.036, optim0_lr0=3.723e-04, train_time=0.930
[alab02] 2024-08-28 01:31:35,797 (trainer:720) INFO: 16epoch:train:1401-1600batch: iter_time=2.324e-04, forward_time=0.134, uma_reduction=0.193, text_vs_uma=0.504, loss_ctc=7.476, loss=3.738, backward_time=0.179, optim_step_time=0.036, optim0_lr0=3.720e-04, train_time=0.877
[alab02] 2024-08-28 01:33:04,111 (trainer:720) INFO: 16epoch:train:1601-1800batch: iter_time=2.362e-04, forward_time=0.135, uma_reduction=0.189, text_vs_uma=0.514, loss_ctc=7.695, loss=3.847, backward_time=0.178, optim_step_time=0.037, optim0_lr0=3.717e-04, train_time=0.883
[alab02] 2024-08-28 01:34:35,100 (trainer:720) INFO: 16epoch:train:1801-2000batch: iter_time=2.271e-04, forward_time=0.139, uma_reduction=0.191, text_vs_uma=0.515, loss_ctc=7.921, loss=3.961, backward_time=0.186, optim_step_time=0.036, optim0_lr0=3.713e-04, train_time=0.910
[alab02] 2024-08-28 01:36:02,705 (trainer:720) INFO: 16epoch:train:2001-2200batch: iter_time=2.250e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.507, loss_ctc=7.496, loss=3.748, backward_time=0.177, optim_step_time=0.036, optim0_lr0=3.710e-04, train_time=0.876
[alab02] 2024-08-28 01:37:32,995 (trainer:720) INFO: 16epoch:train:2201-2400batch: iter_time=2.073e-04, forward_time=0.138, uma_reduction=0.191, text_vs_uma=0.503, loss_ctc=7.101, loss=3.551, backward_time=0.188, optim_step_time=0.036, optim0_lr0=3.706e-04, train_time=0.903
[alab02] 2024-08-28 01:39:04,312 (trainer:720) INFO: 16epoch:train:2401-2600batch: iter_time=2.210e-04, forward_time=0.140, uma_reduction=0.190, text_vs_uma=0.513, loss_ctc=7.487, loss=3.743, backward_time=0.187, optim_step_time=0.038, optim0_lr0=3.703e-04, train_time=0.913
[alab02] 2024-08-28 01:40:33,667 (trainer:720) INFO: 16epoch:train:2601-2800batch: iter_time=2.279e-04, forward_time=0.138, uma_reduction=0.191, text_vs_uma=0.514, loss_ctc=7.411, loss=3.705, backward_time=0.181, optim_step_time=0.038, optim0_lr0=3.700e-04, train_time=0.893
[alab02] 2024-08-28 01:42:04,204 (trainer:720) INFO: 16epoch:train:2801-3000batch: iter_time=2.502e-04, forward_time=0.139, uma_reduction=0.192, text_vs_uma=0.519, loss_ctc=8.035, loss=4.018, backward_time=0.185, optim_step_time=0.036, optim0_lr0=3.696e-04, train_time=0.905
[alab02] 2024-08-28 01:43:32,603 (trainer:720) INFO: 16epoch:train:3001-3200batch: iter_time=2.146e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.494, loss_ctc=7.081, loss=3.541, backward_time=0.181, optim_step_time=0.035, optim0_lr0=3.693e-04, train_time=0.884
[alab02] 2024-08-28 01:45:05,012 (trainer:720) INFO: 16epoch:train:3201-3400batch: iter_time=2.214e-04, forward_time=0.142, uma_reduction=0.191, text_vs_uma=0.511, loss_ctc=7.591, loss=3.796, backward_time=0.190, optim_step_time=0.037, optim0_lr0=3.690e-04, train_time=0.924
[alab02] 2024-08-28 01:46:34,438 (trainer:720) INFO: 16epoch:train:3401-3600batch: iter_time=2.215e-04, forward_time=0.138, uma_reduction=0.192, text_vs_uma=0.503, loss_ctc=7.462, loss=3.731, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.686e-04, train_time=0.894
[alab02] 2024-08-28 01:48:06,315 (trainer:720) INFO: 16epoch:train:3601-3800batch: iter_time=2.186e-04, forward_time=0.141, uma_reduction=0.192, text_vs_uma=0.485, loss_ctc=6.815, loss=3.408, backward_time=0.193, optim_step_time=0.036, optim0_lr0=3.683e-04, train_time=0.918
[alab02] 2024-08-28 01:49:34,516 (trainer:720) INFO: 16epoch:train:3801-4000batch: iter_time=2.614e-04, forward_time=0.136, uma_reduction=0.190, text_vs_uma=0.503, loss_ctc=7.221, loss=3.611, backward_time=0.180, optim_step_time=0.037, optim0_lr0=3.680e-04, train_time=0.882
[alab02] 2024-08-28 01:51:04,724 (trainer:720) INFO: 16epoch:train:4001-4200batch: iter_time=2.231e-04, forward_time=0.139, uma_reduction=0.190, text_vs_uma=0.493, loss_ctc=6.842, loss=3.421, backward_time=0.187, optim_step_time=0.037, optim0_lr0=3.676e-04, train_time=0.902
[alab02] 2024-08-28 01:52:31,542 (trainer:720) INFO: 16epoch:train:4201-4400batch: iter_time=2.374e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.502, loss_ctc=7.123, loss=3.562, backward_time=0.177, optim_step_time=0.036, optim0_lr0=3.673e-04, train_time=0.868
[alab02] 2024-08-28 01:54:00,005 (trainer:720) INFO: 16epoch:train:4401-4600batch: iter_time=2.010e-04, forward_time=0.136, uma_reduction=0.194, text_vs_uma=0.503, loss_ctc=7.272, loss=3.636, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.670e-04, train_time=0.884
[alab02] 2024-08-28 01:55:29,384 (trainer:720) INFO: 16epoch:train:4601-4800batch: iter_time=2.004e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.498, loss_ctc=7.273, loss=3.637, backward_time=0.183, optim_step_time=0.035, optim0_lr0=3.666e-04, train_time=0.893
[alab02] 2024-08-28 01:56:58,008 (trainer:720) INFO: 16epoch:train:4801-5000batch: iter_time=2.190e-04, forward_time=0.135, uma_reduction=0.192, text_vs_uma=0.500, loss_ctc=7.363, loss=3.681, backward_time=0.182, optim_step_time=0.037, optim0_lr0=3.663e-04, train_time=0.886
[alab02] 2024-08-28 01:58:28,158 (trainer:720) INFO: 16epoch:train:5001-5200batch: iter_time=2.077e-04, forward_time=0.137, uma_reduction=0.189, text_vs_uma=0.518, loss_ctc=7.801, loss=3.900, backward_time=0.185, optim_step_time=0.037, optim0_lr0=3.660e-04, train_time=0.901
[alab02] 2024-08-28 01:59:56,445 (trainer:720) INFO: 16epoch:train:5201-5400batch: iter_time=2.225e-04, forward_time=0.135, uma_reduction=0.190, text_vs_uma=0.494, loss_ctc=6.962, loss=3.481, backward_time=0.182, optim_step_time=0.037, optim0_lr0=3.656e-04, train_time=0.883
[alab02] 2024-08-28 02:01:25,540 (trainer:720) INFO: 16epoch:train:5401-5600batch: iter_time=2.039e-04, forward_time=0.138, uma_reduction=0.191, text_vs_uma=0.499, loss_ctc=7.011, loss=3.506, backward_time=0.184, optim_step_time=0.035, optim0_lr0=3.653e-04, train_time=0.891
[alab02] 2024-08-28 02:02:56,864 (trainer:720) INFO: 16epoch:train:5601-5800batch: iter_time=2.057e-04, forward_time=0.140, uma_reduction=0.190, text_vs_uma=0.519, loss_ctc=7.709, loss=3.855, backward_time=0.189, optim_step_time=0.035, optim0_lr0=3.650e-04, train_time=0.913
[alab02] 2024-08-28 02:04:25,039 (trainer:720) INFO: 16epoch:train:5801-6000batch: iter_time=2.011e-04, forward_time=0.134, uma_reduction=0.188, text_vs_uma=0.507, loss_ctc=7.577, loss=3.788, backward_time=0.180, optim_step_time=0.036, optim0_lr0=3.647e-04, train_time=0.881
[alab02] 2024-08-28 02:05:54,894 (trainer:720) INFO: 16epoch:train:6001-6200batch: iter_time=2.358e-04, forward_time=0.138, uma_reduction=0.186, text_vs_uma=0.510, loss_ctc=7.295, loss=3.647, backward_time=0.185, optim_step_time=0.038, optim0_lr0=3.644e-04, train_time=0.898
[alab02] 2024-08-28 02:07:24,869 (trainer:720) INFO: 16epoch:train:6201-6400batch: iter_time=2.463e-04, forward_time=0.138, uma_reduction=0.187, text_vs_uma=0.514, loss_ctc=7.710, loss=3.855, backward_time=0.182, optim_step_time=0.038, optim0_lr0=3.640e-04, train_time=0.899
[alab02] 2024-08-28 02:08:55,645 (trainer:720) INFO: 16epoch:train:6401-6600batch: iter_time=2.438e-04, forward_time=0.141, uma_reduction=0.186, text_vs_uma=0.509, loss_ctc=7.112, loss=3.556, backward_time=0.186, optim_step_time=0.038, optim0_lr0=3.637e-04, train_time=0.907
[alab02] 2024-08-28 02:10:25,481 (trainer:720) INFO: 16epoch:train:6601-6800batch: iter_time=2.877e-04, forward_time=0.137, uma_reduction=0.188, text_vs_uma=0.517, loss_ctc=7.588, loss=3.794, backward_time=0.186, optim_step_time=0.038, optim0_lr0=3.634e-04, train_time=0.898
[alab02] 2024-08-28 02:11:56,173 (trainer:720) INFO: 16epoch:train:6801-7000batch: iter_time=2.512e-04, forward_time=0.139, uma_reduction=0.187, text_vs_uma=0.513, loss_ctc=7.621, loss=3.811, backward_time=0.184, optim_step_time=0.038, optim0_lr0=3.631e-04, train_time=0.907
[alab02] 2024-08-28 02:13:11,858 (trainer:338) INFO: 16epoch results: [train] iter_time=2.967e-04, forward_time=0.138, uma_reduction=0.190, text_vs_uma=0.506, loss_ctc=7.410, loss=3.705, backward_time=0.184, optim_step_time=0.037, optim0_lr0=3.686e-04, train_time=0.897, time=53 minutes and 17.24 seconds, total_count=114016, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.153, text_vs_uma=0.707, loss_ctc=5.520, cer_ctc=0.122, cer=0.122, loss=5.520, time=6.37 seconds, total_count=416, gpu_max_cached_mem_GB=35.900, [att_plot] time=13.87 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-28 02:13:17,494 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 02:13:17,500 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/7epoch.pth
[alab02] 2024-08-28 02:13:17,501 (trainer:272) INFO: 17/150epoch started. Estimated time to finish: 5 days, 7 hours and 59 minutes
[alab02] 2024-08-28 02:14:47,049 (trainer:720) INFO: 17epoch:train:1-200batch: iter_time=0.002, forward_time=0.136, uma_reduction=0.189, text_vs_uma=0.516, loss_ctc=8.018, loss=4.009, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.625e-04, train_time=0.895
[alab02] 2024-08-28 02:16:15,084 (trainer:720) INFO: 17epoch:train:201-400batch: iter_time=2.192e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.499, loss_ctc=7.021, loss=3.510, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.622e-04, train_time=0.880
[alab02] 2024-08-28 02:17:43,265 (trainer:720) INFO: 17epoch:train:401-600batch: iter_time=2.155e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=7.321, loss=3.660, backward_time=0.179, optim_step_time=0.035, optim0_lr0=3.619e-04, train_time=0.882
[alab02] 2024-08-28 02:19:11,682 (trainer:720) INFO: 17epoch:train:601-800batch: iter_time=2.062e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.506, loss_ctc=7.302, loss=3.651, backward_time=0.180, optim_step_time=0.035, optim0_lr0=3.616e-04, train_time=0.884
[alab02] 2024-08-28 02:20:40,969 (trainer:720) INFO: 17epoch:train:801-1000batch: iter_time=2.177e-04, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.499, loss_ctc=6.806, loss=3.403, backward_time=0.186, optim_step_time=0.035, optim0_lr0=3.613e-04, train_time=0.893
[alab02] 2024-08-28 02:22:11,793 (trainer:720) INFO: 17epoch:train:1001-1200batch: iter_time=2.231e-04, forward_time=0.139, uma_reduction=0.188, text_vs_uma=0.499, loss_ctc=7.519, loss=3.760, backward_time=0.187, optim_step_time=0.034, optim0_lr0=3.610e-04, train_time=0.908
[alab02] 2024-08-28 02:23:40,558 (trainer:720) INFO: 17epoch:train:1201-1400batch: iter_time=2.083e-04, forward_time=0.135, uma_reduction=0.190, text_vs_uma=0.511, loss_ctc=7.462, loss=3.731, backward_time=0.182, optim_step_time=0.036, optim0_lr0=3.607e-04, train_time=0.887
[alab02] 2024-08-28 02:25:12,995 (trainer:720) INFO: 17epoch:train:1401-1600batch: iter_time=2.682e-04, forward_time=0.142, uma_reduction=0.191, text_vs_uma=0.490, loss_ctc=6.743, loss=3.372, backward_time=0.193, optim_step_time=0.038, optim0_lr0=3.603e-04, train_time=0.924
[alab02] 2024-08-28 02:26:40,811 (trainer:720) INFO: 17epoch:train:1601-1800batch: iter_time=2.641e-04, forward_time=0.135, uma_reduction=0.192, text_vs_uma=0.502, loss_ctc=7.655, loss=3.828, backward_time=0.175, optim_step_time=0.036, optim0_lr0=3.600e-04, train_time=0.878
[alab02] 2024-08-28 02:28:08,919 (trainer:720) INFO: 17epoch:train:1801-2000batch: iter_time=2.762e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.513, loss_ctc=7.611, loss=3.805, backward_time=0.179, optim_step_time=0.038, optim0_lr0=3.597e-04, train_time=0.881
[alab02] 2024-08-28 02:29:35,952 (trainer:720) INFO: 17epoch:train:2001-2200batch: iter_time=1.994e-04, forward_time=0.132, uma_reduction=0.192, text_vs_uma=0.505, loss_ctc=7.472, loss=3.736, backward_time=0.177, optim_step_time=0.035, optim0_lr0=3.594e-04, train_time=0.870
[alab02] 2024-08-28 02:31:05,213 (trainer:720) INFO: 17epoch:train:2201-2400batch: iter_time=2.196e-04, forward_time=0.135, uma_reduction=0.192, text_vs_uma=0.492, loss_ctc=7.219, loss=3.609, backward_time=0.185, optim_step_time=0.035, optim0_lr0=3.591e-04, train_time=0.892
[alab02] 2024-08-28 02:32:34,218 (trainer:720) INFO: 17epoch:train:2401-2600batch: iter_time=2.114e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.506, loss_ctc=7.163, loss=3.582, backward_time=0.185, optim_step_time=0.036, optim0_lr0=3.588e-04, train_time=0.890
[alab02] 2024-08-28 02:34:02,435 (trainer:720) INFO: 17epoch:train:2601-2800batch: iter_time=2.130e-04, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.486, loss_ctc=6.711, loss=3.355, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.585e-04, train_time=0.882
[alab02] 2024-08-28 02:35:32,131 (trainer:720) INFO: 17epoch:train:2801-3000batch: iter_time=1.957e-04, forward_time=0.136, uma_reduction=0.195, text_vs_uma=0.486, loss_ctc=6.630, loss=3.315, backward_time=0.187, optim_step_time=0.034, optim0_lr0=3.582e-04, train_time=0.897
[alab02] 2024-08-28 02:36:59,451 (trainer:720) INFO: 17epoch:train:3001-3200batch: iter_time=1.945e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.505, loss_ctc=7.407, loss=3.703, backward_time=0.177, optim_step_time=0.034, optim0_lr0=3.579e-04, train_time=0.873
[alab02] 2024-08-28 02:38:28,355 (trainer:720) INFO: 17epoch:train:3201-3400batch: iter_time=1.954e-04, forward_time=0.134, uma_reduction=0.196, text_vs_uma=0.496, loss_ctc=6.795, loss=3.397, backward_time=0.187, optim_step_time=0.034, optim0_lr0=3.576e-04, train_time=0.889
[alab02] 2024-08-28 02:39:56,921 (trainer:720) INFO: 17epoch:train:3401-3600batch: iter_time=1.942e-04, forward_time=0.133, uma_reduction=0.195, text_vs_uma=0.507, loss_ctc=7.714, loss=3.857, backward_time=0.180, optim_step_time=0.035, optim0_lr0=3.573e-04, train_time=0.885
[alab02] 2024-08-28 02:41:26,785 (trainer:720) INFO: 17epoch:train:3601-3800batch: iter_time=1.886e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.497, loss_ctc=7.178, loss=3.589, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.570e-04, train_time=0.898
[alab02] 2024-08-28 02:42:53,872 (trainer:720) INFO: 17epoch:train:3801-4000batch: iter_time=1.805e-04, forward_time=0.132, uma_reduction=0.189, text_vs_uma=0.506, loss_ctc=7.175, loss=3.587, backward_time=0.179, optim_step_time=0.035, optim0_lr0=3.567e-04, train_time=0.871
[alab02] 2024-08-28 02:44:21,958 (trainer:720) INFO: 17epoch:train:4001-4200batch: iter_time=1.830e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.507, loss_ctc=7.011, loss=3.505, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.564e-04, train_time=0.881
[alab02] 2024-08-28 02:45:50,602 (trainer:720) INFO: 17epoch:train:4201-4400batch: iter_time=1.762e-04, forward_time=0.134, uma_reduction=0.193, text_vs_uma=0.490, loss_ctc=6.768, loss=3.384, backward_time=0.185, optim_step_time=0.034, optim0_lr0=3.561e-04, train_time=0.886
[alab02] 2024-08-28 02:47:17,667 (trainer:720) INFO: 17epoch:train:4401-4600batch: iter_time=1.752e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.481, loss_ctc=6.419, loss=3.210, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.558e-04, train_time=0.870
[alab02] 2024-08-28 02:48:47,568 (trainer:720) INFO: 17epoch:train:4601-4800batch: iter_time=2.595e-04, forward_time=0.137, uma_reduction=0.196, text_vs_uma=0.486, loss_ctc=6.864, loss=3.432, backward_time=0.187, optim_step_time=0.035, optim0_lr0=3.555e-04, train_time=0.899
[alab02] 2024-08-28 02:50:16,489 (trainer:720) INFO: 17epoch:train:4801-5000batch: iter_time=1.866e-04, forward_time=0.135, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=6.832, loss=3.416, backward_time=0.185, optim_step_time=0.034, optim0_lr0=3.552e-04, train_time=0.889
[alab02] 2024-08-28 02:51:43,698 (trainer:720) INFO: 17epoch:train:5001-5200batch: iter_time=1.769e-04, forward_time=0.130, uma_reduction=0.196, text_vs_uma=0.485, loss_ctc=6.792, loss=3.396, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.549e-04, train_time=0.872
[alab02] 2024-08-28 02:53:11,825 (trainer:720) INFO: 17epoch:train:5201-5400batch: iter_time=1.834e-04, forward_time=0.133, uma_reduction=0.195, text_vs_uma=0.493, loss_ctc=7.110, loss=3.555, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.546e-04, train_time=0.881
[alab02] 2024-08-28 02:54:37,274 (trainer:720) INFO: 17epoch:train:5401-5600batch: iter_time=1.883e-04, forward_time=0.129, uma_reduction=0.195, text_vs_uma=0.497, loss_ctc=7.357, loss=3.678, backward_time=0.172, optim_step_time=0.034, optim0_lr0=3.543e-04, train_time=0.854
[alab02] 2024-08-28 02:56:05,934 (trainer:720) INFO: 17epoch:train:5601-5800batch: iter_time=1.849e-04, forward_time=0.134, uma_reduction=0.193, text_vs_uma=0.488, loss_ctc=6.584, loss=3.292, backward_time=0.187, optim_step_time=0.033, optim0_lr0=3.540e-04, train_time=0.886
[alab02] 2024-08-28 02:57:34,100 (trainer:720) INFO: 17epoch:train:5801-6000batch: iter_time=1.826e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.490, loss_ctc=6.812, loss=3.406, backward_time=0.182, optim_step_time=0.035, optim0_lr0=3.537e-04, train_time=0.881
[alab02] 2024-08-28 02:59:04,274 (trainer:720) INFO: 17epoch:train:6001-6200batch: iter_time=1.827e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.498, loss_ctc=6.763, loss=3.382, backward_time=0.192, optim_step_time=0.034, optim0_lr0=3.534e-04, train_time=0.902
[alab02] 2024-08-28 03:00:30,979 (trainer:720) INFO: 17epoch:train:6201-6400batch: iter_time=1.838e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.507, loss_ctc=6.753, loss=3.376, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.531e-04, train_time=0.867
[alab02] 2024-08-28 03:02:00,186 (trainer:720) INFO: 17epoch:train:6401-6600batch: iter_time=1.917e-04, forward_time=0.136, uma_reduction=0.192, text_vs_uma=0.505, loss_ctc=6.934, loss=3.467, backward_time=0.186, optim_step_time=0.035, optim0_lr0=3.528e-04, train_time=0.892
[alab02] 2024-08-28 03:03:27,288 (trainer:720) INFO: 17epoch:train:6601-6800batch: iter_time=1.831e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.520, loss_ctc=7.406, loss=3.703, backward_time=0.178, optim_step_time=0.034, optim0_lr0=3.525e-04, train_time=0.871
[alab02] 2024-08-28 03:04:56,712 (trainer:720) INFO: 17epoch:train:6801-7000batch: iter_time=1.959e-04, forward_time=0.135, uma_reduction=0.190, text_vs_uma=0.509, loss_ctc=7.165, loss=3.582, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.522e-04, train_time=0.894
[alab02] 2024-08-28 03:06:11,865 (trainer:338) INFO: 17epoch results: [train] iter_time=2.661e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=7.096, loss=3.548, backward_time=0.183, optim_step_time=0.035, optim0_lr0=3.572e-04, train_time=0.885, time=52 minutes and 35.42 seconds, total_count=121142, gpu_max_cached_mem_GB=35.900, [valid] uma_reduction=0.155, text_vs_uma=0.699, loss_ctc=4.892, cer_ctc=0.116, cer=0.116, loss=4.892, time=6.26 seconds, total_count=442, gpu_max_cached_mem_GB=35.900, [att_plot] time=12.69 seconds, total_count=0, gpu_max_cached_mem_GB=35.900
[alab02] 2024-08-28 03:06:17,774 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 03:06:17,780 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/5epoch.pth
[alab02] 2024-08-28 03:06:17,780 (trainer:272) INFO: 18/150epoch started. Estimated time to finish: 5 days, 6 hours and 28 minutes
[alab02] 2024-08-28 03:07:46,997 (trainer:720) INFO: 18epoch:train:1-200batch: iter_time=0.003, forward_time=0.133, uma_reduction=0.185, text_vs_uma=0.512, loss_ctc=7.415, loss=3.707, backward_time=0.179, optim_step_time=0.036, optim0_lr0=3.517e-04, train_time=0.892
[alab02] 2024-08-28 03:09:16,056 (trainer:720) INFO: 18epoch:train:201-400batch: iter_time=2.515e-04, forward_time=0.136, uma_reduction=0.189, text_vs_uma=0.520, loss_ctc=7.323, loss=3.662, backward_time=0.184, optim_step_time=0.037, optim0_lr0=3.514e-04, train_time=0.890
[alab02] 2024-08-28 03:10:48,815 (trainer:720) INFO: 18epoch:train:401-600batch: iter_time=3.833e-04, forward_time=0.141, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=7.312, loss=3.656, backward_time=0.190, optim_step_time=0.039, optim0_lr0=3.512e-04, train_time=0.927
[alab02] 2024-08-28 03:12:16,637 (trainer:720) INFO: 18epoch:train:601-800batch: iter_time=2.562e-04, forward_time=0.133, uma_reduction=0.190, text_vs_uma=0.513, loss_ctc=7.696, loss=3.848, backward_time=0.176, optim_step_time=0.036, optim0_lr0=3.509e-04, train_time=0.878
[alab02] 2024-08-28 03:13:45,206 (trainer:720) INFO: 18epoch:train:801-1000batch: iter_time=2.035e-04, forward_time=0.133, uma_reduction=0.186, text_vs_uma=0.511, loss_ctc=7.500, loss=3.750, backward_time=0.182, optim_step_time=0.035, optim0_lr0=3.506e-04, train_time=0.885
[alab02] 2024-08-28 03:15:14,392 (trainer:720) INFO: 18epoch:train:1001-1200batch: iter_time=2.464e-04, forward_time=0.136, uma_reduction=0.191, text_vs_uma=0.508, loss_ctc=6.775, loss=3.387, backward_time=0.186, optim_step_time=0.035, optim0_lr0=3.503e-04, train_time=0.892
[alab02] 2024-08-28 03:16:42,391 (trainer:720) INFO: 18epoch:train:1201-1400batch: iter_time=2.223e-04, forward_time=0.132, uma_reduction=0.193, text_vs_uma=0.509, loss_ctc=7.285, loss=3.643, backward_time=0.181, optim_step_time=0.036, optim0_lr0=3.500e-04, train_time=0.880
[alab02] 2024-08-28 03:18:09,888 (trainer:720) INFO: 18epoch:train:1401-1600batch: iter_time=2.064e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.492, loss_ctc=6.251, loss=3.126, backward_time=0.183, optim_step_time=0.035, optim0_lr0=3.497e-04, train_time=0.875
[alab02] 2024-08-28 03:19:39,497 (trainer:720) INFO: 18epoch:train:1601-1800batch: iter_time=2.755e-04, forward_time=0.135, uma_reduction=0.195, text_vs_uma=0.509, loss_ctc=6.967, loss=3.483, backward_time=0.187, optim_step_time=0.036, optim0_lr0=3.494e-04, train_time=0.896
[alab02] 2024-08-28 03:21:06,319 (trainer:720) INFO: 18epoch:train:1801-2000batch: iter_time=1.840e-04, forward_time=0.130, uma_reduction=0.190, text_vs_uma=0.513, loss_ctc=7.585, loss=3.792, backward_time=0.178, optim_step_time=0.034, optim0_lr0=3.492e-04, train_time=0.868
[alab02] 2024-08-28 03:22:33,823 (trainer:720) INFO: 18epoch:train:2001-2200batch: iter_time=1.767e-04, forward_time=0.131, uma_reduction=0.189, text_vs_uma=0.509, loss_ctc=7.174, loss=3.587, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.489e-04, train_time=0.875
[alab02] 2024-08-28 03:24:00,651 (trainer:720) INFO: 18epoch:train:2201-2400batch: iter_time=1.788e-04, forward_time=0.129, uma_reduction=0.189, text_vs_uma=0.522, loss_ctc=7.275, loss=3.638, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.486e-04, train_time=0.868
[alab02] 2024-08-28 03:25:27,083 (trainer:720) INFO: 18epoch:train:2401-2600batch: iter_time=1.783e-04, forward_time=0.130, uma_reduction=0.188, text_vs_uma=0.508, loss_ctc=7.251, loss=3.625, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.483e-04, train_time=0.864
[alab02] 2024-08-28 03:26:53,050 (trainer:720) INFO: 18epoch:train:2601-2800batch: iter_time=1.757e-04, forward_time=0.129, uma_reduction=0.189, text_vs_uma=0.510, loss_ctc=7.213, loss=3.607, backward_time=0.177, optim_step_time=0.034, optim0_lr0=3.480e-04, train_time=0.859
[alab02] 2024-08-28 03:28:20,711 (trainer:720) INFO: 18epoch:train:2801-3000batch: iter_time=1.835e-04, forward_time=0.132, uma_reduction=0.189, text_vs_uma=0.508, loss_ctc=6.924, loss=3.462, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.477e-04, train_time=0.876
[alab02] 2024-08-28 03:29:47,345 (trainer:720) INFO: 18epoch:train:3001-3200batch: iter_time=1.819e-04, forward_time=0.129, uma_reduction=0.189, text_vs_uma=0.504, loss_ctc=6.856, loss=3.428, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.475e-04, train_time=0.866
[alab02] 2024-08-28 03:31:13,538 (trainer:720) INFO: 18epoch:train:3201-3400batch: iter_time=1.687e-04, forward_time=0.128, uma_reduction=0.187, text_vs_uma=0.511, loss_ctc=7.287, loss=3.643, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.472e-04, train_time=0.862
[alab02] 2024-08-28 03:32:40,864 (trainer:720) INFO: 18epoch:train:3401-3600batch: iter_time=1.709e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.498, loss_ctc=6.648, loss=3.324, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.469e-04, train_time=0.873
[alab02] 2024-08-28 03:34:07,972 (trainer:720) INFO: 18epoch:train:3601-3800batch: iter_time=1.707e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.503, loss_ctc=7.420, loss=3.710, backward_time=0.180, optim_step_time=0.034, optim0_lr0=3.466e-04, train_time=0.871
[alab02] 2024-08-28 03:35:36,809 (trainer:720) INFO: 18epoch:train:3801-4000batch: iter_time=1.796e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.496, loss_ctc=6.530, loss=3.265, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.463e-04, train_time=0.888
[alab02] 2024-08-28 03:37:05,373 (trainer:720) INFO: 18epoch:train:4001-4200batch: iter_time=1.907e-04, forward_time=0.133, uma_reduction=0.193, text_vs_uma=0.501, loss_ctc=6.932, loss=3.466, backward_time=0.184, optim_step_time=0.034, optim0_lr0=3.461e-04, train_time=0.885
[alab02] 2024-08-28 03:38:31,255 (trainer:720) INFO: 18epoch:train:4201-4400batch: iter_time=1.821e-04, forward_time=0.129, uma_reduction=0.192, text_vs_uma=0.486, loss_ctc=6.550, loss=3.275, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.458e-04, train_time=0.859
[alab02] 2024-08-28 03:39:58,864 (trainer:720) INFO: 18epoch:train:4401-4600batch: iter_time=1.816e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.519, loss_ctc=7.683, loss=3.842, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.455e-04, train_time=0.876
[alab02] 2024-08-28 03:41:29,858 (trainer:720) INFO: 18epoch:train:4601-4800batch: iter_time=1.879e-04, forward_time=0.138, uma_reduction=0.193, text_vs_uma=0.494, loss_ctc=6.851, loss=3.426, backward_time=0.191, optim_step_time=0.034, optim0_lr0=3.452e-04, train_time=0.910
[alab02] 2024-08-28 03:42:58,145 (trainer:720) INFO: 18epoch:train:4801-5000batch: iter_time=1.810e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.502, loss_ctc=7.193, loss=3.597, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.450e-04, train_time=0.883
[alab02] 2024-08-28 03:44:26,080 (trainer:720) INFO: 18epoch:train:5001-5200batch: iter_time=1.825e-04, forward_time=0.132, uma_reduction=0.195, text_vs_uma=0.489, loss_ctc=6.443, loss=3.222, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.447e-04, train_time=0.879
[alab02] 2024-08-28 03:45:52,696 (trainer:720) INFO: 18epoch:train:5201-5400batch: iter_time=1.789e-04, forward_time=0.130, uma_reduction=0.191, text_vs_uma=0.496, loss_ctc=7.202, loss=3.601, backward_time=0.176, optim_step_time=0.033, optim0_lr0=3.444e-04, train_time=0.866
[alab02] 2024-08-28 03:47:19,861 (trainer:720) INFO: 18epoch:train:5401-5600batch: iter_time=1.759e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.484, loss_ctc=6.388, loss=3.194, backward_time=0.183, optim_step_time=0.034, optim0_lr0=3.442e-04, train_time=0.871
[alab02] 2024-08-28 03:48:50,662 (trainer:720) INFO: 18epoch:train:5601-5800batch: iter_time=1.755e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=7.126, loss=3.563, backward_time=0.189, optim_step_time=0.033, optim0_lr0=3.439e-04, train_time=0.908
[alab02] 2024-08-28 03:50:16,586 (trainer:720) INFO: 18epoch:train:5801-6000batch: iter_time=1.761e-04, forward_time=0.129, uma_reduction=0.193, text_vs_uma=0.510, loss_ctc=7.441, loss=3.721, backward_time=0.175, optim_step_time=0.034, optim0_lr0=3.436e-04, train_time=0.859
[alab02] 2024-08-28 03:51:43,766 (trainer:720) INFO: 18epoch:train:6001-6200batch: iter_time=1.735e-04, forward_time=0.130, uma_reduction=0.194, text_vs_uma=0.497, loss_ctc=6.772, loss=3.386, backward_time=0.183, optim_step_time=0.034, optim0_lr0=3.433e-04, train_time=0.872
[alab02] 2024-08-28 03:53:11,990 (trainer:720) INFO: 18epoch:train:6201-6400batch: iter_time=1.831e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.491, loss_ctc=6.632, loss=3.316, backward_time=0.186, optim_step_time=0.033, optim0_lr0=3.431e-04, train_time=0.882
[alab02] 2024-08-28 03:54:37,542 (trainer:720) INFO: 18epoch:train:6401-6600batch: iter_time=2.033e-04, forward_time=0.129, uma_reduction=0.192, text_vs_uma=0.510, loss_ctc=7.459, loss=3.730, backward_time=0.172, optim_step_time=0.034, optim0_lr0=3.428e-04, train_time=0.855
[alab02] 2024-08-28 03:56:05,521 (trainer:720) INFO: 18epoch:train:6601-6800batch: iter_time=1.876e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.506, loss_ctc=7.029, loss=3.515, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.425e-04, train_time=0.880
[alab02] 2024-08-28 03:57:33,507 (trainer:720) INFO: 18epoch:train:6801-7000batch: iter_time=1.901e-04, forward_time=0.132, uma_reduction=0.191, text_vs_uma=0.503, loss_ctc=7.090, loss=3.545, backward_time=0.180, optim_step_time=0.034, optim0_lr0=3.423e-04, train_time=0.880
[alab02] 2024-08-28 03:58:47,899 (trainer:338) INFO: 18epoch results: [train] iter_time=2.752e-04, forward_time=0.132, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=7.055, loss=3.528, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.469e-04, train_time=0.878, time=52 minutes and 11.22 seconds, total_count=128268, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.162, text_vs_uma=0.670, loss_ctc=4.841, cer_ctc=0.114, cer=0.114, loss=4.841, time=6.1 seconds, total_count=468, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.79 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 03:58:54,246 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 03:58:54,252 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/8epoch.pth
[alab02] 2024-08-28 03:58:54,252 (trainer:272) INFO: 19/150epoch started. Estimated time to finish: 5 days, 4 hours and 58 minutes
[alab02] 2024-08-28 04:00:22,754 (trainer:720) INFO: 19epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.192, text_vs_uma=0.487, loss_ctc=6.726, loss=3.363, backward_time=0.181, optim_step_time=0.035, optim0_lr0=3.418e-04, train_time=0.885
[alab02] 2024-08-28 04:01:52,336 (trainer:720) INFO: 19epoch:train:201-400batch: iter_time=2.200e-04, forward_time=0.136, uma_reduction=0.194, text_vs_uma=0.487, loss_ctc=6.812, loss=3.406, backward_time=0.185, optim_step_time=0.035, optim0_lr0=3.416e-04, train_time=0.896
[alab02] 2024-08-28 04:03:20,247 (trainer:720) INFO: 19epoch:train:401-600batch: iter_time=1.919e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.489, loss_ctc=6.904, loss=3.452, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.413e-04, train_time=0.879
[alab02] 2024-08-28 04:04:45,907 (trainer:720) INFO: 19epoch:train:601-800batch: iter_time=2.011e-04, forward_time=0.128, uma_reduction=0.191, text_vs_uma=0.512, loss_ctc=7.724, loss=3.862, backward_time=0.172, optim_step_time=0.034, optim0_lr0=3.410e-04, train_time=0.856
[alab02] 2024-08-28 04:06:14,135 (trainer:720) INFO: 19epoch:train:801-1000batch: iter_time=2.116e-04, forward_time=0.132, uma_reduction=0.192, text_vs_uma=0.502, loss_ctc=6.767, loss=3.383, backward_time=0.183, optim_step_time=0.035, optim0_lr0=3.408e-04, train_time=0.882
[alab02] 2024-08-28 04:07:43,653 (trainer:720) INFO: 19epoch:train:1001-1200batch: iter_time=2.165e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.494, loss_ctc=6.248, loss=3.124, backward_time=0.191, optim_step_time=0.035, optim0_lr0=3.405e-04, train_time=0.895
[alab02] 2024-08-28 04:09:13,997 (trainer:720) INFO: 19epoch:train:1201-1400batch: iter_time=1.902e-04, forward_time=0.137, uma_reduction=0.192, text_vs_uma=0.491, loss_ctc=6.372, loss=3.186, backward_time=0.193, optim_step_time=0.034, optim0_lr0=3.402e-04, train_time=0.903
[alab02] 2024-08-28 04:10:42,824 (trainer:720) INFO: 19epoch:train:1401-1600batch: iter_time=1.990e-04, forward_time=0.133, uma_reduction=0.189, text_vs_uma=0.505, loss_ctc=6.665, loss=3.332, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.400e-04, train_time=0.888
[alab02] 2024-08-28 04:12:09,967 (trainer:720) INFO: 19epoch:train:1601-1800batch: iter_time=1.661e-04, forward_time=0.131, uma_reduction=0.188, text_vs_uma=0.511, loss_ctc=6.687, loss=3.343, backward_time=0.182, optim_step_time=0.032, optim0_lr0=3.397e-04, train_time=0.871
[alab02] 2024-08-28 04:13:37,269 (trainer:720) INFO: 19epoch:train:1801-2000batch: iter_time=1.766e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.490, loss_ctc=6.682, loss=3.341, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.395e-04, train_time=0.873
[alab02] 2024-08-28 04:15:02,663 (trainer:720) INFO: 19epoch:train:2001-2200batch: iter_time=1.720e-04, forward_time=0.128, uma_reduction=0.189, text_vs_uma=0.514, loss_ctc=6.975, loss=3.487, backward_time=0.175, optim_step_time=0.033, optim0_lr0=3.392e-04, train_time=0.854
[alab02] 2024-08-28 04:16:31,201 (trainer:720) INFO: 19epoch:train:2201-2400batch: iter_time=1.828e-04, forward_time=0.132, uma_reduction=0.192, text_vs_uma=0.502, loss_ctc=6.882, loss=3.441, backward_time=0.186, optim_step_time=0.033, optim0_lr0=3.389e-04, train_time=0.885
[alab02] 2024-08-28 04:17:56,759 (trainer:720) INFO: 19epoch:train:2401-2600batch: iter_time=1.731e-04, forward_time=0.127, uma_reduction=0.191, text_vs_uma=0.497, loss_ctc=6.830, loss=3.415, backward_time=0.178, optim_step_time=0.032, optim0_lr0=3.387e-04, train_time=0.855
[alab02] 2024-08-28 04:19:24,801 (trainer:720) INFO: 19epoch:train:2601-2800batch: iter_time=1.742e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.489, loss_ctc=7.049, loss=3.524, backward_time=0.183, optim_step_time=0.032, optim0_lr0=3.384e-04, train_time=0.880
[alab02] 2024-08-28 04:20:51,228 (trainer:720) INFO: 19epoch:train:2801-3000batch: iter_time=1.741e-04, forward_time=0.128, uma_reduction=0.189, text_vs_uma=0.520, loss_ctc=7.340, loss=3.670, backward_time=0.178, optim_step_time=0.032, optim0_lr0=3.382e-04, train_time=0.864
[alab02] 2024-08-28 04:22:18,646 (trainer:720) INFO: 19epoch:train:3001-3200batch: iter_time=1.827e-04, forward_time=0.131, uma_reduction=0.187, text_vs_uma=0.513, loss_ctc=7.147, loss=3.573, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.379e-04, train_time=0.874
[alab02] 2024-08-28 04:23:45,404 (trainer:720) INFO: 19epoch:train:3201-3400batch: iter_time=1.668e-04, forward_time=0.129, uma_reduction=0.187, text_vs_uma=0.510, loss_ctc=7.245, loss=3.623, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.376e-04, train_time=0.867
[alab02] 2024-08-28 04:25:12,203 (trainer:720) INFO: 19epoch:train:3401-3600batch: iter_time=2.071e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.497, loss_ctc=6.738, loss=3.369, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.374e-04, train_time=0.868
[alab02] 2024-08-28 04:26:39,750 (trainer:720) INFO: 19epoch:train:3601-3800batch: iter_time=1.686e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.497, loss_ctc=6.773, loss=3.387, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.371e-04, train_time=0.875
[alab02] 2024-08-28 04:28:08,955 (trainer:720) INFO: 19epoch:train:3801-4000batch: iter_time=1.617e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.509, loss_ctc=6.869, loss=3.434, backward_time=0.188, optim_step_time=0.032, optim0_lr0=3.369e-04, train_time=0.892
[alab02] 2024-08-28 04:29:36,234 (trainer:720) INFO: 19epoch:train:4001-4200batch: iter_time=1.752e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.508, loss_ctc=6.872, loss=3.436, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.366e-04, train_time=0.873
[alab02] 2024-08-28 04:31:03,272 (trainer:720) INFO: 19epoch:train:4201-4400batch: iter_time=1.686e-04, forward_time=0.131, uma_reduction=0.189, text_vs_uma=0.497, loss_ctc=6.607, loss=3.303, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.364e-04, train_time=0.870
[alab02] 2024-08-28 04:32:32,023 (trainer:720) INFO: 19epoch:train:4401-4600batch: iter_time=1.800e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.506, loss_ctc=6.790, loss=3.395, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.361e-04, train_time=0.887
[alab02] 2024-08-28 04:33:59,301 (trainer:720) INFO: 19epoch:train:4601-4800batch: iter_time=1.713e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.509, loss_ctc=7.106, loss=3.553, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.359e-04, train_time=0.873
[alab02] 2024-08-28 04:35:29,311 (trainer:720) INFO: 19epoch:train:4801-5000batch: iter_time=1.842e-04, forward_time=0.136, uma_reduction=0.187, text_vs_uma=0.502, loss_ctc=6.781, loss=3.391, backward_time=0.188, optim_step_time=0.034, optim0_lr0=3.356e-04, train_time=0.900
[alab02] 2024-08-28 04:36:56,331 (trainer:720) INFO: 19epoch:train:5001-5200batch: iter_time=1.830e-04, forward_time=0.130, uma_reduction=0.188, text_vs_uma=0.522, loss_ctc=7.409, loss=3.705, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.354e-04, train_time=0.870
[alab02] 2024-08-28 04:38:21,820 (trainer:720) INFO: 19epoch:train:5201-5400batch: iter_time=1.799e-04, forward_time=0.128, uma_reduction=0.188, text_vs_uma=0.524, loss_ctc=6.942, loss=3.471, backward_time=0.176, optim_step_time=0.034, optim0_lr0=3.351e-04, train_time=0.855
[alab02] 2024-08-28 04:39:48,443 (trainer:720) INFO: 19epoch:train:5401-5600batch: iter_time=1.842e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.499, loss_ctc=6.672, loss=3.336, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.349e-04, train_time=0.866
[alab02] 2024-08-28 04:41:16,888 (trainer:720) INFO: 19epoch:train:5601-5800batch: iter_time=1.706e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.512, loss_ctc=6.796, loss=3.398, backward_time=0.186, optim_step_time=0.033, optim0_lr0=3.346e-04, train_time=0.884
[alab02] 2024-08-28 04:42:43,075 (trainer:720) INFO: 19epoch:train:5801-6000batch: iter_time=1.817e-04, forward_time=0.130, uma_reduction=0.190, text_vs_uma=0.513, loss_ctc=7.129, loss=3.565, backward_time=0.176, optim_step_time=0.033, optim0_lr0=3.344e-04, train_time=0.862
[alab02] 2024-08-28 04:44:11,709 (trainer:720) INFO: 19epoch:train:6001-6200batch: iter_time=1.778e-04, forward_time=0.133, uma_reduction=0.189, text_vs_uma=0.512, loss_ctc=7.357, loss=3.679, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.341e-04, train_time=0.886
[alab02] 2024-08-28 04:45:40,202 (trainer:720) INFO: 19epoch:train:6201-6400batch: iter_time=1.723e-04, forward_time=0.133, uma_reduction=0.189, text_vs_uma=0.498, loss_ctc=6.983, loss=3.492, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.339e-04, train_time=0.885
[alab02] 2024-08-28 04:47:07,290 (trainer:720) INFO: 19epoch:train:6401-6600batch: iter_time=1.786e-04, forward_time=0.130, uma_reduction=0.189, text_vs_uma=0.511, loss_ctc=7.418, loss=3.709, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.336e-04, train_time=0.871
[alab02] 2024-08-28 04:48:33,954 (trainer:720) INFO: 19epoch:train:6601-6800batch: iter_time=1.988e-04, forward_time=0.131, uma_reduction=0.188, text_vs_uma=0.499, loss_ctc=6.629, loss=3.315, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.334e-04, train_time=0.866
[alab02] 2024-08-28 04:50:01,102 (trainer:720) INFO: 19epoch:train:6801-7000batch: iter_time=1.712e-04, forward_time=0.132, uma_reduction=0.189, text_vs_uma=0.520, loss_ctc=7.060, loss=3.530, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.331e-04, train_time=0.871
[alab02] 2024-08-28 04:51:14,557 (trainer:338) INFO: 19epoch results: [train] iter_time=2.381e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.504, loss_ctc=6.916, loss=3.458, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.373e-04, train_time=0.876, time=52 minutes and 1.84 seconds, total_count=135394, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.165, text_vs_uma=0.657, loss_ctc=4.884, cer_ctc=0.115, cer=0.115, loss=4.884, time=5.91 seconds, total_count=494, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.56 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 04:51:21,651 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 04:51:21,657 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/9epoch.pth
[alab02] 2024-08-28 04:51:21,658 (trainer:272) INFO: 20/150epoch started. Estimated time to finish: 5 days, 3 hours and 31 minutes
[alab02] 2024-08-28 04:52:52,182 (trainer:720) INFO: 20epoch:train:1-200batch: iter_time=0.002, forward_time=0.135, uma_reduction=0.189, text_vs_uma=0.503, loss_ctc=6.867, loss=3.433, backward_time=0.187, optim_step_time=0.035, optim0_lr0=3.327e-04, train_time=0.905
[alab02] 2024-08-28 04:54:20,686 (trainer:720) INFO: 20epoch:train:201-400batch: iter_time=1.830e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.508, loss_ctc=7.021, loss=3.510, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.325e-04, train_time=0.885
[alab02] 2024-08-28 04:55:46,347 (trainer:720) INFO: 20epoch:train:401-600batch: iter_time=1.850e-04, forward_time=0.129, uma_reduction=0.188, text_vs_uma=0.505, loss_ctc=6.909, loss=3.455, backward_time=0.176, optim_step_time=0.032, optim0_lr0=3.322e-04, train_time=0.856
[alab02] 2024-08-28 04:57:13,411 (trainer:720) INFO: 20epoch:train:601-800batch: iter_time=1.935e-04, forward_time=0.130, uma_reduction=0.190, text_vs_uma=0.495, loss_ctc=6.402, loss=3.201, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.320e-04, train_time=0.870
[alab02] 2024-08-28 04:58:38,552 (trainer:720) INFO: 20epoch:train:801-1000batch: iter_time=1.866e-04, forward_time=0.127, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=6.518, loss=3.259, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.317e-04, train_time=0.851
[alab02] 2024-08-28 05:00:05,086 (trainer:720) INFO: 20epoch:train:1001-1200batch: iter_time=1.893e-04, forward_time=0.129, uma_reduction=0.187, text_vs_uma=0.528, loss_ctc=7.643, loss=3.822, backward_time=0.175, optim_step_time=0.033, optim0_lr0=3.315e-04, train_time=0.865
[alab02] 2024-08-28 05:01:33,783 (trainer:720) INFO: 20epoch:train:1201-1400batch: iter_time=1.869e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.499, loss_ctc=6.780, loss=3.390, backward_time=0.185, optim_step_time=0.034, optim0_lr0=3.313e-04, train_time=0.887
[alab02] 2024-08-28 05:03:00,702 (trainer:720) INFO: 20epoch:train:1401-1600batch: iter_time=2.289e-04, forward_time=0.130, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=6.999, loss=3.499, backward_time=0.178, optim_step_time=0.035, optim0_lr0=3.310e-04, train_time=0.869
[alab02] 2024-08-28 05:04:28,265 (trainer:720) INFO: 20epoch:train:1601-1800batch: iter_time=2.456e-04, forward_time=0.132, uma_reduction=0.190, text_vs_uma=0.501, loss_ctc=6.784, loss=3.392, backward_time=0.180, optim_step_time=0.035, optim0_lr0=3.308e-04, train_time=0.875
[alab02] 2024-08-28 05:05:56,542 (trainer:720) INFO: 20epoch:train:1801-2000batch: iter_time=2.052e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=6.199, loss=3.099, backward_time=0.186, optim_step_time=0.034, optim0_lr0=3.305e-04, train_time=0.882
[alab02] 2024-08-28 05:07:22,394 (trainer:720) INFO: 20epoch:train:2001-2200batch: iter_time=2.657e-04, forward_time=0.129, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=6.890, loss=3.445, backward_time=0.175, optim_step_time=0.036, optim0_lr0=3.303e-04, train_time=0.858
[alab02] 2024-08-28 05:08:48,658 (trainer:720) INFO: 20epoch:train:2201-2400batch: iter_time=2.295e-04, forward_time=0.130, uma_reduction=0.188, text_vs_uma=0.515, loss_ctc=6.690, loss=3.345, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.301e-04, train_time=0.862
[alab02] 2024-08-28 05:10:18,495 (trainer:720) INFO: 20epoch:train:2401-2600batch: iter_time=1.800e-04, forward_time=0.134, uma_reduction=0.189, text_vs_uma=0.494, loss_ctc=6.619, loss=3.309, backward_time=0.190, optim_step_time=0.034, optim0_lr0=3.298e-04, train_time=0.898
[alab02] 2024-08-28 05:11:45,840 (trainer:720) INFO: 20epoch:train:2601-2800batch: iter_time=1.807e-04, forward_time=0.130, uma_reduction=0.192, text_vs_uma=0.517, loss_ctc=6.996, loss=3.498, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.296e-04, train_time=0.873
[alab02] 2024-08-28 05:13:14,074 (trainer:720) INFO: 20epoch:train:2801-3000batch: iter_time=1.639e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.486, loss_ctc=6.246, loss=3.123, backward_time=0.188, optim_step_time=0.032, optim0_lr0=3.293e-04, train_time=0.882
[alab02] 2024-08-28 05:14:39,776 (trainer:720) INFO: 20epoch:train:3001-3200batch: iter_time=1.707e-04, forward_time=0.128, uma_reduction=0.192, text_vs_uma=0.493, loss_ctc=6.576, loss=3.288, backward_time=0.179, optim_step_time=0.032, optim0_lr0=3.291e-04, train_time=0.857
[alab02] 2024-08-28 05:16:04,964 (trainer:720) INFO: 20epoch:train:3201-3400batch: iter_time=1.680e-04, forward_time=0.127, uma_reduction=0.192, text_vs_uma=0.506, loss_ctc=6.974, loss=3.487, backward_time=0.175, optim_step_time=0.033, optim0_lr0=3.289e-04, train_time=0.852
[alab02] 2024-08-28 05:17:31,234 (trainer:720) INFO: 20epoch:train:3401-3600batch: iter_time=1.737e-04, forward_time=0.129, uma_reduction=0.189, text_vs_uma=0.505, loss_ctc=7.153, loss=3.577, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.286e-04, train_time=0.862
[alab02] 2024-08-28 05:18:56,797 (trainer:720) INFO: 20epoch:train:3601-3800batch: iter_time=1.600e-04, forward_time=0.128, uma_reduction=0.189, text_vs_uma=0.499, loss_ctc=7.061, loss=3.530, backward_time=0.174, optim_step_time=0.032, optim0_lr0=3.284e-04, train_time=0.855
[alab02] 2024-08-28 05:20:24,982 (trainer:720) INFO: 20epoch:train:3801-4000batch: iter_time=1.701e-04, forward_time=0.132, uma_reduction=0.189, text_vs_uma=0.525, loss_ctc=7.217, loss=3.608, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.282e-04, train_time=0.882
[alab02] 2024-08-28 05:21:51,786 (trainer:720) INFO: 20epoch:train:4001-4200batch: iter_time=1.728e-04, forward_time=0.130, uma_reduction=0.192, text_vs_uma=0.488, loss_ctc=6.490, loss=3.245, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.279e-04, train_time=0.868
[alab02] 2024-08-28 05:23:18,253 (trainer:720) INFO: 20epoch:train:4201-4400batch: iter_time=1.860e-04, forward_time=0.129, uma_reduction=0.191, text_vs_uma=0.494, loss_ctc=6.558, loss=3.279, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.277e-04, train_time=0.864
[alab02] 2024-08-28 05:24:46,668 (trainer:720) INFO: 20epoch:train:4401-4600batch: iter_time=1.663e-04, forward_time=0.132, uma_reduction=0.187, text_vs_uma=0.528, loss_ctc=7.435, loss=3.717, backward_time=0.184, optim_step_time=0.032, optim0_lr0=3.274e-04, train_time=0.884
[alab02] 2024-08-28 05:26:13,468 (trainer:720) INFO: 20epoch:train:4601-4800batch: iter_time=1.736e-04, forward_time=0.129, uma_reduction=0.188, text_vs_uma=0.519, loss_ctc=7.377, loss=3.689, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.272e-04, train_time=0.868
[alab02] 2024-08-28 05:27:39,937 (trainer:720) INFO: 20epoch:train:4801-5000batch: iter_time=1.706e-04, forward_time=0.130, uma_reduction=0.190, text_vs_uma=0.485, loss_ctc=6.095, loss=3.047, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.270e-04, train_time=0.864
[alab02] 2024-08-28 05:29:05,680 (trainer:720) INFO: 20epoch:train:5001-5200batch: iter_time=1.777e-04, forward_time=0.129, uma_reduction=0.188, text_vs_uma=0.505, loss_ctc=6.537, loss=3.268, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.267e-04, train_time=0.857
[alab02] 2024-08-28 05:30:32,259 (trainer:720) INFO: 20epoch:train:5201-5400batch: iter_time=1.721e-04, forward_time=0.130, uma_reduction=0.188, text_vs_uma=0.521, loss_ctc=7.082, loss=3.541, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.265e-04, train_time=0.866
[alab02] 2024-08-28 05:32:01,305 (trainer:720) INFO: 20epoch:train:5401-5600batch: iter_time=1.711e-04, forward_time=0.133, uma_reduction=0.190, text_vs_uma=0.500, loss_ctc=6.747, loss=3.374, backward_time=0.187, optim_step_time=0.033, optim0_lr0=3.263e-04, train_time=0.890
[alab02] 2024-08-28 05:33:30,261 (trainer:720) INFO: 20epoch:train:5601-5800batch: iter_time=1.806e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.504, loss_ctc=6.458, loss=3.229, backward_time=0.189, optim_step_time=0.033, optim0_lr0=3.261e-04, train_time=0.889
[alab02] 2024-08-28 05:34:58,472 (trainer:720) INFO: 20epoch:train:5801-6000batch: iter_time=1.825e-04, forward_time=0.132, uma_reduction=0.191, text_vs_uma=0.498, loss_ctc=6.712, loss=3.356, backward_time=0.183, optim_step_time=0.034, optim0_lr0=3.258e-04, train_time=0.882
[alab02] 2024-08-28 05:36:25,490 (trainer:720) INFO: 20epoch:train:6001-6200batch: iter_time=1.942e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.493, loss_ctc=6.411, loss=3.205, backward_time=0.182, optim_step_time=0.032, optim0_lr0=3.256e-04, train_time=0.870
[alab02] 2024-08-28 05:37:55,327 (trainer:720) INFO: 20epoch:train:6201-6400batch: iter_time=1.707e-04, forward_time=0.135, uma_reduction=0.191, text_vs_uma=0.493, loss_ctc=6.670, loss=3.335, backward_time=0.188, optim_step_time=0.033, optim0_lr0=3.254e-04, train_time=0.898
[alab02] 2024-08-28 05:39:21,167 (trainer:720) INFO: 20epoch:train:6401-6600batch: iter_time=1.678e-04, forward_time=0.128, uma_reduction=0.190, text_vs_uma=0.505, loss_ctc=6.658, loss=3.329, backward_time=0.180, optim_step_time=0.032, optim0_lr0=3.251e-04, train_time=0.858
[alab02] 2024-08-28 05:40:48,814 (trainer:720) INFO: 20epoch:train:6601-6800batch: iter_time=1.818e-04, forward_time=0.131, uma_reduction=0.188, text_vs_uma=0.499, loss_ctc=6.792, loss=3.396, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.249e-04, train_time=0.876
[alab02] 2024-08-28 05:42:15,989 (trainer:720) INFO: 20epoch:train:6801-7000batch: iter_time=1.702e-04, forward_time=0.130, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=7.261, loss=3.631, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.247e-04, train_time=0.872
[alab02] 2024-08-28 05:43:30,698 (trainer:338) INFO: 20epoch results: [train] iter_time=2.321e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.504, loss_ctc=6.797, loss=3.399, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.286e-04, train_time=0.872, time=51 minutes and 49.5 seconds, total_count=142520, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.159, text_vs_uma=0.681, loss_ctc=4.504, cer_ctc=0.120, cer=0.120, loss=4.504, time=6.15 seconds, total_count=520, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.38 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 05:43:37,584 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 05:43:37,590 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/10epoch.pth
[alab02] 2024-08-28 05:43:37,591 (trainer:272) INFO: 21/150epoch started. Estimated time to finish: 5 days, 2 hours and 7 minutes
[alab02] 2024-08-28 05:45:06,107 (trainer:720) INFO: 21epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=6.346, loss=3.173, backward_time=0.185, optim_step_time=0.032, optim0_lr0=3.243e-04, train_time=0.885
[alab02] 2024-08-28 05:46:31,522 (trainer:720) INFO: 21epoch:train:201-400batch: iter_time=1.925e-04, forward_time=0.127, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=6.408, loss=3.204, backward_time=0.178, optim_step_time=0.032, optim0_lr0=3.241e-04, train_time=0.854
[alab02] 2024-08-28 05:47:59,838 (trainer:720) INFO: 21epoch:train:401-600batch: iter_time=2.163e-04, forward_time=0.134, uma_reduction=0.189, text_vs_uma=0.515, loss_ctc=6.957, loss=3.479, backward_time=0.180, optim_step_time=0.034, optim0_lr0=3.238e-04, train_time=0.883
[alab02] 2024-08-28 05:49:28,415 (trainer:720) INFO: 21epoch:train:601-800batch: iter_time=1.987e-04, forward_time=0.132, uma_reduction=0.188, text_vs_uma=0.500, loss_ctc=6.790, loss=3.395, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.236e-04, train_time=0.886
[alab02] 2024-08-28 05:50:57,519 (trainer:720) INFO: 21epoch:train:801-1000batch: iter_time=1.838e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.507, loss_ctc=6.677, loss=3.338, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.234e-04, train_time=0.891
[alab02] 2024-08-28 05:52:23,793 (trainer:720) INFO: 21epoch:train:1001-1200batch: iter_time=1.830e-04, forward_time=0.129, uma_reduction=0.190, text_vs_uma=0.512, loss_ctc=6.689, loss=3.344, backward_time=0.177, optim_step_time=0.032, optim0_lr0=3.232e-04, train_time=0.862
[alab02] 2024-08-28 05:53:49,134 (trainer:720) INFO: 21epoch:train:1201-1400batch: iter_time=2.479e-04, forward_time=0.128, uma_reduction=0.190, text_vs_uma=0.517, loss_ctc=6.886, loss=3.443, backward_time=0.174, optim_step_time=0.033, optim0_lr0=3.229e-04, train_time=0.853
[alab02] 2024-08-28 05:55:16,735 (trainer:720) INFO: 21epoch:train:1401-1600batch: iter_time=1.781e-04, forward_time=0.131, uma_reduction=0.191, text_vs_uma=0.514, loss_ctc=6.490, loss=3.245, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.227e-04, train_time=0.876
[alab02] 2024-08-28 05:56:43,663 (trainer:720) INFO: 21epoch:train:1601-1800batch: iter_time=1.862e-04, forward_time=0.130, uma_reduction=0.193, text_vs_uma=0.495, loss_ctc=6.218, loss=3.109, backward_time=0.182, optim_step_time=0.032, optim0_lr0=3.225e-04, train_time=0.869
[alab02] 2024-08-28 05:58:12,706 (trainer:720) INFO: 21epoch:train:1801-2000batch: iter_time=1.756e-04, forward_time=0.133, uma_reduction=0.190, text_vs_uma=0.508, loss_ctc=7.068, loss=3.534, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.223e-04, train_time=0.890
[alab02] 2024-08-28 05:59:40,548 (trainer:720) INFO: 21epoch:train:2001-2200batch: iter_time=1.775e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.501, loss_ctc=6.334, loss=3.167, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.221e-04, train_time=0.878
[alab02] 2024-08-28 06:01:08,710 (trainer:720) INFO: 21epoch:train:2201-2400batch: iter_time=1.725e-04, forward_time=0.132, uma_reduction=0.193, text_vs_uma=0.499, loss_ctc=6.400, loss=3.200, backward_time=0.186, optim_step_time=0.032, optim0_lr0=3.218e-04, train_time=0.881
[alab02] 2024-08-28 06:02:36,782 (trainer:720) INFO: 21epoch:train:2401-2600batch: iter_time=1.909e-04, forward_time=0.132, uma_reduction=0.190, text_vs_uma=0.499, loss_ctc=6.668, loss=3.334, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.216e-04, train_time=0.880
[alab02] 2024-08-28 06:04:02,911 (trainer:720) INFO: 21epoch:train:2601-2800batch: iter_time=1.900e-04, forward_time=0.129, uma_reduction=0.189, text_vs_uma=0.500, loss_ctc=6.659, loss=3.329, backward_time=0.177, optim_step_time=0.034, optim0_lr0=3.214e-04, train_time=0.861
[alab02] 2024-08-28 06:05:29,300 (trainer:720) INFO: 21epoch:train:2801-3000batch: iter_time=1.895e-04, forward_time=0.128, uma_reduction=0.189, text_vs_uma=0.518, loss_ctc=7.320, loss=3.660, backward_time=0.175, optim_step_time=0.034, optim0_lr0=3.212e-04, train_time=0.864
[alab02] 2024-08-28 06:06:58,211 (trainer:720) INFO: 21epoch:train:3001-3200batch: iter_time=2.003e-04, forward_time=0.134, uma_reduction=0.191, text_vs_uma=0.504, loss_ctc=6.401, loss=3.200, backward_time=0.188, optim_step_time=0.033, optim0_lr0=3.209e-04, train_time=0.889
[alab02] 2024-08-28 06:08:26,171 (trainer:720) INFO: 21epoch:train:3201-3400batch: iter_time=2.001e-04, forward_time=0.132, uma_reduction=0.187, text_vs_uma=0.512, loss_ctc=6.973, loss=3.487, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.207e-04, train_time=0.879
[alab02] 2024-08-28 06:09:54,167 (trainer:720) INFO: 21epoch:train:3401-3600batch: iter_time=1.803e-04, forward_time=0.133, uma_reduction=0.188, text_vs_uma=0.498, loss_ctc=6.178, loss=3.089, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.205e-04, train_time=0.880
[alab02] 2024-08-28 06:11:20,809 (trainer:720) INFO: 21epoch:train:3601-3800batch: iter_time=1.843e-04, forward_time=0.130, uma_reduction=0.189, text_vs_uma=0.507, loss_ctc=6.582, loss=3.291, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.203e-04, train_time=0.866
[alab02] 2024-08-28 06:12:48,521 (trainer:720) INFO: 21epoch:train:3801-4000batch: iter_time=1.839e-04, forward_time=0.132, uma_reduction=0.190, text_vs_uma=0.498, loss_ctc=6.336, loss=3.168, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.201e-04, train_time=0.877
[alab02] 2024-08-28 06:14:18,105 (trainer:720) INFO: 21epoch:train:4001-4200batch: iter_time=1.896e-04, forward_time=0.136, uma_reduction=0.189, text_vs_uma=0.501, loss_ctc=6.400, loss=3.200, backward_time=0.188, optim_step_time=0.035, optim0_lr0=3.198e-04, train_time=0.896
[alab02] 2024-08-28 06:15:46,490 (trainer:720) INFO: 21epoch:train:4201-4400batch: iter_time=2.704e-04, forward_time=0.133, uma_reduction=0.187, text_vs_uma=0.505, loss_ctc=6.405, loss=3.203, backward_time=0.184, optim_step_time=0.034, optim0_lr0=3.196e-04, train_time=0.884
[alab02] 2024-08-28 06:17:14,281 (trainer:720) INFO: 21epoch:train:4401-4600batch: iter_time=1.860e-04, forward_time=0.132, uma_reduction=0.186, text_vs_uma=0.497, loss_ctc=6.445, loss=3.222, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.194e-04, train_time=0.878
[alab02] 2024-08-28 06:18:42,496 (trainer:720) INFO: 21epoch:train:4601-4800batch: iter_time=1.821e-04, forward_time=0.132, uma_reduction=0.188, text_vs_uma=0.507, loss_ctc=6.815, loss=3.407, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.192e-04, train_time=0.882
[alab02] 2024-08-28 06:20:06,766 (trainer:720) INFO: 21epoch:train:4801-5000batch: iter_time=1.740e-04, forward_time=0.125, uma_reduction=0.191, text_vs_uma=0.502, loss_ctc=6.969, loss=3.485, backward_time=0.174, optim_step_time=0.032, optim0_lr0=3.190e-04, train_time=0.842
[alab02] 2024-08-28 06:21:34,977 (trainer:720) INFO: 21epoch:train:5001-5200batch: iter_time=1.693e-04, forward_time=0.133, uma_reduction=0.193, text_vs_uma=0.502, loss_ctc=6.336, loss=3.168, backward_time=0.186, optim_step_time=0.032, optim0_lr0=3.188e-04, train_time=0.882
[alab02] 2024-08-28 06:23:03,025 (trainer:720) INFO: 21epoch:train:5201-5400batch: iter_time=1.808e-04, forward_time=0.132, uma_reduction=0.193, text_vs_uma=0.495, loss_ctc=6.214, loss=3.107, backward_time=0.186, optim_step_time=0.033, optim0_lr0=3.185e-04, train_time=0.880
[alab02] 2024-08-28 06:24:30,212 (trainer:720) INFO: 21epoch:train:5401-5600batch: iter_time=1.922e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.495, loss_ctc=6.444, loss=3.222, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.183e-04, train_time=0.872
[alab02] 2024-08-28 06:25:57,604 (trainer:720) INFO: 21epoch:train:5601-5800batch: iter_time=1.703e-04, forward_time=0.130, uma_reduction=0.192, text_vs_uma=0.499, loss_ctc=6.602, loss=3.301, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.181e-04, train_time=0.874
[alab02] 2024-08-28 06:27:24,487 (trainer:720) INFO: 21epoch:train:5801-6000batch: iter_time=1.744e-04, forward_time=0.130, uma_reduction=0.191, text_vs_uma=0.497, loss_ctc=6.660, loss=3.330, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.179e-04, train_time=0.869
[alab02] 2024-08-28 06:28:51,684 (trainer:720) INFO: 21epoch:train:6001-6200batch: iter_time=1.791e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.498, loss_ctc=6.475, loss=3.238, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.177e-04, train_time=0.872
[alab02] 2024-08-28 06:30:18,722 (trainer:720) INFO: 21epoch:train:6201-6400batch: iter_time=1.793e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.504, loss_ctc=6.805, loss=3.402, backward_time=0.176, optim_step_time=0.035, optim0_lr0=3.175e-04, train_time=0.870
[alab02] 2024-08-28 06:31:46,552 (trainer:720) INFO: 21epoch:train:6401-6600batch: iter_time=1.902e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.499, loss_ctc=6.529, loss=3.265, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.173e-04, train_time=0.878
[alab02] 2024-08-28 06:33:15,675 (trainer:720) INFO: 21epoch:train:6601-6800batch: iter_time=1.873e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.502, loss_ctc=6.757, loss=3.378, backward_time=0.184, optim_step_time=0.035, optim0_lr0=3.171e-04, train_time=0.891
[alab02] 2024-08-28 06:34:41,693 (trainer:720) INFO: 21epoch:train:6801-7000batch: iter_time=1.741e-04, forward_time=0.130, uma_reduction=0.192, text_vs_uma=0.498, loss_ctc=6.284, loss=3.142, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.168e-04, train_time=0.860
[alab02] 2024-08-28 06:35:57,809 (trainer:338) INFO: 21epoch results: [train] iter_time=2.334e-04, forward_time=0.131, uma_reduction=0.190, text_vs_uma=0.503, loss_ctc=6.571, loss=3.285, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.205e-04, train_time=0.875, time=51 minutes and 59.38 seconds, total_count=149646, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.167, text_vs_uma=0.651, loss_ctc=4.606, cer_ctc=0.111, cer=0.111, loss=4.606, time=6.22 seconds, total_count=546, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.61 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 06:36:04,596 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 06:36:04,606 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/11epoch.pth
[alab02] 2024-08-28 06:36:04,606 (trainer:272) INFO: 22/150epoch started. Estimated time to finish: 5 days, 46 minutes and 37.8 seconds
[alab02] 2024-08-28 06:37:34,697 (trainer:720) INFO: 22epoch:train:1-200batch: iter_time=0.003, forward_time=0.134, uma_reduction=0.190, text_vs_uma=0.500, loss_ctc=6.707, loss=3.354, backward_time=0.185, optim_step_time=0.034, optim0_lr0=3.165e-04, train_time=0.900
[alab02] 2024-08-28 06:39:01,228 (trainer:720) INFO: 22epoch:train:201-400batch: iter_time=2.374e-04, forward_time=0.132, uma_reduction=0.191, text_vs_uma=0.514, loss_ctc=6.953, loss=3.476, backward_time=0.174, optim_step_time=0.034, optim0_lr0=3.163e-04, train_time=0.865
[alab02] 2024-08-28 06:40:28,152 (trainer:720) INFO: 22epoch:train:401-600batch: iter_time=2.229e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.492, loss_ctc=6.191, loss=3.095, backward_time=0.178, optim_step_time=0.035, optim0_lr0=3.161e-04, train_time=0.869
[alab02] 2024-08-28 06:41:56,974 (trainer:720) INFO: 22epoch:train:601-800batch: iter_time=2.231e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.498, loss_ctc=6.583, loss=3.292, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.159e-04, train_time=0.888
[alab02] 2024-08-28 06:43:24,152 (trainer:720) INFO: 22epoch:train:801-1000batch: iter_time=1.880e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.506, loss_ctc=6.815, loss=3.408, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.157e-04, train_time=0.872
[alab02] 2024-08-28 06:44:49,418 (trainer:720) INFO: 22epoch:train:1001-1200batch: iter_time=1.918e-04, forward_time=0.128, uma_reduction=0.194, text_vs_uma=0.481, loss_ctc=5.970, loss=2.985, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.154e-04, train_time=0.852
[alab02] 2024-08-28 06:46:19,100 (trainer:720) INFO: 22epoch:train:1201-1400batch: iter_time=1.875e-04, forward_time=0.135, uma_reduction=0.193, text_vs_uma=0.489, loss_ctc=6.227, loss=3.114, backward_time=0.188, optim_step_time=0.033, optim0_lr0=3.152e-04, train_time=0.897
[alab02] 2024-08-28 06:47:46,831 (trainer:720) INFO: 22epoch:train:1401-1600batch: iter_time=1.784e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.495, loss_ctc=6.368, loss=3.184, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.150e-04, train_time=0.877
[alab02] 2024-08-28 06:49:14,822 (trainer:720) INFO: 22epoch:train:1601-1800batch: iter_time=1.765e-04, forward_time=0.132, uma_reduction=0.191, text_vs_uma=0.514, loss_ctc=6.900, loss=3.450, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.148e-04, train_time=0.880
[alab02] 2024-08-28 06:50:42,018 (trainer:720) INFO: 22epoch:train:1801-2000batch: iter_time=1.839e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.489, loss_ctc=6.128, loss=3.064, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.146e-04, train_time=0.872
[alab02] 2024-08-28 06:52:09,937 (trainer:720) INFO: 22epoch:train:2001-2200batch: iter_time=1.771e-04, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.502, loss_ctc=6.840, loss=3.420, backward_time=0.182, optim_step_time=0.032, optim0_lr0=3.144e-04, train_time=0.879
[alab02] 2024-08-28 06:53:37,213 (trainer:720) INFO: 22epoch:train:2201-2400batch: iter_time=1.888e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.511, loss_ctc=6.675, loss=3.337, backward_time=0.180, optim_step_time=0.034, optim0_lr0=3.142e-04, train_time=0.873
[alab02] 2024-08-28 06:55:04,825 (trainer:720) INFO: 22epoch:train:2401-2600batch: iter_time=1.950e-04, forward_time=0.131, uma_reduction=0.192, text_vs_uma=0.512, loss_ctc=6.562, loss=3.281, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.140e-04, train_time=0.876
[alab02] 2024-08-28 06:56:34,043 (trainer:720) INFO: 22epoch:train:2601-2800batch: iter_time=1.878e-04, forward_time=0.134, uma_reduction=0.192, text_vs_uma=0.502, loss_ctc=6.441, loss=3.221, backward_time=0.186, optim_step_time=0.033, optim0_lr0=3.138e-04, train_time=0.892
[alab02] 2024-08-28 06:58:02,458 (trainer:720) INFO: 22epoch:train:2801-3000batch: iter_time=1.917e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.499, loss_ctc=6.398, loss=3.199, backward_time=0.184, optim_step_time=0.035, optim0_lr0=3.136e-04, train_time=0.884
[alab02] 2024-08-28 06:59:28,772 (trainer:720) INFO: 22epoch:train:3001-3200batch: iter_time=2.014e-04, forward_time=0.130, uma_reduction=0.195, text_vs_uma=0.497, loss_ctc=6.950, loss=3.475, backward_time=0.174, optim_step_time=0.035, optim0_lr0=3.134e-04, train_time=0.863
[alab02] 2024-08-28 07:00:59,361 (trainer:720) INFO: 22epoch:train:3201-3400batch: iter_time=2.610e-04, forward_time=0.137, uma_reduction=0.191, text_vs_uma=0.502, loss_ctc=6.595, loss=3.298, backward_time=0.187, optim_step_time=0.036, optim0_lr0=3.132e-04, train_time=0.906
[alab02] 2024-08-28 07:02:27,329 (trainer:720) INFO: 22epoch:train:3401-3600batch: iter_time=2.563e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.504, loss_ctc=7.053, loss=3.527, backward_time=0.181, optim_step_time=0.035, optim0_lr0=3.130e-04, train_time=0.879
[alab02] 2024-08-28 07:03:57,373 (trainer:720) INFO: 22epoch:train:3601-3800batch: iter_time=2.833e-04, forward_time=0.136, uma_reduction=0.196, text_vs_uma=0.498, loss_ctc=6.846, loss=3.423, backward_time=0.187, optim_step_time=0.036, optim0_lr0=3.128e-04, train_time=0.900
[alab02] 2024-08-28 07:05:26,099 (trainer:720) INFO: 22epoch:train:3801-4000batch: iter_time=1.825e-04, forward_time=0.134, uma_reduction=0.195, text_vs_uma=0.484, loss_ctc=6.540, loss=3.270, backward_time=0.184, optim_step_time=0.034, optim0_lr0=3.126e-04, train_time=0.887
[alab02] 2024-08-28 07:06:53,035 (trainer:720) INFO: 22epoch:train:4001-4200batch: iter_time=1.791e-04, forward_time=0.130, uma_reduction=0.193, text_vs_uma=0.497, loss_ctc=6.688, loss=3.344, backward_time=0.181, optim_step_time=0.032, optim0_lr0=3.123e-04, train_time=0.869
[alab02] 2024-08-28 07:08:18,653 (trainer:720) INFO: 22epoch:train:4201-4400batch: iter_time=1.848e-04, forward_time=0.128, uma_reduction=0.195, text_vs_uma=0.499, loss_ctc=6.493, loss=3.246, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.121e-04, train_time=0.856
[alab02] 2024-08-28 07:09:46,889 (trainer:720) INFO: 22epoch:train:4401-4600batch: iter_time=1.867e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.502, loss_ctc=7.024, loss=3.512, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.119e-04, train_time=0.882
[alab02] 2024-08-28 07:11:14,508 (trainer:720) INFO: 22epoch:train:4601-4800batch: iter_time=1.818e-04, forward_time=0.132, uma_reduction=0.195, text_vs_uma=0.492, loss_ctc=6.431, loss=3.215, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.117e-04, train_time=0.876
[alab02] 2024-08-28 07:12:42,618 (trainer:720) INFO: 22epoch:train:4801-5000batch: iter_time=1.944e-04, forward_time=0.132, uma_reduction=0.195, text_vs_uma=0.498, loss_ctc=6.412, loss=3.206, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.115e-04, train_time=0.881
[alab02] 2024-08-28 07:14:09,418 (trainer:720) INFO: 22epoch:train:5001-5200batch: iter_time=1.691e-04, forward_time=0.129, uma_reduction=0.193, text_vs_uma=0.515, loss_ctc=7.304, loss=3.652, backward_time=0.174, optim_step_time=0.034, optim0_lr0=3.113e-04, train_time=0.868
[alab02] 2024-08-28 07:15:36,613 (trainer:720) INFO: 22epoch:train:5201-5400batch: iter_time=1.736e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.504, loss_ctc=6.884, loss=3.442, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.111e-04, train_time=0.872
[alab02] 2024-08-28 07:17:03,129 (trainer:720) INFO: 22epoch:train:5401-5600batch: iter_time=1.686e-04, forward_time=0.129, uma_reduction=0.193, text_vs_uma=0.491, loss_ctc=6.300, loss=3.150, backward_time=0.179, optim_step_time=0.032, optim0_lr0=3.109e-04, train_time=0.865
[alab02] 2024-08-28 07:18:32,184 (trainer:720) INFO: 22epoch:train:5601-5800batch: iter_time=1.806e-04, forward_time=0.134, uma_reduction=0.195, text_vs_uma=0.486, loss_ctc=5.968, loss=2.984, backward_time=0.189, optim_step_time=0.033, optim0_lr0=3.107e-04, train_time=0.890
[alab02] 2024-08-28 07:20:00,589 (trainer:720) INFO: 22epoch:train:5801-6000batch: iter_time=1.686e-04, forward_time=0.133, uma_reduction=0.193, text_vs_uma=0.496, loss_ctc=6.806, loss=3.403, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.105e-04, train_time=0.884
[alab02] 2024-08-28 07:21:26,501 (trainer:720) INFO: 22epoch:train:6001-6200batch: iter_time=1.927e-04, forward_time=0.129, uma_reduction=0.195, text_vs_uma=0.492, loss_ctc=6.265, loss=3.132, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.103e-04, train_time=0.859
[alab02] 2024-08-28 07:22:55,052 (trainer:720) INFO: 22epoch:train:6201-6400batch: iter_time=1.782e-04, forward_time=0.134, uma_reduction=0.195, text_vs_uma=0.483, loss_ctc=6.600, loss=3.300, backward_time=0.183, optim_step_time=0.034, optim0_lr0=3.101e-04, train_time=0.885
[alab02] 2024-08-28 07:24:24,093 (trainer:720) INFO: 22epoch:train:6401-6600batch: iter_time=1.848e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.495, loss_ctc=6.718, loss=3.359, backward_time=0.184, optim_step_time=0.035, optim0_lr0=3.099e-04, train_time=0.890
[alab02] 2024-08-28 07:25:49,692 (trainer:720) INFO: 22epoch:train:6601-6800batch: iter_time=1.735e-04, forward_time=0.128, uma_reduction=0.194, text_vs_uma=0.495, loss_ctc=6.410, loss=3.205, backward_time=0.174, optim_step_time=0.034, optim0_lr0=3.097e-04, train_time=0.856
[alab02] 2024-08-28 07:27:18,045 (trainer:720) INFO: 22epoch:train:6801-7000batch: iter_time=1.731e-04, forward_time=0.134, uma_reduction=0.194, text_vs_uma=0.489, loss_ctc=6.761, loss=3.381, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.095e-04, train_time=0.883
[alab02] 2024-08-28 07:28:34,385 (trainer:338) INFO: 22epoch results: [train] iter_time=2.711e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.498, loss_ctc=6.586, loss=3.293, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.129e-04, train_time=0.878, time=52 minutes and 9.3 seconds, total_count=156772, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.169, text_vs_uma=0.641, loss_ctc=4.447, cer_ctc=0.120, cer=0.120, loss=4.447, time=6.3 seconds, total_count=572, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.17 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 07:28:40,745 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 07:28:40,811 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/14epoch.pth
[alab02] 2024-08-28 07:28:40,812 (trainer:272) INFO: 23/150epoch started. Estimated time to finish: 4 days, 23 hours and 29 minutes
[alab02] 2024-08-28 07:30:08,371 (trainer:720) INFO: 23epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.194, text_vs_uma=0.494, loss_ctc=6.179, loss=3.089, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.092e-04, train_time=0.875
[alab02] 2024-08-28 07:31:36,425 (trainer:720) INFO: 23epoch:train:201-400batch: iter_time=2.321e-04, forward_time=0.135, uma_reduction=0.196, text_vs_uma=0.492, loss_ctc=6.656, loss=3.328, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.090e-04, train_time=0.880
[alab02] 2024-08-28 07:33:04,860 (trainer:720) INFO: 23epoch:train:401-600batch: iter_time=1.888e-04, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.503, loss_ctc=6.811, loss=3.405, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.088e-04, train_time=0.884
[alab02] 2024-08-28 07:34:32,863 (trainer:720) INFO: 23epoch:train:601-800batch: iter_time=1.836e-04, forward_time=0.132, uma_reduction=0.193, text_vs_uma=0.507, loss_ctc=6.582, loss=3.291, backward_time=0.183, optim_step_time=0.034, optim0_lr0=3.086e-04, train_time=0.880
[alab02] 2024-08-28 07:35:58,453 (trainer:720) INFO: 23epoch:train:801-1000batch: iter_time=1.832e-04, forward_time=0.129, uma_reduction=0.194, text_vs_uma=0.491, loss_ctc=6.128, loss=3.064, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.084e-04, train_time=0.856
[alab02] 2024-08-28 07:37:26,752 (trainer:720) INFO: 23epoch:train:1001-1200batch: iter_time=1.848e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.494, loss_ctc=6.726, loss=3.363, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.082e-04, train_time=0.883
[alab02] 2024-08-28 07:38:53,841 (trainer:720) INFO: 23epoch:train:1201-1400batch: iter_time=1.726e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.492, loss_ctc=6.540, loss=3.270, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.080e-04, train_time=0.871
[alab02] 2024-08-28 07:40:21,765 (trainer:720) INFO: 23epoch:train:1401-1600batch: iter_time=1.710e-04, forward_time=0.132, uma_reduction=0.197, text_vs_uma=0.483, loss_ctc=6.881, loss=3.440, backward_time=0.180, optim_step_time=0.033, optim0_lr0=3.079e-04, train_time=0.879
[alab02] 2024-08-28 07:41:50,343 (trainer:720) INFO: 23epoch:train:1601-1800batch: iter_time=1.780e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.489, loss_ctc=6.624, loss=3.312, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.077e-04, train_time=0.886
[alab02] 2024-08-28 07:43:18,319 (trainer:720) INFO: 23epoch:train:1801-2000batch: iter_time=1.819e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.499, loss_ctc=6.580, loss=3.290, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.075e-04, train_time=0.880
[alab02] 2024-08-28 07:44:44,315 (trainer:720) INFO: 23epoch:train:2001-2200batch: iter_time=1.819e-04, forward_time=0.129, uma_reduction=0.196, text_vs_uma=0.486, loss_ctc=6.331, loss=3.165, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.073e-04, train_time=0.860
[alab02] 2024-08-28 07:46:12,103 (trainer:720) INFO: 23epoch:train:2201-2400batch: iter_time=1.827e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.484, loss_ctc=6.486, loss=3.243, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.071e-04, train_time=0.878
[alab02] 2024-08-28 07:47:36,801 (trainer:720) INFO: 23epoch:train:2401-2600batch: iter_time=1.773e-04, forward_time=0.127, uma_reduction=0.196, text_vs_uma=0.491, loss_ctc=6.409, loss=3.205, backward_time=0.174, optim_step_time=0.032, optim0_lr0=3.069e-04, train_time=0.847
[alab02] 2024-08-28 07:49:05,336 (trainer:720) INFO: 23epoch:train:2601-2800batch: iter_time=1.802e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.505, loss_ctc=6.866, loss=3.433, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.067e-04, train_time=0.885
[alab02] 2024-08-28 07:50:33,215 (trainer:720) INFO: 23epoch:train:2801-3000batch: iter_time=1.760e-04, forward_time=0.133, uma_reduction=0.191, text_vs_uma=0.490, loss_ctc=6.653, loss=3.326, backward_time=0.182, optim_step_time=0.032, optim0_lr0=3.065e-04, train_time=0.879
[alab02] 2024-08-28 07:52:01,363 (trainer:720) INFO: 23epoch:train:3001-3200batch: iter_time=1.724e-04, forward_time=0.132, uma_reduction=0.193, text_vs_uma=0.502, loss_ctc=6.702, loss=3.351, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.063e-04, train_time=0.881
[alab02] 2024-08-28 07:53:28,850 (trainer:720) INFO: 23epoch:train:3201-3400batch: iter_time=1.748e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.484, loss_ctc=6.064, loss=3.032, backward_time=0.184, optim_step_time=0.033, optim0_lr0=3.061e-04, train_time=0.875
[alab02] 2024-08-28 07:54:55,536 (trainer:720) INFO: 23epoch:train:3401-3600batch: iter_time=1.736e-04, forward_time=0.130, uma_reduction=0.195, text_vs_uma=0.487, loss_ctc=6.448, loss=3.224, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.059e-04, train_time=0.867
[alab02] 2024-08-28 07:56:22,839 (trainer:720) INFO: 23epoch:train:3601-3800batch: iter_time=1.956e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.491, loss_ctc=6.634, loss=3.317, backward_time=0.178, optim_step_time=0.034, optim0_lr0=3.057e-04, train_time=0.873
[alab02] 2024-08-28 07:57:51,599 (trainer:720) INFO: 23epoch:train:3801-4000batch: iter_time=1.983e-04, forward_time=0.133, uma_reduction=0.195, text_vs_uma=0.480, loss_ctc=6.612, loss=3.306, backward_time=0.183, optim_step_time=0.035, optim0_lr0=3.055e-04, train_time=0.887
[alab02] 2024-08-28 07:59:18,239 (trainer:720) INFO: 23epoch:train:4001-4200batch: iter_time=1.973e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.484, loss_ctc=6.243, loss=3.122, backward_time=0.180, optim_step_time=0.036, optim0_lr0=3.054e-04, train_time=0.866
[alab02] 2024-08-28 08:00:49,010 (trainer:720) INFO: 23epoch:train:4201-4400batch: iter_time=3.191e-04, forward_time=0.138, uma_reduction=0.195, text_vs_uma=0.480, loss_ctc=6.012, loss=3.006, backward_time=0.192, optim_step_time=0.039, optim0_lr0=3.052e-04, train_time=0.907
[alab02] 2024-08-28 08:02:16,812 (trainer:720) INFO: 23epoch:train:4401-4600batch: iter_time=2.123e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.500, loss_ctc=6.739, loss=3.369, backward_time=0.181, optim_step_time=0.034, optim0_lr0=3.050e-04, train_time=0.878
[alab02] 2024-08-28 08:03:43,357 (trainer:720) INFO: 23epoch:train:4601-4800batch: iter_time=1.903e-04, forward_time=0.130, uma_reduction=0.198, text_vs_uma=0.489, loss_ctc=6.456, loss=3.228, backward_time=0.176, optim_step_time=0.033, optim0_lr0=3.048e-04, train_time=0.865
[alab02] 2024-08-28 08:05:11,189 (trainer:720) INFO: 23epoch:train:4801-5000batch: iter_time=1.825e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.551, loss=3.275, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.046e-04, train_time=0.878
[alab02] 2024-08-28 08:06:37,200 (trainer:720) INFO: 23epoch:train:5001-5200batch: iter_time=2.072e-04, forward_time=0.129, uma_reduction=0.201, text_vs_uma=0.485, loss_ctc=6.205, loss=3.102, backward_time=0.179, optim_step_time=0.034, optim0_lr0=3.044e-04, train_time=0.860
[alab02] 2024-08-28 08:08:03,146 (trainer:720) INFO: 23epoch:train:5201-5400batch: iter_time=1.768e-04, forward_time=0.129, uma_reduction=0.195, text_vs_uma=0.477, loss_ctc=6.044, loss=3.022, backward_time=0.178, optim_step_time=0.034, optim0_lr0=3.042e-04, train_time=0.859
[alab02] 2024-08-28 08:09:31,213 (trainer:720) INFO: 23epoch:train:5401-5600batch: iter_time=1.936e-04, forward_time=0.133, uma_reduction=0.197, text_vs_uma=0.485, loss_ctc=6.579, loss=3.289, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.040e-04, train_time=0.880
[alab02] 2024-08-28 08:10:59,562 (trainer:720) INFO: 23epoch:train:5601-5800batch: iter_time=1.804e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.500, loss_ctc=6.852, loss=3.426, backward_time=0.182, optim_step_time=0.034, optim0_lr0=3.038e-04, train_time=0.883
[alab02] 2024-08-28 08:12:26,676 (trainer:720) INFO: 23epoch:train:5801-6000batch: iter_time=1.696e-04, forward_time=0.130, uma_reduction=0.193, text_vs_uma=0.487, loss_ctc=6.450, loss=3.225, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.037e-04, train_time=0.871
[alab02] 2024-08-28 08:13:53,497 (trainer:720) INFO: 23epoch:train:6001-6200batch: iter_time=1.738e-04, forward_time=0.130, uma_reduction=0.196, text_vs_uma=0.482, loss_ctc=6.197, loss=3.099, backward_time=0.182, optim_step_time=0.032, optim0_lr0=3.035e-04, train_time=0.868
[alab02] 2024-08-28 08:15:21,060 (trainer:720) INFO: 23epoch:train:6201-6400batch: iter_time=1.632e-04, forward_time=0.131, uma_reduction=0.198, text_vs_uma=0.491, loss_ctc=6.639, loss=3.319, backward_time=0.181, optim_step_time=0.032, optim0_lr0=3.033e-04, train_time=0.875
[alab02] 2024-08-28 08:16:48,840 (trainer:720) INFO: 23epoch:train:6401-6600batch: iter_time=1.713e-04, forward_time=0.131, uma_reduction=0.199, text_vs_uma=0.474, loss_ctc=6.233, loss=3.117, backward_time=0.185, optim_step_time=0.032, optim0_lr0=3.031e-04, train_time=0.878
[alab02] 2024-08-28 08:18:15,697 (trainer:720) INFO: 23epoch:train:6601-6800batch: iter_time=1.631e-04, forward_time=0.130, uma_reduction=0.198, text_vs_uma=0.484, loss_ctc=6.447, loss=3.223, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.029e-04, train_time=0.868
[alab02] 2024-08-28 08:19:42,682 (trainer:720) INFO: 23epoch:train:6801-7000batch: iter_time=1.667e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.490, loss_ctc=6.520, loss=3.260, backward_time=0.182, optim_step_time=0.033, optim0_lr0=3.027e-04, train_time=0.870
[alab02] 2024-08-28 08:20:57,737 (trainer:338) INFO: 23epoch results: [train] iter_time=2.482e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.490, loss_ctc=6.488, loss=3.244, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.059e-04, train_time=0.875, time=51 minutes and 57.72 seconds, total_count=163898, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.180, text_vs_uma=0.604, loss_ctc=4.421, cer_ctc=0.112, cer=0.112, loss=4.421, time=5.9 seconds, total_count=598, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.3 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 08:21:03,260 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 08:21:03,270 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/12epoch.pth
[alab02] 2024-08-28 08:21:03,271 (trainer:272) INFO: 24/150epoch started. Estimated time to finish: 4 days, 22 hours and 13 minutes
[alab02] 2024-08-28 08:22:30,948 (trainer:720) INFO: 24epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.500, loss_ctc=6.669, loss=3.334, backward_time=0.177, optim_step_time=0.033, optim0_lr0=3.024e-04, train_time=0.876
[alab02] 2024-08-28 08:23:59,205 (trainer:720) INFO: 24epoch:train:201-400batch: iter_time=2.026e-04, forward_time=0.133, uma_reduction=0.200, text_vs_uma=0.475, loss_ctc=5.968, loss=2.984, backward_time=0.185, optim_step_time=0.034, optim0_lr0=3.022e-04, train_time=0.882
[alab02] 2024-08-28 08:25:26,980 (trainer:720) INFO: 24epoch:train:401-600batch: iter_time=1.968e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.467, loss_ctc=6.330, loss=3.165, backward_time=0.182, optim_step_time=0.035, optim0_lr0=3.021e-04, train_time=0.877
[alab02] 2024-08-28 08:26:53,819 (trainer:720) INFO: 24epoch:train:601-800batch: iter_time=1.851e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.476, loss_ctc=6.135, loss=3.067, backward_time=0.181, optim_step_time=0.033, optim0_lr0=3.019e-04, train_time=0.868
[alab02] 2024-08-28 08:28:23,276 (trainer:720) INFO: 24epoch:train:801-1000batch: iter_time=1.778e-04, forward_time=0.134, uma_reduction=0.196, text_vs_uma=0.487, loss_ctc=6.497, loss=3.249, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.017e-04, train_time=0.894
[alab02] 2024-08-28 08:29:48,687 (trainer:720) INFO: 24epoch:train:1001-1200batch: iter_time=1.950e-04, forward_time=0.129, uma_reduction=0.201, text_vs_uma=0.474, loss_ctc=5.952, loss=2.976, backward_time=0.178, optim_step_time=0.034, optim0_lr0=3.015e-04, train_time=0.854
[alab02] 2024-08-28 08:31:15,415 (trainer:720) INFO: 24epoch:train:1201-1400batch: iter_time=1.822e-04, forward_time=0.130, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=6.476, loss=3.238, backward_time=0.179, optim_step_time=0.033, optim0_lr0=3.013e-04, train_time=0.867
[alab02] 2024-08-28 08:32:43,731 (trainer:720) INFO: 24epoch:train:1401-1600batch: iter_time=2.061e-04, forward_time=0.132, uma_reduction=0.195, text_vs_uma=0.490, loss_ctc=6.565, loss=3.283, backward_time=0.183, optim_step_time=0.033, optim0_lr0=3.011e-04, train_time=0.883
[alab02] 2024-08-28 08:34:12,952 (trainer:720) INFO: 24epoch:train:1601-1800batch: iter_time=1.755e-04, forward_time=0.134, uma_reduction=0.195, text_vs_uma=0.483, loss_ctc=6.410, loss=3.205, backward_time=0.187, optim_step_time=0.033, optim0_lr0=3.010e-04, train_time=0.892
[alab02] 2024-08-28 08:35:39,789 (trainer:720) INFO: 24epoch:train:1801-2000batch: iter_time=1.757e-04, forward_time=0.130, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.712, loss=3.356, backward_time=0.178, optim_step_time=0.033, optim0_lr0=3.008e-04, train_time=0.868
[alab02] 2024-08-28 08:37:09,044 (trainer:720) INFO: 24epoch:train:2001-2200batch: iter_time=1.815e-04, forward_time=0.134, uma_reduction=0.197, text_vs_uma=0.490, loss_ctc=6.058, loss=3.029, backward_time=0.189, optim_step_time=0.034, optim0_lr0=3.006e-04, train_time=0.892
[alab02] 2024-08-28 08:38:34,807 (trainer:720) INFO: 24epoch:train:2201-2400batch: iter_time=1.948e-04, forward_time=0.128, uma_reduction=0.199, text_vs_uma=0.479, loss_ctc=6.052, loss=3.026, backward_time=0.176, optim_step_time=0.034, optim0_lr0=3.004e-04, train_time=0.857
[alab02] 2024-08-28 08:40:03,113 (trainer:720) INFO: 24epoch:train:2401-2600batch: iter_time=1.836e-04, forward_time=0.133, uma_reduction=0.202, text_vs_uma=0.469, loss_ctc=6.271, loss=3.136, backward_time=0.185, optim_step_time=0.033, optim0_lr0=3.002e-04, train_time=0.883
[alab02] 2024-08-28 08:41:28,792 (trainer:720) INFO: 24epoch:train:2601-2800batch: iter_time=2.261e-04, forward_time=0.129, uma_reduction=0.198, text_vs_uma=0.495, loss_ctc=6.754, loss=3.377, backward_time=0.175, optim_step_time=0.034, optim0_lr0=3.001e-04, train_time=0.857
[alab02] 2024-08-28 08:42:56,553 (trainer:720) INFO: 24epoch:train:2801-3000batch: iter_time=1.768e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.489, loss_ctc=6.256, loss=3.128, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.999e-04, train_time=0.877
[alab02] 2024-08-28 08:44:27,344 (trainer:720) INFO: 24epoch:train:3001-3200batch: iter_time=1.868e-04, forward_time=0.137, uma_reduction=0.195, text_vs_uma=0.496, loss_ctc=6.582, loss=3.291, backward_time=0.190, optim_step_time=0.033, optim0_lr0=2.997e-04, train_time=0.908
[alab02] 2024-08-28 08:45:55,098 (trainer:720) INFO: 24epoch:train:3201-3400batch: iter_time=1.705e-04, forward_time=0.131, uma_reduction=0.194, text_vs_uma=0.493, loss_ctc=6.370, loss=3.185, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.995e-04, train_time=0.877
[alab02] 2024-08-28 08:47:23,124 (trainer:720) INFO: 24epoch:train:3401-3600batch: iter_time=2.364e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.495, loss_ctc=6.713, loss=3.357, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.993e-04, train_time=0.880
[alab02] 2024-08-28 08:48:51,814 (trainer:720) INFO: 24epoch:train:3601-3800batch: iter_time=1.898e-04, forward_time=0.133, uma_reduction=0.194, text_vs_uma=0.494, loss_ctc=6.885, loss=3.442, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.992e-04, train_time=0.887
[alab02] 2024-08-28 08:50:19,598 (trainer:720) INFO: 24epoch:train:3801-4000batch: iter_time=2.175e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.496, loss_ctc=6.441, loss=3.221, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.990e-04, train_time=0.878
[alab02] 2024-08-28 08:51:47,223 (trainer:720) INFO: 24epoch:train:4001-4200batch: iter_time=2.517e-04, forward_time=0.132, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=6.278, loss=3.139, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.988e-04, train_time=0.876
[alab02] 2024-08-28 08:53:15,383 (trainer:720) INFO: 24epoch:train:4201-4400batch: iter_time=1.945e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.480, loss_ctc=6.733, loss=3.367, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.986e-04, train_time=0.881
[alab02] 2024-08-28 08:54:43,488 (trainer:720) INFO: 24epoch:train:4401-4600batch: iter_time=2.372e-04, forward_time=0.133, uma_reduction=0.192, text_vs_uma=0.492, loss_ctc=6.401, loss=3.201, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.985e-04, train_time=0.881
[alab02] 2024-08-28 08:56:10,616 (trainer:720) INFO: 24epoch:train:4601-4800batch: iter_time=2.105e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.507, loss_ctc=6.539, loss=3.270, backward_time=0.181, optim_step_time=0.036, optim0_lr0=2.983e-04, train_time=0.871
[alab02] 2024-08-28 08:57:37,188 (trainer:720) INFO: 24epoch:train:4801-5000batch: iter_time=2.713e-04, forward_time=0.130, uma_reduction=0.195, text_vs_uma=0.492, loss_ctc=6.003, loss=3.001, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.981e-04, train_time=0.865
[alab02] 2024-08-28 08:59:05,973 (trainer:720) INFO: 24epoch:train:5001-5200batch: iter_time=1.814e-04, forward_time=0.132, uma_reduction=0.193, text_vs_uma=0.494, loss_ctc=6.703, loss=3.352, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.979e-04, train_time=0.888
[alab02] 2024-08-28 09:00:32,714 (trainer:720) INFO: 24epoch:train:5201-5400batch: iter_time=1.647e-04, forward_time=0.130, uma_reduction=0.192, text_vs_uma=0.508, loss_ctc=6.656, loss=3.328, backward_time=0.180, optim_step_time=0.032, optim0_lr0=2.977e-04, train_time=0.867
[alab02] 2024-08-28 09:01:59,028 (trainer:720) INFO: 24epoch:train:5401-5600batch: iter_time=1.722e-04, forward_time=0.130, uma_reduction=0.195, text_vs_uma=0.496, loss_ctc=6.469, loss=3.235, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.976e-04, train_time=0.863
[alab02] 2024-08-28 09:03:26,661 (trainer:720) INFO: 24epoch:train:5601-5800batch: iter_time=1.691e-04, forward_time=0.131, uma_reduction=0.195, text_vs_uma=0.490, loss_ctc=6.446, loss=3.223, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.974e-04, train_time=0.876
[alab02] 2024-08-28 09:04:54,233 (trainer:720) INFO: 24epoch:train:5801-6000batch: iter_time=1.658e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.485, loss_ctc=6.012, loss=3.006, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.972e-04, train_time=0.875
[alab02] 2024-08-28 09:06:19,966 (trainer:720) INFO: 24epoch:train:6001-6200batch: iter_time=1.670e-04, forward_time=0.128, uma_reduction=0.195, text_vs_uma=0.493, loss_ctc=7.160, loss=3.580, backward_time=0.174, optim_step_time=0.033, optim0_lr0=2.970e-04, train_time=0.857
[alab02] 2024-08-28 09:07:47,613 (trainer:720) INFO: 24epoch:train:6201-6400batch: iter_time=1.703e-04, forward_time=0.131, uma_reduction=0.198, text_vs_uma=0.485, loss_ctc=5.935, loss=2.968, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.969e-04, train_time=0.876
[alab02] 2024-08-28 09:09:15,030 (trainer:720) INFO: 24epoch:train:6401-6600batch: iter_time=1.670e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.382, loss=3.191, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.967e-04, train_time=0.874
[alab02] 2024-08-28 09:10:43,084 (trainer:720) INFO: 24epoch:train:6601-6800batch: iter_time=1.646e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.507, loss_ctc=6.721, loss=3.361, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.965e-04, train_time=0.880
[alab02] 2024-08-28 09:12:10,506 (trainer:720) INFO: 24epoch:train:6801-7000batch: iter_time=1.638e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.486, loss_ctc=5.978, loss=2.989, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.963e-04, train_time=0.874
[alab02] 2024-08-28 09:13:23,513 (trainer:338) INFO: 24epoch results: [train] iter_time=2.451e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.489, loss_ctc=6.401, loss=3.200, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.993e-04, train_time=0.876, time=52 minutes and 1.46 seconds, total_count=171024, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.179, text_vs_uma=0.608, loss_ctc=4.495, cer_ctc=0.110, cer=0.110, loss=4.495, time=5.9 seconds, total_count=624, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.88 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 09:13:29,694 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 09:13:29,743 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/13epoch.pth
[alab02] 2024-08-28 09:13:29,744 (trainer:272) INFO: 25/150epoch started. Estimated time to finish: 4 days, 20 hours and 59 minutes
[alab02] 2024-08-28 09:14:58,168 (trainer:720) INFO: 25epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.492, loss_ctc=6.624, loss=3.312, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.961e-04, train_time=0.884
[alab02] 2024-08-28 09:16:25,362 (trainer:720) INFO: 25epoch:train:201-400batch: iter_time=1.890e-04, forward_time=0.131, uma_reduction=0.199, text_vs_uma=0.492, loss_ctc=6.671, loss=3.336, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.959e-04, train_time=0.872
[alab02] 2024-08-28 09:17:50,274 (trainer:720) INFO: 25epoch:train:401-600batch: iter_time=1.847e-04, forward_time=0.127, uma_reduction=0.199, text_vs_uma=0.478, loss_ctc=5.804, loss=2.902, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.957e-04, train_time=0.849
[alab02] 2024-08-28 09:19:16,067 (trainer:720) INFO: 25epoch:train:601-800batch: iter_time=1.859e-04, forward_time=0.128, uma_reduction=0.196, text_vs_uma=0.495, loss_ctc=6.494, loss=3.247, backward_time=0.176, optim_step_time=0.032, optim0_lr0=2.955e-04, train_time=0.858
[alab02] 2024-08-28 09:20:43,908 (trainer:720) INFO: 25epoch:train:801-1000batch: iter_time=1.753e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.491, loss_ctc=6.667, loss=3.333, backward_time=0.182, optim_step_time=0.032, optim0_lr0=2.954e-04, train_time=0.878
[alab02] 2024-08-28 09:22:11,353 (trainer:720) INFO: 25epoch:train:1001-1200batch: iter_time=1.774e-04, forward_time=0.130, uma_reduction=0.193, text_vs_uma=0.503, loss_ctc=6.670, loss=3.335, backward_time=0.181, optim_step_time=0.032, optim0_lr0=2.952e-04, train_time=0.874
[alab02] 2024-08-28 09:23:37,775 (trainer:720) INFO: 25epoch:train:1201-1400batch: iter_time=1.748e-04, forward_time=0.129, uma_reduction=0.194, text_vs_uma=0.494, loss_ctc=6.286, loss=3.143, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.950e-04, train_time=0.864
[alab02] 2024-08-28 09:25:04,371 (trainer:720) INFO: 25epoch:train:1401-1600batch: iter_time=1.739e-04, forward_time=0.129, uma_reduction=0.198, text_vs_uma=0.487, loss_ctc=6.242, loss=3.121, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.949e-04, train_time=0.866
[alab02] 2024-08-28 09:26:28,435 (trainer:720) INFO: 25epoch:train:1601-1800batch: iter_time=1.857e-04, forward_time=0.125, uma_reduction=0.200, text_vs_uma=0.483, loss_ctc=6.349, loss=3.174, backward_time=0.172, optim_step_time=0.032, optim0_lr0=2.947e-04, train_time=0.840
[alab02] 2024-08-28 09:27:56,567 (trainer:720) INFO: 25epoch:train:1801-2000batch: iter_time=1.723e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.024, loss=3.012, backward_time=0.186, optim_step_time=0.033, optim0_lr0=2.945e-04, train_time=0.881
[alab02] 2024-08-28 09:29:23,423 (trainer:720) INFO: 25epoch:train:2001-2200batch: iter_time=1.679e-04, forward_time=0.129, uma_reduction=0.196, text_vs_uma=0.491, loss_ctc=6.470, loss=3.235, backward_time=0.180, optim_step_time=0.032, optim0_lr0=2.943e-04, train_time=0.868
[alab02] 2024-08-28 09:30:50,540 (trainer:720) INFO: 25epoch:train:2201-2400batch: iter_time=1.800e-04, forward_time=0.129, uma_reduction=0.201, text_vs_uma=0.482, loss_ctc=6.221, loss=3.110, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.942e-04, train_time=0.871
[alab02] 2024-08-28 09:32:17,713 (trainer:720) INFO: 25epoch:train:2401-2600batch: iter_time=1.764e-04, forward_time=0.130, uma_reduction=0.198, text_vs_uma=0.485, loss_ctc=6.660, loss=3.330, backward_time=0.180, optim_step_time=0.032, optim0_lr0=2.940e-04, train_time=0.872
[alab02] 2024-08-28 09:33:44,679 (trainer:720) INFO: 25epoch:train:2601-2800batch: iter_time=1.942e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.492, loss_ctc=6.287, loss=3.143, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.938e-04, train_time=0.869
[alab02] 2024-08-28 09:35:12,504 (trainer:720) INFO: 25epoch:train:2801-3000batch: iter_time=1.674e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.502, loss_ctc=6.666, loss=3.333, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.937e-04, train_time=0.878
[alab02] 2024-08-28 09:36:39,914 (trainer:720) INFO: 25epoch:train:3001-3200batch: iter_time=1.704e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.469, loss_ctc=5.900, loss=2.950, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.935e-04, train_time=0.874
[alab02] 2024-08-28 09:38:06,785 (trainer:720) INFO: 25epoch:train:3201-3400batch: iter_time=1.697e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=6.492, loss=3.246, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.933e-04, train_time=0.868
[alab02] 2024-08-28 09:39:32,839 (trainer:720) INFO: 25epoch:train:3401-3600batch: iter_time=1.688e-04, forward_time=0.128, uma_reduction=0.199, text_vs_uma=0.473, loss_ctc=5.959, loss=2.979, backward_time=0.178, optim_step_time=0.032, optim0_lr0=2.932e-04, train_time=0.860
[alab02] 2024-08-28 09:40:59,000 (trainer:720) INFO: 25epoch:train:3601-3800batch: iter_time=1.722e-04, forward_time=0.129, uma_reduction=0.198, text_vs_uma=0.491, loss_ctc=6.555, loss=3.277, backward_time=0.177, optim_step_time=0.033, optim0_lr0=2.930e-04, train_time=0.861
[alab02] 2024-08-28 09:42:26,099 (trainer:720) INFO: 25epoch:train:3801-4000batch: iter_time=1.652e-04, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.483, loss_ctc=6.267, loss=3.133, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.928e-04, train_time=0.871
[alab02] 2024-08-28 09:43:54,306 (trainer:720) INFO: 25epoch:train:4001-4200batch: iter_time=1.818e-04, forward_time=0.133, uma_reduction=0.201, text_vs_uma=0.467, loss_ctc=5.729, loss=2.865, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.927e-04, train_time=0.882
[alab02] 2024-08-28 09:45:23,168 (trainer:720) INFO: 25epoch:train:4201-4400batch: iter_time=1.707e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.491, loss_ctc=6.749, loss=3.374, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.925e-04, train_time=0.888
[alab02] 2024-08-28 09:46:51,067 (trainer:720) INFO: 25epoch:train:4401-4600batch: iter_time=1.679e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.476, loss_ctc=6.065, loss=3.033, backward_time=0.185, optim_step_time=0.032, optim0_lr0=2.923e-04, train_time=0.879
[alab02] 2024-08-28 09:48:19,954 (trainer:720) INFO: 25epoch:train:4601-4800batch: iter_time=1.598e-04, forward_time=0.133, uma_reduction=0.201, text_vs_uma=0.484, loss_ctc=6.310, loss=3.155, backward_time=0.187, optim_step_time=0.032, optim0_lr0=2.922e-04, train_time=0.889
[alab02] 2024-08-28 09:49:46,739 (trainer:720) INFO: 25epoch:train:4801-5000batch: iter_time=1.848e-04, forward_time=0.129, uma_reduction=0.198, text_vs_uma=0.497, loss_ctc=6.475, loss=3.237, backward_time=0.179, optim_step_time=0.032, optim0_lr0=2.920e-04, train_time=0.868
[alab02] 2024-08-28 09:51:13,420 (trainer:720) INFO: 25epoch:train:5001-5200batch: iter_time=1.722e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=5.976, loss=2.988, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.918e-04, train_time=0.867
[alab02] 2024-08-28 09:52:42,392 (trainer:720) INFO: 25epoch:train:5201-5400batch: iter_time=1.649e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.494, loss_ctc=6.974, loss=3.487, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.917e-04, train_time=0.889
[alab02] 2024-08-28 09:54:10,224 (trainer:720) INFO: 25epoch:train:5401-5600batch: iter_time=2.247e-04, forward_time=0.131, uma_reduction=0.202, text_vs_uma=0.478, loss_ctc=6.602, loss=3.301, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.915e-04, train_time=0.878
[alab02] 2024-08-28 09:55:35,896 (trainer:720) INFO: 25epoch:train:5601-5800batch: iter_time=2.459e-04, forward_time=0.129, uma_reduction=0.200, text_vs_uma=0.473, loss_ctc=5.762, loss=2.881, backward_time=0.177, optim_step_time=0.037, optim0_lr0=2.913e-04, train_time=0.856
[alab02] 2024-08-28 09:57:04,489 (trainer:720) INFO: 25epoch:train:5801-6000batch: iter_time=2.929e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.471, loss_ctc=5.903, loss=2.952, backward_time=0.187, optim_step_time=0.036, optim0_lr0=2.912e-04, train_time=0.886
[alab02] 2024-08-28 09:58:32,529 (trainer:720) INFO: 25epoch:train:6001-6200batch: iter_time=1.853e-04, forward_time=0.132, uma_reduction=0.201, text_vs_uma=0.499, loss_ctc=6.235, loss=3.117, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.910e-04, train_time=0.880
[alab02] 2024-08-28 10:00:00,644 (trainer:720) INFO: 25epoch:train:6201-6400batch: iter_time=1.794e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.480, loss_ctc=6.149, loss=3.074, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.908e-04, train_time=0.881
[alab02] 2024-08-28 10:01:28,667 (trainer:720) INFO: 25epoch:train:6401-6600batch: iter_time=2.119e-04, forward_time=0.133, uma_reduction=0.195, text_vs_uma=0.498, loss_ctc=6.672, loss=3.336, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.907e-04, train_time=0.880
[alab02] 2024-08-28 10:02:56,874 (trainer:720) INFO: 25epoch:train:6601-6800batch: iter_time=1.936e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.489, loss_ctc=6.385, loss=3.193, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.905e-04, train_time=0.882
[alab02] 2024-08-28 10:04:25,426 (trainer:720) INFO: 25epoch:train:6801-7000batch: iter_time=1.874e-04, forward_time=0.133, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=6.094, loss=3.047, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.904e-04, train_time=0.885
[alab02] 2024-08-28 10:05:40,912 (trainer:338) INFO: 25epoch results: [train] iter_time=2.413e-04, forward_time=0.131, uma_reduction=0.198, text_vs_uma=0.486, loss_ctc=6.314, loss=3.157, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.931e-04, train_time=0.873, time=51 minutes and 51.18 seconds, total_count=178150, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.193, text_vs_uma=0.564, loss_ctc=4.167, cer_ctc=0.104, cer=0.104, loss=4.167, time=6.08 seconds, total_count=650, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.91 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 10:05:47,484 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 10:05:47,549 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/16epoch.pth
[alab02] 2024-08-28 10:05:47,550 (trainer:272) INFO: 26/150epoch started. Estimated time to finish: 4 days, 19 hours and 46 minutes
[alab02] 2024-08-28 10:07:15,120 (trainer:720) INFO: 26epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.485, loss_ctc=6.286, loss=3.143, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.901e-04, train_time=0.875
[alab02] 2024-08-28 10:08:42,806 (trainer:720) INFO: 26epoch:train:201-400batch: iter_time=1.960e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.495, loss_ctc=6.664, loss=3.332, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.899e-04, train_time=0.877
[alab02] 2024-08-28 10:10:09,950 (trainer:720) INFO: 26epoch:train:401-600batch: iter_time=1.794e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.480, loss_ctc=6.557, loss=3.279, backward_time=0.177, optim_step_time=0.033, optim0_lr0=2.898e-04, train_time=0.871
[alab02] 2024-08-28 10:11:37,902 (trainer:720) INFO: 26epoch:train:601-800batch: iter_time=1.664e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=6.115, loss=3.057, backward_time=0.183, optim_step_time=0.032, optim0_lr0=2.896e-04, train_time=0.879
[alab02] 2024-08-28 10:13:05,823 (trainer:720) INFO: 26epoch:train:801-1000batch: iter_time=1.891e-04, forward_time=0.131, uma_reduction=0.196, text_vs_uma=0.500, loss_ctc=6.271, loss=3.135, backward_time=0.184, optim_step_time=0.032, optim0_lr0=2.894e-04, train_time=0.879
[alab02] 2024-08-28 10:14:32,633 (trainer:720) INFO: 26epoch:train:1001-1200batch: iter_time=1.788e-04, forward_time=0.129, uma_reduction=0.195, text_vs_uma=0.497, loss_ctc=6.478, loss=3.239, backward_time=0.180, optim_step_time=0.032, optim0_lr0=2.893e-04, train_time=0.868
[alab02] 2024-08-28 10:15:58,690 (trainer:720) INFO: 26epoch:train:1201-1400batch: iter_time=1.719e-04, forward_time=0.128, uma_reduction=0.198, text_vs_uma=0.497, loss_ctc=6.392, loss=3.196, backward_time=0.178, optim_step_time=0.032, optim0_lr0=2.891e-04, train_time=0.860
[alab02] 2024-08-28 10:17:25,439 (trainer:720) INFO: 26epoch:train:1401-1600batch: iter_time=1.599e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.476, loss_ctc=6.247, loss=3.124, backward_time=0.178, optim_step_time=0.032, optim0_lr0=2.890e-04, train_time=0.867
[alab02] 2024-08-28 10:18:51,492 (trainer:720) INFO: 26epoch:train:1601-1800batch: iter_time=1.803e-04, forward_time=0.129, uma_reduction=0.201, text_vs_uma=0.470, loss_ctc=5.608, loss=2.804, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.888e-04, train_time=0.860
[alab02] 2024-08-28 10:20:19,231 (trainer:720) INFO: 26epoch:train:1801-2000batch: iter_time=1.704e-04, forward_time=0.131, uma_reduction=0.202, text_vs_uma=0.487, loss_ctc=5.854, loss=2.927, backward_time=0.185, optim_step_time=0.032, optim0_lr0=2.886e-04, train_time=0.877
[alab02] 2024-08-28 10:21:47,642 (trainer:720) INFO: 26epoch:train:2001-2200batch: iter_time=1.789e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.489, loss_ctc=6.143, loss=3.071, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.885e-04, train_time=0.884
[alab02] 2024-08-28 10:23:15,998 (trainer:720) INFO: 26epoch:train:2201-2400batch: iter_time=1.776e-04, forward_time=0.131, uma_reduction=0.201, text_vs_uma=0.485, loss_ctc=6.175, loss=3.088, backward_time=0.186, optim_step_time=0.032, optim0_lr0=2.883e-04, train_time=0.883
[alab02] 2024-08-28 10:24:44,205 (trainer:720) INFO: 26epoch:train:2401-2600batch: iter_time=1.780e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.498, loss_ctc=6.704, loss=3.352, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.882e-04, train_time=0.882
[alab02] 2024-08-28 10:26:11,647 (trainer:720) INFO: 26epoch:train:2601-2800batch: iter_time=1.832e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.473, loss_ctc=5.761, loss=2.881, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.880e-04, train_time=0.874
[alab02] 2024-08-28 10:27:38,275 (trainer:720) INFO: 26epoch:train:2801-3000batch: iter_time=1.787e-04, forward_time=0.129, uma_reduction=0.200, text_vs_uma=0.483, loss_ctc=5.899, loss=2.950, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.878e-04, train_time=0.866
[alab02] 2024-08-28 10:29:06,769 (trainer:720) INFO: 26epoch:train:3001-3200batch: iter_time=1.939e-04, forward_time=0.133, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.950, loss=2.975, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.877e-04, train_time=0.885
[alab02] 2024-08-28 10:30:36,109 (trainer:720) INFO: 26epoch:train:3201-3400batch: iter_time=1.971e-04, forward_time=0.135, uma_reduction=0.203, text_vs_uma=0.478, loss_ctc=5.520, loss=2.760, backward_time=0.190, optim_step_time=0.035, optim0_lr0=2.875e-04, train_time=0.893
[alab02] 2024-08-28 10:32:04,941 (trainer:720) INFO: 26epoch:train:3401-3600batch: iter_time=1.866e-04, forward_time=0.133, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.884, loss=2.942, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.874e-04, train_time=0.888
[alab02] 2024-08-28 10:33:30,901 (trainer:720) INFO: 26epoch:train:3601-3800batch: iter_time=1.798e-04, forward_time=0.130, uma_reduction=0.202, text_vs_uma=0.469, loss_ctc=5.834, loss=2.917, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.872e-04, train_time=0.859
[alab02] 2024-08-28 10:34:57,802 (trainer:720) INFO: 26epoch:train:3801-4000batch: iter_time=1.895e-04, forward_time=0.131, uma_reduction=0.202, text_vs_uma=0.471, loss_ctc=6.142, loss=3.071, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.870e-04, train_time=0.869
[alab02] 2024-08-28 10:36:26,612 (trainer:720) INFO: 26epoch:train:4001-4200batch: iter_time=1.828e-04, forward_time=0.134, uma_reduction=0.203, text_vs_uma=0.463, loss_ctc=5.805, loss=2.902, backward_time=0.187, optim_step_time=0.034, optim0_lr0=2.869e-04, train_time=0.888
[alab02] 2024-08-28 10:37:52,608 (trainer:720) INFO: 26epoch:train:4201-4400batch: iter_time=1.855e-04, forward_time=0.129, uma_reduction=0.200, text_vs_uma=0.492, loss_ctc=6.175, loss=3.087, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.867e-04, train_time=0.860
[alab02] 2024-08-28 10:39:21,133 (trainer:720) INFO: 26epoch:train:4401-4600batch: iter_time=1.843e-04, forward_time=0.134, uma_reduction=0.199, text_vs_uma=0.492, loss_ctc=6.322, loss=3.161, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.866e-04, train_time=0.885
[alab02] 2024-08-28 10:40:49,160 (trainer:720) INFO: 26epoch:train:4601-4800batch: iter_time=1.741e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.478, loss_ctc=5.914, loss=2.957, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.864e-04, train_time=0.880
[alab02] 2024-08-28 10:42:16,539 (trainer:720) INFO: 26epoch:train:4801-5000batch: iter_time=1.913e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.498, loss_ctc=6.631, loss=3.316, backward_time=0.178, optim_step_time=0.036, optim0_lr0=2.863e-04, train_time=0.873
[alab02] 2024-08-28 10:43:46,767 (trainer:720) INFO: 26epoch:train:5001-5200batch: iter_time=1.921e-04, forward_time=0.136, uma_reduction=0.197, text_vs_uma=0.495, loss_ctc=6.375, loss=3.187, backward_time=0.189, optim_step_time=0.035, optim0_lr0=2.861e-04, train_time=0.902
[alab02] 2024-08-28 10:45:13,189 (trainer:720) INFO: 26epoch:train:5201-5400batch: iter_time=2.036e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=6.491, loss=3.245, backward_time=0.175, optim_step_time=0.036, optim0_lr0=2.859e-04, train_time=0.864
[alab02] 2024-08-28 10:46:47,817 (trainer:720) INFO: 26epoch:train:5401-5600batch: iter_time=4.075e-04, forward_time=0.153, uma_reduction=0.198, text_vs_uma=0.487, loss_ctc=6.048, loss=3.024, backward_time=0.187, optim_step_time=0.054, optim0_lr0=2.858e-04, train_time=0.946
[alab02] 2024-08-28 10:48:31,952 (trainer:720) INFO: 26epoch:train:5601-5800batch: iter_time=6.901e-04, forward_time=0.173, uma_reduction=0.195, text_vs_uma=0.491, loss_ctc=5.986, loss=2.993, backward_time=0.208, optim_step_time=0.068, optim0_lr0=2.856e-04, train_time=1.040
[alab02] 2024-08-28 10:50:15,013 (trainer:720) INFO: 26epoch:train:5801-6000batch: iter_time=6.630e-04, forward_time=0.171, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=5.854, loss=2.927, backward_time=0.208, optim_step_time=0.067, optim0_lr0=2.855e-04, train_time=1.030
[alab02] 2024-08-28 10:51:58,659 (trainer:720) INFO: 26epoch:train:6001-6200batch: iter_time=8.398e-04, forward_time=0.170, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.513, loss=2.757, backward_time=0.211, optim_step_time=0.067, optim0_lr0=2.853e-04, train_time=1.036
[alab02] 2024-08-28 10:53:40,755 (trainer:720) INFO: 26epoch:train:6201-6400batch: iter_time=9.622e-04, forward_time=0.165, uma_reduction=0.196, text_vs_uma=0.503, loss_ctc=6.255, loss=3.127, backward_time=0.205, optim_step_time=0.066, optim0_lr0=2.852e-04, train_time=1.020
[alab02] 2024-08-28 10:55:22,267 (trainer:720) INFO: 26epoch:train:6401-6600batch: iter_time=4.668e-04, forward_time=0.170, uma_reduction=0.197, text_vs_uma=0.483, loss_ctc=5.912, loss=2.956, backward_time=0.202, optim_step_time=0.063, optim0_lr0=2.850e-04, train_time=1.015
[alab02] 2024-08-28 10:57:11,132 (trainer:720) INFO: 26epoch:train:6601-6800batch: iter_time=0.001, forward_time=0.177, uma_reduction=0.199, text_vs_uma=0.479, loss_ctc=5.755, loss=2.878, backward_time=0.223, optim_step_time=0.079, optim0_lr0=2.849e-04, train_time=1.088
[alab02] 2024-08-28 10:59:00,140 (trainer:720) INFO: 26epoch:train:6801-7000batch: iter_time=8.323e-04, forward_time=0.182, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=5.739, loss=2.869, backward_time=0.222, optim_step_time=0.073, optim0_lr0=2.847e-04, train_time=1.090
[alab02] 2024-08-28 11:00:48,201 (trainer:338) INFO: 26epoch results: [train] iter_time=3.733e-04, forward_time=0.141, uma_reduction=0.199, text_vs_uma=0.485, loss_ctc=6.090, loss=3.045, backward_time=0.188, optim_step_time=0.042, optim0_lr0=2.873e-04, train_time=0.914, time=54 minutes and 20.21 seconds, total_count=185276, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.190, text_vs_uma=0.572, loss_ctc=4.251, cer_ctc=0.110, cer=0.110, loss=4.251, time=8.89 seconds, total_count=676, gpu_max_cached_mem_GB=35.906, [att_plot] time=31.54 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 11:00:59,312 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 11:00:59,328 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/22epoch.pth
[alab02] 2024-08-28 11:00:59,330 (trainer:272) INFO: 27/150epoch started. Estimated time to finish: 4 days, 18 hours and 49 minutes
[alab02] 2024-08-28 11:02:41,050 (trainer:720) INFO: 27epoch:train:1-200batch: iter_time=0.005, forward_time=0.161, uma_reduction=0.200, text_vs_uma=0.490, loss_ctc=6.283, loss=3.142, backward_time=0.199, optim_step_time=0.061, optim0_lr0=2.845e-04, train_time=1.016
[alab02] 2024-08-28 11:04:20,643 (trainer:720) INFO: 27epoch:train:201-400batch: iter_time=6.064e-04, forward_time=0.160, uma_reduction=0.199, text_vs_uma=0.495, loss_ctc=6.603, loss=3.301, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.843e-04, train_time=0.995
[alab02] 2024-08-28 11:05:57,318 (trainer:720) INFO: 27epoch:train:401-600batch: iter_time=7.010e-04, forward_time=0.151, uma_reduction=0.201, text_vs_uma=0.469, loss_ctc=5.506, loss=2.753, backward_time=0.202, optim_step_time=0.051, optim0_lr0=2.841e-04, train_time=0.966
[alab02] 2024-08-28 11:07:35,895 (trainer:720) INFO: 27epoch:train:601-800batch: iter_time=5.050e-04, forward_time=0.159, uma_reduction=0.200, text_vs_uma=0.480, loss_ctc=6.204, loss=3.102, backward_time=0.196, optim_step_time=0.055, optim0_lr0=2.840e-04, train_time=0.985
[alab02] 2024-08-28 11:09:16,446 (trainer:720) INFO: 27epoch:train:801-1000batch: iter_time=5.736e-04, forward_time=0.163, uma_reduction=0.200, text_vs_uma=0.493, loss_ctc=6.455, loss=3.227, backward_time=0.206, optim_step_time=0.058, optim0_lr0=2.838e-04, train_time=1.005
[alab02] 2024-08-28 11:10:59,397 (trainer:720) INFO: 27epoch:train:1001-1200batch: iter_time=5.760e-04, forward_time=0.169, uma_reduction=0.200, text_vs_uma=0.477, loss_ctc=6.177, loss=3.088, backward_time=0.206, optim_step_time=0.065, optim0_lr0=2.837e-04, train_time=1.029
[alab02] 2024-08-28 11:12:40,082 (trainer:720) INFO: 27epoch:train:1201-1400batch: iter_time=5.747e-04, forward_time=0.166, uma_reduction=0.201, text_vs_uma=0.480, loss_ctc=6.082, loss=3.041, backward_time=0.205, optim_step_time=0.061, optim0_lr0=2.835e-04, train_time=1.006
[alab02] 2024-08-28 11:14:23,250 (trainer:720) INFO: 27epoch:train:1401-1600batch: iter_time=4.754e-04, forward_time=0.169, uma_reduction=0.201, text_vs_uma=0.481, loss_ctc=6.416, loss=3.208, backward_time=0.209, optim_step_time=0.066, optim0_lr0=2.834e-04, train_time=1.031
[alab02] 2024-08-28 11:16:05,916 (trainer:720) INFO: 27epoch:train:1601-1800batch: iter_time=4.473e-04, forward_time=0.168, uma_reduction=0.205, text_vs_uma=0.471, loss_ctc=5.608, loss=2.804, backward_time=0.211, optim_step_time=0.062, optim0_lr0=2.832e-04, train_time=1.026
[alab02] 2024-08-28 11:17:48,683 (trainer:720) INFO: 27epoch:train:1801-2000batch: iter_time=5.041e-04, forward_time=0.168, uma_reduction=0.201, text_vs_uma=0.483, loss_ctc=6.502, loss=3.251, backward_time=0.204, optim_step_time=0.063, optim0_lr0=2.831e-04, train_time=1.027
[alab02] 2024-08-28 11:19:30,918 (trainer:720) INFO: 27epoch:train:2001-2200batch: iter_time=4.946e-04, forward_time=0.166, uma_reduction=0.202, text_vs_uma=0.488, loss_ctc=6.610, loss=3.305, backward_time=0.205, optim_step_time=0.062, optim0_lr0=2.829e-04, train_time=1.022
[alab02] 2024-08-28 11:21:11,868 (trainer:720) INFO: 27epoch:train:2201-2400batch: iter_time=4.297e-04, forward_time=0.167, uma_reduction=0.199, text_vs_uma=0.491, loss_ctc=6.731, loss=3.365, backward_time=0.200, optim_step_time=0.060, optim0_lr0=2.828e-04, train_time=1.009
[alab02] 2024-08-28 11:22:55,914 (trainer:720) INFO: 27epoch:train:2401-2600batch: iter_time=5.063e-04, forward_time=0.172, uma_reduction=0.202, text_vs_uma=0.475, loss_ctc=6.451, loss=3.226, backward_time=0.209, optim_step_time=0.064, optim0_lr0=2.826e-04, train_time=1.040
[alab02] 2024-08-28 11:24:36,867 (trainer:720) INFO: 27epoch:train:2601-2800batch: iter_time=5.366e-04, forward_time=0.163, uma_reduction=0.198, text_vs_uma=0.497, loss_ctc=6.816, loss=3.408, backward_time=0.203, optim_step_time=0.064, optim0_lr0=2.825e-04, train_time=1.009
[alab02] 2024-08-28 11:26:19,915 (trainer:720) INFO: 27epoch:train:2801-3000batch: iter_time=5.754e-04, forward_time=0.170, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.529, loss=3.265, backward_time=0.204, optim_step_time=0.065, optim0_lr0=2.823e-04, train_time=1.030
[alab02] 2024-08-28 11:28:02,081 (trainer:720) INFO: 27epoch:train:3001-3200batch: iter_time=5.514e-04, forward_time=0.169, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=5.872, loss=2.936, backward_time=0.207, optim_step_time=0.066, optim0_lr0=2.822e-04, train_time=1.021
[alab02] 2024-08-28 11:29:44,998 (trainer:720) INFO: 27epoch:train:3201-3400batch: iter_time=4.674e-04, forward_time=0.170, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=5.901, loss=2.951, backward_time=0.211, optim_step_time=0.064, optim0_lr0=2.820e-04, train_time=1.028
[alab02] 2024-08-28 11:31:29,634 (trainer:720) INFO: 27epoch:train:3401-3600batch: iter_time=4.702e-04, forward_time=0.173, uma_reduction=0.201, text_vs_uma=0.470, loss_ctc=5.724, loss=2.862, backward_time=0.215, optim_step_time=0.071, optim0_lr0=2.819e-04, train_time=1.046
[alab02] 2024-08-28 11:33:11,099 (trainer:720) INFO: 27epoch:train:3601-3800batch: iter_time=3.728e-04, forward_time=0.165, uma_reduction=0.199, text_vs_uma=0.478, loss_ctc=5.702, loss=2.851, backward_time=0.210, optim_step_time=0.064, optim0_lr0=2.817e-04, train_time=1.014
[alab02] 2024-08-28 11:34:57,770 (trainer:720) INFO: 27epoch:train:3801-4000batch: iter_time=5.079e-04, forward_time=0.174, uma_reduction=0.200, text_vs_uma=0.471, loss_ctc=5.584, loss=2.792, backward_time=0.218, optim_step_time=0.065, optim0_lr0=2.816e-04, train_time=1.066
[alab02] 2024-08-28 11:36:39,439 (trainer:720) INFO: 27epoch:train:4001-4200batch: iter_time=4.411e-04, forward_time=0.165, uma_reduction=0.202, text_vs_uma=0.482, loss_ctc=5.992, loss=2.996, backward_time=0.208, optim_step_time=0.062, optim0_lr0=2.814e-04, train_time=1.016
[alab02] 2024-08-28 11:38:21,481 (trainer:720) INFO: 27epoch:train:4201-4400batch: iter_time=4.453e-04, forward_time=0.165, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=6.090, loss=3.045, backward_time=0.207, optim_step_time=0.062, optim0_lr0=2.813e-04, train_time=1.020
[alab02] 2024-08-28 11:40:03,049 (trainer:720) INFO: 27epoch:train:4401-4600batch: iter_time=5.355e-04, forward_time=0.165, uma_reduction=0.198, text_vs_uma=0.489, loss_ctc=6.431, loss=3.215, backward_time=0.204, optim_step_time=0.065, optim0_lr0=2.811e-04, train_time=1.015
[alab02] 2024-08-28 11:41:43,609 (trainer:720) INFO: 27epoch:train:4601-4800batch: iter_time=4.572e-04, forward_time=0.162, uma_reduction=0.199, text_vs_uma=0.487, loss_ctc=6.224, loss=3.112, backward_time=0.207, optim_step_time=0.059, optim0_lr0=2.810e-04, train_time=1.005
[alab02] 2024-08-28 11:43:27,075 (trainer:720) INFO: 27epoch:train:4801-5000batch: iter_time=4.546e-04, forward_time=0.170, uma_reduction=0.199, text_vs_uma=0.490, loss_ctc=6.520, loss=3.260, backward_time=0.206, optim_step_time=0.065, optim0_lr0=2.808e-04, train_time=1.034
[alab02] 2024-08-28 11:45:08,155 (trainer:720) INFO: 27epoch:train:5001-5200batch: iter_time=4.508e-04, forward_time=0.166, uma_reduction=0.200, text_vs_uma=0.476, loss_ctc=5.901, loss=2.950, backward_time=0.206, optim_step_time=0.061, optim0_lr0=2.807e-04, train_time=1.010
[alab02] 2024-08-28 11:46:50,253 (trainer:720) INFO: 27epoch:train:5201-5400batch: iter_time=4.425e-04, forward_time=0.169, uma_reduction=0.198, text_vs_uma=0.484, loss_ctc=6.011, loss=3.005, backward_time=0.207, optim_step_time=0.064, optim0_lr0=2.805e-04, train_time=1.020
[alab02] 2024-08-28 11:48:32,084 (trainer:720) INFO: 27epoch:train:5401-5600batch: iter_time=4.043e-04, forward_time=0.166, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=5.894, loss=2.947, backward_time=0.208, optim_step_time=0.063, optim0_lr0=2.804e-04, train_time=1.018
[alab02] 2024-08-28 11:50:12,852 (trainer:720) INFO: 27epoch:train:5601-5800batch: iter_time=4.092e-04, forward_time=0.164, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=6.099, loss=3.050, backward_time=0.205, optim_step_time=0.061, optim0_lr0=2.803e-04, train_time=1.007
[alab02] 2024-08-28 11:51:54,158 (trainer:720) INFO: 27epoch:train:5801-6000batch: iter_time=4.865e-04, forward_time=0.165, uma_reduction=0.199, text_vs_uma=0.477, loss_ctc=5.801, loss=2.900, backward_time=0.208, optim_step_time=0.064, optim0_lr0=2.801e-04, train_time=1.013
[alab02] 2024-08-28 11:53:36,069 (trainer:720) INFO: 27epoch:train:6001-6200batch: iter_time=4.034e-04, forward_time=0.168, uma_reduction=0.197, text_vs_uma=0.499, loss_ctc=6.511, loss=3.256, backward_time=0.203, optim_step_time=0.062, optim0_lr0=2.800e-04, train_time=1.018
[alab02] 2024-08-28 11:55:17,229 (trainer:720) INFO: 27epoch:train:6201-6400batch: iter_time=4.268e-04, forward_time=0.165, uma_reduction=0.197, text_vs_uma=0.485, loss_ctc=6.037, loss=3.019, backward_time=0.202, optim_step_time=0.064, optim0_lr0=2.798e-04, train_time=1.011
[alab02] 2024-08-28 11:56:56,611 (trainer:720) INFO: 27epoch:train:6401-6600batch: iter_time=4.211e-04, forward_time=0.162, uma_reduction=0.198, text_vs_uma=0.482, loss_ctc=6.021, loss=3.011, backward_time=0.205, optim_step_time=0.059, optim0_lr0=2.797e-04, train_time=0.993
[alab02] 2024-08-28 11:58:35,655 (trainer:720) INFO: 27epoch:train:6601-6800batch: iter_time=4.474e-04, forward_time=0.160, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.867, loss=2.933, backward_time=0.199, optim_step_time=0.058, optim0_lr0=2.795e-04, train_time=0.990
[alab02] 2024-08-28 12:00:14,974 (trainer:720) INFO: 27epoch:train:6801-7000batch: iter_time=4.237e-04, forward_time=0.159, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=6.310, loss=3.155, backward_time=0.200, optim_step_time=0.055, optim0_lr0=2.794e-04, train_time=0.993
[alab02] 2024-08-28 12:01:51,526 (trainer:338) INFO: 27epoch results: [train] iter_time=6.181e-04, forward_time=0.165, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=6.159, loss=3.079, backward_time=0.206, optim_step_time=0.062, optim0_lr0=2.818e-04, train_time=1.015, time=1 hour and 20.9 seconds, total_count=192402, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.181, text_vs_uma=0.600, loss_ctc=4.197, cer_ctc=0.107, cer=0.107, loss=4.197, time=7.83 seconds, total_count=702, gpu_max_cached_mem_GB=35.906, [att_plot] time=23.46 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 12:01:59,241 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 12:01:59,256 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/15epoch.pth
[alab02] 2024-08-28 12:01:59,257 (trainer:272) INFO: 28/150epoch started. Estimated time to finish: 4 days, 18 hours and 18 minutes
[alab02] 2024-08-28 12:03:39,527 (trainer:720) INFO: 28epoch:train:1-200batch: iter_time=0.004, forward_time=0.158, uma_reduction=0.196, text_vs_uma=0.464, loss_ctc=5.453, loss=2.726, backward_time=0.205, optim_step_time=0.055, optim0_lr0=2.791e-04, train_time=1.002
[alab02] 2024-08-28 12:05:15,890 (trainer:720) INFO: 28epoch:train:201-400batch: iter_time=5.493e-04, forward_time=0.154, uma_reduction=0.197, text_vs_uma=0.490, loss_ctc=6.020, loss=3.010, backward_time=0.196, optim_step_time=0.050, optim0_lr0=2.790e-04, train_time=0.963
[alab02] 2024-08-28 12:06:53,408 (trainer:720) INFO: 28epoch:train:401-600batch: iter_time=3.871e-04, forward_time=0.154, uma_reduction=0.195, text_vs_uma=0.499, loss_ctc=6.147, loss=3.073, backward_time=0.199, optim_step_time=0.051, optim0_lr0=2.789e-04, train_time=0.975
[alab02] 2024-08-28 12:08:27,559 (trainer:720) INFO: 28epoch:train:601-800batch: iter_time=4.007e-04, forward_time=0.148, uma_reduction=0.195, text_vs_uma=0.495, loss_ctc=6.201, loss=3.101, backward_time=0.192, optim_step_time=0.049, optim0_lr0=2.787e-04, train_time=0.941
[alab02] 2024-08-28 12:10:03,231 (trainer:720) INFO: 28epoch:train:801-1000batch: iter_time=3.704e-04, forward_time=0.153, uma_reduction=0.199, text_vs_uma=0.486, loss_ctc=5.946, loss=2.973, backward_time=0.195, optim_step_time=0.050, optim0_lr0=2.786e-04, train_time=0.956
[alab02] 2024-08-28 12:11:40,669 (trainer:720) INFO: 28epoch:train:1001-1200batch: iter_time=4.110e-04, forward_time=0.155, uma_reduction=0.196, text_vs_uma=0.500, loss_ctc=6.309, loss=3.154, backward_time=0.196, optim_step_time=0.052, optim0_lr0=2.784e-04, train_time=0.974
[alab02] 2024-08-28 12:13:15,176 (trainer:720) INFO: 28epoch:train:1201-1400batch: iter_time=3.632e-04, forward_time=0.150, uma_reduction=0.198, text_vs_uma=0.491, loss_ctc=6.916, loss=3.458, backward_time=0.187, optim_step_time=0.048, optim0_lr0=2.783e-04, train_time=0.945
[alab02] 2024-08-28 12:14:49,795 (trainer:720) INFO: 28epoch:train:1401-1600batch: iter_time=3.506e-04, forward_time=0.148, uma_reduction=0.201, text_vs_uma=0.472, loss_ctc=5.747, loss=2.874, backward_time=0.196, optim_step_time=0.049, optim0_lr0=2.781e-04, train_time=0.946
[alab02] 2024-08-28 12:16:30,647 (trainer:720) INFO: 28epoch:train:1601-1800batch: iter_time=4.642e-04, forward_time=0.165, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=6.313, loss=3.156, backward_time=0.202, optim_step_time=0.060, optim0_lr0=2.780e-04, train_time=1.008
[alab02] 2024-08-28 12:18:11,270 (trainer:720) INFO: 28epoch:train:1801-2000batch: iter_time=4.866e-04, forward_time=0.164, uma_reduction=0.198, text_vs_uma=0.487, loss_ctc=5.962, loss=2.981, backward_time=0.204, optim_step_time=0.059, optim0_lr0=2.778e-04, train_time=1.006
[alab02] 2024-08-28 12:19:53,358 (trainer:720) INFO: 28epoch:train:2001-2200batch: iter_time=5.264e-04, forward_time=0.167, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=6.255, loss=3.127, backward_time=0.203, optim_step_time=0.060, optim0_lr0=2.777e-04, train_time=1.020
[alab02] 2024-08-28 12:21:36,239 (trainer:720) INFO: 28epoch:train:2201-2400batch: iter_time=4.088e-04, forward_time=0.169, uma_reduction=0.196, text_vs_uma=0.489, loss_ctc=6.278, loss=3.139, backward_time=0.201, optim_step_time=0.063, optim0_lr0=2.776e-04, train_time=1.028
[alab02] 2024-08-28 12:23:15,016 (trainer:720) INFO: 28epoch:train:2401-2600batch: iter_time=4.120e-04, forward_time=0.161, uma_reduction=0.194, text_vs_uma=0.500, loss_ctc=6.106, loss=3.053, backward_time=0.201, optim_step_time=0.058, optim0_lr0=2.774e-04, train_time=0.987
[alab02] 2024-08-28 12:24:56,368 (trainer:720) INFO: 28epoch:train:2601-2800batch: iter_time=4.746e-04, forward_time=0.166, uma_reduction=0.198, text_vs_uma=0.477, loss_ctc=6.042, loss=3.021, backward_time=0.203, optim_step_time=0.061, optim0_lr0=2.773e-04, train_time=1.013
[alab02] 2024-08-28 12:26:39,215 (trainer:720) INFO: 28epoch:train:2801-3000batch: iter_time=5.537e-04, forward_time=0.172, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=6.149, loss=3.075, backward_time=0.202, optim_step_time=0.066, optim0_lr0=2.771e-04, train_time=1.028
[alab02] 2024-08-28 12:28:20,979 (trainer:720) INFO: 28epoch:train:3001-3200batch: iter_time=4.646e-04, forward_time=0.168, uma_reduction=0.200, text_vs_uma=0.486, loss_ctc=5.701, loss=2.851, backward_time=0.207, optim_step_time=0.061, optim0_lr0=2.770e-04, train_time=1.017
[alab02] 2024-08-28 12:30:04,402 (trainer:720) INFO: 28epoch:train:3201-3400batch: iter_time=5.475e-04, forward_time=0.172, uma_reduction=0.199, text_vs_uma=0.472, loss_ctc=6.121, loss=3.060, backward_time=0.204, optim_step_time=0.064, optim0_lr0=2.769e-04, train_time=1.033
[alab02] 2024-08-28 12:31:45,954 (trainer:720) INFO: 28epoch:train:3401-3600batch: iter_time=4.505e-04, forward_time=0.165, uma_reduction=0.199, text_vs_uma=0.495, loss_ctc=6.120, loss=3.060, backward_time=0.205, optim_step_time=0.060, optim0_lr0=2.767e-04, train_time=1.015
[alab02] 2024-08-28 12:33:26,918 (trainer:720) INFO: 28epoch:train:3601-3800batch: iter_time=5.234e-04, forward_time=0.164, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.182, loss=3.091, backward_time=0.202, optim_step_time=0.060, optim0_lr0=2.766e-04, train_time=1.009
[alab02] 2024-08-28 12:35:08,758 (trainer:720) INFO: 28epoch:train:3801-4000batch: iter_time=4.137e-04, forward_time=0.167, uma_reduction=0.199, text_vs_uma=0.485, loss_ctc=6.253, loss=3.126, backward_time=0.203, optim_step_time=0.060, optim0_lr0=2.764e-04, train_time=1.018
[alab02] 2024-08-28 12:36:48,728 (trainer:720) INFO: 28epoch:train:4001-4200batch: iter_time=3.807e-04, forward_time=0.162, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.850, loss=2.925, backward_time=0.204, optim_step_time=0.057, optim0_lr0=2.763e-04, train_time=0.999
[alab02] 2024-08-28 12:38:24,932 (trainer:720) INFO: 28epoch:train:4201-4400batch: iter_time=3.709e-04, forward_time=0.152, uma_reduction=0.198, text_vs_uma=0.492, loss_ctc=6.073, loss=3.037, backward_time=0.194, optim_step_time=0.054, optim0_lr0=2.761e-04, train_time=0.961
[alab02] 2024-08-28 12:40:03,699 (trainer:720) INFO: 28epoch:train:4401-4600batch: iter_time=4.411e-04, forward_time=0.158, uma_reduction=0.198, text_vs_uma=0.488, loss_ctc=6.186, loss=3.093, backward_time=0.200, optim_step_time=0.058, optim0_lr0=2.760e-04, train_time=0.987
[alab02] 2024-08-28 12:41:42,449 (trainer:720) INFO: 28epoch:train:4601-4800batch: iter_time=4.468e-04, forward_time=0.160, uma_reduction=0.200, text_vs_uma=0.476, loss_ctc=5.832, loss=2.916, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.759e-04, train_time=0.987
[alab02] 2024-08-28 12:43:20,480 (trainer:720) INFO: 28epoch:train:4801-5000batch: iter_time=4.725e-04, forward_time=0.157, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.828, loss=2.914, backward_time=0.197, optim_step_time=0.053, optim0_lr0=2.757e-04, train_time=0.980
[alab02] 2024-08-28 12:44:58,916 (trainer:720) INFO: 28epoch:train:5001-5200batch: iter_time=7.184e-04, forward_time=0.158, uma_reduction=0.198, text_vs_uma=0.488, loss_ctc=6.268, loss=3.134, backward_time=0.193, optim_step_time=0.058, optim0_lr0=2.756e-04, train_time=0.984
[alab02] 2024-08-28 12:46:37,550 (trainer:720) INFO: 28epoch:train:5201-5400batch: iter_time=5.974e-04, forward_time=0.160, uma_reduction=0.194, text_vs_uma=0.499, loss_ctc=6.095, loss=3.048, backward_time=0.199, optim_step_time=0.055, optim0_lr0=2.754e-04, train_time=0.986
[alab02] 2024-08-28 12:48:14,596 (trainer:720) INFO: 28epoch:train:5401-5600batch: iter_time=5.759e-04, forward_time=0.155, uma_reduction=0.197, text_vs_uma=0.496, loss_ctc=6.311, loss=3.155, backward_time=0.195, optim_step_time=0.057, optim0_lr0=2.753e-04, train_time=0.970
[alab02] 2024-08-28 12:49:54,926 (trainer:720) INFO: 28epoch:train:5601-5800batch: iter_time=7.020e-04, forward_time=0.163, uma_reduction=0.198, text_vs_uma=0.484, loss_ctc=6.068, loss=3.034, backward_time=0.199, optim_step_time=0.064, optim0_lr0=2.752e-04, train_time=1.003
[alab02] 2024-08-28 12:51:35,216 (trainer:720) INFO: 28epoch:train:5801-6000batch: iter_time=8.582e-04, forward_time=0.162, uma_reduction=0.196, text_vs_uma=0.491, loss_ctc=6.237, loss=3.118, backward_time=0.197, optim_step_time=0.062, optim0_lr0=2.750e-04, train_time=1.002
[alab02] 2024-08-28 12:53:11,741 (trainer:720) INFO: 28epoch:train:6001-6200batch: iter_time=5.470e-04, forward_time=0.153, uma_reduction=0.197, text_vs_uma=0.478, loss_ctc=5.603, loss=2.802, backward_time=0.194, optim_step_time=0.061, optim0_lr0=2.749e-04, train_time=0.965
[alab02] 2024-08-28 12:54:48,140 (trainer:720) INFO: 28epoch:train:6201-6400batch: iter_time=6.003e-04, forward_time=0.154, uma_reduction=0.200, text_vs_uma=0.476, loss_ctc=5.994, loss=2.997, backward_time=0.192, optim_step_time=0.053, optim0_lr0=2.748e-04, train_time=0.964
[alab02] 2024-08-28 12:56:22,659 (trainer:720) INFO: 28epoch:train:6401-6600batch: iter_time=4.717e-04, forward_time=0.148, uma_reduction=0.199, text_vs_uma=0.469, loss_ctc=5.816, loss=2.908, backward_time=0.194, optim_step_time=0.051, optim0_lr0=2.746e-04, train_time=0.945
[alab02] 2024-08-28 12:57:58,419 (trainer:720) INFO: 28epoch:train:6601-6800batch: iter_time=5.792e-04, forward_time=0.151, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.403, loss=2.702, backward_time=0.198, optim_step_time=0.052, optim0_lr0=2.745e-04, train_time=0.957
[alab02] 2024-08-28 12:59:34,342 (trainer:720) INFO: 28epoch:train:6801-7000batch: iter_time=4.190e-04, forward_time=0.149, uma_reduction=0.197, text_vs_uma=0.496, loss_ctc=5.956, loss=2.978, backward_time=0.197, optim_step_time=0.049, optim0_lr0=2.743e-04, train_time=0.959
[alab02] 2024-08-28 13:00:59,885 (trainer:338) INFO: 28epoch results: [train] iter_time=5.952e-04, forward_time=0.159, uma_reduction=0.198, text_vs_uma=0.486, loss_ctc=6.061, loss=3.030, backward_time=0.198, optim_step_time=0.056, optim0_lr0=2.767e-04, train_time=0.985, time=58 minutes and 34.1 seconds, total_count=199528, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.186, text_vs_uma=0.583, loss_ctc=4.043, cer_ctc=0.102, cer=0.102, loss=4.043, time=7.05 seconds, total_count=728, gpu_max_cached_mem_GB=35.906, [att_plot] time=19.48 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 13:01:07,977 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 13:01:07,985 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/20epoch.pth
[alab02] 2024-08-28 13:01:07,985 (trainer:272) INFO: 29/150epoch started. Estimated time to finish: 4 days, 17 hours and 37 minutes
[alab02] 2024-08-28 13:02:45,591 (trainer:720) INFO: 29epoch:train:1-200batch: iter_time=0.003, forward_time=0.152, uma_reduction=0.197, text_vs_uma=0.487, loss_ctc=6.133, loss=3.066, backward_time=0.195, optim_step_time=0.047, optim0_lr0=2.741e-04, train_time=0.975
[alab02] 2024-08-28 13:04:18,729 (trainer:720) INFO: 29epoch:train:201-400batch: iter_time=3.821e-04, forward_time=0.145, uma_reduction=0.201, text_vs_uma=0.464, loss_ctc=5.665, loss=2.833, backward_time=0.190, optim_step_time=0.047, optim0_lr0=2.740e-04, train_time=0.931
[alab02] 2024-08-28 13:05:52,835 (trainer:720) INFO: 29epoch:train:401-600batch: iter_time=3.333e-04, forward_time=0.145, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.807, loss=2.903, backward_time=0.193, optim_step_time=0.043, optim0_lr0=2.738e-04, train_time=0.941
[alab02] 2024-08-28 13:07:32,179 (trainer:720) INFO: 29epoch:train:601-800batch: iter_time=4.614e-04, forward_time=0.160, uma_reduction=0.200, text_vs_uma=0.477, loss_ctc=6.054, loss=3.027, backward_time=0.201, optim_step_time=0.057, optim0_lr0=2.737e-04, train_time=0.993
[alab02] 2024-08-28 13:09:13,612 (trainer:720) INFO: 29epoch:train:801-1000batch: iter_time=5.012e-04, forward_time=0.168, uma_reduction=0.197, text_vs_uma=0.494, loss_ctc=6.078, loss=3.039, backward_time=0.200, optim_step_time=0.064, optim0_lr0=2.736e-04, train_time=1.014
[alab02] 2024-08-28 13:10:55,808 (trainer:720) INFO: 29epoch:train:1001-1200batch: iter_time=4.676e-04, forward_time=0.168, uma_reduction=0.199, text_vs_uma=0.489, loss_ctc=6.253, loss=3.126, backward_time=0.202, optim_step_time=0.060, optim0_lr0=2.734e-04, train_time=1.022
[alab02] 2024-08-28 13:12:35,377 (trainer:720) INFO: 29epoch:train:1201-1400batch: iter_time=4.120e-04, forward_time=0.161, uma_reduction=0.199, text_vs_uma=0.489, loss_ctc=6.064, loss=3.032, backward_time=0.204, optim_step_time=0.055, optim0_lr0=2.733e-04, train_time=0.995
[alab02] 2024-08-28 13:14:16,994 (trainer:720) INFO: 29epoch:train:1401-1600batch: iter_time=4.287e-04, forward_time=0.165, uma_reduction=0.199, text_vs_uma=0.494, loss_ctc=6.067, loss=3.034, backward_time=0.204, optim_step_time=0.060, optim0_lr0=2.732e-04, train_time=1.015
[alab02] 2024-08-28 13:15:57,300 (trainer:720) INFO: 29epoch:train:1601-1800batch: iter_time=5.296e-04, forward_time=0.163, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=5.921, loss=2.960, backward_time=0.201, optim_step_time=0.058, optim0_lr0=2.730e-04, train_time=1.003
[alab02] 2024-08-28 13:17:40,174 (trainer:720) INFO: 29epoch:train:1801-2000batch: iter_time=4.798e-04, forward_time=0.169, uma_reduction=0.200, text_vs_uma=0.471, loss_ctc=6.137, loss=3.069, backward_time=0.207, optim_step_time=0.062, optim0_lr0=2.729e-04, train_time=1.028
[alab02] 2024-08-28 13:19:21,439 (trainer:720) INFO: 29epoch:train:2001-2200batch: iter_time=4.544e-04, forward_time=0.166, uma_reduction=0.200, text_vs_uma=0.483, loss_ctc=6.247, loss=3.123, backward_time=0.204, optim_step_time=0.061, optim0_lr0=2.728e-04, train_time=1.012
[alab02] 2024-08-28 13:21:00,800 (trainer:720) INFO: 29epoch:train:2201-2400batch: iter_time=3.801e-04, forward_time=0.160, uma_reduction=0.200, text_vs_uma=0.476, loss_ctc=5.830, loss=2.915, backward_time=0.203, optim_step_time=0.054, optim0_lr0=2.726e-04, train_time=0.993
[alab02] 2024-08-28 13:22:41,222 (trainer:720) INFO: 29epoch:train:2401-2600batch: iter_time=4.621e-04, forward_time=0.163, uma_reduction=0.197, text_vs_uma=0.481, loss_ctc=6.017, loss=3.009, backward_time=0.203, optim_step_time=0.057, optim0_lr0=2.725e-04, train_time=1.004
[alab02] 2024-08-28 13:24:20,184 (trainer:720) INFO: 29epoch:train:2601-2800batch: iter_time=3.987e-04, forward_time=0.161, uma_reduction=0.198, text_vs_uma=0.491, loss_ctc=5.984, loss=2.992, backward_time=0.200, optim_step_time=0.055, optim0_lr0=2.723e-04, train_time=0.989
[alab02] 2024-08-28 13:26:01,128 (trainer:720) INFO: 29epoch:train:2801-3000batch: iter_time=4.209e-04, forward_time=0.166, uma_reduction=0.200, text_vs_uma=0.492, loss_ctc=5.915, loss=2.958, backward_time=0.205, optim_step_time=0.060, optim0_lr0=2.722e-04, train_time=1.009
[alab02] 2024-08-28 13:27:42,344 (trainer:720) INFO: 29epoch:train:3001-3200batch: iter_time=5.194e-04, forward_time=0.167, uma_reduction=0.200, text_vs_uma=0.487, loss_ctc=5.959, loss=2.979, backward_time=0.205, optim_step_time=0.058, optim0_lr0=2.721e-04, train_time=1.012
[alab02] 2024-08-28 13:29:19,944 (trainer:720) INFO: 29epoch:train:3201-3400batch: iter_time=4.215e-04, forward_time=0.157, uma_reduction=0.198, text_vs_uma=0.493, loss_ctc=6.326, loss=3.163, backward_time=0.194, optim_step_time=0.054, optim0_lr0=2.719e-04, train_time=0.975
[alab02] 2024-08-28 13:30:59,146 (trainer:720) INFO: 29epoch:train:3401-3600batch: iter_time=4.066e-04, forward_time=0.161, uma_reduction=0.203, text_vs_uma=0.477, loss_ctc=5.876, loss=2.938, backward_time=0.199, optim_step_time=0.056, optim0_lr0=2.718e-04, train_time=0.992
[alab02] 2024-08-28 13:32:34,235 (trainer:720) INFO: 29epoch:train:3601-3800batch: iter_time=3.302e-04, forward_time=0.153, uma_reduction=0.204, text_vs_uma=0.474, loss_ctc=5.972, loss=2.986, backward_time=0.189, optim_step_time=0.052, optim0_lr0=2.717e-04, train_time=0.950
[alab02] 2024-08-28 13:34:12,146 (trainer:720) INFO: 29epoch:train:3801-4000batch: iter_time=3.915e-04, forward_time=0.159, uma_reduction=0.202, text_vs_uma=0.461, loss_ctc=5.502, loss=2.751, backward_time=0.198, optim_step_time=0.054, optim0_lr0=2.715e-04, train_time=0.979
[alab02] 2024-08-28 13:35:50,768 (trainer:720) INFO: 29epoch:train:4001-4200batch: iter_time=4.121e-04, forward_time=0.160, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.742, loss=2.871, backward_time=0.198, optim_step_time=0.054, optim0_lr0=2.714e-04, train_time=0.986
[alab02] 2024-08-28 13:37:25,792 (trainer:720) INFO: 29epoch:train:4201-4400batch: iter_time=3.413e-04, forward_time=0.152, uma_reduction=0.200, text_vs_uma=0.488, loss_ctc=6.076, loss=3.038, backward_time=0.193, optim_step_time=0.052, optim0_lr0=2.713e-04, train_time=0.950
[alab02] 2024-08-28 13:39:05,047 (trainer:720) INFO: 29epoch:train:4401-4600batch: iter_time=4.130e-04, forward_time=0.161, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=6.353, loss=3.176, backward_time=0.197, optim_step_time=0.056, optim0_lr0=2.711e-04, train_time=0.992
[alab02] 2024-08-28 13:40:48,572 (trainer:720) INFO: 29epoch:train:4601-4800batch: iter_time=4.737e-04, forward_time=0.169, uma_reduction=0.196, text_vs_uma=0.479, loss_ctc=6.117, loss=3.059, backward_time=0.207, optim_step_time=0.063, optim0_lr0=2.710e-04, train_time=1.035
[alab02] 2024-08-28 13:42:32,276 (trainer:720) INFO: 29epoch:train:4801-5000batch: iter_time=4.699e-04, forward_time=0.175, uma_reduction=0.197, text_vs_uma=0.483, loss_ctc=5.753, loss=2.876, backward_time=0.205, optim_step_time=0.066, optim0_lr0=2.709e-04, train_time=1.036
[alab02] 2024-08-28 13:44:16,954 (trainer:720) INFO: 29epoch:train:5001-5200batch: iter_time=4.524e-04, forward_time=0.174, uma_reduction=0.198, text_vs_uma=0.481, loss_ctc=5.629, loss=2.814, backward_time=0.215, optim_step_time=0.064, optim0_lr0=2.707e-04, train_time=1.046
[alab02] 2024-08-28 13:46:00,170 (trainer:720) INFO: 29epoch:train:5201-5400batch: iter_time=4.737e-04, forward_time=0.171, uma_reduction=0.196, text_vs_uma=0.490, loss_ctc=6.060, loss=3.030, backward_time=0.209, optim_step_time=0.064, optim0_lr0=2.706e-04, train_time=1.031
[alab02] 2024-08-28 13:47:43,642 (trainer:720) INFO: 29epoch:train:5401-5600batch: iter_time=4.137e-04, forward_time=0.171, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=6.070, loss=3.035, backward_time=0.208, optim_step_time=0.062, optim0_lr0=2.705e-04, train_time=1.034
[alab02] 2024-08-28 13:49:28,124 (trainer:720) INFO: 29epoch:train:5601-5800batch: iter_time=4.618e-04, forward_time=0.173, uma_reduction=0.197, text_vs_uma=0.484, loss_ctc=5.727, loss=2.863, backward_time=0.212, optim_step_time=0.063, optim0_lr0=2.703e-04, train_time=1.044
[alab02] 2024-08-28 13:51:09,965 (trainer:720) INFO: 29epoch:train:5801-6000batch: iter_time=4.697e-04, forward_time=0.170, uma_reduction=0.201, text_vs_uma=0.476, loss_ctc=5.660, loss=2.830, backward_time=0.205, optim_step_time=0.064, optim0_lr0=2.702e-04, train_time=1.018
[alab02] 2024-08-28 13:52:53,135 (trainer:720) INFO: 29epoch:train:6001-6200batch: iter_time=4.422e-04, forward_time=0.173, uma_reduction=0.199, text_vs_uma=0.478, loss_ctc=5.694, loss=2.847, backward_time=0.205, optim_step_time=0.065, optim0_lr0=2.701e-04, train_time=1.031
[alab02] 2024-08-28 13:54:34,880 (trainer:720) INFO: 29epoch:train:6201-6400batch: iter_time=5.243e-04, forward_time=0.172, uma_reduction=0.197, text_vs_uma=0.472, loss_ctc=5.454, loss=2.727, backward_time=0.204, optim_step_time=0.066, optim0_lr0=2.700e-04, train_time=1.017
[alab02] 2024-08-28 13:56:19,885 (trainer:720) INFO: 29epoch:train:6401-6600batch: iter_time=6.357e-04, forward_time=0.176, uma_reduction=0.199, text_vs_uma=0.486, loss_ctc=5.750, loss=2.875, backward_time=0.212, optim_step_time=0.069, optim0_lr0=2.698e-04, train_time=1.049
[alab02] 2024-08-28 13:58:02,623 (trainer:720) INFO: 29epoch:train:6601-6800batch: iter_time=4.427e-04, forward_time=0.168, uma_reduction=0.198, text_vs_uma=0.496, loss_ctc=5.948, loss=2.974, backward_time=0.211, optim_step_time=0.060, optim0_lr0=2.697e-04, train_time=1.027
[alab02] 2024-08-28 13:59:46,604 (trainer:720) INFO: 29epoch:train:6801-7000batch: iter_time=4.503e-04, forward_time=0.172, uma_reduction=0.199, text_vs_uma=0.481, loss_ctc=5.795, loss=2.898, backward_time=0.207, optim_step_time=0.065, optim0_lr0=2.696e-04, train_time=1.039
[alab02] 2024-08-28 14:01:24,901 (trainer:338) INFO: 29epoch results: [train] iter_time=5.155e-04, forward_time=0.164, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.928, loss=2.964, backward_time=0.202, optim_step_time=0.059, optim0_lr0=2.718e-04, train_time=1.005, time=59 minutes and 43.43 seconds, total_count=206654, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.185, text_vs_uma=0.585, loss_ctc=4.034, cer_ctc=0.102, cer=0.102, loss=4.034, time=8.61 seconds, total_count=754, gpu_max_cached_mem_GB=35.906, [att_plot] time=24.87 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 14:01:36,011 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 14:01:36,024 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/17epoch.pth
[alab02] 2024-08-28 14:01:36,025 (trainer:272) INFO: 30/150epoch started. Estimated time to finish: 4 days, 17 hours and 1 minute
[alab02] 2024-08-28 14:03:18,774 (trainer:720) INFO: 30epoch:train:1-200batch: iter_time=0.004, forward_time=0.168, uma_reduction=0.203, text_vs_uma=0.474, loss_ctc=5.522, loss=2.761, backward_time=0.204, optim_step_time=0.064, optim0_lr0=2.693e-04, train_time=1.026
[alab02] 2024-08-28 14:04:58,563 (trainer:720) INFO: 30epoch:train:201-400batch: iter_time=7.232e-04, forward_time=0.166, uma_reduction=0.204, text_vs_uma=0.479, loss_ctc=5.691, loss=2.845, backward_time=0.199, optim_step_time=0.061, optim0_lr0=2.692e-04, train_time=0.997
[alab02] 2024-08-28 14:06:37,881 (trainer:720) INFO: 30epoch:train:401-600batch: iter_time=6.901e-04, forward_time=0.162, uma_reduction=0.203, text_vs_uma=0.483, loss_ctc=6.057, loss=3.029, backward_time=0.196, optim_step_time=0.060, optim0_lr0=2.691e-04, train_time=0.993
[alab02] 2024-08-28 14:08:19,409 (trainer:720) INFO: 30epoch:train:601-800batch: iter_time=8.208e-04, forward_time=0.166, uma_reduction=0.201, text_vs_uma=0.460, loss_ctc=5.760, loss=2.880, backward_time=0.203, optim_step_time=0.059, optim0_lr0=2.690e-04, train_time=1.015
[alab02] 2024-08-28 14:09:59,717 (trainer:720) INFO: 30epoch:train:801-1000batch: iter_time=6.511e-04, forward_time=0.162, uma_reduction=0.203, text_vs_uma=0.467, loss_ctc=5.634, loss=2.817, backward_time=0.203, optim_step_time=0.061, optim0_lr0=2.688e-04, train_time=1.003
[alab02] 2024-08-28 14:11:43,482 (trainer:720) INFO: 30epoch:train:1001-1200batch: iter_time=7.616e-04, forward_time=0.171, uma_reduction=0.203, text_vs_uma=0.475, loss_ctc=5.778, loss=2.889, backward_time=0.208, optim_step_time=0.062, optim0_lr0=2.687e-04, train_time=1.037
[alab02] 2024-08-28 14:13:27,839 (trainer:720) INFO: 30epoch:train:1201-1400batch: iter_time=7.507e-04, forward_time=0.169, uma_reduction=0.199, text_vs_uma=0.492, loss_ctc=5.910, loss=2.955, backward_time=0.211, optim_step_time=0.063, optim0_lr0=2.686e-04, train_time=1.043
[alab02] 2024-08-28 14:15:11,183 (trainer:720) INFO: 30epoch:train:1401-1600batch: iter_time=5.986e-04, forward_time=0.170, uma_reduction=0.201, text_vs_uma=0.475, loss_ctc=5.646, loss=2.823, backward_time=0.208, optim_step_time=0.064, optim0_lr0=2.684e-04, train_time=1.033
[alab02] 2024-08-28 14:16:53,861 (trainer:720) INFO: 30epoch:train:1601-1800batch: iter_time=6.659e-04, forward_time=0.170, uma_reduction=0.197, text_vs_uma=0.491, loss_ctc=6.030, loss=3.015, backward_time=0.206, optim_step_time=0.064, optim0_lr0=2.683e-04, train_time=1.026
[alab02] 2024-08-28 14:18:38,492 (trainer:720) INFO: 30epoch:train:1801-2000batch: iter_time=7.344e-04, forward_time=0.174, uma_reduction=0.199, text_vs_uma=0.487, loss_ctc=5.997, loss=2.998, backward_time=0.209, optim_step_time=0.065, optim0_lr0=2.682e-04, train_time=1.046
[alab02] 2024-08-28 14:20:22,521 (trainer:720) INFO: 30epoch:train:2001-2200batch: iter_time=7.844e-04, forward_time=0.171, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=6.031, loss=3.015, backward_time=0.208, optim_step_time=0.064, optim0_lr0=2.681e-04, train_time=1.040
[alab02] 2024-08-28 14:22:05,205 (trainer:720) INFO: 30epoch:train:2201-2400batch: iter_time=8.002e-04, forward_time=0.167, uma_reduction=0.196, text_vs_uma=0.507, loss_ctc=6.448, loss=3.224, backward_time=0.203, optim_step_time=0.063, optim0_lr0=2.679e-04, train_time=1.026
[alab02] 2024-08-28 14:23:48,907 (trainer:720) INFO: 30epoch:train:2401-2600batch: iter_time=5.198e-04, forward_time=0.171, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=6.146, loss=3.073, backward_time=0.210, optim_step_time=0.060, optim0_lr0=2.678e-04, train_time=1.036
[alab02] 2024-08-28 14:25:30,905 (trainer:720) INFO: 30epoch:train:2601-2800batch: iter_time=6.835e-04, forward_time=0.169, uma_reduction=0.197, text_vs_uma=0.491, loss_ctc=6.408, loss=3.204, backward_time=0.204, optim_step_time=0.064, optim0_lr0=2.677e-04, train_time=1.020
[alab02] 2024-08-28 14:27:11,087 (trainer:720) INFO: 30epoch:train:2801-3000batch: iter_time=6.257e-04, forward_time=0.163, uma_reduction=0.198, text_vs_uma=0.482, loss_ctc=5.747, loss=2.873, backward_time=0.202, optim_step_time=0.061, optim0_lr0=2.675e-04, train_time=1.001
[alab02] 2024-08-28 14:28:55,423 (trainer:720) INFO: 30epoch:train:3001-3200batch: iter_time=6.251e-04, forward_time=0.173, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.673, loss=2.836, backward_time=0.211, optim_step_time=0.063, optim0_lr0=2.674e-04, train_time=1.042
[alab02] 2024-08-28 14:30:39,421 (trainer:720) INFO: 30epoch:train:3201-3400batch: iter_time=9.707e-04, forward_time=0.175, uma_reduction=0.197, text_vs_uma=0.480, loss_ctc=5.937, loss=2.968, backward_time=0.204, optim_step_time=0.070, optim0_lr0=2.673e-04, train_time=1.040
[alab02] 2024-08-28 14:32:21,422 (trainer:720) INFO: 30epoch:train:3401-3600batch: iter_time=5.159e-04, forward_time=0.168, uma_reduction=0.196, text_vs_uma=0.494, loss_ctc=6.076, loss=3.038, backward_time=0.209, optim_step_time=0.062, optim0_lr0=2.672e-04, train_time=1.019
[alab02] 2024-08-28 14:34:02,669 (trainer:720) INFO: 30epoch:train:3601-3800batch: iter_time=4.213e-04, forward_time=0.162, uma_reduction=0.197, text_vs_uma=0.475, loss_ctc=5.533, loss=2.766, backward_time=0.208, optim_step_time=0.061, optim0_lr0=2.670e-04, train_time=1.012
[alab02] 2024-08-28 14:35:43,225 (trainer:720) INFO: 30epoch:train:3801-4000batch: iter_time=4.284e-04, forward_time=0.161, uma_reduction=0.197, text_vs_uma=0.483, loss_ctc=5.458, loss=2.729, backward_time=0.208, optim_step_time=0.060, optim0_lr0=2.669e-04, train_time=1.005
[alab02] 2024-08-28 14:37:23,944 (trainer:720) INFO: 30epoch:train:4001-4200batch: iter_time=5.499e-04, forward_time=0.166, uma_reduction=0.196, text_vs_uma=0.490, loss_ctc=6.050, loss=3.025, backward_time=0.201, optim_step_time=0.063, optim0_lr0=2.668e-04, train_time=1.007
[alab02] 2024-08-28 14:39:03,936 (trainer:720) INFO: 30epoch:train:4201-4400batch: iter_time=6.141e-04, forward_time=0.162, uma_reduction=0.198, text_vs_uma=0.479, loss_ctc=5.977, loss=2.989, backward_time=0.201, optim_step_time=0.061, optim0_lr0=2.667e-04, train_time=0.999
[alab02] 2024-08-28 14:40:46,770 (trainer:720) INFO: 30epoch:train:4401-4600batch: iter_time=5.894e-04, forward_time=0.166, uma_reduction=0.200, text_vs_uma=0.487, loss_ctc=5.930, loss=2.965, backward_time=0.206, optim_step_time=0.061, optim0_lr0=2.665e-04, train_time=1.028
[alab02] 2024-08-28 14:42:26,125 (trainer:720) INFO: 30epoch:train:4601-4800batch: iter_time=4.904e-04, forward_time=0.159, uma_reduction=0.202, text_vs_uma=0.481, loss_ctc=6.032, loss=3.016, backward_time=0.201, optim_step_time=0.060, optim0_lr0=2.664e-04, train_time=0.993
[alab02] 2024-08-28 14:44:06,361 (trainer:720) INFO: 30epoch:train:4801-5000batch: iter_time=6.828e-04, forward_time=0.160, uma_reduction=0.199, text_vs_uma=0.490, loss_ctc=6.345, loss=3.173, backward_time=0.198, optim_step_time=0.062, optim0_lr0=2.663e-04, train_time=1.002
[alab02] 2024-08-28 14:45:43,302 (trainer:720) INFO: 30epoch:train:5001-5200batch: iter_time=5.868e-04, forward_time=0.156, uma_reduction=0.201, text_vs_uma=0.476, loss_ctc=5.739, loss=2.870, backward_time=0.193, optim_step_time=0.058, optim0_lr0=2.662e-04, train_time=0.969
[alab02] 2024-08-28 14:47:20,940 (trainer:720) INFO: 30epoch:train:5201-5400batch: iter_time=3.798e-04, forward_time=0.153, uma_reduction=0.200, text_vs_uma=0.483, loss_ctc=5.948, loss=2.974, backward_time=0.201, optim_step_time=0.052, optim0_lr0=2.660e-04, train_time=0.976
[alab02] 2024-08-28 14:48:51,556 (trainer:720) INFO: 30epoch:train:5401-5600batch: iter_time=2.447e-04, forward_time=0.139, uma_reduction=0.198, text_vs_uma=0.478, loss_ctc=6.321, loss=3.160, backward_time=0.182, optim_step_time=0.042, optim0_lr0=2.659e-04, train_time=0.906
[alab02] 2024-08-28 14:50:20,905 (trainer:720) INFO: 30epoch:train:5601-5800batch: iter_time=2.124e-04, forward_time=0.136, uma_reduction=0.199, text_vs_uma=0.477, loss_ctc=5.472, loss=2.736, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.658e-04, train_time=0.893
[alab02] 2024-08-28 14:51:49,611 (trainer:720) INFO: 30epoch:train:5801-6000batch: iter_time=1.966e-04, forward_time=0.134, uma_reduction=0.203, text_vs_uma=0.483, loss_ctc=6.091, loss=3.046, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.656e-04, train_time=0.887
[alab02] 2024-08-28 14:53:15,085 (trainer:720) INFO: 30epoch:train:6001-6200batch: iter_time=1.828e-04, forward_time=0.129, uma_reduction=0.201, text_vs_uma=0.474, loss_ctc=5.722, loss=2.861, backward_time=0.175, optim_step_time=0.033, optim0_lr0=2.655e-04, train_time=0.854
[alab02] 2024-08-28 14:54:41,760 (trainer:720) INFO: 30epoch:train:6201-6400batch: iter_time=1.767e-04, forward_time=0.130, uma_reduction=0.202, text_vs_uma=0.480, loss_ctc=6.216, loss=3.108, backward_time=0.175, optim_step_time=0.033, optim0_lr0=2.654e-04, train_time=0.867
[alab02] 2024-08-28 14:56:06,834 (trainer:720) INFO: 30epoch:train:6401-6600batch: iter_time=1.752e-04, forward_time=0.128, uma_reduction=0.207, text_vs_uma=0.464, loss_ctc=5.555, loss=2.777, backward_time=0.175, optim_step_time=0.033, optim0_lr0=2.653e-04, train_time=0.850
[alab02] 2024-08-28 14:57:34,271 (trainer:720) INFO: 30epoch:train:6601-6800batch: iter_time=2.227e-04, forward_time=0.131, uma_reduction=0.202, text_vs_uma=0.480, loss_ctc=5.605, loss=2.803, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.652e-04, train_time=0.874
[alab02] 2024-08-28 14:58:59,901 (trainer:720) INFO: 30epoch:train:6801-7000batch: iter_time=2.314e-04, forward_time=0.128, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.746, loss=2.873, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.650e-04, train_time=0.856
[alab02] 2024-08-28 15:00:15,725 (trainer:338) INFO: 30epoch results: [train] iter_time=6.195e-04, forward_time=0.158, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.896, loss=2.948, backward_time=0.198, optim_step_time=0.055, optim0_lr0=2.671e-04, train_time=0.982, time=58 minutes and 20.51 seconds, total_count=213780, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.191, text_vs_uma=0.568, loss_ctc=3.975, cer_ctc=0.105, cer=0.105, loss=3.975, time=6.03 seconds, total_count=780, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.17 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 15:00:21,151 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 15:00:21,157 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/19epoch.pth
[alab02] 2024-08-28 15:00:21,158 (trainer:272) INFO: 31/150epoch started. Estimated time to finish: 4 days, 16 hours and 15 minutes
[alab02] 2024-08-28 15:01:49,387 (trainer:720) INFO: 31epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.205, text_vs_uma=0.465, loss_ctc=5.161, loss=2.580, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.648e-04, train_time=0.882
[alab02] 2024-08-28 15:03:16,838 (trainer:720) INFO: 31epoch:train:201-400batch: iter_time=2.055e-04, forward_time=0.131, uma_reduction=0.203, text_vs_uma=0.476, loss_ctc=5.764, loss=2.882, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.647e-04, train_time=0.874
[alab02] 2024-08-28 15:04:44,226 (trainer:720) INFO: 31epoch:train:401-600batch: iter_time=2.027e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=6.171, loss=3.086, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.646e-04, train_time=0.874
[alab02] 2024-08-28 15:06:12,733 (trainer:720) INFO: 31epoch:train:601-800batch: iter_time=1.906e-04, forward_time=0.134, uma_reduction=0.201, text_vs_uma=0.477, loss_ctc=5.675, loss=2.838, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.645e-04, train_time=0.885
[alab02] 2024-08-28 15:07:40,154 (trainer:720) INFO: 31epoch:train:801-1000batch: iter_time=2.118e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.498, loss_ctc=6.719, loss=3.359, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.643e-04, train_time=0.874
[alab02] 2024-08-28 15:09:08,076 (trainer:720) INFO: 31epoch:train:1001-1200batch: iter_time=1.925e-04, forward_time=0.132, uma_reduction=0.201, text_vs_uma=0.473, loss_ctc=5.386, loss=2.693, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.642e-04, train_time=0.879
[alab02] 2024-08-28 15:10:35,101 (trainer:720) INFO: 31epoch:train:1201-1400batch: iter_time=1.888e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.478, loss_ctc=5.634, loss=2.817, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.641e-04, train_time=0.870
[alab02] 2024-08-28 15:12:03,012 (trainer:720) INFO: 31epoch:train:1401-1600batch: iter_time=1.845e-04, forward_time=0.132, uma_reduction=0.198, text_vs_uma=0.486, loss_ctc=5.998, loss=2.999, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.640e-04, train_time=0.879
[alab02] 2024-08-28 15:13:31,158 (trainer:720) INFO: 31epoch:train:1601-1800batch: iter_time=1.777e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=5.937, loss=2.969, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.638e-04, train_time=0.881
[alab02] 2024-08-28 15:14:57,689 (trainer:720) INFO: 31epoch:train:1801-2000batch: iter_time=1.945e-04, forward_time=0.129, uma_reduction=0.199, text_vs_uma=0.494, loss_ctc=5.681, loss=2.840, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.637e-04, train_time=0.865
[alab02] 2024-08-28 15:16:25,338 (trainer:720) INFO: 31epoch:train:2001-2200batch: iter_time=1.796e-04, forward_time=0.131, uma_reduction=0.203, text_vs_uma=0.472, loss_ctc=5.346, loss=2.673, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.636e-04, train_time=0.876
[alab02] 2024-08-28 15:17:52,944 (trainer:720) INFO: 31epoch:train:2201-2400batch: iter_time=1.852e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.480, loss_ctc=5.591, loss=2.795, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.635e-04, train_time=0.876
[alab02] 2024-08-28 15:19:21,816 (trainer:720) INFO: 31epoch:train:2401-2600batch: iter_time=1.819e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.733, loss=2.866, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.634e-04, train_time=0.888
[alab02] 2024-08-28 15:20:46,337 (trainer:720) INFO: 31epoch:train:2601-2800batch: iter_time=1.889e-04, forward_time=0.126, uma_reduction=0.192, text_vs_uma=0.488, loss_ctc=5.786, loss=2.893, backward_time=0.174, optim_step_time=0.034, optim0_lr0=2.632e-04, train_time=0.845
[alab02] 2024-08-28 15:22:13,131 (trainer:720) INFO: 31epoch:train:2801-3000batch: iter_time=1.766e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.494, loss_ctc=5.696, loss=2.848, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.631e-04, train_time=0.868
[alab02] 2024-08-28 15:23:39,535 (trainer:720) INFO: 31epoch:train:3001-3200batch: iter_time=1.934e-04, forward_time=0.129, uma_reduction=0.200, text_vs_uma=0.472, loss_ctc=5.509, loss=2.755, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.630e-04, train_time=0.864
[alab02] 2024-08-28 15:25:07,731 (trainer:720) INFO: 31epoch:train:3201-3400batch: iter_time=1.762e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.472, loss_ctc=5.318, loss=2.659, backward_time=0.186, optim_step_time=0.033, optim0_lr0=2.629e-04, train_time=0.882
[alab02] 2024-08-28 15:26:33,858 (trainer:720) INFO: 31epoch:train:3401-3600batch: iter_time=1.723e-04, forward_time=0.128, uma_reduction=0.198, text_vs_uma=0.487, loss_ctc=5.885, loss=2.942, backward_time=0.176, optim_step_time=0.033, optim0_lr0=2.627e-04, train_time=0.861
[alab02] 2024-08-28 15:28:02,095 (trainer:720) INFO: 31epoch:train:3601-3800batch: iter_time=1.809e-04, forward_time=0.133, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=5.844, loss=2.922, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.626e-04, train_time=0.882
[alab02] 2024-08-28 15:29:29,416 (trainer:720) INFO: 31epoch:train:3801-4000batch: iter_time=1.659e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.497, loss_ctc=5.591, loss=2.796, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.625e-04, train_time=0.873
[alab02] 2024-08-28 15:30:58,893 (trainer:720) INFO: 31epoch:train:4001-4200batch: iter_time=2.382e-04, forward_time=0.135, uma_reduction=0.196, text_vs_uma=0.487, loss_ctc=6.235, loss=3.117, backward_time=0.183, optim_step_time=0.037, optim0_lr0=2.624e-04, train_time=0.894
[alab02] 2024-08-28 15:32:34,530 (trainer:720) INFO: 31epoch:train:4201-4400batch: iter_time=3.424e-04, forward_time=0.150, uma_reduction=0.200, text_vs_uma=0.462, loss_ctc=5.470, loss=2.735, backward_time=0.195, optim_step_time=0.047, optim0_lr0=2.623e-04, train_time=0.956
[alab02] 2024-08-28 15:34:13,169 (trainer:720) INFO: 31epoch:train:4401-4600batch: iter_time=3.901e-04, forward_time=0.156, uma_reduction=0.202, text_vs_uma=0.480, loss_ctc=5.860, loss=2.930, backward_time=0.200, optim_step_time=0.051, optim0_lr0=2.621e-04, train_time=0.986
[alab02] 2024-08-28 15:35:49,326 (trainer:720) INFO: 31epoch:train:4601-4800batch: iter_time=4.355e-04, forward_time=0.154, uma_reduction=0.201, text_vs_uma=0.489, loss_ctc=5.829, loss=2.915, backward_time=0.193, optim_step_time=0.052, optim0_lr0=2.620e-04, train_time=0.961
[alab02] 2024-08-28 15:37:25,241 (trainer:720) INFO: 31epoch:train:4801-5000batch: iter_time=3.741e-04, forward_time=0.154, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=6.005, loss=3.003, backward_time=0.190, optim_step_time=0.049, optim0_lr0=2.619e-04, train_time=0.959
[alab02] 2024-08-28 15:39:01,605 (trainer:720) INFO: 31epoch:train:5001-5200batch: iter_time=3.772e-04, forward_time=0.152, uma_reduction=0.200, text_vs_uma=0.475, loss_ctc=5.346, loss=2.673, backward_time=0.201, optim_step_time=0.053, optim0_lr0=2.618e-04, train_time=0.963
[alab02] 2024-08-28 15:40:39,675 (trainer:720) INFO: 31epoch:train:5201-5400batch: iter_time=6.095e-04, forward_time=0.154, uma_reduction=0.202, text_vs_uma=0.471, loss_ctc=5.541, loss=2.770, backward_time=0.199, optim_step_time=0.054, optim0_lr0=2.617e-04, train_time=0.980
[alab02] 2024-08-28 15:42:15,435 (trainer:720) INFO: 31epoch:train:5401-5600batch: iter_time=5.513e-04, forward_time=0.149, uma_reduction=0.201, text_vs_uma=0.480, loss_ctc=5.510, loss=2.755, backward_time=0.194, optim_step_time=0.054, optim0_lr0=2.615e-04, train_time=0.957
[alab02] 2024-08-28 15:43:48,249 (trainer:720) INFO: 31epoch:train:5601-5800batch: iter_time=3.031e-04, forward_time=0.144, uma_reduction=0.199, text_vs_uma=0.478, loss_ctc=5.875, loss=2.938, backward_time=0.189, optim_step_time=0.045, optim0_lr0=2.614e-04, train_time=0.928
[alab02] 2024-08-28 15:45:23,113 (trainer:720) INFO: 31epoch:train:5801-6000batch: iter_time=4.827e-04, forward_time=0.149, uma_reduction=0.200, text_vs_uma=0.480, loss_ctc=5.965, loss=2.983, backward_time=0.188, optim_step_time=0.051, optim0_lr0=2.613e-04, train_time=0.948
[alab02] 2024-08-28 15:47:01,446 (trainer:720) INFO: 31epoch:train:6001-6200batch: iter_time=5.924e-04, forward_time=0.154, uma_reduction=0.202, text_vs_uma=0.471, loss_ctc=5.565, loss=2.783, backward_time=0.202, optim_step_time=0.055, optim0_lr0=2.612e-04, train_time=0.983
[alab02] 2024-08-28 15:48:36,384 (trainer:720) INFO: 31epoch:train:6201-6400batch: iter_time=4.336e-04, forward_time=0.148, uma_reduction=0.199, text_vs_uma=0.477, loss_ctc=5.613, loss=2.807, backward_time=0.196, optim_step_time=0.051, optim0_lr0=2.611e-04, train_time=0.949
[alab02] 2024-08-28 15:50:11,206 (trainer:720) INFO: 31epoch:train:6401-6600batch: iter_time=4.170e-04, forward_time=0.150, uma_reduction=0.201, text_vs_uma=0.482, loss_ctc=5.764, loss=2.882, backward_time=0.189, optim_step_time=0.051, optim0_lr0=2.609e-04, train_time=0.948
[alab02] 2024-08-28 15:51:47,088 (trainer:720) INFO: 31epoch:train:6601-6800batch: iter_time=4.511e-04, forward_time=0.151, uma_reduction=0.201, text_vs_uma=0.485, loss_ctc=5.828, loss=2.914, backward_time=0.193, optim_step_time=0.053, optim0_lr0=2.608e-04, train_time=0.958
[alab02] 2024-08-28 15:53:23,313 (trainer:720) INFO: 31epoch:train:6801-7000batch: iter_time=5.281e-04, forward_time=0.149, uma_reduction=0.201, text_vs_uma=0.486, loss_ctc=5.784, loss=2.892, backward_time=0.195, optim_step_time=0.053, optim0_lr0=2.607e-04, train_time=0.962
[alab02] 2024-08-28 15:54:52,438 (trainer:338) INFO: 31epoch results: [train] iter_time=3.575e-04, forward_time=0.139, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.733, loss=2.867, backward_time=0.186, optim_step_time=0.041, optim0_lr0=2.627e-04, train_time=0.910, time=54 minutes and 2.92 seconds, total_count=220906, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.182, text_vs_uma=0.597, loss_ctc=4.037, cer_ctc=0.104, cer=0.104, loss=4.037, time=8.1 seconds, total_count=806, gpu_max_cached_mem_GB=35.906, [att_plot] time=20.26 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 15:55:00,388 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 15:55:00,409 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/18epoch.pth
[alab02] 2024-08-28 15:55:00,410 (trainer:272) INFO: 32/150epoch started. Estimated time to finish: 4 days, 15 hours and 14 minutes
[alab02] 2024-08-28 15:56:35,880 (trainer:720) INFO: 32epoch:train:1-200batch: iter_time=0.004, forward_time=0.148, uma_reduction=0.194, text_vs_uma=0.499, loss_ctc=6.314, loss=3.157, backward_time=0.186, optim_step_time=0.051, optim0_lr0=2.605e-04, train_time=0.954
[alab02] 2024-08-28 15:58:12,374 (trainer:720) INFO: 32epoch:train:201-400batch: iter_time=6.133e-04, forward_time=0.149, uma_reduction=0.198, text_vs_uma=0.484, loss_ctc=5.634, loss=2.817, backward_time=0.197, optim_step_time=0.054, optim0_lr0=2.604e-04, train_time=0.965
[alab02] 2024-08-28 15:59:49,115 (trainer:720) INFO: 32epoch:train:401-600batch: iter_time=5.965e-04, forward_time=0.150, uma_reduction=0.201, text_vs_uma=0.472, loss_ctc=5.625, loss=2.813, backward_time=0.195, optim_step_time=0.056, optim0_lr0=2.603e-04, train_time=0.967
[alab02] 2024-08-28 16:01:24,820 (trainer:720) INFO: 32epoch:train:601-800batch: iter_time=5.044e-04, forward_time=0.149, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=5.717, loss=2.858, backward_time=0.194, optim_step_time=0.057, optim0_lr0=2.602e-04, train_time=0.957
[alab02] 2024-08-28 16:02:57,910 (trainer:720) INFO: 32epoch:train:801-1000batch: iter_time=4.674e-04, forward_time=0.145, uma_reduction=0.196, text_vs_uma=0.492, loss_ctc=5.694, loss=2.847, backward_time=0.187, optim_step_time=0.048, optim0_lr0=2.600e-04, train_time=0.930
[alab02] 2024-08-28 16:04:29,441 (trainer:720) INFO: 32epoch:train:1001-1200batch: iter_time=4.342e-04, forward_time=0.142, uma_reduction=0.198, text_vs_uma=0.485, loss_ctc=5.467, loss=2.733, backward_time=0.184, optim_step_time=0.050, optim0_lr0=2.599e-04, train_time=0.915
[alab02] 2024-08-28 16:06:02,844 (trainer:720) INFO: 32epoch:train:1201-1400batch: iter_time=4.905e-04, forward_time=0.145, uma_reduction=0.195, text_vs_uma=0.498, loss_ctc=6.087, loss=3.043, backward_time=0.187, optim_step_time=0.048, optim0_lr0=2.598e-04, train_time=0.934
[alab02] 2024-08-28 16:07:38,559 (trainer:720) INFO: 32epoch:train:1401-1600batch: iter_time=4.504e-04, forward_time=0.151, uma_reduction=0.197, text_vs_uma=0.501, loss_ctc=5.773, loss=2.886, backward_time=0.197, optim_step_time=0.049, optim0_lr0=2.597e-04, train_time=0.957
[alab02] 2024-08-28 16:09:12,971 (trainer:720) INFO: 32epoch:train:1601-1800batch: iter_time=5.091e-04, forward_time=0.148, uma_reduction=0.198, text_vs_uma=0.480, loss_ctc=5.779, loss=2.889, backward_time=0.190, optim_step_time=0.051, optim0_lr0=2.596e-04, train_time=0.944
[alab02] 2024-08-28 16:10:47,349 (trainer:720) INFO: 32epoch:train:1801-2000batch: iter_time=3.383e-04, forward_time=0.148, uma_reduction=0.200, text_vs_uma=0.488, loss_ctc=5.417, loss=2.708, backward_time=0.193, optim_step_time=0.045, optim0_lr0=2.595e-04, train_time=0.943
[alab02] 2024-08-28 16:12:24,884 (trainer:720) INFO: 32epoch:train:2001-2200batch: iter_time=4.009e-04, forward_time=0.154, uma_reduction=0.198, text_vs_uma=0.489, loss_ctc=5.613, loss=2.806, backward_time=0.201, optim_step_time=0.052, optim0_lr0=2.593e-04, train_time=0.975
[alab02] 2024-08-28 16:13:58,329 (trainer:720) INFO: 32epoch:train:2201-2400batch: iter_time=3.582e-04, forward_time=0.148, uma_reduction=0.198, text_vs_uma=0.494, loss_ctc=5.866, loss=2.933, backward_time=0.186, optim_step_time=0.052, optim0_lr0=2.592e-04, train_time=0.934
[alab02] 2024-08-28 16:15:37,480 (trainer:720) INFO: 32epoch:train:2401-2600batch: iter_time=3.732e-04, forward_time=0.158, uma_reduction=0.197, text_vs_uma=0.485, loss_ctc=5.774, loss=2.887, backward_time=0.203, optim_step_time=0.055, optim0_lr0=2.591e-04, train_time=0.991
[alab02] 2024-08-28 16:17:13,385 (trainer:720) INFO: 32epoch:train:2601-2800batch: iter_time=4.137e-04, forward_time=0.152, uma_reduction=0.197, text_vs_uma=0.489, loss_ctc=5.800, loss=2.900, backward_time=0.191, optim_step_time=0.055, optim0_lr0=2.590e-04, train_time=0.958
[alab02] 2024-08-28 16:18:48,677 (trainer:720) INFO: 32epoch:train:2801-3000batch: iter_time=3.575e-04, forward_time=0.150, uma_reduction=0.199, text_vs_uma=0.492, loss_ctc=5.702, loss=2.851, backward_time=0.194, optim_step_time=0.052, optim0_lr0=2.589e-04, train_time=0.953
[alab02] 2024-08-28 16:20:24,965 (trainer:720) INFO: 32epoch:train:3001-3200batch: iter_time=4.188e-04, forward_time=0.152, uma_reduction=0.200, text_vs_uma=0.473, loss_ctc=5.506, loss=2.753, backward_time=0.193, optim_step_time=0.055, optim0_lr0=2.588e-04, train_time=0.962
[alab02] 2024-08-28 16:22:03,546 (trainer:720) INFO: 32epoch:train:3201-3400batch: iter_time=4.110e-04, forward_time=0.157, uma_reduction=0.201, text_vs_uma=0.474, loss_ctc=5.845, loss=2.923, backward_time=0.198, optim_step_time=0.054, optim0_lr0=2.587e-04, train_time=0.985
[alab02] 2024-08-28 16:23:40,024 (trainer:720) INFO: 32epoch:train:3401-3600batch: iter_time=4.965e-04, forward_time=0.153, uma_reduction=0.202, text_vs_uma=0.465, loss_ctc=5.180, loss=2.590, backward_time=0.197, optim_step_time=0.053, optim0_lr0=2.585e-04, train_time=0.964
[alab02] 2024-08-28 16:25:19,434 (trainer:720) INFO: 32epoch:train:3601-3800batch: iter_time=4.146e-04, forward_time=0.158, uma_reduction=0.199, text_vs_uma=0.472, loss_ctc=5.580, loss=2.790, backward_time=0.201, optim_step_time=0.055, optim0_lr0=2.584e-04, train_time=0.994
[alab02] 2024-08-28 16:26:57,139 (trainer:720) INFO: 32epoch:train:3801-4000batch: iter_time=3.982e-04, forward_time=0.153, uma_reduction=0.199, text_vs_uma=0.487, loss_ctc=5.996, loss=2.998, backward_time=0.197, optim_step_time=0.055, optim0_lr0=2.583e-04, train_time=0.976
[alab02] 2024-08-28 16:28:35,348 (trainer:720) INFO: 32epoch:train:4001-4200batch: iter_time=4.301e-04, forward_time=0.154, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.631, loss=2.815, backward_time=0.201, optim_step_time=0.056, optim0_lr0=2.582e-04, train_time=0.982
[alab02] 2024-08-28 16:30:10,828 (trainer:720) INFO: 32epoch:train:4201-4400batch: iter_time=3.845e-04, forward_time=0.151, uma_reduction=0.201, text_vs_uma=0.479, loss_ctc=5.474, loss=2.737, backward_time=0.194, optim_step_time=0.052, optim0_lr0=2.581e-04, train_time=0.954
[alab02] 2024-08-28 16:31:47,629 (trainer:720) INFO: 32epoch:train:4401-4600batch: iter_time=4.537e-04, forward_time=0.154, uma_reduction=0.201, text_vs_uma=0.473, loss_ctc=5.433, loss=2.717, backward_time=0.197, optim_step_time=0.053, optim0_lr0=2.580e-04, train_time=0.968
[alab02] 2024-08-28 16:33:22,144 (trainer:720) INFO: 32epoch:train:4601-4800batch: iter_time=4.041e-04, forward_time=0.148, uma_reduction=0.201, text_vs_uma=0.470, loss_ctc=5.403, loss=2.701, backward_time=0.192, optim_step_time=0.052, optim0_lr0=2.579e-04, train_time=0.945
[alab02] 2024-08-28 16:34:59,513 (trainer:720) INFO: 32epoch:train:4801-5000batch: iter_time=4.202e-04, forward_time=0.152, uma_reduction=0.202, text_vs_uma=0.486, loss_ctc=5.802, loss=2.901, backward_time=0.198, optim_step_time=0.052, optim0_lr0=2.577e-04, train_time=0.973
[alab02] 2024-08-28 16:36:34,981 (trainer:720) INFO: 32epoch:train:5001-5200batch: iter_time=4.250e-04, forward_time=0.150, uma_reduction=0.201, text_vs_uma=0.466, loss_ctc=5.344, loss=2.672, backward_time=0.194, optim_step_time=0.050, optim0_lr0=2.576e-04, train_time=0.954
[alab02] 2024-08-28 16:38:06,444 (trainer:720) INFO: 32epoch:train:5201-5400batch: iter_time=3.813e-04, forward_time=0.144, uma_reduction=0.198, text_vs_uma=0.488, loss_ctc=5.481, loss=2.741, backward_time=0.186, optim_step_time=0.047, optim0_lr0=2.575e-04, train_time=0.914
[alab02] 2024-08-28 16:39:41,015 (trainer:720) INFO: 32epoch:train:5401-5600batch: iter_time=3.384e-04, forward_time=0.147, uma_reduction=0.198, text_vs_uma=0.481, loss_ctc=5.601, loss=2.800, backward_time=0.195, optim_step_time=0.050, optim0_lr0=2.574e-04, train_time=0.945
[alab02] 2024-08-28 16:41:12,639 (trainer:720) INFO: 32epoch:train:5601-5800batch: iter_time=3.277e-04, forward_time=0.143, uma_reduction=0.197, text_vs_uma=0.476, loss_ctc=5.865, loss=2.932, backward_time=0.184, optim_step_time=0.048, optim0_lr0=2.573e-04, train_time=0.916
[alab02] 2024-08-28 16:42:45,878 (trainer:720) INFO: 32epoch:train:5801-6000batch: iter_time=3.144e-04, forward_time=0.146, uma_reduction=0.201, text_vs_uma=0.477, loss_ctc=5.718, loss=2.859, backward_time=0.189, optim_step_time=0.046, optim0_lr0=2.572e-04, train_time=0.932
[alab02] 2024-08-28 16:44:20,371 (trainer:720) INFO: 32epoch:train:6001-6200batch: iter_time=2.889e-04, forward_time=0.147, uma_reduction=0.199, text_vs_uma=0.477, loss_ctc=5.844, loss=2.922, backward_time=0.193, optim_step_time=0.043, optim0_lr0=2.571e-04, train_time=0.945
[alab02] 2024-08-28 16:45:55,729 (trainer:720) INFO: 32epoch:train:6201-6400batch: iter_time=3.094e-04, forward_time=0.151, uma_reduction=0.200, text_vs_uma=0.472, loss_ctc=5.182, loss=2.591, backward_time=0.196, optim_step_time=0.047, optim0_lr0=2.569e-04, train_time=0.953
[alab02] 2024-08-28 16:47:29,652 (trainer:720) INFO: 32epoch:train:6401-6600batch: iter_time=3.160e-04, forward_time=0.147, uma_reduction=0.200, text_vs_uma=0.480, loss_ctc=5.505, loss=2.753, backward_time=0.192, optim_step_time=0.047, optim0_lr0=2.568e-04, train_time=0.939
[alab02] 2024-08-28 16:49:01,912 (trainer:720) INFO: 32epoch:train:6601-6800batch: iter_time=3.006e-04, forward_time=0.144, uma_reduction=0.199, text_vs_uma=0.490, loss_ctc=5.975, loss=2.987, backward_time=0.184, optim_step_time=0.044, optim0_lr0=2.567e-04, train_time=0.922
[alab02] 2024-08-28 16:50:32,367 (trainer:720) INFO: 32epoch:train:6801-7000batch: iter_time=2.402e-04, forward_time=0.140, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.330, loss=2.665, backward_time=0.184, optim_step_time=0.041, optim0_lr0=2.566e-04, train_time=0.904
[alab02] 2024-08-28 16:51:54,346 (trainer:338) INFO: 32epoch results: [train] iter_time=5.133e-04, forward_time=0.149, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.650, loss=2.825, backward_time=0.193, optim_step_time=0.051, optim0_lr0=2.585e-04, train_time=0.951, time=56 minutes and 30.44 seconds, total_count=228032, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.181, text_vs_uma=0.598, loss_ctc=4.248, cer_ctc=0.106, cer=0.106, loss=4.248, time=6.47 seconds, total_count=832, gpu_max_cached_mem_GB=35.906, [att_plot] time=17.02 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 16:52:00,876 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 16:52:00,884 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/23epoch.pth
[alab02] 2024-08-28 16:52:00,884 (trainer:272) INFO: 33/150epoch started. Estimated time to finish: 4 days, 14 hours and 21 minutes
[alab02] 2024-08-28 16:53:32,893 (trainer:720) INFO: 33epoch:train:1-200batch: iter_time=0.002, forward_time=0.141, uma_reduction=0.198, text_vs_uma=0.493, loss_ctc=6.008, loss=3.004, backward_time=0.183, optim_step_time=0.038, optim0_lr0=2.564e-04, train_time=0.919
[alab02] 2024-08-28 16:55:04,698 (trainer:720) INFO: 33epoch:train:201-400batch: iter_time=2.368e-04, forward_time=0.140, uma_reduction=0.200, text_vs_uma=0.473, loss_ctc=5.831, loss=2.916, backward_time=0.189, optim_step_time=0.037, optim0_lr0=2.563e-04, train_time=0.918
[alab02] 2024-08-28 16:56:34,445 (trainer:720) INFO: 33epoch:train:401-600batch: iter_time=2.098e-04, forward_time=0.137, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=5.840, loss=2.920, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.562e-04, train_time=0.897
[alab02] 2024-08-28 16:58:01,655 (trainer:720) INFO: 33epoch:train:601-800batch: iter_time=2.372e-04, forward_time=0.134, uma_reduction=0.196, text_vs_uma=0.497, loss_ctc=5.798, loss=2.899, backward_time=0.178, optim_step_time=0.036, optim0_lr0=2.561e-04, train_time=0.872
[alab02] 2024-08-28 16:59:28,667 (trainer:720) INFO: 33epoch:train:801-1000batch: iter_time=2.219e-04, forward_time=0.132, uma_reduction=0.197, text_vs_uma=0.489, loss_ctc=5.812, loss=2.906, backward_time=0.177, optim_step_time=0.035, optim0_lr0=2.560e-04, train_time=0.870
[alab02] 2024-08-28 17:00:58,300 (trainer:720) INFO: 33epoch:train:1001-1200batch: iter_time=2.110e-04, forward_time=0.136, uma_reduction=0.202, text_vs_uma=0.466, loss_ctc=5.312, loss=2.656, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.559e-04, train_time=0.896
[alab02] 2024-08-28 17:02:26,867 (trainer:720) INFO: 33epoch:train:1201-1400batch: iter_time=2.122e-04, forward_time=0.134, uma_reduction=0.198, text_vs_uma=0.478, loss_ctc=5.674, loss=2.837, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.557e-04, train_time=0.885
[alab02] 2024-08-28 17:03:55,077 (trainer:720) INFO: 33epoch:train:1401-1600batch: iter_time=2.127e-04, forward_time=0.134, uma_reduction=0.198, text_vs_uma=0.490, loss_ctc=5.779, loss=2.890, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.556e-04, train_time=0.882
[alab02] 2024-08-28 17:05:23,475 (trainer:720) INFO: 33epoch:train:1601-1800batch: iter_time=1.879e-04, forward_time=0.134, uma_reduction=0.201, text_vs_uma=0.488, loss_ctc=5.922, loss=2.961, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.555e-04, train_time=0.884
[alab02] 2024-08-28 17:06:51,315 (trainer:720) INFO: 33epoch:train:1801-2000batch: iter_time=2.042e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.155, loss=2.577, backward_time=0.186, optim_step_time=0.034, optim0_lr0=2.554e-04, train_time=0.878
[alab02] 2024-08-28 17:08:20,047 (trainer:720) INFO: 33epoch:train:2001-2200batch: iter_time=1.892e-04, forward_time=0.132, uma_reduction=0.197, text_vs_uma=0.482, loss_ctc=6.159, loss=3.080, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.553e-04, train_time=0.887
[alab02] 2024-08-28 17:09:47,515 (trainer:720) INFO: 33epoch:train:2201-2400batch: iter_time=1.759e-04, forward_time=0.131, uma_reduction=0.202, text_vs_uma=0.487, loss_ctc=5.847, loss=2.924, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.552e-04, train_time=0.875
[alab02] 2024-08-28 17:11:16,266 (trainer:720) INFO: 33epoch:train:2401-2600batch: iter_time=2.179e-04, forward_time=0.134, uma_reduction=0.203, text_vs_uma=0.469, loss_ctc=5.320, loss=2.660, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.551e-04, train_time=0.887
[alab02] 2024-08-28 17:12:42,672 (trainer:720) INFO: 33epoch:train:2601-2800batch: iter_time=2.069e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=5.467, loss=2.734, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.550e-04, train_time=0.864
[alab02] 2024-08-28 17:14:10,913 (trainer:720) INFO: 33epoch:train:2801-3000batch: iter_time=1.985e-04, forward_time=0.133, uma_reduction=0.199, text_vs_uma=0.477, loss_ctc=5.572, loss=2.786, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.549e-04, train_time=0.882
[alab02] 2024-08-28 17:15:37,889 (trainer:720) INFO: 33epoch:train:3001-3200batch: iter_time=2.045e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.480, loss_ctc=6.069, loss=3.034, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.547e-04, train_time=0.870
[alab02] 2024-08-28 17:17:04,393 (trainer:720) INFO: 33epoch:train:3201-3400batch: iter_time=1.850e-04, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.472, loss_ctc=5.035, loss=2.517, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.546e-04, train_time=0.865
[alab02] 2024-08-28 17:18:31,378 (trainer:720) INFO: 33epoch:train:3401-3600batch: iter_time=1.916e-04, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.470, loss_ctc=5.371, loss=2.685, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.545e-04, train_time=0.870
[alab02] 2024-08-28 17:19:58,047 (trainer:720) INFO: 33epoch:train:3601-3800batch: iter_time=1.869e-04, forward_time=0.129, uma_reduction=0.199, text_vs_uma=0.480, loss_ctc=5.910, loss=2.955, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.544e-04, train_time=0.866
[alab02] 2024-08-28 17:21:25,637 (trainer:720) INFO: 33epoch:train:3801-4000batch: iter_time=1.947e-04, forward_time=0.133, uma_reduction=0.204, text_vs_uma=0.484, loss_ctc=5.905, loss=2.953, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.543e-04, train_time=0.876
[alab02] 2024-08-28 17:22:55,034 (trainer:720) INFO: 33epoch:train:4001-4200batch: iter_time=1.889e-04, forward_time=0.135, uma_reduction=0.206, text_vs_uma=0.461, loss_ctc=5.757, loss=2.879, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.542e-04, train_time=0.894
[alab02] 2024-08-28 17:24:22,372 (trainer:720) INFO: 33epoch:train:4201-4400batch: iter_time=1.973e-04, forward_time=0.132, uma_reduction=0.206, text_vs_uma=0.477, loss_ctc=5.338, loss=2.669, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.541e-04, train_time=0.873
[alab02] 2024-08-28 17:25:49,756 (trainer:720) INFO: 33epoch:train:4401-4600batch: iter_time=1.841e-04, forward_time=0.132, uma_reduction=0.204, text_vs_uma=0.471, loss_ctc=5.642, loss=2.821, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.540e-04, train_time=0.874
[alab02] 2024-08-28 17:27:17,553 (trainer:720) INFO: 33epoch:train:4601-4800batch: iter_time=1.837e-04, forward_time=0.132, uma_reduction=0.208, text_vs_uma=0.469, loss_ctc=5.304, loss=2.652, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.539e-04, train_time=0.878
[alab02] 2024-08-28 17:28:44,966 (trainer:720) INFO: 33epoch:train:4801-5000batch: iter_time=1.869e-04, forward_time=0.131, uma_reduction=0.205, text_vs_uma=0.469, loss_ctc=5.637, loss=2.818, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.538e-04, train_time=0.874
[alab02] 2024-08-28 17:30:12,904 (trainer:720) INFO: 33epoch:train:5001-5200batch: iter_time=1.645e-04, forward_time=0.132, uma_reduction=0.201, text_vs_uma=0.482, loss_ctc=5.845, loss=2.922, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.537e-04, train_time=0.879
[alab02] 2024-08-28 17:31:40,630 (trainer:720) INFO: 33epoch:train:5201-5400batch: iter_time=1.876e-04, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.482, loss_ctc=5.453, loss=2.726, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.535e-04, train_time=0.877
[alab02] 2024-08-28 17:33:06,377 (trainer:720) INFO: 33epoch:train:5401-5600batch: iter_time=1.893e-04, forward_time=0.128, uma_reduction=0.205, text_vs_uma=0.481, loss_ctc=5.542, loss=2.771, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.534e-04, train_time=0.857
[alab02] 2024-08-28 17:34:33,097 (trainer:720) INFO: 33epoch:train:5601-5800batch: iter_time=1.879e-04, forward_time=0.129, uma_reduction=0.204, text_vs_uma=0.469, loss_ctc=5.205, loss=2.603, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.533e-04, train_time=0.867
[alab02] 2024-08-28 17:35:59,539 (trainer:720) INFO: 33epoch:train:5801-6000batch: iter_time=1.821e-04, forward_time=0.130, uma_reduction=0.203, text_vs_uma=0.474, loss_ctc=5.122, loss=2.561, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.532e-04, train_time=0.864
[alab02] 2024-08-28 17:37:27,677 (trainer:720) INFO: 33epoch:train:6001-6200batch: iter_time=1.865e-04, forward_time=0.133, uma_reduction=0.201, text_vs_uma=0.478, loss_ctc=5.650, loss=2.825, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.531e-04, train_time=0.881
[alab02] 2024-08-28 17:38:55,671 (trainer:720) INFO: 33epoch:train:6201-6400batch: iter_time=1.751e-04, forward_time=0.131, uma_reduction=0.201, text_vs_uma=0.491, loss_ctc=6.354, loss=3.177, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.530e-04, train_time=0.880
[alab02] 2024-08-28 17:40:23,009 (trainer:720) INFO: 33epoch:train:6401-6600batch: iter_time=1.695e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.482, loss_ctc=6.160, loss=3.080, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.529e-04, train_time=0.873
[alab02] 2024-08-28 17:41:50,186 (trainer:720) INFO: 33epoch:train:6601-6800batch: iter_time=1.745e-04, forward_time=0.131, uma_reduction=0.202, text_vs_uma=0.466, loss_ctc=5.316, loss=2.658, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.528e-04, train_time=0.872
[alab02] 2024-08-28 17:43:16,833 (trainer:720) INFO: 33epoch:train:6801-7000batch: iter_time=1.743e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.475, loss_ctc=5.398, loss=2.699, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.527e-04, train_time=0.866
[alab02] 2024-08-28 17:44:33,733 (trainer:338) INFO: 33epoch results: [train] iter_time=2.578e-04, forward_time=0.133, uma_reduction=0.201, text_vs_uma=0.479, loss_ctc=5.637, loss=2.818, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.545e-04, train_time=0.879, time=52 minutes and 13.79 seconds, total_count=235158, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.183, text_vs_uma=0.591, loss_ctc=3.809, cer_ctc=0.102, cer=0.102, loss=3.809, time=6.05 seconds, total_count=858, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.01 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 17:44:39,162 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 17:44:39,169 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/21epoch.pth
[alab02] 2024-08-28 17:44:39,169 (trainer:272) INFO: 34/150epoch started. Estimated time to finish: 4 days, 13 hours and 12 minutes
[alab02] 2024-08-28 17:46:09,112 (trainer:720) INFO: 34epoch:train:1-200batch: iter_time=0.003, forward_time=0.134, uma_reduction=0.199, text_vs_uma=0.485, loss_ctc=5.905, loss=2.953, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.525e-04, train_time=0.899
[alab02] 2024-08-28 17:47:34,849 (trainer:720) INFO: 34epoch:train:201-400batch: iter_time=2.042e-04, forward_time=0.128, uma_reduction=0.200, text_vs_uma=0.474, loss_ctc=5.307, loss=2.653, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.524e-04, train_time=0.857
[alab02] 2024-08-28 17:49:04,534 (trainer:720) INFO: 34epoch:train:401-600batch: iter_time=1.994e-04, forward_time=0.135, uma_reduction=0.198, text_vs_uma=0.488, loss_ctc=5.878, loss=2.939, backward_time=0.188, optim_step_time=0.034, optim0_lr0=2.523e-04, train_time=0.897
[alab02] 2024-08-28 17:50:31,936 (trainer:720) INFO: 34epoch:train:601-800batch: iter_time=1.918e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=5.887, loss=2.944, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.522e-04, train_time=0.874
[alab02] 2024-08-28 17:51:58,194 (trainer:720) INFO: 34epoch:train:801-1000batch: iter_time=2.018e-04, forward_time=0.129, uma_reduction=0.198, text_vs_uma=0.493, loss_ctc=6.016, loss=3.008, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.521e-04, train_time=0.862
[alab02] 2024-08-28 17:53:27,859 (trainer:720) INFO: 34epoch:train:1001-1200batch: iter_time=2.267e-04, forward_time=0.135, uma_reduction=0.195, text_vs_uma=0.488, loss_ctc=5.839, loss=2.920, backward_time=0.187, optim_step_time=0.033, optim0_lr0=2.520e-04, train_time=0.896
[alab02] 2024-08-28 17:54:55,462 (trainer:720) INFO: 34epoch:train:1201-1400batch: iter_time=1.959e-04, forward_time=0.132, uma_reduction=0.197, text_vs_uma=0.479, loss_ctc=5.583, loss=2.792, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.519e-04, train_time=0.876
[alab02] 2024-08-28 17:56:22,343 (trainer:720) INFO: 34epoch:train:1401-1600batch: iter_time=1.969e-04, forward_time=0.130, uma_reduction=0.194, text_vs_uma=0.487, loss_ctc=5.616, loss=2.808, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.518e-04, train_time=0.869
[alab02] 2024-08-28 17:57:50,765 (trainer:720) INFO: 34epoch:train:1601-1800batch: iter_time=1.974e-04, forward_time=0.132, uma_reduction=0.197, text_vs_uma=0.499, loss_ctc=5.917, loss=2.958, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.517e-04, train_time=0.884
[alab02] 2024-08-28 17:59:17,829 (trainer:720) INFO: 34epoch:train:1801-2000batch: iter_time=2.173e-04, forward_time=0.131, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=5.783, loss=2.892, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.515e-04, train_time=0.870
[alab02] 2024-08-28 18:00:46,549 (trainer:720) INFO: 34epoch:train:2001-2200batch: iter_time=1.944e-04, forward_time=0.132, uma_reduction=0.196, text_vs_uma=0.495, loss_ctc=5.444, loss=2.722, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.514e-04, train_time=0.887
[alab02] 2024-08-28 18:02:14,429 (trainer:720) INFO: 34epoch:train:2201-2400batch: iter_time=1.915e-04, forward_time=0.131, uma_reduction=0.198, text_vs_uma=0.472, loss_ctc=5.656, loss=2.828, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.513e-04, train_time=0.879
[alab02] 2024-08-28 18:03:40,779 (trainer:720) INFO: 34epoch:train:2401-2600batch: iter_time=2.398e-04, forward_time=0.130, uma_reduction=0.202, text_vs_uma=0.476, loss_ctc=5.338, loss=2.669, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.512e-04, train_time=0.863
[alab02] 2024-08-28 18:05:08,331 (trainer:720) INFO: 34epoch:train:2601-2800batch: iter_time=2.064e-04, forward_time=0.132, uma_reduction=0.203, text_vs_uma=0.471, loss_ctc=5.616, loss=2.808, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.511e-04, train_time=0.875
[alab02] 2024-08-28 18:06:37,928 (trainer:720) INFO: 34epoch:train:2801-3000batch: iter_time=2.411e-04, forward_time=0.135, uma_reduction=0.205, text_vs_uma=0.467, loss_ctc=5.192, loss=2.596, backward_time=0.190, optim_step_time=0.036, optim0_lr0=2.510e-04, train_time=0.896
[alab02] 2024-08-28 18:08:06,511 (trainer:720) INFO: 34epoch:train:3001-3200batch: iter_time=2.032e-04, forward_time=0.133, uma_reduction=0.199, text_vs_uma=0.486, loss_ctc=5.724, loss=2.862, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.509e-04, train_time=0.886
[alab02] 2024-08-28 18:09:35,803 (trainer:720) INFO: 34epoch:train:3201-3400batch: iter_time=2.287e-04, forward_time=0.133, uma_reduction=0.200, text_vs_uma=0.470, loss_ctc=5.526, loss=2.763, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.508e-04, train_time=0.893
[alab02] 2024-08-28 18:11:04,026 (trainer:720) INFO: 34epoch:train:3401-3600batch: iter_time=2.641e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.481, loss_ctc=5.397, loss=2.699, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.507e-04, train_time=0.882
[alab02] 2024-08-28 18:12:31,325 (trainer:720) INFO: 34epoch:train:3601-3800batch: iter_time=1.910e-04, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.479, loss_ctc=5.670, loss=2.835, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.506e-04, train_time=0.873
[alab02] 2024-08-28 18:13:58,066 (trainer:720) INFO: 34epoch:train:3801-4000batch: iter_time=1.929e-04, forward_time=0.130, uma_reduction=0.196, text_vs_uma=0.480, loss_ctc=5.371, loss=2.685, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.505e-04, train_time=0.867
[alab02] 2024-08-28 18:15:26,357 (trainer:720) INFO: 34epoch:train:4001-4200batch: iter_time=1.833e-04, forward_time=0.132, uma_reduction=0.198, text_vs_uma=0.478, loss_ctc=5.291, loss=2.645, backward_time=0.186, optim_step_time=0.033, optim0_lr0=2.504e-04, train_time=0.883
[alab02] 2024-08-28 18:16:52,757 (trainer:720) INFO: 34epoch:train:4201-4400batch: iter_time=1.867e-04, forward_time=0.129, uma_reduction=0.199, text_vs_uma=0.492, loss_ctc=5.706, loss=2.853, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.503e-04, train_time=0.864
[alab02] 2024-08-28 18:18:21,597 (trainer:720) INFO: 34epoch:train:4401-4600batch: iter_time=1.785e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.495, loss_ctc=5.658, loss=2.829, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.502e-04, train_time=0.888
[alab02] 2024-08-28 18:19:48,735 (trainer:720) INFO: 34epoch:train:4601-4800batch: iter_time=1.794e-04, forward_time=0.129, uma_reduction=0.199, text_vs_uma=0.480, loss_ctc=5.907, loss=2.953, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.501e-04, train_time=0.871
[alab02] 2024-08-28 18:21:17,036 (trainer:720) INFO: 34epoch:train:4801-5000batch: iter_time=1.897e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.494, loss_ctc=6.214, loss=3.107, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.500e-04, train_time=0.883
[alab02] 2024-08-28 18:22:44,620 (trainer:720) INFO: 34epoch:train:5001-5200batch: iter_time=2.178e-04, forward_time=0.132, uma_reduction=0.194, text_vs_uma=0.490, loss_ctc=5.701, loss=2.851, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.499e-04, train_time=0.876
[alab02] 2024-08-28 18:24:14,183 (trainer:720) INFO: 34epoch:train:5201-5400batch: iter_time=2.431e-04, forward_time=0.135, uma_reduction=0.200, text_vs_uma=0.478, loss_ctc=5.357, loss=2.678, backward_time=0.189, optim_step_time=0.035, optim0_lr0=2.498e-04, train_time=0.895
[alab02] 2024-08-28 18:25:43,595 (trainer:720) INFO: 34epoch:train:5401-5600batch: iter_time=2.178e-04, forward_time=0.134, uma_reduction=0.198, text_vs_uma=0.473, loss_ctc=5.394, loss=2.697, backward_time=0.186, optim_step_time=0.037, optim0_lr0=2.497e-04, train_time=0.894
[alab02] 2024-08-28 18:27:11,893 (trainer:720) INFO: 34epoch:train:5601-5800batch: iter_time=1.933e-04, forward_time=0.133, uma_reduction=0.195, text_vs_uma=0.496, loss_ctc=5.894, loss=2.947, backward_time=0.182, optim_step_time=0.037, optim0_lr0=2.496e-04, train_time=0.883
[alab02] 2024-08-28 18:28:38,803 (trainer:720) INFO: 34epoch:train:5801-6000batch: iter_time=1.996e-04, forward_time=0.131, uma_reduction=0.193, text_vs_uma=0.493, loss_ctc=5.600, loss=2.800, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.494e-04, train_time=0.869
[alab02] 2024-08-28 18:30:07,796 (trainer:720) INFO: 34epoch:train:6001-6200batch: iter_time=1.791e-04, forward_time=0.135, uma_reduction=0.197, text_vs_uma=0.493, loss_ctc=5.843, loss=2.922, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.493e-04, train_time=0.890
[alab02] 2024-08-28 18:31:35,476 (trainer:720) INFO: 34epoch:train:6201-6400batch: iter_time=1.933e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.495, loss_ctc=5.713, loss=2.857, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.492e-04, train_time=0.877
[alab02] 2024-08-28 18:33:02,123 (trainer:720) INFO: 34epoch:train:6401-6600batch: iter_time=1.955e-04, forward_time=0.130, uma_reduction=0.197, text_vs_uma=0.494, loss_ctc=5.666, loss=2.833, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.491e-04, train_time=0.866
[alab02] 2024-08-28 18:34:29,932 (trainer:720) INFO: 34epoch:train:6601-6800batch: iter_time=2.309e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.497, loss_ctc=5.323, loss=2.662, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.490e-04, train_time=0.878
[alab02] 2024-08-28 18:35:57,631 (trainer:720) INFO: 34epoch:train:6801-7000batch: iter_time=2.129e-04, forward_time=0.131, uma_reduction=0.200, text_vs_uma=0.473, loss_ctc=5.627, loss=2.813, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.489e-04, train_time=0.877
[alab02] 2024-08-28 18:37:13,029 (trainer:338) INFO: 34epoch results: [train] iter_time=2.808e-04, forward_time=0.132, uma_reduction=0.198, text_vs_uma=0.484, loss_ctc=5.638, loss=2.819, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.507e-04, train_time=0.879, time=52 minutes and 14.37 seconds, total_count=242284, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.181, text_vs_uma=0.601, loss_ctc=3.859, cer_ctc=0.100, cer=0.100, loss=3.859, time=6.03 seconds, total_count=884, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.46 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 18:37:18,210 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 18:37:18,218 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/24epoch.pth
[alab02] 2024-08-28 18:37:18,218 (trainer:272) INFO: 35/150epoch started. Estimated time to finish: 4 days, 12 hours and 5 minutes
[alab02] 2024-08-28 18:38:49,693 (trainer:720) INFO: 35epoch:train:1-200batch: iter_time=0.002, forward_time=0.137, uma_reduction=0.201, text_vs_uma=0.488, loss_ctc=5.642, loss=2.821, backward_time=0.191, optim_step_time=0.033, optim0_lr0=2.488e-04, train_time=0.914
[alab02] 2024-08-28 18:40:16,564 (trainer:720) INFO: 35epoch:train:201-400batch: iter_time=2.194e-04, forward_time=0.130, uma_reduction=0.202, text_vs_uma=0.481, loss_ctc=5.468, loss=2.734, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.487e-04, train_time=0.868
[alab02] 2024-08-28 18:41:45,616 (trainer:720) INFO: 35epoch:train:401-600batch: iter_time=2.317e-04, forward_time=0.135, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=5.837, loss=2.919, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.486e-04, train_time=0.890
[alab02] 2024-08-28 18:43:15,065 (trainer:720) INFO: 35epoch:train:601-800batch: iter_time=2.369e-04, forward_time=0.137, uma_reduction=0.198, text_vs_uma=0.480, loss_ctc=5.703, loss=2.852, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.485e-04, train_time=0.894
[alab02] 2024-08-28 18:44:43,753 (trainer:720) INFO: 35epoch:train:801-1000batch: iter_time=1.914e-04, forward_time=0.133, uma_reduction=0.204, text_vs_uma=0.475, loss_ctc=5.623, loss=2.811, backward_time=0.184, optim_step_time=0.032, optim0_lr0=2.484e-04, train_time=0.887
[alab02] 2024-08-28 18:46:11,350 (trainer:720) INFO: 35epoch:train:1001-1200batch: iter_time=1.888e-04, forward_time=0.130, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=5.359, loss=2.680, backward_time=0.183, optim_step_time=0.032, optim0_lr0=2.483e-04, train_time=0.876
[alab02] 2024-08-28 18:47:40,208 (trainer:720) INFO: 35epoch:train:1201-1400batch: iter_time=1.828e-04, forward_time=0.132, uma_reduction=0.201, text_vs_uma=0.477, loss_ctc=5.212, loss=2.606, backward_time=0.189, optim_step_time=0.033, optim0_lr0=2.482e-04, train_time=0.888
[alab02] 2024-08-28 18:49:08,740 (trainer:720) INFO: 35epoch:train:1401-1600batch: iter_time=1.848e-04, forward_time=0.134, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=5.844, loss=2.922, backward_time=0.182, optim_step_time=0.032, optim0_lr0=2.481e-04, train_time=0.885
[alab02] 2024-08-28 18:50:33,932 (trainer:720) INFO: 35epoch:train:1601-1800batch: iter_time=1.725e-04, forward_time=0.128, uma_reduction=0.201, text_vs_uma=0.469, loss_ctc=5.057, loss=2.529, backward_time=0.178, optim_step_time=0.032, optim0_lr0=2.479e-04, train_time=0.852
[alab02] 2024-08-28 18:52:01,561 (trainer:720) INFO: 35epoch:train:1801-2000batch: iter_time=1.888e-04, forward_time=0.130, uma_reduction=0.198, text_vs_uma=0.480, loss_ctc=5.863, loss=2.932, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.478e-04, train_time=0.876
[alab02] 2024-08-28 18:53:27,554 (trainer:720) INFO: 35epoch:train:2001-2200batch: iter_time=1.802e-04, forward_time=0.129, uma_reduction=0.197, text_vs_uma=0.496, loss_ctc=5.831, loss=2.916, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.477e-04, train_time=0.860
[alab02] 2024-08-28 18:54:52,648 (trainer:720) INFO: 35epoch:train:2201-2400batch: iter_time=1.736e-04, forward_time=0.127, uma_reduction=0.198, text_vs_uma=0.489, loss_ctc=5.591, loss=2.795, backward_time=0.177, optim_step_time=0.032, optim0_lr0=2.476e-04, train_time=0.851
[alab02] 2024-08-28 18:56:20,839 (trainer:720) INFO: 35epoch:train:2401-2600batch: iter_time=1.778e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=5.651, loss=2.825, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.475e-04, train_time=0.882
[alab02] 2024-08-28 18:57:48,464 (trainer:720) INFO: 35epoch:train:2601-2800batch: iter_time=2.023e-04, forward_time=0.132, uma_reduction=0.199, text_vs_uma=0.487, loss_ctc=5.820, loss=2.910, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.474e-04, train_time=0.876
[alab02] 2024-08-28 18:59:16,839 (trainer:720) INFO: 35epoch:train:2801-3000batch: iter_time=2.011e-04, forward_time=0.132, uma_reduction=0.198, text_vs_uma=0.482, loss_ctc=5.341, loss=2.670, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.473e-04, train_time=0.884
[alab02] 2024-08-28 19:00:44,321 (trainer:720) INFO: 35epoch:train:3001-3200batch: iter_time=1.826e-04, forward_time=0.130, uma_reduction=0.199, text_vs_uma=0.486, loss_ctc=5.864, loss=2.932, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.472e-04, train_time=0.875
[alab02] 2024-08-28 19:02:12,216 (trainer:720) INFO: 35epoch:train:3201-3400batch: iter_time=1.946e-04, forward_time=0.132, uma_reduction=0.197, text_vs_uma=0.488, loss_ctc=5.909, loss=2.954, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.471e-04, train_time=0.879
[alab02] 2024-08-28 19:03:38,983 (trainer:720) INFO: 35epoch:train:3401-3600batch: iter_time=1.706e-04, forward_time=0.130, uma_reduction=0.198, text_vs_uma=0.469, loss_ctc=5.353, loss=2.677, backward_time=0.181, optim_step_time=0.032, optim0_lr0=2.470e-04, train_time=0.867
[alab02] 2024-08-28 19:05:04,435 (trainer:720) INFO: 35epoch:train:3601-3800batch: iter_time=2.005e-04, forward_time=0.127, uma_reduction=0.202, text_vs_uma=0.483, loss_ctc=5.607, loss=2.804, backward_time=0.176, optim_step_time=0.033, optim0_lr0=2.469e-04, train_time=0.854
[alab02] 2024-08-28 19:06:31,442 (trainer:720) INFO: 35epoch:train:3801-4000batch: iter_time=1.841e-04, forward_time=0.131, uma_reduction=0.201, text_vs_uma=0.470, loss_ctc=5.407, loss=2.703, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.468e-04, train_time=0.870
[alab02] 2024-08-28 19:07:59,943 (trainer:720) INFO: 35epoch:train:4001-4200batch: iter_time=1.843e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.491, loss_ctc=5.973, loss=2.986, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.467e-04, train_time=0.885
[alab02] 2024-08-28 19:09:28,401 (trainer:720) INFO: 35epoch:train:4201-4400batch: iter_time=2.160e-04, forward_time=0.133, uma_reduction=0.198, text_vs_uma=0.478, loss_ctc=5.433, loss=2.717, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.466e-04, train_time=0.884
[alab02] 2024-08-28 19:10:55,568 (trainer:720) INFO: 35epoch:train:4401-4600batch: iter_time=1.747e-04, forward_time=0.130, uma_reduction=0.197, text_vs_uma=0.486, loss_ctc=5.516, loss=2.758, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.465e-04, train_time=0.871
[alab02] 2024-08-28 19:12:20,975 (trainer:720) INFO: 35epoch:train:4601-4800batch: iter_time=1.826e-04, forward_time=0.128, uma_reduction=0.197, text_vs_uma=0.478, loss_ctc=5.310, loss=2.655, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.464e-04, train_time=0.854
[alab02] 2024-08-28 19:13:49,693 (trainer:720) INFO: 35epoch:train:4801-5000batch: iter_time=1.975e-04, forward_time=0.133, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.678, loss=2.839, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.463e-04, train_time=0.887
[alab02] 2024-08-28 19:15:16,887 (trainer:720) INFO: 35epoch:train:5001-5200batch: iter_time=1.898e-04, forward_time=0.131, uma_reduction=0.195, text_vs_uma=0.490, loss_ctc=5.659, loss=2.830, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.462e-04, train_time=0.872
[alab02] 2024-08-28 19:16:44,272 (trainer:720) INFO: 35epoch:train:5201-5400batch: iter_time=1.892e-04, forward_time=0.132, uma_reduction=0.195, text_vs_uma=0.497, loss_ctc=5.726, loss=2.863, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.461e-04, train_time=0.874
[alab02] 2024-08-28 19:18:10,346 (trainer:720) INFO: 35epoch:train:5401-5600batch: iter_time=1.901e-04, forward_time=0.129, uma_reduction=0.192, text_vs_uma=0.491, loss_ctc=5.815, loss=2.907, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.460e-04, train_time=0.860
[alab02] 2024-08-28 19:19:37,420 (trainer:720) INFO: 35epoch:train:5601-5800batch: iter_time=1.801e-04, forward_time=0.131, uma_reduction=0.197, text_vs_uma=0.484, loss_ctc=5.524, loss=2.762, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.459e-04, train_time=0.870
[alab02] 2024-08-28 19:21:04,150 (trainer:720) INFO: 35epoch:train:5801-6000batch: iter_time=2.079e-04, forward_time=0.131, uma_reduction=0.199, text_vs_uma=0.474, loss_ctc=5.179, loss=2.589, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.458e-04, train_time=0.867
[alab02] 2024-08-28 19:22:31,087 (trainer:720) INFO: 35epoch:train:6001-6200batch: iter_time=2.048e-04, forward_time=0.131, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=5.716, loss=2.858, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.457e-04, train_time=0.869
[alab02] 2024-08-28 19:23:57,037 (trainer:720) INFO: 35epoch:train:6201-6400batch: iter_time=1.988e-04, forward_time=0.129, uma_reduction=0.199, text_vs_uma=0.485, loss_ctc=5.840, loss=2.920, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.456e-04, train_time=0.859
[alab02] 2024-08-28 19:25:27,998 (trainer:720) INFO: 35epoch:train:6401-6600batch: iter_time=2.991e-04, forward_time=0.139, uma_reduction=0.198, text_vs_uma=0.496, loss_ctc=5.777, loss=2.888, backward_time=0.186, optim_step_time=0.046, optim0_lr0=2.455e-04, train_time=0.909
[alab02] 2024-08-28 19:27:07,040 (trainer:720) INFO: 35epoch:train:6601-6800batch: iter_time=4.816e-04, forward_time=0.159, uma_reduction=0.198, text_vs_uma=0.488, loss_ctc=5.680, loss=2.840, backward_time=0.200, optim_step_time=0.055, optim0_lr0=2.454e-04, train_time=0.990
[alab02] 2024-08-28 19:28:44,380 (trainer:720) INFO: 35epoch:train:6801-7000batch: iter_time=4.795e-04, forward_time=0.157, uma_reduction=0.200, text_vs_uma=0.484, loss_ctc=5.269, loss=2.634, backward_time=0.198, optim_step_time=0.053, optim0_lr0=2.453e-04, train_time=0.973
[alab02] 2024-08-28 19:30:18,170 (trainer:338) INFO: 35epoch results: [train] iter_time=2.663e-04, forward_time=0.133, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=5.602, loss=2.801, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.470e-04, train_time=0.883, time=52 minutes and 29.21 seconds, total_count=249410, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.184, text_vs_uma=0.590, loss_ctc=3.895, cer_ctc=0.106, cer=0.106, loss=3.895, time=7.31 seconds, total_count=910, gpu_max_cached_mem_GB=35.906, [att_plot] time=23.43 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 19:30:25,732 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 19:30:25,744 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/26epoch.pth
[alab02] 2024-08-28 19:30:25,744 (trainer:272) INFO: 36/150epoch started. Estimated time to finish: 4 days, 11 hours and 24.29 seconds
[alab02] 2024-08-28 19:32:07,766 (trainer:720) INFO: 36epoch:train:1-200batch: iter_time=0.004, forward_time=0.163, uma_reduction=0.201, text_vs_uma=0.472, loss_ctc=5.414, loss=2.707, backward_time=0.204, optim_step_time=0.055, optim0_lr0=2.452e-04, train_time=1.019
[alab02] 2024-08-28 19:33:46,839 (trainer:720) INFO: 36epoch:train:201-400batch: iter_time=4.359e-04, forward_time=0.163, uma_reduction=0.199, text_vs_uma=0.487, loss_ctc=5.584, loss=2.792, backward_time=0.196, optim_step_time=0.054, optim0_lr0=2.451e-04, train_time=0.990
[alab02] 2024-08-28 19:35:24,853 (trainer:720) INFO: 36epoch:train:401-600batch: iter_time=4.320e-04, forward_time=0.158, uma_reduction=0.202, text_vs_uma=0.479, loss_ctc=5.393, loss=2.697, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.450e-04, train_time=0.980
[alab02] 2024-08-28 19:37:02,743 (trainer:720) INFO: 36epoch:train:601-800batch: iter_time=4.785e-04, forward_time=0.160, uma_reduction=0.199, text_vs_uma=0.483, loss_ctc=5.528, loss=2.764, backward_time=0.197, optim_step_time=0.056, optim0_lr0=2.449e-04, train_time=0.978
[alab02] 2024-08-28 19:38:41,533 (trainer:720) INFO: 36epoch:train:801-1000batch: iter_time=4.275e-04, forward_time=0.159, uma_reduction=0.200, text_vs_uma=0.477, loss_ctc=5.123, loss=2.562, backward_time=0.203, optim_step_time=0.056, optim0_lr0=2.448e-04, train_time=0.988
[alab02] 2024-08-28 19:40:19,828 (trainer:720) INFO: 36epoch:train:1001-1200batch: iter_time=4.426e-04, forward_time=0.157, uma_reduction=0.199, text_vs_uma=0.481, loss_ctc=5.317, loss=2.658, backward_time=0.204, optim_step_time=0.052, optim0_lr0=2.447e-04, train_time=0.982
[alab02] 2024-08-28 19:41:57,510 (trainer:720) INFO: 36epoch:train:1201-1400batch: iter_time=5.565e-04, forward_time=0.156, uma_reduction=0.200, text_vs_uma=0.477, loss_ctc=5.424, loss=2.712, backward_time=0.199, optim_step_time=0.055, optim0_lr0=2.446e-04, train_time=0.976
[alab02] 2024-08-28 19:43:35,702 (trainer:720) INFO: 36epoch:train:1401-1600batch: iter_time=3.858e-04, forward_time=0.158, uma_reduction=0.197, text_vs_uma=0.493, loss_ctc=5.745, loss=2.872, backward_time=0.197, optim_step_time=0.053, optim0_lr0=2.445e-04, train_time=0.982
[alab02] 2024-08-28 19:45:12,786 (trainer:720) INFO: 36epoch:train:1601-1800batch: iter_time=3.783e-04, forward_time=0.157, uma_reduction=0.199, text_vs_uma=0.474, loss_ctc=5.031, loss=2.516, backward_time=0.198, optim_step_time=0.052, optim0_lr0=2.444e-04, train_time=0.970
[alab02] 2024-08-28 19:46:46,233 (trainer:720) INFO: 36epoch:train:1801-2000batch: iter_time=3.803e-04, forward_time=0.151, uma_reduction=0.202, text_vs_uma=0.476, loss_ctc=5.450, loss=2.725, backward_time=0.185, optim_step_time=0.053, optim0_lr0=2.443e-04, train_time=0.934
[alab02] 2024-08-28 19:48:21,203 (trainer:720) INFO: 36epoch:train:2001-2200batch: iter_time=3.106e-04, forward_time=0.148, uma_reduction=0.200, text_vs_uma=0.481, loss_ctc=5.277, loss=2.638, backward_time=0.196, optim_step_time=0.045, optim0_lr0=2.442e-04, train_time=0.949
[alab02] 2024-08-28 19:49:54,747 (trainer:720) INFO: 36epoch:train:2201-2400batch: iter_time=3.069e-04, forward_time=0.147, uma_reduction=0.200, text_vs_uma=0.480, loss_ctc=5.387, loss=2.694, backward_time=0.189, optim_step_time=0.044, optim0_lr0=2.441e-04, train_time=0.935
[alab02] 2024-08-28 19:51:26,173 (trainer:720) INFO: 36epoch:train:2401-2600batch: iter_time=2.537e-04, forward_time=0.142, uma_reduction=0.201, text_vs_uma=0.474, loss_ctc=5.199, loss=2.599, backward_time=0.188, optim_step_time=0.038, optim0_lr0=2.440e-04, train_time=0.914
[alab02] 2024-08-28 19:52:56,243 (trainer:720) INFO: 36epoch:train:2601-2800batch: iter_time=2.530e-04, forward_time=0.139, uma_reduction=0.201, text_vs_uma=0.468, loss_ctc=4.742, loss=2.371, backward_time=0.189, optim_step_time=0.035, optim0_lr0=2.439e-04, train_time=0.900
[alab02] 2024-08-28 19:54:32,863 (trainer:720) INFO: 36epoch:train:2801-3000batch: iter_time=3.057e-04, forward_time=0.155, uma_reduction=0.202, text_vs_uma=0.473, loss_ctc=5.453, loss=2.727, backward_time=0.195, optim_step_time=0.049, optim0_lr0=2.438e-04, train_time=0.966
[alab02] 2024-08-28 19:56:14,263 (trainer:720) INFO: 36epoch:train:3001-3200batch: iter_time=5.635e-04, forward_time=0.169, uma_reduction=0.203, text_vs_uma=0.473, loss_ctc=5.038, loss=2.519, backward_time=0.203, optim_step_time=0.063, optim0_lr0=2.437e-04, train_time=1.013
[alab02] 2024-08-28 19:57:56,637 (trainer:720) INFO: 36epoch:train:3201-3400batch: iter_time=5.092e-04, forward_time=0.167, uma_reduction=0.202, text_vs_uma=0.479, loss_ctc=5.096, loss=2.548, backward_time=0.210, optim_step_time=0.063, optim0_lr0=2.436e-04, train_time=1.023
[alab02] 2024-08-28 19:59:39,102 (trainer:720) INFO: 36epoch:train:3401-3600batch: iter_time=4.443e-04, forward_time=0.169, uma_reduction=0.199, text_vs_uma=0.482, loss_ctc=5.582, loss=2.791, backward_time=0.206, optim_step_time=0.061, optim0_lr0=2.435e-04, train_time=1.024
[alab02] 2024-08-28 20:01:23,942 (trainer:720) INFO: 36epoch:train:3601-3800batch: iter_time=4.924e-04, forward_time=0.174, uma_reduction=0.198, text_vs_uma=0.483, loss_ctc=5.553, loss=2.776, backward_time=0.210, optim_step_time=0.062, optim0_lr0=2.434e-04, train_time=1.048
[alab02] 2024-08-28 20:03:06,586 (trainer:720) INFO: 36epoch:train:3801-4000batch: iter_time=5.365e-04, forward_time=0.169, uma_reduction=0.202, text_vs_uma=0.473, loss_ctc=4.870, loss=2.435, backward_time=0.210, optim_step_time=0.062, optim0_lr0=2.433e-04, train_time=1.026
[alab02] 2024-08-28 20:04:49,099 (trainer:720) INFO: 36epoch:train:4001-4200batch: iter_time=4.254e-04, forward_time=0.168, uma_reduction=0.201, text_vs_uma=0.484, loss_ctc=5.341, loss=2.670, backward_time=0.212, optim_step_time=0.061, optim0_lr0=2.432e-04, train_time=1.025
[alab02] 2024-08-28 20:06:28,873 (trainer:720) INFO: 36epoch:train:4201-4400batch: iter_time=4.242e-04, forward_time=0.164, uma_reduction=0.202, text_vs_uma=0.477, loss_ctc=5.338, loss=2.669, backward_time=0.201, optim_step_time=0.060, optim0_lr0=2.432e-04, train_time=0.997
[alab02] 2024-08-28 20:08:12,042 (trainer:720) INFO: 36epoch:train:4401-4600batch: iter_time=4.681e-04, forward_time=0.169, uma_reduction=0.201, text_vs_uma=0.477, loss_ctc=5.036, loss=2.518, backward_time=0.211, optim_step_time=0.063, optim0_lr0=2.431e-04, train_time=1.031
[alab02] 2024-08-28 20:09:55,193 (trainer:720) INFO: 36epoch:train:4601-4800batch: iter_time=5.073e-04, forward_time=0.170, uma_reduction=0.201, text_vs_uma=0.478, loss_ctc=5.324, loss=2.662, backward_time=0.211, optim_step_time=0.060, optim0_lr0=2.430e-04, train_time=1.031
[alab02] 2024-08-28 20:11:36,642 (trainer:720) INFO: 36epoch:train:4801-5000batch: iter_time=4.645e-04, forward_time=0.166, uma_reduction=0.206, text_vs_uma=0.454, loss_ctc=4.976, loss=2.488, backward_time=0.206, optim_step_time=0.060, optim0_lr0=2.429e-04, train_time=1.014
[alab02] 2024-08-28 20:13:17,857 (trainer:720) INFO: 36epoch:train:5001-5200batch: iter_time=5.225e-04, forward_time=0.167, uma_reduction=0.205, text_vs_uma=0.469, loss_ctc=5.244, loss=2.622, backward_time=0.206, optim_step_time=0.060, optim0_lr0=2.428e-04, train_time=1.011
[alab02] 2024-08-28 20:14:58,877 (trainer:720) INFO: 36epoch:train:5201-5400batch: iter_time=3.834e-04, forward_time=0.163, uma_reduction=0.204, text_vs_uma=0.477, loss_ctc=5.238, loss=2.619, backward_time=0.206, optim_step_time=0.058, optim0_lr0=2.427e-04, train_time=1.010
[alab02] 2024-08-28 20:16:35,835 (trainer:720) INFO: 36epoch:train:5401-5600batch: iter_time=3.858e-04, forward_time=0.154, uma_reduction=0.204, text_vs_uma=0.474, loss_ctc=5.044, loss=2.522, backward_time=0.199, optim_step_time=0.052, optim0_lr0=2.426e-04, train_time=0.969
[alab02] 2024-08-28 20:18:16,204 (trainer:720) INFO: 36epoch:train:5601-5800batch: iter_time=6.336e-04, forward_time=0.162, uma_reduction=0.203, text_vs_uma=0.462, loss_ctc=5.063, loss=2.532, backward_time=0.204, optim_step_time=0.057, optim0_lr0=2.425e-04, train_time=1.003
[alab02] 2024-08-28 20:19:52,840 (trainer:720) INFO: 36epoch:train:5801-6000batch: iter_time=5.469e-04, forward_time=0.156, uma_reduction=0.202, text_vs_uma=0.467, loss_ctc=5.237, loss=2.618, backward_time=0.197, optim_step_time=0.056, optim0_lr0=2.424e-04, train_time=0.966
[alab02] 2024-08-28 20:21:26,034 (trainer:720) INFO: 36epoch:train:6001-6200batch: iter_time=3.487e-04, forward_time=0.147, uma_reduction=0.202, text_vs_uma=0.480, loss_ctc=5.426, loss=2.713, backward_time=0.188, optim_step_time=0.042, optim0_lr0=2.423e-04, train_time=0.932
[alab02] 2024-08-28 20:22:55,447 (trainer:720) INFO: 36epoch:train:6201-6400batch: iter_time=2.261e-04, forward_time=0.137, uma_reduction=0.204, text_vs_uma=0.467, loss_ctc=5.159, loss=2.579, backward_time=0.184, optim_step_time=0.039, optim0_lr0=2.422e-04, train_time=0.894
[alab02] 2024-08-28 20:24:26,262 (trainer:720) INFO: 36epoch:train:6401-6600batch: iter_time=2.648e-04, forward_time=0.140, uma_reduction=0.200, text_vs_uma=0.482, loss_ctc=5.477, loss=2.738, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.421e-04, train_time=0.908
[alab02] 2024-08-28 20:26:00,770 (trainer:720) INFO: 36epoch:train:6601-6800batch: iter_time=4.546e-04, forward_time=0.147, uma_reduction=0.200, text_vs_uma=0.491, loss_ctc=5.773, loss=2.887, backward_time=0.190, optim_step_time=0.046, optim0_lr0=2.420e-04, train_time=0.945
[alab02] 2024-08-28 20:27:41,669 (trainer:720) INFO: 36epoch:train:6801-7000batch: iter_time=5.670e-04, forward_time=0.165, uma_reduction=0.201, text_vs_uma=0.471, loss_ctc=5.221, loss=2.611, backward_time=0.203, optim_step_time=0.063, optim0_lr0=2.419e-04, train_time=1.008
[alab02] 2024-08-28 20:29:24,426 (trainer:338) INFO: 36epoch results: [train] iter_time=5.197e-04, forward_time=0.158, uma_reduction=0.201, text_vs_uma=0.476, loss_ctc=5.291, loss=2.646, backward_time=0.200, optim_step_time=0.054, optim0_lr0=2.435e-04, train_time=0.982, time=58 minutes and 21.13 seconds, total_count=256536, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.190, text_vs_uma=0.570, loss_ctc=3.716, cer_ctc=0.096, cer=0.096, loss=3.716, time=8.65 seconds, total_count=936, gpu_max_cached_mem_GB=35.906, [att_plot] time=28.9 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 20:29:33,173 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 20:29:33,188 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/27epoch.pth
[alab02] 2024-08-28 20:29:33,188 (trainer:272) INFO: 37/150epoch started. Estimated time to finish: 4 days, 10 hours and 15 minutes
[alab02] 2024-08-28 20:31:17,654 (trainer:720) INFO: 37epoch:train:1-200batch: iter_time=0.005, forward_time=0.168, uma_reduction=0.203, text_vs_uma=0.476, loss_ctc=5.463, loss=2.732, backward_time=0.204, optim_step_time=0.060, optim0_lr0=2.418e-04, train_time=1.044
[alab02] 2024-08-28 20:33:00,599 (trainer:720) INFO: 37epoch:train:201-400batch: iter_time=9.589e-04, forward_time=0.169, uma_reduction=0.201, text_vs_uma=0.484, loss_ctc=5.238, loss=2.619, backward_time=0.207, optim_step_time=0.066, optim0_lr0=2.417e-04, train_time=1.029
[alab02] 2024-08-28 20:34:39,699 (trainer:720) INFO: 37epoch:train:401-600batch: iter_time=5.384e-04, forward_time=0.160, uma_reduction=0.204, text_vs_uma=0.476, loss_ctc=5.390, loss=2.695, backward_time=0.199, optim_step_time=0.062, optim0_lr0=2.416e-04, train_time=0.991
[alab02] 2024-08-28 20:36:20,557 (trainer:720) INFO: 37epoch:train:601-800batch: iter_time=6.852e-04, forward_time=0.163, uma_reduction=0.197, text_vs_uma=0.483, loss_ctc=5.435, loss=2.717, backward_time=0.206, optim_step_time=0.060, optim0_lr0=2.415e-04, train_time=1.008
[alab02] 2024-08-28 20:38:01,731 (trainer:720) INFO: 37epoch:train:801-1000batch: iter_time=5.097e-04, forward_time=0.166, uma_reduction=0.194, text_vs_uma=0.497, loss_ctc=5.668, loss=2.834, backward_time=0.203, optim_step_time=0.061, optim0_lr0=2.414e-04, train_time=1.011
[alab02] 2024-08-28 20:39:42,956 (trainer:720) INFO: 37epoch:train:1001-1200batch: iter_time=4.732e-04, forward_time=0.165, uma_reduction=0.196, text_vs_uma=0.497, loss_ctc=5.588, loss=2.794, backward_time=0.206, optim_step_time=0.060, optim0_lr0=2.413e-04, train_time=1.012
[alab02] 2024-08-28 20:41:21,701 (trainer:720) INFO: 37epoch:train:1201-1400batch: iter_time=4.372e-04, forward_time=0.161, uma_reduction=0.197, text_vs_uma=0.489, loss_ctc=5.398, loss=2.699, backward_time=0.206, optim_step_time=0.059, optim0_lr0=2.412e-04, train_time=0.987
[alab02] 2024-08-28 20:43:01,645 (trainer:720) INFO: 37epoch:train:1401-1600batch: iter_time=5.202e-04, forward_time=0.164, uma_reduction=0.193, text_vs_uma=0.479, loss_ctc=5.341, loss=2.670, backward_time=0.204, optim_step_time=0.058, optim0_lr0=2.411e-04, train_time=0.999
[alab02] 2024-08-28 20:44:42,746 (trainer:720) INFO: 37epoch:train:1601-1800batch: iter_time=4.683e-04, forward_time=0.165, uma_reduction=0.195, text_vs_uma=0.502, loss_ctc=5.506, loss=2.753, backward_time=0.204, optim_step_time=0.061, optim0_lr0=2.410e-04, train_time=1.011
[alab02] 2024-08-28 20:46:22,932 (trainer:720) INFO: 37epoch:train:1801-2000batch: iter_time=5.203e-04, forward_time=0.163, uma_reduction=0.199, text_vs_uma=0.491, loss_ctc=5.619, loss=2.810, backward_time=0.198, optim_step_time=0.059, optim0_lr0=2.409e-04, train_time=1.001
[alab02] 2024-08-28 20:47:59,522 (trainer:720) INFO: 37epoch:train:2001-2200batch: iter_time=4.076e-04, forward_time=0.155, uma_reduction=0.200, text_vs_uma=0.477, loss_ctc=5.275, loss=2.637, backward_time=0.196, optim_step_time=0.058, optim0_lr0=2.408e-04, train_time=0.965
[alab02] 2024-08-28 20:49:36,450 (trainer:720) INFO: 37epoch:train:2201-2400batch: iter_time=3.696e-04, forward_time=0.154, uma_reduction=0.200, text_vs_uma=0.475, loss_ctc=5.202, loss=2.601, backward_time=0.198, optim_step_time=0.053, optim0_lr0=2.407e-04, train_time=0.969
[alab02] 2024-08-28 20:51:08,164 (trainer:720) INFO: 37epoch:train:2401-2600batch: iter_time=3.074e-04, forward_time=0.143, uma_reduction=0.196, text_vs_uma=0.480, loss_ctc=5.523, loss=2.761, backward_time=0.184, optim_step_time=0.045, optim0_lr0=2.406e-04, train_time=0.917
[alab02] 2024-08-28 20:52:37,773 (trainer:720) INFO: 37epoch:train:2601-2800batch: iter_time=2.263e-04, forward_time=0.137, uma_reduction=0.201, text_vs_uma=0.480, loss_ctc=5.735, loss=2.868, backward_time=0.182, optim_step_time=0.039, optim0_lr0=2.405e-04, train_time=0.896
[alab02] 2024-08-28 20:54:05,744 (trainer:720) INFO: 37epoch:train:2801-3000batch: iter_time=2.400e-04, forward_time=0.133, uma_reduction=0.204, text_vs_uma=0.469, loss_ctc=5.170, loss=2.585, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.405e-04, train_time=0.879
[alab02] 2024-08-28 20:55:34,183 (trainer:720) INFO: 37epoch:train:3001-3200batch: iter_time=1.993e-04, forward_time=0.134, uma_reduction=0.203, text_vs_uma=0.474, loss_ctc=5.285, loss=2.643, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.404e-04, train_time=0.884
[alab02] 2024-08-28 20:57:02,994 (trainer:720) INFO: 37epoch:train:3201-3400batch: iter_time=2.197e-04, forward_time=0.136, uma_reduction=0.202, text_vs_uma=0.461, loss_ctc=4.973, loss=2.487, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.403e-04, train_time=0.888
[alab02] 2024-08-28 20:58:32,920 (trainer:720) INFO: 37epoch:train:3401-3600batch: iter_time=2.522e-04, forward_time=0.137, uma_reduction=0.203, text_vs_uma=0.458, loss_ctc=5.260, loss=2.630, backward_time=0.186, optim_step_time=0.037, optim0_lr0=2.402e-04, train_time=0.899
[alab02] 2024-08-28 21:00:04,137 (trainer:720) INFO: 37epoch:train:3601-3800batch: iter_time=2.426e-04, forward_time=0.139, uma_reduction=0.201, text_vs_uma=0.482, loss_ctc=5.439, loss=2.719, backward_time=0.189, optim_step_time=0.036, optim0_lr0=2.401e-04, train_time=0.912
[alab02] 2024-08-28 21:01:31,659 (trainer:720) INFO: 37epoch:train:3801-4000batch: iter_time=2.168e-04, forward_time=0.132, uma_reduction=0.200, text_vs_uma=0.478, loss_ctc=5.228, loss=2.614, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.400e-04, train_time=0.875
[alab02] 2024-08-28 21:03:01,186 (trainer:720) INFO: 37epoch:train:4001-4200batch: iter_time=2.505e-04, forward_time=0.136, uma_reduction=0.204, text_vs_uma=0.479, loss_ctc=5.461, loss=2.731, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.399e-04, train_time=0.895
[alab02] 2024-08-28 21:04:27,888 (trainer:720) INFO: 37epoch:train:4201-4400batch: iter_time=1.937e-04, forward_time=0.131, uma_reduction=0.205, text_vs_uma=0.476, loss_ctc=5.568, loss=2.784, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.398e-04, train_time=0.867
[alab02] 2024-08-28 21:05:56,874 (trainer:720) INFO: 37epoch:train:4401-4600batch: iter_time=2.211e-04, forward_time=0.135, uma_reduction=0.205, text_vs_uma=0.465, loss_ctc=5.406, loss=2.703, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.397e-04, train_time=0.890
[alab02] 2024-08-28 21:07:25,451 (trainer:720) INFO: 37epoch:train:4601-4800batch: iter_time=1.949e-04, forward_time=0.134, uma_reduction=0.200, text_vs_uma=0.477, loss_ctc=5.894, loss=2.947, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.396e-04, train_time=0.886
[alab02] 2024-08-28 21:08:53,626 (trainer:720) INFO: 37epoch:train:4801-5000batch: iter_time=2.083e-04, forward_time=0.132, uma_reduction=0.201, text_vs_uma=0.478, loss_ctc=5.302, loss=2.651, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.395e-04, train_time=0.881
[alab02] 2024-08-28 21:10:21,867 (trainer:720) INFO: 37epoch:train:5001-5200batch: iter_time=1.947e-04, forward_time=0.133, uma_reduction=0.203, text_vs_uma=0.472, loss_ctc=5.631, loss=2.815, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.394e-04, train_time=0.882
[alab02] 2024-08-28 21:11:49,744 (trainer:720) INFO: 37epoch:train:5201-5400batch: iter_time=2.126e-04, forward_time=0.133, uma_reduction=0.205, text_vs_uma=0.471, loss_ctc=5.126, loss=2.563, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.393e-04, train_time=0.878
[alab02] 2024-08-28 21:13:20,640 (trainer:720) INFO: 37epoch:train:5401-5600batch: iter_time=2.112e-04, forward_time=0.140, uma_reduction=0.205, text_vs_uma=0.459, loss_ctc=4.933, loss=2.466, backward_time=0.191, optim_step_time=0.038, optim0_lr0=2.393e-04, train_time=0.909
[alab02] 2024-08-28 21:14:58,610 (trainer:720) INFO: 37epoch:train:5601-5800batch: iter_time=3.227e-04, forward_time=0.155, uma_reduction=0.204, text_vs_uma=0.467, loss_ctc=5.521, loss=2.760, backward_time=0.199, optim_step_time=0.055, optim0_lr0=2.392e-04, train_time=0.979
[alab02] 2024-08-28 21:16:36,245 (trainer:720) INFO: 37epoch:train:5801-6000batch: iter_time=3.634e-04, forward_time=0.155, uma_reduction=0.205, text_vs_uma=0.474, loss_ctc=5.559, loss=2.779, backward_time=0.198, optim_step_time=0.055, optim0_lr0=2.391e-04, train_time=0.976
[alab02] 2024-08-28 21:18:16,212 (trainer:720) INFO: 37epoch:train:6001-6200batch: iter_time=3.865e-04, forward_time=0.160, uma_reduction=0.204, text_vs_uma=0.464, loss_ctc=5.262, loss=2.631, backward_time=0.204, optim_step_time=0.057, optim0_lr0=2.390e-04, train_time=0.999
[alab02] 2024-08-28 21:19:55,450 (trainer:720) INFO: 37epoch:train:6201-6400batch: iter_time=3.818e-04, forward_time=0.158, uma_reduction=0.202, text_vs_uma=0.483, loss_ctc=5.742, loss=2.871, backward_time=0.199, optim_step_time=0.058, optim0_lr0=2.389e-04, train_time=0.992
[alab02] 2024-08-28 21:21:33,982 (trainer:720) INFO: 37epoch:train:6401-6600batch: iter_time=4.022e-04, forward_time=0.159, uma_reduction=0.207, text_vs_uma=0.468, loss_ctc=5.655, loss=2.827, backward_time=0.197, optim_step_time=0.058, optim0_lr0=2.388e-04, train_time=0.985
[alab02] 2024-08-28 21:23:13,141 (trainer:720) INFO: 37epoch:train:6601-6800batch: iter_time=3.936e-04, forward_time=0.160, uma_reduction=0.206, text_vs_uma=0.462, loss_ctc=5.424, loss=2.712, backward_time=0.198, optim_step_time=0.059, optim0_lr0=2.387e-04, train_time=0.991
[alab02] 2024-08-28 21:24:50,016 (trainer:720) INFO: 37epoch:train:6801-7000batch: iter_time=3.842e-04, forward_time=0.153, uma_reduction=0.202, text_vs_uma=0.493, loss_ctc=6.218, loss=3.109, backward_time=0.194, optim_step_time=0.055, optim0_lr0=2.386e-04, train_time=0.968
[alab02] 2024-08-28 21:26:18,085 (trainer:338) INFO: 37epoch results: [train] iter_time=4.952e-04, forward_time=0.149, uma_reduction=0.201, text_vs_uma=0.476, loss_ctc=5.432, loss=2.716, backward_time=0.193, optim_step_time=0.048, optim0_lr0=2.402e-04, train_time=0.948, time=56 minutes and 18.74 seconds, total_count=263662, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.196, text_vs_uma=0.552, loss_ctc=3.723, cer_ctc=0.101, cer=0.101, loss=3.723, time=7.28 seconds, total_count=962, gpu_max_cached_mem_GB=35.906, [att_plot] time=18.88 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 21:26:25,519 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 21:26:25,527 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/32epoch.pth
[alab02] 2024-08-28 21:26:25,527 (trainer:272) INFO: 38/150epoch started. Estimated time to finish: 4 days, 9 hours and 21 minutes
[alab02] 2024-08-28 21:27:58,872 (trainer:720) INFO: 38epoch:train:1-200batch: iter_time=0.005, forward_time=0.142, uma_reduction=0.205, text_vs_uma=0.468, loss_ctc=5.406, loss=2.703, backward_time=0.185, optim_step_time=0.043, optim0_lr0=2.385e-04, train_time=0.933
[alab02] 2024-08-28 21:29:29,252 (trainer:720) INFO: 38epoch:train:201-400batch: iter_time=2.664e-04, forward_time=0.139, uma_reduction=0.203, text_vs_uma=0.475, loss_ctc=5.649, loss=2.825, backward_time=0.184, optim_step_time=0.037, optim0_lr0=2.384e-04, train_time=0.904
[alab02] 2024-08-28 21:30:58,831 (trainer:720) INFO: 38epoch:train:401-600batch: iter_time=2.132e-04, forward_time=0.135, uma_reduction=0.204, text_vs_uma=0.464, loss_ctc=5.349, loss=2.675, backward_time=0.186, optim_step_time=0.034, optim0_lr0=2.383e-04, train_time=0.896
[alab02] 2024-08-28 21:32:29,294 (trainer:720) INFO: 38epoch:train:601-800batch: iter_time=2.718e-04, forward_time=0.140, uma_reduction=0.200, text_vs_uma=0.489, loss_ctc=5.875, loss=2.938, backward_time=0.183, optim_step_time=0.043, optim0_lr0=2.382e-04, train_time=0.904
[alab02] 2024-08-28 21:34:05,441 (trainer:720) INFO: 38epoch:train:801-1000batch: iter_time=4.472e-04, forward_time=0.151, uma_reduction=0.199, text_vs_uma=0.478, loss_ctc=5.694, loss=2.847, backward_time=0.193, optim_step_time=0.051, optim0_lr0=2.381e-04, train_time=0.961
[alab02] 2024-08-28 21:35:40,325 (trainer:720) INFO: 38epoch:train:1001-1200batch: iter_time=3.907e-04, forward_time=0.149, uma_reduction=0.200, text_vs_uma=0.470, loss_ctc=5.455, loss=2.728, backward_time=0.191, optim_step_time=0.053, optim0_lr0=2.380e-04, train_time=0.948
[alab02] 2024-08-28 21:37:14,754 (trainer:720) INFO: 38epoch:train:1201-1400batch: iter_time=4.789e-04, forward_time=0.147, uma_reduction=0.201, text_vs_uma=0.488, loss_ctc=5.617, loss=2.809, backward_time=0.192, optim_step_time=0.053, optim0_lr0=2.379e-04, train_time=0.944
[alab02] 2024-08-28 21:38:51,482 (trainer:720) INFO: 38epoch:train:1401-1600batch: iter_time=4.037e-04, forward_time=0.151, uma_reduction=0.201, text_vs_uma=0.468, loss_ctc=5.369, loss=2.685, backward_time=0.196, optim_step_time=0.052, optim0_lr0=2.378e-04, train_time=0.967
[alab02] 2024-08-28 21:40:27,603 (trainer:720) INFO: 38epoch:train:1601-1800batch: iter_time=4.054e-04, forward_time=0.151, uma_reduction=0.202, text_vs_uma=0.470, loss_ctc=4.906, loss=2.453, backward_time=0.198, optim_step_time=0.050, optim0_lr0=2.378e-04, train_time=0.961
[alab02] 2024-08-28 21:42:01,898 (trainer:720) INFO: 38epoch:train:1801-2000batch: iter_time=4.528e-04, forward_time=0.146, uma_reduction=0.202, text_vs_uma=0.474, loss_ctc=5.563, loss=2.781, backward_time=0.190, optim_step_time=0.052, optim0_lr0=2.377e-04, train_time=0.943
[alab02] 2024-08-28 21:43:36,839 (trainer:720) INFO: 38epoch:train:2001-2200batch: iter_time=3.133e-04, forward_time=0.149, uma_reduction=0.200, text_vs_uma=0.478, loss_ctc=6.062, loss=3.031, backward_time=0.187, optim_step_time=0.049, optim0_lr0=2.376e-04, train_time=0.949
[alab02] 2024-08-28 21:45:14,751 (trainer:720) INFO: 38epoch:train:2201-2400batch: iter_time=3.440e-04, forward_time=0.155, uma_reduction=0.201, text_vs_uma=0.482, loss_ctc=5.328, loss=2.664, backward_time=0.200, optim_step_time=0.051, optim0_lr0=2.375e-04, train_time=0.979
[alab02] 2024-08-28 21:46:50,548 (trainer:720) INFO: 38epoch:train:2401-2600batch: iter_time=3.650e-04, forward_time=0.149, uma_reduction=0.201, text_vs_uma=0.484, loss_ctc=5.531, loss=2.766, backward_time=0.198, optim_step_time=0.050, optim0_lr0=2.374e-04, train_time=0.958
[alab02] 2024-08-28 21:48:24,792 (trainer:720) INFO: 38epoch:train:2601-2800batch: iter_time=4.431e-04, forward_time=0.148, uma_reduction=0.203, text_vs_uma=0.474, loss_ctc=5.420, loss=2.710, backward_time=0.192, optim_step_time=0.051, optim0_lr0=2.373e-04, train_time=0.942
[alab02] 2024-08-28 21:50:02,774 (trainer:720) INFO: 38epoch:train:2801-3000batch: iter_time=3.532e-04, forward_time=0.156, uma_reduction=0.203, text_vs_uma=0.466, loss_ctc=4.987, loss=2.493, backward_time=0.201, optim_step_time=0.052, optim0_lr0=2.372e-04, train_time=0.979
[alab02] 2024-08-28 21:51:41,052 (trainer:720) INFO: 38epoch:train:3001-3200batch: iter_time=4.752e-04, forward_time=0.156, uma_reduction=0.201, text_vs_uma=0.492, loss_ctc=5.752, loss=2.876, backward_time=0.199, optim_step_time=0.054, optim0_lr0=2.371e-04, train_time=0.982
[alab02] 2024-08-28 21:53:17,197 (trainer:720) INFO: 38epoch:train:3201-3400batch: iter_time=4.604e-04, forward_time=0.151, uma_reduction=0.200, text_vs_uma=0.475, loss_ctc=5.563, loss=2.782, backward_time=0.194, optim_step_time=0.052, optim0_lr0=2.370e-04, train_time=0.961
[alab02] 2024-08-28 21:54:51,723 (trainer:720) INFO: 38epoch:train:3401-3600batch: iter_time=3.600e-04, forward_time=0.148, uma_reduction=0.197, text_vs_uma=0.481, loss_ctc=5.292, loss=2.646, backward_time=0.193, optim_step_time=0.049, optim0_lr0=2.369e-04, train_time=0.945
[alab02] 2024-08-28 21:56:27,689 (trainer:720) INFO: 38epoch:train:3601-3800batch: iter_time=3.655e-04, forward_time=0.151, uma_reduction=0.196, text_vs_uma=0.505, loss_ctc=6.023, loss=3.011, backward_time=0.193, optim_step_time=0.051, optim0_lr0=2.369e-04, train_time=0.959
[alab02] 2024-08-28 21:58:06,434 (trainer:720) INFO: 38epoch:train:3801-4000batch: iter_time=4.079e-04, forward_time=0.157, uma_reduction=0.201, text_vs_uma=0.481, loss_ctc=5.664, loss=2.832, backward_time=0.199, optim_step_time=0.053, optim0_lr0=2.368e-04, train_time=0.987
[alab02] 2024-08-28 21:59:42,377 (trainer:720) INFO: 38epoch:train:4001-4200batch: iter_time=3.710e-04, forward_time=0.152, uma_reduction=0.203, text_vs_uma=0.483, loss_ctc=5.615, loss=2.807, backward_time=0.192, optim_step_time=0.051, optim0_lr0=2.367e-04, train_time=0.959
[alab02] 2024-08-28 22:01:17,742 (trainer:720) INFO: 38epoch:train:4201-4400batch: iter_time=3.213e-04, forward_time=0.149, uma_reduction=0.206, text_vs_uma=0.476, loss_ctc=5.550, loss=2.775, backward_time=0.192, optim_step_time=0.051, optim0_lr0=2.366e-04, train_time=0.953
[alab02] 2024-08-28 22:02:53,394 (trainer:720) INFO: 38epoch:train:4401-4600batch: iter_time=3.722e-04, forward_time=0.151, uma_reduction=0.207, text_vs_uma=0.472, loss_ctc=5.398, loss=2.699, backward_time=0.194, optim_step_time=0.054, optim0_lr0=2.365e-04, train_time=0.956
[alab02] 2024-08-28 22:04:29,713 (trainer:720) INFO: 38epoch:train:4601-4800batch: iter_time=3.747e-04, forward_time=0.151, uma_reduction=0.201, text_vs_uma=0.476, loss_ctc=5.768, loss=2.884, backward_time=0.193, optim_step_time=0.055, optim0_lr0=2.364e-04, train_time=0.963
[alab02] 2024-08-28 22:06:08,784 (trainer:720) INFO: 38epoch:train:4801-5000batch: iter_time=4.180e-04, forward_time=0.157, uma_reduction=0.202, text_vs_uma=0.473, loss_ctc=5.265, loss=2.632, backward_time=0.203, optim_step_time=0.055, optim0_lr0=2.363e-04, train_time=0.990
[alab02] 2024-08-28 22:07:48,165 (trainer:720) INFO: 38epoch:train:5001-5200batch: iter_time=4.216e-04, forward_time=0.158, uma_reduction=0.207, text_vs_uma=0.469, loss_ctc=5.303, loss=2.652, backward_time=0.203, optim_step_time=0.058, optim0_lr0=2.362e-04, train_time=0.993
[alab02] 2024-08-28 22:09:26,020 (trainer:720) INFO: 38epoch:train:5201-5400batch: iter_time=4.662e-04, forward_time=0.157, uma_reduction=0.200, text_vs_uma=0.470, loss_ctc=5.133, loss=2.566, backward_time=0.197, optim_step_time=0.060, optim0_lr0=2.362e-04, train_time=0.978
[alab02] 2024-08-28 22:11:02,956 (trainer:720) INFO: 38epoch:train:5401-5600batch: iter_time=4.201e-04, forward_time=0.153, uma_reduction=0.205, text_vs_uma=0.461, loss_ctc=5.082, loss=2.541, backward_time=0.196, optim_step_time=0.057, optim0_lr0=2.361e-04, train_time=0.969
[alab02] 2024-08-28 22:12:39,664 (trainer:720) INFO: 38epoch:train:5601-5800batch: iter_time=3.212e-04, forward_time=0.153, uma_reduction=0.207, text_vs_uma=0.467, loss_ctc=5.345, loss=2.673, backward_time=0.195, optim_step_time=0.056, optim0_lr0=2.360e-04, train_time=0.966
[alab02] 2024-08-28 22:14:17,711 (trainer:720) INFO: 38epoch:train:5801-6000batch: iter_time=4.082e-04, forward_time=0.155, uma_reduction=0.206, text_vs_uma=0.463, loss_ctc=5.491, loss=2.746, backward_time=0.196, optim_step_time=0.056, optim0_lr0=2.359e-04, train_time=0.980
[alab02] 2024-08-28 22:15:52,667 (trainer:720) INFO: 38epoch:train:6001-6200batch: iter_time=4.797e-04, forward_time=0.152, uma_reduction=0.208, text_vs_uma=0.469, loss_ctc=5.273, loss=2.636, backward_time=0.192, optim_step_time=0.057, optim0_lr0=2.358e-04, train_time=0.949
[alab02] 2024-08-28 22:17:30,479 (trainer:720) INFO: 38epoch:train:6201-6400batch: iter_time=4.855e-04, forward_time=0.155, uma_reduction=0.203, text_vs_uma=0.461, loss_ctc=5.320, loss=2.660, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.357e-04, train_time=0.978
[alab02] 2024-08-28 22:19:08,757 (trainer:720) INFO: 38epoch:train:6401-6600batch: iter_time=3.543e-04, forward_time=0.155, uma_reduction=0.204, text_vs_uma=0.476, loss_ctc=5.576, loss=2.788, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.356e-04, train_time=0.982
[alab02] 2024-08-28 22:20:46,234 (trainer:720) INFO: 38epoch:train:6601-6800batch: iter_time=4.720e-04, forward_time=0.155, uma_reduction=0.208, text_vs_uma=0.457, loss_ctc=5.100, loss=2.550, backward_time=0.198, optim_step_time=0.058, optim0_lr0=2.355e-04, train_time=0.974
[alab02] 2024-08-28 22:22:22,349 (trainer:720) INFO: 38epoch:train:6801-7000batch: iter_time=6.382e-04, forward_time=0.150, uma_reduction=0.213, text_vs_uma=0.454, loss_ctc=4.960, loss=2.480, backward_time=0.197, optim_step_time=0.055, optim0_lr0=2.355e-04, train_time=0.961
[alab02] 2024-08-28 22:24:01,504 (trainer:338) INFO: 38epoch results: [train] iter_time=5.383e-04, forward_time=0.151, uma_reduction=0.203, text_vs_uma=0.473, loss_ctc=5.429, loss=2.715, backward_time=0.194, optim_step_time=0.052, optim0_lr0=2.369e-04, train_time=0.959, time=57 minutes and 0.98 seconds, total_count=270788, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.200, text_vs_uma=0.541, loss_ctc=3.661, cer_ctc=0.094, cer=0.094, loss=3.661, time=8.09 seconds, total_count=988, gpu_max_cached_mem_GB=35.906, [att_plot] time=26.9 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 22:24:10,493 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-28 22:24:10,580 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/35epoch.pth
[alab02] 2024-08-28 22:24:10,580 (trainer:272) INFO: 39/150epoch started. Estimated time to finish: 4 days, 8 hours and 31 minutes
[alab02] 2024-08-28 22:25:52,206 (trainer:720) INFO: 39epoch:train:1-200batch: iter_time=0.006, forward_time=0.162, uma_reduction=0.209, text_vs_uma=0.447, loss_ctc=4.764, loss=2.382, backward_time=0.203, optim_step_time=0.057, optim0_lr0=2.353e-04, train_time=1.015
[alab02] 2024-08-28 22:27:32,956 (trainer:720) INFO: 39epoch:train:201-400batch: iter_time=5.540e-04, forward_time=0.160, uma_reduction=0.210, text_vs_uma=0.453, loss_ctc=5.028, loss=2.514, backward_time=0.206, optim_step_time=0.059, optim0_lr0=2.352e-04, train_time=1.007
[alab02] 2024-08-28 22:29:07,960 (trainer:720) INFO: 39epoch:train:401-600batch: iter_time=5.733e-04, forward_time=0.150, uma_reduction=0.204, text_vs_uma=0.478, loss_ctc=5.360, loss=2.680, backward_time=0.192, optim_step_time=0.055, optim0_lr0=2.351e-04, train_time=0.950
[alab02] 2024-08-28 22:30:41,286 (trainer:720) INFO: 39epoch:train:601-800batch: iter_time=3.986e-04, forward_time=0.146, uma_reduction=0.204, text_vs_uma=0.472, loss_ctc=5.001, loss=2.501, backward_time=0.192, optim_step_time=0.048, optim0_lr0=2.351e-04, train_time=0.933
[alab02] 2024-08-28 22:32:15,291 (trainer:720) INFO: 39epoch:train:801-1000batch: iter_time=3.424e-04, forward_time=0.149, uma_reduction=0.208, text_vs_uma=0.445, loss_ctc=4.824, loss=2.412, backward_time=0.193, optim_step_time=0.047, optim0_lr0=2.350e-04, train_time=0.940
[alab02] 2024-08-28 22:33:52,146 (trainer:720) INFO: 39epoch:train:1001-1200batch: iter_time=4.038e-04, forward_time=0.153, uma_reduction=0.204, text_vs_uma=0.456, loss_ctc=5.170, loss=2.585, backward_time=0.195, optim_step_time=0.053, optim0_lr0=2.349e-04, train_time=0.968
[alab02] 2024-08-28 22:35:27,387 (trainer:720) INFO: 39epoch:train:1201-1400batch: iter_time=3.596e-04, forward_time=0.148, uma_reduction=0.208, text_vs_uma=0.454, loss_ctc=5.170, loss=2.585, backward_time=0.196, optim_step_time=0.049, optim0_lr0=2.348e-04, train_time=0.952
[alab02] 2024-08-28 22:37:03,006 (trainer:720) INFO: 39epoch:train:1401-1600batch: iter_time=3.365e-04, forward_time=0.151, uma_reduction=0.212, text_vs_uma=0.448, loss_ctc=5.099, loss=2.550, backward_time=0.196, optim_step_time=0.050, optim0_lr0=2.347e-04, train_time=0.956
[alab02] 2024-08-28 22:38:37,353 (trainer:720) INFO: 39epoch:train:1601-1800batch: iter_time=3.226e-04, forward_time=0.148, uma_reduction=0.204, text_vs_uma=0.453, loss_ctc=5.131, loss=2.566, backward_time=0.194, optim_step_time=0.048, optim0_lr0=2.346e-04, train_time=0.943
[alab02] 2024-08-28 22:40:12,165 (trainer:720) INFO: 39epoch:train:1801-2000batch: iter_time=3.624e-04, forward_time=0.150, uma_reduction=0.205, text_vs_uma=0.480, loss_ctc=5.619, loss=2.810, backward_time=0.190, optim_step_time=0.050, optim0_lr0=2.345e-04, train_time=0.948
[alab02] 2024-08-28 22:41:46,163 (trainer:720) INFO: 39epoch:train:2001-2200batch: iter_time=3.883e-04, forward_time=0.147, uma_reduction=0.203, text_vs_uma=0.474, loss_ctc=5.129, loss=2.564, backward_time=0.190, optim_step_time=0.049, optim0_lr0=2.345e-04, train_time=0.940
[alab02] 2024-08-28 22:43:19,456 (trainer:720) INFO: 39epoch:train:2201-2400batch: iter_time=3.076e-04, forward_time=0.146, uma_reduction=0.199, text_vs_uma=0.487, loss_ctc=5.808, loss=2.904, backward_time=0.186, optim_step_time=0.044, optim0_lr0=2.344e-04, train_time=0.933
[alab02] 2024-08-28 22:44:53,305 (trainer:720) INFO: 39epoch:train:2401-2600batch: iter_time=2.948e-04, forward_time=0.146, uma_reduction=0.199, text_vs_uma=0.477, loss_ctc=5.747, loss=2.873, backward_time=0.189, optim_step_time=0.045, optim0_lr0=2.343e-04, train_time=0.938
[alab02] 2024-08-28 22:46:26,445 (trainer:720) INFO: 39epoch:train:2601-2800batch: iter_time=2.713e-04, forward_time=0.146, uma_reduction=0.203, text_vs_uma=0.467, loss_ctc=5.231, loss=2.615, backward_time=0.189, optim_step_time=0.044, optim0_lr0=2.342e-04, train_time=0.931
[alab02] 2024-08-28 22:47:57,850 (trainer:720) INFO: 39epoch:train:2801-3000batch: iter_time=2.604e-04, forward_time=0.143, uma_reduction=0.204, text_vs_uma=0.469, loss_ctc=5.508, loss=2.754, backward_time=0.185, optim_step_time=0.043, optim0_lr0=2.341e-04, train_time=0.914
[alab02] 2024-08-28 22:49:29,095 (trainer:720) INFO: 39epoch:train:3001-3200batch: iter_time=2.792e-04, forward_time=0.143, uma_reduction=0.204, text_vs_uma=0.468, loss_ctc=5.416, loss=2.708, backward_time=0.182, optim_step_time=0.046, optim0_lr0=2.340e-04, train_time=0.912
[alab02] 2024-08-28 22:51:00,324 (trainer:720) INFO: 39epoch:train:3201-3400batch: iter_time=2.473e-04, forward_time=0.142, uma_reduction=0.204, text_vs_uma=0.474, loss_ctc=5.264, loss=2.632, backward_time=0.187, optim_step_time=0.042, optim0_lr0=2.339e-04, train_time=0.912
[alab02] 2024-08-28 22:52:34,440 (trainer:720) INFO: 39epoch:train:3401-3600batch: iter_time=2.996e-04, forward_time=0.148, uma_reduction=0.203, text_vs_uma=0.474, loss_ctc=5.895, loss=2.947, backward_time=0.188, optim_step_time=0.044, optim0_lr0=2.339e-04, train_time=0.941
[alab02] 2024-08-28 22:54:06,792 (trainer:720) INFO: 39epoch:train:3601-3800batch: iter_time=3.152e-04, forward_time=0.145, uma_reduction=0.205, text_vs_uma=0.476, loss_ctc=5.699, loss=2.850, backward_time=0.187, optim_step_time=0.042, optim0_lr0=2.338e-04, train_time=0.923
[alab02] 2024-08-28 22:55:42,437 (trainer:720) INFO: 39epoch:train:3801-4000batch: iter_time=3.251e-04, forward_time=0.150, uma_reduction=0.206, text_vs_uma=0.475, loss_ctc=5.773, loss=2.887, backward_time=0.194, optim_step_time=0.043, optim0_lr0=2.337e-04, train_time=0.956
[alab02] 2024-08-28 22:57:14,629 (trainer:720) INFO: 39epoch:train:4001-4200batch: iter_time=3.655e-04, forward_time=0.142, uma_reduction=0.206, text_vs_uma=0.475, loss_ctc=5.597, loss=2.799, backward_time=0.187, optim_step_time=0.040, optim0_lr0=2.336e-04, train_time=0.922
[alab02] 2024-08-28 22:58:42,533 (trainer:720) INFO: 39epoch:train:4201-4400batch: iter_time=2.326e-04, forward_time=0.136, uma_reduction=0.203, text_vs_uma=0.473, loss_ctc=5.398, loss=2.699, backward_time=0.178, optim_step_time=0.038, optim0_lr0=2.335e-04, train_time=0.879
[alab02] 2024-08-28 23:00:12,050 (trainer:720) INFO: 39epoch:train:4401-4600batch: iter_time=2.435e-04, forward_time=0.139, uma_reduction=0.206, text_vs_uma=0.465, loss_ctc=5.421, loss=2.710, backward_time=0.180, optim_step_time=0.038, optim0_lr0=2.334e-04, train_time=0.895
[alab02] 2024-08-28 23:01:41,096 (trainer:720) INFO: 39epoch:train:4601-4800batch: iter_time=2.112e-04, forward_time=0.138, uma_reduction=0.209, text_vs_uma=0.468, loss_ctc=5.291, loss=2.645, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.333e-04, train_time=0.890
[alab02] 2024-08-28 23:03:09,098 (trainer:720) INFO: 39epoch:train:4801-5000batch: iter_time=2.023e-04, forward_time=0.134, uma_reduction=0.208, text_vs_uma=0.459, loss_ctc=5.375, loss=2.688, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.333e-04, train_time=0.880
[alab02] 2024-08-28 23:04:40,322 (trainer:720) INFO: 39epoch:train:5001-5200batch: iter_time=3.285e-04, forward_time=0.140, uma_reduction=0.206, text_vs_uma=0.458, loss_ctc=5.196, loss=2.598, backward_time=0.189, optim_step_time=0.039, optim0_lr0=2.332e-04, train_time=0.912
[alab02] 2024-08-28 23:06:07,927 (trainer:720) INFO: 39epoch:train:5201-5400batch: iter_time=2.006e-04, forward_time=0.133, uma_reduction=0.209, text_vs_uma=0.467, loss_ctc=5.543, loss=2.772, backward_time=0.177, optim_step_time=0.036, optim0_lr0=2.331e-04, train_time=0.876
[alab02] 2024-08-28 23:07:36,709 (trainer:720) INFO: 39epoch:train:5401-5600batch: iter_time=2.080e-04, forward_time=0.136, uma_reduction=0.209, text_vs_uma=0.449, loss_ctc=5.038, loss=2.519, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.330e-04, train_time=0.888
[alab02] 2024-08-28 23:09:05,102 (trainer:720) INFO: 39epoch:train:5601-5800batch: iter_time=2.123e-04, forward_time=0.134, uma_reduction=0.210, text_vs_uma=0.469, loss_ctc=5.451, loss=2.725, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.329e-04, train_time=0.884
[alab02] 2024-08-28 23:10:32,570 (trainer:720) INFO: 39epoch:train:5801-6000batch: iter_time=2.260e-04, forward_time=0.133, uma_reduction=0.204, text_vs_uma=0.471, loss_ctc=5.524, loss=2.762, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.328e-04, train_time=0.874
[alab02] 2024-08-28 23:12:03,018 (trainer:720) INFO: 39epoch:train:6001-6200batch: iter_time=2.327e-04, forward_time=0.137, uma_reduction=0.203, text_vs_uma=0.473, loss_ctc=5.444, loss=2.722, backward_time=0.189, optim_step_time=0.036, optim0_lr0=2.328e-04, train_time=0.904
[alab02] 2024-08-28 23:13:31,920 (trainer:720) INFO: 39epoch:train:6201-6400batch: iter_time=1.993e-04, forward_time=0.134, uma_reduction=0.205, text_vs_uma=0.471, loss_ctc=5.341, loss=2.671, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.327e-04, train_time=0.889
[alab02] 2024-08-28 23:15:08,273 (trainer:720) INFO: 39epoch:train:6401-6600batch: iter_time=3.725e-04, forward_time=0.152, uma_reduction=0.207, text_vs_uma=0.452, loss_ctc=5.179, loss=2.590, backward_time=0.197, optim_step_time=0.047, optim0_lr0=2.326e-04, train_time=0.963
[alab02] 2024-08-28 23:16:43,818 (trainer:720) INFO: 39epoch:train:6601-6800batch: iter_time=3.458e-04, forward_time=0.152, uma_reduction=0.207, text_vs_uma=0.469, loss_ctc=5.370, loss=2.685, backward_time=0.192, optim_step_time=0.052, optim0_lr0=2.325e-04, train_time=0.955
[alab02] 2024-08-28 23:18:21,003 (trainer:720) INFO: 39epoch:train:6801-7000batch: iter_time=3.728e-04, forward_time=0.155, uma_reduction=0.204, text_vs_uma=0.483, loss_ctc=6.100, loss=3.050, backward_time=0.192, optim_step_time=0.052, optim0_lr0=2.324e-04, train_time=0.971
[alab02] 2024-08-28 23:19:47,662 (trainer:338) INFO: 39epoch results: [train] iter_time=4.664e-04, forward_time=0.145, uma_reduction=0.206, text_vs_uma=0.466, loss_ctc=5.363, loss=2.681, backward_time=0.189, optim_step_time=0.044, optim0_lr0=2.338e-04, train_time=0.928, time=55 minutes and 9.16 seconds, total_count=277914, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.204, text_vs_uma=0.531, loss_ctc=3.610, cer_ctc=0.096, cer=0.096, loss=3.610, time=7.86 seconds, total_count=1014, gpu_max_cached_mem_GB=35.906, [att_plot] time=20.06 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-28 23:19:55,550 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-28 23:19:55,560 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/30epoch.pth
[alab02] 2024-08-28 23:19:55,561 (trainer:272) INFO: 40/150epoch started. Estimated time to finish: 4 days, 7 hours and 34 minutes
[alab02] 2024-08-28 23:21:33,916 (trainer:720) INFO: 40epoch:train:1-200batch: iter_time=0.004, forward_time=0.156, uma_reduction=0.204, text_vs_uma=0.482, loss_ctc=5.561, loss=2.781, backward_time=0.196, optim_step_time=0.052, optim0_lr0=2.323e-04, train_time=0.983
[alab02] 2024-08-28 23:23:10,095 (trainer:720) INFO: 40epoch:train:201-400batch: iter_time=3.687e-04, forward_time=0.153, uma_reduction=0.202, text_vs_uma=0.469, loss_ctc=5.208, loss=2.604, backward_time=0.195, optim_step_time=0.050, optim0_lr0=2.322e-04, train_time=0.961
[alab02] 2024-08-28 23:24:47,419 (trainer:720) INFO: 40epoch:train:401-600batch: iter_time=3.519e-04, forward_time=0.155, uma_reduction=0.200, text_vs_uma=0.473, loss_ctc=5.521, loss=2.761, backward_time=0.198, optim_step_time=0.051, optim0_lr0=2.321e-04, train_time=0.973
[alab02] 2024-08-28 23:26:23,879 (trainer:720) INFO: 40epoch:train:601-800batch: iter_time=3.779e-04, forward_time=0.154, uma_reduction=0.201, text_vs_uma=0.483, loss_ctc=5.722, loss=2.861, backward_time=0.193, optim_step_time=0.054, optim0_lr0=2.320e-04, train_time=0.964
[alab02] 2024-08-28 23:28:04,514 (trainer:720) INFO: 40epoch:train:801-1000batch: iter_time=5.517e-04, forward_time=0.161, uma_reduction=0.206, text_vs_uma=0.475, loss_ctc=5.353, loss=2.677, backward_time=0.205, optim_step_time=0.056, optim0_lr0=2.319e-04, train_time=1.006
[alab02] 2024-08-28 23:29:43,014 (trainer:720) INFO: 40epoch:train:1001-1200batch: iter_time=4.702e-04, forward_time=0.159, uma_reduction=0.207, text_vs_uma=0.456, loss_ctc=5.179, loss=2.589, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.319e-04, train_time=0.985
[alab02] 2024-08-28 23:31:21,696 (trainer:720) INFO: 40epoch:train:1201-1400batch: iter_time=4.827e-04, forward_time=0.159, uma_reduction=0.204, text_vs_uma=0.473, loss_ctc=5.697, loss=2.848, backward_time=0.196, optim_step_time=0.058, optim0_lr0=2.318e-04, train_time=0.986
[alab02] 2024-08-28 23:33:01,637 (trainer:720) INFO: 40epoch:train:1401-1600batch: iter_time=3.968e-04, forward_time=0.159, uma_reduction=0.204, text_vs_uma=0.472, loss_ctc=5.543, loss=2.772, backward_time=0.205, optim_step_time=0.055, optim0_lr0=2.317e-04, train_time=0.999
[alab02] 2024-08-28 23:34:39,490 (trainer:720) INFO: 40epoch:train:1601-1800batch: iter_time=4.347e-04, forward_time=0.156, uma_reduction=0.206, text_vs_uma=0.470, loss_ctc=5.258, loss=2.629, backward_time=0.198, optim_step_time=0.057, optim0_lr0=2.316e-04, train_time=0.978
[alab02] 2024-08-28 23:36:20,597 (trainer:720) INFO: 40epoch:train:1801-2000batch: iter_time=5.485e-04, forward_time=0.163, uma_reduction=0.206, text_vs_uma=0.477, loss_ctc=5.656, loss=2.828, backward_time=0.201, optim_step_time=0.059, optim0_lr0=2.315e-04, train_time=1.010
[alab02] 2024-08-28 23:38:00,973 (trainer:720) INFO: 40epoch:train:2001-2200batch: iter_time=4.713e-04, forward_time=0.162, uma_reduction=0.204, text_vs_uma=0.465, loss_ctc=5.229, loss=2.615, backward_time=0.201, optim_step_time=0.060, optim0_lr0=2.314e-04, train_time=1.003
[alab02] 2024-08-28 23:39:37,189 (trainer:720) INFO: 40epoch:train:2201-2400batch: iter_time=4.350e-04, forward_time=0.154, uma_reduction=0.206, text_vs_uma=0.475, loss_ctc=5.856, loss=2.928, backward_time=0.189, optim_step_time=0.056, optim0_lr0=2.314e-04, train_time=0.962
[alab02] 2024-08-28 23:41:13,371 (trainer:720) INFO: 40epoch:train:2401-2600batch: iter_time=3.971e-04, forward_time=0.152, uma_reduction=0.205, text_vs_uma=0.470, loss_ctc=5.680, loss=2.840, backward_time=0.193, optim_step_time=0.054, optim0_lr0=2.313e-04, train_time=0.961
[alab02] 2024-08-28 23:42:53,413 (trainer:720) INFO: 40epoch:train:2601-2800batch: iter_time=4.450e-04, forward_time=0.160, uma_reduction=0.214, text_vs_uma=0.455, loss_ctc=5.111, loss=2.555, backward_time=0.203, optim_step_time=0.060, optim0_lr0=2.312e-04, train_time=1.000
[alab02] 2024-08-28 23:44:30,662 (trainer:720) INFO: 40epoch:train:2801-3000batch: iter_time=4.164e-04, forward_time=0.157, uma_reduction=0.214, text_vs_uma=0.451, loss_ctc=5.180, loss=2.590, backward_time=0.194, optim_step_time=0.057, optim0_lr0=2.311e-04, train_time=0.972
[alab02] 2024-08-28 23:46:11,284 (trainer:720) INFO: 40epoch:train:3001-3200batch: iter_time=6.788e-04, forward_time=0.160, uma_reduction=0.215, text_vs_uma=0.442, loss_ctc=4.826, loss=2.413, backward_time=0.207, optim_step_time=0.058, optim0_lr0=2.310e-04, train_time=1.006
[alab02] 2024-08-28 23:47:45,936 (trainer:720) INFO: 40epoch:train:3201-3400batch: iter_time=4.662e-04, forward_time=0.150, uma_reduction=0.210, text_vs_uma=0.461, loss_ctc=5.359, loss=2.679, backward_time=0.186, optim_step_time=0.054, optim0_lr0=2.310e-04, train_time=0.946
[alab02] 2024-08-28 23:49:23,693 (trainer:720) INFO: 40epoch:train:3401-3600batch: iter_time=4.619e-04, forward_time=0.158, uma_reduction=0.214, text_vs_uma=0.435, loss_ctc=4.816, loss=2.408, backward_time=0.197, optim_step_time=0.053, optim0_lr0=2.309e-04, train_time=0.977
[alab02] 2024-08-28 23:51:00,220 (trainer:720) INFO: 40epoch:train:3601-3800batch: iter_time=3.884e-04, forward_time=0.154, uma_reduction=0.208, text_vs_uma=0.465, loss_ctc=5.261, loss=2.631, backward_time=0.196, optim_step_time=0.053, optim0_lr0=2.308e-04, train_time=0.965
[alab02] 2024-08-28 23:52:38,041 (trainer:720) INFO: 40epoch:train:3801-4000batch: iter_time=3.972e-04, forward_time=0.156, uma_reduction=0.209, text_vs_uma=0.458, loss_ctc=5.307, loss=2.653, backward_time=0.197, optim_step_time=0.057, optim0_lr0=2.307e-04, train_time=0.978
[alab02] 2024-08-28 23:54:14,273 (trainer:720) INFO: 40epoch:train:4001-4200batch: iter_time=4.507e-04, forward_time=0.152, uma_reduction=0.210, text_vs_uma=0.461, loss_ctc=5.234, loss=2.617, backward_time=0.196, optim_step_time=0.053, optim0_lr0=2.306e-04, train_time=0.962
[alab02] 2024-08-28 23:55:52,271 (trainer:720) INFO: 40epoch:train:4201-4400batch: iter_time=3.464e-04, forward_time=0.156, uma_reduction=0.212, text_vs_uma=0.455, loss_ctc=5.449, loss=2.724, backward_time=0.196, optim_step_time=0.053, optim0_lr0=2.305e-04, train_time=0.980
[alab02] 2024-08-28 23:57:30,762 (trainer:720) INFO: 40epoch:train:4401-4600batch: iter_time=3.926e-04, forward_time=0.159, uma_reduction=0.210, text_vs_uma=0.450, loss_ctc=5.199, loss=2.599, backward_time=0.199, optim_step_time=0.053, optim0_lr0=2.305e-04, train_time=0.985
[alab02] 2024-08-28 23:59:07,181 (trainer:720) INFO: 40epoch:train:4601-4800batch: iter_time=4.419e-04, forward_time=0.152, uma_reduction=0.208, text_vs_uma=0.466, loss_ctc=5.576, loss=2.788, backward_time=0.193, optim_step_time=0.053, optim0_lr0=2.304e-04, train_time=0.964
[alab02] 2024-08-29 00:00:44,564 (trainer:720) INFO: 40epoch:train:4801-5000batch: iter_time=3.458e-04, forward_time=0.152, uma_reduction=0.207, text_vs_uma=0.468, loss_ctc=5.249, loss=2.624, backward_time=0.199, optim_step_time=0.053, optim0_lr0=2.303e-04, train_time=0.973
[alab02] 2024-08-29 00:02:21,796 (trainer:720) INFO: 40epoch:train:5001-5200batch: iter_time=3.570e-04, forward_time=0.154, uma_reduction=0.206, text_vs_uma=0.469, loss_ctc=5.375, loss=2.688, backward_time=0.194, optim_step_time=0.055, optim0_lr0=2.302e-04, train_time=0.972
[alab02] 2024-08-29 00:03:58,214 (trainer:720) INFO: 40epoch:train:5201-5400batch: iter_time=3.441e-04, forward_time=0.153, uma_reduction=0.212, text_vs_uma=0.455, loss_ctc=5.061, loss=2.531, backward_time=0.197, optim_step_time=0.055, optim0_lr0=2.301e-04, train_time=0.964
[alab02] 2024-08-29 00:05:33,236 (trainer:720) INFO: 40epoch:train:5401-5600batch: iter_time=3.258e-04, forward_time=0.151, uma_reduction=0.207, text_vs_uma=0.448, loss_ctc=4.829, loss=2.415, backward_time=0.194, optim_step_time=0.051, optim0_lr0=2.301e-04, train_time=0.950
[alab02] 2024-08-29 00:07:08,880 (trainer:720) INFO: 40epoch:train:5601-5800batch: iter_time=3.345e-04, forward_time=0.152, uma_reduction=0.212, text_vs_uma=0.441, loss_ctc=4.798, loss=2.399, backward_time=0.197, optim_step_time=0.051, optim0_lr0=2.300e-04, train_time=0.956
[alab02] 2024-08-29 00:08:44,221 (trainer:720) INFO: 40epoch:train:5801-6000batch: iter_time=3.688e-04, forward_time=0.150, uma_reduction=0.213, text_vs_uma=0.459, loss_ctc=5.174, loss=2.587, backward_time=0.195, optim_step_time=0.052, optim0_lr0=2.299e-04, train_time=0.953
[alab02] 2024-08-29 00:10:21,275 (trainer:720) INFO: 40epoch:train:6001-6200batch: iter_time=3.387e-04, forward_time=0.154, uma_reduction=0.212, text_vs_uma=0.459, loss_ctc=5.242, loss=2.621, backward_time=0.197, optim_step_time=0.051, optim0_lr0=2.298e-04, train_time=0.970
[alab02] 2024-08-29 00:11:59,026 (trainer:720) INFO: 40epoch:train:6201-6400batch: iter_time=3.443e-04, forward_time=0.157, uma_reduction=0.211, text_vs_uma=0.451, loss_ctc=5.346, loss=2.673, backward_time=0.196, optim_step_time=0.051, optim0_lr0=2.297e-04, train_time=0.977
[alab02] 2024-08-29 00:13:36,553 (trainer:720) INFO: 40epoch:train:6401-6600batch: iter_time=4.071e-04, forward_time=0.155, uma_reduction=0.207, text_vs_uma=0.459, loss_ctc=5.271, loss=2.635, backward_time=0.196, optim_step_time=0.056, optim0_lr0=2.297e-04, train_time=0.975
[alab02] 2024-08-29 00:15:14,198 (trainer:720) INFO: 40epoch:train:6601-6800batch: iter_time=3.632e-04, forward_time=0.156, uma_reduction=0.202, text_vs_uma=0.477, loss_ctc=5.607, loss=2.804, backward_time=0.193, optim_step_time=0.054, optim0_lr0=2.296e-04, train_time=0.976
[alab02] 2024-08-29 00:16:50,393 (trainer:720) INFO: 40epoch:train:6801-7000batch: iter_time=4.363e-04, forward_time=0.153, uma_reduction=0.210, text_vs_uma=0.455, loss_ctc=4.939, loss=2.470, backward_time=0.194, optim_step_time=0.055, optim0_lr0=2.295e-04, train_time=0.961
[alab02] 2024-08-29 00:18:23,874 (trainer:338) INFO: 40epoch results: [train] iter_time=5.190e-04, forward_time=0.156, uma_reduction=0.208, text_vs_uma=0.462, loss_ctc=5.298, loss=2.649, backward_time=0.197, optim_step_time=0.054, optim0_lr0=2.309e-04, train_time=0.975, time=57 minutes and 58.3 seconds, total_count=285040, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.204, text_vs_uma=0.532, loss_ctc=3.715, cer_ctc=0.096, cer=0.096, loss=3.715, time=7.73 seconds, total_count=1040, gpu_max_cached_mem_GB=35.906, [att_plot] time=22.28 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 00:18:31,451 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 00:18:31,459 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/25epoch.pth
[alab02] 2024-08-29 00:18:31,459 (trainer:272) INFO: 41/150epoch started. Estimated time to finish: 4 days, 6 hours and 45 minutes
[alab02] 2024-08-29 00:20:11,574 (trainer:720) INFO: 41epoch:train:1-200batch: iter_time=0.004, forward_time=0.157, uma_reduction=0.210, text_vs_uma=0.463, loss_ctc=5.407, loss=2.703, backward_time=0.200, optim_step_time=0.052, optim0_lr0=2.294e-04, train_time=1.000
[alab02] 2024-08-29 00:21:46,680 (trainer:720) INFO: 41epoch:train:201-400batch: iter_time=3.617e-04, forward_time=0.151, uma_reduction=0.205, text_vs_uma=0.463, loss_ctc=5.049, loss=2.524, backward_time=0.192, optim_step_time=0.049, optim0_lr0=2.293e-04, train_time=0.951
[alab02] 2024-08-29 00:23:24,526 (trainer:720) INFO: 41epoch:train:401-600batch: iter_time=3.423e-04, forward_time=0.157, uma_reduction=0.208, text_vs_uma=0.453, loss_ctc=4.856, loss=2.428, backward_time=0.199, optim_step_time=0.050, optim0_lr0=2.292e-04, train_time=0.978
[alab02] 2024-08-29 00:24:58,578 (trainer:720) INFO: 41epoch:train:601-800batch: iter_time=3.491e-04, forward_time=0.148, uma_reduction=0.213, text_vs_uma=0.448, loss_ctc=4.791, loss=2.396, backward_time=0.192, optim_step_time=0.050, optim0_lr0=2.291e-04, train_time=0.940
[alab02] 2024-08-29 00:26:33,600 (trainer:720) INFO: 41epoch:train:801-1000batch: iter_time=3.277e-04, forward_time=0.150, uma_reduction=0.213, text_vs_uma=0.455, loss_ctc=5.081, loss=2.540, backward_time=0.191, optim_step_time=0.051, optim0_lr0=2.290e-04, train_time=0.950
[alab02] 2024-08-29 00:28:07,531 (trainer:720) INFO: 41epoch:train:1001-1200batch: iter_time=3.062e-04, forward_time=0.147, uma_reduction=0.208, text_vs_uma=0.454, loss_ctc=5.469, loss=2.734, backward_time=0.187, optim_step_time=0.047, optim0_lr0=2.290e-04, train_time=0.939
[alab02] 2024-08-29 00:29:42,157 (trainer:720) INFO: 41epoch:train:1201-1400batch: iter_time=4.383e-04, forward_time=0.151, uma_reduction=0.215, text_vs_uma=0.457, loss_ctc=5.083, loss=2.541, backward_time=0.192, optim_step_time=0.048, optim0_lr0=2.289e-04, train_time=0.946
[alab02] 2024-08-29 00:31:19,608 (trainer:720) INFO: 41epoch:train:1401-1600batch: iter_time=4.536e-04, forward_time=0.154, uma_reduction=0.207, text_vs_uma=0.477, loss_ctc=5.430, loss=2.715, backward_time=0.196, optim_step_time=0.053, optim0_lr0=2.288e-04, train_time=0.974
[alab02] 2024-08-29 00:32:54,317 (trainer:720) INFO: 41epoch:train:1601-1800batch: iter_time=4.733e-04, forward_time=0.148, uma_reduction=0.204, text_vs_uma=0.464, loss_ctc=5.306, loss=2.653, backward_time=0.191, optim_step_time=0.048, optim0_lr0=2.287e-04, train_time=0.947
[alab02] 2024-08-29 00:34:29,407 (trainer:720) INFO: 41epoch:train:1801-2000batch: iter_time=3.792e-04, forward_time=0.150, uma_reduction=0.210, text_vs_uma=0.456, loss_ctc=5.215, loss=2.607, backward_time=0.191, optim_step_time=0.048, optim0_lr0=2.286e-04, train_time=0.951
[alab02] 2024-08-29 00:36:01,899 (trainer:720) INFO: 41epoch:train:2001-2200batch: iter_time=3.484e-04, forward_time=0.147, uma_reduction=0.212, text_vs_uma=0.453, loss_ctc=4.931, loss=2.465, backward_time=0.183, optim_step_time=0.047, optim0_lr0=2.286e-04, train_time=0.925
[alab02] 2024-08-29 00:37:32,873 (trainer:720) INFO: 41epoch:train:2201-2400batch: iter_time=3.006e-04, forward_time=0.141, uma_reduction=0.205, text_vs_uma=0.463, loss_ctc=4.933, loss=2.467, backward_time=0.185, optim_step_time=0.042, optim0_lr0=2.285e-04, train_time=0.909
[alab02] 2024-08-29 00:39:05,181 (trainer:720) INFO: 41epoch:train:2401-2600batch: iter_time=2.696e-04, forward_time=0.143, uma_reduction=0.203, text_vs_uma=0.480, loss_ctc=5.176, loss=2.588, backward_time=0.190, optim_step_time=0.041, optim0_lr0=2.284e-04, train_time=0.923
[alab02] 2024-08-29 00:40:34,416 (trainer:720) INFO: 41epoch:train:2601-2800batch: iter_time=2.776e-04, forward_time=0.136, uma_reduction=0.208, text_vs_uma=0.464, loss_ctc=5.365, loss=2.683, backward_time=0.181, optim_step_time=0.040, optim0_lr0=2.283e-04, train_time=0.892
[alab02] 2024-08-29 00:42:03,468 (trainer:720) INFO: 41epoch:train:2801-3000batch: iter_time=2.677e-04, forward_time=0.135, uma_reduction=0.204, text_vs_uma=0.481, loss_ctc=5.817, loss=2.908, backward_time=0.180, optim_step_time=0.038, optim0_lr0=2.282e-04, train_time=0.890
[alab02] 2024-08-29 00:43:31,741 (trainer:720) INFO: 41epoch:train:3001-3200batch: iter_time=3.232e-04, forward_time=0.135, uma_reduction=0.205, text_vs_uma=0.472, loss_ctc=5.121, loss=2.560, backward_time=0.182, optim_step_time=0.037, optim0_lr0=2.282e-04, train_time=0.882
[alab02] 2024-08-29 00:45:02,620 (trainer:720) INFO: 41epoch:train:3201-3400batch: iter_time=2.797e-04, forward_time=0.137, uma_reduction=0.198, text_vs_uma=0.469, loss_ctc=5.082, loss=2.541, backward_time=0.192, optim_step_time=0.036, optim0_lr0=2.281e-04, train_time=0.909
[alab02] 2024-08-29 00:46:29,484 (trainer:720) INFO: 41epoch:train:3401-3600batch: iter_time=1.899e-04, forward_time=0.132, uma_reduction=0.203, text_vs_uma=0.478, loss_ctc=5.040, loss=2.520, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.280e-04, train_time=0.868
[alab02] 2024-08-29 00:47:58,311 (trainer:720) INFO: 41epoch:train:3601-3800batch: iter_time=1.957e-04, forward_time=0.135, uma_reduction=0.206, text_vs_uma=0.457, loss_ctc=5.005, loss=2.502, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.279e-04, train_time=0.888
[alab02] 2024-08-29 00:49:29,045 (trainer:720) INFO: 41epoch:train:3801-4000batch: iter_time=2.293e-04, forward_time=0.139, uma_reduction=0.201, text_vs_uma=0.479, loss_ctc=4.973, loss=2.487, backward_time=0.190, optim_step_time=0.037, optim0_lr0=2.278e-04, train_time=0.907
[alab02] 2024-08-29 00:50:58,520 (trainer:720) INFO: 41epoch:train:4001-4200batch: iter_time=2.322e-04, forward_time=0.137, uma_reduction=0.206, text_vs_uma=0.464, loss_ctc=4.974, loss=2.487, backward_time=0.185, optim_step_time=0.038, optim0_lr0=2.278e-04, train_time=0.894
[alab02] 2024-08-29 00:52:30,237 (trainer:720) INFO: 41epoch:train:4201-4400batch: iter_time=2.354e-04, forward_time=0.140, uma_reduction=0.203, text_vs_uma=0.460, loss_ctc=5.164, loss=2.582, backward_time=0.190, optim_step_time=0.037, optim0_lr0=2.277e-04, train_time=0.917
[alab02] 2024-08-29 00:54:01,010 (trainer:720) INFO: 41epoch:train:4401-4600batch: iter_time=2.251e-04, forward_time=0.137, uma_reduction=0.201, text_vs_uma=0.482, loss_ctc=5.699, loss=2.849, backward_time=0.186, optim_step_time=0.037, optim0_lr0=2.276e-04, train_time=0.907
[alab02] 2024-08-29 00:55:29,165 (trainer:720) INFO: 41epoch:train:4601-4800batch: iter_time=2.565e-04, forward_time=0.134, uma_reduction=0.201, text_vs_uma=0.485, loss_ctc=5.056, loss=2.528, backward_time=0.184, optim_step_time=0.038, optim0_lr0=2.275e-04, train_time=0.881
[alab02] 2024-08-29 00:57:01,079 (trainer:720) INFO: 41epoch:train:4801-5000batch: iter_time=2.241e-04, forward_time=0.140, uma_reduction=0.200, text_vs_uma=0.491, loss_ctc=5.661, loss=2.831, backward_time=0.190, optim_step_time=0.037, optim0_lr0=2.275e-04, train_time=0.919
[alab02] 2024-08-29 00:58:30,085 (trainer:720) INFO: 41epoch:train:5001-5200batch: iter_time=2.052e-04, forward_time=0.135, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=5.594, loss=2.797, backward_time=0.182, optim_step_time=0.038, optim0_lr0=2.274e-04, train_time=0.890
[alab02] 2024-08-29 00:59:58,924 (trainer:720) INFO: 41epoch:train:5201-5400batch: iter_time=2.159e-04, forward_time=0.135, uma_reduction=0.202, text_vs_uma=0.475, loss_ctc=5.272, loss=2.636, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.273e-04, train_time=0.888
[alab02] 2024-08-29 01:01:29,306 (trainer:720) INFO: 41epoch:train:5401-5600batch: iter_time=2.158e-04, forward_time=0.137, uma_reduction=0.208, text_vs_uma=0.457, loss_ctc=5.125, loss=2.563, backward_time=0.187, optim_step_time=0.036, optim0_lr0=2.272e-04, train_time=0.904
[alab02] 2024-08-29 01:02:55,742 (trainer:720) INFO: 41epoch:train:5601-5800batch: iter_time=1.971e-04, forward_time=0.130, uma_reduction=0.204, text_vs_uma=0.469, loss_ctc=5.178, loss=2.589, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.271e-04, train_time=0.864
[alab02] 2024-08-29 01:04:22,352 (trainer:720) INFO: 41epoch:train:5801-6000batch: iter_time=1.826e-04, forward_time=0.130, uma_reduction=0.202, text_vs_uma=0.483, loss_ctc=5.795, loss=2.898, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.271e-04, train_time=0.866
[alab02] 2024-08-29 01:05:50,215 (trainer:720) INFO: 41epoch:train:6001-6200batch: iter_time=1.973e-04, forward_time=0.132, uma_reduction=0.207, text_vs_uma=0.458, loss_ctc=5.022, loss=2.511, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.270e-04, train_time=0.878
[alab02] 2024-08-29 01:07:20,333 (trainer:720) INFO: 41epoch:train:6201-6400batch: iter_time=2.227e-04, forward_time=0.137, uma_reduction=0.204, text_vs_uma=0.477, loss_ctc=5.626, loss=2.813, backward_time=0.184, optim_step_time=0.037, optim0_lr0=2.269e-04, train_time=0.901
[alab02] 2024-08-29 01:08:48,855 (trainer:720) INFO: 41epoch:train:6401-6600batch: iter_time=2.172e-04, forward_time=0.134, uma_reduction=0.209, text_vs_uma=0.448, loss_ctc=4.993, loss=2.497, backward_time=0.183, optim_step_time=0.037, optim0_lr0=2.268e-04, train_time=0.885
[alab02] 2024-08-29 01:10:17,094 (trainer:720) INFO: 41epoch:train:6601-6800batch: iter_time=1.888e-04, forward_time=0.133, uma_reduction=0.209, text_vs_uma=0.459, loss_ctc=5.071, loss=2.535, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.267e-04, train_time=0.882
[alab02] 2024-08-29 01:11:46,819 (trainer:720) INFO: 41epoch:train:6801-7000batch: iter_time=2.508e-04, forward_time=0.137, uma_reduction=0.210, text_vs_uma=0.459, loss_ctc=4.899, loss=2.449, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.267e-04, train_time=0.897
[alab02] 2024-08-29 01:13:02,980 (trainer:338) INFO: 41epoch results: [train] iter_time=3.793e-04, forward_time=0.140, uma_reduction=0.206, text_vs_uma=0.467, loss_ctc=5.197, loss=2.599, backward_time=0.187, optim_step_time=0.041, optim0_lr0=2.280e-04, train_time=0.912, time=54 minutes and 11.18 seconds, total_count=292166, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.200, text_vs_uma=0.541, loss_ctc=3.717, cer_ctc=0.107, cer=0.107, loss=3.717, time=6.22 seconds, total_count=1066, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.12 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 01:13:08,033 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 01:13:08,034 (trainer:272) INFO: 42/150epoch started. Estimated time to finish: 4 days, 5 hours and 45 minutes
[alab02] 2024-08-29 01:14:38,842 (trainer:720) INFO: 42epoch:train:1-200batch: iter_time=0.002, forward_time=0.136, uma_reduction=0.209, text_vs_uma=0.463, loss_ctc=5.177, loss=2.589, backward_time=0.189, optim_step_time=0.035, optim0_lr0=2.265e-04, train_time=0.908
[alab02] 2024-08-29 01:16:06,824 (trainer:720) INFO: 42epoch:train:201-400batch: iter_time=2.255e-04, forward_time=0.134, uma_reduction=0.212, text_vs_uma=0.456, loss_ctc=4.979, loss=2.489, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.265e-04, train_time=0.880
[alab02] 2024-08-29 01:17:33,689 (trainer:720) INFO: 42epoch:train:401-600batch: iter_time=2.242e-04, forward_time=0.131, uma_reduction=0.210, text_vs_uma=0.458, loss_ctc=5.018, loss=2.509, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.264e-04, train_time=0.868
[alab02] 2024-08-29 01:19:03,599 (trainer:720) INFO: 42epoch:train:601-800batch: iter_time=2.464e-04, forward_time=0.136, uma_reduction=0.209, text_vs_uma=0.458, loss_ctc=5.008, loss=2.504, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.263e-04, train_time=0.899
[alab02] 2024-08-29 01:20:36,141 (trainer:720) INFO: 42epoch:train:801-1000batch: iter_time=2.273e-04, forward_time=0.140, uma_reduction=0.216, text_vs_uma=0.440, loss_ctc=4.692, loss=2.346, backward_time=0.196, optim_step_time=0.036, optim0_lr0=2.262e-04, train_time=0.925
[alab02] 2024-08-29 01:22:02,722 (trainer:720) INFO: 42epoch:train:1001-1200batch: iter_time=2.014e-04, forward_time=0.130, uma_reduction=0.209, text_vs_uma=0.461, loss_ctc=5.333, loss=2.667, backward_time=0.175, optim_step_time=0.034, optim0_lr0=2.262e-04, train_time=0.866
[alab02] 2024-08-29 01:23:31,679 (trainer:720) INFO: 42epoch:train:1201-1400batch: iter_time=2.228e-04, forward_time=0.135, uma_reduction=0.212, text_vs_uma=0.451, loss_ctc=4.875, loss=2.437, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.261e-04, train_time=0.889
[alab02] 2024-08-29 01:24:59,571 (trainer:720) INFO: 42epoch:train:1401-1600batch: iter_time=2.048e-04, forward_time=0.133, uma_reduction=0.208, text_vs_uma=0.454, loss_ctc=4.900, loss=2.450, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.260e-04, train_time=0.879
[alab02] 2024-08-29 01:26:26,849 (trainer:720) INFO: 42epoch:train:1601-1800batch: iter_time=1.931e-04, forward_time=0.133, uma_reduction=0.211, text_vs_uma=0.459, loss_ctc=4.915, loss=2.458, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.259e-04, train_time=0.873
[alab02] 2024-08-29 01:27:56,865 (trainer:720) INFO: 42epoch:train:1801-2000batch: iter_time=2.008e-04, forward_time=0.136, uma_reduction=0.214, text_vs_uma=0.451, loss_ctc=5.330, loss=2.665, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.259e-04, train_time=0.900
[alab02] 2024-08-29 01:29:24,535 (trainer:720) INFO: 42epoch:train:2001-2200batch: iter_time=1.980e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.448, loss_ctc=4.778, loss=2.389, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.258e-04, train_time=0.876
[alab02] 2024-08-29 01:30:52,908 (trainer:720) INFO: 42epoch:train:2201-2400batch: iter_time=2.266e-04, forward_time=0.134, uma_reduction=0.212, text_vs_uma=0.444, loss_ctc=4.845, loss=2.423, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.257e-04, train_time=0.884
[alab02] 2024-08-29 01:32:20,510 (trainer:720) INFO: 42epoch:train:2401-2600batch: iter_time=1.988e-04, forward_time=0.132, uma_reduction=0.213, text_vs_uma=0.448, loss_ctc=5.094, loss=2.547, backward_time=0.177, optim_step_time=0.035, optim0_lr0=2.256e-04, train_time=0.876
[alab02] 2024-08-29 01:33:48,268 (trainer:720) INFO: 42epoch:train:2601-2800batch: iter_time=2.376e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.434, loss_ctc=4.726, loss=2.363, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.255e-04, train_time=0.877
[alab02] 2024-08-29 01:35:16,252 (trainer:720) INFO: 42epoch:train:2801-3000batch: iter_time=1.905e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.430, loss_ctc=4.698, loss=2.349, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.255e-04, train_time=0.880
[alab02] 2024-08-29 01:36:42,864 (trainer:720) INFO: 42epoch:train:3001-3200batch: iter_time=1.914e-04, forward_time=0.131, uma_reduction=0.213, text_vs_uma=0.453, loss_ctc=5.152, loss=2.576, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.254e-04, train_time=0.866
[alab02] 2024-08-29 01:38:12,578 (trainer:720) INFO: 42epoch:train:3201-3400batch: iter_time=2.135e-04, forward_time=0.137, uma_reduction=0.212, text_vs_uma=0.443, loss_ctc=4.615, loss=2.307, backward_time=0.190, optim_step_time=0.037, optim0_lr0=2.253e-04, train_time=0.897
[alab02] 2024-08-29 01:39:41,109 (trainer:720) INFO: 42epoch:train:3401-3600batch: iter_time=2.092e-04, forward_time=0.135, uma_reduction=0.217, text_vs_uma=0.447, loss_ctc=5.044, loss=2.522, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.252e-04, train_time=0.885
[alab02] 2024-08-29 01:41:08,221 (trainer:720) INFO: 42epoch:train:3601-3800batch: iter_time=1.986e-04, forward_time=0.132, uma_reduction=0.218, text_vs_uma=0.452, loss_ctc=5.235, loss=2.617, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.252e-04, train_time=0.871
[alab02] 2024-08-29 01:42:36,582 (trainer:720) INFO: 42epoch:train:3801-4000batch: iter_time=1.849e-04, forward_time=0.135, uma_reduction=0.212, text_vs_uma=0.451, loss_ctc=4.884, loss=2.442, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.251e-04, train_time=0.883
[alab02] 2024-08-29 01:44:03,349 (trainer:720) INFO: 42epoch:train:4001-4200batch: iter_time=1.855e-04, forward_time=0.132, uma_reduction=0.211, text_vs_uma=0.450, loss_ctc=5.107, loss=2.553, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.250e-04, train_time=0.867
[alab02] 2024-08-29 01:45:32,932 (trainer:720) INFO: 42epoch:train:4201-4400batch: iter_time=1.955e-04, forward_time=0.136, uma_reduction=0.213, text_vs_uma=0.446, loss_ctc=5.087, loss=2.544, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.249e-04, train_time=0.896
[alab02] 2024-08-29 01:47:00,801 (trainer:720) INFO: 42epoch:train:4401-4600batch: iter_time=2.214e-04, forward_time=0.134, uma_reduction=0.207, text_vs_uma=0.465, loss_ctc=5.088, loss=2.544, backward_time=0.181, optim_step_time=0.036, optim0_lr0=2.249e-04, train_time=0.878
[alab02] 2024-08-29 01:48:28,164 (trainer:720) INFO: 42epoch:train:4601-4800batch: iter_time=2.027e-04, forward_time=0.134, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=5.528, loss=2.764, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.248e-04, train_time=0.873
[alab02] 2024-08-29 01:49:57,216 (trainer:720) INFO: 42epoch:train:4801-5000batch: iter_time=2.187e-04, forward_time=0.136, uma_reduction=0.208, text_vs_uma=0.456, loss_ctc=5.013, loss=2.506, backward_time=0.184, optim_step_time=0.037, optim0_lr0=2.247e-04, train_time=0.890
[alab02] 2024-08-29 01:51:26,331 (trainer:720) INFO: 42epoch:train:5001-5200batch: iter_time=2.568e-04, forward_time=0.136, uma_reduction=0.213, text_vs_uma=0.459, loss_ctc=5.309, loss=2.655, backward_time=0.179, optim_step_time=0.038, optim0_lr0=2.246e-04, train_time=0.891
[alab02] 2024-08-29 01:52:56,335 (trainer:720) INFO: 42epoch:train:5201-5400batch: iter_time=2.165e-04, forward_time=0.137, uma_reduction=0.208, text_vs_uma=0.467, loss_ctc=5.396, loss=2.698, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.246e-04, train_time=0.900
[alab02] 2024-08-29 01:54:25,060 (trainer:720) INFO: 42epoch:train:5401-5600batch: iter_time=2.062e-04, forward_time=0.135, uma_reduction=0.208, text_vs_uma=0.450, loss_ctc=5.213, loss=2.607, backward_time=0.178, optim_step_time=0.037, optim0_lr0=2.245e-04, train_time=0.887
[alab02] 2024-08-29 01:55:53,931 (trainer:720) INFO: 42epoch:train:5601-5800batch: iter_time=2.043e-04, forward_time=0.136, uma_reduction=0.208, text_vs_uma=0.467, loss_ctc=5.637, loss=2.818, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.244e-04, train_time=0.888
[alab02] 2024-08-29 01:57:20,777 (trainer:720) INFO: 42epoch:train:5801-6000batch: iter_time=2.047e-04, forward_time=0.132, uma_reduction=0.213, text_vs_uma=0.445, loss_ctc=4.603, loss=2.302, backward_time=0.180, optim_step_time=0.037, optim0_lr0=2.243e-04, train_time=0.868
[alab02] 2024-08-29 01:58:51,424 (trainer:720) INFO: 42epoch:train:6001-6200batch: iter_time=2.174e-04, forward_time=0.137, uma_reduction=0.204, text_vs_uma=0.477, loss_ctc=5.421, loss=2.711, backward_time=0.190, optim_step_time=0.036, optim0_lr0=2.243e-04, train_time=0.906
[alab02] 2024-08-29 02:00:19,958 (trainer:720) INFO: 42epoch:train:6201-6400batch: iter_time=2.540e-04, forward_time=0.135, uma_reduction=0.206, text_vs_uma=0.461, loss_ctc=5.247, loss=2.624, backward_time=0.179, optim_step_time=0.037, optim0_lr0=2.242e-04, train_time=0.885
[alab02] 2024-08-29 02:01:51,271 (trainer:720) INFO: 42epoch:train:6401-6600batch: iter_time=3.023e-04, forward_time=0.139, uma_reduction=0.206, text_vs_uma=0.463, loss_ctc=5.270, loss=2.635, backward_time=0.190, optim_step_time=0.036, optim0_lr0=2.241e-04, train_time=0.913
[alab02] 2024-08-29 02:03:21,227 (trainer:720) INFO: 42epoch:train:6601-6800batch: iter_time=3.355e-04, forward_time=0.138, uma_reduction=0.202, text_vs_uma=0.469, loss_ctc=5.066, loss=2.533, backward_time=0.188, optim_step_time=0.037, optim0_lr0=2.240e-04, train_time=0.899
[alab02] 2024-08-29 02:04:49,335 (trainer:720) INFO: 42epoch:train:6801-7000batch: iter_time=2.398e-04, forward_time=0.133, uma_reduction=0.199, text_vs_uma=0.484, loss_ctc=5.147, loss=2.573, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.240e-04, train_time=0.881
[alab02] 2024-08-29 02:06:07,918 (trainer:338) INFO: 42epoch results: [train] iter_time=2.741e-04, forward_time=0.135, uma_reduction=0.210, text_vs_uma=0.456, loss_ctc=5.059, loss=2.529, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.252e-04, train_time=0.886, time=52 minutes and 38.78 seconds, total_count=299292, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.184, text_vs_uma=0.590, loss_ctc=3.944, cer_ctc=0.098, cer=0.098, loss=3.944, time=6.06 seconds, total_count=1092, gpu_max_cached_mem_GB=35.906, [att_plot] time=15.04 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 02:06:13,384 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 02:06:13,449 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/31epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/41epoch.pth
[alab02] 2024-08-29 02:06:13,449 (trainer:272) INFO: 43/150epoch started. Estimated time to finish: 4 days, 4 hours and 42 minutes
[alab02] 2024-08-29 02:07:42,044 (trainer:720) INFO: 43epoch:train:1-200batch: iter_time=0.002, forward_time=0.133, uma_reduction=0.206, text_vs_uma=0.458, loss_ctc=5.037, loss=2.518, backward_time=0.181, optim_step_time=0.037, optim0_lr0=2.238e-04, train_time=0.885
[alab02] 2024-08-29 02:09:12,234 (trainer:720) INFO: 43epoch:train:201-400batch: iter_time=2.242e-04, forward_time=0.136, uma_reduction=0.210, text_vs_uma=0.463, loss_ctc=5.279, loss=2.640, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.238e-04, train_time=0.902
[alab02] 2024-08-29 02:10:39,138 (trainer:720) INFO: 43epoch:train:401-600batch: iter_time=2.204e-04, forward_time=0.132, uma_reduction=0.210, text_vs_uma=0.446, loss_ctc=4.603, loss=2.301, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.237e-04, train_time=0.869
[alab02] 2024-08-29 02:12:07,428 (trainer:720) INFO: 43epoch:train:601-800batch: iter_time=2.001e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.457, loss_ctc=5.051, loss=2.525, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.236e-04, train_time=0.883
[alab02] 2024-08-29 02:13:35,073 (trainer:720) INFO: 43epoch:train:801-1000batch: iter_time=2.075e-04, forward_time=0.133, uma_reduction=0.209, text_vs_uma=0.455, loss_ctc=4.934, loss=2.467, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.235e-04, train_time=0.876
[alab02] 2024-08-29 02:15:04,044 (trainer:720) INFO: 43epoch:train:1001-1200batch: iter_time=2.173e-04, forward_time=0.134, uma_reduction=0.208, text_vs_uma=0.464, loss_ctc=5.486, loss=2.743, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.235e-04, train_time=0.889
[alab02] 2024-08-29 02:16:33,505 (trainer:720) INFO: 43epoch:train:1201-1400batch: iter_time=2.028e-04, forward_time=0.135, uma_reduction=0.208, text_vs_uma=0.453, loss_ctc=4.835, loss=2.418, backward_time=0.189, optim_step_time=0.034, optim0_lr0=2.234e-04, train_time=0.894
[alab02] 2024-08-29 02:18:02,181 (trainer:720) INFO: 43epoch:train:1401-1600batch: iter_time=1.963e-04, forward_time=0.134, uma_reduction=0.206, text_vs_uma=0.467, loss_ctc=5.205, loss=2.603, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.233e-04, train_time=0.886
[alab02] 2024-08-29 02:19:31,122 (trainer:720) INFO: 43epoch:train:1601-1800batch: iter_time=2.002e-04, forward_time=0.134, uma_reduction=0.205, text_vs_uma=0.464, loss_ctc=5.281, loss=2.641, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.232e-04, train_time=0.889
[alab02] 2024-08-29 02:20:57,571 (trainer:720) INFO: 43epoch:train:1801-2000batch: iter_time=1.961e-04, forward_time=0.130, uma_reduction=0.213, text_vs_uma=0.452, loss_ctc=4.806, loss=2.403, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.232e-04, train_time=0.864
[alab02] 2024-08-29 02:22:26,311 (trainer:720) INFO: 43epoch:train:2001-2200batch: iter_time=2.440e-04, forward_time=0.133, uma_reduction=0.211, text_vs_uma=0.445, loss_ctc=4.919, loss=2.459, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.231e-04, train_time=0.887
[alab02] 2024-08-29 02:23:53,788 (trainer:720) INFO: 43epoch:train:2201-2400batch: iter_time=1.968e-04, forward_time=0.131, uma_reduction=0.215, text_vs_uma=0.451, loss_ctc=5.067, loss=2.534, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.230e-04, train_time=0.874
[alab02] 2024-08-29 02:25:22,236 (trainer:720) INFO: 43epoch:train:2401-2600batch: iter_time=2.103e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.432, loss_ctc=5.117, loss=2.559, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.229e-04, train_time=0.884
[alab02] 2024-08-29 02:26:52,144 (trainer:720) INFO: 43epoch:train:2601-2800batch: iter_time=2.115e-04, forward_time=0.136, uma_reduction=0.214, text_vs_uma=0.449, loss_ctc=4.936, loss=2.468, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.229e-04, train_time=0.899
[alab02] 2024-08-29 02:28:20,863 (trainer:720) INFO: 43epoch:train:2801-3000batch: iter_time=2.097e-04, forward_time=0.134, uma_reduction=0.215, text_vs_uma=0.448, loss_ctc=5.136, loss=2.568, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.228e-04, train_time=0.887
[alab02] 2024-08-29 02:29:49,608 (trainer:720) INFO: 43epoch:train:3001-3200batch: iter_time=1.970e-04, forward_time=0.133, uma_reduction=0.217, text_vs_uma=0.445, loss_ctc=4.952, loss=2.476, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.227e-04, train_time=0.887
[alab02] 2024-08-29 02:31:16,458 (trainer:720) INFO: 43epoch:train:3201-3400batch: iter_time=1.940e-04, forward_time=0.130, uma_reduction=0.214, text_vs_uma=0.449, loss_ctc=5.357, loss=2.678, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.226e-04, train_time=0.868
[alab02] 2024-08-29 02:32:45,703 (trainer:720) INFO: 43epoch:train:3401-3600batch: iter_time=1.919e-04, forward_time=0.135, uma_reduction=0.223, text_vs_uma=0.440, loss_ctc=5.272, loss=2.636, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.226e-04, train_time=0.892
[alab02] 2024-08-29 02:34:13,142 (trainer:720) INFO: 43epoch:train:3601-3800batch: iter_time=2.147e-04, forward_time=0.132, uma_reduction=0.219, text_vs_uma=0.428, loss_ctc=4.814, loss=2.407, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.225e-04, train_time=0.874
[alab02] 2024-08-29 02:35:39,583 (trainer:720) INFO: 43epoch:train:3801-4000batch: iter_time=2.137e-04, forward_time=0.129, uma_reduction=0.222, text_vs_uma=0.424, loss_ctc=5.076, loss=2.538, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.224e-04, train_time=0.864
[alab02] 2024-08-29 02:37:06,780 (trainer:720) INFO: 43epoch:train:4001-4200batch: iter_time=2.444e-04, forward_time=0.131, uma_reduction=0.217, text_vs_uma=0.433, loss_ctc=4.651, loss=2.326, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.224e-04, train_time=0.872
[alab02] 2024-08-29 02:38:34,829 (trainer:720) INFO: 43epoch:train:4201-4400batch: iter_time=1.908e-04, forward_time=0.132, uma_reduction=0.221, text_vs_uma=0.432, loss_ctc=4.830, loss=2.415, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.223e-04, train_time=0.880
[alab02] 2024-08-29 02:40:03,506 (trainer:720) INFO: 43epoch:train:4401-4600batch: iter_time=1.801e-04, forward_time=0.135, uma_reduction=0.222, text_vs_uma=0.426, loss_ctc=4.630, loss=2.315, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.222e-04, train_time=0.887
[alab02] 2024-08-29 02:41:31,459 (trainer:720) INFO: 43epoch:train:4601-4800batch: iter_time=1.774e-04, forward_time=0.132, uma_reduction=0.221, text_vs_uma=0.426, loss_ctc=4.745, loss=2.373, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.221e-04, train_time=0.879
[alab02] 2024-08-29 02:42:59,416 (trainer:720) INFO: 43epoch:train:4801-5000batch: iter_time=1.781e-04, forward_time=0.131, uma_reduction=0.216, text_vs_uma=0.449, loss_ctc=5.127, loss=2.563, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.221e-04, train_time=0.879
[alab02] 2024-08-29 02:44:27,200 (trainer:720) INFO: 43epoch:train:5001-5200batch: iter_time=1.893e-04, forward_time=0.132, uma_reduction=0.221, text_vs_uma=0.432, loss_ctc=4.858, loss=2.429, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.220e-04, train_time=0.878
[alab02] 2024-08-29 02:45:55,795 (trainer:720) INFO: 43epoch:train:5201-5400batch: iter_time=1.858e-04, forward_time=0.133, uma_reduction=0.222, text_vs_uma=0.437, loss_ctc=5.046, loss=2.523, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.219e-04, train_time=0.886
[alab02] 2024-08-29 02:47:22,703 (trainer:720) INFO: 43epoch:train:5401-5600batch: iter_time=1.963e-04, forward_time=0.131, uma_reduction=0.215, text_vs_uma=0.452, loss_ctc=5.183, loss=2.592, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.218e-04, train_time=0.869
[alab02] 2024-08-29 02:48:50,871 (trainer:720) INFO: 43epoch:train:5601-5800batch: iter_time=2.021e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.449, loss_ctc=5.021, loss=2.510, backward_time=0.181, optim_step_time=0.037, optim0_lr0=2.218e-04, train_time=0.881
[alab02] 2024-08-29 02:50:19,090 (trainer:720) INFO: 43epoch:train:5801-6000batch: iter_time=1.870e-04, forward_time=0.132, uma_reduction=0.217, text_vs_uma=0.450, loss_ctc=4.957, loss=2.479, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.217e-04, train_time=0.882
[alab02] 2024-08-29 02:51:48,177 (trainer:720) INFO: 43epoch:train:6001-6200batch: iter_time=1.971e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.447, loss_ctc=5.164, loss=2.582, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.216e-04, train_time=0.891
[alab02] 2024-08-29 02:53:15,730 (trainer:720) INFO: 43epoch:train:6201-6400batch: iter_time=1.889e-04, forward_time=0.131, uma_reduction=0.220, text_vs_uma=0.434, loss_ctc=4.951, loss=2.475, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.216e-04, train_time=0.875
[alab02] 2024-08-29 02:54:43,769 (trainer:720) INFO: 43epoch:train:6401-6600batch: iter_time=2.334e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.445, loss_ctc=4.835, loss=2.417, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.215e-04, train_time=0.880
[alab02] 2024-08-29 02:56:12,450 (trainer:720) INFO: 43epoch:train:6601-6800batch: iter_time=2.010e-04, forward_time=0.133, uma_reduction=0.209, text_vs_uma=0.454, loss_ctc=5.033, loss=2.517, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.214e-04, train_time=0.887
[alab02] 2024-08-29 02:57:41,171 (trainer:720) INFO: 43epoch:train:6801-7000batch: iter_time=1.944e-04, forward_time=0.134, uma_reduction=0.210, text_vs_uma=0.453, loss_ctc=5.292, loss=2.646, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.213e-04, train_time=0.887
[alab02] 2024-08-29 02:58:58,583 (trainer:338) INFO: 43epoch results: [train] iter_time=2.548e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.446, loss_ctc=5.016, loss=2.508, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.226e-04, train_time=0.882, time=52 minutes and 23.08 seconds, total_count=306418, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.204, text_vs_uma=0.531, loss_ctc=3.689, cer_ctc=0.099, cer=0.099, loss=3.689, time=6.27 seconds, total_count=1118, gpu_max_cached_mem_GB=35.906, [att_plot] time=15.78 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 02:59:04,333 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 02:59:04,340 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/33epoch.pth
[alab02] 2024-08-29 02:59:04,340 (trainer:272) INFO: 44/150epoch started. Estimated time to finish: 4 days, 3 hours and 38 minutes
[alab02] 2024-08-29 03:00:32,723 (trainer:720) INFO: 44epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.212, text_vs_uma=0.470, loss_ctc=5.489, loss=2.744, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.212e-04, train_time=0.883
[alab02] 2024-08-29 03:02:00,326 (trainer:720) INFO: 44epoch:train:201-400batch: iter_time=3.120e-04, forward_time=0.132, uma_reduction=0.214, text_vs_uma=0.450, loss_ctc=5.010, loss=2.505, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.211e-04, train_time=0.876
[alab02] 2024-08-29 03:03:28,112 (trainer:720) INFO: 44epoch:train:401-600batch: iter_time=2.330e-04, forward_time=0.131, uma_reduction=0.216, text_vs_uma=0.448, loss_ctc=5.319, loss=2.660, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.211e-04, train_time=0.878
[alab02] 2024-08-29 03:04:56,124 (trainer:720) INFO: 44epoch:train:601-800batch: iter_time=2.273e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.453, loss_ctc=5.415, loss=2.708, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.210e-04, train_time=0.880
[alab02] 2024-08-29 03:06:25,050 (trainer:720) INFO: 44epoch:train:801-1000batch: iter_time=2.088e-04, forward_time=0.134, uma_reduction=0.216, text_vs_uma=0.440, loss_ctc=4.982, loss=2.491, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.209e-04, train_time=0.889
[alab02] 2024-08-29 03:07:53,221 (trainer:720) INFO: 44epoch:train:1001-1200batch: iter_time=2.283e-04, forward_time=0.133, uma_reduction=0.210, text_vs_uma=0.450, loss_ctc=5.242, loss=2.621, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.209e-04, train_time=0.882
[alab02] 2024-08-29 03:09:21,759 (trainer:720) INFO: 44epoch:train:1201-1400batch: iter_time=1.872e-04, forward_time=0.132, uma_reduction=0.205, text_vs_uma=0.467, loss_ctc=5.496, loss=2.748, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.208e-04, train_time=0.885
[alab02] 2024-08-29 03:10:49,158 (trainer:720) INFO: 44epoch:train:1401-1600batch: iter_time=1.761e-04, forward_time=0.131, uma_reduction=0.207, text_vs_uma=0.459, loss_ctc=5.097, loss=2.548, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.207e-04, train_time=0.874
[alab02] 2024-08-29 03:12:14,331 (trainer:720) INFO: 44epoch:train:1601-1800batch: iter_time=1.784e-04, forward_time=0.127, uma_reduction=0.210, text_vs_uma=0.470, loss_ctc=5.279, loss=2.640, backward_time=0.177, optim_step_time=0.033, optim0_lr0=2.206e-04, train_time=0.851
[alab02] 2024-08-29 03:13:41,036 (trainer:720) INFO: 44epoch:train:1801-2000batch: iter_time=1.914e-04, forward_time=0.129, uma_reduction=0.216, text_vs_uma=0.456, loss_ctc=5.501, loss=2.750, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.206e-04, train_time=0.867
[alab02] 2024-08-29 03:15:07,572 (trainer:720) INFO: 44epoch:train:2001-2200batch: iter_time=1.859e-04, forward_time=0.129, uma_reduction=0.215, text_vs_uma=0.440, loss_ctc=4.795, loss=2.397, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.205e-04, train_time=0.865
[alab02] 2024-08-29 03:16:36,271 (trainer:720) INFO: 44epoch:train:2201-2400batch: iter_time=1.914e-04, forward_time=0.132, uma_reduction=0.212, text_vs_uma=0.460, loss_ctc=5.588, loss=2.794, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.204e-04, train_time=0.887
[alab02] 2024-08-29 03:18:03,627 (trainer:720) INFO: 44epoch:train:2401-2600batch: iter_time=1.828e-04, forward_time=0.130, uma_reduction=0.217, text_vs_uma=0.440, loss_ctc=4.996, loss=2.498, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.204e-04, train_time=0.873
[alab02] 2024-08-29 03:19:31,262 (trainer:720) INFO: 44epoch:train:2601-2800batch: iter_time=2.117e-04, forward_time=0.131, uma_reduction=0.207, text_vs_uma=0.465, loss_ctc=5.283, loss=2.641, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.203e-04, train_time=0.876
[alab02] 2024-08-29 03:20:59,846 (trainer:720) INFO: 44epoch:train:2801-3000batch: iter_time=1.805e-04, forward_time=0.133, uma_reduction=0.205, text_vs_uma=0.473, loss_ctc=5.695, loss=2.848, backward_time=0.181, optim_step_time=0.032, optim0_lr0=2.202e-04, train_time=0.886
[alab02] 2024-08-29 03:22:27,430 (trainer:720) INFO: 44epoch:train:3001-3200batch: iter_time=1.957e-04, forward_time=0.132, uma_reduction=0.211, text_vs_uma=0.441, loss_ctc=4.797, loss=2.399, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.201e-04, train_time=0.876
[alab02] 2024-08-29 03:23:53,573 (trainer:720) INFO: 44epoch:train:3201-3400batch: iter_time=1.792e-04, forward_time=0.128, uma_reduction=0.203, text_vs_uma=0.466, loss_ctc=5.062, loss=2.531, backward_time=0.179, optim_step_time=0.032, optim0_lr0=2.201e-04, train_time=0.861
[alab02] 2024-08-29 03:25:20,624 (trainer:720) INFO: 44epoch:train:3401-3600batch: iter_time=1.845e-04, forward_time=0.129, uma_reduction=0.206, text_vs_uma=0.462, loss_ctc=5.383, loss=2.691, backward_time=0.180, optim_step_time=0.033, optim0_lr0=2.200e-04, train_time=0.870
[alab02] 2024-08-29 03:26:48,645 (trainer:720) INFO: 44epoch:train:3601-3800batch: iter_time=2.745e-04, forward_time=0.132, uma_reduction=0.211, text_vs_uma=0.450, loss_ctc=4.774, loss=2.387, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.199e-04, train_time=0.880
[alab02] 2024-08-29 03:28:16,707 (trainer:720) INFO: 44epoch:train:3801-4000batch: iter_time=1.931e-04, forward_time=0.132, uma_reduction=0.207, text_vs_uma=0.460, loss_ctc=5.121, loss=2.561, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.199e-04, train_time=0.880
[alab02] 2024-08-29 03:29:47,319 (trainer:720) INFO: 44epoch:train:4001-4200batch: iter_time=2.363e-04, forward_time=0.136, uma_reduction=0.209, text_vs_uma=0.452, loss_ctc=5.058, loss=2.529, backward_time=0.192, optim_step_time=0.035, optim0_lr0=2.198e-04, train_time=0.906
[alab02] 2024-08-29 03:31:16,193 (trainer:720) INFO: 44epoch:train:4201-4400batch: iter_time=1.850e-04, forward_time=0.133, uma_reduction=0.209, text_vs_uma=0.457, loss_ctc=5.183, loss=2.592, backward_time=0.186, optim_step_time=0.034, optim0_lr0=2.197e-04, train_time=0.888
[alab02] 2024-08-29 03:32:46,354 (trainer:720) INFO: 44epoch:train:4401-4600batch: iter_time=2.091e-04, forward_time=0.136, uma_reduction=0.209, text_vs_uma=0.462, loss_ctc=4.763, loss=2.382, backward_time=0.191, optim_step_time=0.036, optim0_lr0=2.196e-04, train_time=0.901
[alab02] 2024-08-29 03:34:13,598 (trainer:720) INFO: 44epoch:train:4601-4800batch: iter_time=2.021e-04, forward_time=0.131, uma_reduction=0.211, text_vs_uma=0.462, loss_ctc=5.077, loss=2.538, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.196e-04, train_time=0.872
[alab02] 2024-08-29 03:35:40,505 (trainer:720) INFO: 44epoch:train:4801-5000batch: iter_time=1.965e-04, forward_time=0.131, uma_reduction=0.212, text_vs_uma=0.449, loss_ctc=5.007, loss=2.504, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.195e-04, train_time=0.869
[alab02] 2024-08-29 03:37:09,122 (trainer:720) INFO: 44epoch:train:5001-5200batch: iter_time=1.996e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.446, loss_ctc=5.163, loss=2.581, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.194e-04, train_time=0.886
[alab02] 2024-08-29 03:38:36,057 (trainer:720) INFO: 44epoch:train:5201-5400batch: iter_time=1.822e-04, forward_time=0.130, uma_reduction=0.216, text_vs_uma=0.446, loss_ctc=4.853, loss=2.426, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.194e-04, train_time=0.869
[alab02] 2024-08-29 03:40:05,952 (trainer:720) INFO: 44epoch:train:5401-5600batch: iter_time=1.894e-04, forward_time=0.135, uma_reduction=0.213, text_vs_uma=0.463, loss_ctc=5.402, loss=2.701, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.193e-04, train_time=0.899
[alab02] 2024-08-29 03:41:31,753 (trainer:720) INFO: 44epoch:train:5601-5800batch: iter_time=1.822e-04, forward_time=0.129, uma_reduction=0.218, text_vs_uma=0.442, loss_ctc=4.667, loss=2.334, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.192e-04, train_time=0.858
[alab02] 2024-08-29 03:43:00,182 (trainer:720) INFO: 44epoch:train:5801-6000batch: iter_time=1.831e-04, forward_time=0.134, uma_reduction=0.218, text_vs_uma=0.438, loss_ctc=4.775, loss=2.387, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.192e-04, train_time=0.884
[alab02] 2024-08-29 03:44:26,936 (trainer:720) INFO: 44epoch:train:6001-6200batch: iter_time=1.839e-04, forward_time=0.131, uma_reduction=0.222, text_vs_uma=0.441, loss_ctc=4.963, loss=2.482, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.191e-04, train_time=0.867
[alab02] 2024-08-29 03:45:54,408 (trainer:720) INFO: 44epoch:train:6201-6400batch: iter_time=1.914e-04, forward_time=0.132, uma_reduction=0.212, text_vs_uma=0.446, loss_ctc=4.922, loss=2.461, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.190e-04, train_time=0.874
[alab02] 2024-08-29 03:47:23,213 (trainer:720) INFO: 44epoch:train:6401-6600batch: iter_time=2.071e-04, forward_time=0.135, uma_reduction=0.208, text_vs_uma=0.454, loss_ctc=4.890, loss=2.445, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.189e-04, train_time=0.888
[alab02] 2024-08-29 03:48:52,251 (trainer:720) INFO: 44epoch:train:6601-6800batch: iter_time=2.092e-04, forward_time=0.136, uma_reduction=0.210, text_vs_uma=0.454, loss_ctc=5.134, loss=2.567, backward_time=0.182, optim_step_time=0.037, optim0_lr0=2.189e-04, train_time=0.890
[alab02] 2024-08-29 03:50:19,918 (trainer:720) INFO: 44epoch:train:6801-7000batch: iter_time=2.128e-04, forward_time=0.134, uma_reduction=0.208, text_vs_uma=0.451, loss_ctc=4.964, loss=2.482, backward_time=0.180, optim_step_time=0.038, optim0_lr0=2.188e-04, train_time=0.876
[alab02] 2024-08-29 03:51:36,862 (trainer:338) INFO: 44epoch results: [train] iter_time=2.584e-04, forward_time=0.132, uma_reduction=0.211, text_vs_uma=0.454, loss_ctc=5.119, loss=2.560, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.200e-04, train_time=0.878, time=52 minutes and 11.35 seconds, total_count=313544, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.196, text_vs_uma=0.553, loss_ctc=3.670, cer_ctc=0.099, cer=0.099, loss=3.670, time=6.36 seconds, total_count=1144, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.81 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 03:51:42,749 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 03:51:42,756 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/29epoch.pth
[alab02] 2024-08-29 03:51:42,756 (trainer:272) INFO: 45/150epoch started. Estimated time to finish: 4 days, 2 hours and 35 minutes
[alab02] 2024-08-29 03:53:13,015 (trainer:720) INFO: 45epoch:train:1-200batch: iter_time=0.003, forward_time=0.136, uma_reduction=0.211, text_vs_uma=0.459, loss_ctc=4.877, loss=2.439, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.187e-04, train_time=0.902
[alab02] 2024-08-29 03:54:42,987 (trainer:720) INFO: 45epoch:train:201-400batch: iter_time=2.326e-04, forward_time=0.138, uma_reduction=0.217, text_vs_uma=0.445, loss_ctc=4.987, loss=2.493, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.186e-04, train_time=0.900
[alab02] 2024-08-29 03:56:11,048 (trainer:720) INFO: 45epoch:train:401-600batch: iter_time=2.292e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.447, loss_ctc=4.809, loss=2.404, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.185e-04, train_time=0.880
[alab02] 2024-08-29 03:57:39,104 (trainer:720) INFO: 45epoch:train:601-800batch: iter_time=2.235e-04, forward_time=0.134, uma_reduction=0.212, text_vs_uma=0.454, loss_ctc=5.006, loss=2.503, backward_time=0.180, optim_step_time=0.037, optim0_lr0=2.185e-04, train_time=0.880
[alab02] 2024-08-29 03:59:07,870 (trainer:720) INFO: 45epoch:train:801-1000batch: iter_time=2.407e-04, forward_time=0.135, uma_reduction=0.209, text_vs_uma=0.439, loss_ctc=4.760, loss=2.380, backward_time=0.183, optim_step_time=0.037, optim0_lr0=2.184e-04, train_time=0.887
[alab02] 2024-08-29 04:00:38,500 (trainer:720) INFO: 45epoch:train:1001-1200batch: iter_time=2.099e-04, forward_time=0.137, uma_reduction=0.216, text_vs_uma=0.438, loss_ctc=4.638, loss=2.319, backward_time=0.190, optim_step_time=0.035, optim0_lr0=2.183e-04, train_time=0.906
[alab02] 2024-08-29 04:02:06,348 (trainer:720) INFO: 45epoch:train:1201-1400batch: iter_time=2.118e-04, forward_time=0.133, uma_reduction=0.220, text_vs_uma=0.445, loss_ctc=5.010, loss=2.505, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.183e-04, train_time=0.878
[alab02] 2024-08-29 04:03:37,703 (trainer:720) INFO: 45epoch:train:1401-1600batch: iter_time=2.261e-04, forward_time=0.137, uma_reduction=0.216, text_vs_uma=0.445, loss_ctc=5.175, loss=2.588, backward_time=0.190, optim_step_time=0.035, optim0_lr0=2.182e-04, train_time=0.913
[alab02] 2024-08-29 04:05:04,115 (trainer:720) INFO: 45epoch:train:1601-1800batch: iter_time=2.121e-04, forward_time=0.131, uma_reduction=0.211, text_vs_uma=0.452, loss_ctc=5.321, loss=2.660, backward_time=0.173, optim_step_time=0.035, optim0_lr0=2.181e-04, train_time=0.864
[alab02] 2024-08-29 04:06:32,224 (trainer:720) INFO: 45epoch:train:1801-2000batch: iter_time=2.153e-04, forward_time=0.134, uma_reduction=0.213, text_vs_uma=0.461, loss_ctc=5.205, loss=2.603, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.181e-04, train_time=0.881
[alab02] 2024-08-29 04:08:03,435 (trainer:720) INFO: 45epoch:train:2001-2200batch: iter_time=2.641e-04, forward_time=0.138, uma_reduction=0.209, text_vs_uma=0.450, loss_ctc=4.922, loss=2.461, backward_time=0.189, optim_step_time=0.036, optim0_lr0=2.180e-04, train_time=0.912
[alab02] 2024-08-29 04:09:32,593 (trainer:720) INFO: 45epoch:train:2201-2400batch: iter_time=1.969e-04, forward_time=0.135, uma_reduction=0.210, text_vs_uma=0.451, loss_ctc=4.785, loss=2.392, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.179e-04, train_time=0.891
[alab02] 2024-08-29 04:10:59,984 (trainer:720) INFO: 45epoch:train:2401-2600batch: iter_time=2.015e-04, forward_time=0.133, uma_reduction=0.212, text_vs_uma=0.454, loss_ctc=4.990, loss=2.495, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.179e-04, train_time=0.874
[alab02] 2024-08-29 04:12:28,921 (trainer:720) INFO: 45epoch:train:2601-2800batch: iter_time=1.925e-04, forward_time=0.135, uma_reduction=0.214, text_vs_uma=0.449, loss_ctc=4.759, loss=2.380, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.178e-04, train_time=0.889
[alab02] 2024-08-29 04:13:56,416 (trainer:720) INFO: 45epoch:train:2801-3000batch: iter_time=1.900e-04, forward_time=0.132, uma_reduction=0.217, text_vs_uma=0.441, loss_ctc=5.008, loss=2.504, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.177e-04, train_time=0.875
[alab02] 2024-08-29 04:15:23,146 (trainer:720) INFO: 45epoch:train:3001-3200batch: iter_time=2.035e-04, forward_time=0.132, uma_reduction=0.223, text_vs_uma=0.430, loss_ctc=4.918, loss=2.459, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.176e-04, train_time=0.867
[alab02] 2024-08-29 04:16:53,317 (trainer:720) INFO: 45epoch:train:3201-3400batch: iter_time=2.106e-04, forward_time=0.137, uma_reduction=0.212, text_vs_uma=0.444, loss_ctc=4.936, loss=2.468, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.176e-04, train_time=0.901
[alab02] 2024-08-29 04:18:19,765 (trainer:720) INFO: 45epoch:train:3401-3600batch: iter_time=1.870e-04, forward_time=0.131, uma_reduction=0.216, text_vs_uma=0.445, loss_ctc=5.018, loss=2.509, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.175e-04, train_time=0.864
[alab02] 2024-08-29 04:19:47,898 (trainer:720) INFO: 45epoch:train:3601-3800batch: iter_time=1.972e-04, forward_time=0.134, uma_reduction=0.218, text_vs_uma=0.435, loss_ctc=4.765, loss=2.382, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.174e-04, train_time=0.881
[alab02] 2024-08-29 04:21:16,376 (trainer:720) INFO: 45epoch:train:3801-4000batch: iter_time=2.655e-04, forward_time=0.134, uma_reduction=0.224, text_vs_uma=0.433, loss_ctc=5.040, loss=2.520, backward_time=0.181, optim_step_time=0.036, optim0_lr0=2.174e-04, train_time=0.885
[alab02] 2024-08-29 04:22:44,932 (trainer:720) INFO: 45epoch:train:4001-4200batch: iter_time=1.919e-04, forward_time=0.135, uma_reduction=0.222, text_vs_uma=0.427, loss_ctc=4.956, loss=2.478, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.173e-04, train_time=0.885
[alab02] 2024-08-29 04:24:16,484 (trainer:720) INFO: 45epoch:train:4201-4400batch: iter_time=1.963e-04, forward_time=0.139, uma_reduction=0.222, text_vs_uma=0.434, loss_ctc=5.133, loss=2.567, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.172e-04, train_time=0.915
[alab02] 2024-08-29 04:25:45,230 (trainer:720) INFO: 45epoch:train:4401-4600batch: iter_time=1.895e-04, forward_time=0.134, uma_reduction=0.224, text_vs_uma=0.425, loss_ctc=4.967, loss=2.484, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.172e-04, train_time=0.887
[alab02] 2024-08-29 04:27:11,932 (trainer:720) INFO: 45epoch:train:4601-4800batch: iter_time=2.058e-04, forward_time=0.132, uma_reduction=0.216, text_vs_uma=0.441, loss_ctc=5.017, loss=2.508, backward_time=0.175, optim_step_time=0.036, optim0_lr0=2.171e-04, train_time=0.867
[alab02] 2024-08-29 04:28:42,002 (trainer:720) INFO: 45epoch:train:4801-5000batch: iter_time=1.965e-04, forward_time=0.136, uma_reduction=0.221, text_vs_uma=0.426, loss_ctc=5.003, loss=2.502, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.170e-04, train_time=0.900
[alab02] 2024-08-29 04:30:09,765 (trainer:720) INFO: 45epoch:train:5001-5200batch: iter_time=1.972e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.437, loss_ctc=4.674, loss=2.337, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.170e-04, train_time=0.877
[alab02] 2024-08-29 04:31:37,305 (trainer:720) INFO: 45epoch:train:5201-5400batch: iter_time=2.004e-04, forward_time=0.133, uma_reduction=0.224, text_vs_uma=0.429, loss_ctc=4.845, loss=2.422, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.169e-04, train_time=0.875
[alab02] 2024-08-29 04:33:06,791 (trainer:720) INFO: 45epoch:train:5401-5600batch: iter_time=1.925e-04, forward_time=0.136, uma_reduction=0.216, text_vs_uma=0.444, loss_ctc=5.008, loss=2.504, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.168e-04, train_time=0.895
[alab02] 2024-08-29 04:34:36,611 (trainer:720) INFO: 45epoch:train:5601-5800batch: iter_time=1.906e-04, forward_time=0.137, uma_reduction=0.209, text_vs_uma=0.456, loss_ctc=5.174, loss=2.587, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.168e-04, train_time=0.898
[alab02] 2024-08-29 04:36:04,572 (trainer:720) INFO: 45epoch:train:5801-6000batch: iter_time=1.935e-04, forward_time=0.134, uma_reduction=0.214, text_vs_uma=0.449, loss_ctc=5.058, loss=2.529, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.167e-04, train_time=0.879
[alab02] 2024-08-29 04:37:33,491 (trainer:720) INFO: 45epoch:train:6001-6200batch: iter_time=1.805e-04, forward_time=0.135, uma_reduction=0.211, text_vs_uma=0.449, loss_ctc=5.082, loss=2.541, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.166e-04, train_time=0.889
[alab02] 2024-08-29 04:39:01,766 (trainer:720) INFO: 45epoch:train:6201-6400batch: iter_time=1.873e-04, forward_time=0.133, uma_reduction=0.223, text_vs_uma=0.442, loss_ctc=5.148, loss=2.574, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.166e-04, train_time=0.883
[alab02] 2024-08-29 04:40:28,279 (trainer:720) INFO: 45epoch:train:6401-6600batch: iter_time=1.948e-04, forward_time=0.131, uma_reduction=0.219, text_vs_uma=0.444, loss_ctc=5.235, loss=2.618, backward_time=0.177, optim_step_time=0.035, optim0_lr0=2.165e-04, train_time=0.865
[alab02] 2024-08-29 04:41:55,699 (trainer:720) INFO: 45epoch:train:6601-6800batch: iter_time=2.035e-04, forward_time=0.133, uma_reduction=0.211, text_vs_uma=0.464, loss_ctc=5.540, loss=2.770, backward_time=0.175, optim_step_time=0.036, optim0_lr0=2.164e-04, train_time=0.874
[alab02] 2024-08-29 04:43:25,021 (trainer:720) INFO: 45epoch:train:6801-7000batch: iter_time=1.913e-04, forward_time=0.136, uma_reduction=0.221, text_vs_uma=0.441, loss_ctc=5.203, loss=2.601, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.164e-04, train_time=0.893
[alab02] 2024-08-29 04:44:42,167 (trainer:338) INFO: 45epoch results: [train] iter_time=2.740e-04, forward_time=0.134, uma_reduction=0.216, text_vs_uma=0.444, loss_ctc=4.995, loss=2.498, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.175e-04, train_time=0.886, time=52 minutes and 39.45 seconds, total_count=320670, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.212, text_vs_uma=0.511, loss_ctc=3.617, cer_ctc=0.096, cer=0.096, loss=3.617, time=6.26 seconds, total_count=1170, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.7 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 04:44:48,286 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 04:44:48,297 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/28epoch.pth
[alab02] 2024-08-29 04:44:48,297 (trainer:272) INFO: 46/150epoch started. Estimated time to finish: 4 days, 1 hour and 32 minutes
[alab02] 2024-08-29 04:46:15,636 (trainer:720) INFO: 46epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.216, text_vs_uma=0.447, loss_ctc=4.782, loss=2.391, backward_time=0.176, optim_step_time=0.036, optim0_lr0=2.162e-04, train_time=0.873
[alab02] 2024-08-29 04:47:43,967 (trainer:720) INFO: 46epoch:train:201-400batch: iter_time=2.234e-04, forward_time=0.135, uma_reduction=0.214, text_vs_uma=0.446, loss_ctc=4.555, loss=2.278, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.162e-04, train_time=0.883
[alab02] 2024-08-29 04:49:15,670 (trainer:720) INFO: 46epoch:train:401-600batch: iter_time=2.367e-04, forward_time=0.140, uma_reduction=0.207, text_vs_uma=0.454, loss_ctc=5.014, loss=2.507, backward_time=0.190, optim_step_time=0.036, optim0_lr0=2.161e-04, train_time=0.917
[alab02] 2024-08-29 04:50:45,000 (trainer:720) INFO: 46epoch:train:601-800batch: iter_time=2.239e-04, forward_time=0.135, uma_reduction=0.217, text_vs_uma=0.448, loss_ctc=5.443, loss=2.721, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.160e-04, train_time=0.893
[alab02] 2024-08-29 04:52:13,993 (trainer:720) INFO: 46epoch:train:801-1000batch: iter_time=2.038e-04, forward_time=0.135, uma_reduction=0.216, text_vs_uma=0.452, loss_ctc=4.913, loss=2.456, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.160e-04, train_time=0.890
[alab02] 2024-08-29 04:53:43,498 (trainer:720) INFO: 46epoch:train:1001-1200batch: iter_time=2.012e-04, forward_time=0.136, uma_reduction=0.213, text_vs_uma=0.448, loss_ctc=4.819, loss=2.409, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.159e-04, train_time=0.895
[alab02] 2024-08-29 04:55:10,136 (trainer:720) INFO: 46epoch:train:1201-1400batch: iter_time=2.070e-04, forward_time=0.132, uma_reduction=0.211, text_vs_uma=0.468, loss_ctc=4.957, loss=2.478, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.158e-04, train_time=0.866
[alab02] 2024-08-29 04:56:38,724 (trainer:720) INFO: 46epoch:train:1401-1600batch: iter_time=2.271e-04, forward_time=0.134, uma_reduction=0.214, text_vs_uma=0.441, loss_ctc=4.969, loss=2.485, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.158e-04, train_time=0.886
[alab02] 2024-08-29 04:58:08,950 (trainer:720) INFO: 46epoch:train:1601-1800batch: iter_time=1.921e-04, forward_time=0.137, uma_reduction=0.219, text_vs_uma=0.433, loss_ctc=4.460, loss=2.230, backward_time=0.190, optim_step_time=0.035, optim0_lr0=2.157e-04, train_time=0.902
[alab02] 2024-08-29 04:59:36,601 (trainer:720) INFO: 46epoch:train:1801-2000batch: iter_time=2.064e-04, forward_time=0.132, uma_reduction=0.218, text_vs_uma=0.447, loss_ctc=5.008, loss=2.504, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.156e-04, train_time=0.876
[alab02] 2024-08-29 05:01:05,404 (trainer:720) INFO: 46epoch:train:2001-2200batch: iter_time=2.608e-04, forward_time=0.135, uma_reduction=0.209, text_vs_uma=0.452, loss_ctc=5.108, loss=2.554, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.156e-04, train_time=0.888
[alab02] 2024-08-29 05:02:36,200 (trainer:720) INFO: 46epoch:train:2201-2400batch: iter_time=2.185e-04, forward_time=0.138, uma_reduction=0.207, text_vs_uma=0.459, loss_ctc=5.015, loss=2.507, backward_time=0.189, optim_step_time=0.036, optim0_lr0=2.155e-04, train_time=0.908
[alab02] 2024-08-29 05:04:05,303 (trainer:720) INFO: 46epoch:train:2401-2600batch: iter_time=2.184e-04, forward_time=0.136, uma_reduction=0.205, text_vs_uma=0.456, loss_ctc=4.649, loss=2.325, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.154e-04, train_time=0.891
[alab02] 2024-08-29 05:05:34,517 (trainer:720) INFO: 46epoch:train:2601-2800batch: iter_time=2.288e-04, forward_time=0.135, uma_reduction=0.205, text_vs_uma=0.474, loss_ctc=5.164, loss=2.582, backward_time=0.183, optim_step_time=0.037, optim0_lr0=2.154e-04, train_time=0.892
[alab02] 2024-08-29 05:07:03,758 (trainer:720) INFO: 46epoch:train:2801-3000batch: iter_time=1.913e-04, forward_time=0.134, uma_reduction=0.205, text_vs_uma=0.473, loss_ctc=5.306, loss=2.653, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.153e-04, train_time=0.892
[alab02] 2024-08-29 05:08:33,038 (trainer:720) INFO: 46epoch:train:3001-3200batch: iter_time=1.934e-04, forward_time=0.136, uma_reduction=0.211, text_vs_uma=0.456, loss_ctc=4.497, loss=2.249, backward_time=0.188, optim_step_time=0.034, optim0_lr0=2.152e-04, train_time=0.893
[alab02] 2024-08-29 05:10:01,596 (trainer:720) INFO: 46epoch:train:3201-3400batch: iter_time=2.014e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.456, loss_ctc=4.938, loss=2.469, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.152e-04, train_time=0.885
[alab02] 2024-08-29 05:11:29,275 (trainer:720) INFO: 46epoch:train:3401-3600batch: iter_time=2.011e-04, forward_time=0.133, uma_reduction=0.210, text_vs_uma=0.457, loss_ctc=4.554, loss=2.277, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.151e-04, train_time=0.877
[alab02] 2024-08-29 05:12:59,054 (trainer:720) INFO: 46epoch:train:3601-3800batch: iter_time=1.912e-04, forward_time=0.136, uma_reduction=0.206, text_vs_uma=0.463, loss_ctc=4.777, loss=2.389, backward_time=0.188, optim_step_time=0.035, optim0_lr0=2.150e-04, train_time=0.898
[alab02] 2024-08-29 05:14:28,062 (trainer:720) INFO: 46epoch:train:3801-4000batch: iter_time=2.019e-04, forward_time=0.136, uma_reduction=0.209, text_vs_uma=0.464, loss_ctc=4.937, loss=2.468, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.150e-04, train_time=0.890
[alab02] 2024-08-29 05:15:59,467 (trainer:720) INFO: 46epoch:train:4001-4200batch: iter_time=2.007e-04, forward_time=0.139, uma_reduction=0.205, text_vs_uma=0.468, loss_ctc=5.559, loss=2.780, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.149e-04, train_time=0.914
[alab02] 2024-08-29 05:17:29,072 (trainer:720) INFO: 46epoch:train:4201-4400batch: iter_time=2.328e-04, forward_time=0.136, uma_reduction=0.206, text_vs_uma=0.467, loss_ctc=5.099, loss=2.549, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.148e-04, train_time=0.896
[alab02] 2024-08-29 05:18:56,501 (trainer:720) INFO: 46epoch:train:4401-4600batch: iter_time=2.633e-04, forward_time=0.133, uma_reduction=0.205, text_vs_uma=0.462, loss_ctc=5.030, loss=2.515, backward_time=0.178, optim_step_time=0.037, optim0_lr0=2.148e-04, train_time=0.874
[alab02] 2024-08-29 05:20:27,412 (trainer:720) INFO: 46epoch:train:4601-4800batch: iter_time=2.950e-04, forward_time=0.138, uma_reduction=0.213, text_vs_uma=0.439, loss_ctc=4.756, loss=2.378, backward_time=0.189, optim_step_time=0.036, optim0_lr0=2.147e-04, train_time=0.909
[alab02] 2024-08-29 05:21:57,689 (trainer:720) INFO: 46epoch:train:4801-5000batch: iter_time=2.096e-04, forward_time=0.138, uma_reduction=0.213, text_vs_uma=0.445, loss_ctc=4.624, loss=2.312, backward_time=0.189, optim_step_time=0.037, optim0_lr0=2.146e-04, train_time=0.903
[alab02] 2024-08-29 05:23:26,194 (trainer:720) INFO: 46epoch:train:5001-5200batch: iter_time=2.813e-04, forward_time=0.134, uma_reduction=0.212, text_vs_uma=0.460, loss_ctc=5.496, loss=2.748, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.146e-04, train_time=0.885
[alab02] 2024-08-29 05:24:55,153 (trainer:720) INFO: 46epoch:train:5201-5400batch: iter_time=2.369e-04, forward_time=0.134, uma_reduction=0.207, text_vs_uma=0.459, loss_ctc=4.899, loss=2.450, backward_time=0.185, optim_step_time=0.037, optim0_lr0=2.145e-04, train_time=0.889
[alab02] 2024-08-29 05:26:24,840 (trainer:720) INFO: 46epoch:train:5401-5600batch: iter_time=1.941e-04, forward_time=0.136, uma_reduction=0.211, text_vs_uma=0.456, loss_ctc=4.976, loss=2.488, backward_time=0.188, optim_step_time=0.035, optim0_lr0=2.144e-04, train_time=0.897
[alab02] 2024-08-29 05:27:52,647 (trainer:720) INFO: 46epoch:train:5601-5800batch: iter_time=1.904e-04, forward_time=0.132, uma_reduction=0.212, text_vs_uma=0.451, loss_ctc=4.765, loss=2.383, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.144e-04, train_time=0.878
[alab02] 2024-08-29 05:29:19,390 (trainer:720) INFO: 46epoch:train:5801-6000batch: iter_time=1.793e-04, forward_time=0.131, uma_reduction=0.208, text_vs_uma=0.459, loss_ctc=4.957, loss=2.479, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.143e-04, train_time=0.867
[alab02] 2024-08-29 05:30:47,714 (trainer:720) INFO: 46epoch:train:6001-6200batch: iter_time=1.754e-04, forward_time=0.132, uma_reduction=0.207, text_vs_uma=0.486, loss_ctc=5.580, loss=2.790, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.143e-04, train_time=0.883
[alab02] 2024-08-29 05:32:14,511 (trainer:720) INFO: 46epoch:train:6201-6400batch: iter_time=1.947e-04, forward_time=0.130, uma_reduction=0.211, text_vs_uma=0.449, loss_ctc=4.746, loss=2.373, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.142e-04, train_time=0.868
[alab02] 2024-08-29 05:33:41,231 (trainer:720) INFO: 46epoch:train:6401-6600batch: iter_time=1.901e-04, forward_time=0.130, uma_reduction=0.206, text_vs_uma=0.461, loss_ctc=4.871, loss=2.435, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.141e-04, train_time=0.867
[alab02] 2024-08-29 05:35:10,724 (trainer:720) INFO: 46epoch:train:6601-6800batch: iter_time=1.866e-04, forward_time=0.134, uma_reduction=0.208, text_vs_uma=0.464, loss_ctc=5.056, loss=2.528, backward_time=0.188, optim_step_time=0.034, optim0_lr0=2.141e-04, train_time=0.895
[alab02] 2024-08-29 05:36:39,243 (trainer:720) INFO: 46epoch:train:6801-7000batch: iter_time=2.110e-04, forward_time=0.134, uma_reduction=0.211, text_vs_uma=0.444, loss_ctc=4.829, loss=2.415, backward_time=0.186, optim_step_time=0.034, optim0_lr0=2.140e-04, train_time=0.885
[alab02] 2024-08-29 05:37:54,164 (trainer:338) INFO: 46epoch results: [train] iter_time=2.670e-04, forward_time=0.135, uma_reduction=0.210, text_vs_uma=0.456, loss_ctc=4.940, loss=2.470, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.151e-04, train_time=0.888, time=52 minutes and 46.77 seconds, total_count=327796, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.210, text_vs_uma=0.517, loss_ctc=3.847, cer_ctc=0.104, cer=0.104, loss=3.847, time=6.13 seconds, total_count=1196, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.96 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 05:37:59,917 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 05:37:59,918 (trainer:272) INFO: 47/150epoch started. Estimated time to finish: 4 days, 31 minutes and 27.4 seconds
[alab02] 2024-08-29 05:39:29,787 (trainer:720) INFO: 47epoch:train:1-200batch: iter_time=0.002, forward_time=0.134, uma_reduction=0.207, text_vs_uma=0.460, loss_ctc=5.219, loss=2.610, backward_time=0.186, optim_step_time=0.034, optim0_lr0=2.139e-04, train_time=0.898
[alab02] 2024-08-29 05:40:59,618 (trainer:720) INFO: 47epoch:train:201-400batch: iter_time=1.886e-04, forward_time=0.135, uma_reduction=0.204, text_vs_uma=0.465, loss_ctc=5.090, loss=2.545, backward_time=0.187, optim_step_time=0.034, optim0_lr0=2.138e-04, train_time=0.898
[alab02] 2024-08-29 05:42:26,682 (trainer:720) INFO: 47epoch:train:401-600batch: iter_time=2.021e-04, forward_time=0.131, uma_reduction=0.207, text_vs_uma=0.463, loss_ctc=5.029, loss=2.515, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.138e-04, train_time=0.870
[alab02] 2024-08-29 05:43:51,749 (trainer:720) INFO: 47epoch:train:601-800batch: iter_time=2.143e-04, forward_time=0.127, uma_reduction=0.207, text_vs_uma=0.464, loss_ctc=5.331, loss=2.666, backward_time=0.174, optim_step_time=0.034, optim0_lr0=2.137e-04, train_time=0.850
[alab02] 2024-08-29 05:45:22,136 (trainer:720) INFO: 47epoch:train:801-1000batch: iter_time=1.890e-04, forward_time=0.136, uma_reduction=0.203, text_vs_uma=0.470, loss_ctc=5.491, loss=2.746, backward_time=0.188, optim_step_time=0.033, optim0_lr0=2.136e-04, train_time=0.904
[alab02] 2024-08-29 05:46:49,985 (trainer:720) INFO: 47epoch:train:1001-1200batch: iter_time=1.869e-04, forward_time=0.132, uma_reduction=0.206, text_vs_uma=0.473, loss_ctc=5.643, loss=2.821, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.136e-04, train_time=0.878
[alab02] 2024-08-29 05:48:17,956 (trainer:720) INFO: 47epoch:train:1201-1400batch: iter_time=1.850e-04, forward_time=0.132, uma_reduction=0.212, text_vs_uma=0.457, loss_ctc=4.986, loss=2.493, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.135e-04, train_time=0.879
[alab02] 2024-08-29 05:49:41,686 (trainer:720) INFO: 47epoch:train:1401-1600batch: iter_time=1.879e-04, forward_time=0.125, uma_reduction=0.213, text_vs_uma=0.455, loss_ctc=5.156, loss=2.578, backward_time=0.170, optim_step_time=0.034, optim0_lr0=2.134e-04, train_time=0.837
[alab02] 2024-08-29 05:51:08,613 (trainer:720) INFO: 47epoch:train:1601-1800batch: iter_time=1.891e-04, forward_time=0.131, uma_reduction=0.210, text_vs_uma=0.459, loss_ctc=4.977, loss=2.489, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.134e-04, train_time=0.869
[alab02] 2024-08-29 05:52:36,806 (trainer:720) INFO: 47epoch:train:1801-2000batch: iter_time=1.915e-04, forward_time=0.133, uma_reduction=0.215, text_vs_uma=0.456, loss_ctc=5.208, loss=2.604, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.133e-04, train_time=0.882
[alab02] 2024-08-29 05:54:06,098 (trainer:720) INFO: 47epoch:train:2001-2200batch: iter_time=1.913e-04, forward_time=0.135, uma_reduction=0.212, text_vs_uma=0.442, loss_ctc=5.134, loss=2.567, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.132e-04, train_time=0.893
[alab02] 2024-08-29 05:55:33,089 (trainer:720) INFO: 47epoch:train:2201-2400batch: iter_time=1.872e-04, forward_time=0.130, uma_reduction=0.214, text_vs_uma=0.453, loss_ctc=4.865, loss=2.432, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.132e-04, train_time=0.870
[alab02] 2024-08-29 05:56:59,288 (trainer:720) INFO: 47epoch:train:2401-2600batch: iter_time=1.900e-04, forward_time=0.130, uma_reduction=0.207, text_vs_uma=0.459, loss_ctc=4.941, loss=2.470, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.131e-04, train_time=0.862
[alab02] 2024-08-29 05:58:28,068 (trainer:720) INFO: 47epoch:train:2601-2800batch: iter_time=1.929e-04, forward_time=0.132, uma_reduction=0.209, text_vs_uma=0.457, loss_ctc=5.489, loss=2.744, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.130e-04, train_time=0.888
[alab02] 2024-08-29 05:59:57,432 (trainer:720) INFO: 47epoch:train:2801-3000batch: iter_time=2.582e-04, forward_time=0.134, uma_reduction=0.209, text_vs_uma=0.459, loss_ctc=5.179, loss=2.590, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.130e-04, train_time=0.893
[alab02] 2024-08-29 06:01:26,182 (trainer:720) INFO: 47epoch:train:3001-3200batch: iter_time=2.107e-04, forward_time=0.134, uma_reduction=0.209, text_vs_uma=0.456, loss_ctc=5.200, loss=2.600, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.129e-04, train_time=0.887
[alab02] 2024-08-29 06:02:54,925 (trainer:720) INFO: 47epoch:train:3201-3400batch: iter_time=1.987e-04, forward_time=0.134, uma_reduction=0.217, text_vs_uma=0.439, loss_ctc=4.688, loss=2.344, backward_time=0.187, optim_step_time=0.034, optim0_lr0=2.128e-04, train_time=0.887
[alab02] 2024-08-29 06:04:23,220 (trainer:720) INFO: 47epoch:train:3401-3600batch: iter_time=2.134e-04, forward_time=0.132, uma_reduction=0.216, text_vs_uma=0.445, loss_ctc=4.569, loss=2.285, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.128e-04, train_time=0.883
[alab02] 2024-08-29 06:05:49,741 (trainer:720) INFO: 47epoch:train:3601-3800batch: iter_time=1.774e-04, forward_time=0.130, uma_reduction=0.213, text_vs_uma=0.451, loss_ctc=4.935, loss=2.467, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.127e-04, train_time=0.865
[alab02] 2024-08-29 06:07:17,353 (trainer:720) INFO: 47epoch:train:3801-4000batch: iter_time=1.824e-04, forward_time=0.131, uma_reduction=0.209, text_vs_uma=0.458, loss_ctc=5.115, loss=2.557, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.127e-04, train_time=0.876
[alab02] 2024-08-29 06:08:45,783 (trainer:720) INFO: 47epoch:train:4001-4200batch: iter_time=1.830e-04, forward_time=0.133, uma_reduction=0.205, text_vs_uma=0.469, loss_ctc=5.353, loss=2.677, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.126e-04, train_time=0.884
[alab02] 2024-08-29 06:10:11,766 (trainer:720) INFO: 47epoch:train:4201-4400batch: iter_time=1.791e-04, forward_time=0.128, uma_reduction=0.207, text_vs_uma=0.457, loss_ctc=4.995, loss=2.497, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.125e-04, train_time=0.860
[alab02] 2024-08-29 06:11:39,161 (trainer:720) INFO: 47epoch:train:4401-4600batch: iter_time=1.808e-04, forward_time=0.131, uma_reduction=0.203, text_vs_uma=0.461, loss_ctc=5.278, loss=2.639, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.125e-04, train_time=0.874
[alab02] 2024-08-29 06:13:06,141 (trainer:720) INFO: 47epoch:train:4601-4800batch: iter_time=2.113e-04, forward_time=0.130, uma_reduction=0.212, text_vs_uma=0.450, loss_ctc=5.032, loss=2.516, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.124e-04, train_time=0.870
[alab02] 2024-08-29 06:14:32,561 (trainer:720) INFO: 47epoch:train:4801-5000batch: iter_time=2.109e-04, forward_time=0.131, uma_reduction=0.214, text_vs_uma=0.452, loss_ctc=5.043, loss=2.522, backward_time=0.177, optim_step_time=0.035, optim0_lr0=2.123e-04, train_time=0.864
[alab02] 2024-08-29 06:16:00,793 (trainer:720) INFO: 47epoch:train:5001-5200batch: iter_time=2.172e-04, forward_time=0.135, uma_reduction=0.211, text_vs_uma=0.451, loss_ctc=4.753, loss=2.376, backward_time=0.181, optim_step_time=0.036, optim0_lr0=2.123e-04, train_time=0.882
[alab02] 2024-08-29 06:17:29,509 (trainer:720) INFO: 47epoch:train:5201-5400batch: iter_time=1.941e-04, forward_time=0.134, uma_reduction=0.206, text_vs_uma=0.465, loss_ctc=5.433, loss=2.717, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.122e-04, train_time=0.887
[alab02] 2024-08-29 06:18:59,640 (trainer:720) INFO: 47epoch:train:5401-5600batch: iter_time=1.926e-04, forward_time=0.135, uma_reduction=0.204, text_vs_uma=0.460, loss_ctc=5.113, loss=2.557, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.121e-04, train_time=0.901
[alab02] 2024-08-29 06:20:27,504 (trainer:720) INFO: 47epoch:train:5601-5800batch: iter_time=2.051e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.440, loss_ctc=4.957, loss=2.478, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.121e-04, train_time=0.878
[alab02] 2024-08-29 06:21:54,863 (trainer:720) INFO: 47epoch:train:5801-6000batch: iter_time=2.022e-04, forward_time=0.132, uma_reduction=0.218, text_vs_uma=0.441, loss_ctc=4.806, loss=2.403, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.120e-04, train_time=0.873
[alab02] 2024-08-29 06:23:22,885 (trainer:720) INFO: 47epoch:train:6001-6200batch: iter_time=1.908e-04, forward_time=0.132, uma_reduction=0.217, text_vs_uma=0.445, loss_ctc=4.984, loss=2.492, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.120e-04, train_time=0.880
[alab02] 2024-08-29 06:24:48,552 (trainer:720) INFO: 47epoch:train:6201-6400batch: iter_time=1.815e-04, forward_time=0.128, uma_reduction=0.219, text_vs_uma=0.444, loss_ctc=5.260, loss=2.630, backward_time=0.173, optim_step_time=0.033, optim0_lr0=2.119e-04, train_time=0.856
[alab02] 2024-08-29 06:26:18,749 (trainer:720) INFO: 47epoch:train:6401-6600batch: iter_time=1.782e-04, forward_time=0.135, uma_reduction=0.216, text_vs_uma=0.455, loss_ctc=5.181, loss=2.591, backward_time=0.190, optim_step_time=0.034, optim0_lr0=2.118e-04, train_time=0.902
[alab02] 2024-08-29 06:27:45,260 (trainer:720) INFO: 47epoch:train:6601-6800batch: iter_time=1.833e-04, forward_time=0.130, uma_reduction=0.215, text_vs_uma=0.446, loss_ctc=4.978, loss=2.489, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.118e-04, train_time=0.865
[alab02] 2024-08-29 06:29:10,495 (trainer:720) INFO: 47epoch:train:6801-7000batch: iter_time=1.744e-04, forward_time=0.128, uma_reduction=0.219, text_vs_uma=0.441, loss_ctc=5.070, loss=2.535, backward_time=0.174, optim_step_time=0.034, optim0_lr0=2.117e-04, train_time=0.852
[alab02] 2024-08-29 06:30:25,817 (trainer:338) INFO: 47epoch results: [train] iter_time=2.512e-04, forward_time=0.132, uma_reduction=0.211, text_vs_uma=0.455, loss_ctc=5.102, loss=2.551, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.128e-04, train_time=0.877, time=52 minutes and 5.81 seconds, total_count=334922, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.218, text_vs_uma=0.497, loss_ctc=3.662, cer_ctc=0.107, cer=0.107, loss=3.662, time=6.04 seconds, total_count=1222, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.04 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 06:30:31,188 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 06:30:31,262 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/46epoch.pth
[alab02] 2024-08-29 06:30:31,263 (trainer:272) INFO: 48/150epoch started. Estimated time to finish: 3 days, 23 hours and 28 minutes
[alab02] 2024-08-29 06:32:02,916 (trainer:720) INFO: 48epoch:train:1-200batch: iter_time=0.002, forward_time=0.136, uma_reduction=0.216, text_vs_uma=0.452, loss_ctc=5.624, loss=2.812, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.116e-04, train_time=0.916
[alab02] 2024-08-29 06:33:30,189 (trainer:720) INFO: 48epoch:train:201-400batch: iter_time=2.360e-04, forward_time=0.130, uma_reduction=0.218, text_vs_uma=0.427, loss_ctc=4.587, loss=2.294, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.115e-04, train_time=0.872
[alab02] 2024-08-29 06:34:59,206 (trainer:720) INFO: 48epoch:train:401-600batch: iter_time=2.433e-04, forward_time=0.133, uma_reduction=0.223, text_vs_uma=0.439, loss_ctc=5.066, loss=2.533, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.115e-04, train_time=0.890
[alab02] 2024-08-29 06:36:29,408 (trainer:720) INFO: 48epoch:train:601-800batch: iter_time=2.357e-04, forward_time=0.136, uma_reduction=0.216, text_vs_uma=0.451, loss_ctc=5.324, loss=2.662, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.114e-04, train_time=0.902
[alab02] 2024-08-29 06:37:58,385 (trainer:720) INFO: 48epoch:train:801-1000batch: iter_time=2.074e-04, forward_time=0.134, uma_reduction=0.214, text_vs_uma=0.443, loss_ctc=5.359, loss=2.680, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.113e-04, train_time=0.890
[alab02] 2024-08-29 06:39:26,534 (trainer:720) INFO: 48epoch:train:1001-1200batch: iter_time=2.610e-04, forward_time=0.133, uma_reduction=0.212, text_vs_uma=0.436, loss_ctc=4.640, loss=2.320, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.113e-04, train_time=0.881
[alab02] 2024-08-29 06:40:56,079 (trainer:720) INFO: 48epoch:train:1201-1400batch: iter_time=2.158e-04, forward_time=0.136, uma_reduction=0.214, text_vs_uma=0.449, loss_ctc=5.032, loss=2.516, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.112e-04, train_time=0.895
[alab02] 2024-08-29 06:42:24,018 (trainer:720) INFO: 48epoch:train:1401-1600batch: iter_time=2.183e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.445, loss_ctc=5.041, loss=2.520, backward_time=0.181, optim_step_time=0.036, optim0_lr0=2.112e-04, train_time=0.879
[alab02] 2024-08-29 06:43:51,048 (trainer:720) INFO: 48epoch:train:1601-1800batch: iter_time=2.155e-04, forward_time=0.132, uma_reduction=0.217, text_vs_uma=0.452, loss_ctc=4.812, loss=2.406, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.111e-04, train_time=0.870
[alab02] 2024-08-29 06:45:18,129 (trainer:720) INFO: 48epoch:train:1801-2000batch: iter_time=2.130e-04, forward_time=0.133, uma_reduction=0.217, text_vs_uma=0.437, loss_ctc=4.753, loss=2.376, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.110e-04, train_time=0.870
[alab02] 2024-08-29 06:46:46,164 (trainer:720) INFO: 48epoch:train:2001-2200batch: iter_time=2.037e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.433, loss_ctc=4.586, loss=2.293, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.110e-04, train_time=0.880
[alab02] 2024-08-29 06:48:12,595 (trainer:720) INFO: 48epoch:train:2201-2400batch: iter_time=2.001e-04, forward_time=0.130, uma_reduction=0.219, text_vs_uma=0.435, loss_ctc=4.892, loss=2.446, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.109e-04, train_time=0.864
[alab02] 2024-08-29 06:49:41,637 (trainer:720) INFO: 48epoch:train:2401-2600batch: iter_time=2.209e-04, forward_time=0.134, uma_reduction=0.211, text_vs_uma=0.453, loss_ctc=5.005, loss=2.503, backward_time=0.187, optim_step_time=0.034, optim0_lr0=2.108e-04, train_time=0.890
[alab02] 2024-08-29 06:51:12,178 (trainer:720) INFO: 48epoch:train:2601-2800batch: iter_time=1.924e-04, forward_time=0.138, uma_reduction=0.211, text_vs_uma=0.450, loss_ctc=5.064, loss=2.532, backward_time=0.190, optim_step_time=0.034, optim0_lr0=2.108e-04, train_time=0.905
[alab02] 2024-08-29 06:52:37,269 (trainer:720) INFO: 48epoch:train:2801-3000batch: iter_time=2.182e-04, forward_time=0.128, uma_reduction=0.213, text_vs_uma=0.463, loss_ctc=5.123, loss=2.562, backward_time=0.175, optim_step_time=0.034, optim0_lr0=2.107e-04, train_time=0.851
[alab02] 2024-08-29 06:54:03,000 (trainer:720) INFO: 48epoch:train:3001-3200batch: iter_time=1.821e-04, forward_time=0.129, uma_reduction=0.214, text_vs_uma=0.445, loss_ctc=4.968, loss=2.484, backward_time=0.176, optim_step_time=0.033, optim0_lr0=2.107e-04, train_time=0.857
[alab02] 2024-08-29 06:55:32,704 (trainer:720) INFO: 48epoch:train:3201-3400batch: iter_time=2.077e-04, forward_time=0.136, uma_reduction=0.215, text_vs_uma=0.441, loss_ctc=4.759, loss=2.380, backward_time=0.188, optim_step_time=0.033, optim0_lr0=2.106e-04, train_time=0.897
[alab02] 2024-08-29 06:57:00,127 (trainer:720) INFO: 48epoch:train:3401-3600batch: iter_time=1.965e-04, forward_time=0.132, uma_reduction=0.215, text_vs_uma=0.439, loss_ctc=5.130, loss=2.565, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.105e-04, train_time=0.874
[alab02] 2024-08-29 06:58:27,004 (trainer:720) INFO: 48epoch:train:3601-3800batch: iter_time=1.994e-04, forward_time=0.131, uma_reduction=0.216, text_vs_uma=0.439, loss_ctc=4.770, loss=2.385, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.105e-04, train_time=0.868
[alab02] 2024-08-29 06:59:56,772 (trainer:720) INFO: 48epoch:train:3801-4000batch: iter_time=1.898e-04, forward_time=0.135, uma_reduction=0.213, text_vs_uma=0.444, loss_ctc=4.880, loss=2.440, backward_time=0.189, optim_step_time=0.034, optim0_lr0=2.104e-04, train_time=0.897
[alab02] 2024-08-29 07:01:25,146 (trainer:720) INFO: 48epoch:train:4001-4200batch: iter_time=2.272e-04, forward_time=0.133, uma_reduction=0.212, text_vs_uma=0.450, loss_ctc=4.671, loss=2.335, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.103e-04, train_time=0.883
[alab02] 2024-08-29 07:02:52,840 (trainer:720) INFO: 48epoch:train:4201-4400batch: iter_time=1.999e-04, forward_time=0.132, uma_reduction=0.215, text_vs_uma=0.443, loss_ctc=5.182, loss=2.591, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.103e-04, train_time=0.877
[alab02] 2024-08-29 07:04:20,393 (trainer:720) INFO: 48epoch:train:4401-4600batch: iter_time=2.049e-04, forward_time=0.131, uma_reduction=0.214, text_vs_uma=0.458, loss_ctc=5.156, loss=2.578, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.102e-04, train_time=0.875
[alab02] 2024-08-29 07:05:49,092 (trainer:720) INFO: 48epoch:train:4601-4800batch: iter_time=1.804e-04, forward_time=0.134, uma_reduction=0.219, text_vs_uma=0.441, loss_ctc=4.816, loss=2.408, backward_time=0.186, optim_step_time=0.034, optim0_lr0=2.102e-04, train_time=0.887
[alab02] 2024-08-29 07:07:14,051 (trainer:720) INFO: 48epoch:train:4801-5000batch: iter_time=1.896e-04, forward_time=0.128, uma_reduction=0.220, text_vs_uma=0.433, loss_ctc=4.736, loss=2.368, backward_time=0.175, optim_step_time=0.035, optim0_lr0=2.101e-04, train_time=0.849
[alab02] 2024-08-29 07:08:40,965 (trainer:720) INFO: 48epoch:train:5001-5200batch: iter_time=1.771e-04, forward_time=0.131, uma_reduction=0.220, text_vs_uma=0.441, loss_ctc=4.886, loss=2.443, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.100e-04, train_time=0.869
[alab02] 2024-08-29 07:10:10,990 (trainer:720) INFO: 48epoch:train:5201-5400batch: iter_time=1.916e-04, forward_time=0.135, uma_reduction=0.222, text_vs_uma=0.429, loss_ctc=4.785, loss=2.392, backward_time=0.190, optim_step_time=0.033, optim0_lr0=2.100e-04, train_time=0.900
[alab02] 2024-08-29 07:11:38,720 (trainer:720) INFO: 48epoch:train:5401-5600batch: iter_time=2.262e-04, forward_time=0.134, uma_reduction=0.220, text_vs_uma=0.442, loss_ctc=4.634, loss=2.317, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.099e-04, train_time=0.877
[alab02] 2024-08-29 07:13:08,312 (trainer:720) INFO: 48epoch:train:5601-5800batch: iter_time=1.933e-04, forward_time=0.135, uma_reduction=0.220, text_vs_uma=0.434, loss_ctc=4.739, loss=2.370, backward_time=0.187, optim_step_time=0.034, optim0_lr0=2.098e-04, train_time=0.896
[alab02] 2024-08-29 07:14:37,894 (trainer:720) INFO: 48epoch:train:5801-6000batch: iter_time=2.637e-04, forward_time=0.136, uma_reduction=0.224, text_vs_uma=0.435, loss_ctc=5.128, loss=2.564, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.098e-04, train_time=0.896
[alab02] 2024-08-29 07:16:05,627 (trainer:720) INFO: 48epoch:train:6001-6200batch: iter_time=2.443e-04, forward_time=0.134, uma_reduction=0.221, text_vs_uma=0.439, loss_ctc=4.952, loss=2.476, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.097e-04, train_time=0.877
[alab02] 2024-08-29 07:17:35,319 (trainer:720) INFO: 48epoch:train:6201-6400batch: iter_time=1.900e-04, forward_time=0.135, uma_reduction=0.220, text_vs_uma=0.444, loss_ctc=4.844, loss=2.422, backward_time=0.188, optim_step_time=0.035, optim0_lr0=2.097e-04, train_time=0.897
[alab02] 2024-08-29 07:19:03,042 (trainer:720) INFO: 48epoch:train:6401-6600batch: iter_time=1.881e-04, forward_time=0.133, uma_reduction=0.212, text_vs_uma=0.446, loss_ctc=4.924, loss=2.462, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.096e-04, train_time=0.877
[alab02] 2024-08-29 07:20:30,673 (trainer:720) INFO: 48epoch:train:6601-6800batch: iter_time=1.719e-04, forward_time=0.132, uma_reduction=0.216, text_vs_uma=0.435, loss_ctc=4.781, loss=2.390, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.095e-04, train_time=0.876
[alab02] 2024-08-29 07:21:58,498 (trainer:720) INFO: 48epoch:train:6801-7000batch: iter_time=2.003e-04, forward_time=0.132, uma_reduction=0.216, text_vs_uma=0.446, loss_ctc=5.068, loss=2.534, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.095e-04, train_time=0.878
[alab02] 2024-08-29 07:23:15,746 (trainer:338) INFO: 48epoch results: [train] iter_time=2.619e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.442, loss_ctc=4.937, loss=2.469, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.105e-04, train_time=0.882, time=52 minutes and 23.95 seconds, total_count=342048, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.216, text_vs_uma=0.501, loss_ctc=3.900, cer_ctc=0.099, cer=0.099, loss=3.900, time=6.3 seconds, total_count=1248, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.24 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 07:23:21,309 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 07:23:21,371 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/37epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/47epoch.pth
[alab02] 2024-08-29 07:23:21,371 (trainer:272) INFO: 49/150epoch started. Estimated time to finish: 3 days, 22 hours and 27 minutes
[alab02] 2024-08-29 07:24:51,825 (trainer:720) INFO: 49epoch:train:1-200batch: iter_time=0.002, forward_time=0.137, uma_reduction=0.212, text_vs_uma=0.452, loss_ctc=5.232, loss=2.616, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.094e-04, train_time=0.904
[alab02] 2024-08-29 07:26:19,928 (trainer:720) INFO: 49epoch:train:201-400batch: iter_time=2.044e-04, forward_time=0.133, uma_reduction=0.212, text_vs_uma=0.462, loss_ctc=5.128, loss=2.564, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.093e-04, train_time=0.881
[alab02] 2024-08-29 07:27:52,600 (trainer:720) INFO: 49epoch:train:401-600batch: iter_time=2.066e-04, forward_time=0.140, uma_reduction=0.216, text_vs_uma=0.439, loss_ctc=5.308, loss=2.654, backward_time=0.192, optim_step_time=0.036, optim0_lr0=2.093e-04, train_time=0.926
[alab02] 2024-08-29 07:29:21,400 (trainer:720) INFO: 49epoch:train:601-800batch: iter_time=2.226e-04, forward_time=0.135, uma_reduction=0.209, text_vs_uma=0.467, loss_ctc=5.383, loss=2.691, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.092e-04, train_time=0.888
[alab02] 2024-08-29 07:30:52,502 (trainer:720) INFO: 49epoch:train:801-1000batch: iter_time=2.242e-04, forward_time=0.140, uma_reduction=0.211, text_vs_uma=0.440, loss_ctc=4.865, loss=2.432, backward_time=0.189, optim_step_time=0.038, optim0_lr0=2.091e-04, train_time=0.911
[alab02] 2024-08-29 07:32:19,987 (trainer:720) INFO: 49epoch:train:1001-1200batch: iter_time=2.745e-04, forward_time=0.132, uma_reduction=0.210, text_vs_uma=0.470, loss_ctc=5.296, loss=2.648, backward_time=0.181, optim_step_time=0.037, optim0_lr0=2.091e-04, train_time=0.875
[alab02] 2024-08-29 07:33:48,148 (trainer:720) INFO: 49epoch:train:1201-1400batch: iter_time=2.021e-04, forward_time=0.134, uma_reduction=0.214, text_vs_uma=0.460, loss_ctc=5.409, loss=2.705, backward_time=0.178, optim_step_time=0.036, optim0_lr0=2.090e-04, train_time=0.881
[alab02] 2024-08-29 07:35:17,736 (trainer:720) INFO: 49epoch:train:1401-1600batch: iter_time=2.234e-04, forward_time=0.137, uma_reduction=0.215, text_vs_uma=0.440, loss_ctc=4.978, loss=2.489, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.090e-04, train_time=0.896
[alab02] 2024-08-29 07:36:46,516 (trainer:720) INFO: 49epoch:train:1601-1800batch: iter_time=2.237e-04, forward_time=0.136, uma_reduction=0.211, text_vs_uma=0.462, loss_ctc=5.464, loss=2.732, backward_time=0.180, optim_step_time=0.038, optim0_lr0=2.089e-04, train_time=0.887
[alab02] 2024-08-29 07:38:17,492 (trainer:720) INFO: 49epoch:train:1801-2000batch: iter_time=2.396e-04, forward_time=0.138, uma_reduction=0.211, text_vs_uma=0.458, loss_ctc=4.953, loss=2.476, backward_time=0.189, optim_step_time=0.039, optim0_lr0=2.088e-04, train_time=0.909
[alab02] 2024-08-29 07:39:45,781 (trainer:720) INFO: 49epoch:train:2001-2200batch: iter_time=2.100e-04, forward_time=0.135, uma_reduction=0.212, text_vs_uma=0.446, loss_ctc=4.837, loss=2.418, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.088e-04, train_time=0.883
[alab02] 2024-08-29 07:41:17,684 (trainer:720) INFO: 49epoch:train:2201-2400batch: iter_time=2.352e-04, forward_time=0.141, uma_reduction=0.217, text_vs_uma=0.445, loss_ctc=5.025, loss=2.513, backward_time=0.190, optim_step_time=0.037, optim0_lr0=2.087e-04, train_time=0.919
[alab02] 2024-08-29 07:42:44,912 (trainer:720) INFO: 49epoch:train:2401-2600batch: iter_time=2.060e-04, forward_time=0.132, uma_reduction=0.217, text_vs_uma=0.449, loss_ctc=5.041, loss=2.520, backward_time=0.177, optim_step_time=0.037, optim0_lr0=2.087e-04, train_time=0.872
[alab02] 2024-08-29 07:44:12,749 (trainer:720) INFO: 49epoch:train:2601-2800batch: iter_time=2.306e-04, forward_time=0.134, uma_reduction=0.215, text_vs_uma=0.446, loss_ctc=4.947, loss=2.474, backward_time=0.179, optim_step_time=0.037, optim0_lr0=2.086e-04, train_time=0.878
[alab02] 2024-08-29 07:45:39,740 (trainer:720) INFO: 49epoch:train:2801-3000batch: iter_time=2.108e-04, forward_time=0.132, uma_reduction=0.219, text_vs_uma=0.439, loss_ctc=4.753, loss=2.376, backward_time=0.179, optim_step_time=0.036, optim0_lr0=2.085e-04, train_time=0.870
[alab02] 2024-08-29 07:47:07,567 (trainer:720) INFO: 49epoch:train:3001-3200batch: iter_time=1.917e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.445, loss_ctc=5.105, loss=2.552, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.085e-04, train_time=0.878
[alab02] 2024-08-29 07:48:38,118 (trainer:720) INFO: 49epoch:train:3201-3400batch: iter_time=1.963e-04, forward_time=0.137, uma_reduction=0.219, text_vs_uma=0.438, loss_ctc=4.804, loss=2.402, backward_time=0.191, optim_step_time=0.035, optim0_lr0=2.084e-04, train_time=0.905
[alab02] 2024-08-29 07:50:04,116 (trainer:720) INFO: 49epoch:train:3401-3600batch: iter_time=2.061e-04, forward_time=0.130, uma_reduction=0.212, text_vs_uma=0.447, loss_ctc=4.818, loss=2.409, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.083e-04, train_time=0.860
[alab02] 2024-08-29 07:51:31,537 (trainer:720) INFO: 49epoch:train:3601-3800batch: iter_time=1.905e-04, forward_time=0.132, uma_reduction=0.214, text_vs_uma=0.453, loss_ctc=5.269, loss=2.634, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.083e-04, train_time=0.874
[alab02] 2024-08-29 07:52:58,323 (trainer:720) INFO: 49epoch:train:3801-4000batch: iter_time=1.952e-04, forward_time=0.132, uma_reduction=0.216, text_vs_uma=0.433, loss_ctc=4.729, loss=2.365, backward_time=0.178, optim_step_time=0.036, optim0_lr0=2.082e-04, train_time=0.868
[alab02] 2024-08-29 07:54:25,768 (trainer:720) INFO: 49epoch:train:4001-4200batch: iter_time=2.088e-04, forward_time=0.132, uma_reduction=0.221, text_vs_uma=0.433, loss_ctc=4.874, loss=2.437, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.082e-04, train_time=0.874
[alab02] 2024-08-29 07:55:54,943 (trainer:720) INFO: 49epoch:train:4201-4400batch: iter_time=1.887e-04, forward_time=0.134, uma_reduction=0.215, text_vs_uma=0.450, loss_ctc=5.145, loss=2.572, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.081e-04, train_time=0.891
[alab02] 2024-08-29 07:57:24,199 (trainer:720) INFO: 49epoch:train:4401-4600batch: iter_time=1.825e-04, forward_time=0.135, uma_reduction=0.219, text_vs_uma=0.457, loss_ctc=5.251, loss=2.625, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.080e-04, train_time=0.892
[alab02] 2024-08-29 07:58:51,589 (trainer:720) INFO: 49epoch:train:4601-4800batch: iter_time=1.727e-04, forward_time=0.131, uma_reduction=0.211, text_vs_uma=0.456, loss_ctc=5.391, loss=2.696, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.080e-04, train_time=0.874
[alab02] 2024-08-29 08:00:17,701 (trainer:720) INFO: 49epoch:train:4801-5000batch: iter_time=1.797e-04, forward_time=0.130, uma_reduction=0.213, text_vs_uma=0.456, loss_ctc=5.443, loss=2.721, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.079e-04, train_time=0.861
[alab02] 2024-08-29 08:01:44,618 (trainer:720) INFO: 49epoch:train:5001-5200batch: iter_time=1.675e-04, forward_time=0.129, uma_reduction=0.213, text_vs_uma=0.453, loss_ctc=5.002, loss=2.501, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.079e-04, train_time=0.869
[alab02] 2024-08-29 08:03:13,265 (trainer:720) INFO: 49epoch:train:5201-5400batch: iter_time=1.637e-04, forward_time=0.133, uma_reduction=0.217, text_vs_uma=0.441, loss_ctc=5.198, loss=2.599, backward_time=0.184, optim_step_time=0.032, optim0_lr0=2.078e-04, train_time=0.886
[alab02] 2024-08-29 08:04:41,335 (trainer:720) INFO: 49epoch:train:5401-5600batch: iter_time=1.750e-04, forward_time=0.133, uma_reduction=0.221, text_vs_uma=0.437, loss_ctc=4.707, loss=2.354, backward_time=0.185, optim_step_time=0.032, optim0_lr0=2.077e-04, train_time=0.880
[alab02] 2024-08-29 08:06:08,349 (trainer:720) INFO: 49epoch:train:5601-5800batch: iter_time=1.746e-04, forward_time=0.131, uma_reduction=0.226, text_vs_uma=0.423, loss_ctc=4.609, loss=2.305, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.077e-04, train_time=0.870
[alab02] 2024-08-29 08:07:36,423 (trainer:720) INFO: 49epoch:train:5801-6000batch: iter_time=1.990e-04, forward_time=0.132, uma_reduction=0.221, text_vs_uma=0.430, loss_ctc=5.022, loss=2.511, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.076e-04, train_time=0.880
[alab02] 2024-08-29 08:09:03,854 (trainer:720) INFO: 49epoch:train:6001-6200batch: iter_time=1.940e-04, forward_time=0.132, uma_reduction=0.216, text_vs_uma=0.447, loss_ctc=5.504, loss=2.752, backward_time=0.175, optim_step_time=0.034, optim0_lr0=2.076e-04, train_time=0.874
[alab02] 2024-08-29 08:10:33,003 (trainer:720) INFO: 49epoch:train:6201-6400batch: iter_time=2.018e-04, forward_time=0.135, uma_reduction=0.220, text_vs_uma=0.433, loss_ctc=4.936, loss=2.468, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.075e-04, train_time=0.891
[alab02] 2024-08-29 08:12:02,831 (trainer:720) INFO: 49epoch:train:6401-6600batch: iter_time=1.946e-04, forward_time=0.136, uma_reduction=0.226, text_vs_uma=0.424, loss_ctc=4.848, loss=2.424, backward_time=0.187, optim_step_time=0.034, optim0_lr0=2.074e-04, train_time=0.898
[alab02] 2024-08-29 08:13:32,205 (trainer:720) INFO: 49epoch:train:6601-6800batch: iter_time=2.033e-04, forward_time=0.135, uma_reduction=0.223, text_vs_uma=0.421, loss_ctc=4.534, loss=2.267, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.074e-04, train_time=0.893
[alab02] 2024-08-29 08:15:01,309 (trainer:720) INFO: 49epoch:train:6801-7000batch: iter_time=1.832e-04, forward_time=0.133, uma_reduction=0.228, text_vs_uma=0.431, loss_ctc=5.260, loss=2.630, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.073e-04, train_time=0.891
[alab02] 2024-08-29 08:16:16,319 (trainer:338) INFO: 49epoch results: [train] iter_time=2.541e-04, forward_time=0.134, uma_reduction=0.216, text_vs_uma=0.445, loss_ctc=5.055, loss=2.528, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.083e-04, train_time=0.885, time=52 minutes and 34.74 seconds, total_count=349174, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.224, text_vs_uma=0.483, loss_ctc=3.668, cer_ctc=0.096, cer=0.096, loss=3.668, time=6.01 seconds, total_count=1274, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.19 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 08:16:22,252 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 08:16:22,259 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/34epoch.pth
[alab02] 2024-08-29 08:16:22,259 (trainer:272) INFO: 50/150epoch started. Estimated time to finish: 3 days, 21 hours and 26 minutes
[alab02] 2024-08-29 08:17:52,673 (trainer:720) INFO: 50epoch:train:1-200batch: iter_time=0.002, forward_time=0.135, uma_reduction=0.217, text_vs_uma=0.445, loss_ctc=4.696, loss=2.348, backward_time=0.189, optim_step_time=0.034, optim0_lr0=2.072e-04, train_time=0.904
[alab02] 2024-08-29 08:19:21,239 (trainer:720) INFO: 50epoch:train:201-400batch: iter_time=2.202e-04, forward_time=0.134, uma_reduction=0.213, text_vs_uma=0.446, loss_ctc=4.921, loss=2.461, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.072e-04, train_time=0.885
[alab02] 2024-08-29 08:20:49,257 (trainer:720) INFO: 50epoch:train:401-600batch: iter_time=2.031e-04, forward_time=0.133, uma_reduction=0.211, text_vs_uma=0.450, loss_ctc=5.069, loss=2.535, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.071e-04, train_time=0.880
[alab02] 2024-08-29 08:22:14,723 (trainer:720) INFO: 50epoch:train:601-800batch: iter_time=1.913e-04, forward_time=0.130, uma_reduction=0.220, text_vs_uma=0.437, loss_ctc=5.115, loss=2.558, backward_time=0.171, optim_step_time=0.034, optim0_lr0=2.071e-04, train_time=0.854
[alab02] 2024-08-29 08:23:43,134 (trainer:720) INFO: 50epoch:train:801-1000batch: iter_time=2.080e-04, forward_time=0.134, uma_reduction=0.227, text_vs_uma=0.423, loss_ctc=4.676, loss=2.338, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.070e-04, train_time=0.884
[alab02] 2024-08-29 08:25:11,774 (trainer:720) INFO: 50epoch:train:1001-1200batch: iter_time=2.060e-04, forward_time=0.133, uma_reduction=0.223, text_vs_uma=0.432, loss_ctc=4.905, loss=2.452, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.069e-04, train_time=0.886
[alab02] 2024-08-29 08:26:36,653 (trainer:720) INFO: 50epoch:train:1201-1400batch: iter_time=1.875e-04, forward_time=0.127, uma_reduction=0.216, text_vs_uma=0.441, loss_ctc=5.062, loss=2.531, backward_time=0.172, optim_step_time=0.034, optim0_lr0=2.069e-04, train_time=0.849
[alab02] 2024-08-29 08:28:05,542 (trainer:720) INFO: 50epoch:train:1401-1600batch: iter_time=1.941e-04, forward_time=0.135, uma_reduction=0.216, text_vs_uma=0.432, loss_ctc=5.074, loss=2.537, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.068e-04, train_time=0.889
[alab02] 2024-08-29 08:29:33,800 (trainer:720) INFO: 50epoch:train:1601-1800batch: iter_time=2.127e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.444, loss_ctc=4.895, loss=2.448, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.068e-04, train_time=0.882
[alab02] 2024-08-29 08:31:04,498 (trainer:720) INFO: 50epoch:train:1801-2000batch: iter_time=2.211e-04, forward_time=0.137, uma_reduction=0.218, text_vs_uma=0.435, loss_ctc=5.017, loss=2.508, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.067e-04, train_time=0.907
[alab02] 2024-08-29 08:32:34,065 (trainer:720) INFO: 50epoch:train:2001-2200batch: iter_time=2.014e-04, forward_time=0.135, uma_reduction=0.219, text_vs_uma=0.452, loss_ctc=5.008, loss=2.504, backward_time=0.188, optim_step_time=0.035, optim0_lr0=2.066e-04, train_time=0.895
[alab02] 2024-08-29 08:34:04,284 (trainer:720) INFO: 50epoch:train:2201-2400batch: iter_time=2.132e-04, forward_time=0.136, uma_reduction=0.215, text_vs_uma=0.450, loss_ctc=5.208, loss=2.604, backward_time=0.188, optim_step_time=0.034, optim0_lr0=2.066e-04, train_time=0.902
[alab02] 2024-08-29 08:35:33,585 (trainer:720) INFO: 50epoch:train:2401-2600batch: iter_time=2.258e-04, forward_time=0.136, uma_reduction=0.216, text_vs_uma=0.440, loss_ctc=5.296, loss=2.648, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.065e-04, train_time=0.893
[alab02] 2024-08-29 08:37:02,726 (trainer:720) INFO: 50epoch:train:2601-2800batch: iter_time=2.108e-04, forward_time=0.135, uma_reduction=0.217, text_vs_uma=0.431, loss_ctc=4.893, loss=2.447, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.065e-04, train_time=0.891
[alab02] 2024-08-29 08:38:29,637 (trainer:720) INFO: 50epoch:train:2801-3000batch: iter_time=2.019e-04, forward_time=0.131, uma_reduction=0.216, text_vs_uma=0.447, loss_ctc=5.265, loss=2.633, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.064e-04, train_time=0.869
[alab02] 2024-08-29 08:39:56,750 (trainer:720) INFO: 50epoch:train:3001-3200batch: iter_time=2.046e-04, forward_time=0.131, uma_reduction=0.222, text_vs_uma=0.434, loss_ctc=4.945, loss=2.472, backward_time=0.177, optim_step_time=0.036, optim0_lr0=2.063e-04, train_time=0.871
[alab02] 2024-08-29 08:41:23,375 (trainer:720) INFO: 50epoch:train:3201-3400batch: iter_time=2.019e-04, forward_time=0.132, uma_reduction=0.223, text_vs_uma=0.443, loss_ctc=5.154, loss=2.577, backward_time=0.175, optim_step_time=0.035, optim0_lr0=2.063e-04, train_time=0.866
[alab02] 2024-08-29 08:42:48,528 (trainer:720) INFO: 50epoch:train:3401-3600batch: iter_time=1.843e-04, forward_time=0.128, uma_reduction=0.221, text_vs_uma=0.441, loss_ctc=4.969, loss=2.485, backward_time=0.175, optim_step_time=0.034, optim0_lr0=2.062e-04, train_time=0.851
[alab02] 2024-08-29 08:44:16,640 (trainer:720) INFO: 50epoch:train:3601-3800batch: iter_time=1.876e-04, forward_time=0.132, uma_reduction=0.218, text_vs_uma=0.442, loss_ctc=5.138, loss=2.569, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.062e-04, train_time=0.881
[alab02] 2024-08-29 08:45:44,615 (trainer:720) INFO: 50epoch:train:3801-4000batch: iter_time=1.835e-04, forward_time=0.132, uma_reduction=0.218, text_vs_uma=0.436, loss_ctc=4.712, loss=2.356, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.061e-04, train_time=0.879
[alab02] 2024-08-29 08:47:10,503 (trainer:720) INFO: 50epoch:train:4001-4200batch: iter_time=1.768e-04, forward_time=0.129, uma_reduction=0.220, text_vs_uma=0.448, loss_ctc=4.807, loss=2.404, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.061e-04, train_time=0.859
[alab02] 2024-08-29 08:48:38,904 (trainer:720) INFO: 50epoch:train:4201-4400batch: iter_time=1.820e-04, forward_time=0.133, uma_reduction=0.222, text_vs_uma=0.441, loss_ctc=5.348, loss=2.674, backward_time=0.182, optim_step_time=0.033, optim0_lr0=2.060e-04, train_time=0.884
[alab02] 2024-08-29 08:50:06,479 (trainer:720) INFO: 50epoch:train:4401-4600batch: iter_time=1.844e-04, forward_time=0.132, uma_reduction=0.220, text_vs_uma=0.436, loss_ctc=4.963, loss=2.482, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.059e-04, train_time=0.876
[alab02] 2024-08-29 08:51:33,889 (trainer:720) INFO: 50epoch:train:4601-4800batch: iter_time=1.861e-04, forward_time=0.132, uma_reduction=0.220, text_vs_uma=0.434, loss_ctc=4.986, loss=2.493, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.059e-04, train_time=0.874
[alab02] 2024-08-29 08:52:58,946 (trainer:720) INFO: 50epoch:train:4801-5000batch: iter_time=1.962e-04, forward_time=0.127, uma_reduction=0.225, text_vs_uma=0.425, loss_ctc=4.740, loss=2.370, backward_time=0.176, optim_step_time=0.035, optim0_lr0=2.058e-04, train_time=0.850
[alab02] 2024-08-29 08:54:28,187 (trainer:720) INFO: 50epoch:train:5001-5200batch: iter_time=2.178e-04, forward_time=0.135, uma_reduction=0.219, text_vs_uma=0.437, loss_ctc=4.989, loss=2.494, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.058e-04, train_time=0.892
[alab02] 2024-08-29 08:55:55,617 (trainer:720) INFO: 50epoch:train:5201-5400batch: iter_time=1.975e-04, forward_time=0.133, uma_reduction=0.216, text_vs_uma=0.444, loss_ctc=5.129, loss=2.564, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.057e-04, train_time=0.874
[alab02] 2024-08-29 08:57:24,201 (trainer:720) INFO: 50epoch:train:5401-5600batch: iter_time=2.084e-04, forward_time=0.134, uma_reduction=0.218, text_vs_uma=0.441, loss_ctc=4.804, loss=2.402, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.057e-04, train_time=0.886
[alab02] 2024-08-29 08:58:52,612 (trainer:720) INFO: 50epoch:train:5601-5800batch: iter_time=1.842e-04, forward_time=0.133, uma_reduction=0.217, text_vs_uma=0.452, loss_ctc=5.315, loss=2.657, backward_time=0.179, optim_step_time=0.035, optim0_lr0=2.056e-04, train_time=0.884
[alab02] 2024-08-29 09:00:20,765 (trainer:720) INFO: 50epoch:train:5801-6000batch: iter_time=1.869e-04, forward_time=0.133, uma_reduction=0.213, text_vs_uma=0.446, loss_ctc=5.187, loss=2.594, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.055e-04, train_time=0.881
[alab02] 2024-08-29 09:01:46,783 (trainer:720) INFO: 50epoch:train:6001-6200batch: iter_time=1.831e-04, forward_time=0.130, uma_reduction=0.218, text_vs_uma=0.444, loss_ctc=5.005, loss=2.502, backward_time=0.178, optim_step_time=0.033, optim0_lr0=2.055e-04, train_time=0.860
[alab02] 2024-08-29 09:03:13,985 (trainer:720) INFO: 50epoch:train:6201-6400batch: iter_time=1.852e-04, forward_time=0.131, uma_reduction=0.224, text_vs_uma=0.431, loss_ctc=4.756, loss=2.378, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.054e-04, train_time=0.872
[alab02] 2024-08-29 09:04:43,423 (trainer:720) INFO: 50epoch:train:6401-6600batch: iter_time=2.135e-04, forward_time=0.136, uma_reduction=0.225, text_vs_uma=0.431, loss_ctc=5.209, loss=2.605, backward_time=0.181, optim_step_time=0.036, optim0_lr0=2.054e-04, train_time=0.894
[alab02] 2024-08-29 09:06:11,561 (trainer:720) INFO: 50epoch:train:6601-6800batch: iter_time=1.984e-04, forward_time=0.134, uma_reduction=0.223, text_vs_uma=0.423, loss_ctc=4.961, loss=2.480, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.053e-04, train_time=0.881
[alab02] 2024-08-29 09:07:41,698 (trainer:720) INFO: 50epoch:train:6801-7000batch: iter_time=2.445e-04, forward_time=0.137, uma_reduction=0.224, text_vs_uma=0.435, loss_ctc=5.085, loss=2.543, backward_time=0.183, optim_step_time=0.038, optim0_lr0=2.052e-04, train_time=0.901
[alab02] 2024-08-29 09:09:00,850 (trainer:338) INFO: 50epoch results: [train] iter_time=2.539e-04, forward_time=0.133, uma_reduction=0.219, text_vs_uma=0.439, loss_ctc=4.997, loss=2.499, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.062e-04, train_time=0.880, time=52 minutes and 16.93 seconds, total_count=356300, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.230, text_vs_uma=0.472, loss_ctc=3.613, cer_ctc=0.092, cer=0.092, loss=3.613, time=6.76 seconds, total_count=1300, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.9 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 09:09:06,998 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-29 09:09:07,004 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/43epoch.pth
[alab02] 2024-08-29 09:09:07,004 (trainer:272) INFO: 51/150epoch started. Estimated time to finish: 3 days, 20 hours and 25 minutes
[alab02] 2024-08-29 09:10:36,347 (trainer:720) INFO: 51epoch:train:1-200batch: iter_time=0.002, forward_time=0.134, uma_reduction=0.216, text_vs_uma=0.446, loss_ctc=4.897, loss=2.449, backward_time=0.181, optim_step_time=0.037, optim0_lr0=2.052e-04, train_time=0.893
[alab02] 2024-08-29 09:12:04,351 (trainer:720) INFO: 51epoch:train:201-400batch: iter_time=3.084e-04, forward_time=0.135, uma_reduction=0.218, text_vs_uma=0.445, loss_ctc=5.149, loss=2.575, backward_time=0.179, optim_step_time=0.037, optim0_lr0=2.051e-04, train_time=0.880
[alab02] 2024-08-29 09:13:31,658 (trainer:720) INFO: 51epoch:train:401-600batch: iter_time=2.632e-04, forward_time=0.133, uma_reduction=0.222, text_vs_uma=0.433, loss_ctc=4.799, loss=2.399, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.050e-04, train_time=0.873
[alab02] 2024-08-29 09:15:01,060 (trainer:720) INFO: 51epoch:train:601-800batch: iter_time=2.203e-04, forward_time=0.136, uma_reduction=0.222, text_vs_uma=0.430, loss_ctc=4.518, loss=2.259, backward_time=0.189, optim_step_time=0.036, optim0_lr0=2.050e-04, train_time=0.894
[alab02] 2024-08-29 09:16:30,256 (trainer:720) INFO: 51epoch:train:801-1000batch: iter_time=2.096e-04, forward_time=0.135, uma_reduction=0.223, text_vs_uma=0.422, loss_ctc=4.392, loss=2.196, backward_time=0.191, optim_step_time=0.034, optim0_lr0=2.049e-04, train_time=0.892
[alab02] 2024-08-29 09:17:57,763 (trainer:720) INFO: 51epoch:train:1001-1200batch: iter_time=1.849e-04, forward_time=0.132, uma_reduction=0.224, text_vs_uma=0.425, loss_ctc=4.679, loss=2.339, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.049e-04, train_time=0.875
[alab02] 2024-08-29 09:19:23,828 (trainer:720) INFO: 51epoch:train:1201-1400batch: iter_time=2.069e-04, forward_time=0.129, uma_reduction=0.225, text_vs_uma=0.423, loss_ctc=4.729, loss=2.365, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.048e-04, train_time=0.860
[alab02] 2024-08-29 09:20:51,308 (trainer:720) INFO: 51epoch:train:1401-1600batch: iter_time=2.053e-04, forward_time=0.132, uma_reduction=0.224, text_vs_uma=0.423, loss_ctc=4.557, loss=2.278, backward_time=0.182, optim_step_time=0.035, optim0_lr0=2.047e-04, train_time=0.875
[alab02] 2024-08-29 09:22:19,656 (trainer:720) INFO: 51epoch:train:1601-1800batch: iter_time=1.972e-04, forward_time=0.132, uma_reduction=0.227, text_vs_uma=0.430, loss_ctc=4.961, loss=2.480, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.047e-04, train_time=0.883
[alab02] 2024-08-29 09:23:47,193 (trainer:720) INFO: 51epoch:train:1801-2000batch: iter_time=1.924e-04, forward_time=0.131, uma_reduction=0.226, text_vs_uma=0.421, loss_ctc=4.507, loss=2.254, backward_time=0.185, optim_step_time=0.033, optim0_lr0=2.046e-04, train_time=0.875
[alab02] 2024-08-29 09:25:12,298 (trainer:720) INFO: 51epoch:train:2001-2200batch: iter_time=1.780e-04, forward_time=0.128, uma_reduction=0.219, text_vs_uma=0.435, loss_ctc=4.760, loss=2.380, backward_time=0.176, optim_step_time=0.033, optim0_lr0=2.046e-04, train_time=0.851
[alab02] 2024-08-29 09:26:40,040 (trainer:720) INFO: 51epoch:train:2201-2400batch: iter_time=1.810e-04, forward_time=0.133, uma_reduction=0.221, text_vs_uma=0.428, loss_ctc=4.857, loss=2.428, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.045e-04, train_time=0.877
[alab02] 2024-08-29 09:28:09,311 (trainer:720) INFO: 51epoch:train:2401-2600batch: iter_time=2.078e-04, forward_time=0.135, uma_reduction=0.226, text_vs_uma=0.416, loss_ctc=4.714, loss=2.357, backward_time=0.189, optim_step_time=0.034, optim0_lr0=2.045e-04, train_time=0.892
[alab02] 2024-08-29 09:29:38,366 (trainer:720) INFO: 51epoch:train:2601-2800batch: iter_time=2.149e-04, forward_time=0.134, uma_reduction=0.227, text_vs_uma=0.415, loss_ctc=4.533, loss=2.266, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.044e-04, train_time=0.890
[alab02] 2024-08-29 09:31:08,804 (trainer:720) INFO: 51epoch:train:2801-3000batch: iter_time=1.991e-04, forward_time=0.137, uma_reduction=0.226, text_vs_uma=0.422, loss_ctc=4.804, loss=2.402, backward_time=0.189, optim_step_time=0.033, optim0_lr0=2.044e-04, train_time=0.904
[alab02] 2024-08-29 09:32:38,656 (trainer:720) INFO: 51epoch:train:3001-3200batch: iter_time=1.986e-04, forward_time=0.135, uma_reduction=0.232, text_vs_uma=0.410, loss_ctc=4.808, loss=2.404, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.043e-04, train_time=0.898
[alab02] 2024-08-29 09:34:07,078 (trainer:720) INFO: 51epoch:train:3201-3400batch: iter_time=2.055e-04, forward_time=0.134, uma_reduction=0.229, text_vs_uma=0.418, loss_ctc=4.571, loss=2.285, backward_time=0.184, optim_step_time=0.036, optim0_lr0=2.042e-04, train_time=0.884
[alab02] 2024-08-29 09:35:34,928 (trainer:720) INFO: 51epoch:train:3401-3600batch: iter_time=1.998e-04, forward_time=0.131, uma_reduction=0.225, text_vs_uma=0.437, loss_ctc=4.937, loss=2.468, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.042e-04, train_time=0.878
[alab02] 2024-08-29 09:37:03,690 (trainer:720) INFO: 51epoch:train:3601-3800batch: iter_time=1.949e-04, forward_time=0.133, uma_reduction=0.219, text_vs_uma=0.442, loss_ctc=4.869, loss=2.435, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.041e-04, train_time=0.887
[alab02] 2024-08-29 09:38:32,811 (trainer:720) INFO: 51epoch:train:3801-4000batch: iter_time=1.948e-04, forward_time=0.133, uma_reduction=0.227, text_vs_uma=0.424, loss_ctc=4.656, loss=2.328, backward_time=0.186, optim_step_time=0.036, optim0_lr0=2.041e-04, train_time=0.891
[alab02] 2024-08-29 09:39:59,841 (trainer:720) INFO: 51epoch:train:4001-4200batch: iter_time=1.865e-04, forward_time=0.130, uma_reduction=0.231, text_vs_uma=0.411, loss_ctc=4.634, loss=2.317, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.040e-04, train_time=0.870
[alab02] 2024-08-29 09:41:28,105 (trainer:720) INFO: 51epoch:train:4201-4400batch: iter_time=1.865e-04, forward_time=0.132, uma_reduction=0.225, text_vs_uma=0.422, loss_ctc=4.613, loss=2.306, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.040e-04, train_time=0.882
[alab02] 2024-08-29 09:42:54,591 (trainer:720) INFO: 51epoch:train:4401-4600batch: iter_time=1.863e-04, forward_time=0.129, uma_reduction=0.225, text_vs_uma=0.420, loss_ctc=4.607, loss=2.304, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.039e-04, train_time=0.865
[alab02] 2024-08-29 09:44:22,801 (trainer:720) INFO: 51epoch:train:4601-4800batch: iter_time=2.001e-04, forward_time=0.133, uma_reduction=0.223, text_vs_uma=0.422, loss_ctc=4.510, loss=2.255, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.038e-04, train_time=0.882
[alab02] 2024-08-29 09:45:53,679 (trainer:720) INFO: 51epoch:train:4801-5000batch: iter_time=1.891e-04, forward_time=0.136, uma_reduction=0.227, text_vs_uma=0.430, loss_ctc=4.841, loss=2.421, backward_time=0.189, optim_step_time=0.034, optim0_lr0=2.038e-04, train_time=0.909
[alab02] 2024-08-29 09:47:19,874 (trainer:720) INFO: 51epoch:train:5001-5200batch: iter_time=1.789e-04, forward_time=0.130, uma_reduction=0.221, text_vs_uma=0.439, loss_ctc=5.024, loss=2.512, backward_time=0.176, optim_step_time=0.033, optim0_lr0=2.037e-04, train_time=0.862
[alab02] 2024-08-29 09:48:45,831 (trainer:720) INFO: 51epoch:train:5201-5400batch: iter_time=1.922e-04, forward_time=0.129, uma_reduction=0.219, text_vs_uma=0.437, loss_ctc=4.721, loss=2.361, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.037e-04, train_time=0.859
[alab02] 2024-08-29 09:50:14,241 (trainer:720) INFO: 51epoch:train:5401-5600batch: iter_time=1.884e-04, forward_time=0.133, uma_reduction=0.221, text_vs_uma=0.431, loss_ctc=4.947, loss=2.473, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.036e-04, train_time=0.884
[alab02] 2024-08-29 09:51:40,459 (trainer:720) INFO: 51epoch:train:5601-5800batch: iter_time=1.948e-04, forward_time=0.129, uma_reduction=0.224, text_vs_uma=0.432, loss_ctc=4.930, loss=2.465, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.036e-04, train_time=0.862
[alab02] 2024-08-29 09:53:08,640 (trainer:720) INFO: 51epoch:train:5801-6000batch: iter_time=1.795e-04, forward_time=0.132, uma_reduction=0.226, text_vs_uma=0.418, loss_ctc=4.583, loss=2.291, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.035e-04, train_time=0.882
[alab02] 2024-08-29 09:54:37,913 (trainer:720) INFO: 51epoch:train:6001-6200batch: iter_time=2.116e-04, forward_time=0.135, uma_reduction=0.222, text_vs_uma=0.428, loss_ctc=4.913, loss=2.457, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.034e-04, train_time=0.893
[alab02] 2024-08-29 09:56:07,000 (trainer:720) INFO: 51epoch:train:6201-6400batch: iter_time=1.965e-04, forward_time=0.135, uma_reduction=0.217, text_vs_uma=0.443, loss_ctc=5.293, loss=2.647, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.034e-04, train_time=0.891
[alab02] 2024-08-29 09:57:33,223 (trainer:720) INFO: 51epoch:train:6401-6600batch: iter_time=2.228e-04, forward_time=0.129, uma_reduction=0.223, text_vs_uma=0.438, loss_ctc=4.581, loss=2.291, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.033e-04, train_time=0.862
[alab02] 2024-08-29 09:59:01,021 (trainer:720) INFO: 51epoch:train:6601-6800batch: iter_time=1.875e-04, forward_time=0.133, uma_reduction=0.219, text_vs_uma=0.438, loss_ctc=4.878, loss=2.439, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.033e-04, train_time=0.878
[alab02] 2024-08-29 10:00:28,701 (trainer:720) INFO: 51epoch:train:6801-7000batch: iter_time=1.753e-04, forward_time=0.131, uma_reduction=0.224, text_vs_uma=0.424, loss_ctc=4.605, loss=2.302, backward_time=0.183, optim_step_time=0.033, optim0_lr0=2.032e-04, train_time=0.877
[alab02] 2024-08-29 10:01:45,781 (trainer:338) INFO: 51epoch results: [train] iter_time=2.500e-04, forward_time=0.133, uma_reduction=0.224, text_vs_uma=0.428, loss_ctc=4.749, loss=2.374, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.042e-04, train_time=0.881, time=52 minutes and 19.56 seconds, total_count=363426, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.256, text_vs_uma=0.423, loss_ctc=3.548, cer_ctc=0.099, cer=0.099, loss=3.548, time=6.04 seconds, total_count=1326, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.18 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 10:01:51,397 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 10:01:51,407 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/48epoch.pth
[alab02] 2024-08-29 10:01:51,407 (trainer:272) INFO: 52/150epoch started. Estimated time to finish: 3 days, 19 hours and 24 minutes
[alab02] 2024-08-29 10:03:20,906 (trainer:720) INFO: 52epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.224, text_vs_uma=0.445, loss_ctc=4.962, loss=2.481, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.031e-04, train_time=0.895
[alab02] 2024-08-29 10:04:48,877 (trainer:720) INFO: 52epoch:train:201-400batch: iter_time=2.118e-04, forward_time=0.132, uma_reduction=0.223, text_vs_uma=0.423, loss_ctc=4.588, loss=2.294, backward_time=0.184, optim_step_time=0.033, optim0_lr0=2.031e-04, train_time=0.879
[alab02] 2024-08-29 10:06:15,640 (trainer:720) INFO: 52epoch:train:401-600batch: iter_time=2.128e-04, forward_time=0.129, uma_reduction=0.231, text_vs_uma=0.425, loss_ctc=4.662, loss=2.331, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.030e-04, train_time=0.867
[alab02] 2024-08-29 10:07:45,442 (trainer:720) INFO: 52epoch:train:601-800batch: iter_time=1.955e-04, forward_time=0.136, uma_reduction=0.231, text_vs_uma=0.415, loss_ctc=4.695, loss=2.348, backward_time=0.185, optim_step_time=0.035, optim0_lr0=2.030e-04, train_time=0.898
[alab02] 2024-08-29 10:09:11,785 (trainer:720) INFO: 52epoch:train:801-1000batch: iter_time=2.945e-04, forward_time=0.130, uma_reduction=0.230, text_vs_uma=0.422, loss_ctc=4.711, loss=2.355, backward_time=0.175, optim_step_time=0.035, optim0_lr0=2.029e-04, train_time=0.863
[alab02] 2024-08-29 10:10:38,858 (trainer:720) INFO: 52epoch:train:1001-1200batch: iter_time=2.032e-04, forward_time=0.130, uma_reduction=0.229, text_vs_uma=0.422, loss_ctc=4.940, loss=2.470, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.029e-04, train_time=0.870
[alab02] 2024-08-29 10:12:05,095 (trainer:720) INFO: 52epoch:train:1201-1400batch: iter_time=1.985e-04, forward_time=0.129, uma_reduction=0.233, text_vs_uma=0.401, loss_ctc=4.527, loss=2.263, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.028e-04, train_time=0.862
[alab02] 2024-08-29 10:13:31,642 (trainer:720) INFO: 52epoch:train:1401-1600batch: iter_time=2.024e-04, forward_time=0.130, uma_reduction=0.235, text_vs_uma=0.410, loss_ctc=4.791, loss=2.396, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.027e-04, train_time=0.865
[alab02] 2024-08-29 10:15:00,150 (trainer:720) INFO: 52epoch:train:1601-1800batch: iter_time=1.930e-04, forward_time=0.134, uma_reduction=0.233, text_vs_uma=0.415, loss_ctc=4.662, loss=2.331, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.027e-04, train_time=0.885
[alab02] 2024-08-29 10:16:28,418 (trainer:720) INFO: 52epoch:train:1801-2000batch: iter_time=1.831e-04, forward_time=0.133, uma_reduction=0.225, text_vs_uma=0.439, loss_ctc=5.154, loss=2.577, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.026e-04, train_time=0.882
[alab02] 2024-08-29 10:17:56,860 (trainer:720) INFO: 52epoch:train:2001-2200batch: iter_time=1.893e-04, forward_time=0.133, uma_reduction=0.231, text_vs_uma=0.412, loss_ctc=4.823, loss=2.412, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.026e-04, train_time=0.884
[alab02] 2024-08-29 10:19:24,950 (trainer:720) INFO: 52epoch:train:2201-2400batch: iter_time=1.912e-04, forward_time=0.133, uma_reduction=0.229, text_vs_uma=0.419, loss_ctc=4.919, loss=2.460, backward_time=0.181, optim_step_time=0.033, optim0_lr0=2.025e-04, train_time=0.881
[alab02] 2024-08-29 10:20:52,547 (trainer:720) INFO: 52epoch:train:2401-2600batch: iter_time=1.988e-04, forward_time=0.132, uma_reduction=0.230, text_vs_uma=0.417, loss_ctc=4.662, loss=2.331, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.025e-04, train_time=0.876
[alab02] 2024-08-29 10:22:20,301 (trainer:720) INFO: 52epoch:train:2601-2800batch: iter_time=2.005e-04, forward_time=0.132, uma_reduction=0.229, text_vs_uma=0.421, loss_ctc=4.819, loss=2.410, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.024e-04, train_time=0.877
[alab02] 2024-08-29 10:23:49,364 (trainer:720) INFO: 52epoch:train:2801-3000batch: iter_time=1.815e-04, forward_time=0.134, uma_reduction=0.226, text_vs_uma=0.426, loss_ctc=5.112, loss=2.556, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.024e-04, train_time=0.890
[alab02] 2024-08-29 10:25:19,349 (trainer:720) INFO: 52epoch:train:3001-3200batch: iter_time=2.014e-04, forward_time=0.136, uma_reduction=0.226, text_vs_uma=0.414, loss_ctc=4.412, loss=2.206, backward_time=0.189, optim_step_time=0.035, optim0_lr0=2.023e-04, train_time=0.900
[alab02] 2024-08-29 10:26:47,421 (trainer:720) INFO: 52epoch:train:3201-3400batch: iter_time=2.041e-04, forward_time=0.133, uma_reduction=0.228, text_vs_uma=0.422, loss_ctc=4.798, loss=2.399, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.022e-04, train_time=0.880
[alab02] 2024-08-29 10:28:17,998 (trainer:720) INFO: 52epoch:train:3401-3600batch: iter_time=2.843e-04, forward_time=0.138, uma_reduction=0.226, text_vs_uma=0.433, loss_ctc=4.805, loss=2.403, backward_time=0.190, optim_step_time=0.036, optim0_lr0=2.022e-04, train_time=0.905
[alab02] 2024-08-29 10:29:47,413 (trainer:720) INFO: 52epoch:train:3601-3800batch: iter_time=2.066e-04, forward_time=0.135, uma_reduction=0.233, text_vs_uma=0.407, loss_ctc=4.493, loss=2.247, backward_time=0.184, optim_step_time=0.037, optim0_lr0=2.021e-04, train_time=0.894
[alab02] 2024-08-29 10:31:16,177 (trainer:720) INFO: 52epoch:train:3801-4000batch: iter_time=2.147e-04, forward_time=0.133, uma_reduction=0.234, text_vs_uma=0.417, loss_ctc=4.830, loss=2.415, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.021e-04, train_time=0.887
[alab02] 2024-08-29 10:32:46,013 (trainer:720) INFO: 52epoch:train:4001-4200batch: iter_time=2.230e-04, forward_time=0.135, uma_reduction=0.233, text_vs_uma=0.411, loss_ctc=5.048, loss=2.524, backward_time=0.182, optim_step_time=0.036, optim0_lr0=2.020e-04, train_time=0.898
[alab02] 2024-08-29 10:34:13,466 (trainer:720) INFO: 52epoch:train:4201-4400batch: iter_time=2.176e-04, forward_time=0.132, uma_reduction=0.230, text_vs_uma=0.418, loss_ctc=4.899, loss=2.450, backward_time=0.177, optim_step_time=0.036, optim0_lr0=2.020e-04, train_time=0.874
[alab02] 2024-08-29 10:35:40,960 (trainer:720) INFO: 52epoch:train:4401-4600batch: iter_time=2.058e-04, forward_time=0.132, uma_reduction=0.226, text_vs_uma=0.426, loss_ctc=4.898, loss=2.449, backward_time=0.180, optim_step_time=0.036, optim0_lr0=2.019e-04, train_time=0.875
[alab02] 2024-08-29 10:37:06,997 (trainer:720) INFO: 52epoch:train:4601-4800batch: iter_time=2.035e-04, forward_time=0.130, uma_reduction=0.229, text_vs_uma=0.418, loss_ctc=4.803, loss=2.401, backward_time=0.175, optim_step_time=0.035, optim0_lr0=2.019e-04, train_time=0.860
[alab02] 2024-08-29 10:38:35,962 (trainer:720) INFO: 52epoch:train:4801-5000batch: iter_time=2.236e-04, forward_time=0.134, uma_reduction=0.232, text_vs_uma=0.408, loss_ctc=4.702, loss=2.351, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.018e-04, train_time=0.889
[alab02] 2024-08-29 10:40:03,234 (trainer:720) INFO: 52epoch:train:5001-5200batch: iter_time=1.936e-04, forward_time=0.132, uma_reduction=0.225, text_vs_uma=0.417, loss_ctc=4.577, loss=2.289, backward_time=0.180, optim_step_time=0.035, optim0_lr0=2.017e-04, train_time=0.872
[alab02] 2024-08-29 10:41:31,241 (trainer:720) INFO: 52epoch:train:5201-5400batch: iter_time=1.901e-04, forward_time=0.133, uma_reduction=0.224, text_vs_uma=0.429, loss_ctc=4.924, loss=2.462, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.017e-04, train_time=0.880
[alab02] 2024-08-29 10:42:57,478 (trainer:720) INFO: 52epoch:train:5401-5600batch: iter_time=2.198e-04, forward_time=0.130, uma_reduction=0.233, text_vs_uma=0.419, loss_ctc=4.718, loss=2.359, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.016e-04, train_time=0.862
[alab02] 2024-08-29 10:44:23,073 (trainer:720) INFO: 52epoch:train:5601-5800batch: iter_time=1.805e-04, forward_time=0.128, uma_reduction=0.232, text_vs_uma=0.417, loss_ctc=4.739, loss=2.369, backward_time=0.173, optim_step_time=0.034, optim0_lr0=2.016e-04, train_time=0.856
[alab02] 2024-08-29 10:45:51,449 (trainer:720) INFO: 52epoch:train:5801-6000batch: iter_time=1.837e-04, forward_time=0.134, uma_reduction=0.239, text_vs_uma=0.399, loss_ctc=4.531, loss=2.266, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.015e-04, train_time=0.884
[alab02] 2024-08-29 10:47:17,549 (trainer:720) INFO: 52epoch:train:6001-6200batch: iter_time=1.898e-04, forward_time=0.129, uma_reduction=0.230, text_vs_uma=0.430, loss_ctc=4.952, loss=2.476, backward_time=0.175, optim_step_time=0.036, optim0_lr0=2.015e-04, train_time=0.861
[alab02] 2024-08-29 10:48:45,018 (trainer:720) INFO: 52epoch:train:6201-6400batch: iter_time=1.856e-04, forward_time=0.132, uma_reduction=0.226, text_vs_uma=0.425, loss_ctc=4.910, loss=2.455, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.014e-04, train_time=0.874
[alab02] 2024-08-29 10:50:12,346 (trainer:720) INFO: 52epoch:train:6401-6600batch: iter_time=1.755e-04, forward_time=0.130, uma_reduction=0.231, text_vs_uma=0.410, loss_ctc=4.886, loss=2.443, backward_time=0.179, optim_step_time=0.033, optim0_lr0=2.014e-04, train_time=0.873
[alab02] 2024-08-29 10:51:41,752 (trainer:720) INFO: 52epoch:train:6601-6800batch: iter_time=2.094e-04, forward_time=0.134, uma_reduction=0.226, text_vs_uma=0.421, loss_ctc=4.629, loss=2.314, backward_time=0.188, optim_step_time=0.036, optim0_lr0=2.013e-04, train_time=0.894
[alab02] 2024-08-29 10:53:10,659 (trainer:720) INFO: 52epoch:train:6801-7000batch: iter_time=2.004e-04, forward_time=0.135, uma_reduction=0.234, text_vs_uma=0.414, loss_ctc=4.702, loss=2.351, backward_time=0.185, optim_step_time=0.036, optim0_lr0=2.013e-04, train_time=0.889
[alab02] 2024-08-29 10:54:29,860 (trainer:338) INFO: 52epoch results: [train] iter_time=2.590e-04, forward_time=0.132, uma_reduction=0.229, text_vs_uma=0.419, loss_ctc=4.784, loss=2.392, backward_time=0.181, optim_step_time=0.035, optim0_lr0=2.022e-04, train_time=0.880, time=52 minutes and 16.15 seconds, total_count=370552, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.245, text_vs_uma=0.443, loss_ctc=3.541, cer_ctc=0.095, cer=0.095, loss=3.541, time=6.4 seconds, total_count=1352, gpu_max_cached_mem_GB=35.906, [att_plot] time=15.9 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 10:54:35,093 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 10:54:35,099 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/44epoch.pth
[alab02] 2024-08-29 10:54:35,100 (trainer:272) INFO: 53/150epoch started. Estimated time to finish: 3 days, 18 hours and 24 minutes
[alab02] 2024-08-29 10:56:05,300 (trainer:720) INFO: 53epoch:train:1-200batch: iter_time=0.002, forward_time=0.135, uma_reduction=0.235, text_vs_uma=0.404, loss_ctc=4.839, loss=2.420, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.012e-04, train_time=0.901
[alab02] 2024-08-29 10:57:33,827 (trainer:720) INFO: 53epoch:train:201-400batch: iter_time=2.113e-04, forward_time=0.134, uma_reduction=0.241, text_vs_uma=0.405, loss_ctc=4.813, loss=2.407, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.011e-04, train_time=0.885
[alab02] 2024-08-29 10:59:00,429 (trainer:720) INFO: 53epoch:train:401-600batch: iter_time=2.046e-04, forward_time=0.130, uma_reduction=0.236, text_vs_uma=0.401, loss_ctc=4.686, loss=2.343, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.011e-04, train_time=0.866
[alab02] 2024-08-29 11:00:29,238 (trainer:720) INFO: 53epoch:train:601-800batch: iter_time=2.292e-04, forward_time=0.134, uma_reduction=0.227, text_vs_uma=0.418, loss_ctc=4.870, loss=2.435, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.010e-04, train_time=0.888
[alab02] 2024-08-29 11:01:58,746 (trainer:720) INFO: 53epoch:train:801-1000batch: iter_time=2.036e-04, forward_time=0.135, uma_reduction=0.226, text_vs_uma=0.429, loss_ctc=4.816, loss=2.408, backward_time=0.186, optim_step_time=0.035, optim0_lr0=2.010e-04, train_time=0.895
[alab02] 2024-08-29 11:03:26,442 (trainer:720) INFO: 53epoch:train:1001-1200batch: iter_time=2.215e-04, forward_time=0.132, uma_reduction=0.224, text_vs_uma=0.429, loss_ctc=4.673, loss=2.336, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.009e-04, train_time=0.877
[alab02] 2024-08-29 11:04:54,502 (trainer:720) INFO: 53epoch:train:1201-1400batch: iter_time=2.137e-04, forward_time=0.133, uma_reduction=0.224, text_vs_uma=0.424, loss_ctc=4.656, loss=2.328, backward_time=0.183, optim_step_time=0.034, optim0_lr0=2.008e-04, train_time=0.880
[alab02] 2024-08-29 11:06:21,513 (trainer:720) INFO: 53epoch:train:1401-1600batch: iter_time=1.979e-04, forward_time=0.131, uma_reduction=0.225, text_vs_uma=0.427, loss_ctc=4.898, loss=2.449, backward_time=0.179, optim_step_time=0.034, optim0_lr0=2.008e-04, train_time=0.870
[alab02] 2024-08-29 11:07:48,729 (trainer:720) INFO: 53epoch:train:1601-1800batch: iter_time=2.083e-04, forward_time=0.131, uma_reduction=0.223, text_vs_uma=0.435, loss_ctc=4.942, loss=2.471, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.007e-04, train_time=0.872
[alab02] 2024-08-29 11:09:16,058 (trainer:720) INFO: 53epoch:train:1801-2000batch: iter_time=1.903e-04, forward_time=0.132, uma_reduction=0.229, text_vs_uma=0.427, loss_ctc=4.885, loss=2.442, backward_time=0.180, optim_step_time=0.034, optim0_lr0=2.007e-04, train_time=0.873
[alab02] 2024-08-29 11:10:42,738 (trainer:720) INFO: 53epoch:train:2001-2200batch: iter_time=1.820e-04, forward_time=0.131, uma_reduction=0.230, text_vs_uma=0.416, loss_ctc=4.862, loss=2.431, backward_time=0.178, optim_step_time=0.035, optim0_lr0=2.006e-04, train_time=0.867
[alab02] 2024-08-29 11:12:12,824 (trainer:720) INFO: 53epoch:train:2201-2400batch: iter_time=1.828e-04, forward_time=0.135, uma_reduction=0.228, text_vs_uma=0.418, loss_ctc=4.830, loss=2.415, backward_time=0.187, optim_step_time=0.035, optim0_lr0=2.006e-04, train_time=0.901
[alab02] 2024-08-29 11:13:42,117 (trainer:720) INFO: 53epoch:train:2401-2600batch: iter_time=1.951e-04, forward_time=0.134, uma_reduction=0.225, text_vs_uma=0.436, loss_ctc=5.006, loss=2.503, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.005e-04, train_time=0.893
[alab02] 2024-08-29 11:15:08,501 (trainer:720) INFO: 53epoch:train:2601-2800batch: iter_time=2.130e-04, forward_time=0.130, uma_reduction=0.223, text_vs_uma=0.423, loss_ctc=4.903, loss=2.452, backward_time=0.177, optim_step_time=0.034, optim0_lr0=2.005e-04, train_time=0.864
[alab02] 2024-08-29 11:16:36,653 (trainer:720) INFO: 53epoch:train:2801-3000batch: iter_time=1.961e-04, forward_time=0.133, uma_reduction=0.227, text_vs_uma=0.424, loss_ctc=4.697, loss=2.348, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.004e-04, train_time=0.881
[alab02] 2024-08-29 11:18:03,580 (trainer:720) INFO: 53epoch:train:3001-3200batch: iter_time=1.884e-04, forward_time=0.130, uma_reduction=0.227, text_vs_uma=0.429, loss_ctc=5.195, loss=2.597, backward_time=0.176, optim_step_time=0.034, optim0_lr0=2.004e-04, train_time=0.869
[alab02] 2024-08-29 11:19:32,180 (trainer:720) INFO: 53epoch:train:3201-3400batch: iter_time=2.097e-04, forward_time=0.134, uma_reduction=0.222, text_vs_uma=0.425, loss_ctc=4.832, loss=2.416, backward_time=0.184, optim_step_time=0.034, optim0_lr0=2.003e-04, train_time=0.886
[alab02] 2024-08-29 11:21:00,302 (trainer:720) INFO: 53epoch:train:3401-3600batch: iter_time=1.976e-04, forward_time=0.134, uma_reduction=0.225, text_vs_uma=0.422, loss_ctc=4.382, loss=2.191, backward_time=0.185, optim_step_time=0.034, optim0_lr0=2.003e-04, train_time=0.881
[alab02] 2024-08-29 11:22:28,402 (trainer:720) INFO: 53epoch:train:3601-3800batch: iter_time=1.855e-04, forward_time=0.132, uma_reduction=0.235, text_vs_uma=0.418, loss_ctc=5.080, loss=2.540, backward_time=0.181, optim_step_time=0.034, optim0_lr0=2.002e-04, train_time=0.881
[alab02] 2024-08-29 11:23:56,243 (trainer:720) INFO: 53epoch:train:3801-4000batch: iter_time=2.094e-04, forward_time=0.133, uma_reduction=0.231, text_vs_uma=0.416, loss_ctc=4.515, loss=2.257, backward_time=0.182, optim_step_time=0.034, optim0_lr0=2.001e-04, train_time=0.878
[alab02] 2024-08-29 11:25:23,055 (trainer:720) INFO: 53epoch:train:4001-4200batch: iter_time=1.905e-04, forward_time=0.131, uma_reduction=0.225, text_vs_uma=0.429, loss_ctc=4.958, loss=2.479, backward_time=0.178, optim_step_time=0.034, optim0_lr0=2.001e-04, train_time=0.868
[alab02] 2024-08-29 11:26:51,337 (trainer:720) INFO: 53epoch:train:4201-4400batch: iter_time=2.033e-04, forward_time=0.134, uma_reduction=0.223, text_vs_uma=0.432, loss_ctc=4.736, loss=2.368, backward_time=0.184, optim_step_time=0.035, optim0_lr0=2.000e-04, train_time=0.883
[alab02] 2024-08-29 11:28:19,754 (trainer:720) INFO: 53epoch:train:4401-4600batch: iter_time=2.048e-04, forward_time=0.134, uma_reduction=0.231, text_vs_uma=0.417, loss_ctc=4.567, loss=2.283, backward_time=0.183, optim_step_time=0.036, optim0_lr0=2.000e-04, train_time=0.884
[alab02] 2024-08-29 11:29:47,389 (trainer:720) INFO: 53epoch:train:4601-4800batch: iter_time=2.070e-04, forward_time=0.132, uma_reduction=0.234, text_vs_uma=0.423, loss_ctc=4.729, loss=2.365, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.999e-04, train_time=0.876
[alab02] 2024-08-29 11:31:19,453 (trainer:720) INFO: 53epoch:train:4801-5000batch: iter_time=2.286e-04, forward_time=0.140, uma_reduction=0.227, text_vs_uma=0.421, loss_ctc=4.683, loss=2.341, backward_time=0.192, optim_step_time=0.038, optim0_lr0=1.999e-04, train_time=0.920
[alab02] 2024-08-29 11:32:47,566 (trainer:720) INFO: 53epoch:train:5001-5200batch: iter_time=2.045e-04, forward_time=0.132, uma_reduction=0.224, text_vs_uma=0.435, loss_ctc=4.830, loss=2.415, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.998e-04, train_time=0.881
[alab02] 2024-08-29 11:34:16,022 (trainer:720) INFO: 53epoch:train:5201-5400batch: iter_time=1.994e-04, forward_time=0.134, uma_reduction=0.222, text_vs_uma=0.433, loss_ctc=4.836, loss=2.418, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.998e-04, train_time=0.884
[alab02] 2024-08-29 11:35:44,900 (trainer:720) INFO: 53epoch:train:5401-5600batch: iter_time=2.131e-04, forward_time=0.134, uma_reduction=0.221, text_vs_uma=0.429, loss_ctc=4.669, loss=2.334, backward_time=0.186, optim_step_time=0.036, optim0_lr0=1.997e-04, train_time=0.888
[alab02] 2024-08-29 11:37:11,032 (trainer:720) INFO: 53epoch:train:5601-5800batch: iter_time=2.250e-04, forward_time=0.130, uma_reduction=0.224, text_vs_uma=0.433, loss_ctc=5.103, loss=2.552, backward_time=0.175, optim_step_time=0.036, optim0_lr0=1.997e-04, train_time=0.861
[alab02] 2024-08-29 11:38:38,854 (trainer:720) INFO: 53epoch:train:5801-6000batch: iter_time=2.038e-04, forward_time=0.134, uma_reduction=0.221, text_vs_uma=0.434, loss_ctc=4.555, loss=2.278, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.996e-04, train_time=0.878
[alab02] 2024-08-29 11:40:08,054 (trainer:720) INFO: 53epoch:train:6001-6200batch: iter_time=1.962e-04, forward_time=0.135, uma_reduction=0.219, text_vs_uma=0.437, loss_ctc=4.731, loss=2.366, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.996e-04, train_time=0.892
[alab02] 2024-08-29 11:41:35,993 (trainer:720) INFO: 53epoch:train:6201-6400batch: iter_time=1.905e-04, forward_time=0.133, uma_reduction=0.218, text_vs_uma=0.431, loss_ctc=4.675, loss=2.338, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.995e-04, train_time=0.879
[alab02] 2024-08-29 11:43:05,927 (trainer:720) INFO: 53epoch:train:6401-6600batch: iter_time=1.847e-04, forward_time=0.135, uma_reduction=0.228, text_vs_uma=0.427, loss_ctc=5.410, loss=2.705, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.995e-04, train_time=0.899
[alab02] 2024-08-29 11:44:35,789 (trainer:720) INFO: 53epoch:train:6601-6800batch: iter_time=1.852e-04, forward_time=0.136, uma_reduction=0.223, text_vs_uma=0.430, loss_ctc=4.774, loss=2.387, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.994e-04, train_time=0.898
[alab02] 2024-08-29 11:46:04,084 (trainer:720) INFO: 53epoch:train:6801-7000batch: iter_time=1.879e-04, forward_time=0.133, uma_reduction=0.221, text_vs_uma=0.434, loss_ctc=5.194, loss=2.597, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.993e-04, train_time=0.883
[alab02] 2024-08-29 11:47:24,018 (trainer:338) INFO: 53epoch results: [train] iter_time=2.650e-04, forward_time=0.133, uma_reduction=0.226, text_vs_uma=0.425, loss_ctc=4.817, loss=2.409, backward_time=0.183, optim_step_time=0.035, optim0_lr0=2.002e-04, train_time=0.883, time=52 minutes and 28.19 seconds, total_count=377678, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.246, text_vs_uma=0.440, loss_ctc=3.485, cer_ctc=0.090, cer=0.090, loss=3.485, time=6.2 seconds, total_count=1378, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.52 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 11:47:29,298 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-29 11:47:29,357 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/51epoch.pth
[alab02] 2024-08-29 11:47:29,357 (trainer:272) INFO: 54/150epoch started. Estimated time to finish: 3 days, 17 hours and 24 minutes
[alab02] 2024-08-29 11:48:58,155 (trainer:720) INFO: 54epoch:train:1-200batch: iter_time=0.002, forward_time=0.133, uma_reduction=0.226, text_vs_uma=0.436, loss_ctc=4.775, loss=2.387, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.993e-04, train_time=0.888
[alab02] 2024-08-29 11:50:26,138 (trainer:720) INFO: 54epoch:train:201-400batch: iter_time=2.179e-04, forward_time=0.132, uma_reduction=0.222, text_vs_uma=0.434, loss_ctc=4.807, loss=2.404, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.992e-04, train_time=0.880
[alab02] 2024-08-29 11:51:53,021 (trainer:720) INFO: 54epoch:train:401-600batch: iter_time=2.195e-04, forward_time=0.131, uma_reduction=0.224, text_vs_uma=0.423, loss_ctc=4.783, loss=2.391, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.992e-04, train_time=0.869
[alab02] 2024-08-29 11:53:21,021 (trainer:720) INFO: 54epoch:train:601-800batch: iter_time=2.352e-04, forward_time=0.132, uma_reduction=0.222, text_vs_uma=0.428, loss_ctc=4.722, loss=2.361, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.991e-04, train_time=0.880
[alab02] 2024-08-29 11:54:48,394 (trainer:720) INFO: 54epoch:train:801-1000batch: iter_time=1.991e-04, forward_time=0.131, uma_reduction=0.221, text_vs_uma=0.433, loss_ctc=5.042, loss=2.521, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.991e-04, train_time=0.874
[alab02] 2024-08-29 11:56:14,795 (trainer:720) INFO: 54epoch:train:1001-1200batch: iter_time=1.698e-04, forward_time=0.129, uma_reduction=0.220, text_vs_uma=0.435, loss_ctc=4.723, loss=2.361, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.990e-04, train_time=0.864
[alab02] 2024-08-29 11:57:45,035 (trainer:720) INFO: 54epoch:train:1201-1400batch: iter_time=2.142e-04, forward_time=0.136, uma_reduction=0.225, text_vs_uma=0.430, loss_ctc=5.093, loss=2.546, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.989e-04, train_time=0.902
[alab02] 2024-08-29 11:59:13,832 (trainer:720) INFO: 54epoch:train:1401-1600batch: iter_time=2.012e-04, forward_time=0.133, uma_reduction=0.222, text_vs_uma=0.429, loss_ctc=5.166, loss=2.583, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.989e-04, train_time=0.888
[alab02] 2024-08-29 12:00:44,327 (trainer:720) INFO: 54epoch:train:1601-1800batch: iter_time=2.094e-04, forward_time=0.137, uma_reduction=0.226, text_vs_uma=0.423, loss_ctc=4.728, loss=2.364, backward_time=0.189, optim_step_time=0.036, optim0_lr0=1.988e-04, train_time=0.905
[alab02] 2024-08-29 12:02:12,275 (trainer:720) INFO: 54epoch:train:1801-2000batch: iter_time=1.954e-04, forward_time=0.132, uma_reduction=0.232, text_vs_uma=0.416, loss_ctc=4.364, loss=2.182, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.988e-04, train_time=0.879
[alab02] 2024-08-29 12:03:40,166 (trainer:720) INFO: 54epoch:train:2001-2200batch: iter_time=2.154e-04, forward_time=0.132, uma_reduction=0.229, text_vs_uma=0.424, loss_ctc=4.790, loss=2.395, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.987e-04, train_time=0.879
[alab02] 2024-08-29 12:05:08,674 (trainer:720) INFO: 54epoch:train:2201-2400batch: iter_time=1.966e-04, forward_time=0.133, uma_reduction=0.229, text_vs_uma=0.431, loss_ctc=4.778, loss=2.389, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.987e-04, train_time=0.885
[alab02] 2024-08-29 12:06:37,288 (trainer:720) INFO: 54epoch:train:2401-2600batch: iter_time=2.031e-04, forward_time=0.134, uma_reduction=0.228, text_vs_uma=0.417, loss_ctc=4.525, loss=2.263, backward_time=0.187, optim_step_time=0.035, optim0_lr0=1.986e-04, train_time=0.886
[alab02] 2024-08-29 12:08:07,888 (trainer:720) INFO: 54epoch:train:2601-2800batch: iter_time=2.207e-04, forward_time=0.138, uma_reduction=0.225, text_vs_uma=0.430, loss_ctc=4.774, loss=2.387, backward_time=0.189, optim_step_time=0.035, optim0_lr0=1.986e-04, train_time=0.906
[alab02] 2024-08-29 12:09:36,501 (trainer:720) INFO: 54epoch:train:2801-3000batch: iter_time=2.668e-04, forward_time=0.133, uma_reduction=0.220, text_vs_uma=0.439, loss_ctc=5.016, loss=2.508, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.985e-04, train_time=0.886
[alab02] 2024-08-29 12:11:02,744 (trainer:720) INFO: 54epoch:train:3001-3200batch: iter_time=1.994e-04, forward_time=0.130, uma_reduction=0.220, text_vs_uma=0.442, loss_ctc=5.176, loss=2.588, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.985e-04, train_time=0.862
[alab02] 2024-08-29 12:12:30,910 (trainer:720) INFO: 54epoch:train:3201-3400batch: iter_time=2.177e-04, forward_time=0.133, uma_reduction=0.223, text_vs_uma=0.433, loss_ctc=4.977, loss=2.489, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.984e-04, train_time=0.881
[alab02] 2024-08-29 12:13:58,536 (trainer:720) INFO: 54epoch:train:3401-3600batch: iter_time=2.557e-04, forward_time=0.133, uma_reduction=0.219, text_vs_uma=0.436, loss_ctc=4.808, loss=2.404, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.984e-04, train_time=0.876
[alab02] 2024-08-29 12:15:25,683 (trainer:720) INFO: 54epoch:train:3601-3800batch: iter_time=1.887e-04, forward_time=0.131, uma_reduction=0.219, text_vs_uma=0.434, loss_ctc=4.733, loss=2.366, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.983e-04, train_time=0.871
[alab02] 2024-08-29 12:16:53,444 (trainer:720) INFO: 54epoch:train:3801-4000batch: iter_time=1.803e-04, forward_time=0.132, uma_reduction=0.225, text_vs_uma=0.437, loss_ctc=5.131, loss=2.565, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.983e-04, train_time=0.877
[alab02] 2024-08-29 12:18:22,174 (trainer:720) INFO: 54epoch:train:4001-4200batch: iter_time=1.894e-04, forward_time=0.134, uma_reduction=0.228, text_vs_uma=0.424, loss_ctc=4.573, loss=2.287, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.982e-04, train_time=0.887
[alab02] 2024-08-29 12:19:49,197 (trainer:720) INFO: 54epoch:train:4201-4400batch: iter_time=1.893e-04, forward_time=0.132, uma_reduction=0.225, text_vs_uma=0.426, loss_ctc=4.920, loss=2.460, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.982e-04, train_time=0.870
[alab02] 2024-08-29 12:21:16,603 (trainer:720) INFO: 54epoch:train:4401-4600batch: iter_time=2.407e-04, forward_time=0.133, uma_reduction=0.229, text_vs_uma=0.416, loss_ctc=4.748, loss=2.374, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.981e-04, train_time=0.874
[alab02] 2024-08-29 12:22:45,065 (trainer:720) INFO: 54epoch:train:4601-4800batch: iter_time=1.831e-04, forward_time=0.133, uma_reduction=0.231, text_vs_uma=0.420, loss_ctc=4.729, loss=2.365, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.981e-04, train_time=0.884
[alab02] 2024-08-29 12:24:10,577 (trainer:720) INFO: 54epoch:train:4801-5000batch: iter_time=1.989e-04, forward_time=0.129, uma_reduction=0.234, text_vs_uma=0.413, loss_ctc=4.461, loss=2.230, backward_time=0.176, optim_step_time=0.035, optim0_lr0=1.980e-04, train_time=0.855
[alab02] 2024-08-29 12:25:37,795 (trainer:720) INFO: 54epoch:train:5001-5200batch: iter_time=1.884e-04, forward_time=0.131, uma_reduction=0.222, text_vs_uma=0.425, loss_ctc=5.092, loss=2.546, backward_time=0.177, optim_step_time=0.035, optim0_lr0=1.980e-04, train_time=0.872
[alab02] 2024-08-29 12:27:06,554 (trainer:720) INFO: 54epoch:train:5201-5400batch: iter_time=1.934e-04, forward_time=0.134, uma_reduction=0.223, text_vs_uma=0.436, loss_ctc=4.929, loss=2.464, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.979e-04, train_time=0.887
[alab02] 2024-08-29 12:28:37,277 (trainer:720) INFO: 54epoch:train:5401-5600batch: iter_time=1.981e-04, forward_time=0.137, uma_reduction=0.226, text_vs_uma=0.427, loss_ctc=5.325, loss=2.663, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.979e-04, train_time=0.907
[alab02] 2024-08-29 12:30:07,071 (trainer:720) INFO: 54epoch:train:5601-5800batch: iter_time=1.955e-04, forward_time=0.135, uma_reduction=0.230, text_vs_uma=0.422, loss_ctc=4.678, loss=2.339, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.978e-04, train_time=0.898
[alab02] 2024-08-29 12:31:36,920 (trainer:720) INFO: 54epoch:train:5801-6000batch: iter_time=1.997e-04, forward_time=0.135, uma_reduction=0.234, text_vs_uma=0.402, loss_ctc=4.962, loss=2.481, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.978e-04, train_time=0.898
[alab02] 2024-08-29 12:33:05,294 (trainer:720) INFO: 54epoch:train:6001-6200batch: iter_time=1.925e-04, forward_time=0.133, uma_reduction=0.233, text_vs_uma=0.421, loss_ctc=5.063, loss=2.531, backward_time=0.180, optim_step_time=0.036, optim0_lr0=1.977e-04, train_time=0.883
[alab02] 2024-08-29 12:34:35,009 (trainer:720) INFO: 54epoch:train:6201-6400batch: iter_time=2.037e-04, forward_time=0.136, uma_reduction=0.233, text_vs_uma=0.415, loss_ctc=4.867, loss=2.434, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.976e-04, train_time=0.897
[alab02] 2024-08-29 12:36:04,791 (trainer:720) INFO: 54epoch:train:6401-6600batch: iter_time=1.932e-04, forward_time=0.136, uma_reduction=0.235, text_vs_uma=0.398, loss_ctc=4.318, loss=2.159, backward_time=0.191, optim_step_time=0.035, optim0_lr0=1.976e-04, train_time=0.898
[alab02] 2024-08-29 12:37:32,107 (trainer:720) INFO: 54epoch:train:6601-6800batch: iter_time=1.962e-04, forward_time=0.132, uma_reduction=0.238, text_vs_uma=0.398, loss_ctc=4.436, loss=2.218, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.975e-04, train_time=0.873
[alab02] 2024-08-29 12:38:59,130 (trainer:720) INFO: 54epoch:train:6801-7000batch: iter_time=2.160e-04, forward_time=0.131, uma_reduction=0.239, text_vs_uma=0.390, loss_ctc=4.248, loss=2.124, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.975e-04, train_time=0.870
[alab02] 2024-08-29 12:40:16,661 (trainer:338) INFO: 54epoch results: [train] iter_time=2.674e-04, forward_time=0.133, uma_reduction=0.227, text_vs_uma=0.424, loss_ctc=4.795, loss=2.398, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.984e-04, train_time=0.883, time=52 minutes and 26.52 seconds, total_count=384804, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.257, text_vs_uma=0.422, loss_ctc=3.283, cer_ctc=0.089, cer=0.089, loss=3.283, time=6.6 seconds, total_count=1404, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.18 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 12:40:22,205 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-29 12:40:22,212 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/42epoch.pth
[alab02] 2024-08-29 12:40:22,213 (trainer:272) INFO: 55/150epoch started. Estimated time to finish: 3 days, 16 hours and 24 minutes
[alab02] 2024-08-29 12:41:52,172 (trainer:720) INFO: 55epoch:train:1-200batch: iter_time=0.002, forward_time=0.133, uma_reduction=0.230, text_vs_uma=0.418, loss_ctc=4.826, loss=2.413, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.974e-04, train_time=0.899
[alab02] 2024-08-29 12:43:19,539 (trainer:720) INFO: 55epoch:train:201-400batch: iter_time=2.076e-04, forward_time=0.131, uma_reduction=0.236, text_vs_uma=0.414, loss_ctc=4.941, loss=2.470, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.974e-04, train_time=0.873
[alab02] 2024-08-29 12:44:49,090 (trainer:720) INFO: 55epoch:train:401-600batch: iter_time=2.005e-04, forward_time=0.134, uma_reduction=0.237, text_vs_uma=0.411, loss_ctc=4.798, loss=2.399, backward_time=0.190, optim_step_time=0.034, optim0_lr0=1.973e-04, train_time=0.895
[alab02] 2024-08-29 12:46:18,023 (trainer:720) INFO: 55epoch:train:601-800batch: iter_time=2.157e-04, forward_time=0.134, uma_reduction=0.238, text_vs_uma=0.406, loss_ctc=4.892, loss=2.446, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.973e-04, train_time=0.889
[alab02] 2024-08-29 12:47:43,559 (trainer:720) INFO: 55epoch:train:801-1000batch: iter_time=1.999e-04, forward_time=0.129, uma_reduction=0.236, text_vs_uma=0.406, loss_ctc=4.907, loss=2.453, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.972e-04, train_time=0.855
[alab02] 2024-08-29 12:49:09,559 (trainer:720) INFO: 55epoch:train:1001-1200batch: iter_time=2.214e-04, forward_time=0.129, uma_reduction=0.229, text_vs_uma=0.431, loss_ctc=4.654, loss=2.327, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.972e-04, train_time=0.860
[alab02] 2024-08-29 12:50:36,192 (trainer:720) INFO: 55epoch:train:1201-1400batch: iter_time=2.286e-04, forward_time=0.130, uma_reduction=0.220, text_vs_uma=0.425, loss_ctc=4.810, loss=2.405, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.971e-04, train_time=0.866
[alab02] 2024-08-29 12:52:04,661 (trainer:720) INFO: 55epoch:train:1401-1600batch: iter_time=2.171e-04, forward_time=0.133, uma_reduction=0.226, text_vs_uma=0.426, loss_ctc=5.220, loss=2.610, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.971e-04, train_time=0.884
[alab02] 2024-08-29 12:53:32,097 (trainer:720) INFO: 55epoch:train:1601-1800batch: iter_time=2.062e-04, forward_time=0.131, uma_reduction=0.226, text_vs_uma=0.418, loss_ctc=4.862, loss=2.431, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.970e-04, train_time=0.874
[alab02] 2024-08-29 12:55:00,521 (trainer:720) INFO: 55epoch:train:1801-2000batch: iter_time=2.153e-04, forward_time=0.133, uma_reduction=0.229, text_vs_uma=0.424, loss_ctc=4.947, loss=2.474, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.969e-04, train_time=0.884
[alab02] 2024-08-29 12:56:28,543 (trainer:720) INFO: 55epoch:train:2001-2200batch: iter_time=1.931e-04, forward_time=0.132, uma_reduction=0.224, text_vs_uma=0.427, loss_ctc=5.015, loss=2.507, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.969e-04, train_time=0.880
[alab02] 2024-08-29 12:57:56,588 (trainer:720) INFO: 55epoch:train:2201-2400batch: iter_time=2.183e-04, forward_time=0.132, uma_reduction=0.222, text_vs_uma=0.434, loss_ctc=4.667, loss=2.333, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.968e-04, train_time=0.880
[alab02] 2024-08-29 12:59:23,410 (trainer:720) INFO: 55epoch:train:2401-2600batch: iter_time=2.013e-04, forward_time=0.130, uma_reduction=0.221, text_vs_uma=0.446, loss_ctc=5.089, loss=2.545, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.968e-04, train_time=0.868
[alab02] 2024-08-29 13:00:48,589 (trainer:720) INFO: 55epoch:train:2601-2800batch: iter_time=1.932e-04, forward_time=0.128, uma_reduction=0.225, text_vs_uma=0.419, loss_ctc=4.300, loss=2.150, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.967e-04, train_time=0.852
[alab02] 2024-08-29 13:02:17,412 (trainer:720) INFO: 55epoch:train:2801-3000batch: iter_time=1.868e-04, forward_time=0.133, uma_reduction=0.223, text_vs_uma=0.422, loss_ctc=4.988, loss=2.494, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.967e-04, train_time=0.888
[alab02] 2024-08-29 13:03:42,342 (trainer:720) INFO: 55epoch:train:3001-3200batch: iter_time=2.043e-04, forward_time=0.128, uma_reduction=0.230, text_vs_uma=0.414, loss_ctc=4.717, loss=2.359, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.966e-04, train_time=0.849
[alab02] 2024-08-29 13:05:09,139 (trainer:720) INFO: 55epoch:train:3201-3400batch: iter_time=1.997e-04, forward_time=0.130, uma_reduction=0.234, text_vs_uma=0.418, loss_ctc=4.899, loss=2.449, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.966e-04, train_time=0.868
[alab02] 2024-08-29 13:06:37,041 (trainer:720) INFO: 55epoch:train:3401-3600batch: iter_time=2.442e-04, forward_time=0.132, uma_reduction=0.232, text_vs_uma=0.421, loss_ctc=4.734, loss=2.367, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.965e-04, train_time=0.879
[alab02] 2024-08-29 13:08:02,603 (trainer:720) INFO: 55epoch:train:3601-3800batch: iter_time=1.900e-04, forward_time=0.128, uma_reduction=0.227, text_vs_uma=0.423, loss_ctc=4.576, loss=2.288, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.965e-04, train_time=0.855
[alab02] 2024-08-29 13:09:29,387 (trainer:720) INFO: 55epoch:train:3801-4000batch: iter_time=1.768e-04, forward_time=0.130, uma_reduction=0.223, text_vs_uma=0.437, loss_ctc=5.143, loss=2.572, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.964e-04, train_time=0.868
[alab02] 2024-08-29 13:10:57,222 (trainer:720) INFO: 55epoch:train:4001-4200batch: iter_time=1.792e-04, forward_time=0.131, uma_reduction=0.224, text_vs_uma=0.430, loss_ctc=4.974, loss=2.487, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.964e-04, train_time=0.878
[alab02] 2024-08-29 13:12:23,373 (trainer:720) INFO: 55epoch:train:4201-4400batch: iter_time=1.970e-04, forward_time=0.130, uma_reduction=0.226, text_vs_uma=0.427, loss_ctc=4.546, loss=2.273, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.963e-04, train_time=0.861
[alab02] 2024-08-29 13:13:48,523 (trainer:720) INFO: 55epoch:train:4401-4600batch: iter_time=2.022e-04, forward_time=0.127, uma_reduction=0.227, text_vs_uma=0.422, loss_ctc=4.785, loss=2.392, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.963e-04, train_time=0.851
[alab02] 2024-08-29 13:15:15,626 (trainer:720) INFO: 55epoch:train:4601-4800batch: iter_time=1.770e-04, forward_time=0.130, uma_reduction=0.232, text_vs_uma=0.422, loss_ctc=4.939, loss=2.469, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.962e-04, train_time=0.871
[alab02] 2024-08-29 13:16:41,448 (trainer:720) INFO: 55epoch:train:4801-5000batch: iter_time=1.787e-04, forward_time=0.129, uma_reduction=0.233, text_vs_uma=0.404, loss_ctc=4.242, loss=2.121, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.962e-04, train_time=0.858
[alab02] 2024-08-29 13:18:07,705 (trainer:720) INFO: 55epoch:train:5001-5200batch: iter_time=1.412e-04, forward_time=0.127, uma_reduction=0.231, text_vs_uma=0.416, loss_ctc=4.990, loss=2.495, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.961e-04, train_time=0.862
[alab02] 2024-08-29 13:19:34,393 (trainer:720) INFO: 55epoch:train:5201-5400batch: iter_time=1.451e-04, forward_time=0.128, uma_reduction=0.231, text_vs_uma=0.409, loss_ctc=4.337, loss=2.169, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.961e-04, train_time=0.867
[alab02] 2024-08-29 13:21:01,541 (trainer:720) INFO: 55epoch:train:5401-5600batch: iter_time=1.387e-04, forward_time=0.129, uma_reduction=0.232, text_vs_uma=0.411, loss_ctc=4.478, loss=2.239, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.960e-04, train_time=0.871
[alab02] 2024-08-29 13:22:27,794 (trainer:720) INFO: 55epoch:train:5601-5800batch: iter_time=1.417e-04, forward_time=0.127, uma_reduction=0.227, text_vs_uma=0.419, loss_ctc=4.681, loss=2.341, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.960e-04, train_time=0.862
[alab02] 2024-08-29 13:23:54,470 (trainer:720) INFO: 55epoch:train:5801-6000batch: iter_time=1.477e-04, forward_time=0.128, uma_reduction=0.229, text_vs_uma=0.417, loss_ctc=4.543, loss=2.271, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.959e-04, train_time=0.867
[alab02] 2024-08-29 13:25:21,864 (trainer:720) INFO: 55epoch:train:6001-6200batch: iter_time=1.661e-04, forward_time=0.130, uma_reduction=0.232, text_vs_uma=0.415, loss_ctc=4.725, loss=2.362, backward_time=0.185, optim_step_time=0.032, optim0_lr0=1.959e-04, train_time=0.874
[alab02] 2024-08-29 13:26:50,299 (trainer:720) INFO: 55epoch:train:6201-6400batch: iter_time=1.567e-04, forward_time=0.131, uma_reduction=0.231, text_vs_uma=0.415, loss_ctc=4.582, loss=2.291, backward_time=0.187, optim_step_time=0.032, optim0_lr0=1.958e-04, train_time=0.884
[alab02] 2024-08-29 13:28:16,333 (trainer:720) INFO: 55epoch:train:6401-6600batch: iter_time=1.497e-04, forward_time=0.127, uma_reduction=0.228, text_vs_uma=0.424, loss_ctc=4.880, loss=2.440, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.958e-04, train_time=0.860
[alab02] 2024-08-29 13:29:44,326 (trainer:720) INFO: 55epoch:train:6601-6800batch: iter_time=1.638e-04, forward_time=0.131, uma_reduction=0.232, text_vs_uma=0.410, loss_ctc=4.548, loss=2.274, backward_time=0.185, optim_step_time=0.032, optim0_lr0=1.957e-04, train_time=0.880
[alab02] 2024-08-29 13:31:09,910 (trainer:720) INFO: 55epoch:train:6801-7000batch: iter_time=1.698e-04, forward_time=0.126, uma_reduction=0.234, text_vs_uma=0.419, loss_ctc=5.158, loss=2.579, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.957e-04, train_time=0.856
[alab02] 2024-08-29 13:32:22,567 (trainer:338) INFO: 55epoch results: [train] iter_time=2.389e-04, forward_time=0.130, uma_reduction=0.229, text_vs_uma=0.420, loss_ctc=4.773, loss=2.387, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.965e-04, train_time=0.870, time=51 minutes and 41.64 seconds, total_count=391930, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.251, text_vs_uma=0.433, loss_ctc=3.441, cer_ctc=0.090, cer=0.090, loss=3.441, time=5.95 seconds, total_count=1430, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.76 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 13:32:27,835 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 13:32:27,842 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/39epoch.pth
[alab02] 2024-08-29 13:32:27,842 (trainer:272) INFO: 56/150epoch started. Estimated time to finish: 3 days, 15 hours and 24 minutes
[alab02] 2024-08-29 13:33:56,677 (trainer:720) INFO: 56epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.237, text_vs_uma=0.394, loss_ctc=4.146, loss=2.073, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.956e-04, train_time=0.888
[alab02] 2024-08-29 13:35:22,030 (trainer:720) INFO: 56epoch:train:201-400batch: iter_time=1.809e-04, forward_time=0.127, uma_reduction=0.233, text_vs_uma=0.409, loss_ctc=4.580, loss=2.290, backward_time=0.175, optim_step_time=0.032, optim0_lr0=1.956e-04, train_time=0.853
[alab02] 2024-08-29 13:36:48,579 (trainer:720) INFO: 56epoch:train:401-600batch: iter_time=1.874e-04, forward_time=0.129, uma_reduction=0.234, text_vs_uma=0.424, loss_ctc=4.680, loss=2.340, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.955e-04, train_time=0.865
[alab02] 2024-08-29 13:38:14,576 (trainer:720) INFO: 56epoch:train:601-800batch: iter_time=2.191e-04, forward_time=0.130, uma_reduction=0.234, text_vs_uma=0.414, loss_ctc=4.485, loss=2.242, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.955e-04, train_time=0.860
[alab02] 2024-08-29 13:39:41,416 (trainer:720) INFO: 56epoch:train:801-1000batch: iter_time=2.319e-04, forward_time=0.131, uma_reduction=0.235, text_vs_uma=0.409, loss_ctc=4.540, loss=2.270, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.954e-04, train_time=0.868
[alab02] 2024-08-29 13:41:08,189 (trainer:720) INFO: 56epoch:train:1001-1200batch: iter_time=2.504e-04, forward_time=0.130, uma_reduction=0.235, text_vs_uma=0.413, loss_ctc=4.074, loss=2.037, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.954e-04, train_time=0.868
[alab02] 2024-08-29 13:42:36,853 (trainer:720) INFO: 56epoch:train:1201-1400batch: iter_time=2.120e-04, forward_time=0.133, uma_reduction=0.239, text_vs_uma=0.391, loss_ctc=4.309, loss=2.154, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.953e-04, train_time=0.886
[alab02] 2024-08-29 13:44:05,677 (trainer:720) INFO: 56epoch:train:1401-1600batch: iter_time=1.881e-04, forward_time=0.135, uma_reduction=0.241, text_vs_uma=0.397, loss_ctc=4.491, loss=2.245, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.953e-04, train_time=0.888
[alab02] 2024-08-29 13:45:31,689 (trainer:720) INFO: 56epoch:train:1601-1800batch: iter_time=1.836e-04, forward_time=0.128, uma_reduction=0.244, text_vs_uma=0.393, loss_ctc=4.373, loss=2.186, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.952e-04, train_time=0.860
[alab02] 2024-08-29 13:46:59,640 (trainer:720) INFO: 56epoch:train:1801-2000batch: iter_time=2.013e-04, forward_time=0.132, uma_reduction=0.241, text_vs_uma=0.392, loss_ctc=4.241, loss=2.121, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.952e-04, train_time=0.879
[alab02] 2024-08-29 13:48:26,765 (trainer:720) INFO: 56epoch:train:2001-2200batch: iter_time=1.938e-04, forward_time=0.131, uma_reduction=0.246, text_vs_uma=0.383, loss_ctc=4.264, loss=2.132, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.951e-04, train_time=0.871
[alab02] 2024-08-29 13:49:56,285 (trainer:720) INFO: 56epoch:train:2201-2400batch: iter_time=1.930e-04, forward_time=0.135, uma_reduction=0.249, text_vs_uma=0.385, loss_ctc=4.515, loss=2.257, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.951e-04, train_time=0.895
[alab02] 2024-08-29 13:51:23,085 (trainer:720) INFO: 56epoch:train:2401-2600batch: iter_time=1.977e-04, forward_time=0.130, uma_reduction=0.244, text_vs_uma=0.400, loss_ctc=4.510, loss=2.255, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.950e-04, train_time=0.868
[alab02] 2024-08-29 13:52:53,765 (trainer:720) INFO: 56epoch:train:2601-2800batch: iter_time=3.061e-04, forward_time=0.140, uma_reduction=0.237, text_vs_uma=0.407, loss_ctc=4.525, loss=2.262, backward_time=0.185, optim_step_time=0.041, optim0_lr0=1.950e-04, train_time=0.906
[alab02] 2024-08-29 13:54:24,016 (trainer:720) INFO: 56epoch:train:2801-3000batch: iter_time=3.114e-04, forward_time=0.138, uma_reduction=0.239, text_vs_uma=0.398, loss_ctc=4.338, loss=2.169, backward_time=0.186, optim_step_time=0.042, optim0_lr0=1.949e-04, train_time=0.902
[alab02] 2024-08-29 13:56:01,721 (trainer:720) INFO: 56epoch:train:3001-3200batch: iter_time=4.843e-04, forward_time=0.155, uma_reduction=0.234, text_vs_uma=0.405, loss_ctc=4.336, loss=2.168, backward_time=0.199, optim_step_time=0.058, optim0_lr0=1.949e-04, train_time=0.976
[alab02] 2024-08-29 13:57:43,147 (trainer:720) INFO: 56epoch:train:3201-3400batch: iter_time=5.327e-04, forward_time=0.166, uma_reduction=0.238, text_vs_uma=0.406, loss_ctc=4.352, loss=2.176, backward_time=0.208, optim_step_time=0.065, optim0_lr0=1.948e-04, train_time=1.014
[alab02] 2024-08-29 13:59:25,160 (trainer:720) INFO: 56epoch:train:3401-3600batch: iter_time=5.307e-04, forward_time=0.164, uma_reduction=0.235, text_vs_uma=0.409, loss_ctc=4.568, loss=2.284, backward_time=0.207, optim_step_time=0.064, optim0_lr0=1.948e-04, train_time=1.020
[alab02] 2024-08-29 14:01:09,744 (trainer:720) INFO: 56epoch:train:3601-3800batch: iter_time=4.860e-04, forward_time=0.171, uma_reduction=0.238, text_vs_uma=0.392, loss_ctc=4.398, loss=2.199, backward_time=0.213, optim_step_time=0.067, optim0_lr0=1.947e-04, train_time=1.045
[alab02] 2024-08-29 14:02:46,161 (trainer:720) INFO: 56epoch:train:3801-4000batch: iter_time=3.775e-04, forward_time=0.153, uma_reduction=0.237, text_vs_uma=0.397, loss_ctc=4.455, loss=2.227, backward_time=0.198, optim_step_time=0.055, optim0_lr0=1.947e-04, train_time=0.964
[alab02] 2024-08-29 14:04:17,596 (trainer:720) INFO: 56epoch:train:4001-4200batch: iter_time=2.212e-04, forward_time=0.141, uma_reduction=0.239, text_vs_uma=0.394, loss_ctc=4.629, loss=2.314, backward_time=0.188, optim_step_time=0.041, optim0_lr0=1.946e-04, train_time=0.914
[alab02] 2024-08-29 14:05:46,976 (trainer:720) INFO: 56epoch:train:4201-4400batch: iter_time=1.964e-04, forward_time=0.135, uma_reduction=0.238, text_vs_uma=0.409, loss_ctc=4.873, loss=2.437, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.946e-04, train_time=0.894
[alab02] 2024-08-29 14:07:20,021 (trainer:720) INFO: 56epoch:train:4401-4600batch: iter_time=3.113e-04, forward_time=0.143, uma_reduction=0.232, text_vs_uma=0.413, loss_ctc=4.457, loss=2.229, backward_time=0.192, optim_step_time=0.045, optim0_lr0=1.945e-04, train_time=0.930
[alab02] 2024-08-29 14:09:02,936 (trainer:720) INFO: 56epoch:train:4601-4800batch: iter_time=4.808e-04, forward_time=0.168, uma_reduction=0.233, text_vs_uma=0.405, loss_ctc=4.330, loss=2.165, backward_time=0.212, optim_step_time=0.065, optim0_lr0=1.945e-04, train_time=1.029
[alab02] 2024-08-29 14:10:44,029 (trainer:720) INFO: 56epoch:train:4801-5000batch: iter_time=4.448e-04, forward_time=0.164, uma_reduction=0.238, text_vs_uma=0.405, loss_ctc=4.315, loss=2.158, backward_time=0.211, optim_step_time=0.063, optim0_lr0=1.944e-04, train_time=1.010
[alab02] 2024-08-29 14:12:28,670 (trainer:720) INFO: 56epoch:train:5001-5200batch: iter_time=4.367e-04, forward_time=0.177, uma_reduction=0.236, text_vs_uma=0.404, loss_ctc=4.607, loss=2.304, backward_time=0.207, optim_step_time=0.069, optim0_lr0=1.944e-04, train_time=1.046
[alab02] 2024-08-29 14:14:08,959 (trainer:720) INFO: 56epoch:train:5201-5400batch: iter_time=4.103e-04, forward_time=0.163, uma_reduction=0.237, text_vs_uma=0.401, loss_ctc=4.789, loss=2.394, backward_time=0.200, optim_step_time=0.062, optim0_lr0=1.943e-04, train_time=1.002
[alab02] 2024-08-29 14:15:52,386 (trainer:720) INFO: 56epoch:train:5401-5600batch: iter_time=4.087e-04, forward_time=0.169, uma_reduction=0.231, text_vs_uma=0.414, loss_ctc=4.758, loss=2.379, backward_time=0.210, optim_step_time=0.065, optim0_lr0=1.943e-04, train_time=1.034
[alab02] 2024-08-29 14:17:32,460 (trainer:720) INFO: 56epoch:train:5601-5800batch: iter_time=4.589e-04, forward_time=0.164, uma_reduction=0.233, text_vs_uma=0.413, loss_ctc=4.885, loss=2.443, backward_time=0.203, optim_step_time=0.065, optim0_lr0=1.942e-04, train_time=1.000
[alab02] 2024-08-29 14:19:14,450 (trainer:720) INFO: 56epoch:train:5801-6000batch: iter_time=4.616e-04, forward_time=0.167, uma_reduction=0.230, text_vs_uma=0.423, loss_ctc=4.779, loss=2.389, backward_time=0.207, optim_step_time=0.065, optim0_lr0=1.942e-04, train_time=1.019
[alab02] 2024-08-29 14:20:58,896 (trainer:720) INFO: 56epoch:train:6001-6200batch: iter_time=4.749e-04, forward_time=0.171, uma_reduction=0.236, text_vs_uma=0.409, loss_ctc=4.663, loss=2.331, backward_time=0.213, optim_step_time=0.066, optim0_lr0=1.941e-04, train_time=1.044
[alab02] 2024-08-29 14:22:40,459 (trainer:720) INFO: 56epoch:train:6201-6400batch: iter_time=4.538e-04, forward_time=0.166, uma_reduction=0.240, text_vs_uma=0.401, loss_ctc=4.750, loss=2.375, backward_time=0.203, optim_step_time=0.062, optim0_lr0=1.941e-04, train_time=1.015
[alab02] 2024-08-29 14:24:21,731 (trainer:720) INFO: 56epoch:train:6401-6600batch: iter_time=4.555e-04, forward_time=0.165, uma_reduction=0.228, text_vs_uma=0.420, loss_ctc=4.353, loss=2.177, backward_time=0.211, optim_step_time=0.063, optim0_lr0=1.940e-04, train_time=1.012
[alab02] 2024-08-29 14:26:00,691 (trainer:720) INFO: 56epoch:train:6601-6800batch: iter_time=4.237e-04, forward_time=0.157, uma_reduction=0.226, text_vs_uma=0.426, loss_ctc=4.725, loss=2.363, backward_time=0.202, optim_step_time=0.058, optim0_lr0=1.940e-04, train_time=0.989
[alab02] 2024-08-29 14:27:33,604 (trainer:720) INFO: 56epoch:train:6801-7000batch: iter_time=3.078e-04, forward_time=0.145, uma_reduction=0.231, text_vs_uma=0.416, loss_ctc=4.438, loss=2.219, backward_time=0.191, optim_step_time=0.047, optim0_lr0=1.939e-04, train_time=0.929
[alab02] 2024-08-29 14:28:50,504 (trainer:338) INFO: 56epoch results: [train] iter_time=3.858e-04, forward_time=0.148, uma_reduction=0.236, text_vs_uma=0.405, loss_ctc=4.498, loss=2.249, backward_time=0.194, optim_step_time=0.048, optim0_lr0=1.948e-04, train_time=0.943, time=56 minutes and 2.5 seconds, total_count=399056, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.241, text_vs_uma=0.451, loss_ctc=3.481, cer_ctc=0.091, cer=0.091, loss=3.481, time=6.24 seconds, total_count=1456, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.92 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 14:28:56,989 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 14:28:56,996 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/40epoch.pth
[alab02] 2024-08-29 14:28:56,996 (trainer:272) INFO: 57/150epoch started. Estimated time to finish: 3 days, 14 hours and 31 minutes
[alab02] 2024-08-29 14:30:27,827 (trainer:720) INFO: 57epoch:train:1-200batch: iter_time=0.002, forward_time=0.135, uma_reduction=0.235, text_vs_uma=0.398, loss_ctc=4.280, loss=2.140, backward_time=0.190, optim_step_time=0.035, optim0_lr0=1.939e-04, train_time=0.908
[alab02] 2024-08-29 14:32:03,518 (trainer:720) INFO: 57epoch:train:201-400batch: iter_time=3.911e-04, forward_time=0.150, uma_reduction=0.224, text_vs_uma=0.428, loss_ctc=4.708, loss=2.354, backward_time=0.196, optim_step_time=0.052, optim0_lr0=1.938e-04, train_time=0.956
[alab02] 2024-08-29 14:33:45,247 (trainer:720) INFO: 57epoch:train:401-600batch: iter_time=4.951e-04, forward_time=0.165, uma_reduction=0.223, text_vs_uma=0.421, loss_ctc=4.255, loss=2.128, backward_time=0.214, optim_step_time=0.060, optim0_lr0=1.938e-04, train_time=1.017
[alab02] 2024-08-29 14:35:27,322 (trainer:720) INFO: 57epoch:train:601-800batch: iter_time=5.782e-04, forward_time=0.171, uma_reduction=0.236, text_vs_uma=0.408, loss_ctc=4.677, loss=2.339, backward_time=0.203, optim_step_time=0.063, optim0_lr0=1.937e-04, train_time=1.020
[alab02] 2024-08-29 14:37:07,442 (trainer:720) INFO: 57epoch:train:801-1000batch: iter_time=5.281e-04, forward_time=0.161, uma_reduction=0.230, text_vs_uma=0.424, loss_ctc=4.674, loss=2.337, backward_time=0.202, optim_step_time=0.063, optim0_lr0=1.937e-04, train_time=1.001
[alab02] 2024-08-29 14:38:46,633 (trainer:720) INFO: 57epoch:train:1001-1200batch: iter_time=5.524e-04, forward_time=0.162, uma_reduction=0.231, text_vs_uma=0.413, loss_ctc=4.407, loss=2.204, backward_time=0.196, optim_step_time=0.064, optim0_lr0=1.936e-04, train_time=0.991
[alab02] 2024-08-29 14:40:30,277 (trainer:720) INFO: 57epoch:train:1201-1400batch: iter_time=4.841e-04, forward_time=0.169, uma_reduction=0.234, text_vs_uma=0.418, loss_ctc=4.922, loss=2.461, backward_time=0.205, optim_step_time=0.065, optim0_lr0=1.936e-04, train_time=1.036
[alab02] 2024-08-29 14:42:13,284 (trainer:720) INFO: 57epoch:train:1401-1600batch: iter_time=5.383e-04, forward_time=0.170, uma_reduction=0.236, text_vs_uma=0.402, loss_ctc=4.541, loss=2.270, backward_time=0.206, optim_step_time=0.065, optim0_lr0=1.935e-04, train_time=1.029
[alab02] 2024-08-29 14:43:53,561 (trainer:720) INFO: 57epoch:train:1601-1800batch: iter_time=4.390e-04, forward_time=0.164, uma_reduction=0.239, text_vs_uma=0.405, loss_ctc=4.867, loss=2.433, backward_time=0.198, optim_step_time=0.060, optim0_lr0=1.935e-04, train_time=1.002
[alab02] 2024-08-29 14:45:33,011 (trainer:720) INFO: 57epoch:train:1801-2000batch: iter_time=5.963e-04, forward_time=0.162, uma_reduction=0.238, text_vs_uma=0.400, loss_ctc=4.453, loss=2.227, backward_time=0.200, optim_step_time=0.064, optim0_lr0=1.934e-04, train_time=0.994
[alab02] 2024-08-29 14:47:17,973 (trainer:720) INFO: 57epoch:train:2001-2200batch: iter_time=5.241e-04, forward_time=0.174, uma_reduction=0.233, text_vs_uma=0.406, loss_ctc=4.266, loss=2.133, backward_time=0.213, optim_step_time=0.066, optim0_lr0=1.934e-04, train_time=1.049
[alab02] 2024-08-29 14:48:59,779 (trainer:720) INFO: 57epoch:train:2201-2400batch: iter_time=5.001e-04, forward_time=0.166, uma_reduction=0.233, text_vs_uma=0.417, loss_ctc=4.900, loss=2.450, backward_time=0.204, optim_step_time=0.061, optim0_lr0=1.933e-04, train_time=1.017
[alab02] 2024-08-29 14:50:41,178 (trainer:720) INFO: 57epoch:train:2401-2600batch: iter_time=4.073e-04, forward_time=0.163, uma_reduction=0.239, text_vs_uma=0.397, loss_ctc=4.554, loss=2.277, backward_time=0.205, optim_step_time=0.060, optim0_lr0=1.933e-04, train_time=1.014
[alab02] 2024-08-29 14:52:18,563 (trainer:720) INFO: 57epoch:train:2601-2800batch: iter_time=3.837e-04, forward_time=0.156, uma_reduction=0.245, text_vs_uma=0.389, loss_ctc=4.531, loss=2.265, backward_time=0.196, optim_step_time=0.059, optim0_lr0=1.932e-04, train_time=0.973
[alab02] 2024-08-29 14:53:52,823 (trainer:720) INFO: 57epoch:train:2801-3000batch: iter_time=2.783e-04, forward_time=0.149, uma_reduction=0.240, text_vs_uma=0.403, loss_ctc=4.921, loss=2.460, backward_time=0.187, optim_step_time=0.046, optim0_lr0=1.932e-04, train_time=0.942
[alab02] 2024-08-29 14:55:21,169 (trainer:720) INFO: 57epoch:train:3001-3200batch: iter_time=2.091e-04, forward_time=0.135, uma_reduction=0.242, text_vs_uma=0.396, loss_ctc=4.512, loss=2.256, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.931e-04, train_time=0.883
[alab02] 2024-08-29 14:56:48,313 (trainer:720) INFO: 57epoch:train:3201-3400batch: iter_time=2.097e-04, forward_time=0.131, uma_reduction=0.246, text_vs_uma=0.395, loss_ctc=4.642, loss=2.321, backward_time=0.177, optim_step_time=0.035, optim0_lr0=1.931e-04, train_time=0.871
[alab02] 2024-08-29 14:58:15,528 (trainer:720) INFO: 57epoch:train:3401-3600batch: iter_time=1.780e-04, forward_time=0.131, uma_reduction=0.240, text_vs_uma=0.409, loss_ctc=5.193, loss=2.597, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.930e-04, train_time=0.872
[alab02] 2024-08-29 14:59:54,233 (trainer:720) INFO: 57epoch:train:3601-3800batch: iter_time=3.569e-04, forward_time=0.157, uma_reduction=0.243, text_vs_uma=0.405, loss_ctc=4.745, loss=2.373, backward_time=0.206, optim_step_time=0.056, optim0_lr0=1.930e-04, train_time=0.987
[alab02] 2024-08-29 15:01:39,182 (trainer:720) INFO: 57epoch:train:3801-4000batch: iter_time=4.579e-04, forward_time=0.174, uma_reduction=0.242, text_vs_uma=0.395, loss_ctc=3.986, loss=1.993, backward_time=0.220, optim_step_time=0.066, optim0_lr0=1.929e-04, train_time=1.049
[alab02] 2024-08-29 15:03:20,619 (trainer:720) INFO: 57epoch:train:4001-4200batch: iter_time=4.509e-04, forward_time=0.166, uma_reduction=0.237, text_vs_uma=0.397, loss_ctc=4.235, loss=2.117, backward_time=0.213, optim_step_time=0.064, optim0_lr0=1.929e-04, train_time=1.014
[alab02] 2024-08-29 15:05:00,025 (trainer:720) INFO: 57epoch:train:4201-4400batch: iter_time=4.716e-04, forward_time=0.159, uma_reduction=0.232, text_vs_uma=0.412, loss_ctc=4.748, loss=2.374, backward_time=0.205, optim_step_time=0.059, optim0_lr0=1.928e-04, train_time=0.993
[alab02] 2024-08-29 15:06:42,236 (trainer:720) INFO: 57epoch:train:4401-4600batch: iter_time=5.446e-04, forward_time=0.165, uma_reduction=0.234, text_vs_uma=0.416, loss_ctc=4.650, loss=2.325, backward_time=0.206, optim_step_time=0.062, optim0_lr0=1.928e-04, train_time=1.021
[alab02] 2024-08-29 15:08:23,163 (trainer:720) INFO: 57epoch:train:4601-4800batch: iter_time=6.323e-04, forward_time=0.163, uma_reduction=0.229, text_vs_uma=0.415, loss_ctc=4.423, loss=2.211, backward_time=0.203, optim_step_time=0.063, optim0_lr0=1.927e-04, train_time=1.009
[alab02] 2024-08-29 15:10:04,893 (trainer:720) INFO: 57epoch:train:4801-5000batch: iter_time=4.593e-04, forward_time=0.165, uma_reduction=0.231, text_vs_uma=0.414, loss_ctc=5.103, loss=2.552, backward_time=0.207, optim_step_time=0.061, optim0_lr0=1.927e-04, train_time=1.017
[alab02] 2024-08-29 15:11:45,127 (trainer:720) INFO: 57epoch:train:5001-5200batch: iter_time=5.089e-04, forward_time=0.162, uma_reduction=0.231, text_vs_uma=0.413, loss_ctc=4.523, loss=2.262, backward_time=0.204, optim_step_time=0.064, optim0_lr0=1.927e-04, train_time=1.002
[alab02] 2024-08-29 15:13:24,689 (trainer:720) INFO: 57epoch:train:5201-5400batch: iter_time=5.051e-04, forward_time=0.161, uma_reduction=0.228, text_vs_uma=0.417, loss_ctc=4.473, loss=2.237, backward_time=0.204, optim_step_time=0.061, optim0_lr0=1.926e-04, train_time=0.995
[alab02] 2024-08-29 15:15:04,232 (trainer:720) INFO: 57epoch:train:5401-5600batch: iter_time=4.889e-04, forward_time=0.161, uma_reduction=0.231, text_vs_uma=0.415, loss_ctc=4.498, loss=2.249, backward_time=0.202, optim_step_time=0.058, optim0_lr0=1.926e-04, train_time=0.995
[alab02] 2024-08-29 15:16:40,812 (trainer:720) INFO: 57epoch:train:5601-5800batch: iter_time=3.165e-04, forward_time=0.153, uma_reduction=0.226, text_vs_uma=0.418, loss_ctc=4.568, loss=2.284, backward_time=0.197, optim_step_time=0.049, optim0_lr0=1.925e-04, train_time=0.965
[alab02] 2024-08-29 15:18:12,617 (trainer:720) INFO: 57epoch:train:5801-6000batch: iter_time=3.210e-04, forward_time=0.144, uma_reduction=0.226, text_vs_uma=0.411, loss_ctc=3.681, loss=1.841, backward_time=0.193, optim_step_time=0.048, optim0_lr0=1.925e-04, train_time=0.918
[alab02] 2024-08-29 15:19:43,371 (trainer:720) INFO: 57epoch:train:6001-6200batch: iter_time=2.275e-04, forward_time=0.138, uma_reduction=0.221, text_vs_uma=0.426, loss_ctc=4.579, loss=2.289, backward_time=0.186, optim_step_time=0.042, optim0_lr0=1.924e-04, train_time=0.907
[alab02] 2024-08-29 15:21:12,637 (trainer:720) INFO: 57epoch:train:6201-6400batch: iter_time=2.029e-04, forward_time=0.135, uma_reduction=0.229, text_vs_uma=0.413, loss_ctc=4.214, loss=2.107, backward_time=0.188, optim_step_time=0.037, optim0_lr0=1.924e-04, train_time=0.892
[alab02] 2024-08-29 15:22:40,770 (trainer:720) INFO: 57epoch:train:6401-6600batch: iter_time=2.012e-04, forward_time=0.132, uma_reduction=0.231, text_vs_uma=0.414, loss_ctc=4.425, loss=2.212, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.923e-04, train_time=0.881
[alab02] 2024-08-29 15:24:08,086 (trainer:720) INFO: 57epoch:train:6601-6800batch: iter_time=1.685e-04, forward_time=0.130, uma_reduction=0.228, text_vs_uma=0.418, loss_ctc=4.646, loss=2.323, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.923e-04, train_time=0.873
[alab02] 2024-08-29 15:25:36,458 (trainer:720) INFO: 57epoch:train:6801-7000batch: iter_time=1.741e-04, forward_time=0.132, uma_reduction=0.234, text_vs_uma=0.406, loss_ctc=4.523, loss=2.262, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.922e-04, train_time=0.883
[alab02] 2024-08-29 15:26:49,447 (trainer:338) INFO: 57epoch results: [train] iter_time=4.492e-04, forward_time=0.154, uma_reduction=0.234, text_vs_uma=0.410, loss_ctc=4.546, loss=2.273, backward_time=0.198, optim_step_time=0.053, optim0_lr0=1.930e-04, train_time=0.968, time=57 minutes and 32.79 seconds, total_count=406182, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.241, text_vs_uma=0.450, loss_ctc=3.663, cer_ctc=0.097, cer=0.097, loss=3.663, time=5.98 seconds, total_count=1482, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.68 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 15:26:54,625 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 15:26:54,626 (trainer:272) INFO: 58/150epoch started. Estimated time to finish: 3 days, 13 hours and 40 minutes
[alab02] 2024-08-29 15:28:23,278 (trainer:720) INFO: 58epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.234, text_vs_uma=0.417, loss_ctc=4.529, loss=2.265, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.921e-04, train_time=0.886
[alab02] 2024-08-29 15:29:48,431 (trainer:720) INFO: 58epoch:train:201-400batch: iter_time=1.905e-04, forward_time=0.126, uma_reduction=0.234, text_vs_uma=0.424, loss_ctc=5.175, loss=2.587, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.921e-04, train_time=0.851
[alab02] 2024-08-29 15:31:16,412 (trainer:720) INFO: 58epoch:train:401-600batch: iter_time=1.914e-04, forward_time=0.132, uma_reduction=0.223, text_vs_uma=0.434, loss_ctc=4.837, loss=2.418, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.921e-04, train_time=0.879
[alab02] 2024-08-29 15:32:43,038 (trainer:720) INFO: 58epoch:train:601-800batch: iter_time=1.739e-04, forward_time=0.128, uma_reduction=0.226, text_vs_uma=0.428, loss_ctc=4.855, loss=2.427, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.920e-04, train_time=0.866
[alab02] 2024-08-29 15:34:10,220 (trainer:720) INFO: 58epoch:train:801-1000batch: iter_time=1.919e-04, forward_time=0.130, uma_reduction=0.234, text_vs_uma=0.415, loss_ctc=4.405, loss=2.203, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.920e-04, train_time=0.872
[alab02] 2024-08-29 15:35:51,100 (trainer:720) INFO: 58epoch:train:1001-1200batch: iter_time=4.680e-04, forward_time=0.162, uma_reduction=0.233, text_vs_uma=0.413, loss_ctc=4.802, loss=2.401, backward_time=0.206, optim_step_time=0.063, optim0_lr0=1.919e-04, train_time=1.008
[alab02] 2024-08-29 15:37:34,205 (trainer:720) INFO: 58epoch:train:1201-1400batch: iter_time=5.061e-04, forward_time=0.167, uma_reduction=0.235, text_vs_uma=0.405, loss_ctc=4.294, loss=2.147, backward_time=0.211, optim_step_time=0.063, optim0_lr0=1.919e-04, train_time=1.031
[alab02] 2024-08-29 15:39:15,816 (trainer:720) INFO: 58epoch:train:1401-1600batch: iter_time=4.785e-04, forward_time=0.165, uma_reduction=0.231, text_vs_uma=0.413, loss_ctc=4.605, loss=2.303, backward_time=0.207, optim_step_time=0.061, optim0_lr0=1.918e-04, train_time=1.015
[alab02] 2024-08-29 15:40:59,571 (trainer:720) INFO: 58epoch:train:1601-1800batch: iter_time=5.100e-04, forward_time=0.169, uma_reduction=0.225, text_vs_uma=0.432, loss_ctc=4.616, loss=2.308, backward_time=0.212, optim_step_time=0.066, optim0_lr0=1.918e-04, train_time=1.037
[alab02] 2024-08-29 15:42:40,548 (trainer:720) INFO: 58epoch:train:1801-2000batch: iter_time=4.062e-04, forward_time=0.162, uma_reduction=0.228, text_vs_uma=0.417, loss_ctc=4.632, loss=2.316, backward_time=0.207, optim_step_time=0.063, optim0_lr0=1.917e-04, train_time=1.009
[alab02] 2024-08-29 15:44:24,364 (trainer:720) INFO: 58epoch:train:2001-2200batch: iter_time=5.040e-04, forward_time=0.170, uma_reduction=0.234, text_vs_uma=0.413, loss_ctc=4.289, loss=2.145, backward_time=0.215, optim_step_time=0.066, optim0_lr0=1.917e-04, train_time=1.038
[alab02] 2024-08-29 15:46:07,287 (trainer:720) INFO: 58epoch:train:2201-2400batch: iter_time=4.939e-04, forward_time=0.168, uma_reduction=0.236, text_vs_uma=0.417, loss_ctc=4.606, loss=2.303, backward_time=0.212, optim_step_time=0.067, optim0_lr0=1.916e-04, train_time=1.029
[alab02] 2024-08-29 15:47:52,014 (trainer:720) INFO: 58epoch:train:2401-2600batch: iter_time=4.607e-04, forward_time=0.171, uma_reduction=0.235, text_vs_uma=0.415, loss_ctc=4.578, loss=2.289, backward_time=0.213, optim_step_time=0.065, optim0_lr0=1.916e-04, train_time=1.047
[alab02] 2024-08-29 15:49:33,886 (trainer:720) INFO: 58epoch:train:2601-2800batch: iter_time=4.971e-04, forward_time=0.167, uma_reduction=0.232, text_vs_uma=0.412, loss_ctc=4.343, loss=2.172, backward_time=0.210, optim_step_time=0.064, optim0_lr0=1.915e-04, train_time=1.018
[alab02] 2024-08-29 15:51:17,790 (trainer:720) INFO: 58epoch:train:2801-3000batch: iter_time=5.068e-04, forward_time=0.170, uma_reduction=0.237, text_vs_uma=0.401, loss_ctc=4.166, loss=2.083, backward_time=0.215, optim_step_time=0.068, optim0_lr0=1.915e-04, train_time=1.038
[alab02] 2024-08-29 15:53:02,500 (trainer:720) INFO: 58epoch:train:3001-3200batch: iter_time=4.361e-04, forward_time=0.172, uma_reduction=0.235, text_vs_uma=0.412, loss_ctc=4.493, loss=2.247, backward_time=0.216, optim_step_time=0.069, optim0_lr0=1.914e-04, train_time=1.046
[alab02] 2024-08-29 15:54:46,476 (trainer:720) INFO: 58epoch:train:3201-3400batch: iter_time=4.685e-04, forward_time=0.171, uma_reduction=0.233, text_vs_uma=0.411, loss_ctc=4.448, loss=2.224, backward_time=0.210, optim_step_time=0.068, optim0_lr0=1.914e-04, train_time=1.039
[alab02] 2024-08-29 15:56:29,570 (trainer:720) INFO: 58epoch:train:3401-3600batch: iter_time=4.264e-04, forward_time=0.167, uma_reduction=0.236, text_vs_uma=0.406, loss_ctc=4.392, loss=2.196, backward_time=0.214, optim_step_time=0.066, optim0_lr0=1.913e-04, train_time=1.030
[alab02] 2024-08-29 15:58:14,780 (trainer:720) INFO: 58epoch:train:3601-3800batch: iter_time=4.977e-04, forward_time=0.173, uma_reduction=0.242, text_vs_uma=0.403, loss_ctc=4.493, loss=2.246, backward_time=0.211, optim_step_time=0.069, optim0_lr0=1.913e-04, train_time=1.051
[alab02] 2024-08-29 15:59:58,435 (trainer:720) INFO: 58epoch:train:3801-4000batch: iter_time=4.918e-04, forward_time=0.172, uma_reduction=0.236, text_vs_uma=0.419, loss_ctc=4.732, loss=2.366, backward_time=0.206, optim_step_time=0.070, optim0_lr0=1.913e-04, train_time=1.036
[alab02] 2024-08-29 16:01:39,046 (trainer:720) INFO: 58epoch:train:4001-4200batch: iter_time=4.308e-04, forward_time=0.163, uma_reduction=0.246, text_vs_uma=0.402, loss_ctc=4.418, loss=2.209, backward_time=0.207, optim_step_time=0.065, optim0_lr0=1.912e-04, train_time=1.006
[alab02] 2024-08-29 16:03:22,436 (trainer:720) INFO: 58epoch:train:4201-4400batch: iter_time=5.357e-04, forward_time=0.170, uma_reduction=0.247, text_vs_uma=0.391, loss_ctc=4.557, loss=2.278, backward_time=0.209, optim_step_time=0.065, optim0_lr0=1.912e-04, train_time=1.033
[alab02] 2024-08-29 16:05:05,955 (trainer:720) INFO: 58epoch:train:4401-4600batch: iter_time=5.081e-04, forward_time=0.172, uma_reduction=0.251, text_vs_uma=0.379, loss_ctc=4.311, loss=2.155, backward_time=0.211, optim_step_time=0.068, optim0_lr0=1.911e-04, train_time=1.035
[alab02] 2024-08-29 16:06:51,683 (trainer:720) INFO: 58epoch:train:4601-4800batch: iter_time=4.953e-04, forward_time=0.172, uma_reduction=0.255, text_vs_uma=0.374, loss_ctc=4.552, loss=2.276, backward_time=0.213, optim_step_time=0.067, optim0_lr0=1.911e-04, train_time=1.057
[alab02] 2024-08-29 16:08:33,241 (trainer:720) INFO: 58epoch:train:4801-5000batch: iter_time=5.325e-04, forward_time=0.167, uma_reduction=0.244, text_vs_uma=0.397, loss_ctc=4.723, loss=2.361, backward_time=0.205, optim_step_time=0.068, optim0_lr0=1.910e-04, train_time=1.015
[alab02] 2024-08-29 16:10:16,275 (trainer:720) INFO: 58epoch:train:5001-5200batch: iter_time=5.017e-04, forward_time=0.168, uma_reduction=0.248, text_vs_uma=0.394, loss_ctc=4.887, loss=2.444, backward_time=0.208, optim_step_time=0.066, optim0_lr0=1.910e-04, train_time=1.030
[alab02] 2024-08-29 16:11:56,341 (trainer:720) INFO: 58epoch:train:5201-5400batch: iter_time=4.460e-04, forward_time=0.161, uma_reduction=0.244, text_vs_uma=0.405, loss_ctc=4.826, loss=2.413, backward_time=0.207, optim_step_time=0.063, optim0_lr0=1.909e-04, train_time=1.000
[alab02] 2024-08-29 16:13:39,967 (trainer:720) INFO: 58epoch:train:5401-5600batch: iter_time=4.632e-04, forward_time=0.171, uma_reduction=0.239, text_vs_uma=0.413, loss_ctc=4.842, loss=2.421, backward_time=0.210, optim_step_time=0.070, optim0_lr0=1.909e-04, train_time=1.036
[alab02] 2024-08-29 16:15:24,981 (trainer:720) INFO: 58epoch:train:5601-5800batch: iter_time=4.934e-04, forward_time=0.176, uma_reduction=0.231, text_vs_uma=0.409, loss_ctc=4.584, loss=2.292, backward_time=0.213, optim_step_time=0.070, optim0_lr0=1.908e-04, train_time=1.049
[alab02] 2024-08-29 16:17:08,395 (trainer:720) INFO: 58epoch:train:5801-6000batch: iter_time=5.203e-04, forward_time=0.169, uma_reduction=0.228, text_vs_uma=0.421, loss_ctc=4.613, loss=2.306, backward_time=0.208, optim_step_time=0.068, optim0_lr0=1.908e-04, train_time=1.034
[alab02] 2024-08-29 16:18:48,322 (trainer:720) INFO: 58epoch:train:6001-6200batch: iter_time=6.377e-04, forward_time=0.161, uma_reduction=0.234, text_vs_uma=0.408, loss_ctc=4.408, loss=2.204, backward_time=0.204, optim_step_time=0.059, optim0_lr0=1.907e-04, train_time=0.999
[alab02] 2024-08-29 16:20:26,642 (trainer:720) INFO: 58epoch:train:6201-6400batch: iter_time=5.926e-04, forward_time=0.157, uma_reduction=0.230, text_vs_uma=0.433, loss_ctc=4.788, loss=2.394, backward_time=0.199, optim_step_time=0.061, optim0_lr0=1.907e-04, train_time=0.983
[alab02] 2024-08-29 16:22:06,539 (trainer:720) INFO: 58epoch:train:6401-6600batch: iter_time=5.252e-04, forward_time=0.161, uma_reduction=0.226, text_vs_uma=0.429, loss_ctc=5.123, loss=2.562, backward_time=0.199, optim_step_time=0.063, optim0_lr0=1.906e-04, train_time=0.998
[alab02] 2024-08-29 16:23:44,855 (trainer:720) INFO: 58epoch:train:6601-6800batch: iter_time=5.053e-04, forward_time=0.158, uma_reduction=0.231, text_vs_uma=0.421, loss_ctc=4.662, loss=2.331, backward_time=0.200, optim_step_time=0.058, optim0_lr0=1.906e-04, train_time=0.983
[alab02] 2024-08-29 16:25:22,393 (trainer:720) INFO: 58epoch:train:6801-7000batch: iter_time=4.662e-04, forward_time=0.155, uma_reduction=0.240, text_vs_uma=0.401, loss_ctc=4.633, loss=2.316, backward_time=0.200, optim_step_time=0.056, optim0_lr0=1.906e-04, train_time=0.975
[alab02] 2024-08-29 16:26:52,633 (trainer:338) INFO: 58epoch results: [train] iter_time=4.888e-04, forward_time=0.161, uma_reduction=0.236, text_vs_uma=0.411, loss_ctc=4.609, loss=2.304, backward_time=0.204, optim_step_time=0.061, optim0_lr0=1.913e-04, train_time=1.001, time=59 minutes and 28.61 seconds, total_count=413308, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.255, text_vs_uma=0.426, loss_ctc=3.330, cer_ctc=0.090, cer=0.090, loss=3.330, time=7.54 seconds, total_count=1508, gpu_max_cached_mem_GB=35.906, [att_plot] time=21.85 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 16:27:00,031 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 16:27:00,132 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/36epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/57epoch.pth
[alab02] 2024-08-29 16:27:00,133 (trainer:272) INFO: 59/150epoch started. Estimated time to finish: 3 days, 12 hours and 52 minutes
[alab02] 2024-08-29 16:28:33,432 (trainer:720) INFO: 59epoch:train:1-200batch: iter_time=0.005, forward_time=0.144, uma_reduction=0.239, text_vs_uma=0.404, loss_ctc=4.662, loss=2.331, backward_time=0.182, optim_step_time=0.048, optim0_lr0=1.905e-04, train_time=0.932
[alab02] 2024-08-29 16:30:06,750 (trainer:720) INFO: 59epoch:train:201-400batch: iter_time=2.883e-04, forward_time=0.145, uma_reduction=0.242, text_vs_uma=0.393, loss_ctc=4.442, loss=2.221, backward_time=0.189, optim_step_time=0.044, optim0_lr0=1.904e-04, train_time=0.933
[alab02] 2024-08-29 16:31:36,828 (trainer:720) INFO: 59epoch:train:401-600batch: iter_time=2.744e-04, forward_time=0.137, uma_reduction=0.235, text_vs_uma=0.409, loss_ctc=4.896, loss=2.448, backward_time=0.183, optim_step_time=0.041, optim0_lr0=1.904e-04, train_time=0.900
[alab02] 2024-08-29 16:33:03,735 (trainer:720) INFO: 59epoch:train:601-800batch: iter_time=2.072e-04, forward_time=0.132, uma_reduction=0.242, text_vs_uma=0.401, loss_ctc=4.194, loss=2.097, backward_time=0.178, optim_step_time=0.038, optim0_lr0=1.903e-04, train_time=0.869
[alab02] 2024-08-29 16:34:31,989 (trainer:720) INFO: 59epoch:train:801-1000batch: iter_time=2.330e-04, forward_time=0.133, uma_reduction=0.236, text_vs_uma=0.403, loss_ctc=4.393, loss=2.197, backward_time=0.182, optim_step_time=0.037, optim0_lr0=1.903e-04, train_time=0.882
[alab02] 2024-08-29 16:35:59,292 (trainer:720) INFO: 59epoch:train:1001-1200batch: iter_time=1.794e-04, forward_time=0.130, uma_reduction=0.229, text_vs_uma=0.423, loss_ctc=4.935, loss=2.467, backward_time=0.178, optim_step_time=0.036, optim0_lr0=1.903e-04, train_time=0.873
[alab02] 2024-08-29 16:37:25,037 (trainer:720) INFO: 59epoch:train:1201-1400batch: iter_time=1.986e-04, forward_time=0.128, uma_reduction=0.234, text_vs_uma=0.420, loss_ctc=4.727, loss=2.364, backward_time=0.175, optim_step_time=0.036, optim0_lr0=1.902e-04, train_time=0.857
[alab02] 2024-08-29 16:38:52,322 (trainer:720) INFO: 59epoch:train:1401-1600batch: iter_time=1.805e-04, forward_time=0.130, uma_reduction=0.240, text_vs_uma=0.402, loss_ctc=4.774, loss=2.387, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.902e-04, train_time=0.873
[alab02] 2024-08-29 16:40:19,514 (trainer:720) INFO: 59epoch:train:1601-1800batch: iter_time=1.932e-04, forward_time=0.130, uma_reduction=0.238, text_vs_uma=0.397, loss_ctc=4.503, loss=2.252, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.901e-04, train_time=0.872
[alab02] 2024-08-29 16:41:48,968 (trainer:720) INFO: 59epoch:train:1801-2000batch: iter_time=2.045e-04, forward_time=0.134, uma_reduction=0.238, text_vs_uma=0.391, loss_ctc=4.044, loss=2.022, backward_time=0.192, optim_step_time=0.035, optim0_lr0=1.901e-04, train_time=0.894
[alab02] 2024-08-29 16:43:23,406 (trainer:720) INFO: 59epoch:train:2001-2200batch: iter_time=3.665e-04, forward_time=0.147, uma_reduction=0.237, text_vs_uma=0.406, loss_ctc=4.353, loss=2.177, backward_time=0.193, optim_step_time=0.051, optim0_lr0=1.900e-04, train_time=0.944
[alab02] 2024-08-29 16:45:03,683 (trainer:720) INFO: 59epoch:train:2201-2400batch: iter_time=3.543e-04, forward_time=0.157, uma_reduction=0.234, text_vs_uma=0.414, loss_ctc=4.888, loss=2.444, backward_time=0.206, optim_step_time=0.060, optim0_lr0=1.900e-04, train_time=1.002
[alab02] 2024-08-29 16:46:42,643 (trainer:720) INFO: 59epoch:train:2401-2600batch: iter_time=3.493e-04, forward_time=0.155, uma_reduction=0.247, text_vs_uma=0.387, loss_ctc=4.282, loss=2.141, backward_time=0.206, optim_step_time=0.057, optim0_lr0=1.899e-04, train_time=0.989
[alab02] 2024-08-29 16:48:23,143 (trainer:720) INFO: 59epoch:train:2601-2800batch: iter_time=3.887e-04, forward_time=0.160, uma_reduction=0.241, text_vs_uma=0.394, loss_ctc=4.569, loss=2.285, backward_time=0.206, optim_step_time=0.062, optim0_lr0=1.899e-04, train_time=1.004
[alab02] 2024-08-29 16:50:01,285 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 16:50:03,176 (trainer:720) INFO: 59epoch:train:2801-3000batch: iter_time=3.687e-04, forward_time=0.160, uma_reduction=0.239, text_vs_uma=0.411, loss_ctc=4.727, loss=2.363, backward_time=0.202, optim_step_time=0.058, optim0_lr0=1.898e-04, train_time=1.000
[alab02] 2024-08-29 16:51:43,259 (trainer:720) INFO: 59epoch:train:3001-3200batch: iter_time=3.726e-04, forward_time=0.158, uma_reduction=0.238, text_vs_uma=0.402, loss_ctc=4.571, loss=2.286, backward_time=0.204, optim_step_time=0.062, optim0_lr0=1.898e-04, train_time=1.000
[alab02] 2024-08-29 16:53:23,676 (trainer:720) INFO: 59epoch:train:3201-3400batch: iter_time=3.428e-04, forward_time=0.158, uma_reduction=0.242, text_vs_uma=0.402, loss_ctc=4.403, loss=2.201, backward_time=0.213, optim_step_time=0.061, optim0_lr0=1.897e-04, train_time=1.004
[alab02] 2024-08-29 16:55:04,173 (trainer:720) INFO: 59epoch:train:3401-3600batch: iter_time=3.344e-04, forward_time=0.157, uma_reduction=0.246, text_vs_uma=0.393, loss_ctc=4.461, loss=2.231, backward_time=0.209, optim_step_time=0.057, optim0_lr0=1.897e-04, train_time=1.004
[alab02] 2024-08-29 16:56:45,464 (trainer:720) INFO: 59epoch:train:3601-3800batch: iter_time=3.749e-04, forward_time=0.159, uma_reduction=0.246, text_vs_uma=0.399, loss_ctc=4.853, loss=2.426, backward_time=0.209, optim_step_time=0.060, optim0_lr0=1.897e-04, train_time=1.012
[alab02] 2024-08-29 16:58:25,251 (trainer:720) INFO: 59epoch:train:3801-4000batch: iter_time=3.771e-04, forward_time=0.159, uma_reduction=0.244, text_vs_uma=0.399, loss_ctc=4.429, loss=2.214, backward_time=0.204, optim_step_time=0.065, optim0_lr0=1.896e-04, train_time=0.997
[alab02] 2024-08-29 17:00:07,222 (trainer:720) INFO: 59epoch:train:4001-4200batch: iter_time=4.702e-04, forward_time=0.165, uma_reduction=0.239, text_vs_uma=0.402, loss_ctc=4.514, loss=2.257, backward_time=0.202, optim_step_time=0.065, optim0_lr0=1.896e-04, train_time=1.019
[alab02] 2024-08-29 17:01:47,243 (trainer:720) INFO: 59epoch:train:4201-4400batch: iter_time=4.214e-04, forward_time=0.160, uma_reduction=0.245, text_vs_uma=0.389, loss_ctc=4.389, loss=2.194, backward_time=0.204, optim_step_time=0.062, optim0_lr0=1.895e-04, train_time=1.000
[alab02] 2024-08-29 17:03:28,092 (trainer:720) INFO: 59epoch:train:4401-4600batch: iter_time=4.712e-04, forward_time=0.165, uma_reduction=0.246, text_vs_uma=0.388, loss_ctc=4.247, loss=2.123, backward_time=0.204, optim_step_time=0.062, optim0_lr0=1.895e-04, train_time=1.008
[alab02] 2024-08-29 17:05:09,721 (trainer:720) INFO: 59epoch:train:4601-4800batch: iter_time=4.129e-04, forward_time=0.165, uma_reduction=0.242, text_vs_uma=0.403, loss_ctc=4.276, loss=2.138, backward_time=0.210, optim_step_time=0.062, optim0_lr0=1.894e-04, train_time=1.016
[alab02] 2024-08-29 17:06:49,072 (trainer:720) INFO: 59epoch:train:4801-5000batch: iter_time=4.471e-04, forward_time=0.162, uma_reduction=0.247, text_vs_uma=0.389, loss_ctc=4.414, loss=2.207, backward_time=0.200, optim_step_time=0.064, optim0_lr0=1.894e-04, train_time=0.993
[alab02] 2024-08-29 17:08:30,456 (trainer:720) INFO: 59epoch:train:5001-5200batch: iter_time=5.039e-04, forward_time=0.165, uma_reduction=0.247, text_vs_uma=0.388, loss_ctc=4.733, loss=2.367, backward_time=0.203, optim_step_time=0.065, optim0_lr0=1.893e-04, train_time=1.013
[alab02] 2024-08-29 17:10:13,547 (trainer:720) INFO: 59epoch:train:5201-5400batch: iter_time=4.363e-04, forward_time=0.169, uma_reduction=0.246, text_vs_uma=0.388, loss_ctc=4.602, loss=2.301, backward_time=0.207, optim_step_time=0.066, optim0_lr0=1.893e-04, train_time=1.030
[alab02] 2024-08-29 17:11:51,814 (trainer:720) INFO: 59epoch:train:5401-5600batch: iter_time=4.145e-04, forward_time=0.157, uma_reduction=0.238, text_vs_uma=0.394, loss_ctc=3.962, loss=1.981, backward_time=0.204, optim_step_time=0.060, optim0_lr0=1.893e-04, train_time=0.982
[alab02] 2024-08-29 17:13:32,675 (trainer:720) INFO: 59epoch:train:5601-5800batch: iter_time=5.250e-04, forward_time=0.166, uma_reduction=0.241, text_vs_uma=0.406, loss_ctc=4.567, loss=2.283, backward_time=0.203, optim_step_time=0.062, optim0_lr0=1.892e-04, train_time=1.008
[alab02] 2024-08-29 17:15:13,526 (trainer:720) INFO: 59epoch:train:5801-6000batch: iter_time=4.896e-04, forward_time=0.163, uma_reduction=0.234, text_vs_uma=0.420, loss_ctc=5.017, loss=2.509, backward_time=0.197, optim_step_time=0.067, optim0_lr0=1.892e-04, train_time=1.008
[alab02] 2024-08-29 17:16:53,781 (trainer:720) INFO: 59epoch:train:6001-6200batch: iter_time=4.100e-04, forward_time=0.161, uma_reduction=0.241, text_vs_uma=0.398, loss_ctc=4.726, loss=2.363, backward_time=0.204, optim_step_time=0.060, optim0_lr0=1.891e-04, train_time=1.002
[alab02] 2024-08-29 17:18:35,827 (trainer:720) INFO: 59epoch:train:6201-6400batch: iter_time=4.549e-04, forward_time=0.165, uma_reduction=0.232, text_vs_uma=0.418, loss_ctc=4.774, loss=2.387, backward_time=0.208, optim_step_time=0.064, optim0_lr0=1.891e-04, train_time=1.020
[alab02] 2024-08-29 17:20:15,564 (trainer:720) INFO: 59epoch:train:6401-6600batch: iter_time=4.517e-04, forward_time=0.162, uma_reduction=0.237, text_vs_uma=0.405, loss_ctc=4.706, loss=2.353, backward_time=0.199, optim_step_time=0.063, optim0_lr0=1.890e-04, train_time=0.997
[alab02] 2024-08-29 17:21:56,349 (trainer:720) INFO: 59epoch:train:6601-6800batch: iter_time=4.479e-04, forward_time=0.165, uma_reduction=0.236, text_vs_uma=0.416, loss_ctc=5.112, loss=2.556, backward_time=0.202, optim_step_time=0.063, optim0_lr0=1.890e-04, train_time=1.007
[alab02] 2024-08-29 17:23:38,507 (trainer:720) INFO: 59epoch:train:6801-7000batch: iter_time=3.776e-04, forward_time=0.165, uma_reduction=0.236, text_vs_uma=0.414, loss_ctc=4.887, loss=2.444, backward_time=0.210, optim_step_time=0.060, optim0_lr0=1.889e-04, train_time=1.021
[alab02] 2024-08-29 17:25:16,326 (trainer:338) INFO: 59epoch results: [train] iter_time=4.912e-04, forward_time=0.154, uma_reduction=0.240, text_vs_uma=0.402, loss_ctc=4.571, loss=2.286, backward_time=0.198, optim_step_time=0.055, optim0_lr0=1.897e-04, train_time=0.971, time=57 minutes and 44.3 seconds, total_count=420434, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.262, text_vs_uma=0.414, loss_ctc=3.324, cer_ctc=0.094, cer=0.094, loss=3.324, time=8.44 seconds, total_count=1534, gpu_max_cached_mem_GB=35.906, [att_plot] time=23.46 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 17:25:25,089 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 17:25:25,101 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/45epoch.pth
[alab02] 2024-08-29 17:25:25,102 (trainer:272) INFO: 60/150epoch started. Estimated time to finish: 3 days, 12 hours and 2 minutes
[alab02] 2024-08-29 17:27:08,871 (trainer:720) INFO: 60epoch:train:1-200batch: iter_time=0.004, forward_time=0.165, uma_reduction=0.237, text_vs_uma=0.404, loss_ctc=4.789, loss=2.394, backward_time=0.205, optim_step_time=0.065, optim0_lr0=1.889e-04, train_time=1.037
[alab02] 2024-08-29 17:28:51,636 (trainer:720) INFO: 60epoch:train:201-400batch: iter_time=5.208e-04, forward_time=0.166, uma_reduction=0.250, text_vs_uma=0.384, loss_ctc=4.365, loss=2.183, backward_time=0.210, optim_step_time=0.066, optim0_lr0=1.888e-04, train_time=1.027
[alab02] 2024-08-29 17:29:02,416 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 17:30:33,417 (trainer:720) INFO: 60epoch:train:401-600batch: iter_time=4.736e-04, forward_time=0.167, uma_reduction=0.248, text_vs_uma=0.395, loss_ctc=4.497, loss=2.249, backward_time=0.204, optim_step_time=0.064, optim0_lr0=1.888e-04, train_time=1.017
[alab02] 2024-08-29 17:32:14,272 (trainer:720) INFO: 60epoch:train:601-800batch: iter_time=4.412e-04, forward_time=0.160, uma_reduction=0.245, text_vs_uma=0.396, loss_ctc=4.720, loss=2.360, backward_time=0.204, optim_step_time=0.060, optim0_lr0=1.887e-04, train_time=1.008
[alab02] 2024-08-29 17:33:57,437 (trainer:720) INFO: 60epoch:train:801-1000batch: iter_time=4.609e-04, forward_time=0.166, uma_reduction=0.239, text_vs_uma=0.399, loss_ctc=4.783, loss=2.392, backward_time=0.210, optim_step_time=0.063, optim0_lr0=1.887e-04, train_time=1.031
[alab02] 2024-08-29 17:35:36,404 (trainer:720) INFO: 60epoch:train:1001-1200batch: iter_time=4.522e-04, forward_time=0.158, uma_reduction=0.235, text_vs_uma=0.413, loss_ctc=4.739, loss=2.369, backward_time=0.202, optim_step_time=0.058, optim0_lr0=1.886e-04, train_time=0.989
[alab02] 2024-08-29 17:37:16,245 (trainer:720) INFO: 60epoch:train:1201-1400batch: iter_time=4.621e-04, forward_time=0.160, uma_reduction=0.240, text_vs_uma=0.408, loss_ctc=4.566, loss=2.283, backward_time=0.204, optim_step_time=0.057, optim0_lr0=1.886e-04, train_time=0.998
[alab02] 2024-08-29 17:38:54,462 (trainer:720) INFO: 60epoch:train:1401-1600batch: iter_time=4.205e-04, forward_time=0.155, uma_reduction=0.247, text_vs_uma=0.388, loss_ctc=4.791, loss=2.395, backward_time=0.198, optim_step_time=0.051, optim0_lr0=1.885e-04, train_time=0.982
[alab02] 2024-08-29 17:40:25,771 (trainer:720) INFO: 60epoch:train:1601-1800batch: iter_time=2.837e-04, forward_time=0.141, uma_reduction=0.248, text_vs_uma=0.386, loss_ctc=4.638, loss=2.319, backward_time=0.184, optim_step_time=0.047, optim0_lr0=1.885e-04, train_time=0.913
[alab02] 2024-08-29 17:41:56,133 (trainer:720) INFO: 60epoch:train:1801-2000batch: iter_time=2.511e-04, forward_time=0.137, uma_reduction=0.245, text_vs_uma=0.389, loss_ctc=4.857, loss=2.429, backward_time=0.183, optim_step_time=0.040, optim0_lr0=1.885e-04, train_time=0.903
[alab02] 2024-08-29 17:43:25,514 (trainer:720) INFO: 60epoch:train:2001-2200batch: iter_time=2.448e-04, forward_time=0.137, uma_reduction=0.246, text_vs_uma=0.392, loss_ctc=4.512, loss=2.256, backward_time=0.185, optim_step_time=0.039, optim0_lr0=1.884e-04, train_time=0.893
[alab02] 2024-08-29 17:44:52,838 (trainer:720) INFO: 60epoch:train:2201-2400batch: iter_time=2.034e-04, forward_time=0.132, uma_reduction=0.246, text_vs_uma=0.394, loss_ctc=4.669, loss=2.334, backward_time=0.178, optim_step_time=0.037, optim0_lr0=1.884e-04, train_time=0.873
[alab02] 2024-08-29 17:46:20,825 (trainer:720) INFO: 60epoch:train:2401-2600batch: iter_time=2.104e-04, forward_time=0.132, uma_reduction=0.246, text_vs_uma=0.393, loss_ctc=4.481, loss=2.240, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.883e-04, train_time=0.880
[alab02] 2024-08-29 17:47:45,753 (trainer:720) INFO: 60epoch:train:2601-2800batch: iter_time=1.906e-04, forward_time=0.126, uma_reduction=0.245, text_vs_uma=0.398, loss_ctc=5.154, loss=2.577, backward_time=0.170, optim_step_time=0.036, optim0_lr0=1.883e-04, train_time=0.849
[alab02] 2024-08-29 17:49:14,648 (trainer:720) INFO: 60epoch:train:2801-3000batch: iter_time=1.835e-04, forward_time=0.134, uma_reduction=0.246, text_vs_uma=0.387, loss_ctc=4.606, loss=2.303, backward_time=0.184, optim_step_time=0.036, optim0_lr0=1.882e-04, train_time=0.889
[alab02] 2024-08-29 17:50:41,660 (trainer:720) INFO: 60epoch:train:3001-3200batch: iter_time=1.893e-04, forward_time=0.130, uma_reduction=0.250, text_vs_uma=0.389, loss_ctc=4.722, loss=2.361, backward_time=0.178, optim_step_time=0.036, optim0_lr0=1.882e-04, train_time=0.870
[alab02] 2024-08-29 17:52:10,238 (trainer:720) INFO: 60epoch:train:3201-3400batch: iter_time=2.215e-04, forward_time=0.132, uma_reduction=0.255, text_vs_uma=0.381, loss_ctc=4.209, loss=2.104, backward_time=0.188, optim_step_time=0.034, optim0_lr0=1.881e-04, train_time=0.886
[alab02] 2024-08-29 17:53:38,738 (trainer:720) INFO: 60epoch:train:3401-3600batch: iter_time=2.069e-04, forward_time=0.131, uma_reduction=0.262, text_vs_uma=0.371, loss_ctc=4.742, loss=2.371, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.881e-04, train_time=0.885
[alab02] 2024-08-29 17:55:05,035 (trainer:720) INFO: 60epoch:train:3601-3800batch: iter_time=1.745e-04, forward_time=0.128, uma_reduction=0.257, text_vs_uma=0.387, loss_ctc=4.625, loss=2.313, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.881e-04, train_time=0.863
[alab02] 2024-08-29 17:56:32,468 (trainer:720) INFO: 60epoch:train:3801-4000batch: iter_time=1.682e-04, forward_time=0.132, uma_reduction=0.246, text_vs_uma=0.388, loss_ctc=4.367, loss=2.183, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.880e-04, train_time=0.874
[alab02] 2024-08-29 17:58:00,867 (trainer:720) INFO: 60epoch:train:4001-4200batch: iter_time=1.663e-04, forward_time=0.132, uma_reduction=0.248, text_vs_uma=0.400, loss_ctc=4.727, loss=2.364, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.880e-04, train_time=0.884
[alab02] 2024-08-29 17:59:29,318 (trainer:720) INFO: 60epoch:train:4201-4400batch: iter_time=1.707e-04, forward_time=0.132, uma_reduction=0.255, text_vs_uma=0.374, loss_ctc=4.191, loss=2.095, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.879e-04, train_time=0.884
[alab02] 2024-08-29 18:00:57,045 (trainer:720) INFO: 60epoch:train:4401-4600batch: iter_time=1.756e-04, forward_time=0.131, uma_reduction=0.252, text_vs_uma=0.380, loss_ctc=4.543, loss=2.272, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.879e-04, train_time=0.877
[alab02] 2024-08-29 18:02:22,372 (trainer:720) INFO: 60epoch:train:4601-4800batch: iter_time=1.828e-04, forward_time=0.127, uma_reduction=0.254, text_vs_uma=0.383, loss_ctc=4.269, loss=2.134, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.878e-04, train_time=0.853
[alab02] 2024-08-29 18:03:49,584 (trainer:720) INFO: 60epoch:train:4801-5000batch: iter_time=1.636e-04, forward_time=0.130, uma_reduction=0.248, text_vs_uma=0.391, loss_ctc=4.561, loss=2.280, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.878e-04, train_time=0.872
[alab02] 2024-08-29 18:05:16,744 (trainer:720) INFO: 60epoch:train:5001-5200batch: iter_time=1.839e-04, forward_time=0.130, uma_reduction=0.250, text_vs_uma=0.393, loss_ctc=4.576, loss=2.288, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.877e-04, train_time=0.871
[alab02] 2024-08-29 18:06:43,927 (trainer:720) INFO: 60epoch:train:5201-5400batch: iter_time=1.727e-04, forward_time=0.129, uma_reduction=0.242, text_vs_uma=0.403, loss_ctc=4.812, loss=2.406, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.877e-04, train_time=0.872
[alab02] 2024-08-29 18:07:21,625 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 18:08:12,744 (trainer:720) INFO: 60epoch:train:5401-5600batch: iter_time=1.739e-04, forward_time=0.133, uma_reduction=0.251, text_vs_uma=0.390, loss_ctc=4.523, loss=2.262, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.877e-04, train_time=0.888
[alab02] 2024-08-29 18:09:39,428 (trainer:720) INFO: 60epoch:train:5601-5800batch: iter_time=1.788e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.384, loss_ctc=5.105, loss=2.552, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.876e-04, train_time=0.867
[alab02] 2024-08-29 18:11:05,421 (trainer:720) INFO: 60epoch:train:5801-6000batch: iter_time=1.826e-04, forward_time=0.128, uma_reduction=0.251, text_vs_uma=0.381, loss_ctc=4.136, loss=2.068, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.876e-04, train_time=0.860
[alab02] 2024-08-29 18:12:35,743 (trainer:720) INFO: 60epoch:train:6001-6200batch: iter_time=1.893e-04, forward_time=0.135, uma_reduction=0.249, text_vs_uma=0.388, loss_ctc=4.937, loss=2.468, backward_time=0.187, optim_step_time=0.035, optim0_lr0=1.875e-04, train_time=0.903
[alab02] 2024-08-29 18:14:01,958 (trainer:720) INFO: 60epoch:train:6201-6400batch: iter_time=1.765e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.371, loss_ctc=4.384, loss=2.192, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.875e-04, train_time=0.862
[alab02] 2024-08-29 18:15:29,271 (trainer:720) INFO: 60epoch:train:6401-6600batch: iter_time=1.738e-04, forward_time=0.130, uma_reduction=0.254, text_vs_uma=0.383, loss_ctc=4.658, loss=2.329, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.874e-04, train_time=0.873
[alab02] 2024-08-29 18:16:56,101 (trainer:720) INFO: 60epoch:train:6601-6800batch: iter_time=1.786e-04, forward_time=0.131, uma_reduction=0.245, text_vs_uma=0.390, loss_ctc=4.489, loss=2.245, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.874e-04, train_time=0.868
[alab02] 2024-08-29 18:18:24,487 (trainer:720) INFO: 60epoch:train:6801-7000batch: iter_time=1.739e-04, forward_time=0.132, uma_reduction=0.242, text_vs_uma=0.391, loss_ctc=4.822, loss=2.411, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.874e-04, train_time=0.884
[alab02] 2024-08-29 18:19:40,866 (trainer:338) INFO: 60epoch results: [train] iter_time=3.457e-04, forward_time=0.138, uma_reduction=0.248, text_vs_uma=0.390, loss_ctc=4.607, loss=2.303, backward_time=0.187, optim_step_time=0.041, optim0_lr0=1.881e-04, train_time=0.908, time=53 minutes and 56.39 seconds, total_count=427560, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.268, text_vs_uma=0.405, loss_ctc=3.252, cer_ctc=0.086, cer=0.086, loss=3.252, time=6.15 seconds, total_count=1560, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.22 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 18:19:45,718 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-29 18:19:45,725 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/49epoch.pth
[alab02] 2024-08-29 18:19:45,725 (trainer:272) INFO: 61/150epoch started. Estimated time to finish: 3 days, 11 hours and 5 minutes
[alab02] 2024-08-29 18:21:14,797 (trainer:720) INFO: 61epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.246, text_vs_uma=0.397, loss_ctc=4.368, loss=2.184, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.873e-04, train_time=0.890
[alab02] 2024-08-29 18:22:41,770 (trainer:720) INFO: 61epoch:train:201-400batch: iter_time=2.064e-04, forward_time=0.131, uma_reduction=0.246, text_vs_uma=0.394, loss_ctc=4.234, loss=2.117, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.872e-04, train_time=0.869
[alab02] 2024-08-29 18:24:09,032 (trainer:720) INFO: 61epoch:train:401-600batch: iter_time=1.796e-04, forward_time=0.130, uma_reduction=0.251, text_vs_uma=0.380, loss_ctc=4.168, loss=2.084, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.872e-04, train_time=0.872
[alab02] 2024-08-29 18:25:34,496 (trainer:720) INFO: 61epoch:train:601-800batch: iter_time=1.905e-04, forward_time=0.127, uma_reduction=0.252, text_vs_uma=0.385, loss_ctc=4.634, loss=2.317, backward_time=0.173, optim_step_time=0.035, optim0_lr0=1.872e-04, train_time=0.854
[alab02] 2024-08-29 18:27:01,330 (trainer:720) INFO: 61epoch:train:801-1000batch: iter_time=1.991e-04, forward_time=0.130, uma_reduction=0.259, text_vs_uma=0.368, loss_ctc=3.985, loss=1.993, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.871e-04, train_time=0.868
[alab02] 2024-08-29 18:28:27,709 (trainer:720) INFO: 61epoch:train:1001-1200batch: iter_time=1.881e-04, forward_time=0.128, uma_reduction=0.252, text_vs_uma=0.388, loss_ctc=4.721, loss=2.360, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.871e-04, train_time=0.864
[alab02] 2024-08-29 18:28:50,545 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 18:29:52,971 (trainer:720) INFO: 61epoch:train:1201-1400batch: iter_time=2.118e-04, forward_time=0.126, uma_reduction=0.248, text_vs_uma=0.389, loss_ctc=4.718, loss=2.359, backward_time=0.175, optim_step_time=0.035, optim0_lr0=1.870e-04, train_time=0.852
[alab02] 2024-08-29 18:31:20,465 (trainer:720) INFO: 61epoch:train:1401-1600batch: iter_time=1.859e-04, forward_time=0.130, uma_reduction=0.242, text_vs_uma=0.393, loss_ctc=4.147, loss=2.074, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.870e-04, train_time=0.875
[alab02] 2024-08-29 18:32:47,406 (trainer:720) INFO: 61epoch:train:1601-1800batch: iter_time=1.829e-04, forward_time=0.128, uma_reduction=0.235, text_vs_uma=0.403, loss_ctc=4.495, loss=2.248, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.869e-04, train_time=0.869
[alab02] 2024-08-29 18:34:14,535 (trainer:720) INFO: 61epoch:train:1801-2000batch: iter_time=1.784e-04, forward_time=0.129, uma_reduction=0.244, text_vs_uma=0.392, loss_ctc=4.619, loss=2.310, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.869e-04, train_time=0.871
[alab02] 2024-08-29 18:35:41,426 (trainer:720) INFO: 61epoch:train:2001-2200batch: iter_time=1.774e-04, forward_time=0.130, uma_reduction=0.244, text_vs_uma=0.399, loss_ctc=4.562, loss=2.281, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.868e-04, train_time=0.869
[alab02] 2024-08-29 18:37:08,119 (trainer:720) INFO: 61epoch:train:2201-2400batch: iter_time=1.886e-04, forward_time=0.129, uma_reduction=0.247, text_vs_uma=0.394, loss_ctc=4.512, loss=2.256, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.868e-04, train_time=0.867
[alab02] 2024-08-29 18:38:35,647 (trainer:720) INFO: 61epoch:train:2401-2600batch: iter_time=1.719e-04, forward_time=0.130, uma_reduction=0.242, text_vs_uma=0.393, loss_ctc=4.360, loss=2.180, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.868e-04, train_time=0.875
[alab02] 2024-08-29 18:40:02,392 (trainer:720) INFO: 61epoch:train:2601-2800batch: iter_time=1.710e-04, forward_time=0.128, uma_reduction=0.244, text_vs_uma=0.393, loss_ctc=4.698, loss=2.349, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.867e-04, train_time=0.867
[alab02] 2024-08-29 18:41:30,144 (trainer:720) INFO: 61epoch:train:2801-3000batch: iter_time=1.716e-04, forward_time=0.130, uma_reduction=0.241, text_vs_uma=0.402, loss_ctc=4.415, loss=2.207, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.867e-04, train_time=0.877
[alab02] 2024-08-29 18:42:57,382 (trainer:720) INFO: 61epoch:train:3001-3200batch: iter_time=1.820e-04, forward_time=0.129, uma_reduction=0.239, text_vs_uma=0.397, loss_ctc=4.226, loss=2.113, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.866e-04, train_time=0.872
[alab02] 2024-08-29 18:44:25,050 (trainer:720) INFO: 61epoch:train:3201-3400batch: iter_time=1.650e-04, forward_time=0.129, uma_reduction=0.249, text_vs_uma=0.377, loss_ctc=4.353, loss=2.177, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.866e-04, train_time=0.876
[alab02] 2024-08-29 18:45:53,416 (trainer:720) INFO: 61epoch:train:3401-3600batch: iter_time=1.629e-04, forward_time=0.130, uma_reduction=0.245, text_vs_uma=0.400, loss_ctc=4.455, loss=2.228, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.865e-04, train_time=0.883
[alab02] 2024-08-29 18:47:20,652 (trainer:720) INFO: 61epoch:train:3601-3800batch: iter_time=1.759e-04, forward_time=0.129, uma_reduction=0.235, text_vs_uma=0.412, loss_ctc=4.257, loss=2.128, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.865e-04, train_time=0.872
[alab02] 2024-08-29 18:48:47,604 (trainer:720) INFO: 61epoch:train:3801-4000batch: iter_time=1.629e-04, forward_time=0.129, uma_reduction=0.239, text_vs_uma=0.405, loss_ctc=4.648, loss=2.324, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.865e-04, train_time=0.869
[alab02] 2024-08-29 18:50:14,073 (trainer:720) INFO: 61epoch:train:4001-4200batch: iter_time=1.572e-04, forward_time=0.128, uma_reduction=0.243, text_vs_uma=0.405, loss_ctc=5.029, loss=2.514, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.864e-04, train_time=0.864
[alab02] 2024-08-29 18:51:41,164 (trainer:720) INFO: 61epoch:train:4201-4400batch: iter_time=1.822e-04, forward_time=0.129, uma_reduction=0.250, text_vs_uma=0.390, loss_ctc=4.335, loss=2.167, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.864e-04, train_time=0.871
[alab02] 2024-08-29 18:53:08,812 (trainer:720) INFO: 61epoch:train:4401-4600batch: iter_time=1.731e-04, forward_time=0.130, uma_reduction=0.238, text_vs_uma=0.405, loss_ctc=4.338, loss=2.169, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.863e-04, train_time=0.876
[alab02] 2024-08-29 18:54:34,117 (trainer:720) INFO: 61epoch:train:4601-4800batch: iter_time=1.687e-04, forward_time=0.126, uma_reduction=0.231, text_vs_uma=0.423, loss_ctc=4.661, loss=2.331, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.863e-04, train_time=0.853
[alab02] 2024-08-29 18:55:58,945 (trainer:720) INFO: 61epoch:train:4801-5000batch: iter_time=1.756e-04, forward_time=0.125, uma_reduction=0.236, text_vs_uma=0.404, loss_ctc=4.463, loss=2.232, backward_time=0.175, optim_step_time=0.035, optim0_lr0=1.862e-04, train_time=0.848
[alab02] 2024-08-29 18:57:26,985 (trainer:720) INFO: 61epoch:train:5001-5200batch: iter_time=1.797e-04, forward_time=0.131, uma_reduction=0.236, text_vs_uma=0.401, loss_ctc=4.345, loss=2.173, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.862e-04, train_time=0.880
[alab02] 2024-08-29 18:58:52,786 (trainer:720) INFO: 61epoch:train:5201-5400batch: iter_time=1.635e-04, forward_time=0.126, uma_reduction=0.235, text_vs_uma=0.403, loss_ctc=4.389, loss=2.194, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.862e-04, train_time=0.858
[alab02] 2024-08-29 19:00:18,936 (trainer:720) INFO: 61epoch:train:5401-5600batch: iter_time=1.748e-04, forward_time=0.127, uma_reduction=0.235, text_vs_uma=0.406, loss_ctc=4.392, loss=2.196, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.861e-04, train_time=0.861
[alab02] 2024-08-29 19:01:48,722 (trainer:720) INFO: 61epoch:train:5601-5800batch: iter_time=1.705e-04, forward_time=0.132, uma_reduction=0.242, text_vs_uma=0.403, loss_ctc=4.618, loss=2.309, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.861e-04, train_time=0.898
[alab02] 2024-08-29 19:03:15,486 (trainer:720) INFO: 61epoch:train:5801-6000batch: iter_time=1.688e-04, forward_time=0.129, uma_reduction=0.262, text_vs_uma=0.375, loss_ctc=4.417, loss=2.209, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.860e-04, train_time=0.867
[alab02] 2024-08-29 19:04:43,482 (trainer:720) INFO: 61epoch:train:6001-6200batch: iter_time=1.635e-04, forward_time=0.130, uma_reduction=0.260, text_vs_uma=0.361, loss_ctc=4.437, loss=2.219, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.860e-04, train_time=0.880
[alab02] 2024-08-29 19:06:10,657 (trainer:720) INFO: 61epoch:train:6201-6400batch: iter_time=1.579e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.368, loss_ctc=4.221, loss=2.110, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.859e-04, train_time=0.872
[alab02] 2024-08-29 19:07:35,923 (trainer:720) INFO: 61epoch:train:6401-6600batch: iter_time=1.572e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.353, loss_ctc=4.309, loss=2.155, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.859e-04, train_time=0.852
[alab02] 2024-08-29 19:09:03,278 (trainer:720) INFO: 61epoch:train:6601-6800batch: iter_time=1.782e-04, forward_time=0.129, uma_reduction=0.261, text_vs_uma=0.373, loss_ctc=4.784, loss=2.392, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.859e-04, train_time=0.873
[alab02] 2024-08-29 19:10:30,665 (trainer:720) INFO: 61epoch:train:6801-7000batch: iter_time=2.226e-04, forward_time=0.130, uma_reduction=0.262, text_vs_uma=0.362, loss_ctc=4.539, loss=2.270, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.858e-04, train_time=0.874
[alab02] 2024-08-29 19:11:45,372 (trainer:338) INFO: 61epoch results: [train] iter_time=2.278e-04, forward_time=0.129, uma_reduction=0.246, text_vs_uma=0.391, loss_ctc=4.444, loss=2.222, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.865e-04, train_time=0.870, time=51 minutes and 40.02 seconds, total_count=434686, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.261, text_vs_uma=0.417, loss_ctc=3.444, cer_ctc=0.089, cer=0.089, loss=3.444, time=6.31 seconds, total_count=1586, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.31 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 19:11:50,221 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 19:11:50,227 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/52epoch.pth
[alab02] 2024-08-29 19:11:50,228 (trainer:272) INFO: 62/150epoch started. Estimated time to finish: 3 days, 10 hours and 4 minutes
[alab02] 2024-08-29 19:13:18,608 (trainer:720) INFO: 62epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.238, text_vs_uma=0.416, loss_ctc=4.791, loss=2.395, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.857e-04, train_time=0.883
[alab02] 2024-08-29 19:14:48,046 (trainer:720) INFO: 62epoch:train:201-400batch: iter_time=2.206e-04, forward_time=0.133, uma_reduction=0.248, text_vs_uma=0.396, loss_ctc=4.657, loss=2.328, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.857e-04, train_time=0.894
[alab02] 2024-08-29 19:16:18,038 (trainer:720) INFO: 62epoch:train:401-600batch: iter_time=2.103e-04, forward_time=0.134, uma_reduction=0.239, text_vs_uma=0.406, loss_ctc=4.463, loss=2.232, backward_time=0.190, optim_step_time=0.035, optim0_lr0=1.857e-04, train_time=0.900
[alab02] 2024-08-29 19:17:48,249 (trainer:720) INFO: 62epoch:train:601-800batch: iter_time=2.114e-04, forward_time=0.136, uma_reduction=0.244, text_vs_uma=0.387, loss_ctc=4.125, loss=2.062, backward_time=0.192, optim_step_time=0.034, optim0_lr0=1.856e-04, train_time=0.902
[alab02] 2024-08-29 19:19:14,818 (trainer:720) INFO: 62epoch:train:801-1000batch: iter_time=2.018e-04, forward_time=0.129, uma_reduction=0.241, text_vs_uma=0.405, loss_ctc=4.261, loss=2.130, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.856e-04, train_time=0.865
[alab02] 2024-08-29 19:20:39,755 (trainer:720) INFO: 62epoch:train:1001-1200batch: iter_time=1.760e-04, forward_time=0.125, uma_reduction=0.240, text_vs_uma=0.404, loss_ctc=4.495, loss=2.247, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.855e-04, train_time=0.849
[alab02] 2024-08-29 19:22:03,940 (trainer:720) INFO: 62epoch:train:1201-1400batch: iter_time=1.933e-04, forward_time=0.125, uma_reduction=0.239, text_vs_uma=0.405, loss_ctc=4.739, loss=2.369, backward_time=0.171, optim_step_time=0.035, optim0_lr0=1.855e-04, train_time=0.842
[alab02] 2024-08-29 19:23:31,810 (trainer:720) INFO: 62epoch:train:1401-1600batch: iter_time=1.972e-04, forward_time=0.130, uma_reduction=0.245, text_vs_uma=0.391, loss_ctc=4.545, loss=2.272, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.854e-04, train_time=0.878
[alab02] 2024-08-29 19:24:59,421 (trainer:720) INFO: 62epoch:train:1601-1800batch: iter_time=1.794e-04, forward_time=0.130, uma_reduction=0.250, text_vs_uma=0.388, loss_ctc=4.474, loss=2.237, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.854e-04, train_time=0.876
[alab02] 2024-08-29 19:26:26,504 (trainer:720) INFO: 62epoch:train:1801-2000batch: iter_time=2.017e-04, forward_time=0.129, uma_reduction=0.243, text_vs_uma=0.408, loss_ctc=4.696, loss=2.348, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.854e-04, train_time=0.871
[alab02] 2024-08-29 19:27:54,883 (trainer:720) INFO: 62epoch:train:2001-2200batch: iter_time=1.808e-04, forward_time=0.130, uma_reduction=0.244, text_vs_uma=0.399, loss_ctc=4.775, loss=2.388, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.853e-04, train_time=0.884
[alab02] 2024-08-29 19:28:36,181 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 19:29:22,341 (trainer:720) INFO: 62epoch:train:2201-2400batch: iter_time=1.715e-04, forward_time=0.129, uma_reduction=0.245, text_vs_uma=0.398, loss_ctc=4.502, loss=2.251, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.853e-04, train_time=0.874
[alab02] 2024-08-29 19:30:49,747 (trainer:720) INFO: 62epoch:train:2401-2600batch: iter_time=1.712e-04, forward_time=0.130, uma_reduction=0.239, text_vs_uma=0.403, loss_ctc=4.405, loss=2.203, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.852e-04, train_time=0.874
[alab02] 2024-08-29 19:32:13,702 (trainer:720) INFO: 62epoch:train:2601-2800batch: iter_time=1.748e-04, forward_time=0.125, uma_reduction=0.256, text_vs_uma=0.384, loss_ctc=4.631, loss=2.316, backward_time=0.170, optim_step_time=0.034, optim0_lr0=1.852e-04, train_time=0.839
[alab02] 2024-08-29 19:33:42,973 (trainer:720) INFO: 62epoch:train:2801-3000batch: iter_time=1.731e-04, forward_time=0.132, uma_reduction=0.257, text_vs_uma=0.371, loss_ctc=4.044, loss=2.022, backward_time=0.190, optim_step_time=0.033, optim0_lr0=1.851e-04, train_time=0.892
[alab02] 2024-08-29 19:35:10,884 (trainer:720) INFO: 62epoch:train:3001-3200batch: iter_time=1.646e-04, forward_time=0.131, uma_reduction=0.259, text_vs_uma=0.372, loss_ctc=4.321, loss=2.161, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.851e-04, train_time=0.879
[alab02] 2024-08-29 19:36:38,243 (trainer:720) INFO: 62epoch:train:3201-3400batch: iter_time=1.716e-04, forward_time=0.130, uma_reduction=0.262, text_vs_uma=0.365, loss_ctc=4.285, loss=2.143, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.851e-04, train_time=0.873
[alab02] 2024-08-29 19:38:07,533 (trainer:720) INFO: 62epoch:train:3401-3600batch: iter_time=1.812e-04, forward_time=0.132, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=4.545, loss=2.272, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.850e-04, train_time=0.893
[alab02] 2024-08-29 19:39:33,829 (trainer:720) INFO: 62epoch:train:3601-3800batch: iter_time=1.795e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.342, loss_ctc=4.203, loss=2.101, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.850e-04, train_time=0.863
[alab02] 2024-08-29 19:41:01,984 (trainer:720) INFO: 62epoch:train:3801-4000batch: iter_time=1.744e-04, forward_time=0.131, uma_reduction=0.261, text_vs_uma=0.367, loss_ctc=4.355, loss=2.177, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.849e-04, train_time=0.881
[alab02] 2024-08-29 19:41:36,363 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 19:42:29,378 (trainer:720) INFO: 62epoch:train:4001-4200batch: iter_time=1.722e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.377, loss_ctc=4.652, loss=2.326, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.849e-04, train_time=0.874
[alab02] 2024-08-29 19:43:56,848 (trainer:720) INFO: 62epoch:train:4201-4400batch: iter_time=1.801e-04, forward_time=0.130, uma_reduction=0.253, text_vs_uma=0.382, loss_ctc=4.305, loss=2.153, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.849e-04, train_time=0.874
[alab02] 2024-08-29 19:45:24,227 (trainer:720) INFO: 62epoch:train:4401-4600batch: iter_time=1.759e-04, forward_time=0.130, uma_reduction=0.251, text_vs_uma=0.384, loss_ctc=4.532, loss=2.266, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.848e-04, train_time=0.874
[alab02] 2024-08-29 19:46:49,874 (trainer:720) INFO: 62epoch:train:4601-4800batch: iter_time=1.929e-04, forward_time=0.127, uma_reduction=0.244, text_vs_uma=0.389, loss_ctc=4.281, loss=2.140, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.848e-04, train_time=0.856
[alab02] 2024-08-29 19:48:16,153 (trainer:720) INFO: 62epoch:train:4801-5000batch: iter_time=1.699e-04, forward_time=0.127, uma_reduction=0.254, text_vs_uma=0.380, loss_ctc=4.549, loss=2.275, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.847e-04, train_time=0.863
[alab02] 2024-08-29 19:49:41,565 (trainer:720) INFO: 62epoch:train:5001-5200batch: iter_time=1.699e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.361, loss_ctc=4.070, loss=2.035, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.847e-04, train_time=0.854
[alab02] 2024-08-29 19:51:07,944 (trainer:720) INFO: 62epoch:train:5201-5400batch: iter_time=1.807e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.370, loss_ctc=4.171, loss=2.085, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.846e-04, train_time=0.864
[alab02] 2024-08-29 19:52:35,902 (trainer:720) INFO: 62epoch:train:5401-5600batch: iter_time=1.634e-04, forward_time=0.130, uma_reduction=0.252, text_vs_uma=0.383, loss_ctc=4.783, loss=2.392, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.846e-04, train_time=0.879
[alab02] 2024-08-29 19:54:02,475 (trainer:720) INFO: 62epoch:train:5601-5800batch: iter_time=1.710e-04, forward_time=0.127, uma_reduction=0.256, text_vs_uma=0.384, loss_ctc=4.791, loss=2.395, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.846e-04, train_time=0.866
[alab02] 2024-08-29 19:55:30,106 (trainer:720) INFO: 62epoch:train:5801-6000batch: iter_time=1.790e-04, forward_time=0.130, uma_reduction=0.250, text_vs_uma=0.380, loss_ctc=4.335, loss=2.168, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.845e-04, train_time=0.876
[alab02] 2024-08-29 19:56:55,023 (trainer:720) INFO: 62epoch:train:6001-6200batch: iter_time=1.625e-04, forward_time=0.125, uma_reduction=0.250, text_vs_uma=0.384, loss_ctc=4.208, loss=2.104, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.845e-04, train_time=0.849
[alab02] 2024-08-29 19:58:20,909 (trainer:720) INFO: 62epoch:train:6201-6400batch: iter_time=1.643e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.362, loss_ctc=4.266, loss=2.133, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.844e-04, train_time=0.859
[alab02] 2024-08-29 19:59:48,080 (trainer:720) INFO: 62epoch:train:6401-6600batch: iter_time=1.704e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=4.357, loss=2.178, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.844e-04, train_time=0.871
[alab02] 2024-08-29 20:01:12,910 (trainer:720) INFO: 62epoch:train:6601-6800batch: iter_time=1.750e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=4.434, loss=2.217, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.843e-04, train_time=0.848
[alab02] 2024-08-29 20:02:40,963 (trainer:720) INFO: 62epoch:train:6801-7000batch: iter_time=1.738e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=4.575, loss=2.287, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.843e-04, train_time=0.880
[alab02] 2024-08-29 20:03:54,961 (trainer:338) INFO: 62epoch results: [train] iter_time=2.221e-04, forward_time=0.129, uma_reduction=0.253, text_vs_uma=0.382, loss_ctc=4.441, loss=2.221, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.850e-04, train_time=0.871, time=51 minutes and 45.24 seconds, total_count=441812, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.268, text_vs_uma=0.405, loss_ctc=3.322, cer_ctc=0.086, cer=0.086, loss=3.322, time=6.32 seconds, total_count=1612, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.16 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 20:04:00,149 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 20:04:00,203 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/59epoch.pth
[alab02] 2024-08-29 20:04:00,203 (trainer:272) INFO: 63/150epoch started. Estimated time to finish: 3 days, 9 hours and 4 minutes
[alab02] 2024-08-29 20:05:27,422 (trainer:720) INFO: 63epoch:train:1-200batch: iter_time=0.002, forward_time=0.129, uma_reduction=0.262, text_vs_uma=0.367, loss_ctc=4.415, loss=2.207, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.842e-04, train_time=0.872
[alab02] 2024-08-29 20:06:54,258 (trainer:720) INFO: 63epoch:train:201-400batch: iter_time=1.987e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=4.274, loss=2.137, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.842e-04, train_time=0.868
[alab02] 2024-08-29 20:08:21,578 (trainer:720) INFO: 63epoch:train:401-600batch: iter_time=2.063e-04, forward_time=0.130, uma_reduction=0.254, text_vs_uma=0.374, loss_ctc=4.259, loss=2.130, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.842e-04, train_time=0.873
[alab02] 2024-08-29 20:09:48,954 (trainer:720) INFO: 63epoch:train:601-800batch: iter_time=2.093e-04, forward_time=0.130, uma_reduction=0.260, text_vs_uma=0.361, loss_ctc=4.297, loss=2.148, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.841e-04, train_time=0.874
[alab02] 2024-08-29 20:11:17,904 (trainer:720) INFO: 63epoch:train:801-1000batch: iter_time=2.052e-04, forward_time=0.132, uma_reduction=0.257, text_vs_uma=0.376, loss_ctc=4.340, loss=2.170, backward_time=0.188, optim_step_time=0.034, optim0_lr0=1.841e-04, train_time=0.889
[alab02] 2024-08-29 20:12:45,191 (trainer:720) INFO: 63epoch:train:1001-1200batch: iter_time=1.986e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.351, loss_ctc=3.917, loss=1.959, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.840e-04, train_time=0.873
[alab02] 2024-08-29 20:14:12,678 (trainer:720) INFO: 63epoch:train:1201-1400batch: iter_time=2.143e-04, forward_time=0.131, uma_reduction=0.248, text_vs_uma=0.396, loss_ctc=4.593, loss=2.296, backward_time=0.180, optim_step_time=0.036, optim0_lr0=1.840e-04, train_time=0.875
[alab02] 2024-08-29 20:15:41,500 (trainer:720) INFO: 63epoch:train:1401-1600batch: iter_time=1.938e-04, forward_time=0.132, uma_reduction=0.244, text_vs_uma=0.388, loss_ctc=4.620, loss=2.310, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.839e-04, train_time=0.888
[alab02] 2024-08-29 20:17:07,823 (trainer:720) INFO: 63epoch:train:1601-1800batch: iter_time=2.266e-04, forward_time=0.128, uma_reduction=0.237, text_vs_uma=0.414, loss_ctc=4.712, loss=2.356, backward_time=0.177, optim_step_time=0.036, optim0_lr0=1.839e-04, train_time=0.863
[alab02] 2024-08-29 20:18:35,432 (trainer:720) INFO: 63epoch:train:1801-2000batch: iter_time=2.035e-04, forward_time=0.130, uma_reduction=0.249, text_vs_uma=0.378, loss_ctc=4.291, loss=2.146, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.839e-04, train_time=0.876
[alab02] 2024-08-29 20:20:03,746 (trainer:720) INFO: 63epoch:train:2001-2200batch: iter_time=1.794e-04, forward_time=0.131, uma_reduction=0.256, text_vs_uma=0.372, loss_ctc=4.262, loss=2.131, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.838e-04, train_time=0.883
[alab02] 2024-08-29 20:21:31,169 (trainer:720) INFO: 63epoch:train:2201-2400batch: iter_time=1.913e-04, forward_time=0.130, uma_reduction=0.252, text_vs_uma=0.378, loss_ctc=4.458, loss=2.229, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.838e-04, train_time=0.874
[alab02] 2024-08-29 20:22:57,830 (trainer:720) INFO: 63epoch:train:2401-2600batch: iter_time=1.757e-04, forward_time=0.128, uma_reduction=0.251, text_vs_uma=0.389, loss_ctc=4.514, loss=2.257, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.837e-04, train_time=0.866
[alab02] 2024-08-29 20:24:23,421 (trainer:720) INFO: 63epoch:train:2601-2800batch: iter_time=1.767e-04, forward_time=0.127, uma_reduction=0.254, text_vs_uma=0.385, loss_ctc=4.729, loss=2.364, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.837e-04, train_time=0.856
[alab02] 2024-08-29 20:25:51,072 (trainer:720) INFO: 63epoch:train:2801-3000batch: iter_time=1.829e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.440, loss=2.220, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.837e-04, train_time=0.876
[alab02] 2024-08-29 20:27:18,596 (trainer:720) INFO: 63epoch:train:3001-3200batch: iter_time=1.859e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.375, loss_ctc=4.656, loss=2.328, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.836e-04, train_time=0.875
[alab02] 2024-08-29 20:28:45,894 (trainer:720) INFO: 63epoch:train:3201-3400batch: iter_time=1.774e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.380, loss_ctc=4.669, loss=2.335, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.836e-04, train_time=0.873
[alab02] 2024-08-29 20:30:12,844 (trainer:720) INFO: 63epoch:train:3401-3600batch: iter_time=1.755e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.376, loss_ctc=4.608, loss=2.304, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.835e-04, train_time=0.869
[alab02] 2024-08-29 20:31:36,470 (trainer:720) INFO: 63epoch:train:3601-3800batch: iter_time=2.073e-04, forward_time=0.124, uma_reduction=0.263, text_vs_uma=0.363, loss_ctc=3.993, loss=1.996, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.835e-04, train_time=0.836
[alab02] 2024-08-29 20:33:03,373 (trainer:720) INFO: 63epoch:train:3801-4000batch: iter_time=1.623e-04, forward_time=0.129, uma_reduction=0.264, text_vs_uma=0.355, loss_ctc=4.191, loss=2.095, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.835e-04, train_time=0.869
[alab02] 2024-08-29 20:34:30,785 (trainer:720) INFO: 63epoch:train:4001-4200batch: iter_time=1.696e-04, forward_time=0.131, uma_reduction=0.273, text_vs_uma=0.363, loss_ctc=4.640, loss=2.320, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.834e-04, train_time=0.874
[alab02] 2024-08-29 20:35:57,023 (trainer:720) INFO: 63epoch:train:4201-4400batch: iter_time=1.733e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.366, loss_ctc=4.584, loss=2.292, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.834e-04, train_time=0.862
[alab02] 2024-08-29 20:37:21,956 (trainer:720) INFO: 63epoch:train:4401-4600batch: iter_time=1.736e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.363, loss_ctc=4.351, loss=2.176, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.833e-04, train_time=0.849
[alab02] 2024-08-29 20:38:47,071 (trainer:720) INFO: 63epoch:train:4601-4800batch: iter_time=1.866e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.368, loss_ctc=4.632, loss=2.316, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.833e-04, train_time=0.851
[alab02] 2024-08-29 20:40:17,101 (trainer:720) INFO: 63epoch:train:4801-5000batch: iter_time=1.763e-04, forward_time=0.134, uma_reduction=0.266, text_vs_uma=0.359, loss_ctc=4.402, loss=2.201, backward_time=0.192, optim_step_time=0.033, optim0_lr0=1.832e-04, train_time=0.900
[alab02] 2024-08-29 20:41:43,522 (trainer:720) INFO: 63epoch:train:5001-5200batch: iter_time=1.717e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=4.261, loss=2.131, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.832e-04, train_time=0.864
[alab02] 2024-08-29 20:43:12,196 (trainer:720) INFO: 63epoch:train:5201-5400batch: iter_time=1.669e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.370, loss_ctc=4.596, loss=2.298, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.832e-04, train_time=0.887
[alab02] 2024-08-29 20:44:39,512 (trainer:720) INFO: 63epoch:train:5401-5600batch: iter_time=1.595e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.353, loss_ctc=4.648, loss=2.324, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.831e-04, train_time=0.873
[alab02] 2024-08-29 20:46:07,711 (trainer:720) INFO: 63epoch:train:5601-5800batch: iter_time=1.710e-04, forward_time=0.131, uma_reduction=0.262, text_vs_uma=0.368, loss_ctc=4.343, loss=2.171, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.831e-04, train_time=0.882
[alab02] 2024-08-29 20:47:34,246 (trainer:720) INFO: 63epoch:train:5801-6000batch: iter_time=1.862e-04, forward_time=0.128, uma_reduction=0.260, text_vs_uma=0.374, loss_ctc=4.541, loss=2.270, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.830e-04, train_time=0.865
[alab02] 2024-08-29 20:48:08,680 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 20:49:01,823 (trainer:720) INFO: 63epoch:train:6001-6200batch: iter_time=1.679e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=4.221, loss=2.111, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.830e-04, train_time=0.876
[alab02] 2024-08-29 20:50:30,001 (trainer:720) INFO: 63epoch:train:6201-6400batch: iter_time=1.856e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=4.723, loss=2.362, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.830e-04, train_time=0.882
[alab02] 2024-08-29 20:52:01,083 (trainer:720) INFO: 63epoch:train:6401-6600batch: iter_time=1.980e-04, forward_time=0.138, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=4.303, loss=2.151, backward_time=0.190, optim_step_time=0.037, optim0_lr0=1.829e-04, train_time=0.911
[alab02] 2024-08-29 20:53:39,751 (trainer:720) INFO: 63epoch:train:6601-6800batch: iter_time=3.119e-04, forward_time=0.157, uma_reduction=0.268, text_vs_uma=0.354, loss_ctc=4.165, loss=2.083, backward_time=0.205, optim_step_time=0.057, optim0_lr0=1.829e-04, train_time=0.986
[alab02] 2024-08-29 20:55:21,711 (trainer:720) INFO: 63epoch:train:6801-7000batch: iter_time=4.077e-04, forward_time=0.165, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=4.613, loss=2.306, backward_time=0.210, optim_step_time=0.061, optim0_lr0=1.828e-04, train_time=1.019
[alab02] 2024-08-29 20:57:03,201 (trainer:338) INFO: 63epoch results: [train] iter_time=2.376e-04, forward_time=0.132, uma_reduction=0.262, text_vs_uma=0.369, loss_ctc=4.443, loss=2.221, backward_time=0.184, optim_step_time=0.036, optim0_lr0=1.835e-04, train_time=0.884, time=52 minutes and 32.01 seconds, total_count=448938, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.290, text_vs_uma=0.375, loss_ctc=3.427, cer_ctc=0.093, cer=0.093, loss=3.427, time=8.08 seconds, total_count=1638, gpu_max_cached_mem_GB=35.906, [att_plot] time=22.9 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 20:57:11,041 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 20:57:11,050 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/38epoch.pth
[alab02] 2024-08-29 20:57:11,050 (trainer:272) INFO: 64/150epoch started. Estimated time to finish: 3 days, 8 hours and 6 minutes
[alab02] 2024-08-29 20:58:51,170 (trainer:720) INFO: 64epoch:train:1-200batch: iter_time=0.003, forward_time=0.163, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=4.636, loss=2.318, backward_time=0.197, optim_step_time=0.062, optim0_lr0=1.828e-04, train_time=1.000
[alab02] 2024-08-29 21:00:32,911 (trainer:720) INFO: 64epoch:train:201-400batch: iter_time=5.168e-04, forward_time=0.166, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=4.627, loss=2.314, backward_time=0.205, optim_step_time=0.064, optim0_lr0=1.827e-04, train_time=1.017
[alab02] 2024-08-29 21:02:14,070 (trainer:720) INFO: 64epoch:train:401-600batch: iter_time=4.746e-04, forward_time=0.163, uma_reduction=0.267, text_vs_uma=0.366, loss_ctc=4.313, loss=2.157, backward_time=0.208, optim_step_time=0.061, optim0_lr0=1.827e-04, train_time=1.011
[alab02] 2024-08-29 21:03:51,498 (trainer:720) INFO: 64epoch:train:601-800batch: iter_time=4.707e-04, forward_time=0.156, uma_reduction=0.255, text_vs_uma=0.375, loss_ctc=4.614, loss=2.307, backward_time=0.200, optim_step_time=0.058, optim0_lr0=1.826e-04, train_time=0.974
[alab02] 2024-08-29 21:05:31,473 (trainer:720) INFO: 64epoch:train:801-1000batch: iter_time=3.985e-04, forward_time=0.159, uma_reduction=0.238, text_vs_uma=0.413, loss_ctc=4.869, loss=2.435, backward_time=0.207, optim_step_time=0.057, optim0_lr0=1.826e-04, train_time=0.999
[alab02] 2024-08-29 21:07:12,201 (trainer:720) INFO: 64epoch:train:1001-1200batch: iter_time=3.774e-04, forward_time=0.161, uma_reduction=0.236, text_vs_uma=0.415, loss_ctc=4.646, loss=2.323, backward_time=0.208, optim_step_time=0.060, optim0_lr0=1.826e-04, train_time=1.007
[alab02] 2024-08-29 21:08:49,944 (trainer:720) INFO: 64epoch:train:1201-1400batch: iter_time=5.243e-04, forward_time=0.157, uma_reduction=0.233, text_vs_uma=0.410, loss_ctc=4.653, loss=2.326, backward_time=0.199, optim_step_time=0.058, optim0_lr0=1.825e-04, train_time=0.977
[alab02] 2024-08-29 21:10:28,370 (trainer:720) INFO: 64epoch:train:1401-1600batch: iter_time=4.688e-04, forward_time=0.157, uma_reduction=0.239, text_vs_uma=0.403, loss_ctc=4.630, loss=2.315, backward_time=0.197, optim_step_time=0.057, optim0_lr0=1.825e-04, train_time=0.984
[alab02] 2024-08-29 21:12:01,003 (trainer:720) INFO: 64epoch:train:1601-1800batch: iter_time=2.910e-04, forward_time=0.145, uma_reduction=0.249, text_vs_uma=0.379, loss_ctc=4.239, loss=2.119, backward_time=0.191, optim_step_time=0.048, optim0_lr0=1.824e-04, train_time=0.926
[alab02] 2024-08-29 21:13:33,597 (trainer:720) INFO: 64epoch:train:1801-2000batch: iter_time=2.755e-04, forward_time=0.143, uma_reduction=0.247, text_vs_uma=0.385, loss_ctc=4.839, loss=2.420, backward_time=0.186, optim_step_time=0.046, optim0_lr0=1.824e-04, train_time=0.926
[alab02] 2024-08-29 21:15:05,257 (trainer:720) INFO: 64epoch:train:2001-2200batch: iter_time=2.577e-04, forward_time=0.142, uma_reduction=0.246, text_vs_uma=0.401, loss_ctc=4.728, loss=2.364, backward_time=0.183, optim_step_time=0.044, optim0_lr0=1.824e-04, train_time=0.916
[alab02] 2024-08-29 21:16:42,679 (trainer:720) INFO: 64epoch:train:2201-2400batch: iter_time=4.741e-04, forward_time=0.152, uma_reduction=0.254, text_vs_uma=0.373, loss_ctc=4.135, loss=2.067, backward_time=0.200, optim_step_time=0.053, optim0_lr0=1.823e-04, train_time=0.974
[alab02] 2024-08-29 21:18:20,718 (trainer:720) INFO: 64epoch:train:2401-2600batch: iter_time=6.086e-04, forward_time=0.156, uma_reduction=0.257, text_vs_uma=0.378, loss_ctc=4.444, loss=2.222, backward_time=0.198, optim_step_time=0.065, optim0_lr0=1.823e-04, train_time=0.980
[alab02] 2024-08-29 21:20:00,970 (trainer:720) INFO: 64epoch:train:2601-2800batch: iter_time=6.414e-04, forward_time=0.161, uma_reduction=0.261, text_vs_uma=0.376, loss_ctc=4.953, loss=2.476, backward_time=0.197, optim_step_time=0.067, optim0_lr0=1.822e-04, train_time=1.002
[alab02] 2024-08-29 21:21:32,281 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 21:21:42,251 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 21:21:42,290 (trainer:720) INFO: 64epoch:train:2801-3000batch: iter_time=6.568e-04, forward_time=0.166, uma_reduction=0.256, text_vs_uma=0.371, loss_ctc=4.451, loss=2.226, backward_time=0.202, optim_step_time=0.063, optim0_lr0=1.822e-04, train_time=1.013
[alab02] 2024-08-29 21:23:26,138 (trainer:720) INFO: 64epoch:train:3001-3200batch: iter_time=6.044e-04, forward_time=0.167, uma_reduction=0.267, text_vs_uma=0.368, loss_ctc=4.511, loss=2.255, backward_time=0.209, optim_step_time=0.068, optim0_lr0=1.822e-04, train_time=1.038
[alab02] 2024-08-29 21:25:07,543 (trainer:720) INFO: 64epoch:train:3201-3400batch: iter_time=6.274e-04, forward_time=0.165, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=4.418, loss=2.209, backward_time=0.203, optim_step_time=0.068, optim0_lr0=1.821e-04, train_time=1.014
[alab02] 2024-08-29 21:26:48,952 (trainer:720) INFO: 64epoch:train:3401-3600batch: iter_time=7.661e-04, forward_time=0.163, uma_reduction=0.268, text_vs_uma=0.367, loss_ctc=5.141, loss=2.571, backward_time=0.202, optim_step_time=0.066, optim0_lr0=1.821e-04, train_time=1.013
[alab02] 2024-08-29 21:28:31,646 (trainer:720) INFO: 64epoch:train:3601-3800batch: iter_time=4.460e-04, forward_time=0.165, uma_reduction=0.284, text_vs_uma=0.337, loss_ctc=4.237, loss=2.118, backward_time=0.210, optim_step_time=0.064, optim0_lr0=1.820e-04, train_time=1.026
[alab02] 2024-08-29 21:30:11,240 (trainer:720) INFO: 64epoch:train:3801-4000batch: iter_time=4.322e-04, forward_time=0.161, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=4.491, loss=2.246, backward_time=0.204, optim_step_time=0.063, optim0_lr0=1.820e-04, train_time=0.995
[alab02] 2024-08-29 21:31:52,393 (trainer:720) INFO: 64epoch:train:4001-4200batch: iter_time=4.026e-04, forward_time=0.162, uma_reduction=0.278, text_vs_uma=0.340, loss_ctc=4.437, loss=2.219, backward_time=0.203, optim_step_time=0.060, optim0_lr0=1.820e-04, train_time=1.011
[alab02] 2024-08-29 21:33:29,828 (trainer:720) INFO: 64epoch:train:4201-4400batch: iter_time=4.152e-04, forward_time=0.153, uma_reduction=0.279, text_vs_uma=0.343, loss_ctc=4.468, loss=2.234, backward_time=0.199, optim_step_time=0.056, optim0_lr0=1.819e-04, train_time=0.974
[alab02] 2024-08-29 21:35:07,877 (trainer:720) INFO: 64epoch:train:4401-4600batch: iter_time=4.446e-04, forward_time=0.153, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=4.931, loss=2.466, backward_time=0.199, optim_step_time=0.056, optim0_lr0=1.819e-04, train_time=0.980
[alab02] 2024-08-29 21:36:42,195 (trainer:720) INFO: 64epoch:train:4601-4800batch: iter_time=2.715e-04, forward_time=0.145, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=4.676, loss=2.338, backward_time=0.193, optim_step_time=0.047, optim0_lr0=1.818e-04, train_time=0.943
[alab02] 2024-08-29 21:38:12,997 (trainer:720) INFO: 64epoch:train:4801-5000batch: iter_time=2.264e-04, forward_time=0.140, uma_reduction=0.263, text_vs_uma=0.375, loss_ctc=4.821, loss=2.410, backward_time=0.183, optim_step_time=0.041, optim0_lr0=1.818e-04, train_time=0.908
[alab02] 2024-08-29 21:39:47,185 (trainer:720) INFO: 64epoch:train:5001-5200batch: iter_time=2.850e-04, forward_time=0.147, uma_reduction=0.271, text_vs_uma=0.347, loss_ctc=4.359, loss=2.180, backward_time=0.196, optim_step_time=0.049, optim0_lr0=1.818e-04, train_time=0.941
[alab02] 2024-08-29 21:41:28,348 (trainer:720) INFO: 64epoch:train:5201-5400batch: iter_time=3.805e-04, forward_time=0.162, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=4.872, loss=2.436, backward_time=0.207, optim_step_time=0.062, optim0_lr0=1.817e-04, train_time=1.011
[alab02] 2024-08-29 21:43:10,852 (trainer:720) INFO: 64epoch:train:5401-5600batch: iter_time=5.466e-04, forward_time=0.165, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=4.817, loss=2.409, backward_time=0.206, optim_step_time=0.064, optim0_lr0=1.817e-04, train_time=1.024
[alab02] 2024-08-29 21:44:54,011 (trainer:720) INFO: 64epoch:train:5601-5800batch: iter_time=4.188e-04, forward_time=0.166, uma_reduction=0.284, text_vs_uma=0.339, loss_ctc=4.367, loss=2.183, backward_time=0.215, optim_step_time=0.062, optim0_lr0=1.816e-04, train_time=1.031
[alab02] 2024-08-29 21:46:33,089 (trainer:720) INFO: 64epoch:train:5801-6000batch: iter_time=4.179e-04, forward_time=0.161, uma_reduction=0.287, text_vs_uma=0.343, loss_ctc=4.486, loss=2.243, backward_time=0.203, optim_step_time=0.062, optim0_lr0=1.816e-04, train_time=0.990
[alab02] 2024-08-29 21:48:16,215 (trainer:720) INFO: 64epoch:train:6001-6200batch: iter_time=4.647e-04, forward_time=0.167, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=4.090, loss=2.045, backward_time=0.214, optim_step_time=0.067, optim0_lr0=1.816e-04, train_time=1.031
[alab02] 2024-08-29 21:49:56,860 (trainer:720) INFO: 64epoch:train:6201-6400batch: iter_time=4.581e-04, forward_time=0.163, uma_reduction=0.273, text_vs_uma=0.348, loss_ctc=4.215, loss=2.108, backward_time=0.205, optim_step_time=0.064, optim0_lr0=1.815e-04, train_time=1.006
[alab02] 2024-08-29 21:51:38,779 (trainer:720) INFO: 64epoch:train:6401-6600batch: iter_time=4.111e-04, forward_time=0.164, uma_reduction=0.271, text_vs_uma=0.366, loss_ctc=4.533, loss=2.267, backward_time=0.209, optim_step_time=0.063, optim0_lr0=1.815e-04, train_time=1.018
[alab02] 2024-08-29 21:53:21,564 (trainer:720) INFO: 64epoch:train:6601-6800batch: iter_time=4.010e-04, forward_time=0.167, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.987, loss=1.994, backward_time=0.215, optim_step_time=0.065, optim0_lr0=1.814e-04, train_time=1.027
[alab02] 2024-08-29 21:55:05,312 (trainer:720) INFO: 64epoch:train:6801-7000batch: iter_time=4.289e-04, forward_time=0.169, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=4.532, loss=2.266, backward_time=0.209, optim_step_time=0.068, optim0_lr0=1.814e-04, train_time=1.037
[alab02] 2024-08-29 21:56:43,365 (trainer:338) INFO: 64epoch results: [train] iter_time=5.269e-04, forward_time=0.159, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=4.538, loss=2.269, backward_time=0.202, optim_step_time=0.060, optim0_lr0=1.821e-04, train_time=0.993, time=59 minutes and 0.18 seconds, total_count=456064, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.290, text_vs_uma=0.375, loss_ctc=3.307, cer_ctc=0.089, cer=0.089, loss=3.307, time=8.27 seconds, total_count=1664, gpu_max_cached_mem_GB=35.906, [att_plot] time=23.86 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 21:56:52,678 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 21:56:52,775 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/63epoch.pth
[alab02] 2024-08-29 21:56:52,776 (trainer:272) INFO: 65/150epoch started. Estimated time to finish: 3 days, 7 hours and 17 minutes
[alab02] 2024-08-29 21:58:37,461 (trainer:720) INFO: 65epoch:train:1-200batch: iter_time=0.003, forward_time=0.169, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=4.419, loss=2.210, backward_time=0.210, optim_step_time=0.069, optim0_lr0=1.813e-04, train_time=1.046
[alab02] 2024-08-29 22:00:21,528 (trainer:720) INFO: 65epoch:train:201-400batch: iter_time=5.445e-04, forward_time=0.169, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=4.306, loss=2.153, backward_time=0.215, optim_step_time=0.066, optim0_lr0=1.813e-04, train_time=1.040
[alab02] 2024-08-29 22:02:02,460 (trainer:720) INFO: 65epoch:train:401-600batch: iter_time=5.514e-04, forward_time=0.161, uma_reduction=0.247, text_vs_uma=0.394, loss_ctc=4.328, loss=2.164, backward_time=0.215, optim_step_time=0.061, optim0_lr0=1.813e-04, train_time=1.009
[alab02] 2024-08-29 22:03:43,023 (trainer:720) INFO: 65epoch:train:601-800batch: iter_time=5.296e-04, forward_time=0.162, uma_reduction=0.253, text_vs_uma=0.378, loss_ctc=4.224, loss=2.112, backward_time=0.208, optim_step_time=0.063, optim0_lr0=1.812e-04, train_time=1.005
[alab02] 2024-08-29 22:05:26,063 (trainer:720) INFO: 65epoch:train:801-1000batch: iter_time=4.631e-04, forward_time=0.172, uma_reduction=0.260, text_vs_uma=0.366, loss_ctc=3.957, loss=1.978, backward_time=0.211, optim_step_time=0.068, optim0_lr0=1.812e-04, train_time=1.030
[alab02] 2024-08-29 22:07:09,109 (trainer:720) INFO: 65epoch:train:1001-1200batch: iter_time=5.821e-04, forward_time=0.168, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=4.172, loss=2.086, backward_time=0.212, optim_step_time=0.066, optim0_lr0=1.811e-04, train_time=1.030
[alab02] 2024-08-29 22:08:53,830 (trainer:720) INFO: 65epoch:train:1201-1400batch: iter_time=4.876e-04, forward_time=0.171, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=4.359, loss=2.179, backward_time=0.216, optim_step_time=0.068, optim0_lr0=1.811e-04, train_time=1.047
[alab02] 2024-08-29 22:10:35,786 (trainer:720) INFO: 65epoch:train:1401-1600batch: iter_time=4.415e-04, forward_time=0.165, uma_reduction=0.268, text_vs_uma=0.367, loss_ctc=4.468, loss=2.234, backward_time=0.209, optim_step_time=0.063, optim0_lr0=1.811e-04, train_time=1.019
[alab02] 2024-08-29 22:12:17,875 (trainer:720) INFO: 65epoch:train:1601-1800batch: iter_time=4.406e-04, forward_time=0.166, uma_reduction=0.268, text_vs_uma=0.371, loss_ctc=4.602, loss=2.301, backward_time=0.206, optim_step_time=0.063, optim0_lr0=1.810e-04, train_time=1.020
[alab02] 2024-08-29 22:13:59,224 (trainer:720) INFO: 65epoch:train:1801-2000batch: iter_time=3.993e-04, forward_time=0.162, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=4.458, loss=2.229, backward_time=0.209, optim_step_time=0.064, optim0_lr0=1.810e-04, train_time=1.013
[alab02] 2024-08-29 22:15:40,118 (trainer:720) INFO: 65epoch:train:2001-2200batch: iter_time=4.384e-04, forward_time=0.162, uma_reduction=0.268, text_vs_uma=0.358, loss_ctc=4.678, loss=2.339, backward_time=0.202, optim_step_time=0.061, optim0_lr0=1.809e-04, train_time=1.008
[alab02] 2024-08-29 22:17:14,333 (trainer:720) INFO: 65epoch:train:2201-2400batch: iter_time=3.250e-04, forward_time=0.148, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=4.101, loss=2.051, backward_time=0.194, optim_step_time=0.055, optim0_lr0=1.809e-04, train_time=0.942
[alab02] 2024-08-29 22:18:50,294 (trainer:720) INFO: 65epoch:train:2401-2600batch: iter_time=3.727e-04, forward_time=0.152, uma_reduction=0.258, text_vs_uma=0.385, loss_ctc=4.718, loss=2.359, backward_time=0.194, optim_step_time=0.054, optim0_lr0=1.809e-04, train_time=0.959
[alab02] 2024-08-29 22:20:25,688 (trainer:720) INFO: 65epoch:train:2601-2800batch: iter_time=2.670e-04, forward_time=0.148, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=4.328, loss=2.164, backward_time=0.198, optim_step_time=0.048, optim0_lr0=1.808e-04, train_time=0.954
[alab02] 2024-08-29 22:21:56,528 (trainer:720) INFO: 65epoch:train:2801-3000batch: iter_time=2.530e-04, forward_time=0.140, uma_reduction=0.262, text_vs_uma=0.365, loss_ctc=4.331, loss=2.165, backward_time=0.183, optim_step_time=0.046, optim0_lr0=1.808e-04, train_time=0.908
[alab02] 2024-08-29 22:23:28,394 (trainer:720) INFO: 65epoch:train:3001-3200batch: iter_time=2.359e-04, forward_time=0.140, uma_reduction=0.252, text_vs_uma=0.387, loss_ctc=4.774, loss=2.387, backward_time=0.186, optim_step_time=0.042, optim0_lr0=1.807e-04, train_time=0.918
[alab02] 2024-08-29 22:25:01,981 (trainer:720) INFO: 65epoch:train:3201-3400batch: iter_time=2.194e-04, forward_time=0.143, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=4.339, loss=2.169, backward_time=0.197, optim_step_time=0.041, optim0_lr0=1.807e-04, train_time=0.936
[alab02] 2024-08-29 22:26:31,584 (trainer:720) INFO: 65epoch:train:3401-3600batch: iter_time=2.250e-04, forward_time=0.137, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=4.195, loss=2.098, backward_time=0.184, optim_step_time=0.039, optim0_lr0=1.807e-04, train_time=0.896
[alab02] 2024-08-29 22:28:00,208 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 22:28:02,039 (trainer:720) INFO: 65epoch:train:3601-3800batch: iter_time=2.066e-04, forward_time=0.138, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=4.491, loss=2.245, backward_time=0.185, optim_step_time=0.038, optim0_lr0=1.806e-04, train_time=0.904
[alab02] 2024-08-29 22:29:33,940 (trainer:720) INFO: 65epoch:train:3801-4000batch: iter_time=2.227e-04, forward_time=0.140, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=4.673, loss=2.337, backward_time=0.188, optim_step_time=0.040, optim0_lr0=1.806e-04, train_time=0.919
[alab02] 2024-08-29 22:31:04,671 (trainer:720) INFO: 65epoch:train:4001-4200batch: iter_time=2.249e-04, forward_time=0.138, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=4.411, loss=2.206, backward_time=0.188, optim_step_time=0.040, optim0_lr0=1.805e-04, train_time=0.907
[alab02] 2024-08-29 22:32:34,820 (trainer:720) INFO: 65epoch:train:4201-4400batch: iter_time=2.197e-04, forward_time=0.138, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=4.513, loss=2.257, backward_time=0.181, optim_step_time=0.041, optim0_lr0=1.805e-04, train_time=0.901
[alab02] 2024-08-29 22:34:14,016 (trainer:720) INFO: 65epoch:train:4401-4600batch: iter_time=4.210e-04, forward_time=0.159, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=4.315, loss=2.157, backward_time=0.199, optim_step_time=0.061, optim0_lr0=1.805e-04, train_time=0.992
[alab02] 2024-08-29 22:35:54,032 (trainer:720) INFO: 65epoch:train:4601-4800batch: iter_time=4.511e-04, forward_time=0.161, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=4.595, loss=2.297, backward_time=0.199, optim_step_time=0.060, optim0_lr0=1.804e-04, train_time=1.000
[alab02] 2024-08-29 22:37:32,849 (trainer:720) INFO: 65epoch:train:4801-5000batch: iter_time=4.657e-04, forward_time=0.156, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=4.529, loss=2.265, backward_time=0.201, optim_step_time=0.060, optim0_lr0=1.804e-04, train_time=0.988
[alab02] 2024-08-29 22:39:12,980 (trainer:720) INFO: 65epoch:train:5001-5200batch: iter_time=4.622e-04, forward_time=0.159, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=4.300, loss=2.150, backward_time=0.204, optim_step_time=0.059, optim0_lr0=1.804e-04, train_time=1.001
[alab02] 2024-08-29 22:40:50,598 (trainer:720) INFO: 65epoch:train:5201-5400batch: iter_time=6.582e-04, forward_time=0.156, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=4.129, loss=2.064, backward_time=0.199, optim_step_time=0.058, optim0_lr0=1.803e-04, train_time=0.976
[alab02] 2024-08-29 22:42:28,563 (trainer:720) INFO: 65epoch:train:5401-5600batch: iter_time=4.818e-04, forward_time=0.155, uma_reduction=0.285, text_vs_uma=0.345, loss_ctc=4.592, loss=2.296, backward_time=0.199, optim_step_time=0.056, optim0_lr0=1.803e-04, train_time=0.979
[alab02] 2024-08-29 22:44:08,494 (trainer:720) INFO: 65epoch:train:5601-5800batch: iter_time=5.037e-04, forward_time=0.161, uma_reduction=0.287, text_vs_uma=0.341, loss_ctc=4.471, loss=2.235, backward_time=0.200, optim_step_time=0.061, optim0_lr0=1.802e-04, train_time=0.999
[alab02] 2024-08-29 22:45:47,753 (trainer:720) INFO: 65epoch:train:5801-6000batch: iter_time=4.835e-04, forward_time=0.158, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.387, loss=2.194, backward_time=0.200, optim_step_time=0.063, optim0_lr0=1.802e-04, train_time=0.992
[alab02] 2024-08-29 22:47:29,159 (trainer:720) INFO: 65epoch:train:6001-6200batch: iter_time=4.701e-04, forward_time=0.163, uma_reduction=0.262, text_vs_uma=0.361, loss_ctc=4.423, loss=2.212, backward_time=0.203, optim_step_time=0.064, optim0_lr0=1.802e-04, train_time=1.013
[alab02] 2024-08-29 22:49:05,014 (trainer:720) INFO: 65epoch:train:6201-6400batch: iter_time=4.788e-04, forward_time=0.154, uma_reduction=0.252, text_vs_uma=0.385, loss_ctc=4.585, loss=2.292, backward_time=0.190, optim_step_time=0.059, optim0_lr0=1.801e-04, train_time=0.958
[alab02] 2024-08-29 22:50:45,935 (trainer:720) INFO: 65epoch:train:6401-6600batch: iter_time=4.862e-04, forward_time=0.163, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=4.210, loss=2.105, backward_time=0.205, optim_step_time=0.064, optim0_lr0=1.801e-04, train_time=1.009
[alab02] 2024-08-29 22:52:27,590 (trainer:720) INFO: 65epoch:train:6601-6800batch: iter_time=4.492e-04, forward_time=0.168, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=4.361, loss=2.181, backward_time=0.207, optim_step_time=0.066, optim0_lr0=1.800e-04, train_time=1.016
[alab02] 2024-08-29 22:54:05,684 (trainer:720) INFO: 65epoch:train:6801-7000batch: iter_time=3.785e-04, forward_time=0.160, uma_reduction=0.270, text_vs_uma=0.364, loss_ctc=4.247, loss=2.123, backward_time=0.196, optim_step_time=0.062, optim0_lr0=1.800e-04, train_time=0.980
[alab02] 2024-08-29 22:55:45,813 (trainer:338) INFO: 65epoch results: [train] iter_time=4.868e-04, forward_time=0.156, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=4.390, loss=2.195, backward_time=0.200, optim_step_time=0.057, optim0_lr0=1.807e-04, train_time=0.981, time=58 minutes and 17.4 seconds, total_count=463190, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.272, text_vs_uma=0.398, loss_ctc=3.236, cer_ctc=0.090, cer=0.090, loss=3.236, time=8.6 seconds, total_count=1690, gpu_max_cached_mem_GB=35.906, [att_plot] time=27.03 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 22:55:55,113 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 22:55:55,123 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/50epoch.pth
[alab02] 2024-08-29 22:55:55,124 (trainer:272) INFO: 66/150epoch started. Estimated time to finish: 3 days, 6 hours and 27 minutes
[alab02] 2024-08-29 22:57:37,585 (trainer:720) INFO: 66epoch:train:1-200batch: iter_time=0.004, forward_time=0.164, uma_reduction=0.257, text_vs_uma=0.381, loss_ctc=4.827, loss=2.414, backward_time=0.195, optim_step_time=0.066, optim0_lr0=1.799e-04, train_time=1.024
[alab02] 2024-08-29 22:59:18,639 (trainer:720) INFO: 66epoch:train:201-400batch: iter_time=5.088e-04, forward_time=0.163, uma_reduction=0.256, text_vs_uma=0.372, loss_ctc=4.295, loss=2.148, backward_time=0.202, optim_step_time=0.062, optim0_lr0=1.799e-04, train_time=1.010
[alab02] 2024-08-29 23:00:59,228 (trainer:720) INFO: 66epoch:train:401-600batch: iter_time=4.512e-04, forward_time=0.163, uma_reduction=0.246, text_vs_uma=0.396, loss_ctc=4.081, loss=2.040, backward_time=0.206, optim_step_time=0.057, optim0_lr0=1.799e-04, train_time=1.005
[alab02] 2024-08-29 23:02:39,299 (trainer:720) INFO: 66epoch:train:601-800batch: iter_time=4.524e-04, forward_time=0.162, uma_reduction=0.251, text_vs_uma=0.396, loss_ctc=4.462, loss=2.231, backward_time=0.203, optim_step_time=0.058, optim0_lr0=1.798e-04, train_time=1.000
[alab02] 2024-08-29 23:04:16,274 (trainer:720) INFO: 66epoch:train:801-1000batch: iter_time=3.634e-04, forward_time=0.153, uma_reduction=0.263, text_vs_uma=0.365, loss_ctc=3.934, loss=1.967, backward_time=0.197, optim_step_time=0.053, optim0_lr0=1.798e-04, train_time=0.969
[alab02] 2024-08-29 23:05:51,950 (trainer:720) INFO: 66epoch:train:1001-1200batch: iter_time=4.160e-04, forward_time=0.153, uma_reduction=0.261, text_vs_uma=0.368, loss_ctc=3.914, loss=1.957, backward_time=0.193, optim_step_time=0.053, optim0_lr0=1.797e-04, train_time=0.956
[alab02] 2024-08-29 23:07:27,322 (trainer:720) INFO: 66epoch:train:1201-1400batch: iter_time=2.981e-04, forward_time=0.152, uma_reduction=0.255, text_vs_uma=0.379, loss_ctc=4.342, loss=2.171, backward_time=0.192, optim_step_time=0.047, optim0_lr0=1.797e-04, train_time=0.953
[alab02] 2024-08-29 23:09:00,464 (trainer:720) INFO: 66epoch:train:1401-1600batch: iter_time=2.598e-04, forward_time=0.146, uma_reduction=0.264, text_vs_uma=0.362, loss_ctc=4.320, loss=2.160, backward_time=0.189, optim_step_time=0.044, optim0_lr0=1.797e-04, train_time=0.931
[alab02] 2024-08-29 23:10:33,285 (trainer:720) INFO: 66epoch:train:1601-1800batch: iter_time=3.191e-04, forward_time=0.147, uma_reduction=0.278, text_vs_uma=0.342, loss_ctc=3.784, loss=1.892, backward_time=0.192, optim_step_time=0.043, optim0_lr0=1.796e-04, train_time=0.928
[alab02] 2024-08-29 23:12:04,618 (trainer:720) INFO: 66epoch:train:1801-2000batch: iter_time=2.517e-04, forward_time=0.140, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=4.326, loss=2.163, backward_time=0.189, optim_step_time=0.037, optim0_lr0=1.796e-04, train_time=0.913
[alab02] 2024-08-29 23:13:30,030 (trainer:720) INFO: 66epoch:train:2001-2200batch: iter_time=2.208e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=4.392, loss=2.196, backward_time=0.174, optim_step_time=0.035, optim0_lr0=1.796e-04, train_time=0.854
[alab02] 2024-08-29 23:14:56,968 (trainer:720) INFO: 66epoch:train:2201-2400batch: iter_time=2.143e-04, forward_time=0.132, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=4.501, loss=2.251, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.795e-04, train_time=0.869
[alab02] 2024-08-29 23:16:25,886 (trainer:720) INFO: 66epoch:train:2401-2600batch: iter_time=1.948e-04, forward_time=0.133, uma_reduction=0.262, text_vs_uma=0.365, loss_ctc=4.421, loss=2.211, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.795e-04, train_time=0.889
[alab02] 2024-08-29 23:17:51,413 (trainer:720) INFO: 66epoch:train:2601-2800batch: iter_time=1.860e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=4.262, loss=2.131, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.794e-04, train_time=0.855
[alab02] 2024-08-29 23:19:18,696 (trainer:720) INFO: 66epoch:train:2801-3000batch: iter_time=1.744e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.347, loss_ctc=4.216, loss=2.108, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.794e-04, train_time=0.873
[alab02] 2024-08-29 23:20:46,816 (trainer:720) INFO: 66epoch:train:3001-3200batch: iter_time=1.587e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=4.191, loss=2.095, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.794e-04, train_time=0.881
[alab02] 2024-08-29 23:22:13,531 (trainer:720) INFO: 66epoch:train:3201-3400batch: iter_time=1.715e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=4.202, loss=2.101, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.793e-04, train_time=0.867
[alab02] 2024-08-29 23:23:38,974 (trainer:720) INFO: 66epoch:train:3401-3600batch: iter_time=1.925e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=4.264, loss=2.132, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.793e-04, train_time=0.854
[alab02] 2024-08-29 23:25:08,817 (trainer:720) INFO: 66epoch:train:3601-3800batch: iter_time=1.859e-04, forward_time=0.134, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=4.155, loss=2.078, backward_time=0.190, optim_step_time=0.032, optim0_lr0=1.792e-04, train_time=0.898
[alab02] 2024-08-29 23:26:36,640 (trainer:720) INFO: 66epoch:train:3801-4000batch: iter_time=2.213e-04, forward_time=0.133, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=4.293, loss=2.146, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.792e-04, train_time=0.878
[alab02] 2024-08-29 23:28:05,070 (trainer:720) INFO: 66epoch:train:4001-4200batch: iter_time=2.108e-04, forward_time=0.135, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=4.323, loss=2.161, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.792e-04, train_time=0.884
[alab02] 2024-08-29 23:29:35,041 (trainer:720) INFO: 66epoch:train:4201-4400batch: iter_time=1.975e-04, forward_time=0.136, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=4.312, loss=2.156, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.791e-04, train_time=0.899
[alab02] 2024-08-29 23:31:02,606 (trainer:720) INFO: 66epoch:train:4401-4600batch: iter_time=2.022e-04, forward_time=0.132, uma_reduction=0.255, text_vs_uma=0.383, loss_ctc=4.448, loss=2.224, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.791e-04, train_time=0.875
[alab02] 2024-08-29 23:32:30,517 (trainer:720) INFO: 66epoch:train:4601-4800batch: iter_time=2.055e-04, forward_time=0.133, uma_reduction=0.263, text_vs_uma=0.365, loss_ctc=4.097, loss=2.049, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.791e-04, train_time=0.879
[alab02] 2024-08-29 23:33:59,768 (trainer:720) INFO: 66epoch:train:4801-5000batch: iter_time=2.034e-04, forward_time=0.136, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=4.695, loss=2.348, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.790e-04, train_time=0.892
[alab02] 2024-08-29 23:35:29,366 (trainer:720) INFO: 66epoch:train:5001-5200batch: iter_time=2.121e-04, forward_time=0.136, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=4.569, loss=2.285, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.790e-04, train_time=0.896
[alab02] 2024-08-29 23:36:57,364 (trainer:720) INFO: 66epoch:train:5201-5400batch: iter_time=2.047e-04, forward_time=0.133, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=4.347, loss=2.173, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.789e-04, train_time=0.880
[alab02] 2024-08-29 23:38:26,451 (trainer:720) INFO: 66epoch:train:5401-5600batch: iter_time=1.912e-04, forward_time=0.135, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=4.216, loss=2.108, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.789e-04, train_time=0.891
[alab02] 2024-08-29 23:39:55,428 (trainer:720) INFO: 66epoch:train:5601-5800batch: iter_time=1.996e-04, forward_time=0.135, uma_reduction=0.285, text_vs_uma=0.336, loss_ctc=4.303, loss=2.151, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.789e-04, train_time=0.890
[alab02] 2024-08-29 23:41:25,871 (trainer:720) INFO: 66epoch:train:5801-6000batch: iter_time=2.061e-04, forward_time=0.138, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=4.109, loss=2.055, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.788e-04, train_time=0.904
[alab02] 2024-08-29 23:42:29,851 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-29 23:42:54,666 (trainer:720) INFO: 66epoch:train:6001-6200batch: iter_time=1.875e-04, forward_time=0.134, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.659, loss=2.330, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.788e-04, train_time=0.888
[alab02] 2024-08-29 23:44:22,635 (trainer:720) INFO: 66epoch:train:6201-6400batch: iter_time=2.057e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=4.485, loss=2.243, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.787e-04, train_time=0.879
[alab02] 2024-08-29 23:45:51,251 (trainer:720) INFO: 66epoch:train:6401-6600batch: iter_time=2.029e-04, forward_time=0.135, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=4.488, loss=2.244, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.787e-04, train_time=0.886
[alab02] 2024-08-29 23:47:18,680 (trainer:720) INFO: 66epoch:train:6601-6800batch: iter_time=1.909e-04, forward_time=0.132, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=4.304, loss=2.152, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.787e-04, train_time=0.874
[alab02] 2024-08-29 23:48:49,827 (trainer:720) INFO: 66epoch:train:6801-7000batch: iter_time=2.325e-04, forward_time=0.139, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=4.463, loss=2.232, backward_time=0.191, optim_step_time=0.033, optim0_lr0=1.786e-04, train_time=0.911
[alab02] 2024-08-29 23:50:09,190 (trainer:338) INFO: 66epoch results: [train] iter_time=3.577e-04, forward_time=0.139, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=4.307, loss=2.154, backward_time=0.186, optim_step_time=0.038, optim0_lr0=1.793e-04, train_time=0.906, time=53 minutes and 50.46 seconds, total_count=470316, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.317, text_vs_uma=0.343, loss_ctc=3.226, cer_ctc=0.094, cer=0.094, loss=3.226, time=6.77 seconds, total_count=1716, gpu_max_cached_mem_GB=35.906, [att_plot] time=16.83 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-29 23:50:15,030 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-29 23:50:15,032 (trainer:272) INFO: 67/150epoch started. Estimated time to finish: 3 days, 5 hours and 30 minutes
[alab02] 2024-08-29 23:51:47,057 (trainer:720) INFO: 67epoch:train:1-200batch: iter_time=0.002, forward_time=0.139, uma_reduction=0.281, text_vs_uma=0.351, loss_ctc=4.571, loss=2.286, backward_time=0.184, optim_step_time=0.041, optim0_lr0=1.786e-04, train_time=0.920
[alab02] 2024-08-29 23:53:16,657 (trainer:720) INFO: 67epoch:train:201-400batch: iter_time=2.512e-04, forward_time=0.138, uma_reduction=0.265, text_vs_uma=0.369, loss_ctc=4.679, loss=2.339, backward_time=0.180, optim_step_time=0.041, optim0_lr0=1.785e-04, train_time=0.896
[alab02] 2024-08-29 23:54:46,721 (trainer:720) INFO: 67epoch:train:401-600batch: iter_time=2.922e-04, forward_time=0.138, uma_reduction=0.257, text_vs_uma=0.381, loss_ctc=4.426, loss=2.213, backward_time=0.182, optim_step_time=0.044, optim0_lr0=1.785e-04, train_time=0.900
[alab02] 2024-08-29 23:56:19,596 (trainer:720) INFO: 67epoch:train:601-800batch: iter_time=2.930e-04, forward_time=0.142, uma_reduction=0.268, text_vs_uma=0.356, loss_ctc=4.142, loss=2.071, backward_time=0.193, optim_step_time=0.042, optim0_lr0=1.785e-04, train_time=0.928
[alab02] 2024-08-29 23:57:52,860 (trainer:720) INFO: 67epoch:train:801-1000batch: iter_time=2.637e-04, forward_time=0.142, uma_reduction=0.262, text_vs_uma=0.363, loss_ctc=4.350, loss=2.175, backward_time=0.194, optim_step_time=0.042, optim0_lr0=1.784e-04, train_time=0.932
[alab02] 2024-08-29 23:59:24,083 (trainer:720) INFO: 67epoch:train:1001-1200batch: iter_time=2.940e-04, forward_time=0.140, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=4.698, loss=2.349, backward_time=0.184, optim_step_time=0.042, optim0_lr0=1.784e-04, train_time=0.912
[alab02] 2024-08-30 00:00:55,076 (trainer:720) INFO: 67epoch:train:1201-1400batch: iter_time=2.521e-04, forward_time=0.140, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=4.376, loss=2.188, backward_time=0.188, optim_step_time=0.041, optim0_lr0=1.783e-04, train_time=0.910
[alab02] 2024-08-30 00:02:26,086 (trainer:720) INFO: 67epoch:train:1401-1600batch: iter_time=2.994e-04, forward_time=0.140, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=4.268, loss=2.134, backward_time=0.187, optim_step_time=0.042, optim0_lr0=1.783e-04, train_time=0.910
[alab02] 2024-08-30 00:03:55,510 (trainer:720) INFO: 67epoch:train:1601-1800batch: iter_time=3.483e-04, forward_time=0.136, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=4.815, loss=2.408, backward_time=0.179, optim_step_time=0.041, optim0_lr0=1.783e-04, train_time=0.894
[alab02] 2024-08-30 00:05:26,866 (trainer:720) INFO: 67epoch:train:1801-2000batch: iter_time=3.067e-04, forward_time=0.139, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.148, loss=2.074, backward_time=0.190, optim_step_time=0.041, optim0_lr0=1.782e-04, train_time=0.913
[alab02] 2024-08-30 00:06:56,865 (trainer:720) INFO: 67epoch:train:2001-2200batch: iter_time=2.375e-04, forward_time=0.138, uma_reduction=0.270, text_vs_uma=0.361, loss_ctc=4.558, loss=2.279, backward_time=0.185, optim_step_time=0.038, optim0_lr0=1.782e-04, train_time=0.900
[alab02] 2024-08-30 00:08:25,383 (trainer:720) INFO: 67epoch:train:2201-2400batch: iter_time=2.227e-04, forward_time=0.135, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=4.350, loss=2.175, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.782e-04, train_time=0.885
[alab02] 2024-08-30 00:09:53,333 (trainer:720) INFO: 67epoch:train:2401-2600batch: iter_time=2.078e-04, forward_time=0.134, uma_reduction=0.275, text_vs_uma=0.351, loss_ctc=4.460, loss=2.230, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.781e-04, train_time=0.879
[alab02] 2024-08-30 00:10:25,188 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 00:11:23,225 (trainer:720) INFO: 67epoch:train:2601-2800batch: iter_time=2.043e-04, forward_time=0.138, uma_reduction=0.267, text_vs_uma=0.356, loss_ctc=4.608, loss=2.304, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.781e-04, train_time=0.899
[alab02] 2024-08-30 00:12:51,986 (trainer:720) INFO: 67epoch:train:2801-3000batch: iter_time=1.927e-04, forward_time=0.136, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=4.147, loss=2.073, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.780e-04, train_time=0.887
[alab02] 2024-08-30 00:14:18,894 (trainer:720) INFO: 67epoch:train:3001-3200batch: iter_time=2.307e-04, forward_time=0.133, uma_reduction=0.266, text_vs_uma=0.367, loss_ctc=4.350, loss=2.175, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.780e-04, train_time=0.869
[alab02] 2024-08-30 00:15:48,764 (trainer:720) INFO: 67epoch:train:3201-3400batch: iter_time=2.095e-04, forward_time=0.137, uma_reduction=0.275, text_vs_uma=0.351, loss_ctc=4.558, loss=2.279, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.780e-04, train_time=0.898
[alab02] 2024-08-30 00:17:17,337 (trainer:720) INFO: 67epoch:train:3401-3600batch: iter_time=2.076e-04, forward_time=0.134, uma_reduction=0.266, text_vs_uma=0.373, loss_ctc=4.811, loss=2.405, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.779e-04, train_time=0.885
[alab02] 2024-08-30 00:18:47,051 (trainer:720) INFO: 67epoch:train:3601-3800batch: iter_time=1.955e-04, forward_time=0.136, uma_reduction=0.253, text_vs_uma=0.372, loss_ctc=4.326, loss=2.163, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.779e-04, train_time=0.897
[alab02] 2024-08-30 00:20:17,228 (trainer:720) INFO: 67epoch:train:3801-4000batch: iter_time=1.964e-04, forward_time=0.138, uma_reduction=0.249, text_vs_uma=0.383, loss_ctc=4.585, loss=2.293, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.779e-04, train_time=0.901
[alab02] 2024-08-30 00:21:45,689 (trainer:720) INFO: 67epoch:train:4001-4200batch: iter_time=2.004e-04, forward_time=0.135, uma_reduction=0.253, text_vs_uma=0.384, loss_ctc=4.600, loss=2.300, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.778e-04, train_time=0.884
[alab02] 2024-08-30 00:23:13,448 (trainer:720) INFO: 67epoch:train:4201-4400batch: iter_time=2.060e-04, forward_time=0.134, uma_reduction=0.250, text_vs_uma=0.390, loss_ctc=4.723, loss=2.362, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.778e-04, train_time=0.877
[alab02] 2024-08-30 00:24:41,647 (trainer:720) INFO: 67epoch:train:4401-4600batch: iter_time=2.011e-04, forward_time=0.134, uma_reduction=0.254, text_vs_uma=0.381, loss_ctc=4.421, loss=2.210, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.777e-04, train_time=0.882
[alab02] 2024-08-30 00:26:12,565 (trainer:720) INFO: 67epoch:train:4601-4800batch: iter_time=2.148e-04, forward_time=0.139, uma_reduction=0.271, text_vs_uma=0.370, loss_ctc=4.418, loss=2.209, backward_time=0.189, optim_step_time=0.035, optim0_lr0=1.777e-04, train_time=0.909
[alab02] 2024-08-30 00:27:42,343 (trainer:720) INFO: 67epoch:train:4801-5000batch: iter_time=2.004e-04, forward_time=0.137, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.702, loss=2.351, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.777e-04, train_time=0.898
[alab02] 2024-08-30 00:29:12,956 (trainer:720) INFO: 67epoch:train:5001-5200batch: iter_time=2.032e-04, forward_time=0.138, uma_reduction=0.269, text_vs_uma=0.369, loss_ctc=4.887, loss=2.443, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.776e-04, train_time=0.906
[alab02] 2024-08-30 00:30:41,068 (trainer:720) INFO: 67epoch:train:5201-5400batch: iter_time=2.152e-04, forward_time=0.134, uma_reduction=0.267, text_vs_uma=0.369, loss_ctc=4.591, loss=2.295, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.776e-04, train_time=0.881
[alab02] 2024-08-30 00:32:10,992 (trainer:720) INFO: 67epoch:train:5401-5600batch: iter_time=2.067e-04, forward_time=0.137, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=4.687, loss=2.343, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.776e-04, train_time=0.899
[alab02] 2024-08-30 00:33:40,684 (trainer:720) INFO: 67epoch:train:5601-5800batch: iter_time=1.943e-04, forward_time=0.138, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=4.473, loss=2.237, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.775e-04, train_time=0.897
[alab02] 2024-08-30 00:35:09,857 (trainer:720) INFO: 67epoch:train:5801-6000batch: iter_time=2.181e-04, forward_time=0.135, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=4.368, loss=2.184, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.775e-04, train_time=0.891
[alab02] 2024-08-30 00:36:40,022 (trainer:720) INFO: 67epoch:train:6001-6200batch: iter_time=2.293e-04, forward_time=0.138, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=4.823, loss=2.412, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.774e-04, train_time=0.901
[alab02] 2024-08-30 00:38:08,530 (trainer:720) INFO: 67epoch:train:6201-6400batch: iter_time=2.080e-04, forward_time=0.134, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=4.500, loss=2.250, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.774e-04, train_time=0.885
[alab02] 2024-08-30 00:39:35,778 (trainer:720) INFO: 67epoch:train:6401-6600batch: iter_time=2.077e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=4.383, loss=2.192, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.774e-04, train_time=0.872
[alab02] 2024-08-30 00:41:03,705 (trainer:720) INFO: 67epoch:train:6601-6800batch: iter_time=2.122e-04, forward_time=0.134, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=4.318, loss=2.159, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.773e-04, train_time=0.879
[alab02] 2024-08-30 00:42:33,095 (trainer:720) INFO: 67epoch:train:6801-7000batch: iter_time=2.153e-04, forward_time=0.136, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=4.311, loss=2.155, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.773e-04, train_time=0.894
[alab02] 2024-08-30 00:43:51,795 (trainer:338) INFO: 67epoch results: [train] iter_time=2.884e-04, forward_time=0.137, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=4.491, loss=2.245, backward_time=0.184, optim_step_time=0.037, optim0_lr0=1.779e-04, train_time=0.896, time=53 minutes and 15.15 seconds, total_count=477442, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.270, text_vs_uma=0.403, loss_ctc=3.397, cer_ctc=0.097, cer=0.097, loss=3.397, time=6.5 seconds, total_count=1742, gpu_max_cached_mem_GB=35.906, [att_plot] time=15.11 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 00:43:57,615 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 00:43:57,672 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/66epoch.pth
[alab02] 2024-08-30 00:43:57,673 (trainer:272) INFO: 68/150epoch started. Estimated time to finish: 3 days, 4 hours and 32 minutes
[alab02] 2024-08-30 00:45:29,788 (trainer:720) INFO: 68epoch:train:1-200batch: iter_time=0.002, forward_time=0.140, uma_reduction=0.256, text_vs_uma=0.375, loss_ctc=4.206, loss=2.103, backward_time=0.191, optim_step_time=0.035, optim0_lr0=1.772e-04, train_time=0.921
[alab02] 2024-08-30 00:46:59,652 (trainer:720) INFO: 68epoch:train:201-400batch: iter_time=2.445e-04, forward_time=0.137, uma_reduction=0.247, text_vs_uma=0.383, loss_ctc=4.339, loss=2.170, backward_time=0.186, optim_step_time=0.036, optim0_lr0=1.772e-04, train_time=0.898
[alab02] 2024-08-30 00:48:30,193 (trainer:720) INFO: 68epoch:train:401-600batch: iter_time=2.111e-04, forward_time=0.138, uma_reduction=0.251, text_vs_uma=0.384, loss_ctc=4.030, loss=2.015, backward_time=0.192, optim_step_time=0.035, optim0_lr0=1.772e-04, train_time=0.905
[alab02] 2024-08-30 00:49:57,751 (trainer:720) INFO: 68epoch:train:601-800batch: iter_time=2.857e-04, forward_time=0.132, uma_reduction=0.257, text_vs_uma=0.381, loss_ctc=4.451, loss=2.225, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.771e-04, train_time=0.875
[alab02] 2024-08-30 00:51:28,076 (trainer:720) INFO: 68epoch:train:801-1000batch: iter_time=2.250e-04, forward_time=0.138, uma_reduction=0.267, text_vs_uma=0.349, loss_ctc=4.106, loss=2.053, backward_time=0.187, optim_step_time=0.035, optim0_lr0=1.771e-04, train_time=0.903
[alab02] 2024-08-30 00:52:56,193 (trainer:720) INFO: 68epoch:train:1001-1200batch: iter_time=2.263e-04, forward_time=0.132, uma_reduction=0.259, text_vs_uma=0.367, loss_ctc=4.443, loss=2.222, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.770e-04, train_time=0.881
[alab02] 2024-08-30 00:54:23,984 (trainer:720) INFO: 68epoch:train:1201-1400batch: iter_time=2.268e-04, forward_time=0.132, uma_reduction=0.277, text_vs_uma=0.359, loss_ctc=4.266, loss=2.133, backward_time=0.181, optim_step_time=0.036, optim0_lr0=1.770e-04, train_time=0.878
[alab02] 2024-08-30 00:55:50,349 (trainer:720) INFO: 68epoch:train:1401-1600batch: iter_time=2.334e-04, forward_time=0.131, uma_reduction=0.290, text_vs_uma=0.337, loss_ctc=3.961, loss=1.980, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.770e-04, train_time=0.863
[alab02] 2024-08-30 00:57:17,815 (trainer:720) INFO: 68epoch:train:1601-1800batch: iter_time=2.399e-04, forward_time=0.133, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=4.241, loss=2.120, backward_time=0.180, optim_step_time=0.037, optim0_lr0=1.769e-04, train_time=0.874
[alab02] 2024-08-30 00:58:45,452 (trainer:720) INFO: 68epoch:train:1801-2000batch: iter_time=1.945e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.358, loss_ctc=3.918, loss=1.959, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.769e-04, train_time=0.876
[alab02] 2024-08-30 01:00:12,630 (trainer:720) INFO: 68epoch:train:2001-2200batch: iter_time=1.766e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=4.443, loss=2.221, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.769e-04, train_time=0.872
[alab02] 2024-08-30 01:01:39,947 (trainer:720) INFO: 68epoch:train:2201-2400batch: iter_time=1.802e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=4.554, loss=2.277, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.768e-04, train_time=0.873
[alab02] 2024-08-30 01:03:07,243 (trainer:720) INFO: 68epoch:train:2401-2600batch: iter_time=1.661e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.361, loss_ctc=4.197, loss=2.099, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.768e-04, train_time=0.873
[alab02] 2024-08-30 01:04:32,841 (trainer:720) INFO: 68epoch:train:2601-2800batch: iter_time=1.788e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.345, loss_ctc=4.033, loss=2.016, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.768e-04, train_time=0.856
[alab02] 2024-08-30 01:06:01,333 (trainer:720) INFO: 68epoch:train:2801-3000batch: iter_time=1.975e-04, forward_time=0.133, uma_reduction=0.256, text_vs_uma=0.370, loss_ctc=3.993, loss=1.997, backward_time=0.188, optim_step_time=0.032, optim0_lr0=1.767e-04, train_time=0.885
[alab02] 2024-08-30 01:07:28,972 (trainer:720) INFO: 68epoch:train:3001-3200batch: iter_time=2.017e-04, forward_time=0.132, uma_reduction=0.249, text_vs_uma=0.399, loss_ctc=4.470, loss=2.235, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.767e-04, train_time=0.876
[alab02] 2024-08-30 01:08:55,514 (trainer:720) INFO: 68epoch:train:3201-3400batch: iter_time=1.746e-04, forward_time=0.130, uma_reduction=0.250, text_vs_uma=0.379, loss_ctc=4.199, loss=2.100, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.766e-04, train_time=0.865
[alab02] 2024-08-30 01:10:22,414 (trainer:720) INFO: 68epoch:train:3401-3600batch: iter_time=1.846e-04, forward_time=0.130, uma_reduction=0.262, text_vs_uma=0.371, loss_ctc=4.346, loss=2.173, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.766e-04, train_time=0.869
[alab02] 2024-08-30 01:11:48,554 (trainer:720) INFO: 68epoch:train:3601-3800batch: iter_time=1.790e-04, forward_time=0.128, uma_reduction=0.247, text_vs_uma=0.394, loss_ctc=4.288, loss=2.144, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.766e-04, train_time=0.861
[alab02] 2024-08-30 01:11:49,290 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 01:13:16,558 (trainer:720) INFO: 68epoch:train:3801-4000batch: iter_time=1.779e-04, forward_time=0.132, uma_reduction=0.251, text_vs_uma=0.385, loss_ctc=4.325, loss=2.162, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.765e-04, train_time=0.880
[alab02] 2024-08-30 01:14:45,691 (trainer:720) INFO: 68epoch:train:4001-4200batch: iter_time=1.717e-04, forward_time=0.134, uma_reduction=0.250, text_vs_uma=0.378, loss_ctc=4.450, loss=2.225, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.765e-04, train_time=0.891
[alab02] 2024-08-30 01:16:13,300 (trainer:720) INFO: 68epoch:train:4201-4400batch: iter_time=1.882e-04, forward_time=0.131, uma_reduction=0.251, text_vs_uma=0.377, loss_ctc=4.332, loss=2.166, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.765e-04, train_time=0.876
[alab02] 2024-08-30 01:17:40,292 (trainer:720) INFO: 68epoch:train:4401-4600batch: iter_time=1.987e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=4.322, loss=2.161, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.764e-04, train_time=0.870
[alab02] 2024-08-30 01:19:07,135 (trainer:720) INFO: 68epoch:train:4601-4800batch: iter_time=1.706e-04, forward_time=0.130, uma_reduction=0.263, text_vs_uma=0.373, loss_ctc=4.477, loss=2.239, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.764e-04, train_time=0.868
[alab02] 2024-08-30 01:20:31,502 (trainer:720) INFO: 68epoch:train:4801-5000batch: iter_time=1.707e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=4.399, loss=2.199, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.764e-04, train_time=0.843
[alab02] 2024-08-30 01:21:59,324 (trainer:720) INFO: 68epoch:train:5001-5200batch: iter_time=1.660e-04, forward_time=0.132, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=4.271, loss=2.135, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.763e-04, train_time=0.878
[alab02] 2024-08-30 01:23:27,307 (trainer:720) INFO: 68epoch:train:5201-5400batch: iter_time=1.620e-04, forward_time=0.132, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=4.531, loss=2.266, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.763e-04, train_time=0.880
[alab02] 2024-08-30 01:24:55,204 (trainer:720) INFO: 68epoch:train:5401-5600batch: iter_time=1.694e-04, forward_time=0.133, uma_reduction=0.289, text_vs_uma=0.333, loss_ctc=4.144, loss=2.072, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.762e-04, train_time=0.879
[alab02] 2024-08-30 01:26:24,394 (trainer:720) INFO: 68epoch:train:5601-5800batch: iter_time=1.593e-04, forward_time=0.133, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=4.257, loss=2.129, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.762e-04, train_time=0.892
[alab02] 2024-08-30 01:27:50,713 (trainer:720) INFO: 68epoch:train:5801-6000batch: iter_time=1.741e-04, forward_time=0.129, uma_reduction=0.287, text_vs_uma=0.341, loss_ctc=4.702, loss=2.351, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.762e-04, train_time=0.863
[alab02] 2024-08-30 01:29:17,054 (trainer:720) INFO: 68epoch:train:6001-6200batch: iter_time=1.702e-04, forward_time=0.130, uma_reduction=0.291, text_vs_uma=0.339, loss_ctc=4.401, loss=2.200, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.761e-04, train_time=0.863
[alab02] 2024-08-30 01:30:44,349 (trainer:720) INFO: 68epoch:train:6201-6400batch: iter_time=1.642e-04, forward_time=0.131, uma_reduction=0.294, text_vs_uma=0.325, loss_ctc=4.235, loss=2.118, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.761e-04, train_time=0.873
[alab02] 2024-08-30 01:32:10,626 (trainer:720) INFO: 68epoch:train:6401-6600batch: iter_time=1.608e-04, forward_time=0.129, uma_reduction=0.293, text_vs_uma=0.336, loss_ctc=4.541, loss=2.271, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.761e-04, train_time=0.863
[alab02] 2024-08-30 01:33:37,568 (trainer:720) INFO: 68epoch:train:6601-6800batch: iter_time=1.749e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.342, loss_ctc=4.289, loss=2.144, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.760e-04, train_time=0.869
[alab02] 2024-08-30 01:35:05,078 (trainer:720) INFO: 68epoch:train:6801-7000batch: iter_time=1.630e-04, forward_time=0.131, uma_reduction=0.284, text_vs_uma=0.348, loss_ctc=4.529, loss=2.265, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.760e-04, train_time=0.875
[alab02] 2024-08-30 01:36:20,058 (trainer:338) INFO: 68epoch results: [train] iter_time=2.544e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.297, loss=2.149, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.766e-04, train_time=0.876, time=52 minutes and 3.66 seconds, total_count=484568, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.302, text_vs_uma=0.359, loss_ctc=3.267, cer_ctc=0.090, cer=0.090, loss=3.267, time=6.05 seconds, total_count=1768, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.68 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 01:36:25,446 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 01:36:25,506 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/56epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/67epoch.pth
[alab02] 2024-08-30 01:36:25,506 (trainer:272) INFO: 69/150epoch started. Estimated time to finish: 3 days, 3 hours and 34 minutes
[alab02] 2024-08-30 01:37:52,355 (trainer:720) INFO: 69epoch:train:1-200batch: iter_time=0.002, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=4.343, loss=2.172, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.759e-04, train_time=0.868
[alab02] 2024-08-30 01:39:17,198 (trainer:720) INFO: 69epoch:train:201-400batch: iter_time=1.726e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.359, loss_ctc=4.114, loss=2.057, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.759e-04, train_time=0.848
[alab02] 2024-08-30 01:40:42,148 (trainer:720) INFO: 69epoch:train:401-600batch: iter_time=1.866e-04, forward_time=0.126, uma_reduction=0.261, text_vs_uma=0.374, loss_ctc=4.461, loss=2.231, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.759e-04, train_time=0.849
[alab02] 2024-08-30 01:42:07,870 (trainer:720) INFO: 69epoch:train:601-800batch: iter_time=2.045e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=4.136, loss=2.068, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.758e-04, train_time=0.857
[alab02] 2024-08-30 01:42:56,419 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 01:43:33,589 (trainer:720) INFO: 69epoch:train:801-1000batch: iter_time=1.697e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=4.316, loss=2.158, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.758e-04, train_time=0.857
[alab02] 2024-08-30 01:44:59,941 (trainer:720) INFO: 69epoch:train:1001-1200batch: iter_time=1.839e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=4.230, loss=2.115, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.757e-04, train_time=0.863
[alab02] 2024-08-30 01:46:26,746 (trainer:720) INFO: 69epoch:train:1201-1400batch: iter_time=1.857e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=4.130, loss=2.065, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.757e-04, train_time=0.868
[alab02] 2024-08-30 01:47:53,826 (trainer:720) INFO: 69epoch:train:1401-1600batch: iter_time=1.770e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.358, loss_ctc=4.568, loss=2.284, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.757e-04, train_time=0.871
[alab02] 2024-08-30 01:49:20,922 (trainer:720) INFO: 69epoch:train:1601-1800batch: iter_time=1.769e-04, forward_time=0.130, uma_reduction=0.286, text_vs_uma=0.333, loss_ctc=4.306, loss=2.153, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.756e-04, train_time=0.871
[alab02] 2024-08-30 01:50:47,884 (trainer:720) INFO: 69epoch:train:1801-2000batch: iter_time=1.746e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=4.067, loss=2.033, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.756e-04, train_time=0.869
[alab02] 2024-08-30 01:52:13,337 (trainer:720) INFO: 69epoch:train:2001-2200batch: iter_time=1.678e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=4.259, loss=2.129, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.756e-04, train_time=0.854
[alab02] 2024-08-30 01:53:39,227 (trainer:720) INFO: 69epoch:train:2201-2400batch: iter_time=1.701e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=4.464, loss=2.232, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.755e-04, train_time=0.859
[alab02] 2024-08-30 01:55:04,584 (trainer:720) INFO: 69epoch:train:2401-2600batch: iter_time=1.756e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.349, loss_ctc=4.123, loss=2.061, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.755e-04, train_time=0.853
[alab02] 2024-08-30 01:56:30,828 (trainer:720) INFO: 69epoch:train:2601-2800batch: iter_time=1.813e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.645, loss=2.322, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.755e-04, train_time=0.862
[alab02] 2024-08-30 01:57:55,556 (trainer:720) INFO: 69epoch:train:2801-3000batch: iter_time=1.726e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=4.338, loss=2.169, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.754e-04, train_time=0.847
[alab02] 2024-08-30 01:59:23,240 (trainer:720) INFO: 69epoch:train:3001-3200batch: iter_time=1.703e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.392, loss_ctc=4.535, loss=2.267, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.754e-04, train_time=0.877
[alab02] 2024-08-30 02:00:49,227 (trainer:720) INFO: 69epoch:train:3201-3400batch: iter_time=1.722e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=4.539, loss=2.270, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.753e-04, train_time=0.860
[alab02] 2024-08-30 02:02:15,335 (trainer:720) INFO: 69epoch:train:3401-3600batch: iter_time=1.624e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=4.202, loss=2.101, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.753e-04, train_time=0.861
[alab02] 2024-08-30 02:03:44,239 (trainer:720) INFO: 69epoch:train:3601-3800batch: iter_time=1.732e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.509, loss=2.255, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.753e-04, train_time=0.889
[alab02] 2024-08-30 02:05:09,716 (trainer:720) INFO: 69epoch:train:3801-4000batch: iter_time=1.785e-04, forward_time=0.127, uma_reduction=0.260, text_vs_uma=0.374, loss_ctc=4.423, loss=2.212, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.752e-04, train_time=0.855
[alab02] 2024-08-30 02:06:36,294 (trainer:720) INFO: 69epoch:train:4001-4200batch: iter_time=1.950e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.374, loss_ctc=4.931, loss=2.466, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.752e-04, train_time=0.866
[alab02] 2024-08-30 02:08:01,168 (trainer:720) INFO: 69epoch:train:4201-4400batch: iter_time=1.782e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.357, loss_ctc=4.018, loss=2.009, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.752e-04, train_time=0.848
[alab02] 2024-08-30 02:09:25,038 (trainer:720) INFO: 69epoch:train:4401-4600batch: iter_time=1.679e-04, forward_time=0.125, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=4.181, loss=2.090, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.751e-04, train_time=0.839
[alab02] 2024-08-30 02:10:52,714 (trainer:720) INFO: 69epoch:train:4601-4800batch: iter_time=1.571e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.370, loss_ctc=4.542, loss=2.271, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.751e-04, train_time=0.877
[alab02] 2024-08-30 02:12:06,434 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 02:12:18,293 (trainer:720) INFO: 69epoch:train:4801-5000batch: iter_time=1.716e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=4.460, loss=2.230, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.751e-04, train_time=0.856
[alab02] 2024-08-30 02:13:42,643 (trainer:720) INFO: 69epoch:train:5001-5200batch: iter_time=1.647e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=4.650, loss=2.325, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.750e-04, train_time=0.843
[alab02] 2024-08-30 02:15:07,274 (trainer:720) INFO: 69epoch:train:5201-5400batch: iter_time=1.646e-04, forward_time=0.126, uma_reduction=0.286, text_vs_uma=0.339, loss_ctc=4.481, loss=2.241, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.750e-04, train_time=0.846
[alab02] 2024-08-30 02:16:33,114 (trainer:720) INFO: 69epoch:train:5401-5600batch: iter_time=1.587e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.352, loss_ctc=4.497, loss=2.248, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.750e-04, train_time=0.858
[alab02] 2024-08-30 02:18:00,045 (trainer:720) INFO: 69epoch:train:5601-5800batch: iter_time=1.692e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.342, loss_ctc=4.194, loss=2.097, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.749e-04, train_time=0.869
[alab02] 2024-08-30 02:19:27,499 (trainer:720) INFO: 69epoch:train:5801-6000batch: iter_time=1.701e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=4.677, loss=2.338, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.749e-04, train_time=0.874
[alab02] 2024-08-30 02:20:51,666 (trainer:720) INFO: 69epoch:train:6001-6200batch: iter_time=1.635e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=4.418, loss=2.209, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.748e-04, train_time=0.841
[alab02] 2024-08-30 02:22:18,050 (trainer:720) INFO: 69epoch:train:6201-6400batch: iter_time=1.614e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.374, loss_ctc=4.450, loss=2.225, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.748e-04, train_time=0.864
[alab02] 2024-08-30 02:23:46,918 (trainer:720) INFO: 69epoch:train:6401-6600batch: iter_time=1.596e-04, forward_time=0.133, uma_reduction=0.281, text_vs_uma=0.341, loss_ctc=4.602, loss=2.301, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.748e-04, train_time=0.888
[alab02] 2024-08-30 02:25:14,101 (trainer:720) INFO: 69epoch:train:6601-6800batch: iter_time=1.727e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=4.564, loss=2.282, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.747e-04, train_time=0.872
[alab02] 2024-08-30 02:26:41,864 (trainer:720) INFO: 69epoch:train:6801-7000batch: iter_time=1.621e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.703, loss=2.351, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.747e-04, train_time=0.877
[alab02] 2024-08-30 02:27:56,075 (trainer:338) INFO: 69epoch results: [train] iter_time=2.191e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=4.399, loss=2.200, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.753e-04, train_time=0.862, time=51 minutes and 11.37 seconds, total_count=491694, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.293, text_vs_uma=0.372, loss_ctc=3.420, cer_ctc=0.099, cer=0.099, loss=3.420, time=6.06 seconds, total_count=1794, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.14 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 02:28:01,209 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 02:28:01,210 (trainer:272) INFO: 70/150epoch started. Estimated time to finish: 3 days, 2 hours and 34 minutes
[alab02] 2024-08-30 02:29:27,347 (trainer:720) INFO: 70epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=4.765, loss=2.383, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.746e-04, train_time=0.861
[alab02] 2024-08-30 02:30:51,927 (trainer:720) INFO: 70epoch:train:201-400batch: iter_time=1.763e-04, forward_time=0.126, uma_reduction=0.286, text_vs_uma=0.337, loss_ctc=4.164, loss=2.082, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.746e-04, train_time=0.846
[alab02] 2024-08-30 02:32:16,657 (trainer:720) INFO: 70epoch:train:401-600batch: iter_time=1.725e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.335, loss_ctc=4.230, loss=2.115, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.746e-04, train_time=0.847
[alab02] 2024-08-30 02:33:43,175 (trainer:720) INFO: 70epoch:train:601-800batch: iter_time=2.039e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.355, loss_ctc=4.360, loss=2.180, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.745e-04, train_time=0.865
[alab02] 2024-08-30 02:35:11,307 (trainer:720) INFO: 70epoch:train:801-1000batch: iter_time=1.763e-04, forward_time=0.132, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=4.307, loss=2.153, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.745e-04, train_time=0.881
[alab02] 2024-08-30 02:36:38,517 (trainer:720) INFO: 70epoch:train:1001-1200batch: iter_time=1.733e-04, forward_time=0.130, uma_reduction=0.288, text_vs_uma=0.333, loss_ctc=4.354, loss=2.177, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.745e-04, train_time=0.872
[alab02] 2024-08-30 02:38:07,244 (trainer:720) INFO: 70epoch:train:1201-1400batch: iter_time=1.717e-04, forward_time=0.133, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=4.144, loss=2.072, backward_time=0.188, optim_step_time=0.031, optim0_lr0=1.744e-04, train_time=0.887
[alab02] 2024-08-30 02:39:34,306 (trainer:720) INFO: 70epoch:train:1401-1600batch: iter_time=1.746e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=4.410, loss=2.205, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.744e-04, train_time=0.870
[alab02] 2024-08-30 02:40:59,559 (trainer:720) INFO: 70epoch:train:1601-1800batch: iter_time=1.662e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=4.217, loss=2.108, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.744e-04, train_time=0.852
[alab02] 2024-08-30 02:41:49,353 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 02:42:25,545 (trainer:720) INFO: 70epoch:train:1801-2000batch: iter_time=1.634e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=4.231, loss=2.115, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.743e-04, train_time=0.860
[alab02] 2024-08-30 02:43:51,868 (trainer:720) INFO: 70epoch:train:2001-2200batch: iter_time=1.721e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=4.629, loss=2.314, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.743e-04, train_time=0.863
[alab02] 2024-08-30 02:45:18,860 (trainer:720) INFO: 70epoch:train:2201-2400batch: iter_time=1.719e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.341, loss_ctc=4.023, loss=2.011, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.743e-04, train_time=0.870
[alab02] 2024-08-30 02:46:45,094 (trainer:720) INFO: 70epoch:train:2401-2600batch: iter_time=1.693e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.341, loss_ctc=3.968, loss=1.984, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.742e-04, train_time=0.862
[alab02] 2024-08-30 02:48:12,100 (trainer:720) INFO: 70epoch:train:2601-2800batch: iter_time=1.632e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.357, loss_ctc=4.272, loss=2.136, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.742e-04, train_time=0.870
[alab02] 2024-08-30 02:49:37,962 (trainer:720) INFO: 70epoch:train:2801-3000batch: iter_time=1.622e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.363, loss_ctc=4.274, loss=2.137, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.742e-04, train_time=0.858
[alab02] 2024-08-30 02:51:03,528 (trainer:720) INFO: 70epoch:train:3001-3200batch: iter_time=1.759e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.990, loss=1.995, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.741e-04, train_time=0.855
[alab02] 2024-08-30 02:52:27,256 (trainer:720) INFO: 70epoch:train:3201-3400batch: iter_time=1.702e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=4.717, loss=2.358, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.741e-04, train_time=0.837
[alab02] 2024-08-30 02:53:53,635 (trainer:720) INFO: 70epoch:train:3401-3600batch: iter_time=1.632e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=4.453, loss=2.227, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.740e-04, train_time=0.864
[alab02] 2024-08-30 02:54:13,419 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 02:55:20,274 (trainer:720) INFO: 70epoch:train:3601-3800batch: iter_time=1.704e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=4.273, loss=2.137, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.740e-04, train_time=0.866
[alab02] 2024-08-30 02:56:46,008 (trainer:720) INFO: 70epoch:train:3801-4000batch: iter_time=1.696e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=4.262, loss=2.131, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.740e-04, train_time=0.857
[alab02] 2024-08-30 02:58:12,311 (trainer:720) INFO: 70epoch:train:4001-4200batch: iter_time=1.595e-04, forward_time=0.129, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=4.363, loss=2.181, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.739e-04, train_time=0.863
[alab02] 2024-08-30 02:59:37,689 (trainer:720) INFO: 70epoch:train:4201-4400batch: iter_time=1.700e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=4.310, loss=2.155, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.739e-04, train_time=0.854
[alab02] 2024-08-30 03:01:03,227 (trainer:720) INFO: 70epoch:train:4401-4600batch: iter_time=1.718e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=4.205, loss=2.102, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.739e-04, train_time=0.855
[alab02] 2024-08-30 03:02:28,817 (trainer:720) INFO: 70epoch:train:4601-4800batch: iter_time=1.666e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.361, loss=2.181, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.738e-04, train_time=0.856
[alab02] 2024-08-30 03:03:54,510 (trainer:720) INFO: 70epoch:train:4801-5000batch: iter_time=1.662e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=4.193, loss=2.097, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.738e-04, train_time=0.857
[alab02] 2024-08-30 03:05:19,948 (trainer:720) INFO: 70epoch:train:5001-5200batch: iter_time=1.703e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=4.164, loss=2.082, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.738e-04, train_time=0.854
[alab02] 2024-08-30 03:06:46,053 (trainer:720) INFO: 70epoch:train:5201-5400batch: iter_time=1.619e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=4.379, loss=2.189, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.737e-04, train_time=0.861
[alab02] 2024-08-30 03:08:13,438 (trainer:720) INFO: 70epoch:train:5401-5600batch: iter_time=1.619e-04, forward_time=0.131, uma_reduction=0.277, text_vs_uma=0.342, loss_ctc=4.218, loss=2.109, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.737e-04, train_time=0.874
[alab02] 2024-08-30 03:09:38,307 (trainer:720) INFO: 70epoch:train:5601-5800batch: iter_time=1.497e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=4.189, loss=2.095, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.737e-04, train_time=0.848
[alab02] 2024-08-30 03:11:04,423 (trainer:720) INFO: 70epoch:train:5801-6000batch: iter_time=1.685e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=4.111, loss=2.056, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.736e-04, train_time=0.861
[alab02] 2024-08-30 03:12:30,239 (trainer:720) INFO: 70epoch:train:6001-6200batch: iter_time=1.750e-04, forward_time=0.128, uma_reduction=0.285, text_vs_uma=0.341, loss_ctc=4.066, loss=2.033, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.736e-04, train_time=0.858
[alab02] 2024-08-30 03:13:56,349 (trainer:720) INFO: 70epoch:train:6201-6400batch: iter_time=1.567e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=4.223, loss=2.112, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.736e-04, train_time=0.861
[alab02] 2024-08-30 03:15:23,311 (trainer:720) INFO: 70epoch:train:6401-6600batch: iter_time=1.720e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.360, loss_ctc=4.562, loss=2.281, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.735e-04, train_time=0.869
[alab02] 2024-08-30 03:16:50,410 (trainer:720) INFO: 70epoch:train:6601-6800batch: iter_time=1.719e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=4.874, loss=2.437, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.735e-04, train_time=0.871
[alab02] 2024-08-30 03:18:17,160 (trainer:720) INFO: 70epoch:train:6801-7000batch: iter_time=1.674e-04, forward_time=0.130, uma_reduction=0.263, text_vs_uma=0.371, loss_ctc=4.553, loss=2.276, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.735e-04, train_time=0.867
[alab02] 2024-08-30 03:19:31,044 (trainer:338) INFO: 70epoch results: [train] iter_time=2.180e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=4.304, loss=2.152, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.740e-04, train_time=0.862, time=51 minutes and 11.1 seconds, total_count=498820, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.261, text_vs_uma=0.417, loss_ctc=3.607, cer_ctc=0.098, cer=0.098, loss=3.607, time=5.88 seconds, total_count=1820, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.85 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 03:19:36,273 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 03:19:36,333 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/69epoch.pth
[alab02] 2024-08-30 03:19:36,333 (trainer:272) INFO: 71/150epoch started. Estimated time to finish: 3 days, 1 hour and 35 minutes
[alab02] 2024-08-30 03:21:04,112 (trainer:720) INFO: 71epoch:train:1-200batch: iter_time=0.002, forward_time=0.129, uma_reduction=0.244, text_vs_uma=0.395, loss_ctc=4.573, loss=2.287, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.734e-04, train_time=0.877
[alab02] 2024-08-30 03:22:30,403 (trainer:720) INFO: 71epoch:train:201-400batch: iter_time=1.973e-04, forward_time=0.129, uma_reduction=0.259, text_vs_uma=0.372, loss_ctc=4.146, loss=2.073, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.734e-04, train_time=0.863
[alab02] 2024-08-30 03:23:53,638 (trainer:720) INFO: 71epoch:train:401-600batch: iter_time=1.799e-04, forward_time=0.124, uma_reduction=0.259, text_vs_uma=0.367, loss_ctc=4.205, loss=2.103, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.733e-04, train_time=0.832
[alab02] 2024-08-30 03:25:20,625 (trainer:720) INFO: 71epoch:train:601-800batch: iter_time=1.706e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=4.414, loss=2.207, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.733e-04, train_time=0.870
[alab02] 2024-08-30 03:26:47,344 (trainer:720) INFO: 71epoch:train:801-1000batch: iter_time=1.819e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.366, loss_ctc=4.446, loss=2.223, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.733e-04, train_time=0.867
[alab02] 2024-08-30 03:28:11,213 (trainer:720) INFO: 71epoch:train:1001-1200batch: iter_time=1.627e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=4.257, loss=2.128, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.732e-04, train_time=0.838
[alab02] 2024-08-30 03:29:36,250 (trainer:720) INFO: 71epoch:train:1201-1400batch: iter_time=1.557e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=4.468, loss=2.234, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.732e-04, train_time=0.850
[alab02] 2024-08-30 03:31:06,527 (trainer:720) INFO: 71epoch:train:1401-1600batch: iter_time=2.150e-04, forward_time=0.136, uma_reduction=0.264, text_vs_uma=0.364, loss_ctc=4.436, loss=2.218, backward_time=0.190, optim_step_time=0.038, optim0_lr0=1.732e-04, train_time=0.902
[alab02] 2024-08-30 03:32:32,684 (trainer:720) INFO: 71epoch:train:1601-1800batch: iter_time=1.818e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=4.602, loss=2.301, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.731e-04, train_time=0.861
[alab02] 2024-08-30 03:34:00,312 (trainer:720) INFO: 71epoch:train:1801-2000batch: iter_time=1.673e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=4.646, loss=2.323, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.731e-04, train_time=0.876
[alab02] 2024-08-30 03:35:27,315 (trainer:720) INFO: 71epoch:train:2001-2200batch: iter_time=1.607e-04, forward_time=0.129, uma_reduction=0.263, text_vs_uma=0.370, loss_ctc=4.452, loss=2.226, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.731e-04, train_time=0.870
[alab02] 2024-08-30 03:36:51,150 (trainer:720) INFO: 71epoch:train:2201-2400batch: iter_time=1.641e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=4.266, loss=2.133, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.730e-04, train_time=0.838
[alab02] 2024-08-30 03:38:18,359 (trainer:720) INFO: 71epoch:train:2401-2600batch: iter_time=1.804e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.350, loss_ctc=4.127, loss=2.063, backward_time=0.184, optim_step_time=0.029, optim0_lr0=1.730e-04, train_time=0.872
[alab02] 2024-08-30 03:39:43,690 (trainer:720) INFO: 71epoch:train:2601-2800batch: iter_time=1.581e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=4.426, loss=2.213, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.729e-04, train_time=0.853
[alab02] 2024-08-30 03:41:09,471 (trainer:720) INFO: 71epoch:train:2801-3000batch: iter_time=1.672e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=4.126, loss=2.063, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.729e-04, train_time=0.858
[alab02] 2024-08-30 03:42:35,902 (trainer:720) INFO: 71epoch:train:3001-3200batch: iter_time=1.548e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=4.495, loss=2.248, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.729e-04, train_time=0.864
[alab02] 2024-08-30 03:44:03,532 (trainer:720) INFO: 71epoch:train:3201-3400batch: iter_time=1.521e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=4.436, loss=2.218, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.728e-04, train_time=0.876
[alab02] 2024-08-30 03:45:31,214 (trainer:720) INFO: 71epoch:train:3401-3600batch: iter_time=1.749e-04, forward_time=0.130, uma_reduction=0.250, text_vs_uma=0.393, loss_ctc=4.769, loss=2.385, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.728e-04, train_time=0.877
[alab02] 2024-08-30 03:46:56,815 (trainer:720) INFO: 71epoch:train:3601-3800batch: iter_time=1.647e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.373, loss_ctc=4.454, loss=2.227, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.728e-04, train_time=0.856
[alab02] 2024-08-30 03:48:22,916 (trainer:720) INFO: 71epoch:train:3801-4000batch: iter_time=1.858e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=4.535, loss=2.268, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.727e-04, train_time=0.861
[alab02] 2024-08-30 03:49:48,032 (trainer:720) INFO: 71epoch:train:4001-4200batch: iter_time=1.571e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.372, loss_ctc=4.747, loss=2.374, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.727e-04, train_time=0.851
[alab02] 2024-08-30 03:51:14,187 (trainer:720) INFO: 71epoch:train:4201-4400batch: iter_time=1.658e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.355, loss_ctc=3.887, loss=1.943, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.727e-04, train_time=0.861
[alab02] 2024-08-30 03:52:12,503 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 03:52:41,331 (trainer:720) INFO: 71epoch:train:4401-4600batch: iter_time=1.736e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.367, loss_ctc=4.392, loss=2.196, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.726e-04, train_time=0.871
[alab02] 2024-08-30 03:54:07,457 (trainer:720) INFO: 71epoch:train:4601-4800batch: iter_time=1.597e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=4.231, loss=2.116, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.726e-04, train_time=0.861
[alab02] 2024-08-30 03:55:33,160 (trainer:720) INFO: 71epoch:train:4801-5000batch: iter_time=1.594e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.352, loss_ctc=4.128, loss=2.064, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.726e-04, train_time=0.857
[alab02] 2024-08-30 03:57:01,101 (trainer:720) INFO: 71epoch:train:5001-5200batch: iter_time=1.568e-04, forward_time=0.131, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=4.687, loss=2.344, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.725e-04, train_time=0.879
[alab02] 2024-08-30 03:58:25,711 (trainer:720) INFO: 71epoch:train:5201-5400batch: iter_time=1.604e-04, forward_time=0.125, uma_reduction=0.258, text_vs_uma=0.380, loss_ctc=4.512, loss=2.256, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.725e-04, train_time=0.846
[alab02] 2024-08-30 03:59:52,029 (trainer:720) INFO: 71epoch:train:5401-5600batch: iter_time=1.858e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=4.448, loss=2.224, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.725e-04, train_time=0.863
[alab02] 2024-08-30 04:01:18,479 (trainer:720) INFO: 71epoch:train:5601-5800batch: iter_time=1.564e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.367, loss_ctc=4.409, loss=2.205, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.724e-04, train_time=0.864
[alab02] 2024-08-30 04:02:44,579 (trainer:720) INFO: 71epoch:train:5801-6000batch: iter_time=1.692e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=4.213, loss=2.107, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.724e-04, train_time=0.861
[alab02] 2024-08-30 04:04:11,991 (trainer:720) INFO: 71epoch:train:6001-6200batch: iter_time=1.580e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=4.073, loss=2.036, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.724e-04, train_time=0.874
[alab02] 2024-08-30 04:05:39,259 (trainer:720) INFO: 71epoch:train:6201-6400batch: iter_time=1.604e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=4.485, loss=2.243, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.723e-04, train_time=0.872
[alab02] 2024-08-30 04:07:05,680 (trainer:720) INFO: 71epoch:train:6401-6600batch: iter_time=1.572e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=4.432, loss=2.216, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.723e-04, train_time=0.864
[alab02] 2024-08-30 04:08:30,991 (trainer:720) INFO: 71epoch:train:6601-6800batch: iter_time=1.584e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=4.298, loss=2.149, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.723e-04, train_time=0.853
[alab02] 2024-08-30 04:09:58,250 (trainer:720) INFO: 71epoch:train:6801-7000batch: iter_time=2.184e-04, forward_time=0.130, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.987, loss=1.994, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.722e-04, train_time=0.872
[alab02] 2024-08-30 04:11:13,471 (trainer:338) INFO: 71epoch results: [train] iter_time=2.193e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=4.377, loss=2.189, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.728e-04, train_time=0.863, time=51 minutes and 16.93 seconds, total_count=505946, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.277, text_vs_uma=0.392, loss_ctc=3.428, cer_ctc=0.091, cer=0.091, loss=3.428, time=6.23 seconds, total_count=1846, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.98 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 04:11:18,604 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 04:11:18,663 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/70epoch.pth
[alab02] 2024-08-30 04:11:18,663 (trainer:272) INFO: 72/150epoch started. Estimated time to finish: 3 days, 36 minutes and 2.15 seconds
[alab02] 2024-08-30 04:12:43,032 (trainer:720) INFO: 72epoch:train:1-200batch: iter_time=0.002, forward_time=0.124, uma_reduction=0.252, text_vs_uma=0.381, loss_ctc=4.104, loss=2.052, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.722e-04, train_time=0.843
[alab02] 2024-08-30 04:14:11,013 (trainer:720) INFO: 72epoch:train:201-400batch: iter_time=1.757e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.369, loss_ctc=4.202, loss=2.101, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.721e-04, train_time=0.880
[alab02] 2024-08-30 04:15:10,248 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 04:15:37,650 (trainer:720) INFO: 72epoch:train:401-600batch: iter_time=1.634e-04, forward_time=0.128, uma_reduction=0.259, text_vs_uma=0.381, loss_ctc=4.647, loss=2.323, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.721e-04, train_time=0.866
[alab02] 2024-08-30 04:17:04,189 (trainer:720) INFO: 72epoch:train:601-800batch: iter_time=1.666e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.341, loss_ctc=4.032, loss=2.016, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.721e-04, train_time=0.865
[alab02] 2024-08-30 04:18:30,445 (trainer:720) INFO: 72epoch:train:801-1000batch: iter_time=2.097e-04, forward_time=0.128, uma_reduction=0.290, text_vs_uma=0.331, loss_ctc=3.926, loss=1.963, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.720e-04, train_time=0.862
[alab02] 2024-08-30 04:19:56,082 (trainer:720) INFO: 72epoch:train:1001-1200batch: iter_time=1.693e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.334, loss_ctc=3.971, loss=1.985, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.720e-04, train_time=0.856
[alab02] 2024-08-30 04:21:23,681 (trainer:720) INFO: 72epoch:train:1201-1400batch: iter_time=1.708e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.359, loss_ctc=4.377, loss=2.189, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.720e-04, train_time=0.876
[alab02] 2024-08-30 04:22:47,885 (trainer:720) INFO: 72epoch:train:1401-1600batch: iter_time=1.619e-04, forward_time=0.125, uma_reduction=0.286, text_vs_uma=0.347, loss_ctc=4.191, loss=2.096, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.719e-04, train_time=0.842
[alab02] 2024-08-30 04:24:15,018 (trainer:720) INFO: 72epoch:train:1601-1800batch: iter_time=1.731e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=4.142, loss=2.071, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.719e-04, train_time=0.871
[alab02] 2024-08-30 04:25:40,647 (trainer:720) INFO: 72epoch:train:1801-2000batch: iter_time=1.855e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.351, loss_ctc=4.325, loss=2.163, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.719e-04, train_time=0.856
[alab02] 2024-08-30 04:27:04,551 (trainer:720) INFO: 72epoch:train:2001-2200batch: iter_time=1.681e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=4.364, loss=2.182, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.718e-04, train_time=0.839
[alab02] 2024-08-30 04:28:28,819 (trainer:720) INFO: 72epoch:train:2201-2400batch: iter_time=1.802e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.363, loss_ctc=4.161, loss=2.080, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.718e-04, train_time=0.842
[alab02] 2024-08-30 04:29:56,422 (trainer:720) INFO: 72epoch:train:2401-2600batch: iter_time=1.631e-04, forward_time=0.131, uma_reduction=0.275, text_vs_uma=0.344, loss_ctc=3.924, loss=1.962, backward_time=0.188, optim_step_time=0.031, optim0_lr0=1.718e-04, train_time=0.876
[alab02] 2024-08-30 04:31:21,412 (trainer:720) INFO: 72epoch:train:2601-2800batch: iter_time=1.671e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.344, loss_ctc=4.060, loss=2.030, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.717e-04, train_time=0.850
[alab02] 2024-08-30 04:32:47,283 (trainer:720) INFO: 72epoch:train:2801-3000batch: iter_time=1.704e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.363, loss_ctc=4.417, loss=2.209, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.717e-04, train_time=0.858
[alab02] 2024-08-30 04:34:14,467 (trainer:720) INFO: 72epoch:train:3001-3200batch: iter_time=1.724e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.365, loss_ctc=4.366, loss=2.183, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.717e-04, train_time=0.872
[alab02] 2024-08-30 04:35:42,783 (trainer:720) INFO: 72epoch:train:3201-3400batch: iter_time=1.634e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=4.325, loss=2.162, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.716e-04, train_time=0.883
[alab02] 2024-08-30 04:37:09,977 (trainer:720) INFO: 72epoch:train:3401-3600batch: iter_time=1.620e-04, forward_time=0.130, uma_reduction=0.283, text_vs_uma=0.343, loss_ctc=4.430, loss=2.215, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.716e-04, train_time=0.872
[alab02] 2024-08-30 04:38:37,267 (trainer:720) INFO: 72epoch:train:3601-3800batch: iter_time=1.561e-04, forward_time=0.130, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=4.251, loss=2.126, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.716e-04, train_time=0.873
[alab02] 2024-08-30 04:40:00,936 (trainer:720) INFO: 72epoch:train:3801-4000batch: iter_time=1.668e-04, forward_time=0.124, uma_reduction=0.282, text_vs_uma=0.351, loss_ctc=4.598, loss=2.299, backward_time=0.169, optim_step_time=0.031, optim0_lr0=1.715e-04, train_time=0.836
[alab02] 2024-08-30 04:41:26,535 (trainer:720) INFO: 72epoch:train:4001-4200batch: iter_time=1.620e-04, forward_time=0.127, uma_reduction=0.286, text_vs_uma=0.335, loss_ctc=4.086, loss=2.043, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.715e-04, train_time=0.856
[alab02] 2024-08-30 04:42:52,687 (trainer:720) INFO: 72epoch:train:4201-4400batch: iter_time=1.529e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=4.513, loss=2.256, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.715e-04, train_time=0.861
[alab02] 2024-08-30 04:44:23,210 (trainer:720) INFO: 72epoch:train:4401-4600batch: iter_time=1.611e-04, forward_time=0.134, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=4.158, loss=2.079, backward_time=0.194, optim_step_time=0.030, optim0_lr0=1.714e-04, train_time=0.905
[alab02] 2024-08-30 04:45:50,740 (trainer:720) INFO: 72epoch:train:4601-4800batch: iter_time=1.699e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.346, loss_ctc=4.001, loss=2.001, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.714e-04, train_time=0.875
[alab02] 2024-08-30 04:47:18,500 (trainer:720) INFO: 72epoch:train:4801-5000batch: iter_time=1.592e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=4.165, loss=2.083, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.714e-04, train_time=0.877
[alab02] 2024-08-30 04:48:45,808 (trainer:720) INFO: 72epoch:train:5001-5200batch: iter_time=1.528e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.340, loss_ctc=4.280, loss=2.140, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.713e-04, train_time=0.873
[alab02] 2024-08-30 04:50:12,531 (trainer:720) INFO: 72epoch:train:5201-5400batch: iter_time=1.765e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=4.196, loss=2.098, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.713e-04, train_time=0.867
[alab02] 2024-08-30 04:51:38,696 (trainer:720) INFO: 72epoch:train:5401-5600batch: iter_time=1.778e-04, forward_time=0.128, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=4.095, loss=2.048, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.713e-04, train_time=0.861
[alab02] 2024-08-30 04:53:07,064 (trainer:720) INFO: 72epoch:train:5601-5800batch: iter_time=1.729e-04, forward_time=0.132, uma_reduction=0.285, text_vs_uma=0.333, loss_ctc=3.937, loss=1.969, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.712e-04, train_time=0.883
[alab02] 2024-08-30 04:54:30,629 (trainer:720) INFO: 72epoch:train:5801-6000batch: iter_time=1.631e-04, forward_time=0.124, uma_reduction=0.290, text_vs_uma=0.340, loss_ctc=4.074, loss=2.037, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.712e-04, train_time=0.835
[alab02] 2024-08-30 04:55:56,650 (trainer:720) INFO: 72epoch:train:6001-6200batch: iter_time=1.696e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.346, loss_ctc=4.227, loss=2.114, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.712e-04, train_time=0.860
[alab02] 2024-08-30 04:57:22,262 (trainer:720) INFO: 72epoch:train:6201-6400batch: iter_time=1.681e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.352, loss_ctc=4.274, loss=2.137, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.711e-04, train_time=0.856
[alab02] 2024-08-30 04:58:49,094 (trainer:720) INFO: 72epoch:train:6401-6600batch: iter_time=1.598e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=4.137, loss=2.069, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.711e-04, train_time=0.868
[alab02] 2024-08-30 05:00:16,867 (trainer:720) INFO: 72epoch:train:6601-6800batch: iter_time=1.657e-04, forward_time=0.131, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=4.081, loss=2.041, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.711e-04, train_time=0.877
[alab02] 2024-08-30 05:01:42,249 (trainer:720) INFO: 72epoch:train:6801-7000batch: iter_time=1.563e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=4.258, loss=2.129, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.710e-04, train_time=0.854
[alab02] 2024-08-30 05:02:55,745 (trainer:338) INFO: 72epoch results: [train] iter_time=2.180e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.209, loss=2.105, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.716e-04, train_time=0.863, time=51 minutes and 17.75 seconds, total_count=513072, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.288, text_vs_uma=0.378, loss_ctc=3.408, cer_ctc=0.091, cer=0.091, loss=3.408, time=6.15 seconds, total_count=1872, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.18 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 05:03:00,188 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 05:03:00,243 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/71epoch.pth
[alab02] 2024-08-30 05:03:00,244 (trainer:272) INFO: 73/150epoch started. Estimated time to finish: 2 days, 23 hours and 37 minutes
[alab02] 2024-08-30 05:04:26,445 (trainer:720) INFO: 73epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.365, loss_ctc=4.555, loss=2.278, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.710e-04, train_time=0.862
[alab02] 2024-08-30 05:05:53,202 (trainer:720) INFO: 73epoch:train:201-400batch: iter_time=1.720e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.352, loss_ctc=4.242, loss=2.121, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.709e-04, train_time=0.867
[alab02] 2024-08-30 05:07:18,334 (trainer:720) INFO: 73epoch:train:401-600batch: iter_time=1.721e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.352, loss_ctc=4.200, loss=2.100, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.709e-04, train_time=0.851
[alab02] 2024-08-30 05:08:43,884 (trainer:720) INFO: 73epoch:train:601-800batch: iter_time=1.819e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=4.461, loss=2.231, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.709e-04, train_time=0.855
[alab02] 2024-08-30 05:10:08,637 (trainer:720) INFO: 73epoch:train:801-1000batch: iter_time=1.919e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=4.333, loss=2.167, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.708e-04, train_time=0.847
[alab02] 2024-08-30 05:11:35,628 (trainer:720) INFO: 73epoch:train:1001-1200batch: iter_time=1.732e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=4.516, loss=2.258, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.708e-04, train_time=0.870
[alab02] 2024-08-30 05:13:01,171 (trainer:720) INFO: 73epoch:train:1201-1400batch: iter_time=1.776e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=4.539, loss=2.269, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.708e-04, train_time=0.855
[alab02] 2024-08-30 05:14:27,330 (trainer:720) INFO: 73epoch:train:1401-1600batch: iter_time=1.667e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=4.421, loss=2.211, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.707e-04, train_time=0.861
[alab02] 2024-08-30 05:15:55,373 (trainer:720) INFO: 73epoch:train:1601-1800batch: iter_time=1.683e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.384, loss=2.192, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.707e-04, train_time=0.880
[alab02] 2024-08-30 05:16:53,395 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 05:17:18,907 (trainer:720) INFO: 73epoch:train:1801-2000batch: iter_time=1.735e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=4.068, loss=2.034, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.707e-04, train_time=0.835
[alab02] 2024-08-30 05:18:43,337 (trainer:720) INFO: 73epoch:train:2001-2200batch: iter_time=1.632e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=4.367, loss=2.184, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.706e-04, train_time=0.844
[alab02] 2024-08-30 05:20:11,328 (trainer:720) INFO: 73epoch:train:2201-2400batch: iter_time=1.612e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.368, loss_ctc=4.474, loss=2.237, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.706e-04, train_time=0.880
[alab02] 2024-08-30 05:21:36,190 (trainer:720) INFO: 73epoch:train:2401-2600batch: iter_time=1.667e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=4.698, loss=2.349, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.706e-04, train_time=0.848
[alab02] 2024-08-30 05:23:01,983 (trainer:720) INFO: 73epoch:train:2601-2800batch: iter_time=1.686e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=4.104, loss=2.052, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.705e-04, train_time=0.858
[alab02] 2024-08-30 05:23:07,940 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 05:24:28,152 (trainer:720) INFO: 73epoch:train:2801-3000batch: iter_time=1.673e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=4.726, loss=2.363, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.705e-04, train_time=0.861
[alab02] 2024-08-30 05:25:54,882 (trainer:720) INFO: 73epoch:train:3001-3200batch: iter_time=1.714e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=4.191, loss=2.095, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.705e-04, train_time=0.867
[alab02] 2024-08-30 05:27:21,914 (trainer:720) INFO: 73epoch:train:3201-3400batch: iter_time=1.646e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=4.318, loss=2.159, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.704e-04, train_time=0.870
[alab02] 2024-08-30 05:28:49,217 (trainer:720) INFO: 73epoch:train:3401-3600batch: iter_time=1.708e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=4.609, loss=2.305, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.704e-04, train_time=0.873
[alab02] 2024-08-30 05:30:15,593 (trainer:720) INFO: 73epoch:train:3601-3800batch: iter_time=1.780e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=4.300, loss=2.150, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.704e-04, train_time=0.864
[alab02] 2024-08-30 05:31:42,140 (trainer:720) INFO: 73epoch:train:3801-4000batch: iter_time=1.725e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=4.557, loss=2.278, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.703e-04, train_time=0.865
[alab02] 2024-08-30 05:33:06,542 (trainer:720) INFO: 73epoch:train:4001-4200batch: iter_time=1.682e-04, forward_time=0.125, uma_reduction=0.287, text_vs_uma=0.336, loss_ctc=4.172, loss=2.086, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.703e-04, train_time=0.844
[alab02] 2024-08-30 05:34:32,809 (trainer:720) INFO: 73epoch:train:4201-4400batch: iter_time=1.650e-04, forward_time=0.128, uma_reduction=0.291, text_vs_uma=0.337, loss_ctc=4.031, loss=2.015, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.703e-04, train_time=0.862
[alab02] 2024-08-30 05:35:57,844 (trainer:720) INFO: 73epoch:train:4401-4600batch: iter_time=1.734e-04, forward_time=0.126, uma_reduction=0.290, text_vs_uma=0.338, loss_ctc=4.385, loss=2.192, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.702e-04, train_time=0.850
[alab02] 2024-08-30 05:37:24,206 (trainer:720) INFO: 73epoch:train:4601-4800batch: iter_time=1.957e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.346, loss_ctc=4.434, loss=2.217, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.702e-04, train_time=0.863
[alab02] 2024-08-30 05:38:51,104 (trainer:720) INFO: 73epoch:train:4801-5000batch: iter_time=2.212e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.351, loss_ctc=4.387, loss=2.194, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.702e-04, train_time=0.869
[alab02] 2024-08-30 05:40:16,027 (trainer:720) INFO: 73epoch:train:5001-5200batch: iter_time=1.613e-04, forward_time=0.126, uma_reduction=0.288, text_vs_uma=0.332, loss_ctc=4.165, loss=2.083, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.701e-04, train_time=0.849
[alab02] 2024-08-30 05:41:42,364 (trainer:720) INFO: 73epoch:train:5201-5400batch: iter_time=1.682e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=4.659, loss=2.329, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.701e-04, train_time=0.863
[alab02] 2024-08-30 05:43:10,252 (trainer:720) INFO: 73epoch:train:5401-5600batch: iter_time=1.677e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.351, loss_ctc=4.385, loss=2.192, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.701e-04, train_time=0.879
[alab02] 2024-08-30 05:44:37,364 (trainer:720) INFO: 73epoch:train:5601-5800batch: iter_time=1.677e-04, forward_time=0.130, uma_reduction=0.288, text_vs_uma=0.337, loss_ctc=4.062, loss=2.031, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.700e-04, train_time=0.871
[alab02] 2024-08-30 05:46:03,140 (trainer:720) INFO: 73epoch:train:5801-6000batch: iter_time=1.619e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.349, loss_ctc=4.218, loss=2.109, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.700e-04, train_time=0.858
[alab02] 2024-08-30 05:47:30,387 (trainer:720) INFO: 73epoch:train:6001-6200batch: iter_time=1.591e-04, forward_time=0.130, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=4.272, loss=2.136, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.700e-04, train_time=0.872
[alab02] 2024-08-30 05:48:55,956 (trainer:720) INFO: 73epoch:train:6201-6400batch: iter_time=1.551e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.346, loss_ctc=4.252, loss=2.126, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.700e-04, train_time=0.855
[alab02] 2024-08-30 05:50:23,168 (trainer:720) INFO: 73epoch:train:6401-6600batch: iter_time=1.609e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=4.195, loss=2.098, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.699e-04, train_time=0.872
[alab02] 2024-08-30 05:51:49,718 (trainer:720) INFO: 73epoch:train:6601-6800batch: iter_time=1.744e-04, forward_time=0.129, uma_reduction=0.287, text_vs_uma=0.343, loss_ctc=4.123, loss=2.061, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.699e-04, train_time=0.865
[alab02] 2024-08-30 05:53:17,141 (trainer:720) INFO: 73epoch:train:6801-7000batch: iter_time=1.587e-04, forward_time=0.130, uma_reduction=0.291, text_vs_uma=0.324, loss_ctc=3.809, loss=1.904, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.699e-04, train_time=0.874
[alab02] 2024-08-30 05:54:30,441 (trainer:338) INFO: 73epoch results: [train] iter_time=2.286e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.351, loss_ctc=4.330, loss=2.165, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.704e-04, train_time=0.862, time=51 minutes and 11.6 seconds, total_count=520198, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.303, text_vs_uma=0.359, loss_ctc=3.314, cer_ctc=0.087, cer=0.087, loss=3.314, time=5.94 seconds, total_count=1898, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.66 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 05:54:35,187 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 05:54:35,251 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/55epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/72epoch.pth
[alab02] 2024-08-30 05:54:35,252 (trainer:272) INFO: 74/150epoch started. Estimated time to finish: 2 days, 22 hours and 38 minutes
[alab02] 2024-08-30 05:56:00,459 (trainer:720) INFO: 74epoch:train:1-200batch: iter_time=0.002, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=4.193, loss=2.097, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.698e-04, train_time=0.852
[alab02] 2024-08-30 05:57:27,948 (trainer:720) INFO: 74epoch:train:201-400batch: iter_time=1.749e-04, forward_time=0.130, uma_reduction=0.286, text_vs_uma=0.335, loss_ctc=4.249, loss=2.125, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.698e-04, train_time=0.875
[alab02] 2024-08-30 05:58:54,030 (trainer:720) INFO: 74epoch:train:401-600batch: iter_time=1.814e-04, forward_time=0.128, uma_reduction=0.291, text_vs_uma=0.333, loss_ctc=3.956, loss=1.978, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.697e-04, train_time=0.861
[alab02] 2024-08-30 06:00:21,110 (trainer:720) INFO: 74epoch:train:601-800batch: iter_time=1.721e-04, forward_time=0.130, uma_reduction=0.291, text_vs_uma=0.331, loss_ctc=3.843, loss=1.921, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.697e-04, train_time=0.871
[alab02] 2024-08-30 06:01:46,301 (trainer:720) INFO: 74epoch:train:801-1000batch: iter_time=1.690e-04, forward_time=0.127, uma_reduction=0.289, text_vs_uma=0.327, loss_ctc=3.673, loss=1.836, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.697e-04, train_time=0.852
[alab02] 2024-08-30 06:03:13,013 (trainer:720) INFO: 74epoch:train:1001-1200batch: iter_time=1.842e-04, forward_time=0.129, uma_reduction=0.286, text_vs_uma=0.343, loss_ctc=3.909, loss=1.955, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.696e-04, train_time=0.867
[alab02] 2024-08-30 06:04:41,689 (trainer:720) INFO: 74epoch:train:1201-1400batch: iter_time=1.696e-04, forward_time=0.132, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=4.050, loss=2.025, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.696e-04, train_time=0.887
[alab02] 2024-08-30 06:06:09,514 (trainer:720) INFO: 74epoch:train:1401-1600batch: iter_time=1.731e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.079, loss=2.039, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.696e-04, train_time=0.878
[alab02] 2024-08-30 06:07:36,406 (trainer:720) INFO: 74epoch:train:1601-1800batch: iter_time=1.665e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.352, loss_ctc=3.858, loss=1.929, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.695e-04, train_time=0.869
[alab02] 2024-08-30 06:09:02,100 (trainer:720) INFO: 74epoch:train:1801-2000batch: iter_time=1.693e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=4.388, loss=2.194, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.695e-04, train_time=0.857
[alab02] 2024-08-30 06:10:29,412 (trainer:720) INFO: 74epoch:train:2001-2200batch: iter_time=1.710e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=3.993, loss=1.996, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.695e-04, train_time=0.873
[alab02] 2024-08-30 06:11:55,367 (trainer:720) INFO: 74epoch:train:2201-2400batch: iter_time=1.582e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=4.167, loss=2.083, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.694e-04, train_time=0.859
[alab02] 2024-08-30 06:13:20,237 (trainer:720) INFO: 74epoch:train:2401-2600batch: iter_time=1.500e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.341, loss_ctc=4.079, loss=2.039, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.694e-04, train_time=0.848
[alab02] 2024-08-30 06:14:44,901 (trainer:720) INFO: 74epoch:train:2601-2800batch: iter_time=1.600e-04, forward_time=0.125, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=4.298, loss=2.149, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.694e-04, train_time=0.846
[alab02] 2024-08-30 06:16:13,015 (trainer:720) INFO: 74epoch:train:2801-3000batch: iter_time=1.474e-04, forward_time=0.131, uma_reduction=0.285, text_vs_uma=0.345, loss_ctc=4.289, loss=2.144, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.693e-04, train_time=0.881
[alab02] 2024-08-30 06:17:37,707 (trainer:720) INFO: 74epoch:train:3001-3200batch: iter_time=1.505e-04, forward_time=0.126, uma_reduction=0.290, text_vs_uma=0.340, loss_ctc=3.955, loss=1.978, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.693e-04, train_time=0.847
[alab02] 2024-08-30 06:19:04,126 (trainer:720) INFO: 74epoch:train:3201-3400batch: iter_time=1.534e-04, forward_time=0.128, uma_reduction=0.302, text_vs_uma=0.320, loss_ctc=4.034, loss=2.017, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.693e-04, train_time=0.864
[alab02] 2024-08-30 06:20:30,801 (trainer:720) INFO: 74epoch:train:3401-3600batch: iter_time=1.553e-04, forward_time=0.128, uma_reduction=0.303, text_vs_uma=0.322, loss_ctc=4.101, loss=2.050, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.692e-04, train_time=0.867
[alab02] 2024-08-30 06:21:56,890 (trainer:720) INFO: 74epoch:train:3601-3800batch: iter_time=1.619e-04, forward_time=0.128, uma_reduction=0.293, text_vs_uma=0.331, loss_ctc=4.290, loss=2.145, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.692e-04, train_time=0.861
[alab02] 2024-08-30 06:23:22,225 (trainer:720) INFO: 74epoch:train:3801-4000batch: iter_time=1.500e-04, forward_time=0.127, uma_reduction=0.290, text_vs_uma=0.336, loss_ctc=4.306, loss=2.153, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.692e-04, train_time=0.853
[alab02] 2024-08-30 06:24:01,472 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 06:24:48,334 (trainer:720) INFO: 74epoch:train:4001-4200batch: iter_time=1.648e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.241, loss=2.121, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.692e-04, train_time=0.861
[alab02] 2024-08-30 06:26:15,533 (trainer:720) INFO: 74epoch:train:4201-4400batch: iter_time=1.736e-04, forward_time=0.131, uma_reduction=0.262, text_vs_uma=0.368, loss_ctc=4.182, loss=2.091, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.691e-04, train_time=0.872
[alab02] 2024-08-30 06:27:43,546 (trainer:720) INFO: 74epoch:train:4401-4600batch: iter_time=1.894e-04, forward_time=0.133, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=3.791, loss=1.896, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.691e-04, train_time=0.880
[alab02] 2024-08-30 06:29:11,173 (trainer:720) INFO: 74epoch:train:4601-4800batch: iter_time=2.310e-04, forward_time=0.132, uma_reduction=0.282, text_vs_uma=0.350, loss_ctc=4.276, loss=2.138, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.691e-04, train_time=0.876
[alab02] 2024-08-30 06:30:36,193 (trainer:720) INFO: 74epoch:train:4801-5000batch: iter_time=1.761e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=4.476, loss=2.238, backward_time=0.173, optim_step_time=0.032, optim0_lr0=1.690e-04, train_time=0.850
[alab02] 2024-08-30 06:32:05,091 (trainer:720) INFO: 74epoch:train:5001-5200batch: iter_time=1.916e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.369, loss_ctc=4.493, loss=2.247, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.690e-04, train_time=0.889
[alab02] 2024-08-30 06:33:32,035 (trainer:720) INFO: 74epoch:train:5201-5400batch: iter_time=1.596e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.348, loss_ctc=3.997, loss=1.999, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.690e-04, train_time=0.869
[alab02] 2024-08-30 06:34:59,588 (trainer:720) INFO: 74epoch:train:5401-5600batch: iter_time=1.629e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=4.183, loss=2.092, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.689e-04, train_time=0.875
[alab02] 2024-08-30 06:36:26,739 (trainer:720) INFO: 74epoch:train:5601-5800batch: iter_time=1.568e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=4.217, loss=2.108, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.689e-04, train_time=0.871
[alab02] 2024-08-30 06:37:51,245 (trainer:720) INFO: 74epoch:train:5801-6000batch: iter_time=1.837e-04, forward_time=0.126, uma_reduction=0.260, text_vs_uma=0.373, loss_ctc=4.688, loss=2.344, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.689e-04, train_time=0.845
[alab02] 2024-08-30 06:39:17,775 (trainer:720) INFO: 74epoch:train:6001-6200batch: iter_time=1.697e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.346, loss_ctc=4.071, loss=2.035, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.688e-04, train_time=0.865
[alab02] 2024-08-30 06:40:45,189 (trainer:720) INFO: 74epoch:train:6201-6400batch: iter_time=1.625e-04, forward_time=0.130, uma_reduction=0.279, text_vs_uma=0.355, loss_ctc=4.688, loss=2.344, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.688e-04, train_time=0.874
[alab02] 2024-08-30 06:42:08,969 (trainer:720) INFO: 74epoch:train:6401-6600batch: iter_time=1.642e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=4.266, loss=2.133, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.688e-04, train_time=0.838
[alab02] 2024-08-30 06:43:35,776 (trainer:720) INFO: 74epoch:train:6601-6800batch: iter_time=1.670e-04, forward_time=0.131, uma_reduction=0.284, text_vs_uma=0.334, loss_ctc=3.954, loss=1.977, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.687e-04, train_time=0.868
[alab02] 2024-08-30 06:45:04,764 (trainer:720) INFO: 74epoch:train:6801-7000batch: iter_time=1.632e-04, forward_time=0.133, uma_reduction=0.285, text_vs_uma=0.344, loss_ctc=4.195, loss=2.097, backward_time=0.188, optim_step_time=0.031, optim0_lr0=1.687e-04, train_time=0.890
[alab02] 2024-08-30 06:46:18,680 (trainer:338) INFO: 74epoch results: [train] iter_time=2.313e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=4.143, loss=2.071, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.692e-04, train_time=0.865, time=51 minutes and 23.83 seconds, total_count=527324, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.297, text_vs_uma=0.366, loss_ctc=3.354, cer_ctc=0.092, cer=0.092, loss=3.354, time=6.13 seconds, total_count=1924, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.47 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 06:46:23,783 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 06:46:23,784 (trainer:272) INFO: 75/150epoch started. Estimated time to finish: 2 days, 21 hours and 40 minutes
[alab02] 2024-08-30 06:47:49,204 (trainer:720) INFO: 75epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=4.290, loss=2.145, backward_time=0.171, optim_step_time=0.031, optim0_lr0=1.686e-04, train_time=0.854
[alab02] 2024-08-30 06:48:03,700 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 06:49:15,469 (trainer:720) INFO: 75epoch:train:201-400batch: iter_time=1.734e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.139, loss=2.070, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.686e-04, train_time=0.862
[alab02] 2024-08-30 06:50:43,656 (trainer:720) INFO: 75epoch:train:401-600batch: iter_time=1.746e-04, forward_time=0.132, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=4.485, loss=2.242, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.686e-04, train_time=0.882
[alab02] 2024-08-30 06:52:08,382 (trainer:720) INFO: 75epoch:train:601-800batch: iter_time=1.659e-04, forward_time=0.127, uma_reduction=0.288, text_vs_uma=0.335, loss_ctc=4.040, loss=2.020, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.686e-04, train_time=0.847
[alab02] 2024-08-30 06:53:36,025 (trainer:720) INFO: 75epoch:train:801-1000batch: iter_time=1.838e-04, forward_time=0.132, uma_reduction=0.281, text_vs_uma=0.351, loss_ctc=4.424, loss=2.212, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.685e-04, train_time=0.876
[alab02] 2024-08-30 06:55:04,316 (trainer:720) INFO: 75epoch:train:1001-1200batch: iter_time=1.906e-04, forward_time=0.132, uma_reduction=0.283, text_vs_uma=0.336, loss_ctc=4.105, loss=2.053, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.685e-04, train_time=0.883
[alab02] 2024-08-30 06:56:31,060 (trainer:720) INFO: 75epoch:train:1201-1400batch: iter_time=1.846e-04, forward_time=0.131, uma_reduction=0.284, text_vs_uma=0.332, loss_ctc=4.047, loss=2.024, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.685e-04, train_time=0.867
[alab02] 2024-08-30 06:57:56,590 (trainer:720) INFO: 75epoch:train:1401-1600batch: iter_time=1.692e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=4.568, loss=2.284, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.684e-04, train_time=0.855
[alab02] 2024-08-30 06:59:22,576 (trainer:720) INFO: 75epoch:train:1601-1800batch: iter_time=1.677e-04, forward_time=0.130, uma_reduction=0.286, text_vs_uma=0.337, loss_ctc=4.243, loss=2.121, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.684e-04, train_time=0.860
[alab02] 2024-08-30 07:00:48,178 (trainer:720) INFO: 75epoch:train:1801-2000batch: iter_time=1.785e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.342, loss_ctc=4.109, loss=2.054, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.684e-04, train_time=0.856
[alab02] 2024-08-30 07:02:17,091 (trainer:720) INFO: 75epoch:train:2001-2200batch: iter_time=1.836e-04, forward_time=0.133, uma_reduction=0.290, text_vs_uma=0.333, loss_ctc=4.144, loss=2.072, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.683e-04, train_time=0.889
[alab02] 2024-08-30 07:03:44,873 (trainer:720) INFO: 75epoch:train:2201-2400batch: iter_time=1.738e-04, forward_time=0.132, uma_reduction=0.289, text_vs_uma=0.338, loss_ctc=4.264, loss=2.132, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.683e-04, train_time=0.878
[alab02] 2024-08-30 07:05:11,761 (trainer:720) INFO: 75epoch:train:2401-2600batch: iter_time=1.681e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.338, loss_ctc=4.047, loss=2.024, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.683e-04, train_time=0.869
[alab02] 2024-08-30 07:06:38,447 (trainer:720) INFO: 75epoch:train:2601-2800batch: iter_time=1.686e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=4.296, loss=2.148, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.682e-04, train_time=0.867
[alab02] 2024-08-30 07:08:05,069 (trainer:720) INFO: 75epoch:train:2801-3000batch: iter_time=1.710e-04, forward_time=0.129, uma_reduction=0.288, text_vs_uma=0.342, loss_ctc=4.130, loss=2.065, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.682e-04, train_time=0.866
[alab02] 2024-08-30 07:09:29,426 (trainer:720) INFO: 75epoch:train:3001-3200batch: iter_time=1.694e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.340, loss_ctc=4.124, loss=2.062, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.682e-04, train_time=0.843
[alab02] 2024-08-30 07:10:59,516 (trainer:720) INFO: 75epoch:train:3201-3400batch: iter_time=1.785e-04, forward_time=0.135, uma_reduction=0.273, text_vs_uma=0.346, loss_ctc=3.992, loss=1.996, backward_time=0.193, optim_step_time=0.031, optim0_lr0=1.681e-04, train_time=0.901
[alab02] 2024-08-30 07:12:26,540 (trainer:720) INFO: 75epoch:train:3401-3600batch: iter_time=1.790e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.361, loss_ctc=4.323, loss=2.162, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.681e-04, train_time=0.870
[alab02] 2024-08-30 07:13:52,084 (trainer:720) INFO: 75epoch:train:3601-3800batch: iter_time=1.727e-04, forward_time=0.128, uma_reduction=0.258, text_vs_uma=0.379, loss_ctc=4.079, loss=2.040, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.681e-04, train_time=0.855
[alab02] 2024-08-30 07:15:20,126 (trainer:720) INFO: 75epoch:train:3801-4000batch: iter_time=1.870e-04, forward_time=0.132, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.538, loss=2.269, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.680e-04, train_time=0.880
[alab02] 2024-08-30 07:16:46,131 (trainer:720) INFO: 75epoch:train:4001-4200batch: iter_time=1.980e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.352, loss_ctc=4.346, loss=2.173, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.680e-04, train_time=0.860
[alab02] 2024-08-30 07:18:11,993 (trainer:720) INFO: 75epoch:train:4201-4400batch: iter_time=1.809e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.964, loss=1.982, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.680e-04, train_time=0.858
[alab02] 2024-08-30 07:19:38,933 (trainer:720) INFO: 75epoch:train:4401-4600batch: iter_time=1.727e-04, forward_time=0.131, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=4.393, loss=2.197, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.679e-04, train_time=0.869
[alab02] 2024-08-30 07:21:06,723 (trainer:720) INFO: 75epoch:train:4601-4800batch: iter_time=1.730e-04, forward_time=0.132, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=4.341, loss=2.171, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.679e-04, train_time=0.878
[alab02] 2024-08-30 07:22:32,530 (trainer:720) INFO: 75epoch:train:4801-5000batch: iter_time=1.789e-04, forward_time=0.129, uma_reduction=0.251, text_vs_uma=0.391, loss_ctc=4.685, loss=2.342, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.679e-04, train_time=0.858
[alab02] 2024-08-30 07:23:58,593 (trainer:720) INFO: 75epoch:train:5001-5200batch: iter_time=1.695e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.379, loss_ctc=4.514, loss=2.257, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.679e-04, train_time=0.860
[alab02] 2024-08-30 07:25:24,117 (trainer:720) INFO: 75epoch:train:5201-5400batch: iter_time=1.731e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=4.252, loss=2.126, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.678e-04, train_time=0.855
[alab02] 2024-08-30 07:26:49,993 (trainer:720) INFO: 75epoch:train:5401-5600batch: iter_time=1.832e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=4.458, loss=2.229, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.678e-04, train_time=0.859
[alab02] 2024-08-30 07:28:17,158 (trainer:720) INFO: 75epoch:train:5601-5800batch: iter_time=1.770e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=4.288, loss=2.144, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.678e-04, train_time=0.871
[alab02] 2024-08-30 07:29:42,390 (trainer:720) INFO: 75epoch:train:5801-6000batch: iter_time=1.715e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.348, loss_ctc=4.348, loss=2.174, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.677e-04, train_time=0.852
[alab02] 2024-08-30 07:31:08,724 (trainer:720) INFO: 75epoch:train:6001-6200batch: iter_time=1.634e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.338, loss_ctc=4.010, loss=2.005, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.677e-04, train_time=0.863
[alab02] 2024-08-30 07:32:35,215 (trainer:720) INFO: 75epoch:train:6201-6400batch: iter_time=1.534e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=4.295, loss=2.148, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.677e-04, train_time=0.865
[alab02] 2024-08-30 07:34:00,887 (trainer:720) INFO: 75epoch:train:6401-6600batch: iter_time=1.584e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=4.002, loss=2.001, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.676e-04, train_time=0.856
[alab02] 2024-08-30 07:35:28,822 (trainer:720) INFO: 75epoch:train:6601-6800batch: iter_time=1.630e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=4.531, loss=2.266, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.676e-04, train_time=0.879
[alab02] 2024-08-30 07:36:56,876 (trainer:720) INFO: 75epoch:train:6801-7000batch: iter_time=1.577e-04, forward_time=0.131, uma_reduction=0.288, text_vs_uma=0.335, loss_ctc=4.162, loss=2.081, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.676e-04, train_time=0.880
[alab02] 2024-08-30 07:38:10,838 (trainer:338) INFO: 75epoch results: [train] iter_time=2.299e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=4.252, loss=2.126, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.681e-04, train_time=0.866, time=51 minutes and 27.52 seconds, total_count=534450, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.302, text_vs_uma=0.360, loss_ctc=3.423, cer_ctc=0.094, cer=0.094, loss=3.423, time=6.03 seconds, total_count=1950, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.51 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 07:38:16,142 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 07:38:16,209 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/74epoch.pth
[alab02] 2024-08-30 07:38:16,209 (trainer:272) INFO: 76/150epoch started. Estimated time to finish: 2 days, 20 hours and 41 minutes
[alab02] 2024-08-30 07:39:44,013 (trainer:720) INFO: 76epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=4.290, loss=2.145, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.675e-04, train_time=0.878
[alab02] 2024-08-30 07:41:10,192 (trainer:720) INFO: 76epoch:train:201-400batch: iter_time=1.956e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=4.063, loss=2.031, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.675e-04, train_time=0.862
[alab02] 2024-08-30 07:42:37,315 (trainer:720) INFO: 76epoch:train:401-600batch: iter_time=1.751e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.358, loss_ctc=4.271, loss=2.135, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.675e-04, train_time=0.871
[alab02] 2024-08-30 07:44:02,812 (trainer:720) INFO: 76epoch:train:601-800batch: iter_time=1.720e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.356, loss_ctc=4.105, loss=2.053, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.674e-04, train_time=0.855
[alab02] 2024-08-30 07:45:29,141 (trainer:720) INFO: 76epoch:train:801-1000batch: iter_time=1.795e-04, forward_time=0.130, uma_reduction=0.286, text_vs_uma=0.340, loss_ctc=4.036, loss=2.018, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.674e-04, train_time=0.863
[alab02] 2024-08-30 07:46:57,114 (trainer:720) INFO: 76epoch:train:1001-1200batch: iter_time=1.732e-04, forward_time=0.133, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=4.190, loss=2.095, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.674e-04, train_time=0.879
[alab02] 2024-08-30 07:47:50,856 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 07:48:24,610 (trainer:720) INFO: 76epoch:train:1201-1400batch: iter_time=1.778e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.332, loss_ctc=3.699, loss=1.849, backward_time=0.188, optim_step_time=0.030, optim0_lr0=1.673e-04, train_time=0.875
[alab02] 2024-08-30 07:49:51,724 (trainer:720) INFO: 76epoch:train:1401-1600batch: iter_time=1.722e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.331, loss_ctc=3.926, loss=1.963, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.673e-04, train_time=0.871
[alab02] 2024-08-30 07:51:17,222 (trainer:720) INFO: 76epoch:train:1601-1800batch: iter_time=1.719e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=4.071, loss=2.036, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.673e-04, train_time=0.855
[alab02] 2024-08-30 07:52:42,883 (trainer:720) INFO: 76epoch:train:1801-2000batch: iter_time=1.739e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=4.319, loss=2.160, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.672e-04, train_time=0.856
[alab02] 2024-08-30 07:54:10,442 (trainer:720) INFO: 76epoch:train:2001-2200batch: iter_time=1.756e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=3.960, loss=1.980, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.672e-04, train_time=0.875
[alab02] 2024-08-30 07:55:37,173 (trainer:720) INFO: 76epoch:train:2201-2400batch: iter_time=1.589e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.367, loss_ctc=4.423, loss=2.211, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.672e-04, train_time=0.867
[alab02] 2024-08-30 07:57:03,546 (trainer:720) INFO: 76epoch:train:2401-2600batch: iter_time=1.922e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.821, loss=1.910, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.671e-04, train_time=0.863
[alab02] 2024-08-30 07:57:51,002 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 07:58:28,640 (trainer:720) INFO: 76epoch:train:2601-2800batch: iter_time=1.724e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=4.222, loss=2.111, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.671e-04, train_time=0.851
[alab02] 2024-08-30 07:59:54,536 (trainer:720) INFO: 76epoch:train:2801-3000batch: iter_time=2.151e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.356, loss_ctc=3.994, loss=1.997, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.671e-04, train_time=0.859
[alab02] 2024-08-30 08:01:20,661 (trainer:720) INFO: 76epoch:train:3001-3200batch: iter_time=1.811e-04, forward_time=0.130, uma_reduction=0.263, text_vs_uma=0.375, loss_ctc=4.242, loss=2.121, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.671e-04, train_time=0.861
[alab02] 2024-08-30 08:02:47,143 (trainer:720) INFO: 76epoch:train:3201-3400batch: iter_time=2.303e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.360, loss_ctc=4.232, loss=2.116, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.670e-04, train_time=0.865
[alab02] 2024-08-30 08:04:13,385 (trainer:720) INFO: 76epoch:train:3401-3600batch: iter_time=1.789e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=4.297, loss=2.148, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.670e-04, train_time=0.862
[alab02] 2024-08-30 08:05:41,702 (trainer:720) INFO: 76epoch:train:3601-3800batch: iter_time=1.727e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.853, loss=1.927, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.670e-04, train_time=0.883
[alab02] 2024-08-30 08:07:08,803 (trainer:720) INFO: 76epoch:train:3801-4000batch: iter_time=1.774e-04, forward_time=0.130, uma_reduction=0.260, text_vs_uma=0.369, loss_ctc=4.333, loss=2.166, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.669e-04, train_time=0.871
[alab02] 2024-08-30 08:08:33,549 (trainer:720) INFO: 76epoch:train:4001-4200batch: iter_time=1.728e-04, forward_time=0.126, uma_reduction=0.257, text_vs_uma=0.380, loss_ctc=4.481, loss=2.240, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.669e-04, train_time=0.847
[alab02] 2024-08-30 08:09:59,985 (trainer:720) INFO: 76epoch:train:4201-4400batch: iter_time=1.573e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.363, loss_ctc=4.326, loss=2.163, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.669e-04, train_time=0.864
[alab02] 2024-08-30 08:11:26,762 (trainer:720) INFO: 76epoch:train:4401-4600batch: iter_time=1.774e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.338, loss_ctc=4.151, loss=2.075, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.668e-04, train_time=0.868
[alab02] 2024-08-30 08:12:53,436 (trainer:720) INFO: 76epoch:train:4601-4800batch: iter_time=1.823e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.345, loss_ctc=4.039, loss=2.019, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.668e-04, train_time=0.867
[alab02] 2024-08-30 08:14:19,328 (trainer:720) INFO: 76epoch:train:4801-5000batch: iter_time=1.724e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=4.690, loss=2.345, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.668e-04, train_time=0.859
[alab02] 2024-08-30 08:15:46,773 (trainer:720) INFO: 76epoch:train:5001-5200batch: iter_time=1.682e-04, forward_time=0.132, uma_reduction=0.282, text_vs_uma=0.346, loss_ctc=4.121, loss=2.060, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.667e-04, train_time=0.874
[alab02] 2024-08-30 08:17:11,936 (trainer:720) INFO: 76epoch:train:5201-5400batch: iter_time=1.691e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=4.558, loss=2.279, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.667e-04, train_time=0.851
[alab02] 2024-08-30 08:18:39,386 (trainer:720) INFO: 76epoch:train:5401-5600batch: iter_time=1.771e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.355, loss_ctc=4.474, loss=2.237, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.667e-04, train_time=0.874
[alab02] 2024-08-30 08:20:06,478 (trainer:720) INFO: 76epoch:train:5601-5800batch: iter_time=1.626e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.373, loss_ctc=4.682, loss=2.341, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.667e-04, train_time=0.871
[alab02] 2024-08-30 08:21:33,820 (trainer:720) INFO: 76epoch:train:5801-6000batch: iter_time=1.652e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=4.078, loss=2.039, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.666e-04, train_time=0.873
[alab02] 2024-08-30 08:23:01,912 (trainer:720) INFO: 76epoch:train:6001-6200batch: iter_time=1.616e-04, forward_time=0.131, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=4.268, loss=2.134, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.666e-04, train_time=0.881
[alab02] 2024-08-30 08:24:29,359 (trainer:720) INFO: 76epoch:train:6201-6400batch: iter_time=1.711e-04, forward_time=0.131, uma_reduction=0.277, text_vs_uma=0.344, loss_ctc=4.216, loss=2.108, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.666e-04, train_time=0.874
[alab02] 2024-08-30 08:25:56,916 (trainer:720) INFO: 76epoch:train:6401-6600batch: iter_time=1.609e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=4.105, loss=2.053, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.665e-04, train_time=0.875
[alab02] 2024-08-30 08:27:23,929 (trainer:720) INFO: 76epoch:train:6601-6800batch: iter_time=1.711e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.346, loss_ctc=3.632, loss=1.816, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.665e-04, train_time=0.870
[alab02] 2024-08-30 08:28:50,701 (trainer:720) INFO: 76epoch:train:6801-7000batch: iter_time=1.672e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=4.628, loss=2.314, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.665e-04, train_time=0.868
[alab02] 2024-08-30 08:30:03,975 (trainer:338) INFO: 76epoch results: [train] iter_time=2.263e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=4.184, loss=2.092, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.670e-04, train_time=0.867, time=51 minutes and 28.9 seconds, total_count=541576, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.291, text_vs_uma=0.374, loss_ctc=3.445, cer_ctc=0.099, cer=0.099, loss=3.445, time=6.19 seconds, total_count=1976, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.67 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 08:30:09,288 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 08:30:09,343 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/75epoch.pth
[alab02] 2024-08-30 08:30:09,343 (trainer:272) INFO: 77/150epoch started. Estimated time to finish: 2 days, 19 hours and 43 minutes
[alab02] 2024-08-30 08:31:36,403 (trainer:720) INFO: 77epoch:train:1-200batch: iter_time=0.002, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.357, loss_ctc=4.302, loss=2.151, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.664e-04, train_time=0.870
[alab02] 2024-08-30 08:33:03,755 (trainer:720) INFO: 77epoch:train:201-400batch: iter_time=1.815e-04, forward_time=0.131, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=4.482, loss=2.241, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.664e-04, train_time=0.873
[alab02] 2024-08-30 08:34:30,267 (trainer:720) INFO: 77epoch:train:401-600batch: iter_time=1.731e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=4.298, loss=2.149, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.664e-04, train_time=0.865
[alab02] 2024-08-30 08:35:55,456 (trainer:720) INFO: 77epoch:train:601-800batch: iter_time=1.667e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.356, loss_ctc=4.510, loss=2.255, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.663e-04, train_time=0.852
[alab02] 2024-08-30 08:37:23,165 (trainer:720) INFO: 77epoch:train:801-1000batch: iter_time=1.765e-04, forward_time=0.130, uma_reduction=0.284, text_vs_uma=0.343, loss_ctc=4.384, loss=2.192, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.663e-04, train_time=0.877
[alab02] 2024-08-30 08:38:49,187 (trainer:720) INFO: 77epoch:train:1001-1200batch: iter_time=1.767e-04, forward_time=0.129, uma_reduction=0.283, text_vs_uma=0.344, loss_ctc=4.105, loss=2.052, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.663e-04, train_time=0.860
[alab02] 2024-08-30 08:40:15,035 (trainer:720) INFO: 77epoch:train:1201-1400batch: iter_time=1.677e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.352, loss_ctc=4.355, loss=2.178, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.662e-04, train_time=0.858
[alab02] 2024-08-30 08:41:42,759 (trainer:720) INFO: 77epoch:train:1401-1600batch: iter_time=1.698e-04, forward_time=0.131, uma_reduction=0.285, text_vs_uma=0.345, loss_ctc=4.031, loss=2.016, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.662e-04, train_time=0.877
[alab02] 2024-08-30 08:43:09,874 (trainer:720) INFO: 77epoch:train:1601-1800batch: iter_time=1.659e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=4.431, loss=2.216, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.662e-04, train_time=0.871
[alab02] 2024-08-30 08:44:35,988 (trainer:720) INFO: 77epoch:train:1801-2000batch: iter_time=1.697e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.358, loss_ctc=4.206, loss=2.103, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.661e-04, train_time=0.861
[alab02] 2024-08-30 08:46:03,406 (trainer:720) INFO: 77epoch:train:2001-2200batch: iter_time=1.694e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.377, loss_ctc=3.793, loss=1.896, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.661e-04, train_time=0.874
[alab02] 2024-08-30 08:47:30,196 (trainer:720) INFO: 77epoch:train:2201-2400batch: iter_time=1.592e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.372, loss_ctc=4.157, loss=2.078, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.661e-04, train_time=0.868
[alab02] 2024-08-30 08:48:54,867 (trainer:720) INFO: 77epoch:train:2401-2600batch: iter_time=1.635e-04, forward_time=0.125, uma_reduction=0.260, text_vs_uma=0.379, loss_ctc=4.719, loss=2.359, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.660e-04, train_time=0.846
[alab02] 2024-08-30 08:50:18,654 (trainer:720) INFO: 77epoch:train:2601-2800batch: iter_time=1.655e-04, forward_time=0.124, uma_reduction=0.286, text_vs_uma=0.339, loss_ctc=4.045, loss=2.023, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.660e-04, train_time=0.838
[alab02] 2024-08-30 08:51:46,180 (trainer:720) INFO: 77epoch:train:2801-3000batch: iter_time=1.573e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.351, loss_ctc=4.328, loss=2.164, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.660e-04, train_time=0.875
[alab02] 2024-08-30 08:53:11,764 (trainer:720) INFO: 77epoch:train:3001-3200batch: iter_time=1.648e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.341, loss_ctc=3.996, loss=1.998, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.660e-04, train_time=0.856
[alab02] 2024-08-30 08:54:38,239 (trainer:720) INFO: 77epoch:train:3201-3400batch: iter_time=1.551e-04, forward_time=0.129, uma_reduction=0.283, text_vs_uma=0.352, loss_ctc=4.527, loss=2.263, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.659e-04, train_time=0.865
[alab02] 2024-08-30 08:56:06,222 (trainer:720) INFO: 77epoch:train:3401-3600batch: iter_time=1.662e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=4.430, loss=2.215, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.659e-04, train_time=0.880
[alab02] 2024-08-30 08:56:56,533 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 08:57:32,433 (trainer:720) INFO: 77epoch:train:3601-3800batch: iter_time=1.630e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.369, loss_ctc=4.634, loss=2.317, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.659e-04, train_time=0.862
[alab02] 2024-08-30 08:58:59,335 (trainer:720) INFO: 77epoch:train:3801-4000batch: iter_time=1.746e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=4.450, loss=2.225, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.658e-04, train_time=0.869
[alab02] 2024-08-30 09:00:23,837 (trainer:720) INFO: 77epoch:train:4001-4200batch: iter_time=1.669e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=4.076, loss=2.038, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.658e-04, train_time=0.845
[alab02] 2024-08-30 09:01:51,200 (trainer:720) INFO: 77epoch:train:4201-4400batch: iter_time=1.630e-04, forward_time=0.130, uma_reduction=0.285, text_vs_uma=0.343, loss_ctc=4.174, loss=2.087, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.658e-04, train_time=0.873
[alab02] 2024-08-30 09:03:17,728 (trainer:720) INFO: 77epoch:train:4401-4600batch: iter_time=1.681e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=4.204, loss=2.102, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.657e-04, train_time=0.865
[alab02] 2024-08-30 09:04:44,258 (trainer:720) INFO: 77epoch:train:4601-4800batch: iter_time=1.630e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.356, loss_ctc=4.187, loss=2.093, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.657e-04, train_time=0.865
[alab02] 2024-08-30 09:06:11,287 (trainer:720) INFO: 77epoch:train:4801-5000batch: iter_time=1.522e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.370, loss_ctc=4.282, loss=2.141, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.657e-04, train_time=0.870
[alab02] 2024-08-30 09:07:37,239 (trainer:720) INFO: 77epoch:train:5001-5200batch: iter_time=1.684e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.344, loss_ctc=3.942, loss=1.971, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.657e-04, train_time=0.859
[alab02] 2024-08-30 09:09:05,150 (trainer:720) INFO: 77epoch:train:5201-5400batch: iter_time=1.697e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.349, loss_ctc=4.039, loss=2.020, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.656e-04, train_time=0.879
[alab02] 2024-08-30 09:10:32,666 (trainer:720) INFO: 77epoch:train:5401-5600batch: iter_time=1.726e-04, forward_time=0.130, uma_reduction=0.288, text_vs_uma=0.342, loss_ctc=4.176, loss=2.088, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.656e-04, train_time=0.875
[alab02] 2024-08-30 09:11:59,705 (trainer:720) INFO: 77epoch:train:5601-5800batch: iter_time=1.612e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.342, loss_ctc=4.190, loss=2.095, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.656e-04, train_time=0.870
[alab02] 2024-08-30 09:13:26,871 (trainer:720) INFO: 77epoch:train:5801-6000batch: iter_time=1.646e-04, forward_time=0.130, uma_reduction=0.290, text_vs_uma=0.334, loss_ctc=4.123, loss=2.061, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.655e-04, train_time=0.871
[alab02] 2024-08-30 09:13:34,231 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 09:14:54,505 (trainer:720) INFO: 77epoch:train:6001-6200batch: iter_time=1.689e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.351, loss_ctc=4.333, loss=2.166, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.655e-04, train_time=0.876
[alab02] 2024-08-30 09:16:22,402 (trainer:720) INFO: 77epoch:train:6201-6400batch: iter_time=1.678e-04, forward_time=0.132, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=4.326, loss=2.163, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.655e-04, train_time=0.879
[alab02] 2024-08-30 09:17:49,410 (trainer:720) INFO: 77epoch:train:6401-6600batch: iter_time=1.672e-04, forward_time=0.129, uma_reduction=0.259, text_vs_uma=0.370, loss_ctc=4.310, loss=2.155, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.654e-04, train_time=0.870
[alab02] 2024-08-30 09:19:14,867 (trainer:720) INFO: 77epoch:train:6601-6800batch: iter_time=1.591e-04, forward_time=0.127, uma_reduction=0.259, text_vs_uma=0.368, loss_ctc=4.389, loss=2.195, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.654e-04, train_time=0.854
[alab02] 2024-08-30 09:20:42,477 (trainer:720) INFO: 77epoch:train:6801-7000batch: iter_time=1.705e-04, forward_time=0.131, uma_reduction=0.254, text_vs_uma=0.378, loss_ctc=4.305, loss=2.152, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.654e-04, train_time=0.876
[alab02] 2024-08-30 09:21:57,544 (trainer:338) INFO: 77epoch results: [train] iter_time=2.119e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.356, loss_ctc=4.259, loss=2.129, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.659e-04, train_time=0.867, time=51 minutes and 28.73 seconds, total_count=548702, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.278, text_vs_uma=0.392, loss_ctc=3.397, cer_ctc=0.098, cer=0.098, loss=3.397, time=6.02 seconds, total_count=2002, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.45 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 09:22:02,681 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 09:22:02,744 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/76epoch.pth
[alab02] 2024-08-30 09:22:02,744 (trainer:272) INFO: 78/150epoch started. Estimated time to finish: 2 days, 18 hours and 46 minutes
[alab02] 2024-08-30 09:23:31,618 (trainer:720) INFO: 78epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.260, text_vs_uma=0.374, loss_ctc=4.439, loss=2.220, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.653e-04, train_time=0.888
[alab02] 2024-08-30 09:24:56,490 (trainer:720) INFO: 78epoch:train:201-400batch: iter_time=1.831e-04, forward_time=0.126, uma_reduction=0.256, text_vs_uma=0.376, loss_ctc=4.353, loss=2.176, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.653e-04, train_time=0.848
[alab02] 2024-08-30 09:26:23,529 (trainer:720) INFO: 78epoch:train:401-600batch: iter_time=1.864e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.376, loss_ctc=4.764, loss=2.382, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.653e-04, train_time=0.870
[alab02] 2024-08-30 09:27:48,067 (trainer:720) INFO: 78epoch:train:601-800batch: iter_time=1.810e-04, forward_time=0.126, uma_reduction=0.261, text_vs_uma=0.376, loss_ctc=4.564, loss=2.282, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.652e-04, train_time=0.845
[alab02] 2024-08-30 09:29:15,313 (trainer:720) INFO: 78epoch:train:801-1000batch: iter_time=1.932e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.367, loss_ctc=4.252, loss=2.126, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.652e-04, train_time=0.872
[alab02] 2024-08-30 09:30:41,570 (trainer:720) INFO: 78epoch:train:1001-1200batch: iter_time=1.827e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.376, loss_ctc=4.332, loss=2.166, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.652e-04, train_time=0.862
[alab02] 2024-08-30 09:32:09,334 (trainer:720) INFO: 78epoch:train:1201-1400batch: iter_time=1.679e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.370, loss_ctc=4.381, loss=2.191, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.652e-04, train_time=0.877
[alab02] 2024-08-30 09:33:35,527 (trainer:720) INFO: 78epoch:train:1401-1600batch: iter_time=2.199e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.375, loss_ctc=4.337, loss=2.169, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.651e-04, train_time=0.862
[alab02] 2024-08-30 09:35:04,038 (trainer:720) INFO: 78epoch:train:1601-1800batch: iter_time=1.653e-04, forward_time=0.132, uma_reduction=0.260, text_vs_uma=0.373, loss_ctc=4.181, loss=2.090, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.651e-04, train_time=0.885
[alab02] 2024-08-30 09:36:31,713 (trainer:720) INFO: 78epoch:train:1801-2000batch: iter_time=1.747e-04, forward_time=0.130, uma_reduction=0.259, text_vs_uma=0.383, loss_ctc=4.451, loss=2.226, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.651e-04, train_time=0.877
[alab02] 2024-08-30 09:37:57,686 (trainer:720) INFO: 78epoch:train:2001-2200batch: iter_time=1.803e-04, forward_time=0.128, uma_reduction=0.254, text_vs_uma=0.379, loss_ctc=4.466, loss=2.233, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.650e-04, train_time=0.860
[alab02] 2024-08-30 09:39:25,262 (trainer:720) INFO: 78epoch:train:2201-2400batch: iter_time=1.729e-04, forward_time=0.130, uma_reduction=0.257, text_vs_uma=0.370, loss_ctc=4.258, loss=2.129, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.650e-04, train_time=0.876
[alab02] 2024-08-30 09:40:51,556 (trainer:720) INFO: 78epoch:train:2401-2600batch: iter_time=1.684e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=4.299, loss=2.150, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.650e-04, train_time=0.863
[alab02] 2024-08-30 09:42:19,618 (trainer:720) INFO: 78epoch:train:2601-2800batch: iter_time=1.709e-04, forward_time=0.131, uma_reduction=0.259, text_vs_uma=0.375, loss_ctc=4.474, loss=2.237, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.649e-04, train_time=0.880
[alab02] 2024-08-30 09:43:46,525 (trainer:720) INFO: 78epoch:train:2801-3000batch: iter_time=1.681e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.354, loss_ctc=4.072, loss=2.036, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.649e-04, train_time=0.869
[alab02] 2024-08-30 09:45:11,731 (trainer:720) INFO: 78epoch:train:3001-3200batch: iter_time=1.728e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=4.034, loss=2.017, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.649e-04, train_time=0.852
[alab02] 2024-08-30 09:46:36,106 (trainer:720) INFO: 78epoch:train:3201-3400batch: iter_time=1.673e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=3.827, loss=1.914, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.649e-04, train_time=0.844
[alab02] 2024-08-30 09:48:03,283 (trainer:720) INFO: 78epoch:train:3401-3600batch: iter_time=1.842e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=4.048, loss=2.024, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.648e-04, train_time=0.872
[alab02] 2024-08-30 09:49:32,004 (trainer:720) INFO: 78epoch:train:3601-3800batch: iter_time=1.684e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.348, loss_ctc=3.938, loss=1.969, backward_time=0.188, optim_step_time=0.031, optim0_lr0=1.648e-04, train_time=0.887
[alab02] 2024-08-30 09:50:58,481 (trainer:720) INFO: 78epoch:train:3801-4000batch: iter_time=1.691e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=4.356, loss=2.178, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.648e-04, train_time=0.865
[alab02] 2024-08-30 09:52:27,781 (trainer:720) INFO: 78epoch:train:4001-4200batch: iter_time=1.645e-04, forward_time=0.133, uma_reduction=0.280, text_vs_uma=0.351, loss_ctc=3.927, loss=1.963, backward_time=0.191, optim_step_time=0.031, optim0_lr0=1.647e-04, train_time=0.893
[alab02] 2024-08-30 09:53:55,537 (trainer:720) INFO: 78epoch:train:4201-4400batch: iter_time=1.661e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.957, loss=1.979, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.647e-04, train_time=0.877
[alab02] 2024-08-30 09:55:22,469 (trainer:720) INFO: 78epoch:train:4401-4600batch: iter_time=1.674e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=4.268, loss=2.134, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.647e-04, train_time=0.869
[alab02] 2024-08-30 09:56:49,006 (trainer:720) INFO: 78epoch:train:4601-4800batch: iter_time=1.547e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.347, loss_ctc=4.170, loss=2.085, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.646e-04, train_time=0.865
[alab02] 2024-08-30 09:58:15,125 (trainer:720) INFO: 78epoch:train:4801-5000batch: iter_time=1.675e-04, forward_time=0.129, uma_reduction=0.284, text_vs_uma=0.335, loss_ctc=3.469, loss=1.734, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.646e-04, train_time=0.861
[alab02] 2024-08-30 09:59:41,363 (trainer:720) INFO: 78epoch:train:5001-5200batch: iter_time=1.655e-04, forward_time=0.128, uma_reduction=0.291, text_vs_uma=0.331, loss_ctc=4.171, loss=2.086, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.646e-04, train_time=0.862
[alab02] 2024-08-30 10:01:09,355 (trainer:720) INFO: 78epoch:train:5201-5400batch: iter_time=1.668e-04, forward_time=0.132, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=4.540, loss=2.270, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.646e-04, train_time=0.880
[alab02] 2024-08-30 10:02:35,049 (trainer:720) INFO: 78epoch:train:5401-5600batch: iter_time=1.640e-04, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.373, loss_ctc=4.342, loss=2.171, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.645e-04, train_time=0.857
[alab02] 2024-08-30 10:04:01,157 (trainer:720) INFO: 78epoch:train:5601-5800batch: iter_time=1.604e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.719, loss=1.860, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.645e-04, train_time=0.861
[alab02] 2024-08-30 10:05:28,775 (trainer:720) INFO: 78epoch:train:5801-6000batch: iter_time=1.713e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.354, loss_ctc=4.274, loss=2.137, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.645e-04, train_time=0.876
[alab02] 2024-08-30 10:06:53,461 (trainer:720) INFO: 78epoch:train:6001-6200batch: iter_time=1.611e-04, forward_time=0.127, uma_reduction=0.250, text_vs_uma=0.389, loss_ctc=4.075, loss=2.038, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.644e-04, train_time=0.847
[alab02] 2024-08-30 10:08:21,403 (trainer:720) INFO: 78epoch:train:6201-6400batch: iter_time=1.667e-04, forward_time=0.132, uma_reduction=0.255, text_vs_uma=0.381, loss_ctc=4.217, loss=2.108, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.644e-04, train_time=0.879
[alab02] 2024-08-30 10:09:47,915 (trainer:720) INFO: 78epoch:train:6401-6600batch: iter_time=1.697e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.356, loss_ctc=3.886, loss=1.943, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.644e-04, train_time=0.865
[alab02] 2024-08-30 10:11:15,548 (trainer:720) INFO: 78epoch:train:6601-6800batch: iter_time=1.659e-04, forward_time=0.131, uma_reduction=0.247, text_vs_uma=0.385, loss_ctc=4.050, loss=2.025, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.643e-04, train_time=0.876
[alab02] 2024-08-30 10:12:41,353 (trainer:720) INFO: 78epoch:train:6801-7000batch: iter_time=1.708e-04, forward_time=0.128, uma_reduction=0.249, text_vs_uma=0.396, loss_ctc=4.369, loss=2.184, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.643e-04, train_time=0.858
[alab02] 2024-08-30 10:13:57,387 (trainer:338) INFO: 78epoch results: [train] iter_time=2.135e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=4.195, loss=2.097, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.648e-04, train_time=0.868, time=51 minutes and 35.36 seconds, total_count=555828, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.274, text_vs_uma=0.395, loss_ctc=3.226, cer_ctc=0.092, cer=0.092, loss=3.226, time=6 seconds, total_count=2028, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.29 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 10:14:02,534 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 10:14:02,594 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/77epoch.pth
[alab02] 2024-08-30 10:14:02,594 (trainer:272) INFO: 79/150epoch started. Estimated time to finish: 2 days, 17 hours and 48 minutes
[alab02] 2024-08-30 10:15:31,051 (trainer:720) INFO: 79epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=4.044, loss=2.022, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.643e-04, train_time=0.884
[alab02] 2024-08-30 10:15:44,935 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 10:16:59,304 (trainer:720) INFO: 79epoch:train:201-400batch: iter_time=1.977e-04, forward_time=0.133, uma_reduction=0.262, text_vs_uma=0.362, loss_ctc=3.962, loss=1.981, backward_time=0.186, optim_step_time=0.032, optim0_lr0=1.642e-04, train_time=0.882
[alab02] 2024-08-30 10:18:26,790 (trainer:720) INFO: 79epoch:train:401-600batch: iter_time=2.006e-04, forward_time=0.132, uma_reduction=0.262, text_vs_uma=0.371, loss_ctc=4.038, loss=2.019, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.642e-04, train_time=0.875
[alab02] 2024-08-30 10:19:56,502 (trainer:720) INFO: 79epoch:train:601-800batch: iter_time=2.148e-04, forward_time=0.134, uma_reduction=0.263, text_vs_uma=0.366, loss_ctc=4.012, loss=2.006, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.642e-04, train_time=0.897
[alab02] 2024-08-30 10:21:23,226 (trainer:720) INFO: 79epoch:train:801-1000batch: iter_time=2.496e-04, forward_time=0.130, uma_reduction=0.254, text_vs_uma=0.378, loss_ctc=4.245, loss=2.123, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.642e-04, train_time=0.867
[alab02] 2024-08-30 10:22:50,514 (trainer:720) INFO: 79epoch:train:1001-1200batch: iter_time=2.096e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.730, loss=1.865, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.641e-04, train_time=0.873
[alab02] 2024-08-30 10:24:19,792 (trainer:720) INFO: 79epoch:train:1201-1400batch: iter_time=1.666e-04, forward_time=0.134, uma_reduction=0.265, text_vs_uma=0.362, loss_ctc=4.367, loss=2.184, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.641e-04, train_time=0.893
[alab02] 2024-08-30 10:25:44,752 (trainer:720) INFO: 79epoch:train:1401-1600batch: iter_time=1.616e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=4.253, loss=2.126, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.641e-04, train_time=0.849
[alab02] 2024-08-30 10:27:11,330 (trainer:720) INFO: 79epoch:train:1601-1800batch: iter_time=1.763e-04, forward_time=0.129, uma_reduction=0.258, text_vs_uma=0.378, loss_ctc=4.305, loss=2.153, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.640e-04, train_time=0.866
[alab02] 2024-08-30 10:28:36,117 (trainer:720) INFO: 79epoch:train:1801-2000batch: iter_time=1.579e-04, forward_time=0.126, uma_reduction=0.260, text_vs_uma=0.370, loss_ctc=4.167, loss=2.083, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.640e-04, train_time=0.848
[alab02] 2024-08-30 10:29:07,363 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 10:30:02,199 (trainer:720) INFO: 79epoch:train:2001-2200batch: iter_time=1.708e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.347, loss_ctc=3.689, loss=1.844, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.640e-04, train_time=0.861
[alab02] 2024-08-30 10:31:28,602 (trainer:720) INFO: 79epoch:train:2201-2400batch: iter_time=1.767e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=4.152, loss=2.076, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.639e-04, train_time=0.864
[alab02] 2024-08-30 10:32:53,044 (trainer:720) INFO: 79epoch:train:2401-2600batch: iter_time=1.790e-04, forward_time=0.126, uma_reduction=0.259, text_vs_uma=0.375, loss_ctc=4.036, loss=2.018, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.639e-04, train_time=0.844
[alab02] 2024-08-30 10:34:18,734 (trainer:720) INFO: 79epoch:train:2601-2800batch: iter_time=1.755e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.372, loss_ctc=4.213, loss=2.106, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.639e-04, train_time=0.857
[alab02] 2024-08-30 10:35:45,224 (trainer:720) INFO: 79epoch:train:2801-3000batch: iter_time=2.359e-04, forward_time=0.130, uma_reduction=0.256, text_vs_uma=0.378, loss_ctc=4.392, loss=2.196, backward_time=0.177, optim_step_time=0.037, optim0_lr0=1.639e-04, train_time=0.864
[alab02] 2024-08-30 10:37:12,045 (trainer:720) INFO: 79epoch:train:3001-3200batch: iter_time=1.956e-04, forward_time=0.130, uma_reduction=0.258, text_vs_uma=0.375, loss_ctc=4.004, loss=2.002, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.638e-04, train_time=0.868
[alab02] 2024-08-30 10:38:38,874 (trainer:720) INFO: 79epoch:train:3201-3400batch: iter_time=1.763e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.371, loss_ctc=4.204, loss=2.102, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.638e-04, train_time=0.868
[alab02] 2024-08-30 10:40:05,850 (trainer:720) INFO: 79epoch:train:3401-3600batch: iter_time=1.871e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.364, loss_ctc=4.191, loss=2.095, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.638e-04, train_time=0.870
[alab02] 2024-08-30 10:41:31,754 (trainer:720) INFO: 79epoch:train:3601-3800batch: iter_time=1.989e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=4.233, loss=2.117, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.637e-04, train_time=0.859
[alab02] 2024-08-30 10:42:58,918 (trainer:720) INFO: 79epoch:train:3801-4000batch: iter_time=1.983e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=4.264, loss=2.132, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.637e-04, train_time=0.871
[alab02] 2024-08-30 10:44:25,651 (trainer:720) INFO: 79epoch:train:4001-4200batch: iter_time=1.962e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=4.072, loss=2.036, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.637e-04, train_time=0.867
[alab02] 2024-08-30 10:45:52,492 (trainer:720) INFO: 79epoch:train:4201-4400batch: iter_time=1.914e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.977, loss=1.989, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.637e-04, train_time=0.868
[alab02] 2024-08-30 10:47:18,526 (trainer:720) INFO: 79epoch:train:4401-4600batch: iter_time=1.692e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.969, loss=1.984, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.636e-04, train_time=0.860
[alab02] 2024-08-30 10:48:45,858 (trainer:720) INFO: 79epoch:train:4601-4800batch: iter_time=1.703e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.259, loss=2.130, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.636e-04, train_time=0.873
[alab02] 2024-08-30 10:50:14,288 (trainer:720) INFO: 79epoch:train:4801-5000batch: iter_time=1.600e-04, forward_time=0.133, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=4.348, loss=2.174, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.636e-04, train_time=0.884
[alab02] 2024-08-30 10:51:38,489 (trainer:720) INFO: 79epoch:train:5001-5200batch: iter_time=1.811e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=4.014, loss=2.007, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.635e-04, train_time=0.842
[alab02] 2024-08-30 10:53:03,892 (trainer:720) INFO: 79epoch:train:5201-5400batch: iter_time=1.656e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=4.235, loss=2.118, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.635e-04, train_time=0.854
[alab02] 2024-08-30 10:54:30,558 (trainer:720) INFO: 79epoch:train:5401-5600batch: iter_time=1.664e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.806, loss=1.903, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.635e-04, train_time=0.866
[alab02] 2024-08-30 10:55:55,929 (trainer:720) INFO: 79epoch:train:5601-5800batch: iter_time=1.601e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.369, loss_ctc=4.523, loss=2.262, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.634e-04, train_time=0.853
[alab02] 2024-08-30 10:57:21,102 (trainer:720) INFO: 79epoch:train:5801-6000batch: iter_time=1.646e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=4.466, loss=2.233, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.634e-04, train_time=0.851
[alab02] 2024-08-30 10:58:47,137 (trainer:720) INFO: 79epoch:train:6001-6200batch: iter_time=1.519e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.370, loss_ctc=4.367, loss=2.183, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.634e-04, train_time=0.860
[alab02] 2024-08-30 11:00:14,179 (trainer:720) INFO: 79epoch:train:6201-6400batch: iter_time=1.650e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.352, loss_ctc=3.749, loss=1.874, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.634e-04, train_time=0.870
[alab02] 2024-08-30 11:01:40,304 (trainer:720) INFO: 79epoch:train:6401-6600batch: iter_time=1.603e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=4.233, loss=2.116, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.633e-04, train_time=0.861
[alab02] 2024-08-30 11:03:06,179 (trainer:720) INFO: 79epoch:train:6601-6800batch: iter_time=1.760e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.361, loss_ctc=4.095, loss=2.048, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.633e-04, train_time=0.859
[alab02] 2024-08-30 11:04:33,919 (trainer:720) INFO: 79epoch:train:6801-7000batch: iter_time=1.819e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=4.449, loss=2.224, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.633e-04, train_time=0.877
[alab02] 2024-08-30 11:05:48,556 (trainer:338) INFO: 79epoch results: [train] iter_time=2.357e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=4.148, loss=2.074, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.638e-04, train_time=0.866, time=51 minutes and 26.55 seconds, total_count=562954, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.274, text_vs_uma=0.397, loss_ctc=3.403, cer_ctc=0.088, cer=0.088, loss=3.403, time=6.14 seconds, total_count=2054, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.27 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 11:05:53,993 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 11:05:54,078 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/68epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/78epoch.pth
[alab02] 2024-08-30 11:05:54,078 (trainer:272) INFO: 80/150epoch started. Estimated time to finish: 2 days, 16 hours and 51 minutes
[alab02] 2024-08-30 11:07:24,167 (trainer:720) INFO: 80epoch:train:1-200batch: iter_time=0.002, forward_time=0.136, uma_reduction=0.271, text_vs_uma=0.346, loss_ctc=4.074, loss=2.037, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.632e-04, train_time=0.900
[alab02] 2024-08-30 11:08:52,829 (trainer:720) INFO: 80epoch:train:201-400batch: iter_time=2.235e-04, forward_time=0.133, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.820, loss=1.910, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.632e-04, train_time=0.886
[alab02] 2024-08-30 11:10:20,221 (trainer:720) INFO: 80epoch:train:401-600batch: iter_time=2.142e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=4.406, loss=2.203, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.632e-04, train_time=0.874
[alab02] 2024-08-30 11:11:48,179 (trainer:720) INFO: 80epoch:train:601-800batch: iter_time=2.010e-04, forward_time=0.132, uma_reduction=0.279, text_vs_uma=0.351, loss_ctc=3.855, loss=1.928, backward_time=0.186, optim_step_time=0.032, optim0_lr0=1.631e-04, train_time=0.879
[alab02] 2024-08-30 11:13:16,453 (trainer:720) INFO: 80epoch:train:801-1000batch: iter_time=2.069e-04, forward_time=0.133, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=3.893, loss=1.946, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.631e-04, train_time=0.882
[alab02] 2024-08-30 11:14:45,439 (trainer:720) INFO: 80epoch:train:1001-1200batch: iter_time=1.829e-04, forward_time=0.133, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=4.179, loss=2.089, backward_time=0.187, optim_step_time=0.032, optim0_lr0=1.631e-04, train_time=0.890
[alab02] 2024-08-30 11:16:10,274 (trainer:720) INFO: 80epoch:train:1201-1400batch: iter_time=1.695e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.352, loss_ctc=4.082, loss=2.041, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.631e-04, train_time=0.848
[alab02] 2024-08-30 11:17:34,501 (trainer:720) INFO: 80epoch:train:1401-1600batch: iter_time=1.660e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.370, loss_ctc=4.350, loss=2.175, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.630e-04, train_time=0.842
[alab02] 2024-08-30 11:19:00,208 (trainer:720) INFO: 80epoch:train:1601-1800batch: iter_time=1.774e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.345, loss_ctc=3.836, loss=1.918, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.630e-04, train_time=0.857
[alab02] 2024-08-30 11:20:24,963 (trainer:720) INFO: 80epoch:train:1801-2000batch: iter_time=1.641e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.369, loss_ctc=4.243, loss=2.121, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.630e-04, train_time=0.847
[alab02] 2024-08-30 11:21:51,040 (trainer:720) INFO: 80epoch:train:2001-2200batch: iter_time=1.623e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.383, loss_ctc=4.325, loss=2.163, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.629e-04, train_time=0.861
[alab02] 2024-08-30 11:23:16,810 (trainer:720) INFO: 80epoch:train:2201-2400batch: iter_time=1.528e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=4.221, loss=2.111, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.629e-04, train_time=0.857
[alab02] 2024-08-30 11:24:44,276 (trainer:720) INFO: 80epoch:train:2401-2600batch: iter_time=1.556e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=4.138, loss=2.069, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.629e-04, train_time=0.874
[alab02] 2024-08-30 11:26:10,049 (trainer:720) INFO: 80epoch:train:2601-2800batch: iter_time=1.582e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.357, loss_ctc=4.505, loss=2.252, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.629e-04, train_time=0.858
[alab02] 2024-08-30 11:27:36,498 (trainer:720) INFO: 80epoch:train:2801-3000batch: iter_time=1.669e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=4.124, loss=2.062, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.628e-04, train_time=0.864
[alab02] 2024-08-30 11:29:02,019 (trainer:720) INFO: 80epoch:train:3001-3200batch: iter_time=1.569e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.358, loss_ctc=4.302, loss=2.151, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.628e-04, train_time=0.855
[alab02] 2024-08-30 11:29:10,772 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 11:30:27,999 (trainer:720) INFO: 80epoch:train:3201-3400batch: iter_time=1.710e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=4.219, loss=2.109, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.628e-04, train_time=0.860
[alab02] 2024-08-30 11:31:54,581 (trainer:720) INFO: 80epoch:train:3401-3600batch: iter_time=1.701e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=4.133, loss=2.067, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.627e-04, train_time=0.866
[alab02] 2024-08-30 11:33:17,987 (trainer:720) INFO: 80epoch:train:3601-3800batch: iter_time=1.711e-04, forward_time=0.123, uma_reduction=0.259, text_vs_uma=0.379, loss_ctc=4.548, loss=2.274, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.627e-04, train_time=0.834
[alab02] 2024-08-30 11:34:46,407 (trainer:720) INFO: 80epoch:train:3801-4000batch: iter_time=1.619e-04, forward_time=0.131, uma_reduction=0.263, text_vs_uma=0.362, loss_ctc=4.194, loss=2.097, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.627e-04, train_time=0.884
[alab02] 2024-08-30 11:36:11,986 (trainer:720) INFO: 80epoch:train:4001-4200batch: iter_time=1.700e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.351, loss_ctc=3.953, loss=1.977, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.627e-04, train_time=0.856
[alab02] 2024-08-30 11:37:40,452 (trainer:720) INFO: 80epoch:train:4201-4400batch: iter_time=1.688e-04, forward_time=0.131, uma_reduction=0.261, text_vs_uma=0.370, loss_ctc=4.334, loss=2.167, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.626e-04, train_time=0.884
[alab02] 2024-08-30 11:39:08,079 (trainer:720) INFO: 80epoch:train:4401-4600batch: iter_time=1.750e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.360, loss_ctc=4.152, loss=2.076, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.626e-04, train_time=0.876
[alab02] 2024-08-30 11:39:13,189 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 11:40:32,635 (trainer:720) INFO: 80epoch:train:4601-4800batch: iter_time=1.685e-04, forward_time=0.126, uma_reduction=0.260, text_vs_uma=0.366, loss_ctc=3.769, loss=1.884, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.626e-04, train_time=0.845
[alab02] 2024-08-30 11:41:58,967 (trainer:720) INFO: 80epoch:train:4801-5000batch: iter_time=1.656e-04, forward_time=0.128, uma_reduction=0.253, text_vs_uma=0.382, loss_ctc=4.695, loss=2.348, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.625e-04, train_time=0.863
[alab02] 2024-08-30 11:43:26,211 (trainer:720) INFO: 80epoch:train:5001-5200batch: iter_time=1.693e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.777, loss=1.889, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.625e-04, train_time=0.872
[alab02] 2024-08-30 11:44:54,113 (trainer:720) INFO: 80epoch:train:5201-5400batch: iter_time=1.702e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=4.109, loss=2.055, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.625e-04, train_time=0.879
[alab02] 2024-08-30 11:46:19,553 (trainer:720) INFO: 80epoch:train:5401-5600batch: iter_time=1.606e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.373, loss_ctc=4.108, loss=2.054, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.625e-04, train_time=0.854
[alab02] 2024-08-30 11:47:45,380 (trainer:720) INFO: 80epoch:train:5601-5800batch: iter_time=1.647e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=4.027, loss=2.014, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.624e-04, train_time=0.858
[alab02] 2024-08-30 11:49:08,509 (trainer:720) INFO: 80epoch:train:5801-6000batch: iter_time=1.648e-04, forward_time=0.123, uma_reduction=0.266, text_vs_uma=0.361, loss_ctc=3.964, loss=1.982, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.624e-04, train_time=0.831
[alab02] 2024-08-30 11:50:34,504 (trainer:720) INFO: 80epoch:train:6001-6200batch: iter_time=1.704e-04, forward_time=0.128, uma_reduction=0.253, text_vs_uma=0.381, loss_ctc=4.332, loss=2.166, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.624e-04, train_time=0.860
[alab02] 2024-08-30 11:51:59,424 (trainer:720) INFO: 80epoch:train:6201-6400batch: iter_time=1.709e-04, forward_time=0.126, uma_reduction=0.256, text_vs_uma=0.376, loss_ctc=4.205, loss=2.103, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.623e-04, train_time=0.849
[alab02] 2024-08-30 11:53:26,083 (trainer:720) INFO: 80epoch:train:6401-6600batch: iter_time=1.603e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=4.159, loss=2.080, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.623e-04, train_time=0.866
[alab02] 2024-08-30 11:54:53,590 (trainer:720) INFO: 80epoch:train:6601-6800batch: iter_time=1.592e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.372, loss_ctc=4.525, loss=2.263, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.623e-04, train_time=0.875
[alab02] 2024-08-30 11:56:20,985 (trainer:720) INFO: 80epoch:train:6801-7000batch: iter_time=1.837e-04, forward_time=0.130, uma_reduction=0.253, text_vs_uma=0.372, loss_ctc=4.184, loss=2.092, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.623e-04, train_time=0.874
[alab02] 2024-08-30 11:57:35,011 (trainer:338) INFO: 80epoch results: [train] iter_time=2.266e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.362, loss_ctc=4.160, loss=2.080, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.627e-04, train_time=0.864, time=51 minutes and 21.58 seconds, total_count=570080, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.269, text_vs_uma=0.404, loss_ctc=3.324, cer_ctc=0.090, cer=0.090, loss=3.324, time=5.97 seconds, total_count=2080, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.38 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 11:57:40,260 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 11:57:40,260 (trainer:272) INFO: 81/150epoch started. Estimated time to finish: 2 days, 15 hours and 53 minutes
[alab02] 2024-08-30 11:59:07,069 (trainer:720) INFO: 81epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.362, loss_ctc=4.349, loss=2.175, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.622e-04, train_time=0.868
[alab02] 2024-08-30 12:00:33,070 (trainer:720) INFO: 81epoch:train:201-400batch: iter_time=2.173e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=4.057, loss=2.028, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.622e-04, train_time=0.860
[alab02] 2024-08-30 12:02:01,088 (trainer:720) INFO: 81epoch:train:401-600batch: iter_time=2.084e-04, forward_time=0.132, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=4.334, loss=2.167, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.621e-04, train_time=0.880
[alab02] 2024-08-30 12:03:27,999 (trainer:720) INFO: 81epoch:train:601-800batch: iter_time=2.133e-04, forward_time=0.130, uma_reduction=0.259, text_vs_uma=0.375, loss_ctc=4.157, loss=2.079, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.621e-04, train_time=0.869
[alab02] 2024-08-30 12:04:52,569 (trainer:720) INFO: 81epoch:train:801-1000batch: iter_time=1.924e-04, forward_time=0.126, uma_reduction=0.252, text_vs_uma=0.374, loss_ctc=4.199, loss=2.100, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.621e-04, train_time=0.845
[alab02] 2024-08-30 12:06:17,609 (trainer:720) INFO: 81epoch:train:1001-1200batch: iter_time=1.808e-04, forward_time=0.125, uma_reduction=0.253, text_vs_uma=0.385, loss_ctc=4.182, loss=2.091, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.621e-04, train_time=0.850
[alab02] 2024-08-30 12:07:43,943 (trainer:720) INFO: 81epoch:train:1201-1400batch: iter_time=1.863e-04, forward_time=0.128, uma_reduction=0.254, text_vs_uma=0.387, loss_ctc=4.424, loss=2.212, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.620e-04, train_time=0.863
[alab02] 2024-08-30 12:09:06,600 (trainer:720) INFO: 81epoch:train:1401-1600batch: iter_time=1.789e-04, forward_time=0.122, uma_reduction=0.254, text_vs_uma=0.390, loss_ctc=4.257, loss=2.128, backward_time=0.168, optim_step_time=0.030, optim0_lr0=1.620e-04, train_time=0.826
[alab02] 2024-08-30 12:09:18,892 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 12:10:32,698 (trainer:720) INFO: 81epoch:train:1601-1800batch: iter_time=1.699e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.360, loss_ctc=3.982, loss=1.991, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.620e-04, train_time=0.861
[alab02] 2024-08-30 12:12:00,772 (trainer:720) INFO: 81epoch:train:1801-2000batch: iter_time=1.734e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.372, loss_ctc=4.261, loss=2.130, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.619e-04, train_time=0.881
[alab02] 2024-08-30 12:13:27,114 (trainer:720) INFO: 81epoch:train:2001-2200batch: iter_time=1.849e-04, forward_time=0.128, uma_reduction=0.247, text_vs_uma=0.393, loss_ctc=4.636, loss=2.318, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.619e-04, train_time=0.863
[alab02] 2024-08-30 12:14:55,270 (trainer:720) INFO: 81epoch:train:2201-2400batch: iter_time=1.754e-04, forward_time=0.131, uma_reduction=0.248, text_vs_uma=0.400, loss_ctc=4.419, loss=2.210, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.619e-04, train_time=0.881
[alab02] 2024-08-30 12:16:21,947 (trainer:720) INFO: 81epoch:train:2401-2600batch: iter_time=1.817e-04, forward_time=0.128, uma_reduction=0.247, text_vs_uma=0.399, loss_ctc=4.602, loss=2.301, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.619e-04, train_time=0.867
[alab02] 2024-08-30 12:17:47,233 (trainer:720) INFO: 81epoch:train:2601-2800batch: iter_time=1.736e-04, forward_time=0.127, uma_reduction=0.251, text_vs_uma=0.379, loss_ctc=4.026, loss=2.013, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.618e-04, train_time=0.853
[alab02] 2024-08-30 12:19:12,224 (trainer:720) INFO: 81epoch:train:2801-3000batch: iter_time=1.564e-04, forward_time=0.125, uma_reduction=0.255, text_vs_uma=0.377, loss_ctc=4.382, loss=2.191, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.618e-04, train_time=0.850
[alab02] 2024-08-30 12:20:35,745 (trainer:720) INFO: 81epoch:train:3001-3200batch: iter_time=1.564e-04, forward_time=0.124, uma_reduction=0.254, text_vs_uma=0.382, loss_ctc=4.150, loss=2.075, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.618e-04, train_time=0.835
[alab02] 2024-08-30 12:22:02,573 (trainer:720) INFO: 81epoch:train:3201-3400batch: iter_time=1.649e-04, forward_time=0.128, uma_reduction=0.254, text_vs_uma=0.382, loss_ctc=4.394, loss=2.197, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.618e-04, train_time=0.868
[alab02] 2024-08-30 12:23:27,977 (trainer:720) INFO: 81epoch:train:3401-3600batch: iter_time=1.638e-04, forward_time=0.126, uma_reduction=0.260, text_vs_uma=0.365, loss_ctc=4.329, loss=2.165, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.617e-04, train_time=0.854
[alab02] 2024-08-30 12:24:52,794 (trainer:720) INFO: 81epoch:train:3601-3800batch: iter_time=1.599e-04, forward_time=0.125, uma_reduction=0.258, text_vs_uma=0.383, loss_ctc=4.357, loss=2.179, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.617e-04, train_time=0.848
[alab02] 2024-08-30 12:26:18,696 (trainer:720) INFO: 81epoch:train:3801-4000batch: iter_time=1.722e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.376, loss_ctc=4.181, loss=2.091, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.617e-04, train_time=0.859
[alab02] 2024-08-30 12:27:46,224 (trainer:720) INFO: 81epoch:train:4001-4200batch: iter_time=1.586e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=4.087, loss=2.044, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.616e-04, train_time=0.875
[alab02] 2024-08-30 12:29:10,198 (trainer:720) INFO: 81epoch:train:4201-4400batch: iter_time=1.782e-04, forward_time=0.124, uma_reduction=0.263, text_vs_uma=0.366, loss_ctc=4.069, loss=2.034, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.616e-04, train_time=0.840
[alab02] 2024-08-30 12:30:36,907 (trainer:720) INFO: 81epoch:train:4401-4600batch: iter_time=1.630e-04, forward_time=0.129, uma_reduction=0.261, text_vs_uma=0.372, loss_ctc=4.371, loss=2.186, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.616e-04, train_time=0.867
[alab02] 2024-08-30 12:32:02,224 (trainer:720) INFO: 81epoch:train:4601-4800batch: iter_time=1.711e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=4.167, loss=2.083, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.616e-04, train_time=0.853
[alab02] 2024-08-30 12:33:28,261 (trainer:720) INFO: 81epoch:train:4801-5000batch: iter_time=1.625e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.379, loss_ctc=4.571, loss=2.286, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.615e-04, train_time=0.860
[alab02] 2024-08-30 12:34:55,366 (trainer:720) INFO: 81epoch:train:5001-5200batch: iter_time=1.626e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.366, loss_ctc=4.156, loss=2.078, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.615e-04, train_time=0.871
[alab02] 2024-08-30 12:36:20,215 (trainer:720) INFO: 81epoch:train:5201-5400batch: iter_time=1.535e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.354, loss_ctc=4.249, loss=2.125, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.615e-04, train_time=0.848
[alab02] 2024-08-30 12:37:46,655 (trainer:720) INFO: 81epoch:train:5401-5600batch: iter_time=1.515e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=4.496, loss=2.248, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.614e-04, train_time=0.864
[alab02] 2024-08-30 12:39:12,263 (trainer:720) INFO: 81epoch:train:5601-5800batch: iter_time=1.749e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.342, loss_ctc=4.134, loss=2.067, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.614e-04, train_time=0.856
[alab02] 2024-08-30 12:40:39,071 (trainer:720) INFO: 81epoch:train:5801-6000batch: iter_time=1.622e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.963, loss=1.982, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.614e-04, train_time=0.868
[alab02] 2024-08-30 12:42:03,692 (trainer:720) INFO: 81epoch:train:6001-6200batch: iter_time=1.579e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.194, loss=2.097, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.614e-04, train_time=0.846
[alab02] 2024-08-30 12:43:30,666 (trainer:720) INFO: 81epoch:train:6201-6400batch: iter_time=1.648e-04, forward_time=0.129, uma_reduction=0.286, text_vs_uma=0.341, loss_ctc=4.237, loss=2.118, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.613e-04, train_time=0.869
[alab02] 2024-08-30 12:44:59,191 (trainer:720) INFO: 81epoch:train:6401-6600batch: iter_time=1.699e-04, forward_time=0.131, uma_reduction=0.292, text_vs_uma=0.328, loss_ctc=4.052, loss=2.026, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.613e-04, train_time=0.885
[alab02] 2024-08-30 12:46:23,345 (trainer:720) INFO: 81epoch:train:6601-6800batch: iter_time=1.681e-04, forward_time=0.125, uma_reduction=0.289, text_vs_uma=0.339, loss_ctc=4.171, loss=2.086, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.613e-04, train_time=0.841
[alab02] 2024-08-30 12:47:50,027 (trainer:720) INFO: 81epoch:train:6801-7000batch: iter_time=1.728e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=3.910, loss=1.955, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.612e-04, train_time=0.867
[alab02] 2024-08-30 12:49:04,923 (trainer:338) INFO: 81epoch results: [train] iter_time=2.204e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.368, loss_ctc=4.240, loss=2.120, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.617e-04, train_time=0.860, time=51 minutes and 4.92 seconds, total_count=577206, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.290, text_vs_uma=0.375, loss_ctc=3.120, cer_ctc=0.087, cer=0.087, loss=3.120, time=5.87 seconds, total_count=2106, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.87 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 12:49:09,981 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 12:49:10,044 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/58epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/80epoch.pth
[alab02] 2024-08-30 12:49:10,044 (trainer:272) INFO: 82/150epoch started. Estimated time to finish: 2 days, 14 hours and 56 minutes
[alab02] 2024-08-30 12:50:37,405 (trainer:720) INFO: 82epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=4.184, loss=2.092, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.612e-04, train_time=0.873
[alab02] 2024-08-30 12:52:03,298 (trainer:720) INFO: 82epoch:train:201-400batch: iter_time=1.913e-04, forward_time=0.127, uma_reduction=0.263, text_vs_uma=0.362, loss_ctc=4.140, loss=2.070, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.612e-04, train_time=0.859
[alab02] 2024-08-30 12:53:28,180 (trainer:720) INFO: 82epoch:train:401-600batch: iter_time=1.741e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.344, loss_ctc=4.081, loss=2.040, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.611e-04, train_time=0.849
[alab02] 2024-08-30 12:54:54,787 (trainer:720) INFO: 82epoch:train:601-800batch: iter_time=1.734e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.899, loss=1.949, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.611e-04, train_time=0.866
[alab02] 2024-08-30 12:56:22,195 (trainer:720) INFO: 82epoch:train:801-1000batch: iter_time=1.750e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.356, loss_ctc=4.353, loss=2.177, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.611e-04, train_time=0.874
[alab02] 2024-08-30 12:57:48,416 (trainer:720) INFO: 82epoch:train:1001-1200batch: iter_time=1.781e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.354, loss_ctc=3.934, loss=1.967, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.611e-04, train_time=0.862
[alab02] 2024-08-30 12:59:14,875 (trainer:720) INFO: 82epoch:train:1201-1400batch: iter_time=1.626e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.374, loss_ctc=3.974, loss=1.987, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.610e-04, train_time=0.864
[alab02] 2024-08-30 13:00:42,651 (trainer:720) INFO: 82epoch:train:1401-1600batch: iter_time=1.713e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.356, loss_ctc=3.970, loss=1.985, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.610e-04, train_time=0.878
[alab02] 2024-08-30 13:02:00,669 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 13:02:09,235 (trainer:720) INFO: 82epoch:train:1601-1800batch: iter_time=1.754e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=4.150, loss=2.075, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.610e-04, train_time=0.866
[alab02] 2024-08-30 13:03:34,853 (trainer:720) INFO: 82epoch:train:1801-2000batch: iter_time=1.794e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=4.457, loss=2.229, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.609e-04, train_time=0.856
[alab02] 2024-08-30 13:05:01,337 (trainer:720) INFO: 82epoch:train:2001-2200batch: iter_time=1.612e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.360, loss_ctc=3.816, loss=1.908, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.609e-04, train_time=0.865
[alab02] 2024-08-30 13:06:26,669 (trainer:720) INFO: 82epoch:train:2201-2400batch: iter_time=1.780e-04, forward_time=0.127, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=4.349, loss=2.174, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.609e-04, train_time=0.853
[alab02] 2024-08-30 13:07:55,884 (trainer:720) INFO: 82epoch:train:2401-2600batch: iter_time=1.644e-04, forward_time=0.133, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=4.408, loss=2.204, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.609e-04, train_time=0.892
[alab02] 2024-08-30 13:09:24,674 (trainer:720) INFO: 82epoch:train:2601-2800batch: iter_time=1.676e-04, forward_time=0.132, uma_reduction=0.280, text_vs_uma=0.341, loss_ctc=3.689, loss=1.845, backward_time=0.192, optim_step_time=0.030, optim0_lr0=1.608e-04, train_time=0.888
[alab02] 2024-08-30 13:10:51,219 (trainer:720) INFO: 82epoch:train:2801-3000batch: iter_time=1.673e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.896, loss=1.948, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.608e-04, train_time=0.865
[alab02] 2024-08-30 13:12:16,396 (trainer:720) INFO: 82epoch:train:3001-3200batch: iter_time=1.663e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.371, loss_ctc=4.170, loss=2.085, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.608e-04, train_time=0.852
[alab02] 2024-08-30 13:13:42,751 (trainer:720) INFO: 82epoch:train:3201-3400batch: iter_time=1.651e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.369, loss_ctc=3.645, loss=1.822, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.608e-04, train_time=0.863
[alab02] 2024-08-30 13:15:07,948 (trainer:720) INFO: 82epoch:train:3401-3600batch: iter_time=1.598e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.370, loss_ctc=4.273, loss=2.137, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.607e-04, train_time=0.852
[alab02] 2024-08-30 13:16:32,822 (trainer:720) INFO: 82epoch:train:3601-3800batch: iter_time=1.662e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=4.094, loss=2.047, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.607e-04, train_time=0.849
[alab02] 2024-08-30 13:17:59,592 (trainer:720) INFO: 82epoch:train:3801-4000batch: iter_time=1.698e-04, forward_time=0.129, uma_reduction=0.262, text_vs_uma=0.369, loss_ctc=4.117, loss=2.058, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.607e-04, train_time=0.867
[alab02] 2024-08-30 13:19:27,508 (trainer:720) INFO: 82epoch:train:4001-4200batch: iter_time=1.690e-04, forward_time=0.131, uma_reduction=0.263, text_vs_uma=0.364, loss_ctc=3.964, loss=1.982, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.606e-04, train_time=0.879
[alab02] 2024-08-30 13:20:54,044 (trainer:720) INFO: 82epoch:train:4201-4400batch: iter_time=1.605e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.980, loss=1.990, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.606e-04, train_time=0.865
[alab02] 2024-08-30 13:22:19,467 (trainer:720) INFO: 82epoch:train:4401-4600batch: iter_time=1.558e-04, forward_time=0.126, uma_reduction=0.258, text_vs_uma=0.375, loss_ctc=3.951, loss=1.976, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.606e-04, train_time=0.854
[alab02] 2024-08-30 13:23:46,649 (trainer:720) INFO: 82epoch:train:4601-4800batch: iter_time=1.699e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.368, loss_ctc=3.970, loss=1.985, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.606e-04, train_time=0.872
[alab02] 2024-08-30 13:25:12,632 (trainer:720) INFO: 82epoch:train:4801-5000batch: iter_time=1.648e-04, forward_time=0.127, uma_reduction=0.244, text_vs_uma=0.394, loss_ctc=4.452, loss=2.226, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.605e-04, train_time=0.860
[alab02] 2024-08-30 13:26:39,355 (trainer:720) INFO: 82epoch:train:5001-5200batch: iter_time=1.619e-04, forward_time=0.128, uma_reduction=0.250, text_vs_uma=0.390, loss_ctc=4.417, loss=2.209, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.605e-04, train_time=0.867
[alab02] 2024-08-30 13:28:05,175 (trainer:720) INFO: 82epoch:train:5201-5400batch: iter_time=1.548e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.365, loss_ctc=4.017, loss=2.008, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.605e-04, train_time=0.858
[alab02] 2024-08-30 13:29:32,098 (trainer:720) INFO: 82epoch:train:5401-5600batch: iter_time=1.578e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.374, loss_ctc=4.355, loss=2.178, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.605e-04, train_time=0.869
[alab02] 2024-08-30 13:30:57,887 (trainer:720) INFO: 82epoch:train:5601-5800batch: iter_time=1.707e-04, forward_time=0.127, uma_reduction=0.253, text_vs_uma=0.384, loss_ctc=4.372, loss=2.186, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.604e-04, train_time=0.858
[alab02] 2024-08-30 13:32:25,029 (trainer:720) INFO: 82epoch:train:5801-6000batch: iter_time=1.674e-04, forward_time=0.129, uma_reduction=0.248, text_vs_uma=0.393, loss_ctc=4.432, loss=2.216, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.604e-04, train_time=0.871
[alab02] 2024-08-30 13:33:50,883 (trainer:720) INFO: 82epoch:train:6001-6200batch: iter_time=1.984e-04, forward_time=0.128, uma_reduction=0.249, text_vs_uma=0.386, loss_ctc=3.964, loss=1.982, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.604e-04, train_time=0.858
[alab02] 2024-08-30 13:35:16,373 (trainer:720) INFO: 82epoch:train:6201-6400batch: iter_time=1.536e-04, forward_time=0.128, uma_reduction=0.251, text_vs_uma=0.382, loss_ctc=3.780, loss=1.890, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.603e-04, train_time=0.855
[alab02] 2024-08-30 13:36:43,592 (trainer:720) INFO: 82epoch:train:6401-6600batch: iter_time=1.634e-04, forward_time=0.129, uma_reduction=0.245, text_vs_uma=0.403, loss_ctc=4.118, loss=2.059, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.603e-04, train_time=0.872
[alab02] 2024-08-30 13:38:10,162 (trainer:720) INFO: 82epoch:train:6601-6800batch: iter_time=1.816e-04, forward_time=0.129, uma_reduction=0.247, text_vs_uma=0.381, loss_ctc=4.446, loss=2.223, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.603e-04, train_time=0.865
[alab02] 2024-08-30 13:39:37,608 (trainer:720) INFO: 82epoch:train:6801-7000batch: iter_time=1.723e-04, forward_time=0.130, uma_reduction=0.260, text_vs_uma=0.368, loss_ctc=4.015, loss=2.008, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.603e-04, train_time=0.874
[alab02] 2024-08-30 13:40:51,632 (trainer:338) INFO: 82epoch results: [train] iter_time=2.264e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.367, loss_ctc=4.101, loss=2.051, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.607e-04, train_time=0.865, time=51 minutes and 22.55 seconds, total_count=584332, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.266, text_vs_uma=0.410, loss_ctc=3.352, cer_ctc=0.105, cer=0.105, loss=3.352, time=6.08 seconds, total_count=2132, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.96 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 13:40:56,877 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 13:40:56,878 (trainer:272) INFO: 83/150epoch started. Estimated time to finish: 2 days, 13 hours and 58 minutes
[alab02] 2024-08-30 13:42:24,132 (trainer:720) INFO: 83epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=4.099, loss=2.049, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.602e-04, train_time=0.872
[alab02] 2024-08-30 13:43:50,617 (trainer:720) INFO: 83epoch:train:201-400batch: iter_time=1.793e-04, forward_time=0.129, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.784, loss=1.892, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.602e-04, train_time=0.865
[alab02] 2024-08-30 13:45:16,664 (trainer:720) INFO: 83epoch:train:401-600batch: iter_time=1.890e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=4.387, loss=2.193, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.602e-04, train_time=0.860
[alab02] 2024-08-30 13:46:42,142 (trainer:720) INFO: 83epoch:train:601-800batch: iter_time=1.768e-04, forward_time=0.126, uma_reduction=0.256, text_vs_uma=0.381, loss_ctc=4.275, loss=2.138, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.601e-04, train_time=0.855
[alab02] 2024-08-30 13:48:06,695 (trainer:720) INFO: 83epoch:train:801-1000batch: iter_time=1.742e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.368, loss_ctc=4.332, loss=2.166, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.601e-04, train_time=0.845
[alab02] 2024-08-30 13:49:32,942 (trainer:720) INFO: 83epoch:train:1001-1200batch: iter_time=1.974e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.354, loss_ctc=4.001, loss=2.000, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.601e-04, train_time=0.862
[alab02] 2024-08-30 13:50:59,157 (trainer:720) INFO: 83epoch:train:1201-1400batch: iter_time=1.661e-04, forward_time=0.128, uma_reduction=0.250, text_vs_uma=0.393, loss_ctc=4.703, loss=2.351, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.601e-04, train_time=0.862
[alab02] 2024-08-30 13:52:25,513 (trainer:720) INFO: 83epoch:train:1401-1600batch: iter_time=1.604e-04, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.371, loss_ctc=4.042, loss=2.021, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.600e-04, train_time=0.863
[alab02] 2024-08-30 13:53:54,330 (trainer:720) INFO: 83epoch:train:1601-1800batch: iter_time=1.605e-04, forward_time=0.132, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=4.173, loss=2.086, backward_time=0.188, optim_step_time=0.030, optim0_lr0=1.600e-04, train_time=0.888
[alab02] 2024-08-30 13:55:19,917 (trainer:720) INFO: 83epoch:train:1801-2000batch: iter_time=2.313e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.376, loss_ctc=4.195, loss=2.097, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.600e-04, train_time=0.856
[alab02] 2024-08-30 13:56:47,701 (trainer:720) INFO: 83epoch:train:2001-2200batch: iter_time=1.986e-04, forward_time=0.133, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=3.820, loss=1.910, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.599e-04, train_time=0.878
[alab02] 2024-08-30 13:58:15,777 (trainer:720) INFO: 83epoch:train:2201-2400batch: iter_time=1.951e-04, forward_time=0.132, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=4.326, loss=2.163, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.599e-04, train_time=0.881
[alab02] 2024-08-30 13:59:42,879 (trainer:720) INFO: 83epoch:train:2401-2600batch: iter_time=2.509e-04, forward_time=0.132, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=3.932, loss=1.966, backward_time=0.179, optim_step_time=0.036, optim0_lr0=1.599e-04, train_time=0.871
[alab02] 2024-08-30 14:01:13,971 (trainer:720) INFO: 83epoch:train:2601-2800batch: iter_time=2.511e-04, forward_time=0.138, uma_reduction=0.263, text_vs_uma=0.363, loss_ctc=4.288, loss=2.144, backward_time=0.190, optim_step_time=0.035, optim0_lr0=1.599e-04, train_time=0.911
[alab02] 2024-08-30 14:02:41,022 (trainer:720) INFO: 83epoch:train:2801-3000batch: iter_time=2.509e-04, forward_time=0.132, uma_reduction=0.263, text_vs_uma=0.362, loss_ctc=4.109, loss=2.055, backward_time=0.176, optim_step_time=0.035, optim0_lr0=1.598e-04, train_time=0.870
[alab02] 2024-08-30 14:03:30,710 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 14:04:08,602 (trainer:720) INFO: 83epoch:train:3001-3200batch: iter_time=2.300e-04, forward_time=0.134, uma_reduction=0.261, text_vs_uma=0.376, loss_ctc=4.142, loss=2.071, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.598e-04, train_time=0.876
[alab02] 2024-08-30 14:05:39,926 (trainer:720) INFO: 83epoch:train:3201-3400batch: iter_time=2.475e-04, forward_time=0.141, uma_reduction=0.266, text_vs_uma=0.359, loss_ctc=3.849, loss=1.925, backward_time=0.190, optim_step_time=0.040, optim0_lr0=1.598e-04, train_time=0.913
[alab02] 2024-08-30 14:07:11,137 (trainer:720) INFO: 83epoch:train:3401-3600batch: iter_time=2.721e-04, forward_time=0.140, uma_reduction=0.270, text_vs_uma=0.364, loss_ctc=4.235, loss=2.118, backward_time=0.186, optim_step_time=0.042, optim0_lr0=1.598e-04, train_time=0.912
[alab02] 2024-08-30 14:08:40,820 (trainer:720) INFO: 83epoch:train:3601-3800batch: iter_time=3.192e-04, forward_time=0.137, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=4.080, loss=2.040, backward_time=0.181, optim_step_time=0.041, optim0_lr0=1.597e-04, train_time=0.897
[alab02] 2024-08-30 14:10:13,921 (trainer:720) INFO: 83epoch:train:3801-4000batch: iter_time=2.643e-04, forward_time=0.144, uma_reduction=0.266, text_vs_uma=0.358, loss_ctc=4.128, loss=2.064, backward_time=0.189, optim_step_time=0.042, optim0_lr0=1.597e-04, train_time=0.931
[alab02] 2024-08-30 14:11:46,065 (trainer:720) INFO: 83epoch:train:4001-4200batch: iter_time=2.807e-04, forward_time=0.142, uma_reduction=0.251, text_vs_uma=0.375, loss_ctc=4.345, loss=2.173, backward_time=0.187, optim_step_time=0.042, optim0_lr0=1.597e-04, train_time=0.921
[alab02] 2024-08-30 14:13:14,419 (trainer:720) INFO: 83epoch:train:4201-4400batch: iter_time=2.881e-04, forward_time=0.136, uma_reduction=0.262, text_vs_uma=0.376, loss_ctc=4.169, loss=2.085, backward_time=0.178, optim_step_time=0.040, optim0_lr0=1.596e-04, train_time=0.883
[alab02] 2024-08-30 14:14:44,378 (trainer:720) INFO: 83epoch:train:4401-4600batch: iter_time=2.844e-04, forward_time=0.137, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=4.092, loss=2.046, backward_time=0.185, optim_step_time=0.038, optim0_lr0=1.596e-04, train_time=0.899
[alab02] 2024-08-30 14:16:14,007 (trainer:720) INFO: 83epoch:train:4601-4800batch: iter_time=2.813e-04, forward_time=0.138, uma_reduction=0.263, text_vs_uma=0.362, loss_ctc=4.210, loss=2.105, backward_time=0.183, optim_step_time=0.041, optim0_lr0=1.596e-04, train_time=0.896
[alab02] 2024-08-30 14:17:46,083 (trainer:720) INFO: 83epoch:train:4801-5000batch: iter_time=3.735e-04, forward_time=0.143, uma_reduction=0.259, text_vs_uma=0.373, loss_ctc=4.267, loss=2.133, backward_time=0.187, optim_step_time=0.045, optim0_lr0=1.596e-04, train_time=0.920
[alab02] 2024-08-30 14:19:20,333 (trainer:720) INFO: 83epoch:train:5001-5200batch: iter_time=3.003e-04, forward_time=0.145, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=4.405, loss=2.202, backward_time=0.191, optim_step_time=0.046, optim0_lr0=1.595e-04, train_time=0.942
[alab02] 2024-08-30 14:20:50,945 (trainer:720) INFO: 83epoch:train:5201-5400batch: iter_time=3.185e-04, forward_time=0.140, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.975, loss=1.987, backward_time=0.183, optim_step_time=0.045, optim0_lr0=1.595e-04, train_time=0.906
[alab02] 2024-08-30 14:22:22,264 (trainer:720) INFO: 83epoch:train:5401-5600batch: iter_time=2.810e-04, forward_time=0.140, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=4.303, loss=2.152, backward_time=0.187, optim_step_time=0.041, optim0_lr0=1.595e-04, train_time=0.913
[alab02] 2024-08-30 14:23:51,242 (trainer:720) INFO: 83epoch:train:5601-5800batch: iter_time=2.509e-04, forward_time=0.136, uma_reduction=0.259, text_vs_uma=0.366, loss_ctc=4.002, loss=2.001, backward_time=0.184, optim_step_time=0.038, optim0_lr0=1.595e-04, train_time=0.889
[alab02] 2024-08-30 14:25:20,788 (trainer:720) INFO: 83epoch:train:5801-6000batch: iter_time=2.189e-04, forward_time=0.137, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=4.453, loss=2.227, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.594e-04, train_time=0.895
[alab02] 2024-08-30 14:26:47,419 (trainer:720) INFO: 83epoch:train:6001-6200batch: iter_time=1.990e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=4.363, loss=2.182, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.594e-04, train_time=0.866
[alab02] 2024-08-30 14:28:15,631 (trainer:720) INFO: 83epoch:train:6201-6400batch: iter_time=1.891e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=4.008, loss=2.004, backward_time=0.187, optim_step_time=0.032, optim0_lr0=1.594e-04, train_time=0.882
[alab02] 2024-08-30 14:29:43,085 (trainer:720) INFO: 83epoch:train:6401-6600batch: iter_time=1.910e-04, forward_time=0.131, uma_reduction=0.264, text_vs_uma=0.364, loss_ctc=4.090, loss=2.045, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.593e-04, train_time=0.874
[alab02] 2024-08-30 14:31:10,731 (trainer:720) INFO: 83epoch:train:6601-6800batch: iter_time=2.362e-04, forward_time=0.132, uma_reduction=0.271, text_vs_uma=0.366, loss_ctc=4.475, loss=2.237, backward_time=0.179, optim_step_time=0.036, optim0_lr0=1.593e-04, train_time=0.876
[alab02] 2024-08-30 14:32:38,890 (trainer:720) INFO: 83epoch:train:6801-7000batch: iter_time=1.760e-04, forward_time=0.132, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=4.255, loss=2.128, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.593e-04, train_time=0.881
[alab02] 2024-08-30 14:33:54,813 (trainer:338) INFO: 83epoch results: [train] iter_time=2.760e-04, forward_time=0.134, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=4.171, loss=2.086, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.597e-04, train_time=0.886, time=52 minutes and 38.54 seconds, total_count=591458, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.299, text_vs_uma=0.363, loss_ctc=3.228, cer_ctc=0.089, cer=0.089, loss=3.228, time=6.08 seconds, total_count=2158, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.31 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 14:33:59,639 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 14:33:59,670 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/53epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/82epoch.pth
[alab02] 2024-08-30 14:33:59,670 (trainer:272) INFO: 84/150epoch started. Estimated time to finish: 2 days, 13 hours and 2 minutes
[alab02] 2024-08-30 14:35:27,686 (trainer:720) INFO: 84epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=4.318, loss=2.159, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.592e-04, train_time=0.880
[alab02] 2024-08-30 14:36:55,923 (trainer:720) INFO: 84epoch:train:201-400batch: iter_time=1.844e-04, forward_time=0.132, uma_reduction=0.264, text_vs_uma=0.367, loss_ctc=3.909, loss=1.954, backward_time=0.188, optim_step_time=0.030, optim0_lr0=1.592e-04, train_time=0.882
[alab02] 2024-08-30 14:38:22,102 (trainer:720) INFO: 84epoch:train:401-600batch: iter_time=1.727e-04, forward_time=0.128, uma_reduction=0.248, text_vs_uma=0.394, loss_ctc=4.285, loss=2.142, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.592e-04, train_time=0.862
[alab02] 2024-08-30 14:39:50,793 (trainer:720) INFO: 84epoch:train:601-800batch: iter_time=1.692e-04, forward_time=0.132, uma_reduction=0.260, text_vs_uma=0.376, loss_ctc=4.290, loss=2.145, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.592e-04, train_time=0.887
[alab02] 2024-08-30 14:41:18,732 (trainer:720) INFO: 84epoch:train:801-1000batch: iter_time=1.810e-04, forward_time=0.132, uma_reduction=0.256, text_vs_uma=0.379, loss_ctc=4.004, loss=2.002, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.591e-04, train_time=0.879
[alab02] 2024-08-30 14:42:44,874 (trainer:720) INFO: 84epoch:train:1001-1200batch: iter_time=1.770e-04, forward_time=0.128, uma_reduction=0.244, text_vs_uma=0.394, loss_ctc=4.253, loss=2.126, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.591e-04, train_time=0.861
[alab02] 2024-08-30 14:44:12,721 (trainer:720) INFO: 84epoch:train:1201-1400batch: iter_time=1.735e-04, forward_time=0.131, uma_reduction=0.251, text_vs_uma=0.386, loss_ctc=4.214, loss=2.107, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.591e-04, train_time=0.878
[alab02] 2024-08-30 14:45:38,332 (trainer:720) INFO: 84epoch:train:1401-1600batch: iter_time=1.764e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.376, loss_ctc=4.219, loss=2.110, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.591e-04, train_time=0.856
[alab02] 2024-08-30 14:46:09,373 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 14:47:02,932 (trainer:720) INFO: 84epoch:train:1601-1800batch: iter_time=1.781e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=4.001, loss=2.001, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.590e-04, train_time=0.846
[alab02] 2024-08-30 14:48:30,923 (trainer:720) INFO: 84epoch:train:1801-2000batch: iter_time=1.626e-04, forward_time=0.131, uma_reduction=0.287, text_vs_uma=0.336, loss_ctc=3.979, loss=1.990, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.590e-04, train_time=0.880
[alab02] 2024-08-30 14:49:57,767 (trainer:720) INFO: 84epoch:train:2001-2200batch: iter_time=1.671e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=4.212, loss=2.106, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.590e-04, train_time=0.868
[alab02] 2024-08-30 14:51:23,309 (trainer:720) INFO: 84epoch:train:2201-2400batch: iter_time=1.650e-04, forward_time=0.127, uma_reduction=0.260, text_vs_uma=0.362, loss_ctc=4.042, loss=2.021, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.590e-04, train_time=0.855
[alab02] 2024-08-30 14:52:49,360 (trainer:720) INFO: 84epoch:train:2401-2600batch: iter_time=1.731e-04, forward_time=0.128, uma_reduction=0.256, text_vs_uma=0.369, loss_ctc=3.989, loss=1.995, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.589e-04, train_time=0.860
[alab02] 2024-08-30 14:54:13,444 (trainer:720) INFO: 84epoch:train:2601-2800batch: iter_time=1.654e-04, forward_time=0.126, uma_reduction=0.258, text_vs_uma=0.368, loss_ctc=4.300, loss=2.150, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.589e-04, train_time=0.841
[alab02] 2024-08-30 14:55:38,212 (trainer:720) INFO: 84epoch:train:2801-3000batch: iter_time=1.678e-04, forward_time=0.126, uma_reduction=0.251, text_vs_uma=0.381, loss_ctc=3.974, loss=1.987, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.589e-04, train_time=0.847
[alab02] 2024-08-30 14:57:05,278 (trainer:720) INFO: 84epoch:train:3001-3200batch: iter_time=1.820e-04, forward_time=0.130, uma_reduction=0.256, text_vs_uma=0.374, loss_ctc=3.980, loss=1.990, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.588e-04, train_time=0.870
[alab02] 2024-08-30 14:58:30,988 (trainer:720) INFO: 84epoch:train:3201-3400batch: iter_time=1.853e-04, forward_time=0.127, uma_reduction=0.252, text_vs_uma=0.382, loss_ctc=4.160, loss=2.080, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.588e-04, train_time=0.857
[alab02] 2024-08-30 14:59:55,848 (trainer:720) INFO: 84epoch:train:3401-3600batch: iter_time=1.777e-04, forward_time=0.127, uma_reduction=0.255, text_vs_uma=0.382, loss_ctc=4.248, loss=2.124, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.588e-04, train_time=0.848
[alab02] 2024-08-30 15:01:19,992 (trainer:720) INFO: 84epoch:train:3601-3800batch: iter_time=1.767e-04, forward_time=0.126, uma_reduction=0.252, text_vs_uma=0.392, loss_ctc=4.191, loss=2.095, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.588e-04, train_time=0.841
[alab02] 2024-08-30 15:02:45,760 (trainer:720) INFO: 84epoch:train:3801-4000batch: iter_time=1.760e-04, forward_time=0.127, uma_reduction=0.249, text_vs_uma=0.395, loss_ctc=4.200, loss=2.100, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.587e-04, train_time=0.857
[alab02] 2024-08-30 15:04:12,437 (trainer:720) INFO: 84epoch:train:4001-4200batch: iter_time=1.760e-04, forward_time=0.129, uma_reduction=0.261, text_vs_uma=0.364, loss_ctc=3.917, loss=1.959, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.587e-04, train_time=0.867
[alab02] 2024-08-30 15:05:40,364 (trainer:720) INFO: 84epoch:train:4201-4400batch: iter_time=1.636e-04, forward_time=0.131, uma_reduction=0.254, text_vs_uma=0.380, loss_ctc=4.156, loss=2.078, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.587e-04, train_time=0.879
[alab02] 2024-08-30 15:07:07,366 (trainer:720) INFO: 84epoch:train:4401-4600batch: iter_time=1.683e-04, forward_time=0.130, uma_reduction=0.251, text_vs_uma=0.387, loss_ctc=3.760, loss=1.880, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.587e-04, train_time=0.870
[alab02] 2024-08-30 15:08:32,872 (trainer:720) INFO: 84epoch:train:4601-4800batch: iter_time=1.657e-04, forward_time=0.127, uma_reduction=0.254, text_vs_uma=0.376, loss_ctc=4.091, loss=2.045, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.586e-04, train_time=0.855
[alab02] 2024-08-30 15:09:59,614 (trainer:720) INFO: 84epoch:train:4801-5000batch: iter_time=1.822e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.383, loss_ctc=4.144, loss=2.072, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.586e-04, train_time=0.867
[alab02] 2024-08-30 15:11:25,941 (trainer:720) INFO: 84epoch:train:5001-5200batch: iter_time=1.894e-04, forward_time=0.128, uma_reduction=0.254, text_vs_uma=0.391, loss_ctc=4.098, loss=2.049, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.586e-04, train_time=0.863
[alab02] 2024-08-30 15:12:51,880 (trainer:720) INFO: 84epoch:train:5201-5400batch: iter_time=1.734e-04, forward_time=0.128, uma_reduction=0.251, text_vs_uma=0.386, loss_ctc=4.252, loss=2.126, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.586e-04, train_time=0.859
[alab02] 2024-08-30 15:14:19,000 (trainer:720) INFO: 84epoch:train:5401-5600batch: iter_time=1.824e-04, forward_time=0.130, uma_reduction=0.252, text_vs_uma=0.394, loss_ctc=4.291, loss=2.145, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.585e-04, train_time=0.871
[alab02] 2024-08-30 15:15:45,460 (trainer:720) INFO: 84epoch:train:5601-5800batch: iter_time=1.934e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.383, loss_ctc=4.337, loss=2.169, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.585e-04, train_time=0.864
[alab02] 2024-08-30 15:17:09,931 (trainer:720) INFO: 84epoch:train:5801-6000batch: iter_time=1.958e-04, forward_time=0.126, uma_reduction=0.253, text_vs_uma=0.390, loss_ctc=4.257, loss=2.128, backward_time=0.174, optim_step_time=0.032, optim0_lr0=1.585e-04, train_time=0.844
[alab02] 2024-08-30 15:18:35,115 (trainer:720) INFO: 84epoch:train:6001-6200batch: iter_time=1.985e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.372, loss_ctc=4.374, loss=2.187, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.584e-04, train_time=0.852
[alab02] 2024-08-30 15:20:02,000 (trainer:720) INFO: 84epoch:train:6201-6400batch: iter_time=1.860e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=4.067, loss=2.033, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.584e-04, train_time=0.869
[alab02] 2024-08-30 15:21:28,931 (trainer:720) INFO: 84epoch:train:6401-6600batch: iter_time=1.911e-04, forward_time=0.130, uma_reduction=0.259, text_vs_uma=0.373, loss_ctc=4.392, loss=2.196, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.584e-04, train_time=0.869
[alab02] 2024-08-30 15:22:34,870 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 15:22:54,706 (trainer:720) INFO: 84epoch:train:6601-6800batch: iter_time=2.008e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.349, loss_ctc=3.897, loss=1.948, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.584e-04, train_time=0.858
[alab02] 2024-08-30 15:24:22,694 (trainer:720) INFO: 84epoch:train:6801-7000batch: iter_time=1.849e-04, forward_time=0.131, uma_reduction=0.290, text_vs_uma=0.337, loss_ctc=4.195, loss=2.097, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.583e-04, train_time=0.880
[alab02] 2024-08-30 15:25:37,465 (trainer:338) INFO: 84epoch results: [train] iter_time=2.340e-04, forward_time=0.129, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=4.143, loss=2.072, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.588e-04, train_time=0.864, time=51 minutes and 18.16 seconds, total_count=598584, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.289, text_vs_uma=0.376, loss_ctc=3.095, cer_ctc=0.082, cer=0.082, loss=3.095, time=6.03 seconds, total_count=2184, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.6 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 15:25:42,744 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-30 15:25:42,748 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/65epoch.pth
[alab02] 2024-08-30 15:25:42,748 (trainer:272) INFO: 85/150epoch started. Estimated time to finish: 2 days, 12 hours and 5 minutes
[alab02] 2024-08-30 15:27:11,024 (trainer:720) INFO: 85epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.351, loss_ctc=3.805, loss=1.902, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.583e-04, train_time=0.882
[alab02] 2024-08-30 15:28:39,971 (trainer:720) INFO: 85epoch:train:201-400batch: iter_time=1.957e-04, forward_time=0.133, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=4.445, loss=2.222, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.583e-04, train_time=0.889
[alab02] 2024-08-30 15:30:07,373 (trainer:720) INFO: 85epoch:train:401-600batch: iter_time=1.911e-04, forward_time=0.131, uma_reduction=0.284, text_vs_uma=0.341, loss_ctc=4.086, loss=2.043, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.582e-04, train_time=0.874
[alab02] 2024-08-30 15:31:37,001 (trainer:720) INFO: 85epoch:train:601-800batch: iter_time=1.965e-04, forward_time=0.134, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=4.273, loss=2.136, backward_time=0.186, optim_step_time=0.032, optim0_lr0=1.582e-04, train_time=0.896
[alab02] 2024-08-30 15:33:04,964 (trainer:720) INFO: 85epoch:train:801-1000batch: iter_time=1.886e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.362, loss_ctc=4.308, loss=2.154, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.582e-04, train_time=0.879
[alab02] 2024-08-30 15:34:33,303 (trainer:720) INFO: 85epoch:train:1001-1200batch: iter_time=1.757e-04, forward_time=0.132, uma_reduction=0.255, text_vs_uma=0.384, loss_ctc=4.186, loss=2.093, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.582e-04, train_time=0.883
[alab02] 2024-08-30 15:36:01,171 (trainer:720) INFO: 85epoch:train:1201-1400batch: iter_time=2.010e-04, forward_time=0.131, uma_reduction=0.254, text_vs_uma=0.385, loss_ctc=4.143, loss=2.072, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.581e-04, train_time=0.878
[alab02] 2024-08-30 15:37:28,083 (trainer:720) INFO: 85epoch:train:1401-1600batch: iter_time=1.951e-04, forward_time=0.130, uma_reduction=0.255, text_vs_uma=0.388, loss_ctc=4.119, loss=2.059, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.581e-04, train_time=0.869
[alab02] 2024-08-30 15:38:53,530 (trainer:720) INFO: 85epoch:train:1601-1800batch: iter_time=1.808e-04, forward_time=0.127, uma_reduction=0.256, text_vs_uma=0.373, loss_ctc=3.939, loss=1.970, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.581e-04, train_time=0.854
[alab02] 2024-08-30 15:40:19,805 (trainer:720) INFO: 85epoch:train:1801-2000batch: iter_time=1.834e-04, forward_time=0.129, uma_reduction=0.254, text_vs_uma=0.369, loss_ctc=3.786, loss=1.893, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.581e-04, train_time=0.863
[alab02] 2024-08-30 15:40:30,367 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 15:41:47,007 (trainer:720) INFO: 85epoch:train:2001-2200batch: iter_time=1.881e-04, forward_time=0.130, uma_reduction=0.253, text_vs_uma=0.376, loss_ctc=3.912, loss=1.956, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.580e-04, train_time=0.872
[alab02] 2024-08-30 15:43:12,935 (trainer:720) INFO: 85epoch:train:2201-2400batch: iter_time=1.800e-04, forward_time=0.128, uma_reduction=0.251, text_vs_uma=0.381, loss_ctc=3.674, loss=1.837, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.580e-04, train_time=0.859
[alab02] 2024-08-30 15:44:39,480 (trainer:720) INFO: 85epoch:train:2401-2600batch: iter_time=1.775e-04, forward_time=0.129, uma_reduction=0.256, text_vs_uma=0.375, loss_ctc=4.210, loss=2.105, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.580e-04, train_time=0.865
[alab02] 2024-08-30 15:46:07,124 (trainer:720) INFO: 85epoch:train:2601-2800batch: iter_time=1.805e-04, forward_time=0.131, uma_reduction=0.252, text_vs_uma=0.380, loss_ctc=4.089, loss=2.044, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.580e-04, train_time=0.876
[alab02] 2024-08-30 15:47:32,582 (trainer:720) INFO: 85epoch:train:2801-3000batch: iter_time=1.729e-04, forward_time=0.127, uma_reduction=0.244, text_vs_uma=0.392, loss_ctc=3.971, loss=1.985, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.579e-04, train_time=0.854
[alab02] 2024-08-30 15:48:59,391 (trainer:720) INFO: 85epoch:train:3001-3200batch: iter_time=1.776e-04, forward_time=0.129, uma_reduction=0.243, text_vs_uma=0.400, loss_ctc=4.231, loss=2.116, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.579e-04, train_time=0.868
[alab02] 2024-08-30 15:50:26,163 (trainer:720) INFO: 85epoch:train:3201-3400batch: iter_time=1.768e-04, forward_time=0.130, uma_reduction=0.251, text_vs_uma=0.385, loss_ctc=4.404, loss=2.202, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.579e-04, train_time=0.867
[alab02] 2024-08-30 15:51:53,847 (trainer:720) INFO: 85epoch:train:3401-3600batch: iter_time=2.087e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.372, loss_ctc=4.104, loss=2.052, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.578e-04, train_time=0.877
[alab02] 2024-08-30 15:53:20,388 (trainer:720) INFO: 85epoch:train:3601-3800batch: iter_time=1.810e-04, forward_time=0.129, uma_reduction=0.259, text_vs_uma=0.378, loss_ctc=4.277, loss=2.138, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.578e-04, train_time=0.865
[alab02] 2024-08-30 15:54:46,982 (trainer:720) INFO: 85epoch:train:3801-4000batch: iter_time=1.735e-04, forward_time=0.129, uma_reduction=0.263, text_vs_uma=0.376, loss_ctc=4.319, loss=2.159, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.578e-04, train_time=0.866
[alab02] 2024-08-30 15:56:12,759 (trainer:720) INFO: 85epoch:train:4001-4200batch: iter_time=1.867e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=4.303, loss=2.151, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.578e-04, train_time=0.858
[alab02] 2024-08-30 15:57:40,301 (trainer:720) INFO: 85epoch:train:4201-4400batch: iter_time=1.713e-04, forward_time=0.130, uma_reduction=0.283, text_vs_uma=0.343, loss_ctc=4.381, loss=2.190, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.577e-04, train_time=0.875
[alab02] 2024-08-30 15:59:08,013 (trainer:720) INFO: 85epoch:train:4401-4600batch: iter_time=1.744e-04, forward_time=0.130, uma_reduction=0.285, text_vs_uma=0.344, loss_ctc=3.939, loss=1.969, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.577e-04, train_time=0.877
[alab02] 2024-08-30 16:00:34,910 (trainer:720) INFO: 85epoch:train:4601-4800batch: iter_time=1.715e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=4.298, loss=2.149, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.577e-04, train_time=0.869
[alab02] 2024-08-30 16:02:02,401 (trainer:720) INFO: 85epoch:train:4801-5000batch: iter_time=1.762e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.367, loss_ctc=4.448, loss=2.224, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.577e-04, train_time=0.875
[alab02] 2024-08-30 16:03:27,210 (trainer:720) INFO: 85epoch:train:5001-5200batch: iter_time=1.869e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.355, loss_ctc=4.131, loss=2.066, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.576e-04, train_time=0.848
[alab02] 2024-08-30 16:04:54,477 (trainer:720) INFO: 85epoch:train:5201-5400batch: iter_time=2.012e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=4.068, loss=2.034, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.576e-04, train_time=0.872
[alab02] 2024-08-30 16:06:20,813 (trainer:720) INFO: 85epoch:train:5401-5600batch: iter_time=2.168e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=4.001, loss=2.000, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.576e-04, train_time=0.863
[alab02] 2024-08-30 16:07:47,015 (trainer:720) INFO: 85epoch:train:5601-5800batch: iter_time=2.091e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=4.445, loss=2.222, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.576e-04, train_time=0.862
[alab02] 2024-08-30 16:09:13,162 (trainer:720) INFO: 85epoch:train:5801-6000batch: iter_time=2.046e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=4.079, loss=2.040, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.575e-04, train_time=0.861
[alab02] 2024-08-30 16:10:41,295 (trainer:720) INFO: 85epoch:train:6001-6200batch: iter_time=1.894e-04, forward_time=0.132, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=4.156, loss=2.078, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.575e-04, train_time=0.881
[alab02] 2024-08-30 16:12:07,801 (trainer:720) INFO: 85epoch:train:6201-6400batch: iter_time=1.794e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=4.190, loss=2.095, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.575e-04, train_time=0.865
[alab02] 2024-08-30 16:13:34,707 (trainer:720) INFO: 85epoch:train:6401-6600batch: iter_time=1.975e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.334, loss_ctc=3.827, loss=1.913, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.575e-04, train_time=0.869
[alab02] 2024-08-30 16:15:00,488 (trainer:720) INFO: 85epoch:train:6601-6800batch: iter_time=1.900e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=3.694, loss=1.847, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.574e-04, train_time=0.858
[alab02] 2024-08-30 16:16:28,282 (trainer:720) INFO: 85epoch:train:6801-7000batch: iter_time=1.738e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=4.490, loss=2.245, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.574e-04, train_time=0.878
[alab02] 2024-08-30 16:17:42,525 (trainer:338) INFO: 85epoch results: [train] iter_time=2.357e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=4.130, loss=2.065, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.578e-04, train_time=0.870, time=51 minutes and 40.46 seconds, total_count=605710, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.265, text_vs_uma=0.410, loss_ctc=3.272, cer_ctc=0.092, cer=0.092, loss=3.272, time=5.91 seconds, total_count=2210, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.4 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 16:17:47,442 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 16:17:47,443 (trainer:272) INFO: 86/150epoch started. Estimated time to finish: 2 days, 11 hours and 9 minutes
[alab02] 2024-08-30 16:19:15,716 (trainer:720) INFO: 86epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=4.293, loss=2.147, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.574e-04, train_time=0.882
[alab02] 2024-08-30 16:20:41,655 (trainer:720) INFO: 86epoch:train:201-400batch: iter_time=1.943e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.367, loss_ctc=4.002, loss=2.001, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.573e-04, train_time=0.859
[alab02] 2024-08-30 16:22:10,562 (trainer:720) INFO: 86epoch:train:401-600batch: iter_time=1.971e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=3.876, loss=1.938, backward_time=0.188, optim_step_time=0.031, optim0_lr0=1.573e-04, train_time=0.889
[alab02] 2024-08-30 16:23:35,009 (trainer:720) INFO: 86epoch:train:601-800batch: iter_time=1.958e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.340, loss_ctc=3.837, loss=1.918, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.573e-04, train_time=0.844
[alab02] 2024-08-30 16:25:01,499 (trainer:720) INFO: 86epoch:train:801-1000batch: iter_time=1.946e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=4.262, loss=2.131, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.573e-04, train_time=0.865
[alab02] 2024-08-30 16:26:30,047 (trainer:720) INFO: 86epoch:train:1001-1200batch: iter_time=2.030e-04, forward_time=0.132, uma_reduction=0.265, text_vs_uma=0.368, loss_ctc=3.698, loss=1.849, backward_time=0.189, optim_step_time=0.031, optim0_lr0=1.572e-04, train_time=0.885
[alab02] 2024-08-30 16:27:55,721 (trainer:720) INFO: 86epoch:train:1201-1400batch: iter_time=1.922e-04, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=3.846, loss=1.923, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.572e-04, train_time=0.856
[alab02] 2024-08-30 16:29:20,732 (trainer:720) INFO: 86epoch:train:1401-1600batch: iter_time=2.043e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.356, loss_ctc=4.058, loss=2.029, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.572e-04, train_time=0.850
[alab02] 2024-08-30 16:30:48,316 (trainer:720) INFO: 86epoch:train:1601-1800batch: iter_time=1.970e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.338, loss_ctc=3.749, loss=1.875, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.572e-04, train_time=0.876
[alab02] 2024-08-30 16:32:14,929 (trainer:720) INFO: 86epoch:train:1801-2000batch: iter_time=1.932e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.018, loss=2.009, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.571e-04, train_time=0.866
[alab02] 2024-08-30 16:33:41,865 (trainer:720) INFO: 86epoch:train:2001-2200batch: iter_time=1.834e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.929, loss=1.964, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.571e-04, train_time=0.869
[alab02] 2024-08-30 16:35:11,799 (trainer:720) INFO: 86epoch:train:2201-2400batch: iter_time=2.246e-04, forward_time=0.137, uma_reduction=0.288, text_vs_uma=0.334, loss_ctc=4.086, loss=2.043, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.571e-04, train_time=0.899
[alab02] 2024-08-30 16:36:37,995 (trainer:720) INFO: 86epoch:train:2401-2600batch: iter_time=1.857e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.936, loss=1.968, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.571e-04, train_time=0.862
[alab02] 2024-08-30 16:38:07,118 (trainer:720) INFO: 86epoch:train:2601-2800batch: iter_time=1.759e-04, forward_time=0.133, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=4.031, loss=2.016, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.570e-04, train_time=0.891
[alab02] 2024-08-30 16:39:34,071 (trainer:720) INFO: 86epoch:train:2801-3000batch: iter_time=1.766e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.343, loss_ctc=3.836, loss=1.918, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.570e-04, train_time=0.869
[alab02] 2024-08-30 16:40:58,609 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 16:41:00,436 (trainer:720) INFO: 86epoch:train:3001-3200batch: iter_time=1.815e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.969, loss=1.984, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.570e-04, train_time=0.863
[alab02] 2024-08-30 16:42:25,116 (trainer:720) INFO: 86epoch:train:3201-3400batch: iter_time=1.922e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.372, loss_ctc=4.083, loss=2.042, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.569e-04, train_time=0.847
[alab02] 2024-08-30 16:43:51,672 (trainer:720) INFO: 86epoch:train:3401-3600batch: iter_time=1.780e-04, forward_time=0.129, uma_reduction=0.262, text_vs_uma=0.372, loss_ctc=4.070, loss=2.035, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.569e-04, train_time=0.865
[alab02] 2024-08-30 16:45:19,627 (trainer:720) INFO: 86epoch:train:3601-3800batch: iter_time=1.695e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=4.112, loss=2.056, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.569e-04, train_time=0.879
[alab02] 2024-08-30 16:46:47,102 (trainer:720) INFO: 86epoch:train:3801-4000batch: iter_time=1.728e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.356, loss_ctc=4.139, loss=2.069, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.569e-04, train_time=0.875
[alab02] 2024-08-30 16:48:21,088 (trainer:720) INFO: 86epoch:train:4001-4200batch: iter_time=3.141e-04, forward_time=0.144, uma_reduction=0.283, text_vs_uma=0.339, loss_ctc=3.923, loss=1.962, backward_time=0.195, optim_step_time=0.045, optim0_lr0=1.568e-04, train_time=0.939
[alab02] 2024-08-30 16:49:57,510 (trainer:720) INFO: 86epoch:train:4201-4400batch: iter_time=5.139e-04, forward_time=0.150, uma_reduction=0.282, text_vs_uma=0.338, loss_ctc=3.853, loss=1.926, backward_time=0.198, optim_step_time=0.051, optim0_lr0=1.568e-04, train_time=0.964
[alab02] 2024-08-30 16:51:33,353 (trainer:720) INFO: 86epoch:train:4401-4600batch: iter_time=6.543e-04, forward_time=0.148, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=4.201, loss=2.101, backward_time=0.192, optim_step_time=0.055, optim0_lr0=1.568e-04, train_time=0.958
[alab02] 2024-08-30 16:53:11,066 (trainer:720) INFO: 86epoch:train:4601-4800batch: iter_time=4.131e-04, forward_time=0.153, uma_reduction=0.282, text_vs_uma=0.347, loss_ctc=3.991, loss=1.996, backward_time=0.199, optim_step_time=0.054, optim0_lr0=1.568e-04, train_time=0.977
[alab02] 2024-08-30 16:54:46,207 (trainer:720) INFO: 86epoch:train:4801-5000batch: iter_time=4.969e-04, forward_time=0.148, uma_reduction=0.287, text_vs_uma=0.343, loss_ctc=3.747, loss=1.874, backward_time=0.197, optim_step_time=0.049, optim0_lr0=1.567e-04, train_time=0.951
[alab02] 2024-08-30 16:56:18,035 (trainer:720) INFO: 86epoch:train:5001-5200batch: iter_time=4.728e-04, forward_time=0.141, uma_reduction=0.285, text_vs_uma=0.333, loss_ctc=4.027, loss=2.014, backward_time=0.187, optim_step_time=0.045, optim0_lr0=1.567e-04, train_time=0.918
[alab02] 2024-08-30 16:57:51,775 (trainer:720) INFO: 86epoch:train:5201-5400batch: iter_time=3.199e-04, forward_time=0.144, uma_reduction=0.285, text_vs_uma=0.336, loss_ctc=3.702, loss=1.851, backward_time=0.196, optim_step_time=0.042, optim0_lr0=1.567e-04, train_time=0.937
[alab02] 2024-08-30 16:59:22,286 (trainer:720) INFO: 86epoch:train:5401-5600batch: iter_time=2.283e-04, forward_time=0.137, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=3.774, loss=1.887, backward_time=0.191, optim_step_time=0.037, optim0_lr0=1.567e-04, train_time=0.905
[alab02] 2024-08-30 17:00:50,571 (trainer:720) INFO: 86epoch:train:5601-5800batch: iter_time=2.308e-04, forward_time=0.134, uma_reduction=0.280, text_vs_uma=0.354, loss_ctc=4.247, loss=2.124, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.566e-04, train_time=0.883
[alab02] 2024-08-30 17:02:15,969 (trainer:720) INFO: 86epoch:train:5801-6000batch: iter_time=1.917e-04, forward_time=0.128, uma_reduction=0.293, text_vs_uma=0.321, loss_ctc=3.565, loss=1.782, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.566e-04, train_time=0.854
[alab02] 2024-08-30 17:03:51,116 (trainer:720) INFO: 86epoch:train:6001-6200batch: iter_time=4.196e-04, forward_time=0.147, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=4.318, loss=2.159, backward_time=0.194, optim_step_time=0.046, optim0_lr0=1.566e-04, train_time=0.951
[alab02] 2024-08-30 17:05:25,115 (trainer:720) INFO: 86epoch:train:6201-6400batch: iter_time=3.894e-04, forward_time=0.148, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=4.273, loss=2.137, backward_time=0.188, optim_step_time=0.049, optim0_lr0=1.566e-04, train_time=0.939
[alab02] 2024-08-30 17:07:01,463 (trainer:720) INFO: 86epoch:train:6401-6600batch: iter_time=3.590e-04, forward_time=0.154, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=4.235, loss=2.117, backward_time=0.194, optim_step_time=0.049, optim0_lr0=1.565e-04, train_time=0.963
[alab02] 2024-08-30 17:08:35,733 (trainer:720) INFO: 86epoch:train:6601-6800batch: iter_time=3.504e-04, forward_time=0.153, uma_reduction=0.293, text_vs_uma=0.332, loss_ctc=4.159, loss=2.080, backward_time=0.190, optim_step_time=0.049, optim0_lr0=1.565e-04, train_time=0.942
[alab02] 2024-08-30 17:10:13,510 (trainer:720) INFO: 86epoch:train:6801-7000batch: iter_time=3.425e-04, forward_time=0.156, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=4.434, loss=2.217, backward_time=0.200, optim_step_time=0.053, optim0_lr0=1.565e-04, train_time=0.977
[alab02] 2024-08-30 17:10:22,477 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 17:11:47,650 (trainer:338) INFO: 86epoch results: [train] iter_time=3.269e-04, forward_time=0.137, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.004, loss=2.002, backward_time=0.186, optim_step_time=0.038, optim0_lr0=1.569e-04, train_time=0.900, time=53 minutes and 27.92 seconds, total_count=612836, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.286, text_vs_uma=0.380, loss_ctc=3.133, cer_ctc=0.087, cer=0.087, loss=3.133, time=8.23 seconds, total_count=2236, gpu_max_cached_mem_GB=35.906, [att_plot] time=24.05 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 17:11:56,341 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 17:11:56,431 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/61epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/85epoch.pth
[alab02] 2024-08-30 17:11:56,431 (trainer:272) INFO: 87/150epoch started. Estimated time to finish: 2 days, 10 hours and 14 minutes
[alab02] 2024-08-30 17:13:36,211 (trainer:720) INFO: 87epoch:train:1-200batch: iter_time=0.007, forward_time=0.156, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.942, loss=1.971, backward_time=0.200, optim_step_time=0.053, optim0_lr0=1.564e-04, train_time=0.997
[alab02] 2024-08-30 17:15:12,641 (trainer:720) INFO: 87epoch:train:201-400batch: iter_time=5.623e-04, forward_time=0.156, uma_reduction=0.265, text_vs_uma=0.372, loss_ctc=4.197, loss=2.098, backward_time=0.192, optim_step_time=0.054, optim0_lr0=1.564e-04, train_time=0.964
[alab02] 2024-08-30 17:16:51,005 (trainer:720) INFO: 87epoch:train:401-600batch: iter_time=4.116e-04, forward_time=0.159, uma_reduction=0.284, text_vs_uma=0.338, loss_ctc=3.687, loss=1.844, backward_time=0.203, optim_step_time=0.053, optim0_lr0=1.564e-04, train_time=0.983
[alab02] 2024-08-30 17:18:30,215 (trainer:720) INFO: 87epoch:train:601-800batch: iter_time=4.129e-04, forward_time=0.158, uma_reduction=0.288, text_vs_uma=0.328, loss_ctc=3.893, loss=1.946, backward_time=0.202, optim_step_time=0.054, optim0_lr0=1.564e-04, train_time=0.992
[alab02] 2024-08-30 17:20:07,549 (trainer:720) INFO: 87epoch:train:801-1000batch: iter_time=3.985e-04, forward_time=0.155, uma_reduction=0.294, text_vs_uma=0.325, loss_ctc=3.828, loss=1.914, backward_time=0.201, optim_step_time=0.051, optim0_lr0=1.563e-04, train_time=0.973
[alab02] 2024-08-30 17:21:43,186 (trainer:720) INFO: 87epoch:train:1001-1200batch: iter_time=3.551e-04, forward_time=0.152, uma_reduction=0.291, text_vs_uma=0.339, loss_ctc=3.525, loss=1.763, backward_time=0.198, optim_step_time=0.048, optim0_lr0=1.563e-04, train_time=0.956
[alab02] 2024-08-30 17:23:14,681 (trainer:720) INFO: 87epoch:train:1201-1400batch: iter_time=2.528e-04, forward_time=0.143, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.782, loss=1.891, backward_time=0.188, optim_step_time=0.040, optim0_lr0=1.563e-04, train_time=0.915
[alab02] 2024-08-30 17:24:45,527 (trainer:720) INFO: 87epoch:train:1401-1600batch: iter_time=2.183e-04, forward_time=0.139, uma_reduction=0.283, text_vs_uma=0.345, loss_ctc=3.933, loss=1.967, backward_time=0.190, optim_step_time=0.034, optim0_lr0=1.563e-04, train_time=0.908
[alab02] 2024-08-30 17:26:11,956 (trainer:720) INFO: 87epoch:train:1601-1800batch: iter_time=1.915e-04, forward_time=0.130, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=4.267, loss=2.134, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.562e-04, train_time=0.864
[alab02] 2024-08-30 17:27:40,991 (trainer:720) INFO: 87epoch:train:1801-2000batch: iter_time=1.787e-04, forward_time=0.135, uma_reduction=0.284, text_vs_uma=0.340, loss_ctc=4.054, loss=2.027, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.562e-04, train_time=0.890
[alab02] 2024-08-30 17:29:12,863 (trainer:720) INFO: 87epoch:train:2001-2200batch: iter_time=2.300e-04, forward_time=0.141, uma_reduction=0.291, text_vs_uma=0.339, loss_ctc=4.022, loss=2.011, backward_time=0.191, optim_step_time=0.038, optim0_lr0=1.562e-04, train_time=0.918
[alab02] 2024-08-30 17:30:51,532 (trainer:720) INFO: 87epoch:train:2201-2400batch: iter_time=3.832e-04, forward_time=0.161, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=4.108, loss=2.054, backward_time=0.197, optim_step_time=0.056, optim0_lr0=1.562e-04, train_time=0.986
[alab02] 2024-08-30 17:32:32,351 (trainer:720) INFO: 87epoch:train:2401-2600batch: iter_time=4.417e-04, forward_time=0.160, uma_reduction=0.278, text_vs_uma=0.341, loss_ctc=3.876, loss=1.938, backward_time=0.206, optim_step_time=0.057, optim0_lr0=1.561e-04, train_time=1.008
[alab02] 2024-08-30 17:34:11,568 (trainer:720) INFO: 87epoch:train:2601-2800batch: iter_time=3.811e-04, forward_time=0.160, uma_reduction=0.286, text_vs_uma=0.337, loss_ctc=3.903, loss=1.952, backward_time=0.201, optim_step_time=0.059, optim0_lr0=1.561e-04, train_time=0.992
[alab02] 2024-08-30 17:35:49,879 (trainer:720) INFO: 87epoch:train:2801-3000batch: iter_time=4.677e-04, forward_time=0.158, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=4.302, loss=2.151, backward_time=0.198, optim_step_time=0.056, optim0_lr0=1.561e-04, train_time=0.983
[alab02] 2024-08-30 17:37:26,699 (trainer:720) INFO: 87epoch:train:3001-3200batch: iter_time=4.243e-04, forward_time=0.155, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.950, loss=1.975, backward_time=0.196, optim_step_time=0.056, optim0_lr0=1.561e-04, train_time=0.968
[alab02] 2024-08-30 17:39:04,949 (trainer:720) INFO: 87epoch:train:3201-3400batch: iter_time=3.950e-04, forward_time=0.156, uma_reduction=0.285, text_vs_uma=0.337, loss_ctc=4.008, loss=2.004, backward_time=0.202, optim_step_time=0.055, optim0_lr0=1.560e-04, train_time=0.982
[alab02] 2024-08-30 17:40:43,078 (trainer:720) INFO: 87epoch:train:3401-3600batch: iter_time=3.986e-04, forward_time=0.158, uma_reduction=0.295, text_vs_uma=0.323, loss_ctc=3.689, loss=1.844, backward_time=0.204, optim_step_time=0.056, optim0_lr0=1.560e-04, train_time=0.981
[alab02] 2024-08-30 17:42:21,581 (trainer:720) INFO: 87epoch:train:3601-3800batch: iter_time=3.858e-04, forward_time=0.157, uma_reduction=0.290, text_vs_uma=0.333, loss_ctc=3.850, loss=1.925, backward_time=0.201, optim_step_time=0.057, optim0_lr0=1.560e-04, train_time=0.984
[alab02] 2024-08-30 17:44:01,535 (trainer:720) INFO: 87epoch:train:3801-4000batch: iter_time=4.617e-04, forward_time=0.160, uma_reduction=0.284, text_vs_uma=0.337, loss_ctc=4.174, loss=2.087, backward_time=0.204, optim_step_time=0.054, optim0_lr0=1.560e-04, train_time=0.999
[alab02] 2024-08-30 17:45:39,069 (trainer:720) INFO: 87epoch:train:4001-4200batch: iter_time=4.078e-04, forward_time=0.157, uma_reduction=0.299, text_vs_uma=0.326, loss_ctc=4.174, loss=2.087, backward_time=0.196, optim_step_time=0.054, optim0_lr0=1.559e-04, train_time=0.975
[alab02] 2024-08-30 17:47:17,133 (trainer:720) INFO: 87epoch:train:4201-4400batch: iter_time=4.124e-04, forward_time=0.159, uma_reduction=0.292, text_vs_uma=0.332, loss_ctc=4.086, loss=2.043, backward_time=0.193, optim_step_time=0.056, optim0_lr0=1.559e-04, train_time=0.980
[alab02] 2024-08-30 17:48:52,162 (trainer:720) INFO: 87epoch:train:4401-4600batch: iter_time=3.638e-04, forward_time=0.150, uma_reduction=0.290, text_vs_uma=0.335, loss_ctc=3.731, loss=1.866, backward_time=0.198, optim_step_time=0.051, optim0_lr0=1.559e-04, train_time=0.950
[alab02] 2024-08-30 17:50:31,005 (trainer:720) INFO: 87epoch:train:4601-4800batch: iter_time=4.511e-04, forward_time=0.158, uma_reduction=0.297, text_vs_uma=0.323, loss_ctc=3.955, loss=1.977, backward_time=0.197, optim_step_time=0.059, optim0_lr0=1.559e-04, train_time=0.988
[alab02] 2024-08-30 17:52:02,188 (trainer:720) INFO: 87epoch:train:4801-5000batch: iter_time=2.891e-04, forward_time=0.141, uma_reduction=0.301, text_vs_uma=0.319, loss_ctc=4.102, loss=2.051, backward_time=0.185, optim_step_time=0.044, optim0_lr0=1.558e-04, train_time=0.911
[alab02] 2024-08-30 17:53:31,252 (trainer:720) INFO: 87epoch:train:5001-5200batch: iter_time=2.579e-04, forward_time=0.135, uma_reduction=0.296, text_vs_uma=0.338, loss_ctc=3.957, loss=1.978, backward_time=0.182, optim_step_time=0.038, optim0_lr0=1.558e-04, train_time=0.890
[alab02] 2024-08-30 17:54:59,772 (trainer:720) INFO: 87epoch:train:5201-5400batch: iter_time=2.445e-04, forward_time=0.135, uma_reduction=0.297, text_vs_uma=0.326, loss_ctc=3.884, loss=1.942, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.558e-04, train_time=0.885
[alab02] 2024-08-30 17:56:28,269 (trainer:720) INFO: 87epoch:train:5401-5600batch: iter_time=2.531e-04, forward_time=0.134, uma_reduction=0.288, text_vs_uma=0.344, loss_ctc=3.963, loss=1.982, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.558e-04, train_time=0.885
[alab02] 2024-08-30 17:57:58,313 (trainer:720) INFO: 87epoch:train:5601-5800batch: iter_time=2.303e-04, forward_time=0.137, uma_reduction=0.292, text_vs_uma=0.337, loss_ctc=3.980, loss=1.990, backward_time=0.187, optim_step_time=0.035, optim0_lr0=1.557e-04, train_time=0.900
[alab02] 2024-08-30 17:59:27,984 (trainer:720) INFO: 87epoch:train:5801-6000batch: iter_time=2.713e-04, forward_time=0.136, uma_reduction=0.304, text_vs_uma=0.319, loss_ctc=4.099, loss=2.050, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.557e-04, train_time=0.896
[alab02] 2024-08-30 18:00:03,159 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 18:00:58,184 (trainer:720) INFO: 87epoch:train:6001-6200batch: iter_time=2.515e-04, forward_time=0.137, uma_reduction=0.299, text_vs_uma=0.322, loss_ctc=3.846, loss=1.923, backward_time=0.186, optim_step_time=0.039, optim0_lr0=1.557e-04, train_time=0.902
[alab02] 2024-08-30 18:02:28,987 (trainer:720) INFO: 87epoch:train:6201-6400batch: iter_time=2.437e-04, forward_time=0.138, uma_reduction=0.286, text_vs_uma=0.340, loss_ctc=3.889, loss=1.944, backward_time=0.189, optim_step_time=0.038, optim0_lr0=1.557e-04, train_time=0.908
[alab02] 2024-08-30 18:03:59,983 (trainer:720) INFO: 87epoch:train:6401-6600batch: iter_time=2.794e-04, forward_time=0.138, uma_reduction=0.290, text_vs_uma=0.339, loss_ctc=4.124, loss=2.062, backward_time=0.188, optim_step_time=0.039, optim0_lr0=1.556e-04, train_time=0.910
[alab02] 2024-08-30 18:05:27,528 (trainer:720) INFO: 87epoch:train:6601-6800batch: iter_time=2.436e-04, forward_time=0.133, uma_reduction=0.291, text_vs_uma=0.334, loss_ctc=4.186, loss=2.093, backward_time=0.179, optim_step_time=0.038, optim0_lr0=1.556e-04, train_time=0.875
[alab02] 2024-08-30 18:06:55,651 (trainer:720) INFO: 87epoch:train:6801-7000batch: iter_time=2.667e-04, forward_time=0.133, uma_reduction=0.292, text_vs_uma=0.336, loss_ctc=4.010, loss=2.005, backward_time=0.180, optim_step_time=0.039, optim0_lr0=1.556e-04, train_time=0.881
[alab02] 2024-08-30 18:08:17,509 (trainer:338) INFO: 87epoch results: [train] iter_time=5.099e-04, forward_time=0.148, uma_reduction=0.288, text_vs_uma=0.337, loss_ctc=3.963, loss=1.981, backward_time=0.193, optim_step_time=0.047, optim0_lr0=1.560e-04, train_time=0.942, time=55 minutes and 57.24 seconds, total_count=619962, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.295, text_vs_uma=0.369, loss_ctc=3.184, cer_ctc=0.090, cer=0.090, loss=3.184, time=6.93 seconds, total_count=2262, gpu_max_cached_mem_GB=35.906, [att_plot] time=16.91 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 18:08:26,173 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 18:08:26,176 (trainer:272) INFO: 88/150epoch started. Estimated time to finish: 2 days, 9 hours and 21 minutes
[alab02] 2024-08-30 18:09:57,897 (trainer:720) INFO: 88epoch:train:1-200batch: iter_time=0.003, forward_time=0.138, uma_reduction=0.290, text_vs_uma=0.338, loss_ctc=3.863, loss=1.932, backward_time=0.190, optim_step_time=0.038, optim0_lr0=1.555e-04, train_time=0.917
[alab02] 2024-08-30 18:11:29,534 (trainer:720) INFO: 88epoch:train:201-400batch: iter_time=3.739e-04, forward_time=0.139, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=4.272, loss=2.136, backward_time=0.189, optim_step_time=0.040, optim0_lr0=1.555e-04, train_time=0.916
[alab02] 2024-08-30 18:12:59,795 (trainer:720) INFO: 88epoch:train:401-600batch: iter_time=2.718e-04, forward_time=0.136, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.811, loss=1.905, backward_time=0.190, optim_step_time=0.037, optim0_lr0=1.555e-04, train_time=0.902
[alab02] 2024-08-30 18:14:28,118 (trainer:720) INFO: 88epoch:train:601-800batch: iter_time=3.060e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.056, loss=2.028, backward_time=0.180, optim_step_time=0.039, optim0_lr0=1.555e-04, train_time=0.883
[alab02] 2024-08-30 18:15:58,998 (trainer:720) INFO: 88epoch:train:801-1000batch: iter_time=4.107e-04, forward_time=0.139, uma_reduction=0.297, text_vs_uma=0.325, loss_ctc=3.820, loss=1.910, backward_time=0.189, optim_step_time=0.041, optim0_lr0=1.554e-04, train_time=0.908
[alab02] 2024-08-30 18:17:30,379 (trainer:720) INFO: 88epoch:train:1001-1200batch: iter_time=2.564e-04, forward_time=0.139, uma_reduction=0.299, text_vs_uma=0.321, loss_ctc=3.575, loss=1.788, backward_time=0.193, optim_step_time=0.038, optim0_lr0=1.554e-04, train_time=0.913
[alab02] 2024-08-30 18:19:01,041 (trainer:720) INFO: 88epoch:train:1201-1400batch: iter_time=2.680e-04, forward_time=0.138, uma_reduction=0.293, text_vs_uma=0.325, loss_ctc=3.698, loss=1.849, backward_time=0.190, optim_step_time=0.038, optim0_lr0=1.554e-04, train_time=0.906
[alab02] 2024-08-30 18:20:31,515 (trainer:720) INFO: 88epoch:train:1401-1600batch: iter_time=3.390e-04, forward_time=0.137, uma_reduction=0.284, text_vs_uma=0.349, loss_ctc=4.301, loss=2.150, backward_time=0.186, optim_step_time=0.036, optim0_lr0=1.554e-04, train_time=0.904
[alab02] 2024-08-30 18:22:00,069 (trainer:720) INFO: 88epoch:train:1601-1800batch: iter_time=2.426e-04, forward_time=0.133, uma_reduction=0.282, text_vs_uma=0.347, loss_ctc=4.148, loss=2.074, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.553e-04, train_time=0.885
[alab02] 2024-08-30 18:23:26,406 (trainer:720) INFO: 88epoch:train:1801-2000batch: iter_time=2.338e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.832, loss=1.916, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.553e-04, train_time=0.863
[alab02] 2024-08-30 18:24:54,308 (trainer:720) INFO: 88epoch:train:2001-2200batch: iter_time=2.360e-04, forward_time=0.132, uma_reduction=0.285, text_vs_uma=0.337, loss_ctc=4.031, loss=2.016, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.553e-04, train_time=0.879
[alab02] 2024-08-30 18:26:24,115 (trainer:720) INFO: 88epoch:train:2201-2400batch: iter_time=2.682e-04, forward_time=0.134, uma_reduction=0.279, text_vs_uma=0.349, loss_ctc=3.813, loss=1.907, backward_time=0.187, optim_step_time=0.036, optim0_lr0=1.553e-04, train_time=0.898
[alab02] 2024-08-30 18:27:53,555 (trainer:720) INFO: 88epoch:train:2401-2600batch: iter_time=2.205e-04, forward_time=0.135, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=4.061, loss=2.030, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.552e-04, train_time=0.894
[alab02] 2024-08-30 18:29:21,653 (trainer:720) INFO: 88epoch:train:2601-2800batch: iter_time=2.234e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.943, loss=1.972, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.552e-04, train_time=0.881
[alab02] 2024-08-30 18:30:50,560 (trainer:720) INFO: 88epoch:train:2801-3000batch: iter_time=2.414e-04, forward_time=0.134, uma_reduction=0.268, text_vs_uma=0.369, loss_ctc=4.075, loss=2.037, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.552e-04, train_time=0.889
[alab02] 2024-08-30 18:32:18,961 (trainer:720) INFO: 88epoch:train:3001-3200batch: iter_time=2.251e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=4.069, loss=2.035, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.552e-04, train_time=0.884
[alab02] 2024-08-30 18:33:32,375 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 18:33:47,005 (trainer:720) INFO: 88epoch:train:3201-3400batch: iter_time=2.261e-04, forward_time=0.133, uma_reduction=0.279, text_vs_uma=0.355, loss_ctc=4.199, loss=2.100, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.551e-04, train_time=0.880
[alab02] 2024-08-30 18:35:16,410 (trainer:720) INFO: 88epoch:train:3401-3600batch: iter_time=2.240e-04, forward_time=0.135, uma_reduction=0.282, text_vs_uma=0.335, loss_ctc=4.265, loss=2.132, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.551e-04, train_time=0.894
[alab02] 2024-08-30 18:36:47,090 (trainer:720) INFO: 88epoch:train:3601-3800batch: iter_time=1.979e-04, forward_time=0.136, uma_reduction=0.294, text_vs_uma=0.327, loss_ctc=3.906, loss=1.953, backward_time=0.189, optim_step_time=0.035, optim0_lr0=1.551e-04, train_time=0.907
[alab02] 2024-08-30 18:38:14,844 (trainer:720) INFO: 88epoch:train:3801-4000batch: iter_time=2.181e-04, forward_time=0.133, uma_reduction=0.287, text_vs_uma=0.337, loss_ctc=3.839, loss=1.920, backward_time=0.181, optim_step_time=0.036, optim0_lr0=1.551e-04, train_time=0.877
[alab02] 2024-08-30 18:39:45,501 (trainer:720) INFO: 88epoch:train:4001-4200batch: iter_time=2.610e-04, forward_time=0.137, uma_reduction=0.289, text_vs_uma=0.334, loss_ctc=4.149, loss=2.075, backward_time=0.183, optim_step_time=0.045, optim0_lr0=1.550e-04, train_time=0.906
[alab02] 2024-08-30 18:40:25,989 (trainer:662) WARNING: The grad norm is inf. Skipping updating the model.
[alab02] 2024-08-30 18:41:12,412 (trainer:720) INFO: 88epoch:train:4201-4400batch: iter_time=2.039e-04, forward_time=0.133, uma_reduction=0.288, text_vs_uma=0.334, loss_ctc=3.857, loss=1.928, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.550e-04, train_time=0.869
[alab02] 2024-08-30 18:42:39,518 (trainer:720) INFO: 88epoch:train:4401-4600batch: iter_time=1.802e-04, forward_time=0.131, uma_reduction=0.289, text_vs_uma=0.333, loss_ctc=4.005, loss=2.002, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.550e-04, train_time=0.871
[alab02] 2024-08-30 18:44:07,037 (trainer:720) INFO: 88epoch:train:4601-4800batch: iter_time=1.818e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.342, loss_ctc=3.969, loss=1.985, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.550e-04, train_time=0.875
[alab02] 2024-08-30 18:45:34,583 (trainer:720) INFO: 88epoch:train:4801-5000batch: iter_time=2.015e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.351, loss_ctc=4.150, loss=2.075, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.549e-04, train_time=0.875
[alab02] 2024-08-30 18:47:00,307 (trainer:720) INFO: 88epoch:train:5001-5200batch: iter_time=1.850e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.345, loss_ctc=4.058, loss=2.029, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.549e-04, train_time=0.857
[alab02] 2024-08-30 18:48:27,478 (trainer:720) INFO: 88epoch:train:5201-5400batch: iter_time=1.871e-04, forward_time=0.131, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=4.160, loss=2.080, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.549e-04, train_time=0.871
[alab02] 2024-08-30 18:49:55,786 (trainer:720) INFO: 88epoch:train:5401-5600batch: iter_time=1.999e-04, forward_time=0.132, uma_reduction=0.275, text_vs_uma=0.351, loss_ctc=4.053, loss=2.027, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.549e-04, train_time=0.883
[alab02] 2024-08-30 18:51:22,722 (trainer:720) INFO: 88epoch:train:5601-5800batch: iter_time=1.827e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.344, loss_ctc=4.034, loss=2.017, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.548e-04, train_time=0.869
[alab02] 2024-08-30 18:52:49,578 (trainer:720) INFO: 88epoch:train:5801-6000batch: iter_time=1.800e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.338, loss_ctc=3.904, loss=1.952, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.548e-04, train_time=0.868
[alab02] 2024-08-30 18:54:16,503 (trainer:720) INFO: 88epoch:train:6001-6200batch: iter_time=1.846e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.350, loss_ctc=4.045, loss=2.023, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.548e-04, train_time=0.869
[alab02] 2024-08-30 18:55:44,735 (trainer:720) INFO: 88epoch:train:6201-6400batch: iter_time=1.924e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.353, loss_ctc=4.165, loss=2.082, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.548e-04, train_time=0.882
[alab02] 2024-08-30 18:57:12,342 (trainer:720) INFO: 88epoch:train:6401-6600batch: iter_time=1.898e-04, forward_time=0.131, uma_reduction=0.297, text_vs_uma=0.318, loss_ctc=3.876, loss=1.938, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.547e-04, train_time=0.876
[alab02] 2024-08-30 18:58:39,047 (trainer:720) INFO: 88epoch:train:6601-6800batch: iter_time=1.815e-04, forward_time=0.129, uma_reduction=0.313, text_vs_uma=0.312, loss_ctc=3.837, loss=1.919, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.547e-04, train_time=0.867
[alab02] 2024-08-30 19:00:05,486 (trainer:720) INFO: 88epoch:train:6801-7000batch: iter_time=2.248e-04, forward_time=0.129, uma_reduction=0.295, text_vs_uma=0.328, loss_ctc=3.702, loss=1.851, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.547e-04, train_time=0.864
[alab02] 2024-08-30 19:01:21,089 (trainer:338) INFO: 88epoch results: [train] iter_time=3.101e-04, forward_time=0.133, uma_reduction=0.284, text_vs_uma=0.341, loss_ctc=3.980, loss=1.990, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.551e-04, train_time=0.885, time=52 minutes and 35.03 seconds, total_count=627088, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.308, text_vs_uma=0.353, loss_ctc=3.091, cer_ctc=0.084, cer=0.084, loss=3.091, time=6.08 seconds, total_count=2288, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.81 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 19:01:26,432 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 19:01:26,531 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/54epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/87epoch.pth
[alab02] 2024-08-30 19:01:26,531 (trainer:272) INFO: 89/150epoch started. Estimated time to finish: 2 days, 8 hours and 25 minutes
[alab02] 2024-08-30 19:02:54,254 (trainer:720) INFO: 89epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.296, text_vs_uma=0.335, loss_ctc=4.002, loss=2.001, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.547e-04, train_time=0.877
[alab02] 2024-08-30 19:04:18,632 (trainer:720) INFO: 89epoch:train:201-400batch: iter_time=1.967e-04, forward_time=0.125, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=4.012, loss=2.006, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.546e-04, train_time=0.844
[alab02] 2024-08-30 19:05:46,164 (trainer:720) INFO: 89epoch:train:401-600batch: iter_time=2.064e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=4.122, loss=2.061, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.546e-04, train_time=0.875
[alab02] 2024-08-30 19:07:14,747 (trainer:720) INFO: 89epoch:train:601-800batch: iter_time=1.989e-04, forward_time=0.132, uma_reduction=0.286, text_vs_uma=0.326, loss_ctc=3.821, loss=1.910, backward_time=0.188, optim_step_time=0.032, optim0_lr0=1.546e-04, train_time=0.886
[alab02] 2024-08-30 19:08:38,263 (trainer:720) INFO: 89epoch:train:801-1000batch: iter_time=1.901e-04, forward_time=0.123, uma_reduction=0.292, text_vs_uma=0.331, loss_ctc=3.783, loss=1.892, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.546e-04, train_time=0.835
[alab02] 2024-08-30 19:10:04,287 (trainer:720) INFO: 89epoch:train:1001-1200batch: iter_time=1.962e-04, forward_time=0.128, uma_reduction=0.283, text_vs_uma=0.349, loss_ctc=4.544, loss=2.272, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.545e-04, train_time=0.860
[alab02] 2024-08-30 19:11:30,562 (trainer:720) INFO: 89epoch:train:1201-1400batch: iter_time=1.855e-04, forward_time=0.128, uma_reduction=0.288, text_vs_uma=0.338, loss_ctc=3.719, loss=1.859, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.545e-04, train_time=0.863
[alab02] 2024-08-30 19:12:55,166 (trainer:720) INFO: 89epoch:train:1401-1600batch: iter_time=1.816e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=4.028, loss=2.014, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.545e-04, train_time=0.846
[alab02] 2024-08-30 19:14:20,390 (trainer:720) INFO: 89epoch:train:1601-1800batch: iter_time=1.757e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.350, loss_ctc=3.893, loss=1.946, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.545e-04, train_time=0.852
[alab02] 2024-08-30 19:15:46,496 (trainer:720) INFO: 89epoch:train:1801-2000batch: iter_time=1.806e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=4.142, loss=2.071, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.544e-04, train_time=0.861
[alab02] 2024-08-30 19:17:12,516 (trainer:720) INFO: 89epoch:train:2001-2200batch: iter_time=1.734e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.339, loss_ctc=4.031, loss=2.016, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.544e-04, train_time=0.860
[alab02] 2024-08-30 19:18:37,478 (trainer:720) INFO: 89epoch:train:2201-2400batch: iter_time=1.741e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.344, loss_ctc=3.826, loss=1.913, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.544e-04, train_time=0.849
[alab02] 2024-08-30 19:20:04,487 (trainer:720) INFO: 89epoch:train:2401-2600batch: iter_time=1.854e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=4.129, loss=2.064, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.544e-04, train_time=0.870
[alab02] 2024-08-30 19:21:29,954 (trainer:720) INFO: 89epoch:train:2601-2800batch: iter_time=1.896e-04, forward_time=0.127, uma_reduction=0.263, text_vs_uma=0.376, loss_ctc=4.277, loss=2.138, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.543e-04, train_time=0.854
[alab02] 2024-08-30 19:22:57,214 (trainer:720) INFO: 89epoch:train:2801-3000batch: iter_time=1.839e-04, forward_time=0.130, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=4.014, loss=2.007, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.543e-04, train_time=0.872
[alab02] 2024-08-30 19:24:23,784 (trainer:720) INFO: 89epoch:train:3001-3200batch: iter_time=1.795e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.358, loss_ctc=4.072, loss=2.036, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.543e-04, train_time=0.865
[alab02] 2024-08-30 19:25:52,106 (trainer:720) INFO: 89epoch:train:3201-3400batch: iter_time=1.791e-04, forward_time=0.132, uma_reduction=0.277, text_vs_uma=0.342, loss_ctc=3.962, loss=1.981, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.543e-04, train_time=0.883
[alab02] 2024-08-30 19:27:17,949 (trainer:720) INFO: 89epoch:train:3401-3600batch: iter_time=1.753e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=4.094, loss=2.047, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.542e-04, train_time=0.858
[alab02] 2024-08-30 19:28:44,935 (trainer:720) INFO: 89epoch:train:3601-3800batch: iter_time=1.729e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=3.968, loss=1.984, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.542e-04, train_time=0.870
[alab02] 2024-08-30 19:30:12,893 (trainer:720) INFO: 89epoch:train:3801-4000batch: iter_time=1.710e-04, forward_time=0.131, uma_reduction=0.283, text_vs_uma=0.346, loss_ctc=4.215, loss=2.108, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.542e-04, train_time=0.879
[alab02] 2024-08-30 19:31:38,752 (trainer:720) INFO: 89epoch:train:4001-4200batch: iter_time=1.792e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=3.610, loss=1.805, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.542e-04, train_time=0.858
[alab02] 2024-08-30 19:33:04,337 (trainer:720) INFO: 89epoch:train:4201-4400batch: iter_time=1.783e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.360, loss_ctc=4.122, loss=2.061, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.541e-04, train_time=0.856
[alab02] 2024-08-30 19:34:33,249 (trainer:720) INFO: 89epoch:train:4401-4600batch: iter_time=2.331e-04, forward_time=0.134, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=4.081, loss=2.040, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.541e-04, train_time=0.889
[alab02] 2024-08-30 19:36:00,955 (trainer:720) INFO: 89epoch:train:4601-4800batch: iter_time=2.341e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.344, loss_ctc=4.136, loss=2.068, backward_time=0.178, optim_step_time=0.039, optim0_lr0=1.541e-04, train_time=0.877
[alab02] 2024-08-30 19:37:28,986 (trainer:720) INFO: 89epoch:train:4801-5000batch: iter_time=2.438e-04, forward_time=0.134, uma_reduction=0.291, text_vs_uma=0.330, loss_ctc=3.821, loss=1.910, backward_time=0.182, optim_step_time=0.036, optim0_lr0=1.541e-04, train_time=0.880
[alab02] 2024-08-30 19:38:57,749 (trainer:720) INFO: 89epoch:train:5001-5200batch: iter_time=2.304e-04, forward_time=0.134, uma_reduction=0.288, text_vs_uma=0.341, loss_ctc=3.641, loss=1.820, backward_time=0.185, optim_step_time=0.037, optim0_lr0=1.540e-04, train_time=0.887
[alab02] 2024-08-30 19:40:30,283 (trainer:720) INFO: 89epoch:train:5201-5400batch: iter_time=2.212e-04, forward_time=0.142, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.999, loss=2.000, backward_time=0.191, optim_step_time=0.043, optim0_lr0=1.540e-04, train_time=0.925
[alab02] 2024-08-30 19:41:59,119 (trainer:720) INFO: 89epoch:train:5401-5600batch: iter_time=2.028e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=3.976, loss=1.988, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.540e-04, train_time=0.888
[alab02] 2024-08-30 19:43:26,020 (trainer:720) INFO: 89epoch:train:5601-5800batch: iter_time=1.953e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=3.888, loss=1.944, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.540e-04, train_time=0.869
[alab02] 2024-08-30 19:44:51,882 (trainer:720) INFO: 89epoch:train:5801-6000batch: iter_time=1.874e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.026, loss=2.013, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.539e-04, train_time=0.858
[alab02] 2024-08-30 19:46:21,018 (trainer:720) INFO: 89epoch:train:6001-6200batch: iter_time=1.992e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=4.351, loss=2.175, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.539e-04, train_time=0.891
[alab02] 2024-08-30 19:47:50,068 (trainer:720) INFO: 89epoch:train:6201-6400batch: iter_time=2.368e-04, forward_time=0.133, uma_reduction=0.256, text_vs_uma=0.385, loss_ctc=4.233, loss=2.117, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.539e-04, train_time=0.890
[alab02] 2024-08-30 19:49:19,294 (trainer:720) INFO: 89epoch:train:6401-6600batch: iter_time=2.221e-04, forward_time=0.133, uma_reduction=0.267, text_vs_uma=0.353, loss_ctc=3.830, loss=1.915, backward_time=0.186, optim_step_time=0.036, optim0_lr0=1.539e-04, train_time=0.892
[alab02] 2024-08-30 19:50:45,298 (trainer:720) INFO: 89epoch:train:6601-6800batch: iter_time=1.840e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.348, loss_ctc=3.907, loss=1.954, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.539e-04, train_time=0.860
[alab02] 2024-08-30 19:52:12,169 (trainer:720) INFO: 89epoch:train:6801-7000batch: iter_time=1.966e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.371, loss_ctc=4.184, loss=2.092, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.538e-04, train_time=0.868
[alab02] 2024-08-30 19:53:30,272 (trainer:338) INFO: 89epoch results: [train] iter_time=2.514e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.004, loss=2.002, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.542e-04, train_time=0.870, time=51 minutes and 42.33 seconds, total_count=634214, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.287, text_vs_uma=0.378, loss_ctc=3.235, cer_ctc=0.088, cer=0.088, loss=3.235, time=6.42 seconds, total_count=2314, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.99 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 19:53:50,140 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 19:53:50,206 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/64epoch.pth
[alab02] 2024-08-30 19:53:50,209 (trainer:272) INFO: 90/150epoch started. Estimated time to finish: 2 days, 7 hours and 29 minutes
[alab02] 2024-08-30 19:55:22,713 (trainer:720) INFO: 90epoch:train:1-200batch: iter_time=0.004, forward_time=0.137, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.887, loss=1.944, backward_time=0.191, optim_step_time=0.036, optim0_lr0=1.538e-04, train_time=0.925
[alab02] 2024-08-30 19:56:32,381 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 19:56:50,381 (trainer:720) INFO: 90epoch:train:201-400batch: iter_time=2.570e-04, forward_time=0.132, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.745, loss=1.872, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.538e-04, train_time=0.876
[alab02] 2024-08-30 19:58:18,593 (trainer:720) INFO: 90epoch:train:401-600batch: iter_time=2.286e-04, forward_time=0.132, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=4.123, loss=2.062, backward_time=0.181, optim_step_time=0.038, optim0_lr0=1.537e-04, train_time=0.882
[alab02] 2024-08-30 19:59:45,207 (trainer:720) INFO: 90epoch:train:601-800batch: iter_time=2.299e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=4.135, loss=2.068, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.537e-04, train_time=0.866
[alab02] 2024-08-30 20:01:15,558 (trainer:720) INFO: 90epoch:train:801-1000batch: iter_time=2.917e-04, forward_time=0.137, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=4.114, loss=2.057, backward_time=0.187, optim_step_time=0.035, optim0_lr0=1.537e-04, train_time=0.903
[alab02] 2024-08-30 20:02:44,034 (trainer:720) INFO: 90epoch:train:1001-1200batch: iter_time=2.195e-04, forward_time=0.132, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=3.536, loss=1.768, backward_time=0.188, optim_step_time=0.035, optim0_lr0=1.537e-04, train_time=0.884
[alab02] 2024-08-30 20:04:12,140 (trainer:720) INFO: 90epoch:train:1201-1400batch: iter_time=2.021e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=4.311, loss=2.155, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.536e-04, train_time=0.881
[alab02] 2024-08-30 20:05:38,440 (trainer:720) INFO: 90epoch:train:1401-1600batch: iter_time=1.775e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.368, loss_ctc=4.118, loss=2.059, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.536e-04, train_time=0.863
[alab02] 2024-08-30 20:07:01,115 (trainer:720) INFO: 90epoch:train:1601-1800batch: iter_time=1.837e-04, forward_time=0.123, uma_reduction=0.266, text_vs_uma=0.367, loss_ctc=4.067, loss=2.034, backward_time=0.169, optim_step_time=0.031, optim0_lr0=1.536e-04, train_time=0.827
[alab02] 2024-08-30 20:08:25,846 (trainer:720) INFO: 90epoch:train:1801-2000batch: iter_time=1.768e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.367, loss_ctc=4.090, loss=2.045, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.536e-04, train_time=0.847
[alab02] 2024-08-30 20:09:53,359 (trainer:720) INFO: 90epoch:train:2001-2200batch: iter_time=1.828e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=4.043, loss=2.021, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.535e-04, train_time=0.875
[alab02] 2024-08-30 20:11:19,883 (trainer:720) INFO: 90epoch:train:2201-2400batch: iter_time=1.773e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.871, loss=1.936, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.535e-04, train_time=0.865
[alab02] 2024-08-30 20:12:46,202 (trainer:720) INFO: 90epoch:train:2401-2600batch: iter_time=1.787e-04, forward_time=0.128, uma_reduction=0.283, text_vs_uma=0.341, loss_ctc=4.355, loss=2.177, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.535e-04, train_time=0.863
[alab02] 2024-08-30 20:14:12,067 (trainer:720) INFO: 90epoch:train:2601-2800batch: iter_time=1.713e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.851, loss=1.925, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.535e-04, train_time=0.858
[alab02] 2024-08-30 20:15:39,804 (trainer:720) INFO: 90epoch:train:2801-3000batch: iter_time=1.753e-04, forward_time=0.130, uma_reduction=0.288, text_vs_uma=0.342, loss_ctc=4.059, loss=2.029, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.534e-04, train_time=0.877
[alab02] 2024-08-30 20:17:04,925 (trainer:720) INFO: 90epoch:train:3001-3200batch: iter_time=1.673e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=4.052, loss=2.026, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.534e-04, train_time=0.851
[alab02] 2024-08-30 20:18:30,826 (trainer:720) INFO: 90epoch:train:3201-3400batch: iter_time=1.645e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.883, loss=1.941, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.534e-04, train_time=0.859
[alab02] 2024-08-30 20:19:57,165 (trainer:720) INFO: 90epoch:train:3401-3600batch: iter_time=1.593e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=4.289, loss=2.144, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.534e-04, train_time=0.863
[alab02] 2024-08-30 20:21:23,111 (trainer:720) INFO: 90epoch:train:3601-3800batch: iter_time=1.602e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.369, loss_ctc=4.081, loss=2.040, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.534e-04, train_time=0.859
[alab02] 2024-08-30 20:22:49,207 (trainer:720) INFO: 90epoch:train:3801-4000batch: iter_time=1.606e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=4.085, loss=2.043, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.533e-04, train_time=0.861
[alab02] 2024-08-30 20:24:16,466 (trainer:720) INFO: 90epoch:train:4001-4200batch: iter_time=1.567e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.950, loss=1.975, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.533e-04, train_time=0.872
[alab02] 2024-08-30 20:25:41,762 (trainer:720) INFO: 90epoch:train:4201-4400batch: iter_time=1.630e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=4.109, loss=2.055, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.533e-04, train_time=0.853
[alab02] 2024-08-30 20:27:08,135 (trainer:720) INFO: 90epoch:train:4401-4600batch: iter_time=1.682e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.170, loss=2.085, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.533e-04, train_time=0.864
[alab02] 2024-08-30 20:28:35,144 (trainer:720) INFO: 90epoch:train:4601-4800batch: iter_time=1.651e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.371, loss_ctc=4.318, loss=2.159, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.532e-04, train_time=0.870
[alab02] 2024-08-30 20:30:01,280 (trainer:720) INFO: 90epoch:train:4801-5000batch: iter_time=1.612e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.366, loss_ctc=4.590, loss=2.295, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.532e-04, train_time=0.861
[alab02] 2024-08-30 20:31:25,866 (trainer:720) INFO: 90epoch:train:5001-5200batch: iter_time=1.581e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.943, loss=1.972, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.532e-04, train_time=0.846
[alab02] 2024-08-30 20:32:50,842 (trainer:720) INFO: 90epoch:train:5201-5400batch: iter_time=1.581e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=3.988, loss=1.994, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.532e-04, train_time=0.850
[alab02] 2024-08-30 20:34:16,112 (trainer:720) INFO: 90epoch:train:5401-5600batch: iter_time=1.552e-04, forward_time=0.127, uma_reduction=0.285, text_vs_uma=0.339, loss_ctc=3.971, loss=1.985, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.531e-04, train_time=0.852
[alab02] 2024-08-30 20:35:41,141 (trainer:720) INFO: 90epoch:train:5601-5800batch: iter_time=1.629e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.336, loss_ctc=3.976, loss=1.988, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.531e-04, train_time=0.850
[alab02] 2024-08-30 20:37:05,944 (trainer:720) INFO: 90epoch:train:5801-6000batch: iter_time=1.566e-04, forward_time=0.126, uma_reduction=0.290, text_vs_uma=0.337, loss_ctc=3.950, loss=1.975, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.531e-04, train_time=0.848
[alab02] 2024-08-30 20:38:32,146 (trainer:720) INFO: 90epoch:train:6001-6200batch: iter_time=1.703e-04, forward_time=0.128, uma_reduction=0.291, text_vs_uma=0.328, loss_ctc=3.765, loss=1.882, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.531e-04, train_time=0.862
[alab02] 2024-08-30 20:39:57,190 (trainer:720) INFO: 90epoch:train:6201-6400batch: iter_time=1.690e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=3.892, loss=1.946, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.530e-04, train_time=0.850
[alab02] 2024-08-30 20:41:21,779 (trainer:720) INFO: 90epoch:train:6401-6600batch: iter_time=1.613e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=3.992, loss=1.996, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.530e-04, train_time=0.846
[alab02] 2024-08-30 20:42:47,566 (trainer:720) INFO: 90epoch:train:6601-6800batch: iter_time=1.599e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.346, loss_ctc=3.788, loss=1.894, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.530e-04, train_time=0.858
[alab02] 2024-08-30 20:44:13,355 (trainer:720) INFO: 90epoch:train:6801-7000batch: iter_time=1.668e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=4.048, loss=2.024, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.530e-04, train_time=0.858
[alab02] 2024-08-30 20:45:27,615 (trainer:338) INFO: 90epoch results: [train] iter_time=2.724e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=4.030, loss=2.015, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.534e-04, train_time=0.864, time=51 minutes and 18.2 seconds, total_count=641340, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.280, text_vs_uma=0.388, loss_ctc=3.175, cer_ctc=0.087, cer=0.087, loss=3.175, time=5.95 seconds, total_count=2340, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.26 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 20:45:33,230 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 20:45:33,237 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/83epoch.pth
[alab02] 2024-08-30 20:45:33,238 (trainer:272) INFO: 91/150epoch started. Estimated time to finish: 2 days, 6 hours and 32 minutes
[alab02] 2024-08-30 20:46:58,529 (trainer:720) INFO: 91epoch:train:1-200batch: iter_time=0.002, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=3.882, loss=1.941, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.529e-04, train_time=0.853
[alab02] 2024-08-30 20:48:23,932 (trainer:720) INFO: 91epoch:train:201-400batch: iter_time=1.797e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.337, loss_ctc=3.500, loss=1.750, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.529e-04, train_time=0.854
[alab02] 2024-08-30 20:49:50,606 (trainer:720) INFO: 91epoch:train:401-600batch: iter_time=1.903e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.338, loss_ctc=4.017, loss=2.009, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.529e-04, train_time=0.866
[alab02] 2024-08-30 20:51:18,133 (trainer:720) INFO: 91epoch:train:601-800batch: iter_time=1.787e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.589, loss=1.795, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.529e-04, train_time=0.875
[alab02] 2024-08-30 20:52:45,715 (trainer:720) INFO: 91epoch:train:801-1000batch: iter_time=1.677e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=4.180, loss=2.090, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.528e-04, train_time=0.876
[alab02] 2024-08-30 20:54:13,147 (trainer:720) INFO: 91epoch:train:1001-1200batch: iter_time=1.596e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.973, loss=1.987, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.528e-04, train_time=0.874
[alab02] 2024-08-30 20:55:38,632 (trainer:720) INFO: 91epoch:train:1201-1400batch: iter_time=1.487e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.593, loss=1.796, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.528e-04, train_time=0.855
[alab02] 2024-08-30 20:55:47,385 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 20:57:04,313 (trainer:720) INFO: 91epoch:train:1401-1600batch: iter_time=1.657e-04, forward_time=0.127, uma_reduction=0.285, text_vs_uma=0.332, loss_ctc=3.544, loss=1.772, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.528e-04, train_time=0.857
[alab02] 2024-08-30 20:58:30,116 (trainer:720) INFO: 91epoch:train:1601-1800batch: iter_time=1.706e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=4.181, loss=2.090, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.527e-04, train_time=0.858
[alab02] 2024-08-30 20:59:55,819 (trainer:720) INFO: 91epoch:train:1801-2000batch: iter_time=1.611e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.345, loss_ctc=3.624, loss=1.812, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.527e-04, train_time=0.857
[alab02] 2024-08-30 21:01:20,193 (trainer:720) INFO: 91epoch:train:2001-2200batch: iter_time=1.616e-04, forward_time=0.125, uma_reduction=0.288, text_vs_uma=0.329, loss_ctc=3.490, loss=1.745, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.527e-04, train_time=0.844
[alab02] 2024-08-30 21:02:48,852 (trainer:720) INFO: 91epoch:train:2201-2400batch: iter_time=1.582e-04, forward_time=0.132, uma_reduction=0.289, text_vs_uma=0.333, loss_ctc=3.978, loss=1.989, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.527e-04, train_time=0.886
[alab02] 2024-08-30 21:04:14,978 (trainer:720) INFO: 91epoch:train:2401-2600batch: iter_time=1.544e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.330, loss_ctc=3.563, loss=1.781, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.526e-04, train_time=0.861
[alab02] 2024-08-30 21:05:38,071 (trainer:720) INFO: 91epoch:train:2601-2800batch: iter_time=1.512e-04, forward_time=0.123, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.749, loss=1.874, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.526e-04, train_time=0.831
[alab02] 2024-08-30 21:07:01,313 (trainer:720) INFO: 91epoch:train:2801-3000batch: iter_time=1.596e-04, forward_time=0.124, uma_reduction=0.281, text_vs_uma=0.349, loss_ctc=4.244, loss=2.122, backward_time=0.169, optim_step_time=0.030, optim0_lr0=1.526e-04, train_time=0.832
[alab02] 2024-08-30 21:08:27,089 (trainer:720) INFO: 91epoch:train:3001-3200batch: iter_time=1.528e-04, forward_time=0.126, uma_reduction=0.301, text_vs_uma=0.321, loss_ctc=3.692, loss=1.846, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.526e-04, train_time=0.857
[alab02] 2024-08-30 21:09:51,508 (trainer:720) INFO: 91epoch:train:3201-3400batch: iter_time=1.470e-04, forward_time=0.124, uma_reduction=0.290, text_vs_uma=0.326, loss_ctc=4.105, loss=2.053, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.526e-04, train_time=0.844
[alab02] 2024-08-30 21:11:17,680 (trainer:720) INFO: 91epoch:train:3401-3600batch: iter_time=1.705e-04, forward_time=0.127, uma_reduction=0.291, text_vs_uma=0.337, loss_ctc=3.767, loss=1.883, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.525e-04, train_time=0.862
[alab02] 2024-08-30 21:12:42,383 (trainer:720) INFO: 91epoch:train:3601-3800batch: iter_time=1.555e-04, forward_time=0.126, uma_reduction=0.293, text_vs_uma=0.330, loss_ctc=3.594, loss=1.797, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.525e-04, train_time=0.847
[alab02] 2024-08-30 21:14:07,461 (trainer:720) INFO: 91epoch:train:3801-4000batch: iter_time=1.694e-04, forward_time=0.126, uma_reduction=0.283, text_vs_uma=0.337, loss_ctc=3.375, loss=1.688, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.525e-04, train_time=0.851
[alab02] 2024-08-30 21:15:33,847 (trainer:720) INFO: 91epoch:train:4001-4200batch: iter_time=1.652e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.339, loss_ctc=3.796, loss=1.898, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.525e-04, train_time=0.864
[alab02] 2024-08-30 21:16:59,094 (trainer:720) INFO: 91epoch:train:4201-4400batch: iter_time=1.676e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.340, loss_ctc=4.306, loss=2.153, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.524e-04, train_time=0.852
[alab02] 2024-08-30 21:18:25,946 (trainer:720) INFO: 91epoch:train:4401-4600batch: iter_time=1.740e-04, forward_time=0.128, uma_reduction=0.295, text_vs_uma=0.335, loss_ctc=3.911, loss=1.955, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.524e-04, train_time=0.868
[alab02] 2024-08-30 21:19:52,441 (trainer:720) INFO: 91epoch:train:4601-4800batch: iter_time=1.668e-04, forward_time=0.128, uma_reduction=0.294, text_vs_uma=0.335, loss_ctc=3.820, loss=1.910, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.524e-04, train_time=0.865
[alab02] 2024-08-30 21:21:19,068 (trainer:720) INFO: 91epoch:train:4801-5000batch: iter_time=1.651e-04, forward_time=0.129, uma_reduction=0.300, text_vs_uma=0.321, loss_ctc=3.489, loss=1.744, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.524e-04, train_time=0.866
[alab02] 2024-08-30 21:22:45,646 (trainer:720) INFO: 91epoch:train:5001-5200batch: iter_time=1.547e-04, forward_time=0.128, uma_reduction=0.298, text_vs_uma=0.330, loss_ctc=4.018, loss=2.009, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.523e-04, train_time=0.866
[alab02] 2024-08-30 21:24:11,691 (trainer:720) INFO: 91epoch:train:5201-5400batch: iter_time=1.655e-04, forward_time=0.127, uma_reduction=0.297, text_vs_uma=0.325, loss_ctc=3.560, loss=1.780, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.523e-04, train_time=0.860
[alab02] 2024-08-30 21:25:39,304 (trainer:720) INFO: 91epoch:train:5401-5600batch: iter_time=1.628e-04, forward_time=0.129, uma_reduction=0.302, text_vs_uma=0.322, loss_ctc=3.852, loss=1.926, backward_time=0.185, optim_step_time=0.032, optim0_lr0=1.523e-04, train_time=0.876
[alab02] 2024-08-30 21:25:51,796 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 21:27:04,115 (trainer:720) INFO: 91epoch:train:5601-5800batch: iter_time=1.643e-04, forward_time=0.126, uma_reduction=0.302, text_vs_uma=0.317, loss_ctc=3.930, loss=1.965, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.523e-04, train_time=0.848
[alab02] 2024-08-30 21:28:33,237 (trainer:720) INFO: 91epoch:train:5801-6000batch: iter_time=1.707e-04, forward_time=0.133, uma_reduction=0.294, text_vs_uma=0.329, loss_ctc=3.818, loss=1.909, backward_time=0.187, optim_step_time=0.032, optim0_lr0=1.522e-04, train_time=0.891
[alab02] 2024-08-30 21:30:04,300 (trainer:720) INFO: 91epoch:train:6001-6200batch: iter_time=2.410e-04, forward_time=0.138, uma_reduction=0.295, text_vs_uma=0.333, loss_ctc=4.033, loss=2.016, backward_time=0.188, optim_step_time=0.041, optim0_lr0=1.522e-04, train_time=0.910
[alab02] 2024-08-30 21:31:40,442 (trainer:720) INFO: 91epoch:train:6201-6400batch: iter_time=3.718e-04, forward_time=0.151, uma_reduction=0.290, text_vs_uma=0.338, loss_ctc=3.900, loss=1.950, backward_time=0.193, optim_step_time=0.055, optim0_lr0=1.522e-04, train_time=0.961
[alab02] 2024-08-30 21:33:16,125 (trainer:720) INFO: 91epoch:train:6401-6600batch: iter_time=3.520e-04, forward_time=0.149, uma_reduction=0.294, text_vs_uma=0.331, loss_ctc=3.715, loss=1.858, backward_time=0.194, optim_step_time=0.052, optim0_lr0=1.522e-04, train_time=0.956
[alab02] 2024-08-30 21:34:52,985 (trainer:720) INFO: 91epoch:train:6601-6800batch: iter_time=3.486e-04, forward_time=0.151, uma_reduction=0.299, text_vs_uma=0.327, loss_ctc=3.860, loss=1.930, backward_time=0.199, optim_step_time=0.051, optim0_lr0=1.522e-04, train_time=0.968
[alab02] 2024-08-30 21:36:29,287 (trainer:720) INFO: 91epoch:train:6801-7000batch: iter_time=3.867e-04, forward_time=0.151, uma_reduction=0.290, text_vs_uma=0.327, loss_ctc=3.927, loss=1.963, backward_time=0.194, optim_step_time=0.052, optim0_lr0=1.521e-04, train_time=0.963
[alab02] 2024-08-30 21:37:56,549 (trainer:338) INFO: 91epoch results: [train] iter_time=2.355e-04, forward_time=0.131, uma_reduction=0.288, text_vs_uma=0.336, loss_ctc=3.815, loss=1.907, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.525e-04, train_time=0.874, time=51 minutes and 55.53 seconds, total_count=648466, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.305, text_vs_uma=0.357, loss_ctc=3.161, cer_ctc=0.088, cer=0.088, loss=3.161, time=6.78 seconds, total_count=2366, gpu_max_cached_mem_GB=35.906, [att_plot] time=21 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 21:38:04,040 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 21:38:04,046 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/79epoch.pth
[alab02] 2024-08-30 21:38:04,047 (trainer:272) INFO: 92/150epoch started. Estimated time to finish: 2 days, 5 hours and 36 minutes
[alab02] 2024-08-30 21:39:39,874 (trainer:720) INFO: 92epoch:train:1-200batch: iter_time=0.004, forward_time=0.148, uma_reduction=0.285, text_vs_uma=0.346, loss_ctc=3.873, loss=1.936, backward_time=0.189, optim_step_time=0.053, optim0_lr0=1.521e-04, train_time=0.958
[alab02] 2024-08-30 21:41:13,839 (trainer:720) INFO: 92epoch:train:201-400batch: iter_time=3.573e-04, forward_time=0.147, uma_reduction=0.286, text_vs_uma=0.342, loss_ctc=3.901, loss=1.950, backward_time=0.192, optim_step_time=0.049, optim0_lr0=1.521e-04, train_time=0.939
[alab02] 2024-08-30 21:42:49,828 (trainer:720) INFO: 92epoch:train:401-600batch: iter_time=3.942e-04, forward_time=0.153, uma_reduction=0.287, text_vs_uma=0.333, loss_ctc=3.817, loss=1.909, backward_time=0.192, optim_step_time=0.054, optim0_lr0=1.520e-04, train_time=0.959
[alab02] 2024-08-30 21:44:26,151 (trainer:720) INFO: 92epoch:train:601-800batch: iter_time=5.493e-04, forward_time=0.150, uma_reduction=0.299, text_vs_uma=0.325, loss_ctc=3.887, loss=1.943, backward_time=0.195, optim_step_time=0.052, optim0_lr0=1.520e-04, train_time=0.963
[alab02] 2024-08-30 21:46:00,773 (trainer:720) INFO: 92epoch:train:801-1000batch: iter_time=5.254e-04, forward_time=0.147, uma_reduction=0.304, text_vs_uma=0.313, loss_ctc=3.798, loss=1.899, backward_time=0.190, optim_step_time=0.050, optim0_lr0=1.520e-04, train_time=0.946
[alab02] 2024-08-30 21:47:33,524 (trainer:720) INFO: 92epoch:train:1001-1200batch: iter_time=3.767e-04, forward_time=0.143, uma_reduction=0.298, text_vs_uma=0.331, loss_ctc=4.046, loss=2.023, backward_time=0.184, optim_step_time=0.048, optim0_lr0=1.520e-04, train_time=0.927
[alab02] 2024-08-30 21:49:07,116 (trainer:720) INFO: 92epoch:train:1201-1400batch: iter_time=4.367e-04, forward_time=0.145, uma_reduction=0.290, text_vs_uma=0.344, loss_ctc=4.149, loss=2.074, backward_time=0.188, optim_step_time=0.046, optim0_lr0=1.519e-04, train_time=0.936
[alab02] 2024-08-30 21:50:40,891 (trainer:720) INFO: 92epoch:train:1401-1600batch: iter_time=4.771e-04, forward_time=0.145, uma_reduction=0.288, text_vs_uma=0.335, loss_ctc=3.952, loss=1.976, backward_time=0.191, optim_step_time=0.047, optim0_lr0=1.519e-04, train_time=0.937
[alab02] 2024-08-30 21:52:21,871 (trainer:720) INFO: 92epoch:train:1601-1800batch: iter_time=8.131e-04, forward_time=0.164, uma_reduction=0.277, text_vs_uma=0.353, loss_ctc=3.965, loss=1.983, backward_time=0.200, optim_step_time=0.062, optim0_lr0=1.519e-04, train_time=1.009
[alab02] 2024-08-30 21:53:00,122 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 21:53:59,158 (trainer:720) INFO: 92epoch:train:1801-2000batch: iter_time=5.383e-04, forward_time=0.155, uma_reduction=0.283, text_vs_uma=0.345, loss_ctc=3.923, loss=1.962, backward_time=0.194, optim_step_time=0.056, optim0_lr0=1.519e-04, train_time=0.972
[alab02] 2024-08-30 21:55:37,930 (trainer:720) INFO: 92epoch:train:2001-2200batch: iter_time=5.581e-04, forward_time=0.157, uma_reduction=0.291, text_vs_uma=0.329, loss_ctc=3.791, loss=1.896, backward_time=0.198, optim_step_time=0.058, optim0_lr0=1.519e-04, train_time=0.987
[alab02] 2024-08-30 21:57:17,310 (trainer:720) INFO: 92epoch:train:2201-2400batch: iter_time=6.592e-04, forward_time=0.157, uma_reduction=0.297, text_vs_uma=0.324, loss_ctc=3.852, loss=1.926, backward_time=0.196, optim_step_time=0.064, optim0_lr0=1.518e-04, train_time=0.993
[alab02] 2024-08-30 21:58:56,567 (trainer:720) INFO: 92epoch:train:2401-2600batch: iter_time=6.078e-04, forward_time=0.157, uma_reduction=0.289, text_vs_uma=0.337, loss_ctc=4.158, loss=2.079, backward_time=0.197, optim_step_time=0.059, optim0_lr0=1.518e-04, train_time=0.992
[alab02] 2024-08-30 22:00:38,677 (trainer:720) INFO: 92epoch:train:2601-2800batch: iter_time=6.307e-04, forward_time=0.165, uma_reduction=0.302, text_vs_uma=0.319, loss_ctc=3.648, loss=1.824, backward_time=0.204, optim_step_time=0.064, optim0_lr0=1.518e-04, train_time=1.021
[alab02] 2024-08-30 22:02:20,417 (trainer:720) INFO: 92epoch:train:2801-3000batch: iter_time=7.664e-04, forward_time=0.162, uma_reduction=0.288, text_vs_uma=0.336, loss_ctc=4.084, loss=2.042, backward_time=0.204, optim_step_time=0.066, optim0_lr0=1.518e-04, train_time=1.017
[alab02] 2024-08-30 22:04:04,400 (trainer:720) INFO: 92epoch:train:3001-3200batch: iter_time=7.290e-04, forward_time=0.171, uma_reduction=0.285, text_vs_uma=0.341, loss_ctc=3.973, loss=1.986, backward_time=0.206, optim_step_time=0.068, optim0_lr0=1.517e-04, train_time=1.039
[alab02] 2024-08-30 22:05:49,160 (trainer:720) INFO: 92epoch:train:3201-3400batch: iter_time=7.304e-04, forward_time=0.172, uma_reduction=0.284, text_vs_uma=0.345, loss_ctc=3.780, loss=1.890, backward_time=0.211, optim_step_time=0.069, optim0_lr0=1.517e-04, train_time=1.047
[alab02] 2024-08-30 22:07:30,552 (trainer:720) INFO: 92epoch:train:3401-3600batch: iter_time=6.340e-04, forward_time=0.165, uma_reduction=0.285, text_vs_uma=0.336, loss_ctc=3.709, loss=1.854, backward_time=0.204, optim_step_time=0.065, optim0_lr0=1.517e-04, train_time=1.013
[alab02] 2024-08-30 22:09:15,398 (trainer:720) INFO: 92epoch:train:3601-3800batch: iter_time=6.884e-04, forward_time=0.173, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=4.014, loss=2.007, backward_time=0.208, optim_step_time=0.071, optim0_lr0=1.517e-04, train_time=1.048
[alab02] 2024-08-30 22:10:59,214 (trainer:720) INFO: 92epoch:train:3801-4000batch: iter_time=5.883e-04, forward_time=0.172, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.972, loss=1.986, backward_time=0.208, optim_step_time=0.069, optim0_lr0=1.516e-04, train_time=1.038
[alab02] 2024-08-30 22:12:46,657 (trainer:720) INFO: 92epoch:train:4001-4200batch: iter_time=6.805e-04, forward_time=0.178, uma_reduction=0.284, text_vs_uma=0.343, loss_ctc=3.935, loss=1.968, backward_time=0.217, optim_step_time=0.071, optim0_lr0=1.516e-04, train_time=1.074
[alab02] 2024-08-30 22:14:31,502 (trainer:720) INFO: 92epoch:train:4201-4400batch: iter_time=6.365e-04, forward_time=0.174, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=3.570, loss=1.785, backward_time=0.213, optim_step_time=0.068, optim0_lr0=1.516e-04, train_time=1.048
[alab02] 2024-08-30 22:16:17,878 (trainer:720) INFO: 92epoch:train:4401-4600batch: iter_time=5.788e-04, forward_time=0.177, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=4.069, loss=2.034, backward_time=0.213, optim_step_time=0.070, optim0_lr0=1.516e-04, train_time=1.063
[alab02] 2024-08-30 22:18:01,484 (trainer:720) INFO: 92epoch:train:4601-4800batch: iter_time=7.134e-04, forward_time=0.170, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.827, loss=1.914, backward_time=0.208, optim_step_time=0.071, optim0_lr0=1.516e-04, train_time=1.035
[alab02] 2024-08-30 22:19:48,151 (trainer:720) INFO: 92epoch:train:4801-5000batch: iter_time=6.901e-04, forward_time=0.174, uma_reduction=0.268, text_vs_uma=0.370, loss_ctc=3.932, loss=1.966, backward_time=0.216, optim_step_time=0.074, optim0_lr0=1.515e-04, train_time=1.066
[alab02] 2024-08-30 22:21:33,346 (trainer:720) INFO: 92epoch:train:5001-5200batch: iter_time=8.122e-04, forward_time=0.173, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.936, loss=1.968, backward_time=0.209, optim_step_time=0.072, optim0_lr0=1.515e-04, train_time=1.051
[alab02] 2024-08-30 22:23:18,248 (trainer:720) INFO: 92epoch:train:5201-5400batch: iter_time=6.046e-04, forward_time=0.173, uma_reduction=0.277, text_vs_uma=0.343, loss_ctc=3.613, loss=1.807, backward_time=0.211, optim_step_time=0.073, optim0_lr0=1.515e-04, train_time=1.048
[alab02] 2024-08-30 22:25:02,935 (trainer:720) INFO: 92epoch:train:5401-5600batch: iter_time=9.395e-04, forward_time=0.173, uma_reduction=0.280, text_vs_uma=0.348, loss_ctc=3.761, loss=1.881, backward_time=0.209, optim_step_time=0.073, optim0_lr0=1.515e-04, train_time=1.046
[alab02] 2024-08-30 22:26:46,902 (trainer:720) INFO: 92epoch:train:5601-5800batch: iter_time=6.597e-04, forward_time=0.171, uma_reduction=0.280, text_vs_uma=0.355, loss_ctc=3.966, loss=1.983, backward_time=0.207, optim_step_time=0.073, optim0_lr0=1.514e-04, train_time=1.039
[alab02] 2024-08-30 22:28:27,960 (trainer:720) INFO: 92epoch:train:5801-6000batch: iter_time=6.189e-04, forward_time=0.165, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.723, loss=1.861, backward_time=0.202, optim_step_time=0.068, optim0_lr0=1.514e-04, train_time=1.010
[alab02] 2024-08-30 22:30:13,130 (trainer:720) INFO: 92epoch:train:6001-6200batch: iter_time=5.903e-04, forward_time=0.174, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=4.064, loss=2.032, backward_time=0.209, optim_step_time=0.068, optim0_lr0=1.514e-04, train_time=1.051
[alab02] 2024-08-30 22:31:55,695 (trainer:720) INFO: 92epoch:train:6201-6400batch: iter_time=6.439e-04, forward_time=0.169, uma_reduction=0.285, text_vs_uma=0.338, loss_ctc=3.737, loss=1.869, backward_time=0.205, optim_step_time=0.069, optim0_lr0=1.514e-04, train_time=1.025
[alab02] 2024-08-30 22:33:37,304 (trainer:720) INFO: 92epoch:train:6401-6600batch: iter_time=4.658e-04, forward_time=0.163, uma_reduction=0.281, text_vs_uma=0.352, loss_ctc=3.876, loss=1.938, backward_time=0.206, optim_step_time=0.067, optim0_lr0=1.513e-04, train_time=1.015
[alab02] 2024-08-30 22:35:16,428 (trainer:720) INFO: 92epoch:train:6601-6800batch: iter_time=4.259e-04, forward_time=0.161, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=3.903, loss=1.952, backward_time=0.198, optim_step_time=0.062, optim0_lr0=1.513e-04, train_time=0.991
[alab02] 2024-08-30 22:36:57,653 (trainer:720) INFO: 92epoch:train:6801-7000batch: iter_time=4.421e-04, forward_time=0.162, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=4.177, loss=2.089, backward_time=0.202, optim_step_time=0.056, optim0_lr0=1.513e-04, train_time=1.012
[alab02] 2024-08-30 22:38:28,150 (trainer:338) INFO: 92epoch results: [train] iter_time=6.941e-04, forward_time=0.163, uma_reduction=0.284, text_vs_uma=0.342, loss_ctc=3.898, loss=1.949, backward_time=0.202, optim_step_time=0.063, optim0_lr0=1.517e-04, train_time=1.008, time=59 minutes and 54.44 seconds, total_count=655592, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.277, text_vs_uma=0.392, loss_ctc=3.286, cer_ctc=0.087, cer=0.087, loss=3.286, time=7.87 seconds, total_count=2392, gpu_max_cached_mem_GB=35.906, [att_plot] time=21.79 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 22:38:36,916 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 22:38:36,955 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/91epoch.pth
[alab02] 2024-08-30 22:38:36,956 (trainer:272) INFO: 93/150epoch started. Estimated time to finish: 2 days, 4 hours and 46 minutes
[alab02] 2024-08-30 22:40:14,297 (trainer:720) INFO: 93epoch:train:1-200batch: iter_time=0.003, forward_time=0.153, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=4.290, loss=2.145, backward_time=0.191, optim_step_time=0.051, optim0_lr0=1.513e-04, train_time=0.973
[alab02] 2024-08-30 22:41:48,174 (trainer:720) INFO: 93epoch:train:201-400batch: iter_time=5.334e-04, forward_time=0.147, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=4.011, loss=2.006, backward_time=0.187, optim_step_time=0.052, optim0_lr0=1.512e-04, train_time=0.938
[alab02] 2024-08-30 22:43:19,144 (trainer:720) INFO: 93epoch:train:401-600batch: iter_time=3.317e-04, forward_time=0.138, uma_reduction=0.277, text_vs_uma=0.356, loss_ctc=4.074, loss=2.037, backward_time=0.184, optim_step_time=0.043, optim0_lr0=1.512e-04, train_time=0.909
[alab02] 2024-08-30 22:44:47,942 (trainer:720) INFO: 93epoch:train:601-800batch: iter_time=2.213e-04, forward_time=0.134, uma_reduction=0.294, text_vs_uma=0.331, loss_ctc=3.933, loss=1.967, backward_time=0.183, optim_step_time=0.037, optim0_lr0=1.512e-04, train_time=0.888
[alab02] 2024-08-30 22:46:18,514 (trainer:720) INFO: 93epoch:train:801-1000batch: iter_time=2.028e-04, forward_time=0.135, uma_reduction=0.296, text_vs_uma=0.323, loss_ctc=3.720, loss=1.860, backward_time=0.192, optim_step_time=0.035, optim0_lr0=1.512e-04, train_time=0.905
[alab02] 2024-08-30 22:47:45,995 (trainer:720) INFO: 93epoch:train:1001-1200batch: iter_time=2.028e-04, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.334, loss_ctc=3.611, loss=1.805, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.511e-04, train_time=0.875
[alab02] 2024-08-30 22:49:13,700 (trainer:720) INFO: 93epoch:train:1201-1400batch: iter_time=1.963e-04, forward_time=0.130, uma_reduction=0.289, text_vs_uma=0.331, loss_ctc=3.765, loss=1.883, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.511e-04, train_time=0.877
[alab02] 2024-08-30 22:50:42,558 (trainer:720) INFO: 93epoch:train:1401-1600batch: iter_time=2.013e-04, forward_time=0.131, uma_reduction=0.288, text_vs_uma=0.340, loss_ctc=3.744, loss=1.872, backward_time=0.188, optim_step_time=0.035, optim0_lr0=1.511e-04, train_time=0.888
[alab02] 2024-08-30 22:52:09,121 (trainer:720) INFO: 93epoch:train:1601-1800batch: iter_time=2.187e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.338, loss_ctc=3.938, loss=1.969, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.511e-04, train_time=0.865
[alab02] 2024-08-30 22:53:35,028 (trainer:720) INFO: 93epoch:train:1801-2000batch: iter_time=2.200e-04, forward_time=0.127, uma_reduction=0.287, text_vs_uma=0.334, loss_ctc=3.563, loss=1.782, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.511e-04, train_time=0.859
[alab02] 2024-08-30 22:55:02,891 (trainer:720) INFO: 93epoch:train:2001-2200batch: iter_time=1.866e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.339, loss_ctc=3.600, loss=1.800, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.510e-04, train_time=0.878
[alab02] 2024-08-30 22:56:30,874 (trainer:720) INFO: 93epoch:train:2201-2400batch: iter_time=1.886e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=4.036, loss=2.018, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.510e-04, train_time=0.880
[alab02] 2024-08-30 22:57:58,401 (trainer:720) INFO: 93epoch:train:2401-2600batch: iter_time=1.942e-04, forward_time=0.129, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.781, loss=1.890, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.510e-04, train_time=0.875
[alab02] 2024-08-30 22:59:25,230 (trainer:720) INFO: 93epoch:train:2601-2800batch: iter_time=2.045e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.776, loss=1.888, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.510e-04, train_time=0.868
[alab02] 2024-08-30 23:00:54,540 (trainer:720) INFO: 93epoch:train:2801-3000batch: iter_time=1.804e-04, forward_time=0.133, uma_reduction=0.264, text_vs_uma=0.360, loss_ctc=3.693, loss=1.847, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.509e-04, train_time=0.893
[alab02] 2024-08-30 23:02:22,674 (trainer:720) INFO: 93epoch:train:3001-3200batch: iter_time=1.771e-04, forward_time=0.131, uma_reduction=0.260, text_vs_uma=0.371, loss_ctc=3.807, loss=1.903, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.509e-04, train_time=0.881
[alab02] 2024-08-30 23:03:50,731 (trainer:720) INFO: 93epoch:train:3201-3400batch: iter_time=1.861e-04, forward_time=0.131, uma_reduction=0.260, text_vs_uma=0.376, loss_ctc=4.280, loss=2.140, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.509e-04, train_time=0.880
[alab02] 2024-08-30 23:05:14,597 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 23:05:16,467 (trainer:720) INFO: 93epoch:train:3401-3600batch: iter_time=1.794e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.647, loss=1.824, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.509e-04, train_time=0.857
[alab02] 2024-08-30 23:06:44,023 (trainer:720) INFO: 93epoch:train:3601-3800batch: iter_time=2.204e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.365, loss_ctc=4.010, loss=2.005, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.508e-04, train_time=0.875
[alab02] 2024-08-30 23:08:12,994 (trainer:720) INFO: 93epoch:train:3801-4000batch: iter_time=2.059e-04, forward_time=0.133, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.850, loss=1.925, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.508e-04, train_time=0.889
[alab02] 2024-08-30 23:09:38,759 (trainer:720) INFO: 93epoch:train:4001-4200batch: iter_time=2.169e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=3.946, loss=1.973, backward_time=0.176, optim_step_time=0.035, optim0_lr0=1.508e-04, train_time=0.857
[alab02] 2024-08-30 23:11:05,655 (trainer:720) INFO: 93epoch:train:4201-4400batch: iter_time=2.009e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=4.324, loss=2.162, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.508e-04, train_time=0.869
[alab02] 2024-08-30 23:12:32,934 (trainer:720) INFO: 93epoch:train:4401-4600batch: iter_time=1.921e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.812, loss=1.906, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.508e-04, train_time=0.873
[alab02] 2024-08-30 23:14:00,838 (trainer:720) INFO: 93epoch:train:4601-4800batch: iter_time=1.878e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=4.001, loss=2.000, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.507e-04, train_time=0.879
[alab02] 2024-08-30 23:15:29,377 (trainer:720) INFO: 93epoch:train:4801-5000batch: iter_time=1.933e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.939, loss=1.970, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.507e-04, train_time=0.885
[alab02] 2024-08-30 23:16:54,710 (trainer:720) INFO: 93epoch:train:5001-5200batch: iter_time=1.830e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.341, loss_ctc=3.925, loss=1.962, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.507e-04, train_time=0.853
[alab02] 2024-08-30 23:18:22,982 (trainer:720) INFO: 93epoch:train:5201-5400batch: iter_time=1.948e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=3.773, loss=1.886, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.507e-04, train_time=0.882
[alab02] 2024-08-30 23:19:49,704 (trainer:720) INFO: 93epoch:train:5401-5600batch: iter_time=1.851e-04, forward_time=0.129, uma_reduction=0.290, text_vs_uma=0.338, loss_ctc=3.827, loss=1.914, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.506e-04, train_time=0.867
[alab02] 2024-08-30 23:21:15,858 (trainer:720) INFO: 93epoch:train:5601-5800batch: iter_time=1.963e-04, forward_time=0.128, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=3.671, loss=1.836, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.506e-04, train_time=0.861
[alab02] 2024-08-30 23:22:42,979 (trainer:720) INFO: 93epoch:train:5801-6000batch: iter_time=2.009e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.066, loss=2.033, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.506e-04, train_time=0.871
[alab02] 2024-08-30 23:24:09,761 (trainer:720) INFO: 93epoch:train:6001-6200batch: iter_time=1.858e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.953, loss=1.977, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.506e-04, train_time=0.868
[alab02] 2024-08-30 23:25:37,586 (trainer:720) INFO: 93epoch:train:6201-6400batch: iter_time=1.857e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=4.059, loss=2.030, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.506e-04, train_time=0.878
[alab02] 2024-08-30 23:27:02,866 (trainer:720) INFO: 93epoch:train:6401-6600batch: iter_time=1.957e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.365, loss_ctc=4.409, loss=2.205, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.505e-04, train_time=0.853
[alab02] 2024-08-30 23:28:30,496 (trainer:720) INFO: 93epoch:train:6601-6800batch: iter_time=1.903e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=3.832, loss=1.916, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.505e-04, train_time=0.876
[alab02] 2024-08-30 23:29:57,712 (trainer:720) INFO: 93epoch:train:6801-7000batch: iter_time=1.843e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.898, loss=1.949, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.505e-04, train_time=0.872
[alab02] 2024-08-30 23:31:12,860 (trainer:338) INFO: 93epoch results: [train] iter_time=2.922e-04, forward_time=0.131, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.900, loss=1.950, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.509e-04, train_time=0.880, time=52 minutes and 15.75 seconds, total_count=662718, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.287, text_vs_uma=0.378, loss_ctc=3.176, cer_ctc=0.084, cer=0.084, loss=3.176, time=6.1 seconds, total_count=2418, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.05 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-30 23:31:18,063 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-30 23:31:18,081 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/89epoch.pth
[alab02] 2024-08-30 23:31:18,082 (trainer:272) INFO: 94/150epoch started. Estimated time to finish: 2 days, 3 hours and 50 minutes
[alab02] 2024-08-30 23:32:45,024 (trainer:720) INFO: 94epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.788, loss=1.894, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.504e-04, train_time=0.869
[alab02] 2024-08-30 23:33:33,735 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-30 23:34:12,768 (trainer:720) INFO: 94epoch:train:201-400batch: iter_time=2.074e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=3.964, loss=1.982, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.504e-04, train_time=0.877
[alab02] 2024-08-30 23:35:42,237 (trainer:720) INFO: 94epoch:train:401-600batch: iter_time=2.013e-04, forward_time=0.133, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=4.390, loss=2.195, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.504e-04, train_time=0.894
[alab02] 2024-08-30 23:37:09,978 (trainer:720) INFO: 94epoch:train:601-800batch: iter_time=2.113e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.358, loss_ctc=4.218, loss=2.109, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.504e-04, train_time=0.877
[alab02] 2024-08-30 23:38:36,254 (trainer:720) INFO: 94epoch:train:801-1000batch: iter_time=2.144e-04, forward_time=0.128, uma_reduction=0.292, text_vs_uma=0.329, loss_ctc=3.617, loss=1.808, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.504e-04, train_time=0.863
[alab02] 2024-08-30 23:40:03,570 (trainer:720) INFO: 94epoch:train:1001-1200batch: iter_time=2.220e-04, forward_time=0.132, uma_reduction=0.294, text_vs_uma=0.332, loss_ctc=3.669, loss=1.835, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.503e-04, train_time=0.873
[alab02] 2024-08-30 23:41:33,114 (trainer:720) INFO: 94epoch:train:1201-1400batch: iter_time=2.026e-04, forward_time=0.134, uma_reduction=0.292, text_vs_uma=0.330, loss_ctc=3.655, loss=1.828, backward_time=0.191, optim_step_time=0.034, optim0_lr0=1.503e-04, train_time=0.895
[alab02] 2024-08-30 23:42:59,564 (trainer:720) INFO: 94epoch:train:1401-1600batch: iter_time=1.908e-04, forward_time=0.128, uma_reduction=0.292, text_vs_uma=0.322, loss_ctc=3.783, loss=1.891, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.503e-04, train_time=0.864
[alab02] 2024-08-30 23:44:25,686 (trainer:720) INFO: 94epoch:train:1601-1800batch: iter_time=2.064e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.355, loss_ctc=3.837, loss=1.919, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.503e-04, train_time=0.861
[alab02] 2024-08-30 23:45:51,549 (trainer:720) INFO: 94epoch:train:1801-2000batch: iter_time=1.926e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.346, loss_ctc=3.980, loss=1.990, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.502e-04, train_time=0.858
[alab02] 2024-08-30 23:47:18,004 (trainer:720) INFO: 94epoch:train:2001-2200batch: iter_time=1.918e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=4.008, loss=2.004, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.502e-04, train_time=0.864
[alab02] 2024-08-30 23:48:43,664 (trainer:720) INFO: 94epoch:train:2201-2400batch: iter_time=1.889e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.338, loss_ctc=3.812, loss=1.906, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.502e-04, train_time=0.856
[alab02] 2024-08-30 23:50:10,754 (trainer:720) INFO: 94epoch:train:2401-2600batch: iter_time=1.942e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.547, loss=1.773, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.502e-04, train_time=0.871
[alab02] 2024-08-30 23:51:38,622 (trainer:720) INFO: 94epoch:train:2601-2800batch: iter_time=1.878e-04, forward_time=0.130, uma_reduction=0.283, text_vs_uma=0.347, loss_ctc=4.077, loss=2.039, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.502e-04, train_time=0.878
[alab02] 2024-08-30 23:53:05,417 (trainer:720) INFO: 94epoch:train:2801-3000batch: iter_time=1.921e-04, forward_time=0.129, uma_reduction=0.290, text_vs_uma=0.331, loss_ctc=4.043, loss=2.021, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.501e-04, train_time=0.868
[alab02] 2024-08-30 23:54:34,403 (trainer:720) INFO: 94epoch:train:3001-3200batch: iter_time=1.916e-04, forward_time=0.133, uma_reduction=0.292, text_vs_uma=0.330, loss_ctc=3.491, loss=1.745, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.501e-04, train_time=0.890
[alab02] 2024-08-30 23:56:00,972 (trainer:720) INFO: 94epoch:train:3201-3400batch: iter_time=1.788e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.352, loss_ctc=4.060, loss=2.030, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.501e-04, train_time=0.865
[alab02] 2024-08-30 23:57:27,911 (trainer:720) INFO: 94epoch:train:3401-3600batch: iter_time=1.824e-04, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.333, loss_ctc=3.778, loss=1.889, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.501e-04, train_time=0.869
[alab02] 2024-08-30 23:58:56,659 (trainer:720) INFO: 94epoch:train:3601-3800batch: iter_time=1.877e-04, forward_time=0.132, uma_reduction=0.294, text_vs_uma=0.334, loss_ctc=3.895, loss=1.948, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.500e-04, train_time=0.887
[alab02] 2024-08-31 00:00:25,039 (trainer:720) INFO: 94epoch:train:3801-4000batch: iter_time=2.136e-04, forward_time=0.131, uma_reduction=0.293, text_vs_uma=0.330, loss_ctc=3.806, loss=1.903, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.500e-04, train_time=0.884
[alab02] 2024-08-31 00:01:51,374 (trainer:720) INFO: 94epoch:train:4001-4200batch: iter_time=1.982e-04, forward_time=0.128, uma_reduction=0.288, text_vs_uma=0.341, loss_ctc=3.964, loss=1.982, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.500e-04, train_time=0.863
[alab02] 2024-08-31 00:03:16,103 (trainer:720) INFO: 94epoch:train:4201-4400batch: iter_time=1.861e-04, forward_time=0.126, uma_reduction=0.283, text_vs_uma=0.342, loss_ctc=3.902, loss=1.951, backward_time=0.173, optim_step_time=0.034, optim0_lr0=1.500e-04, train_time=0.847
[alab02] 2024-08-31 00:04:43,263 (trainer:720) INFO: 94epoch:train:4401-4600batch: iter_time=2.093e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=3.918, loss=1.959, backward_time=0.180, optim_step_time=0.036, optim0_lr0=1.499e-04, train_time=0.871
[alab02] 2024-08-31 00:06:09,944 (trainer:720) INFO: 94epoch:train:4601-4800batch: iter_time=1.955e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.346, loss_ctc=3.531, loss=1.765, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.499e-04, train_time=0.867
[alab02] 2024-08-31 00:07:37,073 (trainer:720) INFO: 94epoch:train:4801-5000batch: iter_time=2.623e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.343, loss_ctc=3.564, loss=1.782, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.499e-04, train_time=0.871
[alab02] 2024-08-31 00:09:03,849 (trainer:720) INFO: 94epoch:train:5001-5200batch: iter_time=1.852e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.360, loss_ctc=4.158, loss=2.079, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.499e-04, train_time=0.868
[alab02] 2024-08-31 00:10:31,353 (trainer:720) INFO: 94epoch:train:5201-5400batch: iter_time=1.989e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=4.018, loss=2.009, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.499e-04, train_time=0.875
[alab02] 2024-08-31 00:11:57,726 (trainer:720) INFO: 94epoch:train:5401-5600batch: iter_time=1.785e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=3.990, loss=1.995, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.498e-04, train_time=0.863
[alab02] 2024-08-31 00:13:25,596 (trainer:720) INFO: 94epoch:train:5601-5800batch: iter_time=1.789e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=4.125, loss=2.062, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.498e-04, train_time=0.878
[alab02] 2024-08-31 00:14:52,985 (trainer:720) INFO: 94epoch:train:5801-6000batch: iter_time=1.814e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=4.084, loss=2.042, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.498e-04, train_time=0.874
[alab02] 2024-08-31 00:16:20,954 (trainer:720) INFO: 94epoch:train:6001-6200batch: iter_time=1.927e-04, forward_time=0.131, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=4.028, loss=2.014, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.498e-04, train_time=0.879
[alab02] 2024-08-31 00:17:23,921 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 00:17:48,926 (trainer:720) INFO: 94epoch:train:6201-6400batch: iter_time=2.103e-04, forward_time=0.131, uma_reduction=0.275, text_vs_uma=0.357, loss_ctc=3.987, loss=1.994, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.497e-04, train_time=0.879
[alab02] 2024-08-31 00:19:15,552 (trainer:720) INFO: 94epoch:train:6401-6600batch: iter_time=2.070e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.877, loss=1.939, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.497e-04, train_time=0.866
[alab02] 2024-08-31 00:20:42,142 (trainer:720) INFO: 94epoch:train:6601-6800batch: iter_time=1.941e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.921, loss=1.960, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.497e-04, train_time=0.866
[alab02] 2024-08-31 00:22:08,766 (trainer:720) INFO: 94epoch:train:6801-7000batch: iter_time=1.909e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.365, loss_ctc=4.145, loss=2.072, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.497e-04, train_time=0.866
[alab02] 2024-08-31 00:23:25,798 (trainer:338) INFO: 94epoch results: [train] iter_time=2.373e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=3.899, loss=1.949, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.501e-04, train_time=0.872, time=51 minutes and 47.43 seconds, total_count=669844, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.296, text_vs_uma=0.367, loss_ctc=3.097, cer_ctc=0.087, cer=0.087, loss=3.097, time=6.02 seconds, total_count=2444, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.26 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 00:23:30,617 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 00:23:30,622 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/86epoch.pth
[alab02] 2024-08-31 00:23:30,622 (trainer:272) INFO: 95/150epoch started. Estimated time to finish: 2 days, 2 hours and 54 minutes
[alab02] 2024-08-31 00:24:58,294 (trainer:720) INFO: 95epoch:train:1-200batch: iter_time=0.003, forward_time=0.129, uma_reduction=0.292, text_vs_uma=0.333, loss_ctc=3.796, loss=1.898, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.496e-04, train_time=0.876
[alab02] 2024-08-31 00:26:23,408 (trainer:720) INFO: 95epoch:train:201-400batch: iter_time=2.192e-04, forward_time=0.126, uma_reduction=0.292, text_vs_uma=0.331, loss_ctc=3.882, loss=1.941, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.496e-04, train_time=0.851
[alab02] 2024-08-31 00:27:51,959 (trainer:720) INFO: 95epoch:train:401-600batch: iter_time=2.245e-04, forward_time=0.132, uma_reduction=0.295, text_vs_uma=0.326, loss_ctc=3.855, loss=1.927, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.496e-04, train_time=0.885
[alab02] 2024-08-31 00:29:19,214 (trainer:720) INFO: 95epoch:train:601-800batch: iter_time=2.222e-04, forward_time=0.129, uma_reduction=0.284, text_vs_uma=0.342, loss_ctc=4.063, loss=2.032, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.496e-04, train_time=0.872
[alab02] 2024-08-31 00:30:48,012 (trainer:720) INFO: 95epoch:train:801-1000batch: iter_time=2.174e-04, forward_time=0.132, uma_reduction=0.296, text_vs_uma=0.327, loss_ctc=3.728, loss=1.864, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.496e-04, train_time=0.888
[alab02] 2024-08-31 00:32:15,509 (trainer:720) INFO: 95epoch:train:1001-1200batch: iter_time=1.991e-04, forward_time=0.129, uma_reduction=0.292, text_vs_uma=0.332, loss_ctc=3.849, loss=1.924, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.495e-04, train_time=0.875
[alab02] 2024-08-31 00:33:41,529 (trainer:720) INFO: 95epoch:train:1201-1400batch: iter_time=2.116e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.337, loss_ctc=3.869, loss=1.935, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.495e-04, train_time=0.860
[alab02] 2024-08-31 00:35:07,979 (trainer:720) INFO: 95epoch:train:1401-1600batch: iter_time=1.969e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.827, loss=1.913, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.495e-04, train_time=0.864
[alab02] 2024-08-31 00:36:34,196 (trainer:720) INFO: 95epoch:train:1601-1800batch: iter_time=2.093e-04, forward_time=0.128, uma_reduction=0.283, text_vs_uma=0.343, loss_ctc=3.869, loss=1.935, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.495e-04, train_time=0.862
[alab02] 2024-08-31 00:37:59,294 (trainer:720) INFO: 95epoch:train:1801-2000batch: iter_time=2.227e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.344, loss_ctc=3.654, loss=1.827, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.494e-04, train_time=0.851
[alab02] 2024-08-31 00:39:26,160 (trainer:720) INFO: 95epoch:train:2001-2200batch: iter_time=2.057e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.358, loss_ctc=3.955, loss=1.977, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.494e-04, train_time=0.868
[alab02] 2024-08-31 00:40:54,342 (trainer:720) INFO: 95epoch:train:2201-2400batch: iter_time=2.079e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=4.141, loss=2.071, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.494e-04, train_time=0.882
[alab02] 2024-08-31 00:42:23,236 (trainer:720) INFO: 95epoch:train:2401-2600batch: iter_time=2.164e-04, forward_time=0.132, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=4.096, loss=2.048, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.494e-04, train_time=0.889
[alab02] 2024-08-31 00:43:51,625 (trainer:720) INFO: 95epoch:train:2601-2800batch: iter_time=1.967e-04, forward_time=0.132, uma_reduction=0.286, text_vs_uma=0.343, loss_ctc=3.664, loss=1.832, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.494e-04, train_time=0.884
[alab02] 2024-08-31 00:45:18,809 (trainer:720) INFO: 95epoch:train:2801-3000batch: iter_time=2.300e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.355, loss_ctc=4.033, loss=2.016, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.493e-04, train_time=0.872
[alab02] 2024-08-31 00:46:46,727 (trainer:720) INFO: 95epoch:train:3001-3200batch: iter_time=2.007e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.357, loss_ctc=4.101, loss=2.051, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.493e-04, train_time=0.879
[alab02] 2024-08-31 00:48:13,990 (trainer:720) INFO: 95epoch:train:3201-3400batch: iter_time=1.967e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.912, loss=1.956, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.493e-04, train_time=0.872
[alab02] 2024-08-31 00:49:41,327 (trainer:720) INFO: 95epoch:train:3401-3600batch: iter_time=2.060e-04, forward_time=0.130, uma_reduction=0.283, text_vs_uma=0.347, loss_ctc=4.033, loss=2.016, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.493e-04, train_time=0.873
[alab02] 2024-08-31 00:51:08,941 (trainer:720) INFO: 95epoch:train:3601-3800batch: iter_time=2.058e-04, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.336, loss_ctc=3.779, loss=1.889, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.492e-04, train_time=0.876
[alab02] 2024-08-31 00:52:35,504 (trainer:720) INFO: 95epoch:train:3801-4000batch: iter_time=2.072e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.889, loss=1.944, backward_time=0.179, optim_step_time=0.036, optim0_lr0=1.492e-04, train_time=0.865
[alab02] 2024-08-31 00:54:01,213 (trainer:720) INFO: 95epoch:train:4001-4200batch: iter_time=1.810e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.348, loss_ctc=4.008, loss=2.004, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.492e-04, train_time=0.857
[alab02] 2024-08-31 00:55:23,216 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 00:55:26,836 (trainer:720) INFO: 95epoch:train:4201-4400batch: iter_time=1.896e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=4.307, loss=2.154, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.492e-04, train_time=0.856
[alab02] 2024-08-31 00:56:54,268 (trainer:720) INFO: 95epoch:train:4401-4600batch: iter_time=1.912e-04, forward_time=0.130, uma_reduction=0.291, text_vs_uma=0.328, loss_ctc=3.780, loss=1.890, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.492e-04, train_time=0.874
[alab02] 2024-08-31 00:58:21,909 (trainer:720) INFO: 95epoch:train:4601-4800batch: iter_time=2.002e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.341, loss_ctc=4.065, loss=2.032, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.491e-04, train_time=0.876
[alab02] 2024-08-31 00:59:48,717 (trainer:720) INFO: 95epoch:train:4801-5000batch: iter_time=2.133e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.880, loss=1.940, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.491e-04, train_time=0.868
[alab02] 2024-08-31 01:01:14,204 (trainer:720) INFO: 95epoch:train:5001-5200batch: iter_time=1.757e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=4.342, loss=2.171, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.491e-04, train_time=0.855
[alab02] 2024-08-31 01:02:41,821 (trainer:720) INFO: 95epoch:train:5201-5400batch: iter_time=1.869e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.341, loss_ctc=3.722, loss=1.861, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.491e-04, train_time=0.876
[alab02] 2024-08-31 01:04:08,970 (trainer:720) INFO: 95epoch:train:5401-5600batch: iter_time=1.933e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=4.170, loss=2.085, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.490e-04, train_time=0.871
[alab02] 2024-08-31 01:05:36,060 (trainer:720) INFO: 95epoch:train:5601-5800batch: iter_time=1.766e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=4.080, loss=2.040, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.490e-04, train_time=0.871
[alab02] 2024-08-31 01:07:02,479 (trainer:720) INFO: 95epoch:train:5801-6000batch: iter_time=1.817e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.852, loss=1.926, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.490e-04, train_time=0.864
[alab02] 2024-08-31 01:08:28,527 (trainer:720) INFO: 95epoch:train:6001-6200batch: iter_time=1.753e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=4.105, loss=2.052, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.490e-04, train_time=0.860
[alab02] 2024-08-31 01:09:54,706 (trainer:720) INFO: 95epoch:train:6201-6400batch: iter_time=1.798e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=4.166, loss=2.083, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.490e-04, train_time=0.862
[alab02] 2024-08-31 01:11:19,820 (trainer:720) INFO: 95epoch:train:6401-6600batch: iter_time=1.778e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=4.340, loss=2.170, backward_time=0.172, optim_step_time=0.033, optim0_lr0=1.489e-04, train_time=0.851
[alab02] 2024-08-31 01:12:45,692 (trainer:720) INFO: 95epoch:train:6601-6800batch: iter_time=1.690e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=4.077, loss=2.039, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.489e-04, train_time=0.858
[alab02] 2024-08-31 01:14:15,304 (trainer:720) INFO: 95epoch:train:6801-7000batch: iter_time=1.888e-04, forward_time=0.134, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=4.176, loss=2.088, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.489e-04, train_time=0.896
[alab02] 2024-08-31 01:15:29,817 (trainer:338) INFO: 95epoch results: [train] iter_time=2.805e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=3.959, loss=1.980, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.493e-04, train_time=0.870, time=51 minutes and 39.68 seconds, total_count=676970, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.280, text_vs_uma=0.388, loss_ctc=3.149, cer_ctc=0.090, cer=0.090, loss=3.149, time=6.17 seconds, total_count=2470, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.35 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 01:15:35,121 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 01:15:35,122 (trainer:272) INFO: 96/150epoch started. Estimated time to finish: 2 days, 1 hour and 58 minutes
[alab02] 2024-08-31 01:17:04,051 (trainer:720) INFO: 96epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.357, loss_ctc=3.938, loss=1.969, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.489e-04, train_time=0.889
[alab02] 2024-08-31 01:18:31,675 (trainer:720) INFO: 96epoch:train:201-400batch: iter_time=1.975e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.361, loss_ctc=3.818, loss=1.909, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.488e-04, train_time=0.876
[alab02] 2024-08-31 01:20:00,602 (trainer:720) INFO: 96epoch:train:401-600batch: iter_time=1.830e-04, forward_time=0.133, uma_reduction=0.259, text_vs_uma=0.373, loss_ctc=3.921, loss=1.961, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.488e-04, train_time=0.889
[alab02] 2024-08-31 01:21:28,037 (trainer:720) INFO: 96epoch:train:601-800batch: iter_time=1.869e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.569, loss=1.784, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.488e-04, train_time=0.874
[alab02] 2024-08-31 01:22:54,014 (trainer:720) INFO: 96epoch:train:801-1000batch: iter_time=1.893e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.367, loss_ctc=3.903, loss=1.951, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.488e-04, train_time=0.860
[alab02] 2024-08-31 01:24:19,957 (trainer:720) INFO: 96epoch:train:1001-1200batch: iter_time=1.748e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.357, loss_ctc=3.793, loss=1.896, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.487e-04, train_time=0.859
[alab02] 2024-08-31 01:25:46,076 (trainer:720) INFO: 96epoch:train:1201-1400batch: iter_time=1.781e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.370, loss_ctc=3.996, loss=1.998, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.487e-04, train_time=0.861
[alab02] 2024-08-31 01:27:13,263 (trainer:720) INFO: 96epoch:train:1401-1600batch: iter_time=1.816e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=3.641, loss=1.820, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.487e-04, train_time=0.872
[alab02] 2024-08-31 01:28:38,172 (trainer:720) INFO: 96epoch:train:1601-1800batch: iter_time=2.110e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=4.249, loss=2.124, backward_time=0.172, optim_step_time=0.034, optim0_lr0=1.487e-04, train_time=0.849
[alab02] 2024-08-31 01:30:04,229 (trainer:720) INFO: 96epoch:train:1801-2000batch: iter_time=1.807e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=4.052, loss=2.026, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.487e-04, train_time=0.860
[alab02] 2024-08-31 01:31:33,693 (trainer:720) INFO: 96epoch:train:2001-2200batch: iter_time=1.803e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.367, loss_ctc=4.172, loss=2.086, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.486e-04, train_time=0.894
[alab02] 2024-08-31 01:33:02,087 (trainer:720) INFO: 96epoch:train:2201-2400batch: iter_time=2.013e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=3.883, loss=1.941, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.486e-04, train_time=0.884
[alab02] 2024-08-31 01:34:30,293 (trainer:720) INFO: 96epoch:train:2401-2600batch: iter_time=1.897e-04, forward_time=0.132, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=4.193, loss=2.096, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.486e-04, train_time=0.882
[alab02] 2024-08-31 01:35:58,840 (trainer:720) INFO: 96epoch:train:2601-2800batch: iter_time=1.882e-04, forward_time=0.134, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.605, loss=1.803, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.486e-04, train_time=0.885
[alab02] 2024-08-31 01:37:28,661 (trainer:720) INFO: 96epoch:train:2801-3000batch: iter_time=1.977e-04, forward_time=0.135, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.809, loss=1.904, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.485e-04, train_time=0.898
[alab02] 2024-08-31 01:38:58,836 (trainer:720) INFO: 96epoch:train:3001-3200batch: iter_time=1.846e-04, forward_time=0.135, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=4.162, loss=2.081, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.485e-04, train_time=0.902
[alab02] 2024-08-31 01:40:25,004 (trainer:720) INFO: 96epoch:train:3201-3400batch: iter_time=1.778e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.348, loss_ctc=3.924, loss=1.962, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.485e-04, train_time=0.861
[alab02] 2024-08-31 01:41:53,968 (trainer:720) INFO: 96epoch:train:3401-3600batch: iter_time=1.820e-04, forward_time=0.133, uma_reduction=0.275, text_vs_uma=0.349, loss_ctc=3.956, loss=1.978, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.485e-04, train_time=0.889
[alab02] 2024-08-31 01:43:20,665 (trainer:720) INFO: 96epoch:train:3601-3800batch: iter_time=1.975e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.365, loss_ctc=4.304, loss=2.152, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.485e-04, train_time=0.867
[alab02] 2024-08-31 01:44:48,832 (trainer:720) INFO: 96epoch:train:3801-4000batch: iter_time=1.982e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=4.006, loss=2.003, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.484e-04, train_time=0.881
[alab02] 2024-08-31 01:46:15,876 (trainer:720) INFO: 96epoch:train:4001-4200batch: iter_time=1.763e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.343, loss_ctc=3.803, loss=1.902, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.484e-04, train_time=0.870
[alab02] 2024-08-31 01:47:44,003 (trainer:720) INFO: 96epoch:train:4201-4400batch: iter_time=1.716e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=3.849, loss=1.925, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.484e-04, train_time=0.881
[alab02] 2024-08-31 01:49:12,180 (trainer:720) INFO: 96epoch:train:4401-4600batch: iter_time=1.642e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.782, loss=1.891, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.484e-04, train_time=0.882
[alab02] 2024-08-31 01:50:39,359 (trainer:720) INFO: 96epoch:train:4601-4800batch: iter_time=1.855e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=4.009, loss=2.005, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.484e-04, train_time=0.872
[alab02] 2024-08-31 01:52:07,537 (trainer:720) INFO: 96epoch:train:4801-5000batch: iter_time=1.748e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.341, loss_ctc=3.724, loss=1.862, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.483e-04, train_time=0.882
[alab02] 2024-08-31 01:53:35,488 (trainer:720) INFO: 96epoch:train:5001-5200batch: iter_time=1.807e-04, forward_time=0.131, uma_reduction=0.284, text_vs_uma=0.339, loss_ctc=3.734, loss=1.867, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.483e-04, train_time=0.879
[alab02] 2024-08-31 01:55:03,715 (trainer:720) INFO: 96epoch:train:5201-5400batch: iter_time=1.769e-04, forward_time=0.131, uma_reduction=0.283, text_vs_uma=0.345, loss_ctc=3.887, loss=1.944, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.483e-04, train_time=0.882
[alab02] 2024-08-31 01:55:15,496 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 01:56:28,603 (trainer:720) INFO: 96epoch:train:5401-5600batch: iter_time=1.815e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.345, loss_ctc=3.661, loss=1.831, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.483e-04, train_time=0.849
[alab02] 2024-08-31 01:57:54,579 (trainer:720) INFO: 96epoch:train:5601-5800batch: iter_time=1.715e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.348, loss_ctc=3.645, loss=1.823, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.482e-04, train_time=0.860
[alab02] 2024-08-31 01:58:37,209 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 01:59:22,275 (trainer:720) INFO: 96epoch:train:5801-6000batch: iter_time=1.657e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=4.017, loss=2.009, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.482e-04, train_time=0.877
[alab02] 2024-08-31 02:00:49,053 (trainer:720) INFO: 96epoch:train:6001-6200batch: iter_time=1.965e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.358, loss_ctc=4.039, loss=2.019, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.482e-04, train_time=0.868
[alab02] 2024-08-31 02:02:13,435 (trainer:720) INFO: 96epoch:train:6201-6400batch: iter_time=1.791e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.704, loss=1.852, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.482e-04, train_time=0.844
[alab02] 2024-08-31 02:03:38,979 (trainer:720) INFO: 96epoch:train:6401-6600batch: iter_time=1.617e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.851, loss=1.926, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.482e-04, train_time=0.855
[alab02] 2024-08-31 02:05:06,481 (trainer:720) INFO: 96epoch:train:6601-6800batch: iter_time=1.746e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.360, loss_ctc=3.936, loss=1.968, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.481e-04, train_time=0.875
[alab02] 2024-08-31 02:06:33,747 (trainer:720) INFO: 96epoch:train:6801-7000batch: iter_time=1.740e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.950, loss=1.975, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.481e-04, train_time=0.872
[alab02] 2024-08-31 02:07:48,969 (trainer:338) INFO: 96epoch results: [train] iter_time=2.334e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.893, loss=1.946, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.485e-04, train_time=0.874, time=51 minutes and 54.96 seconds, total_count=684096, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.266, text_vs_uma=0.408, loss_ctc=3.258, cer_ctc=0.090, cer=0.090, loss=3.258, time=6.21 seconds, total_count=2496, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.68 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 02:07:53,857 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 02:07:53,922 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/95epoch.pth
[alab02] 2024-08-31 02:07:53,922 (trainer:272) INFO: 97/150epoch started. Estimated time to finish: 2 days, 1 hour and 2 minutes
[alab02] 2024-08-31 02:09:21,754 (trainer:720) INFO: 97epoch:train:1-200batch: iter_time=0.001, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=3.951, loss=1.976, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.481e-04, train_time=0.878
[alab02] 2024-08-31 02:10:50,676 (trainer:720) INFO: 97epoch:train:201-400batch: iter_time=1.774e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=4.020, loss=2.010, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.481e-04, train_time=0.889
[alab02] 2024-08-31 02:12:19,015 (trainer:720) INFO: 97epoch:train:401-600batch: iter_time=2.244e-04, forward_time=0.131, uma_reduction=0.264, text_vs_uma=0.360, loss_ctc=3.638, loss=1.819, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.480e-04, train_time=0.883
[alab02] 2024-08-31 02:13:46,658 (trainer:720) INFO: 97epoch:train:601-800batch: iter_time=1.972e-04, forward_time=0.131, uma_reduction=0.265, text_vs_uma=0.371, loss_ctc=3.876, loss=1.938, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.480e-04, train_time=0.876
[alab02] 2024-08-31 02:15:14,045 (trainer:720) INFO: 97epoch:train:801-1000batch: iter_time=1.817e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.346, loss_ctc=3.620, loss=1.810, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.480e-04, train_time=0.874
[alab02] 2024-08-31 02:16:40,779 (trainer:720) INFO: 97epoch:train:1001-1200batch: iter_time=2.009e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=3.921, loss=1.961, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.480e-04, train_time=0.867
[alab02] 2024-08-31 02:18:07,199 (trainer:720) INFO: 97epoch:train:1201-1400batch: iter_time=1.836e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=3.908, loss=1.954, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.479e-04, train_time=0.864
[alab02] 2024-08-31 02:19:32,932 (trainer:720) INFO: 97epoch:train:1401-1600batch: iter_time=1.842e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=3.980, loss=1.990, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.479e-04, train_time=0.857
[alab02] 2024-08-31 02:20:59,204 (trainer:720) INFO: 97epoch:train:1601-1800batch: iter_time=1.937e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.340, loss_ctc=3.813, loss=1.907, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.479e-04, train_time=0.862
[alab02] 2024-08-31 02:22:27,197 (trainer:720) INFO: 97epoch:train:1801-2000batch: iter_time=1.675e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.354, loss_ctc=4.236, loss=2.118, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.479e-04, train_time=0.880
[alab02] 2024-08-31 02:23:53,974 (trainer:720) INFO: 97epoch:train:2001-2200batch: iter_time=1.874e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=4.141, loss=2.070, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.479e-04, train_time=0.868
[alab02] 2024-08-31 02:25:20,904 (trainer:720) INFO: 97epoch:train:2201-2400batch: iter_time=1.800e-04, forward_time=0.129, uma_reduction=0.283, text_vs_uma=0.342, loss_ctc=3.815, loss=1.907, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.478e-04, train_time=0.869
[alab02] 2024-08-31 02:26:49,364 (trainer:720) INFO: 97epoch:train:2401-2600batch: iter_time=1.789e-04, forward_time=0.132, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=4.063, loss=2.032, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.478e-04, train_time=0.884
[alab02] 2024-08-31 02:28:16,675 (trainer:720) INFO: 97epoch:train:2601-2800batch: iter_time=2.149e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=4.023, loss=2.011, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.478e-04, train_time=0.873
[alab02] 2024-08-31 02:29:42,979 (trainer:720) INFO: 97epoch:train:2801-3000batch: iter_time=1.832e-04, forward_time=0.127, uma_reduction=0.287, text_vs_uma=0.334, loss_ctc=3.731, loss=1.866, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.478e-04, train_time=0.863
[alab02] 2024-08-31 02:31:08,229 (trainer:720) INFO: 97epoch:train:3001-3200batch: iter_time=1.851e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.342, loss_ctc=3.817, loss=1.909, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.478e-04, train_time=0.852
[alab02] 2024-08-31 02:32:33,766 (trainer:720) INFO: 97epoch:train:3201-3400batch: iter_time=1.684e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.343, loss_ctc=3.914, loss=1.957, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.477e-04, train_time=0.855
[alab02] 2024-08-31 02:33:47,650 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 02:34:00,424 (trainer:720) INFO: 97epoch:train:3401-3600batch: iter_time=2.025e-04, forward_time=0.129, uma_reduction=0.286, text_vs_uma=0.331, loss_ctc=3.533, loss=1.767, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.477e-04, train_time=0.866
[alab02] 2024-08-31 02:35:24,858 (trainer:720) INFO: 97epoch:train:3601-3800batch: iter_time=1.699e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.751, loss=1.876, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.477e-04, train_time=0.844
[alab02] 2024-08-31 02:36:49,739 (trainer:720) INFO: 97epoch:train:3801-4000batch: iter_time=1.831e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.832, loss=1.916, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.477e-04, train_time=0.849
[alab02] 2024-08-31 02:38:15,520 (trainer:720) INFO: 97epoch:train:4001-4200batch: iter_time=1.832e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.347, loss_ctc=3.747, loss=1.873, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.476e-04, train_time=0.858
[alab02] 2024-08-31 02:39:44,071 (trainer:720) INFO: 97epoch:train:4201-4400batch: iter_time=1.848e-04, forward_time=0.131, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.925, loss=1.962, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.476e-04, train_time=0.885
[alab02] 2024-08-31 02:41:12,518 (trainer:720) INFO: 97epoch:train:4401-4600batch: iter_time=1.844e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=3.726, loss=1.863, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.476e-04, train_time=0.884
[alab02] 2024-08-31 02:42:38,830 (trainer:720) INFO: 97epoch:train:4601-4800batch: iter_time=1.878e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.715, loss=1.857, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.476e-04, train_time=0.863
[alab02] 2024-08-31 02:44:04,981 (trainer:720) INFO: 97epoch:train:4801-5000batch: iter_time=1.833e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.358, loss_ctc=3.686, loss=1.843, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.476e-04, train_time=0.861
[alab02] 2024-08-31 02:45:33,022 (trainer:720) INFO: 97epoch:train:5001-5200batch: iter_time=1.801e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.671, loss=1.836, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.475e-04, train_time=0.880
[alab02] 2024-08-31 02:46:59,446 (trainer:720) INFO: 97epoch:train:5201-5400batch: iter_time=1.806e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.894, loss=1.947, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.475e-04, train_time=0.864
[alab02] 2024-08-31 02:48:27,652 (trainer:720) INFO: 97epoch:train:5401-5600batch: iter_time=1.834e-04, forward_time=0.131, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.677, loss=1.839, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.475e-04, train_time=0.882
[alab02] 2024-08-31 02:49:55,759 (trainer:720) INFO: 97epoch:train:5601-5800batch: iter_time=2.079e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.899, loss=1.949, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.475e-04, train_time=0.881
[alab02] 2024-08-31 02:51:21,790 (trainer:720) INFO: 97epoch:train:5801-6000batch: iter_time=1.646e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.884, loss=1.942, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.475e-04, train_time=0.860
[alab02] 2024-08-31 02:52:48,359 (trainer:720) INFO: 97epoch:train:6001-6200batch: iter_time=1.937e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.373, loss_ctc=4.244, loss=2.122, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.474e-04, train_time=0.865
[alab02] 2024-08-31 02:54:17,490 (trainer:720) INFO: 97epoch:train:6201-6400batch: iter_time=1.824e-04, forward_time=0.133, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.896, loss=1.948, backward_time=0.188, optim_step_time=0.035, optim0_lr0=1.474e-04, train_time=0.891
[alab02] 2024-08-31 02:55:44,753 (trainer:720) INFO: 97epoch:train:6401-6600batch: iter_time=1.690e-04, forward_time=0.129, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=3.784, loss=1.892, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.474e-04, train_time=0.872
[alab02] 2024-08-31 02:57:11,590 (trainer:720) INFO: 97epoch:train:6601-6800batch: iter_time=1.805e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.347, loss_ctc=4.009, loss=2.005, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.474e-04, train_time=0.868
[alab02] 2024-08-31 02:58:35,567 (trainer:720) INFO: 97epoch:train:6801-7000batch: iter_time=1.556e-04, forward_time=0.124, uma_reduction=0.282, text_vs_uma=0.338, loss_ctc=3.503, loss=1.751, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.473e-04, train_time=0.840
[alab02] 2024-08-31 02:59:48,266 (trainer:338) INFO: 97epoch results: [train] iter_time=2.197e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.849, loss=1.924, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.477e-04, train_time=0.869, time=51 minutes and 35.84 seconds, total_count=691222, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.277, text_vs_uma=0.392, loss_ctc=3.119, cer_ctc=0.084, cer=0.084, loss=3.119, time=5.92 seconds, total_count=2522, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.58 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 02:59:53,759 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 02:59:53,837 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/73epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/96epoch.pth
[alab02] 2024-08-31 02:59:53,837 (trainer:272) INFO: 98/150epoch started. Estimated time to finish: 2 days, 6 minutes and 51.8 seconds
[alab02] 2024-08-31 03:01:20,231 (trainer:720) INFO: 98epoch:train:1-200batch: iter_time=0.002, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.356, loss_ctc=3.872, loss=1.936, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.473e-04, train_time=0.863
[alab02] 2024-08-31 03:02:46,107 (trainer:720) INFO: 98epoch:train:201-400batch: iter_time=1.881e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=4.029, loss=2.015, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.473e-04, train_time=0.859
[alab02] 2024-08-31 03:04:13,051 (trainer:720) INFO: 98epoch:train:401-600batch: iter_time=1.926e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.928, loss=1.964, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.473e-04, train_time=0.869
[alab02] 2024-08-31 03:05:38,308 (trainer:720) INFO: 98epoch:train:601-800batch: iter_time=1.649e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.356, loss_ctc=3.832, loss=1.916, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.472e-04, train_time=0.852
[alab02] 2024-08-31 03:06:23,329 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 03:07:05,817 (trainer:720) INFO: 98epoch:train:801-1000batch: iter_time=1.791e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=4.374, loss=2.187, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.472e-04, train_time=0.875
[alab02] 2024-08-31 03:08:33,646 (trainer:720) INFO: 98epoch:train:1001-1200batch: iter_time=1.664e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=4.067, loss=2.034, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.472e-04, train_time=0.878
[alab02] 2024-08-31 03:10:02,331 (trainer:720) INFO: 98epoch:train:1201-1400batch: iter_time=1.935e-04, forward_time=0.132, uma_reduction=0.266, text_vs_uma=0.362, loss_ctc=4.182, loss=2.091, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.472e-04, train_time=0.887
[alab02] 2024-08-31 03:11:26,492 (trainer:720) INFO: 98epoch:train:1401-1600batch: iter_time=1.787e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=4.186, loss=2.093, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.472e-04, train_time=0.841
[alab02] 2024-08-31 03:12:53,416 (trainer:720) INFO: 98epoch:train:1601-1800batch: iter_time=1.841e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.340, loss_ctc=3.688, loss=1.844, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.471e-04, train_time=0.869
[alab02] 2024-08-31 03:14:19,206 (trainer:720) INFO: 98epoch:train:1801-2000batch: iter_time=1.838e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.371, loss_ctc=4.265, loss=2.133, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.471e-04, train_time=0.858
[alab02] 2024-08-31 03:15:47,612 (trainer:720) INFO: 98epoch:train:2001-2200batch: iter_time=1.638e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.837, loss=1.919, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.471e-04, train_time=0.884
[alab02] 2024-08-31 03:17:12,752 (trainer:720) INFO: 98epoch:train:2201-2400batch: iter_time=1.794e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=3.968, loss=1.984, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.471e-04, train_time=0.851
[alab02] 2024-08-31 03:18:40,043 (trainer:720) INFO: 98epoch:train:2401-2600batch: iter_time=1.820e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.361, loss_ctc=4.040, loss=2.020, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.471e-04, train_time=0.873
[alab02] 2024-08-31 03:20:07,265 (trainer:720) INFO: 98epoch:train:2601-2800batch: iter_time=1.823e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.364, loss_ctc=3.994, loss=1.997, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.470e-04, train_time=0.872
[alab02] 2024-08-31 03:21:34,180 (trainer:720) INFO: 98epoch:train:2801-3000batch: iter_time=1.835e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.751, loss=1.876, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.470e-04, train_time=0.869
[alab02] 2024-08-31 03:23:00,801 (trainer:720) INFO: 98epoch:train:3001-3200batch: iter_time=1.797e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.366, loss_ctc=3.882, loss=1.941, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.470e-04, train_time=0.866
[alab02] 2024-08-31 03:24:26,560 (trainer:720) INFO: 98epoch:train:3201-3400batch: iter_time=1.910e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.359, loss_ctc=3.928, loss=1.964, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.470e-04, train_time=0.857
[alab02] 2024-08-31 03:25:54,946 (trainer:720) INFO: 98epoch:train:3401-3600batch: iter_time=2.000e-04, forward_time=0.131, uma_reduction=0.270, text_vs_uma=0.374, loss_ctc=4.304, loss=2.152, backward_time=0.181, optim_step_time=0.036, optim0_lr0=1.470e-04, train_time=0.884
[alab02] 2024-08-31 03:27:21,965 (trainer:720) INFO: 98epoch:train:3601-3800batch: iter_time=1.918e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=3.797, loss=1.899, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.469e-04, train_time=0.870
[alab02] 2024-08-31 03:28:48,903 (trainer:720) INFO: 98epoch:train:3801-4000batch: iter_time=1.747e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=4.259, loss=2.129, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.469e-04, train_time=0.869
[alab02] 2024-08-31 03:30:14,906 (trainer:720) INFO: 98epoch:train:4001-4200batch: iter_time=1.753e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.342, loss_ctc=3.819, loss=1.910, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.469e-04, train_time=0.860
[alab02] 2024-08-31 03:31:40,977 (trainer:720) INFO: 98epoch:train:4201-4400batch: iter_time=1.898e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=4.135, loss=2.067, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.469e-04, train_time=0.860
[alab02] 2024-08-31 03:33:06,387 (trainer:720) INFO: 98epoch:train:4401-4600batch: iter_time=1.692e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.012, loss=2.006, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.468e-04, train_time=0.854
[alab02] 2024-08-31 03:34:36,372 (trainer:720) INFO: 98epoch:train:4601-4800batch: iter_time=1.941e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.818, loss=1.909, backward_time=0.190, optim_step_time=0.034, optim0_lr0=1.468e-04, train_time=0.900
[alab02] 2024-08-31 03:36:03,085 (trainer:720) INFO: 98epoch:train:4801-5000batch: iter_time=1.914e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.362, loss_ctc=3.852, loss=1.926, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.468e-04, train_time=0.867
[alab02] 2024-08-31 03:37:29,363 (trainer:720) INFO: 98epoch:train:5001-5200batch: iter_time=1.970e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.353, loss_ctc=3.856, loss=1.928, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.468e-04, train_time=0.863
[alab02] 2024-08-31 03:38:57,713 (trainer:720) INFO: 98epoch:train:5201-5400batch: iter_time=1.951e-04, forward_time=0.131, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=3.780, loss=1.890, backward_time=0.186, optim_step_time=0.035, optim0_lr0=1.468e-04, train_time=0.883
[alab02] 2024-08-31 03:40:24,266 (trainer:720) INFO: 98epoch:train:5401-5600batch: iter_time=1.668e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.773, loss=1.887, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.467e-04, train_time=0.865
[alab02] 2024-08-31 03:41:52,061 (trainer:720) INFO: 98epoch:train:5601-5800batch: iter_time=2.049e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=4.013, loss=2.006, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.467e-04, train_time=0.878
[alab02] 2024-08-31 03:43:17,774 (trainer:720) INFO: 98epoch:train:5801-6000batch: iter_time=1.797e-04, forward_time=0.127, uma_reduction=0.286, text_vs_uma=0.335, loss_ctc=3.820, loss=1.910, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.467e-04, train_time=0.857
[alab02] 2024-08-31 03:44:44,359 (trainer:720) INFO: 98epoch:train:6001-6200batch: iter_time=1.621e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.828, loss=1.914, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.467e-04, train_time=0.866
[alab02] 2024-08-31 03:46:09,714 (trainer:720) INFO: 98epoch:train:6201-6400batch: iter_time=1.620e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.363, loss_ctc=4.153, loss=2.076, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.467e-04, train_time=0.853
[alab02] 2024-08-31 03:47:36,899 (trainer:720) INFO: 98epoch:train:6401-6600batch: iter_time=1.739e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=4.143, loss=2.071, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.466e-04, train_time=0.872
[alab02] 2024-08-31 03:48:40,554 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 03:49:03,197 (trainer:720) INFO: 98epoch:train:6601-6800batch: iter_time=1.736e-04, forward_time=0.129, uma_reduction=0.284, text_vs_uma=0.342, loss_ctc=3.965, loss=1.982, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.466e-04, train_time=0.863
[alab02] 2024-08-31 03:50:28,713 (trainer:720) INFO: 98epoch:train:6801-7000batch: iter_time=1.721e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.339, loss_ctc=3.480, loss=1.740, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.466e-04, train_time=0.855
[alab02] 2024-08-31 03:51:40,709 (trainer:338) INFO: 98epoch results: [train] iter_time=2.230e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.949, loss=1.974, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.469e-04, train_time=0.867, time=51 minutes and 28.87 seconds, total_count=698348, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.294, text_vs_uma=0.370, loss_ctc=3.099, cer_ctc=0.089, cer=0.089, loss=3.099, time=6.07 seconds, total_count=2548, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.93 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 03:51:45,658 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 03:51:45,660 (trainer:272) INFO: 99/150epoch started. Estimated time to finish: 1 day, 23 hours and 11 minutes
[alab02] 2024-08-31 03:53:12,993 (trainer:720) INFO: 99epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.285, text_vs_uma=0.339, loss_ctc=3.721, loss=1.860, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.466e-04, train_time=0.873
[alab02] 2024-08-31 03:54:39,733 (trainer:720) INFO: 99epoch:train:201-400batch: iter_time=1.641e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=4.100, loss=2.050, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.465e-04, train_time=0.867
[alab02] 2024-08-31 03:56:07,037 (trainer:720) INFO: 99epoch:train:401-600batch: iter_time=1.927e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=4.016, loss=2.008, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.465e-04, train_time=0.873
[alab02] 2024-08-31 03:57:33,534 (trainer:720) INFO: 99epoch:train:601-800batch: iter_time=1.694e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.338, loss_ctc=3.852, loss=1.926, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.465e-04, train_time=0.865
[alab02] 2024-08-31 03:59:00,027 (trainer:720) INFO: 99epoch:train:801-1000batch: iter_time=1.849e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.337, loss_ctc=3.871, loss=1.935, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.465e-04, train_time=0.865
[alab02] 2024-08-31 04:00:27,479 (trainer:720) INFO: 99epoch:train:1001-1200batch: iter_time=1.984e-04, forward_time=0.129, uma_reduction=0.284, text_vs_uma=0.341, loss_ctc=3.985, loss=1.993, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.465e-04, train_time=0.874
[alab02] 2024-08-31 04:01:56,423 (trainer:720) INFO: 99epoch:train:1201-1400batch: iter_time=2.048e-04, forward_time=0.131, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=4.056, loss=2.028, backward_time=0.184, optim_step_time=0.038, optim0_lr0=1.464e-04, train_time=0.889
[alab02] 2024-08-31 04:03:24,423 (trainer:720) INFO: 99epoch:train:1401-1600batch: iter_time=1.658e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=4.022, loss=2.011, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.464e-04, train_time=0.880
[alab02] 2024-08-31 04:04:52,386 (trainer:720) INFO: 99epoch:train:1601-1800batch: iter_time=1.774e-04, forward_time=0.131, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=4.017, loss=2.008, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.464e-04, train_time=0.879
[alab02] 2024-08-31 04:06:20,421 (trainer:720) INFO: 99epoch:train:1801-2000batch: iter_time=2.029e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.331, loss_ctc=3.674, loss=1.837, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.464e-04, train_time=0.880
[alab02] 2024-08-31 04:07:48,526 (trainer:720) INFO: 99epoch:train:2001-2200batch: iter_time=1.865e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.924, loss=1.962, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.463e-04, train_time=0.881
[alab02] 2024-08-31 04:09:11,917 (trainer:720) INFO: 99epoch:train:2201-2400batch: iter_time=1.795e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.682, loss=1.841, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.463e-04, train_time=0.834
[alab02] 2024-08-31 04:10:38,047 (trainer:720) INFO: 99epoch:train:2401-2600batch: iter_time=1.829e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=4.018, loss=2.009, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.463e-04, train_time=0.861
[alab02] 2024-08-31 04:12:04,457 (trainer:720) INFO: 99epoch:train:2601-2800batch: iter_time=1.887e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=4.090, loss=2.045, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.463e-04, train_time=0.864
[alab02] 2024-08-31 04:13:29,505 (trainer:720) INFO: 99epoch:train:2801-3000batch: iter_time=1.757e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.799, loss=1.899, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.463e-04, train_time=0.850
[alab02] 2024-08-31 04:14:57,337 (trainer:720) INFO: 99epoch:train:3001-3200batch: iter_time=1.642e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.824, loss=1.912, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.462e-04, train_time=0.878
[alab02] 2024-08-31 04:16:24,437 (trainer:720) INFO: 99epoch:train:3201-3400batch: iter_time=1.738e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=4.417, loss=2.209, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.462e-04, train_time=0.871
[alab02] 2024-08-31 04:17:52,465 (trainer:720) INFO: 99epoch:train:3401-3600batch: iter_time=1.837e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.922, loss=1.961, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.462e-04, train_time=0.880
[alab02] 2024-08-31 04:19:17,127 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 04:19:21,931 (trainer:720) INFO: 99epoch:train:3601-3800batch: iter_time=1.783e-04, forward_time=0.132, uma_reduction=0.283, text_vs_uma=0.345, loss_ctc=3.801, loss=1.900, backward_time=0.191, optim_step_time=0.034, optim0_lr0=1.462e-04, train_time=0.894
[alab02] 2024-08-31 04:20:48,304 (trainer:720) INFO: 99epoch:train:3801-4000batch: iter_time=1.795e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.361, loss_ctc=4.112, loss=2.056, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.462e-04, train_time=0.864
[alab02] 2024-08-31 04:22:14,999 (trainer:720) INFO: 99epoch:train:4001-4200batch: iter_time=1.734e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.341, loss_ctc=3.948, loss=1.974, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.461e-04, train_time=0.867
[alab02] 2024-08-31 04:23:41,089 (trainer:720) INFO: 99epoch:train:4201-4400batch: iter_time=1.719e-04, forward_time=0.127, uma_reduction=0.290, text_vs_uma=0.333, loss_ctc=3.622, loss=1.811, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.461e-04, train_time=0.861
[alab02] 2024-08-31 04:25:07,437 (trainer:720) INFO: 99epoch:train:4401-4600batch: iter_time=1.900e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.626, loss=1.813, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.461e-04, train_time=0.863
[alab02] 2024-08-31 04:26:34,466 (trainer:720) INFO: 99epoch:train:4601-4800batch: iter_time=1.759e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.774, loss=1.887, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.461e-04, train_time=0.870
[alab02] 2024-08-31 04:28:01,429 (trainer:720) INFO: 99epoch:train:4801-5000batch: iter_time=1.713e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.685, loss=1.843, backward_time=0.185, optim_step_time=0.032, optim0_lr0=1.461e-04, train_time=0.869
[alab02] 2024-08-31 04:29:30,028 (trainer:720) INFO: 99epoch:train:5001-5200batch: iter_time=1.962e-04, forward_time=0.132, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=3.500, loss=1.750, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.460e-04, train_time=0.886
[alab02] 2024-08-31 04:30:56,577 (trainer:720) INFO: 99epoch:train:5201-5400batch: iter_time=1.773e-04, forward_time=0.128, uma_reduction=0.285, text_vs_uma=0.333, loss_ctc=3.523, loss=1.762, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.460e-04, train_time=0.865
[alab02] 2024-08-31 04:32:21,735 (trainer:720) INFO: 99epoch:train:5401-5600batch: iter_time=1.770e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.834, loss=1.917, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.460e-04, train_time=0.851
[alab02] 2024-08-31 04:33:48,957 (trainer:720) INFO: 99epoch:train:5601-5800batch: iter_time=1.741e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=4.289, loss=2.144, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.460e-04, train_time=0.872
[alab02] 2024-08-31 04:35:13,445 (trainer:720) INFO: 99epoch:train:5801-6000batch: iter_time=1.735e-04, forward_time=0.125, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=3.915, loss=1.957, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.460e-04, train_time=0.845
[alab02] 2024-08-31 04:36:41,250 (trainer:720) INFO: 99epoch:train:6001-6200batch: iter_time=1.901e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.355, loss_ctc=3.757, loss=1.879, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.459e-04, train_time=0.878
[alab02] 2024-08-31 04:38:07,745 (trainer:720) INFO: 99epoch:train:6201-6400batch: iter_time=1.769e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.363, loss_ctc=3.984, loss=1.992, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.459e-04, train_time=0.865
[alab02] 2024-08-31 04:39:34,037 (trainer:720) INFO: 99epoch:train:6401-6600batch: iter_time=1.890e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=3.902, loss=1.951, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.459e-04, train_time=0.863
[alab02] 2024-08-31 04:41:01,137 (trainer:720) INFO: 99epoch:train:6601-6800batch: iter_time=2.185e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.362, loss_ctc=4.174, loss=2.087, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.459e-04, train_time=0.871
[alab02] 2024-08-31 04:42:28,606 (trainer:720) INFO: 99epoch:train:6801-7000batch: iter_time=1.830e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=4.033, loss=2.017, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.459e-04, train_time=0.874
[alab02] 2024-08-31 04:43:43,740 (trainer:338) INFO: 99epoch results: [train] iter_time=2.371e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.890, loss=1.945, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.462e-04, train_time=0.869, time=51 minutes and 38.34 seconds, total_count=705474, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.314, text_vs_uma=0.346, loss_ctc=3.070, cer_ctc=0.084, cer=0.084, loss=3.070, time=6.12 seconds, total_count=2574, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.62 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 04:43:48,249 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 04:43:48,377 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/92epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/98epoch.pth
[alab02] 2024-08-31 04:43:48,378 (trainer:272) INFO: 100/150epoch started. Estimated time to finish: 1 day, 22 hours and 15 minutes
[alab02] 2024-08-31 04:45:18,003 (trainer:720) INFO: 100epoch:train:1-200batch: iter_time=0.001, forward_time=0.132, uma_reduction=0.270, text_vs_uma=0.364, loss_ctc=4.275, loss=2.138, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.458e-04, train_time=0.896
[alab02] 2024-08-31 04:46:44,186 (trainer:720) INFO: 100epoch:train:201-400batch: iter_time=1.827e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=4.150, loss=2.075, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.458e-04, train_time=0.862
[alab02] 2024-08-31 04:48:09,897 (trainer:720) INFO: 100epoch:train:401-600batch: iter_time=1.826e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.889, loss=1.944, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.458e-04, train_time=0.857
[alab02] 2024-08-31 04:49:36,494 (trainer:720) INFO: 100epoch:train:601-800batch: iter_time=2.020e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=4.117, loss=2.058, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.458e-04, train_time=0.866
[alab02] 2024-08-31 04:51:03,314 (trainer:720) INFO: 100epoch:train:801-1000batch: iter_time=1.822e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.333, loss_ctc=3.299, loss=1.649, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.457e-04, train_time=0.868
[alab02] 2024-08-31 04:52:31,785 (trainer:720) INFO: 100epoch:train:1001-1200batch: iter_time=1.870e-04, forward_time=0.131, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.952, loss=1.976, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.457e-04, train_time=0.884
[alab02] 2024-08-31 04:53:56,478 (trainer:720) INFO: 100epoch:train:1201-1400batch: iter_time=1.882e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=4.001, loss=2.000, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.457e-04, train_time=0.847
[alab02] 2024-08-31 04:55:25,154 (trainer:720) INFO: 100epoch:train:1401-1600batch: iter_time=1.784e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=3.782, loss=1.891, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.457e-04, train_time=0.887
[alab02] 2024-08-31 04:56:51,369 (trainer:720) INFO: 100epoch:train:1601-1800batch: iter_time=1.862e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=3.843, loss=1.921, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.457e-04, train_time=0.862
[alab02] 2024-08-31 04:58:16,712 (trainer:720) INFO: 100epoch:train:1801-2000batch: iter_time=1.812e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=4.238, loss=2.119, backward_time=0.173, optim_step_time=0.034, optim0_lr0=1.456e-04, train_time=0.853
[alab02] 2024-08-31 04:59:43,781 (trainer:720) INFO: 100epoch:train:2001-2200batch: iter_time=1.871e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=3.696, loss=1.848, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.456e-04, train_time=0.870
[alab02] 2024-08-31 05:01:08,940 (trainer:720) INFO: 100epoch:train:2201-2400batch: iter_time=1.858e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.842, loss=1.921, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.456e-04, train_time=0.851
[alab02] 2024-08-31 05:02:34,822 (trainer:720) INFO: 100epoch:train:2401-2600batch: iter_time=1.792e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.714, loss=1.857, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.456e-04, train_time=0.859
[alab02] 2024-08-31 05:04:02,822 (trainer:720) INFO: 100epoch:train:2601-2800batch: iter_time=1.982e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.871, loss=1.935, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.455e-04, train_time=0.880
[alab02] 2024-08-31 05:05:28,331 (trainer:720) INFO: 100epoch:train:2801-3000batch: iter_time=1.830e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.913, loss=1.957, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.455e-04, train_time=0.855
[alab02] 2024-08-31 05:06:56,258 (trainer:720) INFO: 100epoch:train:3001-3200batch: iter_time=1.731e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=4.184, loss=2.092, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.455e-04, train_time=0.879
[alab02] 2024-08-31 05:08:25,898 (trainer:720) INFO: 100epoch:train:3201-3400batch: iter_time=1.881e-04, forward_time=0.133, uma_reduction=0.267, text_vs_uma=0.356, loss_ctc=3.923, loss=1.962, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.455e-04, train_time=0.896
[alab02] 2024-08-31 05:09:51,449 (trainer:720) INFO: 100epoch:train:3401-3600batch: iter_time=1.674e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.370, loss_ctc=3.851, loss=1.925, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.455e-04, train_time=0.855
[alab02] 2024-08-31 05:11:18,368 (trainer:720) INFO: 100epoch:train:3601-3800batch: iter_time=1.958e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.553, loss=1.776, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.454e-04, train_time=0.869
[alab02] 2024-08-31 05:12:45,863 (trainer:720) INFO: 100epoch:train:3801-4000batch: iter_time=1.812e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.350, loss_ctc=3.639, loss=1.819, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.454e-04, train_time=0.875
[alab02] 2024-08-31 05:14:15,104 (trainer:720) INFO: 100epoch:train:4001-4200batch: iter_time=1.768e-04, forward_time=0.132, uma_reduction=0.263, text_vs_uma=0.378, loss_ctc=3.979, loss=1.989, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.454e-04, train_time=0.892
[alab02] 2024-08-31 05:15:42,858 (trainer:720) INFO: 100epoch:train:4201-4400batch: iter_time=1.778e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=3.846, loss=1.923, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.454e-04, train_time=0.877
[alab02] 2024-08-31 05:17:08,259 (trainer:720) INFO: 100epoch:train:4401-4600batch: iter_time=1.912e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=4.381, loss=2.190, backward_time=0.172, optim_step_time=0.034, optim0_lr0=1.454e-04, train_time=0.854
[alab02] 2024-08-31 05:17:52,873 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 05:18:34,199 (trainer:720) INFO: 100epoch:train:4601-4800batch: iter_time=1.828e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.373, loss_ctc=4.103, loss=2.051, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.453e-04, train_time=0.859
[alab02] 2024-08-31 05:20:01,262 (trainer:720) INFO: 100epoch:train:4801-5000batch: iter_time=1.760e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=4.009, loss=2.004, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.453e-04, train_time=0.870
[alab02] 2024-08-31 05:21:28,678 (trainer:720) INFO: 100epoch:train:5001-5200batch: iter_time=1.642e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=3.857, loss=1.929, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.453e-04, train_time=0.874
[alab02] 2024-08-31 05:22:22,404 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 05:22:54,704 (trainer:720) INFO: 100epoch:train:5201-5400batch: iter_time=1.666e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.364, loss_ctc=3.937, loss=1.969, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.453e-04, train_time=0.860
[alab02] 2024-08-31 05:24:21,291 (trainer:720) INFO: 100epoch:train:5401-5600batch: iter_time=1.606e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.351, loss_ctc=3.863, loss=1.932, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.453e-04, train_time=0.866
[alab02] 2024-08-31 05:25:48,372 (trainer:720) INFO: 100epoch:train:5601-5800batch: iter_time=1.651e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=3.753, loss=1.877, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.452e-04, train_time=0.871
[alab02] 2024-08-31 05:27:15,648 (trainer:720) INFO: 100epoch:train:5801-6000batch: iter_time=1.631e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.351, loss_ctc=3.877, loss=1.939, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.452e-04, train_time=0.873
[alab02] 2024-08-31 05:28:41,789 (trainer:720) INFO: 100epoch:train:6001-6200batch: iter_time=1.754e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=3.576, loss=1.788, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.452e-04, train_time=0.861
[alab02] 2024-08-31 05:30:09,790 (trainer:720) INFO: 100epoch:train:6201-6400batch: iter_time=1.624e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=3.677, loss=1.839, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.452e-04, train_time=0.880
[alab02] 2024-08-31 05:31:36,245 (trainer:720) INFO: 100epoch:train:6401-6600batch: iter_time=1.792e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.336, loss_ctc=3.391, loss=1.695, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.452e-04, train_time=0.864
[alab02] 2024-08-31 05:33:03,939 (trainer:720) INFO: 100epoch:train:6601-6800batch: iter_time=1.715e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.346, loss_ctc=3.591, loss=1.795, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.451e-04, train_time=0.877
[alab02] 2024-08-31 05:34:31,841 (trainer:720) INFO: 100epoch:train:6801-7000batch: iter_time=1.714e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.343, loss_ctc=3.525, loss=1.762, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.451e-04, train_time=0.879
[alab02] 2024-08-31 05:35:48,258 (trainer:338) INFO: 100epoch results: [train] iter_time=2.153e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.847, loss=1.923, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.455e-04, train_time=0.870, time=51 minutes and 40.21 seconds, total_count=712600, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.272, text_vs_uma=0.400, loss_ctc=3.061, cer_ctc=0.087, cer=0.087, loss=3.061, time=6.03 seconds, total_count=2600, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.64 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 05:35:52,981 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 05:35:52,987 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/94epoch.pth
[alab02] 2024-08-31 05:35:52,988 (trainer:272) INFO: 101/150epoch started. Estimated time to finish: 1 day, 21 hours and 19 minutes
[alab02] 2024-08-31 05:37:20,829 (trainer:720) INFO: 101epoch:train:1-200batch: iter_time=0.001, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.361, loss_ctc=3.992, loss=1.996, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.451e-04, train_time=0.878
[alab02] 2024-08-31 05:38:49,239 (trainer:720) INFO: 101epoch:train:201-400batch: iter_time=1.850e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.697, loss=1.849, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.451e-04, train_time=0.884
[alab02] 2024-08-31 05:40:16,137 (trainer:720) INFO: 101epoch:train:401-600batch: iter_time=1.922e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.361, loss_ctc=3.607, loss=1.804, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.450e-04, train_time=0.869
[alab02] 2024-08-31 05:41:43,643 (trainer:720) INFO: 101epoch:train:601-800batch: iter_time=1.809e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.367, loss_ctc=3.900, loss=1.950, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.450e-04, train_time=0.875
[alab02] 2024-08-31 05:43:10,060 (trainer:720) INFO: 101epoch:train:801-1000batch: iter_time=1.865e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=4.021, loss=2.011, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.450e-04, train_time=0.864
[alab02] 2024-08-31 05:44:37,934 (trainer:720) INFO: 101epoch:train:1001-1200batch: iter_time=1.856e-04, forward_time=0.129, uma_reduction=0.278, text_vs_uma=0.343, loss_ctc=3.497, loss=1.748, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.450e-04, train_time=0.879
[alab02] 2024-08-31 05:46:06,351 (trainer:720) INFO: 101epoch:train:1201-1400batch: iter_time=1.794e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=3.613, loss=1.806, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.450e-04, train_time=0.884
[alab02] 2024-08-31 05:47:33,979 (trainer:720) INFO: 101epoch:train:1401-1600batch: iter_time=1.811e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.351, loss_ctc=4.197, loss=2.099, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.449e-04, train_time=0.876
[alab02] 2024-08-31 05:49:00,309 (trainer:720) INFO: 101epoch:train:1601-1800batch: iter_time=1.735e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.680, loss=1.840, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.449e-04, train_time=0.863
[alab02] 2024-08-31 05:50:25,403 (trainer:720) INFO: 101epoch:train:1801-2000batch: iter_time=1.788e-04, forward_time=0.125, uma_reduction=0.259, text_vs_uma=0.380, loss_ctc=4.060, loss=2.030, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.449e-04, train_time=0.851
[alab02] 2024-08-31 05:51:50,320 (trainer:720) INFO: 101epoch:train:2001-2200batch: iter_time=2.048e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.343, loss_ctc=3.417, loss=1.709, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.449e-04, train_time=0.849
[alab02] 2024-08-31 05:53:19,288 (trainer:720) INFO: 101epoch:train:2201-2400batch: iter_time=1.761e-04, forward_time=0.132, uma_reduction=0.267, text_vs_uma=0.366, loss_ctc=3.820, loss=1.910, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.449e-04, train_time=0.889
[alab02] 2024-08-31 05:54:46,849 (trainer:720) INFO: 101epoch:train:2401-2600batch: iter_time=1.892e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.355, loss_ctc=3.761, loss=1.881, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.448e-04, train_time=0.875
[alab02] 2024-08-31 05:56:11,990 (trainer:720) INFO: 101epoch:train:2601-2800batch: iter_time=1.748e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=4.006, loss=2.003, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.448e-04, train_time=0.851
[alab02] 2024-08-31 05:57:38,826 (trainer:720) INFO: 101epoch:train:2801-3000batch: iter_time=1.688e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.885, loss=1.943, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.448e-04, train_time=0.868
[alab02] 2024-08-31 05:59:05,389 (trainer:720) INFO: 101epoch:train:3001-3200batch: iter_time=1.815e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=3.801, loss=1.901, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.448e-04, train_time=0.865
[alab02] 2024-08-31 06:00:31,447 (trainer:720) INFO: 101epoch:train:3201-3400batch: iter_time=1.801e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.778, loss=1.889, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.448e-04, train_time=0.860
[alab02] 2024-08-31 06:01:58,217 (trainer:720) INFO: 101epoch:train:3401-3600batch: iter_time=1.654e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.379, loss_ctc=4.013, loss=2.006, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.447e-04, train_time=0.867
[alab02] 2024-08-31 06:02:28,775 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 06:03:23,900 (trainer:720) INFO: 101epoch:train:3601-3800batch: iter_time=1.693e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.372, loss_ctc=3.680, loss=1.840, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.447e-04, train_time=0.857
[alab02] 2024-08-31 06:04:49,346 (trainer:720) INFO: 101epoch:train:3801-4000batch: iter_time=1.760e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.857, loss=1.929, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.447e-04, train_time=0.854
[alab02] 2024-08-31 06:06:16,271 (trainer:720) INFO: 101epoch:train:4001-4200batch: iter_time=1.653e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=3.928, loss=1.964, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.447e-04, train_time=0.869
[alab02] 2024-08-31 06:07:44,173 (trainer:720) INFO: 101epoch:train:4201-4400batch: iter_time=1.772e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.367, loss=1.683, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.447e-04, train_time=0.879
[alab02] 2024-08-31 06:09:10,924 (trainer:720) INFO: 101epoch:train:4401-4600batch: iter_time=1.685e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=3.838, loss=1.919, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.446e-04, train_time=0.867
[alab02] 2024-08-31 06:10:39,250 (trainer:720) INFO: 101epoch:train:4601-4800batch: iter_time=1.664e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.376, loss_ctc=3.768, loss=1.884, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.446e-04, train_time=0.883
[alab02] 2024-08-31 06:12:06,088 (trainer:720) INFO: 101epoch:train:4801-5000batch: iter_time=1.614e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.551, loss=1.776, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.446e-04, train_time=0.868
[alab02] 2024-08-31 06:13:33,433 (trainer:720) INFO: 101epoch:train:5001-5200batch: iter_time=1.890e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=4.188, loss=2.094, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.446e-04, train_time=0.873
[alab02] 2024-08-31 06:14:58,930 (trainer:720) INFO: 101epoch:train:5201-5400batch: iter_time=1.742e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.939, loss=1.969, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.446e-04, train_time=0.855
[alab02] 2024-08-31 06:16:24,944 (trainer:720) INFO: 101epoch:train:5401-5600batch: iter_time=1.683e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=4.151, loss=2.076, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.445e-04, train_time=0.860
[alab02] 2024-08-31 06:17:51,011 (trainer:720) INFO: 101epoch:train:5601-5800batch: iter_time=1.612e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=4.113, loss=2.056, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.445e-04, train_time=0.860
[alab02] 2024-08-31 06:19:16,614 (trainer:720) INFO: 101epoch:train:5801-6000batch: iter_time=1.583e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=3.776, loss=1.888, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.445e-04, train_time=0.856
[alab02] 2024-08-31 06:20:42,405 (trainer:720) INFO: 101epoch:train:6001-6200batch: iter_time=1.733e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=3.625, loss=1.812, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.445e-04, train_time=0.858
[alab02] 2024-08-31 06:22:08,718 (trainer:720) INFO: 101epoch:train:6201-6400batch: iter_time=1.790e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.876, loss=1.938, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.445e-04, train_time=0.863
[alab02] 2024-08-31 06:23:34,692 (trainer:720) INFO: 101epoch:train:6401-6600batch: iter_time=1.771e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.747, loss=1.873, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.444e-04, train_time=0.859
[alab02] 2024-08-31 06:24:59,487 (trainer:720) INFO: 101epoch:train:6601-6800batch: iter_time=1.679e-04, forward_time=0.124, uma_reduction=0.263, text_vs_uma=0.373, loss_ctc=3.979, loss=1.989, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.444e-04, train_time=0.848
[alab02] 2024-08-31 06:26:25,625 (trainer:720) INFO: 101epoch:train:6801-7000batch: iter_time=1.780e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.357, loss_ctc=3.594, loss=1.797, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.444e-04, train_time=0.861
[alab02] 2024-08-31 06:27:40,235 (trainer:338) INFO: 101epoch results: [train] iter_time=2.121e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.810, loss=1.905, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.447e-04, train_time=0.866, time=51 minutes and 27.25 seconds, total_count=719726, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.275, text_vs_uma=0.395, loss_ctc=3.165, cer_ctc=0.088, cer=0.088, loss=3.165, time=6.12 seconds, total_count=2626, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.87 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 06:27:44,984 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 06:27:44,985 (trainer:272) INFO: 102/150epoch started. Estimated time to finish: 1 day, 20 hours and 24 minutes
[alab02] 2024-08-31 06:29:13,779 (trainer:720) INFO: 102epoch:train:1-200batch: iter_time=0.002, forward_time=0.133, uma_reduction=0.267, text_vs_uma=0.360, loss_ctc=3.698, loss=1.849, backward_time=0.183, optim_step_time=0.037, optim0_lr0=1.444e-04, train_time=0.887
[alab02] 2024-08-31 06:30:15,936 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 06:30:42,035 (trainer:720) INFO: 102epoch:train:201-400batch: iter_time=2.424e-04, forward_time=0.132, uma_reduction=0.263, text_vs_uma=0.365, loss_ctc=3.755, loss=1.877, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.443e-04, train_time=0.882
[alab02] 2024-08-31 06:32:08,918 (trainer:720) INFO: 102epoch:train:401-600batch: iter_time=2.286e-04, forward_time=0.131, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=3.625, loss=1.813, backward_time=0.181, optim_step_time=0.037, optim0_lr0=1.443e-04, train_time=0.869
[alab02] 2024-08-31 06:33:36,053 (trainer:720) INFO: 102epoch:train:601-800batch: iter_time=2.132e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.359, loss_ctc=3.662, loss=1.831, backward_time=0.181, optim_step_time=0.037, optim0_lr0=1.443e-04, train_time=0.871
[alab02] 2024-08-31 06:35:03,297 (trainer:720) INFO: 102epoch:train:801-1000batch: iter_time=2.114e-04, forward_time=0.130, uma_reduction=0.281, text_vs_uma=0.339, loss_ctc=3.728, loss=1.864, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.443e-04, train_time=0.872
[alab02] 2024-08-31 06:36:31,873 (trainer:720) INFO: 102epoch:train:1001-1200batch: iter_time=1.927e-04, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=3.757, loss=1.878, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.443e-04, train_time=0.886
[alab02] 2024-08-31 06:37:59,882 (trainer:720) INFO: 102epoch:train:1201-1400batch: iter_time=1.873e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.357, loss_ctc=4.153, loss=2.076, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.442e-04, train_time=0.880
[alab02] 2024-08-31 06:39:26,960 (trainer:720) INFO: 102epoch:train:1401-1600batch: iter_time=1.889e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.337, loss_ctc=3.539, loss=1.769, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.442e-04, train_time=0.871
[alab02] 2024-08-31 06:40:52,248 (trainer:720) INFO: 102epoch:train:1601-1800batch: iter_time=1.793e-04, forward_time=0.126, uma_reduction=0.286, text_vs_uma=0.334, loss_ctc=3.261, loss=1.631, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.442e-04, train_time=0.853
[alab02] 2024-08-31 06:42:20,650 (trainer:720) INFO: 102epoch:train:1801-2000batch: iter_time=1.865e-04, forward_time=0.131, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=3.689, loss=1.845, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.442e-04, train_time=0.884
[alab02] 2024-08-31 06:43:47,544 (trainer:720) INFO: 102epoch:train:2001-2200batch: iter_time=1.741e-04, forward_time=0.129, uma_reduction=0.286, text_vs_uma=0.339, loss_ctc=3.651, loss=1.826, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.442e-04, train_time=0.869
[alab02] 2024-08-31 06:45:15,233 (trainer:720) INFO: 102epoch:train:2201-2400batch: iter_time=1.824e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=3.754, loss=1.877, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.441e-04, train_time=0.877
[alab02] 2024-08-31 06:46:42,098 (trainer:720) INFO: 102epoch:train:2401-2600batch: iter_time=1.747e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.848, loss=1.924, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.441e-04, train_time=0.868
[alab02] 2024-08-31 06:48:08,189 (trainer:720) INFO: 102epoch:train:2601-2800batch: iter_time=1.813e-04, forward_time=0.127, uma_reduction=0.291, text_vs_uma=0.330, loss_ctc=3.480, loss=1.740, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.441e-04, train_time=0.861
[alab02] 2024-08-31 06:49:33,757 (trainer:720) INFO: 102epoch:train:2801-3000batch: iter_time=2.351e-04, forward_time=0.126, uma_reduction=0.292, text_vs_uma=0.329, loss_ctc=3.627, loss=1.814, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.441e-04, train_time=0.855
[alab02] 2024-08-31 06:51:00,200 (trainer:720) INFO: 102epoch:train:3001-3200batch: iter_time=1.737e-04, forward_time=0.128, uma_reduction=0.293, text_vs_uma=0.334, loss_ctc=3.637, loss=1.819, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.441e-04, train_time=0.864
[alab02] 2024-08-31 06:52:26,103 (trainer:720) INFO: 102epoch:train:3201-3400batch: iter_time=1.593e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.353, loss_ctc=3.880, loss=1.940, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.440e-04, train_time=0.859
[alab02] 2024-08-31 06:53:53,427 (trainer:720) INFO: 102epoch:train:3401-3600batch: iter_time=1.808e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.560, loss=1.780, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.440e-04, train_time=0.873
[alab02] 2024-08-31 06:55:18,720 (trainer:720) INFO: 102epoch:train:3601-3800batch: iter_time=1.720e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=4.162, loss=2.081, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.440e-04, train_time=0.853
[alab02] 2024-08-31 06:56:46,245 (trainer:720) INFO: 102epoch:train:3801-4000batch: iter_time=1.795e-04, forward_time=0.129, uma_reduction=0.283, text_vs_uma=0.349, loss_ctc=3.740, loss=1.870, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.440e-04, train_time=0.875
[alab02] 2024-08-31 06:58:13,420 (trainer:720) INFO: 102epoch:train:4001-4200batch: iter_time=1.593e-04, forward_time=0.130, uma_reduction=0.285, text_vs_uma=0.341, loss_ctc=4.019, loss=2.009, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.440e-04, train_time=0.872
[alab02] 2024-08-31 06:59:40,192 (trainer:720) INFO: 102epoch:train:4201-4400batch: iter_time=1.705e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.350, loss_ctc=3.921, loss=1.960, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.439e-04, train_time=0.867
[alab02] 2024-08-31 07:01:08,171 (trainer:720) INFO: 102epoch:train:4401-4600batch: iter_time=1.694e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.343, loss_ctc=3.641, loss=1.821, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.439e-04, train_time=0.880
[alab02] 2024-08-31 07:02:33,825 (trainer:720) INFO: 102epoch:train:4601-4800batch: iter_time=1.775e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.860, loss=1.930, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.439e-04, train_time=0.856
[alab02] 2024-08-31 07:03:59,633 (trainer:720) INFO: 102epoch:train:4801-5000batch: iter_time=1.772e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.904, loss=1.952, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.439e-04, train_time=0.858
[alab02] 2024-08-31 07:05:25,609 (trainer:720) INFO: 102epoch:train:5001-5200batch: iter_time=1.749e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=4.077, loss=2.039, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.439e-04, train_time=0.860
[alab02] 2024-08-31 07:06:52,189 (trainer:720) INFO: 102epoch:train:5201-5400batch: iter_time=1.849e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.351, loss_ctc=3.488, loss=1.744, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.438e-04, train_time=0.866
[alab02] 2024-08-31 07:08:20,210 (trainer:720) INFO: 102epoch:train:5401-5600batch: iter_time=1.723e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.352, loss_ctc=3.824, loss=1.912, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.438e-04, train_time=0.880
[alab02] 2024-08-31 07:09:49,377 (trainer:720) INFO: 102epoch:train:5601-5800batch: iter_time=1.696e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=3.852, loss=1.926, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.438e-04, train_time=0.891
[alab02] 2024-08-31 07:11:15,470 (trainer:720) INFO: 102epoch:train:5801-6000batch: iter_time=1.669e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.753, loss=1.876, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.438e-04, train_time=0.861
[alab02] 2024-08-31 07:12:43,191 (trainer:720) INFO: 102epoch:train:6001-6200batch: iter_time=1.634e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.360, loss_ctc=4.110, loss=2.055, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.438e-04, train_time=0.877
[alab02] 2024-08-31 07:14:09,613 (trainer:720) INFO: 102epoch:train:6201-6400batch: iter_time=1.822e-04, forward_time=0.128, uma_reduction=0.288, text_vs_uma=0.327, loss_ctc=3.500, loss=1.750, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.437e-04, train_time=0.864
[alab02] 2024-08-31 07:15:34,966 (trainer:720) INFO: 102epoch:train:6401-6600batch: iter_time=1.664e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.345, loss_ctc=3.736, loss=1.868, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.437e-04, train_time=0.853
[alab02] 2024-08-31 07:17:01,982 (trainer:720) INFO: 102epoch:train:6601-6800batch: iter_time=1.873e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.345, loss_ctc=3.849, loss=1.925, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.437e-04, train_time=0.870
[alab02] 2024-08-31 07:18:29,583 (trainer:720) INFO: 102epoch:train:6801-7000batch: iter_time=1.842e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.792, loss=1.896, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.437e-04, train_time=0.876
[alab02] 2024-08-31 07:19:44,915 (trainer:338) INFO: 102epoch results: [train] iter_time=2.307e-04, forward_time=0.129, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.755, loss=1.878, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.440e-04, train_time=0.870, time=51 minutes and 41.04 seconds, total_count=726852, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.286, text_vs_uma=0.379, loss_ctc=3.146, cer_ctc=0.088, cer=0.088, loss=3.146, time=6.03 seconds, total_count=2652, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.86 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 07:19:49,562 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 07:19:49,589 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/101epoch.pth
[alab02] 2024-08-31 07:19:49,589 (trainer:272) INFO: 103/150epoch started. Estimated time to finish: 1 day, 19 hours and 28 minutes
[alab02] 2024-08-31 07:21:18,004 (trainer:720) INFO: 103epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.376, loss_ctc=4.296, loss=2.148, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.437e-04, train_time=0.884
[alab02] 2024-08-31 07:22:43,856 (trainer:720) INFO: 103epoch:train:201-400batch: iter_time=1.859e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.703, loss=1.852, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.436e-04, train_time=0.858
[alab02] 2024-08-31 07:24:10,869 (trainer:720) INFO: 103epoch:train:401-600batch: iter_time=2.095e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.853, loss=1.927, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.436e-04, train_time=0.870
[alab02] 2024-08-31 07:25:36,492 (trainer:720) INFO: 103epoch:train:601-800batch: iter_time=1.930e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.909, loss=1.954, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.436e-04, train_time=0.856
[alab02] 2024-08-31 07:27:04,758 (trainer:720) INFO: 103epoch:train:801-1000batch: iter_time=1.715e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.359, loss_ctc=3.983, loss=1.991, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.436e-04, train_time=0.882
[alab02] 2024-08-31 07:28:32,264 (trainer:720) INFO: 103epoch:train:1001-1200batch: iter_time=1.932e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.338, loss_ctc=3.580, loss=1.790, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.436e-04, train_time=0.875
[alab02] 2024-08-31 07:29:58,284 (trainer:720) INFO: 103epoch:train:1201-1400batch: iter_time=1.993e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.117, loss=2.058, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.435e-04, train_time=0.860
[alab02] 2024-08-31 07:31:25,689 (trainer:720) INFO: 103epoch:train:1401-1600batch: iter_time=1.739e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=3.895, loss=1.947, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.435e-04, train_time=0.874
[alab02] 2024-08-31 07:32:51,725 (trainer:720) INFO: 103epoch:train:1601-1800batch: iter_time=1.676e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.353, loss_ctc=3.850, loss=1.925, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.435e-04, train_time=0.860
[alab02] 2024-08-31 07:34:19,014 (trainer:720) INFO: 103epoch:train:1801-2000batch: iter_time=1.929e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.856, loss=1.928, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.435e-04, train_time=0.873
[alab02] 2024-08-31 07:35:46,374 (trainer:720) INFO: 103epoch:train:2001-2200batch: iter_time=2.051e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=3.774, loss=1.887, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.435e-04, train_time=0.873
[alab02] 2024-08-31 07:37:15,767 (trainer:720) INFO: 103epoch:train:2201-2400batch: iter_time=2.260e-04, forward_time=0.133, uma_reduction=0.267, text_vs_uma=0.350, loss_ctc=3.672, loss=1.836, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.434e-04, train_time=0.894
[alab02] 2024-08-31 07:38:43,287 (trainer:720) INFO: 103epoch:train:2401-2600batch: iter_time=2.117e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.528, loss=1.764, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.434e-04, train_time=0.875
[alab02] 2024-08-31 07:40:09,289 (trainer:720) INFO: 103epoch:train:2601-2800batch: iter_time=1.868e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.351, loss_ctc=3.802, loss=1.901, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.434e-04, train_time=0.860
[alab02] 2024-08-31 07:41:14,081 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 07:41:38,120 (trainer:720) INFO: 103epoch:train:2801-3000batch: iter_time=1.753e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.873, loss=1.936, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.434e-04, train_time=0.888
[alab02] 2024-08-31 07:43:04,604 (trainer:720) INFO: 103epoch:train:3001-3200batch: iter_time=1.922e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.825, loss=1.913, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.434e-04, train_time=0.865
[alab02] 2024-08-31 07:44:31,589 (trainer:720) INFO: 103epoch:train:3201-3400batch: iter_time=1.870e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.839, loss=1.920, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.433e-04, train_time=0.870
[alab02] 2024-08-31 07:45:57,104 (trainer:720) INFO: 103epoch:train:3401-3600batch: iter_time=1.538e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.779, loss=1.890, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.433e-04, train_time=0.855
[alab02] 2024-08-31 07:47:23,608 (trainer:720) INFO: 103epoch:train:3601-3800batch: iter_time=1.665e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.926, loss=1.963, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.433e-04, train_time=0.865
[alab02] 2024-08-31 07:48:51,253 (trainer:720) INFO: 103epoch:train:3801-4000batch: iter_time=1.709e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=3.842, loss=1.921, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.433e-04, train_time=0.876
[alab02] 2024-08-31 07:50:18,364 (trainer:720) INFO: 103epoch:train:4001-4200batch: iter_time=1.549e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.813, loss=1.906, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.433e-04, train_time=0.871
[alab02] 2024-08-31 07:51:43,825 (trainer:720) INFO: 103epoch:train:4201-4400batch: iter_time=1.713e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.341, loss_ctc=3.606, loss=1.803, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.432e-04, train_time=0.854
[alab02] 2024-08-31 07:53:08,833 (trainer:720) INFO: 103epoch:train:4401-4600batch: iter_time=1.503e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.354, loss_ctc=4.211, loss=2.105, backward_time=0.173, optim_step_time=0.032, optim0_lr0=1.432e-04, train_time=0.850
[alab02] 2024-08-31 07:54:34,952 (trainer:720) INFO: 103epoch:train:4601-4800batch: iter_time=1.597e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.338, loss_ctc=3.631, loss=1.816, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.432e-04, train_time=0.861
[alab02] 2024-08-31 07:56:03,323 (trainer:720) INFO: 103epoch:train:4801-5000batch: iter_time=1.653e-04, forward_time=0.130, uma_reduction=0.284, text_vs_uma=0.344, loss_ctc=3.808, loss=1.904, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.432e-04, train_time=0.884
[alab02] 2024-08-31 07:57:28,852 (trainer:720) INFO: 103epoch:train:5001-5200batch: iter_time=1.543e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.376, loss=1.688, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.432e-04, train_time=0.855
[alab02] 2024-08-31 07:58:55,421 (trainer:720) INFO: 103epoch:train:5201-5400batch: iter_time=1.742e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.705, loss=1.853, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.431e-04, train_time=0.866
[alab02] 2024-08-31 08:00:22,446 (trainer:720) INFO: 103epoch:train:5401-5600batch: iter_time=1.750e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.991, loss=1.995, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.431e-04, train_time=0.870
[alab02] 2024-08-31 08:01:48,899 (trainer:720) INFO: 103epoch:train:5601-5800batch: iter_time=1.760e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.344, loss_ctc=3.622, loss=1.811, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.431e-04, train_time=0.864
[alab02] 2024-08-31 08:03:15,277 (trainer:720) INFO: 103epoch:train:5801-6000batch: iter_time=1.887e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.423, loss=1.712, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.431e-04, train_time=0.864
[alab02] 2024-08-31 08:04:42,414 (trainer:720) INFO: 103epoch:train:6001-6200batch: iter_time=1.911e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.507, loss=1.753, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.431e-04, train_time=0.871
[alab02] 2024-08-31 08:06:07,060 (trainer:720) INFO: 103epoch:train:6201-6400batch: iter_time=1.785e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=3.814, loss=1.907, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.430e-04, train_time=0.846
[alab02] 2024-08-31 08:07:33,744 (trainer:720) INFO: 103epoch:train:6401-6600batch: iter_time=1.775e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.903, loss=1.952, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.430e-04, train_time=0.867
[alab02] 2024-08-31 08:09:01,472 (trainer:720) INFO: 103epoch:train:6601-6800batch: iter_time=1.665e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=4.024, loss=2.012, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.430e-04, train_time=0.877
[alab02] 2024-08-31 08:10:28,452 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 08:10:28,463 (trainer:720) INFO: 103epoch:train:6801-7000batch: iter_time=1.733e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.865, loss=1.933, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.430e-04, train_time=0.870
[alab02] 2024-08-31 08:11:41,846 (trainer:338) INFO: 103epoch results: [train] iter_time=2.267e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.801, loss=1.901, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.433e-04, train_time=0.868, time=51 minutes and 33.12 seconds, total_count=733978, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.276, text_vs_uma=0.393, loss_ctc=3.164, cer_ctc=0.090, cer=0.090, loss=3.164, time=6.16 seconds, total_count=2678, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.97 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 08:11:46,531 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 08:11:46,586 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/102epoch.pth
[alab02] 2024-08-31 08:11:46,586 (trainer:272) INFO: 104/150epoch started. Estimated time to finish: 1 day, 18 hours and 33 minutes
[alab02] 2024-08-31 08:13:14,442 (trainer:720) INFO: 104epoch:train:1-200batch: iter_time=0.001, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.415, loss=1.708, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.430e-04, train_time=0.878
[alab02] 2024-08-31 08:14:41,902 (trainer:720) INFO: 104epoch:train:201-400batch: iter_time=1.890e-04, forward_time=0.129, uma_reduction=0.261, text_vs_uma=0.374, loss_ctc=4.238, loss=2.119, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.429e-04, train_time=0.874
[alab02] 2024-08-31 08:16:06,870 (trainer:720) INFO: 104epoch:train:401-600batch: iter_time=2.145e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=3.562, loss=1.781, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.429e-04, train_time=0.849
[alab02] 2024-08-31 08:17:33,136 (trainer:720) INFO: 104epoch:train:601-800batch: iter_time=2.157e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.346, loss_ctc=3.693, loss=1.847, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.429e-04, train_time=0.862
[alab02] 2024-08-31 08:19:00,661 (trainer:720) INFO: 104epoch:train:801-1000batch: iter_time=1.995e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.361, loss_ctc=3.815, loss=1.908, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.429e-04, train_time=0.875
[alab02] 2024-08-31 08:20:28,165 (trainer:720) INFO: 104epoch:train:1001-1200batch: iter_time=2.055e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.369, loss=1.685, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.429e-04, train_time=0.875
[alab02] 2024-08-31 08:21:56,142 (trainer:720) INFO: 104epoch:train:1201-1400batch: iter_time=2.092e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.910, loss=1.955, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.428e-04, train_time=0.880
[alab02] 2024-08-31 08:23:24,405 (trainer:720) INFO: 104epoch:train:1401-1600batch: iter_time=2.032e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.348, loss_ctc=3.997, loss=1.999, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.428e-04, train_time=0.882
[alab02] 2024-08-31 08:24:49,778 (trainer:720) INFO: 104epoch:train:1601-1800batch: iter_time=1.935e-04, forward_time=0.126, uma_reduction=0.283, text_vs_uma=0.348, loss_ctc=3.883, loss=1.941, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.428e-04, train_time=0.854
[alab02] 2024-08-31 08:26:17,173 (trainer:720) INFO: 104epoch:train:1801-2000batch: iter_time=1.843e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.353, loss_ctc=3.898, loss=1.949, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.428e-04, train_time=0.874
[alab02] 2024-08-31 08:27:41,713 (trainer:720) INFO: 104epoch:train:2001-2200batch: iter_time=1.689e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.782, loss=1.891, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.428e-04, train_time=0.845
[alab02] 2024-08-31 08:29:08,253 (trainer:720) INFO: 104epoch:train:2201-2400batch: iter_time=1.655e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.343, loss_ctc=3.625, loss=1.812, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.427e-04, train_time=0.865
[alab02] 2024-08-31 08:30:35,579 (trainer:720) INFO: 104epoch:train:2401-2600batch: iter_time=1.688e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.736, loss=1.868, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.427e-04, train_time=0.873
[alab02] 2024-08-31 08:32:01,068 (trainer:720) INFO: 104epoch:train:2601-2800batch: iter_time=1.824e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.346, loss_ctc=3.730, loss=1.865, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.427e-04, train_time=0.855
[alab02] 2024-08-31 08:33:26,606 (trainer:720) INFO: 104epoch:train:2801-3000batch: iter_time=1.615e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.372, loss_ctc=4.133, loss=2.066, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.427e-04, train_time=0.855
[alab02] 2024-08-31 08:34:52,737 (trainer:720) INFO: 104epoch:train:3001-3200batch: iter_time=1.658e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.363, loss_ctc=4.010, loss=2.005, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.427e-04, train_time=0.861
[alab02] 2024-08-31 08:36:18,855 (trainer:720) INFO: 104epoch:train:3201-3400batch: iter_time=1.642e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.343, loss_ctc=3.697, loss=1.848, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.426e-04, train_time=0.861
[alab02] 2024-08-31 08:37:45,012 (trainer:720) INFO: 104epoch:train:3401-3600batch: iter_time=1.803e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.829, loss=1.915, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.426e-04, train_time=0.861
[alab02] 2024-08-31 08:39:12,431 (trainer:720) INFO: 104epoch:train:3601-3800batch: iter_time=1.704e-04, forward_time=0.130, uma_reduction=0.263, text_vs_uma=0.372, loss_ctc=4.071, loss=2.035, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.426e-04, train_time=0.874
[alab02] 2024-08-31 08:40:39,466 (trainer:720) INFO: 104epoch:train:3801-4000batch: iter_time=2.040e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.361, loss_ctc=3.840, loss=1.920, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.426e-04, train_time=0.870
[alab02] 2024-08-31 08:42:06,378 (trainer:720) INFO: 104epoch:train:4001-4200batch: iter_time=1.632e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.349, loss_ctc=3.896, loss=1.948, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.426e-04, train_time=0.869
[alab02] 2024-08-31 08:43:32,099 (trainer:720) INFO: 104epoch:train:4201-4400batch: iter_time=1.662e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=3.746, loss=1.873, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.426e-04, train_time=0.857
[alab02] 2024-08-31 08:44:57,842 (trainer:720) INFO: 104epoch:train:4401-4600batch: iter_time=1.758e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.342, loss_ctc=3.617, loss=1.809, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.425e-04, train_time=0.857
[alab02] 2024-08-31 08:46:25,969 (trainer:720) INFO: 104epoch:train:4601-4800batch: iter_time=1.749e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=3.806, loss=1.903, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.425e-04, train_time=0.881
[alab02] 2024-08-31 08:47:52,414 (trainer:720) INFO: 104epoch:train:4801-5000batch: iter_time=1.725e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.358, loss_ctc=3.693, loss=1.847, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.425e-04, train_time=0.864
[alab02] 2024-08-31 08:49:20,432 (trainer:720) INFO: 104epoch:train:5001-5200batch: iter_time=2.120e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.350, loss_ctc=3.552, loss=1.776, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.425e-04, train_time=0.880
[alab02] 2024-08-31 08:50:11,486 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 08:50:47,001 (trainer:720) INFO: 104epoch:train:5201-5400batch: iter_time=1.771e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.740, loss=1.870, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.425e-04, train_time=0.865
[alab02] 2024-08-31 08:52:14,213 (trainer:720) INFO: 104epoch:train:5401-5600batch: iter_time=1.734e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.857, loss=1.929, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.424e-04, train_time=0.872
[alab02] 2024-08-31 08:53:40,602 (trainer:720) INFO: 104epoch:train:5601-5800batch: iter_time=1.635e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.364, loss_ctc=4.009, loss=2.005, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.424e-04, train_time=0.864
[alab02] 2024-08-31 08:55:07,249 (trainer:720) INFO: 104epoch:train:5801-6000batch: iter_time=1.636e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.375, loss_ctc=4.029, loss=2.014, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.424e-04, train_time=0.866
[alab02] 2024-08-31 08:56:33,274 (trainer:720) INFO: 104epoch:train:6001-6200batch: iter_time=1.640e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.373, loss_ctc=3.902, loss=1.951, backward_time=0.177, optim_step_time=0.035, optim0_lr0=1.424e-04, train_time=0.860
[alab02] 2024-08-31 08:58:00,395 (trainer:720) INFO: 104epoch:train:6201-6400batch: iter_time=1.686e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.336, loss_ctc=3.642, loss=1.821, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.424e-04, train_time=0.871
[alab02] 2024-08-31 08:59:28,398 (trainer:720) INFO: 104epoch:train:6401-6600batch: iter_time=1.663e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.349, loss_ctc=4.045, loss=2.023, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.423e-04, train_time=0.880
[alab02] 2024-08-31 09:00:54,731 (trainer:720) INFO: 104epoch:train:6601-6800batch: iter_time=1.729e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.341, loss_ctc=3.592, loss=1.796, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.423e-04, train_time=0.863
[alab02] 2024-08-31 09:02:20,826 (trainer:720) INFO: 104epoch:train:6801-7000batch: iter_time=1.721e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=4.259, loss=2.130, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.423e-04, train_time=0.861
[alab02] 2024-08-31 09:03:34,310 (trainer:338) INFO: 104epoch results: [train] iter_time=2.146e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.809, loss=1.904, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.426e-04, train_time=0.867, time=51 minutes and 28.96 seconds, total_count=741104, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.296, text_vs_uma=0.367, loss_ctc=3.150, cer_ctc=0.088, cer=0.088, loss=3.150, time=6.03 seconds, total_count=2704, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.72 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 09:03:38,840 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 09:03:38,886 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/103epoch.pth
[alab02] 2024-08-31 09:03:38,887 (trainer:272) INFO: 105/150epoch started. Estimated time to finish: 1 day, 17 hours and 37 minutes
[alab02] 2024-08-31 09:05:05,437 (trainer:720) INFO: 105epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.849, loss=1.925, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.423e-04, train_time=0.865
[alab02] 2024-08-31 09:06:33,264 (trainer:720) INFO: 105epoch:train:201-400batch: iter_time=1.946e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.933, loss=1.966, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.423e-04, train_time=0.878
[alab02] 2024-08-31 09:08:02,534 (trainer:720) INFO: 105epoch:train:401-600batch: iter_time=1.994e-04, forward_time=0.132, uma_reduction=0.261, text_vs_uma=0.373, loss_ctc=4.058, loss=2.029, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.422e-04, train_time=0.892
[alab02] 2024-08-31 09:09:31,878 (trainer:720) INFO: 105epoch:train:601-800batch: iter_time=1.960e-04, forward_time=0.133, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.993, loss=1.997, backward_time=0.188, optim_step_time=0.034, optim0_lr0=1.422e-04, train_time=0.893
[alab02] 2024-08-31 09:10:58,661 (trainer:720) INFO: 105epoch:train:801-1000batch: iter_time=2.070e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.364, loss_ctc=3.732, loss=1.866, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.422e-04, train_time=0.868
[alab02] 2024-08-31 09:12:26,387 (trainer:720) INFO: 105epoch:train:1001-1200batch: iter_time=2.076e-04, forward_time=0.130, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.837, loss=1.918, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.422e-04, train_time=0.877
[alab02] 2024-08-31 09:13:54,322 (trainer:720) INFO: 105epoch:train:1201-1400batch: iter_time=1.968e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.895, loss=1.947, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.422e-04, train_time=0.879
[alab02] 2024-08-31 09:15:19,989 (trainer:720) INFO: 105epoch:train:1401-1600batch: iter_time=2.350e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.342, loss_ctc=3.401, loss=1.701, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.421e-04, train_time=0.857
[alab02] 2024-08-31 09:16:50,249 (trainer:720) INFO: 105epoch:train:1601-1800batch: iter_time=1.900e-04, forward_time=0.134, uma_reduction=0.281, text_vs_uma=0.342, loss_ctc=3.596, loss=1.798, backward_time=0.192, optim_step_time=0.034, optim0_lr0=1.421e-04, train_time=0.902
[alab02] 2024-08-31 09:18:17,258 (trainer:720) INFO: 105epoch:train:1801-2000batch: iter_time=1.883e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.897, loss=1.948, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.421e-04, train_time=0.870
[alab02] 2024-08-31 09:19:45,448 (trainer:720) INFO: 105epoch:train:2001-2200batch: iter_time=1.832e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.346, loss_ctc=3.768, loss=1.884, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.421e-04, train_time=0.882
[alab02] 2024-08-31 09:20:43,508 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 09:21:11,280 (trainer:720) INFO: 105epoch:train:2201-2400batch: iter_time=1.793e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.671, loss=1.836, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.421e-04, train_time=0.858
[alab02] 2024-08-31 09:22:38,122 (trainer:720) INFO: 105epoch:train:2401-2600batch: iter_time=1.737e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.949, loss=1.974, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.420e-04, train_time=0.868
[alab02] 2024-08-31 09:24:04,862 (trainer:720) INFO: 105epoch:train:2601-2800batch: iter_time=1.811e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=3.936, loss=1.968, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.420e-04, train_time=0.867
[alab02] 2024-08-31 09:25:28,925 (trainer:720) INFO: 105epoch:train:2801-3000batch: iter_time=1.783e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.812, loss=1.906, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.420e-04, train_time=0.840
[alab02] 2024-08-31 09:26:54,453 (trainer:720) INFO: 105epoch:train:3001-3200batch: iter_time=1.710e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.888, loss=1.944, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.420e-04, train_time=0.855
[alab02] 2024-08-31 09:28:21,601 (trainer:720) INFO: 105epoch:train:3201-3400batch: iter_time=1.756e-04, forward_time=0.129, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.787, loss=1.894, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.420e-04, train_time=0.871
[alab02] 2024-08-31 09:29:48,354 (trainer:720) INFO: 105epoch:train:3401-3600batch: iter_time=1.841e-04, forward_time=0.128, uma_reduction=0.289, text_vs_uma=0.332, loss_ctc=3.876, loss=1.938, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.419e-04, train_time=0.867
[alab02] 2024-08-31 09:31:14,737 (trainer:720) INFO: 105epoch:train:3601-3800batch: iter_time=1.982e-04, forward_time=0.127, uma_reduction=0.287, text_vs_uma=0.345, loss_ctc=4.072, loss=2.036, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.419e-04, train_time=0.864
[alab02] 2024-08-31 09:32:41,287 (trainer:720) INFO: 105epoch:train:3801-4000batch: iter_time=1.741e-04, forward_time=0.128, uma_reduction=0.291, text_vs_uma=0.334, loss_ctc=3.771, loss=1.885, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.419e-04, train_time=0.865
[alab02] 2024-08-31 09:34:07,851 (trainer:720) INFO: 105epoch:train:4001-4200batch: iter_time=1.806e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.755, loss=1.878, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.419e-04, train_time=0.865
[alab02] 2024-08-31 09:35:35,200 (trainer:720) INFO: 105epoch:train:4201-4400batch: iter_time=1.640e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.707, loss=1.854, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.419e-04, train_time=0.873
[alab02] 2024-08-31 09:37:01,247 (trainer:720) INFO: 105epoch:train:4401-4600batch: iter_time=1.817e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.338, loss_ctc=3.398, loss=1.699, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.418e-04, train_time=0.860
[alab02] 2024-08-31 09:38:27,856 (trainer:720) INFO: 105epoch:train:4601-4800batch: iter_time=1.678e-04, forward_time=0.128, uma_reduction=0.285, text_vs_uma=0.333, loss_ctc=3.460, loss=1.730, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.418e-04, train_time=0.866
[alab02] 2024-08-31 09:39:54,551 (trainer:720) INFO: 105epoch:train:4801-5000batch: iter_time=1.766e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.350, loss_ctc=3.923, loss=1.962, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.418e-04, train_time=0.867
[alab02] 2024-08-31 09:41:22,637 (trainer:720) INFO: 105epoch:train:5001-5200batch: iter_time=1.746e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.354, loss_ctc=3.857, loss=1.928, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.418e-04, train_time=0.881
[alab02] 2024-08-31 09:42:48,197 (trainer:720) INFO: 105epoch:train:5201-5400batch: iter_time=1.628e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.745, loss=1.872, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.418e-04, train_time=0.855
[alab02] 2024-08-31 09:44:15,177 (trainer:720) INFO: 105epoch:train:5401-5600batch: iter_time=1.662e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.983, loss=1.991, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.418e-04, train_time=0.870
[alab02] 2024-08-31 09:45:42,526 (trainer:720) INFO: 105epoch:train:5601-5800batch: iter_time=1.886e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=3.982, loss=1.991, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.417e-04, train_time=0.873
[alab02] 2024-08-31 09:47:08,720 (trainer:720) INFO: 105epoch:train:5801-6000batch: iter_time=1.647e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.352, loss_ctc=3.768, loss=1.884, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.417e-04, train_time=0.862
[alab02] 2024-08-31 09:48:35,542 (trainer:720) INFO: 105epoch:train:6001-6200batch: iter_time=1.597e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.635, loss=1.818, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.417e-04, train_time=0.868
[alab02] 2024-08-31 09:50:00,322 (trainer:720) INFO: 105epoch:train:6201-6400batch: iter_time=1.582e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.963, loss=1.982, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.417e-04, train_time=0.848
[alab02] 2024-08-31 09:51:27,561 (trainer:720) INFO: 105epoch:train:6401-6600batch: iter_time=1.690e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.460, loss=1.730, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.417e-04, train_time=0.872
[alab02] 2024-08-31 09:52:53,675 (trainer:720) INFO: 105epoch:train:6601-6800batch: iter_time=1.522e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.731, loss=1.866, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.416e-04, train_time=0.861
[alab02] 2024-08-31 09:54:19,187 (trainer:720) INFO: 105epoch:train:6801-7000batch: iter_time=1.574e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.364, loss_ctc=3.741, loss=1.871, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.416e-04, train_time=0.855
[alab02] 2024-08-31 09:54:38,798 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 09:55:32,024 (trainer:338) INFO: 105epoch results: [train] iter_time=2.313e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.793, loss=1.897, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.419e-04, train_time=0.868, time=51 minutes and 34.57 seconds, total_count=748230, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.275, text_vs_uma=0.395, loss_ctc=3.180, cer_ctc=0.092, cer=0.092, loss=3.180, time=5.95 seconds, total_count=2730, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.61 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 09:55:36,294 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 09:55:36,353 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/104epoch.pth
[alab02] 2024-08-31 09:55:36,353 (trainer:272) INFO: 106/150epoch started. Estimated time to finish: 1 day, 16 hours and 42 minutes
[alab02] 2024-08-31 09:57:05,139 (trainer:720) INFO: 106epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=3.787, loss=1.894, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.416e-04, train_time=0.887
[alab02] 2024-08-31 09:58:31,845 (trainer:720) INFO: 106epoch:train:201-400batch: iter_time=1.829e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.359, loss_ctc=3.766, loss=1.883, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.416e-04, train_time=0.867
[alab02] 2024-08-31 09:59:58,594 (trainer:720) INFO: 106epoch:train:401-600batch: iter_time=1.778e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.599, loss=1.800, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.416e-04, train_time=0.867
[alab02] 2024-08-31 10:01:23,978 (trainer:720) INFO: 106epoch:train:601-800batch: iter_time=2.054e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.688, loss=1.844, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.415e-04, train_time=0.854
[alab02] 2024-08-31 10:02:50,114 (trainer:720) INFO: 106epoch:train:801-1000batch: iter_time=1.917e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.704, loss=1.852, backward_time=0.175, optim_step_time=0.035, optim0_lr0=1.415e-04, train_time=0.861
[alab02] 2024-08-31 10:04:17,446 (trainer:720) INFO: 106epoch:train:1001-1200batch: iter_time=1.855e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.579, loss=1.790, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.415e-04, train_time=0.873
[alab02] 2024-08-31 10:05:45,608 (trainer:720) INFO: 106epoch:train:1201-1400batch: iter_time=2.011e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.648, loss=1.824, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.415e-04, train_time=0.881
[alab02] 2024-08-31 10:07:11,622 (trainer:720) INFO: 106epoch:train:1401-1600batch: iter_time=1.878e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.360, loss_ctc=3.620, loss=1.810, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.415e-04, train_time=0.860
[alab02] 2024-08-31 10:08:38,322 (trainer:720) INFO: 106epoch:train:1601-1800batch: iter_time=2.102e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=3.524, loss=1.762, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.414e-04, train_time=0.867
[alab02] 2024-08-31 10:10:03,704 (trainer:720) INFO: 106epoch:train:1801-2000batch: iter_time=1.626e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.353, loss_ctc=3.590, loss=1.795, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.414e-04, train_time=0.854
[alab02] 2024-08-31 10:11:29,137 (trainer:720) INFO: 106epoch:train:2001-2200batch: iter_time=1.711e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.366, loss_ctc=3.811, loss=1.906, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.414e-04, train_time=0.854
[alab02] 2024-08-31 10:12:56,193 (trainer:720) INFO: 106epoch:train:2201-2400batch: iter_time=1.659e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.437, loss=1.719, backward_time=0.185, optim_step_time=0.032, optim0_lr0=1.414e-04, train_time=0.870
[alab02] 2024-08-31 10:14:21,148 (trainer:720) INFO: 106epoch:train:2401-2600batch: iter_time=1.624e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.392, loss=1.696, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.414e-04, train_time=0.849
[alab02] 2024-08-31 10:15:47,877 (trainer:720) INFO: 106epoch:train:2601-2800batch: iter_time=1.662e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.855, loss=1.928, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.413e-04, train_time=0.867
[alab02] 2024-08-31 10:17:12,984 (trainer:720) INFO: 106epoch:train:2801-3000batch: iter_time=1.533e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.776, loss=1.888, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.413e-04, train_time=0.851
[alab02] 2024-08-31 10:18:40,117 (trainer:720) INFO: 106epoch:train:3001-3200batch: iter_time=1.576e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.682, loss=1.841, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.413e-04, train_time=0.871
[alab02] 2024-08-31 10:20:08,500 (trainer:720) INFO: 106epoch:train:3201-3400batch: iter_time=1.630e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.912, loss=1.956, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.413e-04, train_time=0.884
[alab02] 2024-08-31 10:21:35,145 (trainer:720) INFO: 106epoch:train:3401-3600batch: iter_time=1.563e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.357, loss_ctc=3.638, loss=1.819, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.413e-04, train_time=0.866
[alab02] 2024-08-31 10:23:01,220 (trainer:720) INFO: 106epoch:train:3601-3800batch: iter_time=1.586e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=3.690, loss=1.845, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.413e-04, train_time=0.861
[alab02] 2024-08-31 10:24:29,304 (trainer:720) INFO: 106epoch:train:3801-4000batch: iter_time=1.707e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.628, loss=1.814, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.412e-04, train_time=0.881
[alab02] 2024-08-31 10:25:56,967 (trainer:720) INFO: 106epoch:train:4001-4200batch: iter_time=1.611e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.936, loss=1.968, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.412e-04, train_time=0.876
[alab02] 2024-08-31 10:27:20,968 (trainer:720) INFO: 106epoch:train:4201-4400batch: iter_time=1.657e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.808, loss=1.904, backward_time=0.172, optim_step_time=0.034, optim0_lr0=1.412e-04, train_time=0.840
[alab02] 2024-08-31 10:28:47,976 (trainer:720) INFO: 106epoch:train:4401-4600batch: iter_time=1.629e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.822, loss=1.911, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.412e-04, train_time=0.870
[alab02] 2024-08-31 10:29:59,268 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 10:30:14,606 (trainer:720) INFO: 106epoch:train:4601-4800batch: iter_time=1.620e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.339, loss_ctc=3.479, loss=1.739, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.412e-04, train_time=0.866
[alab02] 2024-08-31 10:31:41,453 (trainer:720) INFO: 106epoch:train:4801-5000batch: iter_time=1.574e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.820, loss=1.910, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.411e-04, train_time=0.868
[alab02] 2024-08-31 10:33:07,163 (trainer:720) INFO: 106epoch:train:5001-5200batch: iter_time=1.684e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.771, loss=1.886, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.411e-04, train_time=0.857
[alab02] 2024-08-31 10:34:35,338 (trainer:720) INFO: 106epoch:train:5201-5400batch: iter_time=1.705e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.900, loss=1.950, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.411e-04, train_time=0.882
[alab02] 2024-08-31 10:36:02,449 (trainer:720) INFO: 106epoch:train:5401-5600batch: iter_time=1.705e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=3.803, loss=1.902, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.411e-04, train_time=0.871
[alab02] 2024-08-31 10:37:27,057 (trainer:720) INFO: 106epoch:train:5601-5800batch: iter_time=1.574e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.595, loss=1.798, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.411e-04, train_time=0.846
[alab02] 2024-08-31 10:38:51,343 (trainer:720) INFO: 106epoch:train:5801-6000batch: iter_time=1.700e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.365, loss_ctc=3.730, loss=1.865, backward_time=0.172, optim_step_time=0.033, optim0_lr0=1.410e-04, train_time=0.843
[alab02] 2024-08-31 10:40:18,307 (trainer:720) INFO: 106epoch:train:6001-6200batch: iter_time=1.744e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.342, loss_ctc=3.415, loss=1.708, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.410e-04, train_time=0.869
[alab02] 2024-08-31 10:41:44,254 (trainer:720) INFO: 106epoch:train:6201-6400batch: iter_time=1.765e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.357, loss_ctc=3.615, loss=1.807, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.410e-04, train_time=0.859
[alab02] 2024-08-31 10:43:11,997 (trainer:720) INFO: 106epoch:train:6401-6600batch: iter_time=1.862e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.340, loss_ctc=3.308, loss=1.654, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.410e-04, train_time=0.877
[alab02] 2024-08-31 10:44:37,304 (trainer:720) INFO: 106epoch:train:6601-6800batch: iter_time=1.751e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.660, loss=1.830, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.410e-04, train_time=0.853
[alab02] 2024-08-31 10:45:15,490 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 10:46:03,440 (trainer:720) INFO: 106epoch:train:6801-7000batch: iter_time=1.800e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.678, loss=1.839, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.410e-04, train_time=0.861
[alab02] 2024-08-31 10:47:18,350 (trainer:338) INFO: 106epoch results: [train] iter_time=2.263e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.680, loss=1.840, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.413e-04, train_time=0.865, time=51 minutes and 22.19 seconds, total_count=755356, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.289, text_vs_uma=0.375, loss_ctc=3.003, cer_ctc=0.080, cer=0.080, loss=3.003, time=6.19 seconds, total_count=2756, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.62 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 10:47:23,268 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-31 10:47:23,336 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/81epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/105epoch.pth
[alab02] 2024-08-31 10:47:23,337 (trainer:272) INFO: 107/150epoch started. Estimated time to finish: 1 day, 15 hours and 47 minutes
[alab02] 2024-08-31 10:48:51,663 (trainer:720) INFO: 107epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=3.636, loss=1.818, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.409e-04, train_time=0.883
[alab02] 2024-08-31 10:50:17,435 (trainer:720) INFO: 107epoch:train:201-400batch: iter_time=1.896e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.519, loss=1.759, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.409e-04, train_time=0.857
[alab02] 2024-08-31 10:51:44,308 (trainer:720) INFO: 107epoch:train:401-600batch: iter_time=1.978e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.368, loss_ctc=3.683, loss=1.841, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.409e-04, train_time=0.868
[alab02] 2024-08-31 10:53:11,679 (trainer:720) INFO: 107epoch:train:601-800batch: iter_time=2.078e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.370, loss_ctc=3.834, loss=1.917, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.409e-04, train_time=0.873
[alab02] 2024-08-31 10:54:40,521 (trainer:720) INFO: 107epoch:train:801-1000batch: iter_time=1.714e-04, forward_time=0.131, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=3.663, loss=1.832, backward_time=0.188, optim_step_time=0.034, optim0_lr0=1.408e-04, train_time=0.888
[alab02] 2024-08-31 10:56:05,084 (trainer:720) INFO: 107epoch:train:1001-1200batch: iter_time=1.802e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.359, loss_ctc=3.650, loss=1.825, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.408e-04, train_time=0.845
[alab02] 2024-08-31 10:57:30,940 (trainer:720) INFO: 107epoch:train:1201-1400batch: iter_time=1.807e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.378, loss_ctc=4.104, loss=2.052, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.408e-04, train_time=0.858
[alab02] 2024-08-31 10:58:58,285 (trainer:720) INFO: 107epoch:train:1401-1600batch: iter_time=1.832e-04, forward_time=0.130, uma_reduction=0.256, text_vs_uma=0.382, loss_ctc=4.006, loss=2.003, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.408e-04, train_time=0.873
[alab02] 2024-08-31 11:00:23,135 (trainer:720) INFO: 107epoch:train:1601-1800batch: iter_time=1.869e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=3.540, loss=1.770, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.408e-04, train_time=0.848
[alab02] 2024-08-31 11:01:51,745 (trainer:720) INFO: 107epoch:train:1801-2000batch: iter_time=1.789e-04, forward_time=0.131, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=3.651, loss=1.825, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.408e-04, train_time=0.886
[alab02] 2024-08-31 11:03:18,353 (trainer:720) INFO: 107epoch:train:2001-2200batch: iter_time=1.733e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.377, loss_ctc=4.131, loss=2.065, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.407e-04, train_time=0.866
[alab02] 2024-08-31 11:04:43,842 (trainer:720) INFO: 107epoch:train:2201-2400batch: iter_time=1.765e-04, forward_time=0.126, uma_reduction=0.259, text_vs_uma=0.375, loss_ctc=3.741, loss=1.870, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.407e-04, train_time=0.855
[alab02] 2024-08-31 11:06:09,744 (trainer:720) INFO: 107epoch:train:2401-2600batch: iter_time=1.839e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.365, loss_ctc=3.474, loss=1.737, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.407e-04, train_time=0.859
[alab02] 2024-08-31 11:07:37,624 (trainer:720) INFO: 107epoch:train:2601-2800batch: iter_time=1.827e-04, forward_time=0.129, uma_reduction=0.259, text_vs_uma=0.376, loss_ctc=3.881, loss=1.941, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.407e-04, train_time=0.879
[alab02] 2024-08-31 11:09:04,051 (trainer:720) INFO: 107epoch:train:2801-3000batch: iter_time=1.794e-04, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=3.857, loss=1.929, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.407e-04, train_time=0.864
[alab02] 2024-08-31 11:10:29,134 (trainer:720) INFO: 107epoch:train:3001-3200batch: iter_time=1.735e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.364, loss_ctc=3.870, loss=1.935, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.406e-04, train_time=0.851
[alab02] 2024-08-31 11:11:56,773 (trainer:720) INFO: 107epoch:train:3201-3400batch: iter_time=1.720e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.452, loss=1.726, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.406e-04, train_time=0.876
[alab02] 2024-08-31 11:13:25,182 (trainer:720) INFO: 107epoch:train:3401-3600batch: iter_time=1.627e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=4.114, loss=2.057, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.406e-04, train_time=0.884
[alab02] 2024-08-31 11:14:52,877 (trainer:720) INFO: 107epoch:train:3601-3800batch: iter_time=1.706e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=3.747, loss=1.874, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.406e-04, train_time=0.877
[alab02] 2024-08-31 11:16:18,791 (trainer:720) INFO: 107epoch:train:3801-4000batch: iter_time=1.780e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.359, loss_ctc=3.679, loss=1.840, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.406e-04, train_time=0.859
[alab02] 2024-08-31 11:17:44,970 (trainer:720) INFO: 107epoch:train:4001-4200batch: iter_time=1.765e-04, forward_time=0.129, uma_reduction=0.260, text_vs_uma=0.374, loss_ctc=3.722, loss=1.861, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.406e-04, train_time=0.862
[alab02] 2024-08-31 11:19:11,395 (trainer:720) INFO: 107epoch:train:4201-4400batch: iter_time=1.747e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.863, loss=1.932, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.405e-04, train_time=0.864
[alab02] 2024-08-31 11:20:40,066 (trainer:720) INFO: 107epoch:train:4401-4600batch: iter_time=1.795e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.364, loss_ctc=3.809, loss=1.905, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.405e-04, train_time=0.886
[alab02] 2024-08-31 11:22:06,507 (trainer:720) INFO: 107epoch:train:4601-4800batch: iter_time=1.652e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.882, loss=1.941, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.405e-04, train_time=0.864
[alab02] 2024-08-31 11:23:34,679 (trainer:720) INFO: 107epoch:train:4801-5000batch: iter_time=1.745e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.338, loss_ctc=3.445, loss=1.723, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.405e-04, train_time=0.881
[alab02] 2024-08-31 11:25:02,061 (trainer:720) INFO: 107epoch:train:5001-5200batch: iter_time=1.732e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.369, loss_ctc=3.637, loss=1.819, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.405e-04, train_time=0.874
[alab02] 2024-08-31 11:26:29,949 (trainer:720) INFO: 107epoch:train:5201-5400batch: iter_time=1.714e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=3.888, loss=1.944, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.404e-04, train_time=0.879
[alab02] 2024-08-31 11:27:54,953 (trainer:720) INFO: 107epoch:train:5401-5600batch: iter_time=1.735e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=3.865, loss=1.932, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.404e-04, train_time=0.850
[alab02] 2024-08-31 11:29:20,532 (trainer:720) INFO: 107epoch:train:5601-5800batch: iter_time=1.650e-04, forward_time=0.126, uma_reduction=0.258, text_vs_uma=0.375, loss_ctc=3.876, loss=1.938, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.404e-04, train_time=0.856
[alab02] 2024-08-31 11:30:47,863 (trainer:720) INFO: 107epoch:train:5801-6000batch: iter_time=1.705e-04, forward_time=0.129, uma_reduction=0.257, text_vs_uma=0.370, loss_ctc=3.966, loss=1.983, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.404e-04, train_time=0.873
[alab02] 2024-08-31 11:32:12,315 (trainer:720) INFO: 107epoch:train:6001-6200batch: iter_time=1.573e-04, forward_time=0.126, uma_reduction=0.260, text_vs_uma=0.383, loss_ctc=4.048, loss=2.024, backward_time=0.172, optim_step_time=0.033, optim0_lr0=1.404e-04, train_time=0.844
[alab02] 2024-08-31 11:33:37,804 (trainer:720) INFO: 107epoch:train:6201-6400batch: iter_time=1.622e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.330, loss=1.665, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.403e-04, train_time=0.855
[alab02] 2024-08-31 11:35:04,205 (trainer:720) INFO: 107epoch:train:6401-6600batch: iter_time=1.620e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.367, loss_ctc=3.951, loss=1.976, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.403e-04, train_time=0.864
[alab02] 2024-08-31 11:36:30,392 (trainer:720) INFO: 107epoch:train:6601-6800batch: iter_time=1.642e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.374, loss_ctc=3.951, loss=1.975, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.403e-04, train_time=0.862
[alab02] 2024-08-31 11:37:57,379 (trainer:720) INFO: 107epoch:train:6801-7000batch: iter_time=1.700e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=3.685, loss=1.842, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.403e-04, train_time=0.870
[alab02] 2024-08-31 11:39:13,608 (trainer:338) INFO: 107epoch results: [train] iter_time=2.217e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=3.769, loss=1.885, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.406e-04, train_time=0.867, time=51 minutes and 31.21 seconds, total_count=762482, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.269, text_vs_uma=0.405, loss_ctc=3.269, cer_ctc=0.093, cer=0.093, loss=3.269, time=6.01 seconds, total_count=2782, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.05 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 11:39:18,209 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 11:39:18,210 (trainer:272) INFO: 108/150epoch started. Estimated time to finish: 1 day, 14 hours and 52 minutes
[alab02] 2024-08-31 11:40:47,097 (trainer:720) INFO: 108epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.354, loss_ctc=3.582, loss=1.791, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.403e-04, train_time=0.888
[alab02] 2024-08-31 11:42:15,981 (trainer:720) INFO: 108epoch:train:201-400batch: iter_time=1.903e-04, forward_time=0.132, uma_reduction=0.275, text_vs_uma=0.352, loss_ctc=3.784, loss=1.892, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.402e-04, train_time=0.889
[alab02] 2024-08-31 11:43:43,498 (trainer:720) INFO: 108epoch:train:401-600batch: iter_time=1.971e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.354, loss_ctc=3.692, loss=1.846, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.402e-04, train_time=0.875
[alab02] 2024-08-31 11:45:12,199 (trainer:720) INFO: 108epoch:train:601-800batch: iter_time=1.978e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.353, loss_ctc=3.786, loss=1.893, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.402e-04, train_time=0.887
[alab02] 2024-08-31 11:46:38,355 (trainer:720) INFO: 108epoch:train:801-1000batch: iter_time=1.974e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.620, loss=1.810, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.402e-04, train_time=0.861
[alab02] 2024-08-31 11:48:07,820 (trainer:720) INFO: 108epoch:train:1001-1200batch: iter_time=1.779e-04, forward_time=0.133, uma_reduction=0.267, text_vs_uma=0.356, loss_ctc=3.808, loss=1.904, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.402e-04, train_time=0.894
[alab02] 2024-08-31 11:49:34,459 (trainer:720) INFO: 108epoch:train:1201-1400batch: iter_time=1.838e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.368, loss_ctc=3.663, loss=1.832, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.402e-04, train_time=0.866
[alab02] 2024-08-31 11:51:01,563 (trainer:720) INFO: 108epoch:train:1401-1600batch: iter_time=1.678e-04, forward_time=0.129, uma_reduction=0.260, text_vs_uma=0.373, loss_ctc=3.711, loss=1.855, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.401e-04, train_time=0.871
[alab02] 2024-08-31 11:52:30,662 (trainer:720) INFO: 108epoch:train:1601-1800batch: iter_time=1.824e-04, forward_time=0.133, uma_reduction=0.265, text_vs_uma=0.361, loss_ctc=3.770, loss=1.885, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.401e-04, train_time=0.891
[alab02] 2024-08-31 11:52:59,758 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 11:53:56,635 (trainer:720) INFO: 108epoch:train:1801-2000batch: iter_time=1.754e-04, forward_time=0.127, uma_reduction=0.257, text_vs_uma=0.371, loss_ctc=3.860, loss=1.930, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.401e-04, train_time=0.859
[alab02] 2024-08-31 11:55:22,084 (trainer:720) INFO: 108epoch:train:2001-2200batch: iter_time=1.817e-04, forward_time=0.127, uma_reduction=0.258, text_vs_uma=0.363, loss_ctc=3.423, loss=1.711, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.401e-04, train_time=0.854
[alab02] 2024-08-31 11:56:47,551 (trainer:720) INFO: 108epoch:train:2201-2400batch: iter_time=1.668e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.377, loss_ctc=3.931, loss=1.966, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.401e-04, train_time=0.854
[alab02] 2024-08-31 11:58:14,656 (trainer:720) INFO: 108epoch:train:2401-2600batch: iter_time=1.943e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.354, loss_ctc=3.724, loss=1.862, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.400e-04, train_time=0.871
[alab02] 2024-08-31 11:59:41,374 (trainer:720) INFO: 108epoch:train:2601-2800batch: iter_time=1.681e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.351, loss_ctc=3.659, loss=1.829, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.400e-04, train_time=0.867
[alab02] 2024-08-31 12:01:08,123 (trainer:720) INFO: 108epoch:train:2801-3000batch: iter_time=1.626e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=4.077, loss=2.038, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.400e-04, train_time=0.867
[alab02] 2024-08-31 12:02:35,104 (trainer:720) INFO: 108epoch:train:3001-3200batch: iter_time=1.790e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.774, loss=1.887, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.400e-04, train_time=0.870
[alab02] 2024-08-31 12:04:00,440 (trainer:720) INFO: 108epoch:train:3201-3400batch: iter_time=1.653e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.622, loss=1.811, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.400e-04, train_time=0.853
[alab02] 2024-08-31 12:05:29,571 (trainer:720) INFO: 108epoch:train:3401-3600batch: iter_time=1.672e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.756, loss=1.878, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.400e-04, train_time=0.891
[alab02] 2024-08-31 12:06:55,991 (trainer:720) INFO: 108epoch:train:3601-3800batch: iter_time=1.823e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.751, loss=1.876, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.399e-04, train_time=0.864
[alab02] 2024-08-31 12:08:23,545 (trainer:720) INFO: 108epoch:train:3801-4000batch: iter_time=1.730e-04, forward_time=0.131, uma_reduction=0.264, text_vs_uma=0.375, loss_ctc=3.945, loss=1.973, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.399e-04, train_time=0.875
[alab02] 2024-08-31 12:09:50,417 (trainer:720) INFO: 108epoch:train:4001-4200batch: iter_time=1.680e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.568, loss=1.784, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.399e-04, train_time=0.868
[alab02] 2024-08-31 12:11:18,376 (trainer:720) INFO: 108epoch:train:4201-4400batch: iter_time=1.716e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.356, loss_ctc=3.662, loss=1.831, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.399e-04, train_time=0.879
[alab02] 2024-08-31 12:12:46,554 (trainer:720) INFO: 108epoch:train:4401-4600batch: iter_time=1.699e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.521, loss=1.760, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.399e-04, train_time=0.882
[alab02] 2024-08-31 12:14:14,769 (trainer:720) INFO: 108epoch:train:4601-4800batch: iter_time=1.728e-04, forward_time=0.131, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.756, loss=1.878, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.398e-04, train_time=0.882
[alab02] 2024-08-31 12:15:43,147 (trainer:720) INFO: 108epoch:train:4801-5000batch: iter_time=1.741e-04, forward_time=0.132, uma_reduction=0.267, text_vs_uma=0.356, loss_ctc=3.443, loss=1.721, backward_time=0.190, optim_step_time=0.033, optim0_lr0=1.398e-04, train_time=0.884
[alab02] 2024-08-31 12:17:11,061 (trainer:720) INFO: 108epoch:train:5001-5200batch: iter_time=1.765e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.324, loss=1.662, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.398e-04, train_time=0.879
[alab02] 2024-08-31 12:18:36,780 (trainer:720) INFO: 108epoch:train:5201-5400batch: iter_time=1.726e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.880, loss=1.940, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.398e-04, train_time=0.857
[alab02] 2024-08-31 12:20:01,295 (trainer:720) INFO: 108epoch:train:5401-5600batch: iter_time=1.753e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.358, loss_ctc=3.668, loss=1.834, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.398e-04, train_time=0.845
[alab02] 2024-08-31 12:21:28,874 (trainer:720) INFO: 108epoch:train:5601-5800batch: iter_time=1.707e-04, forward_time=0.130, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.733, loss=1.866, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.397e-04, train_time=0.876
[alab02] 2024-08-31 12:22:54,596 (trainer:720) INFO: 108epoch:train:5801-6000batch: iter_time=1.774e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.368, loss_ctc=4.161, loss=2.080, backward_time=0.173, optim_step_time=0.033, optim0_lr0=1.397e-04, train_time=0.857
[alab02] 2024-08-31 12:24:20,088 (trainer:720) INFO: 108epoch:train:6001-6200batch: iter_time=1.751e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.375, loss_ctc=3.777, loss=1.888, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.397e-04, train_time=0.855
[alab02] 2024-08-31 12:25:46,571 (trainer:720) INFO: 108epoch:train:6201-6400batch: iter_time=1.776e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.608, loss=1.804, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.397e-04, train_time=0.865
[alab02] 2024-08-31 12:27:13,371 (trainer:720) INFO: 108epoch:train:6401-6600batch: iter_time=1.720e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.827, loss=1.914, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.397e-04, train_time=0.868
[alab02] 2024-08-31 12:28:41,835 (trainer:720) INFO: 108epoch:train:6601-6800batch: iter_time=1.764e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.672, loss=1.836, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.397e-04, train_time=0.884
[alab02] 2024-08-31 12:30:05,937 (trainer:720) INFO: 108epoch:train:6801-7000batch: iter_time=1.636e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=3.792, loss=1.896, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.396e-04, train_time=0.841
[alab02] 2024-08-31 12:31:20,961 (trainer:338) INFO: 108epoch results: [train] iter_time=2.228e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.717, loss=1.858, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.399e-04, train_time=0.871, time=51 minutes and 43.21 seconds, total_count=769608, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.286, text_vs_uma=0.380, loss_ctc=3.182, cer_ctc=0.089, cer=0.089, loss=3.182, time=6.03 seconds, total_count=2808, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.52 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 12:31:25,883 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 12:31:25,946 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/107epoch.pth
[alab02] 2024-08-31 12:31:25,946 (trainer:272) INFO: 109/150epoch started. Estimated time to finish: 1 day, 13 hours and 56 minutes
[alab02] 2024-08-31 12:32:53,578 (trainer:720) INFO: 109epoch:train:1-200batch: iter_time=0.002, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.765, loss=1.883, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.396e-04, train_time=0.876
[alab02] 2024-08-31 12:34:21,832 (trainer:720) INFO: 109epoch:train:201-400batch: iter_time=1.937e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=4.185, loss=2.093, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.396e-04, train_time=0.882
[alab02] 2024-08-31 12:35:48,835 (trainer:720) INFO: 109epoch:train:401-600batch: iter_time=1.786e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.964, loss=1.982, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.396e-04, train_time=0.870
[alab02] 2024-08-31 12:37:11,793 (trainer:720) INFO: 109epoch:train:601-800batch: iter_time=1.930e-04, forward_time=0.121, uma_reduction=0.266, text_vs_uma=0.371, loss_ctc=3.955, loss=1.977, backward_time=0.170, optim_step_time=0.033, optim0_lr0=1.396e-04, train_time=0.829
[alab02] 2024-08-31 12:38:39,052 (trainer:720) INFO: 109epoch:train:801-1000batch: iter_time=1.780e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.832, loss=1.916, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.395e-04, train_time=0.872
[alab02] 2024-08-31 12:40:07,922 (trainer:720) INFO: 109epoch:train:1001-1200batch: iter_time=1.740e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.976, loss=1.988, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.395e-04, train_time=0.888
[alab02] 2024-08-31 12:41:34,271 (trainer:720) INFO: 109epoch:train:1201-1400batch: iter_time=1.831e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.867, loss=1.933, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.395e-04, train_time=0.863
[alab02] 2024-08-31 12:43:01,860 (trainer:720) INFO: 109epoch:train:1401-1600batch: iter_time=1.866e-04, forward_time=0.130, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.670, loss=1.835, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.395e-04, train_time=0.876
[alab02] 2024-08-31 12:44:02,746 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 12:44:27,523 (trainer:720) INFO: 109epoch:train:1601-1800batch: iter_time=1.740e-04, forward_time=0.126, uma_reduction=0.262, text_vs_uma=0.384, loss_ctc=4.123, loss=2.062, backward_time=0.175, optim_step_time=0.032, optim0_lr0=1.395e-04, train_time=0.856
[alab02] 2024-08-31 12:45:54,099 (trainer:720) INFO: 109epoch:train:1801-2000batch: iter_time=1.801e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.363, loss_ctc=3.545, loss=1.772, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.394e-04, train_time=0.866
[alab02] 2024-08-31 12:47:20,616 (trainer:720) INFO: 109epoch:train:2001-2200batch: iter_time=1.853e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=3.403, loss=1.702, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.394e-04, train_time=0.865
[alab02] 2024-08-31 12:48:47,564 (trainer:720) INFO: 109epoch:train:2201-2400batch: iter_time=2.070e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.357, loss_ctc=3.723, loss=1.861, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.394e-04, train_time=0.869
[alab02] 2024-08-31 12:50:14,183 (trainer:720) INFO: 109epoch:train:2401-2600batch: iter_time=1.778e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.524, loss=1.762, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.394e-04, train_time=0.866
[alab02] 2024-08-31 12:51:41,194 (trainer:720) INFO: 109epoch:train:2601-2800batch: iter_time=1.730e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.346, loss_ctc=3.548, loss=1.774, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.394e-04, train_time=0.870
[alab02] 2024-08-31 12:53:07,788 (trainer:720) INFO: 109epoch:train:2801-3000batch: iter_time=1.832e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=3.979, loss=1.989, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.394e-04, train_time=0.866
[alab02] 2024-08-31 12:54:38,076 (trainer:720) INFO: 109epoch:train:3001-3200batch: iter_time=2.131e-04, forward_time=0.136, uma_reduction=0.268, text_vs_uma=0.370, loss_ctc=3.845, loss=1.923, backward_time=0.188, optim_step_time=0.036, optim0_lr0=1.393e-04, train_time=0.903
[alab02] 2024-08-31 12:56:07,617 (trainer:720) INFO: 109epoch:train:3201-3400batch: iter_time=1.865e-04, forward_time=0.134, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=3.590, loss=1.795, backward_time=0.188, optim_step_time=0.036, optim0_lr0=1.393e-04, train_time=0.895
[alab02] 2024-08-31 12:57:35,741 (trainer:720) INFO: 109epoch:train:3401-3600batch: iter_time=1.799e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=3.694, loss=1.847, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.393e-04, train_time=0.881
[alab02] 2024-08-31 12:59:01,573 (trainer:720) INFO: 109epoch:train:3601-3800batch: iter_time=1.805e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.784, loss=1.892, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.393e-04, train_time=0.858
[alab02] 2024-08-31 13:00:28,388 (trainer:720) INFO: 109epoch:train:3801-4000batch: iter_time=1.643e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.862, loss=1.931, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.393e-04, train_time=0.868
[alab02] 2024-08-31 13:01:55,742 (trainer:720) INFO: 109epoch:train:4001-4200batch: iter_time=1.751e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.723, loss=1.861, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.392e-04, train_time=0.873
[alab02] 2024-08-31 13:03:23,390 (trainer:720) INFO: 109epoch:train:4201-4400batch: iter_time=1.567e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.874, loss=1.937, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.392e-04, train_time=0.876
[alab02] 2024-08-31 13:04:51,387 (trainer:720) INFO: 109epoch:train:4401-4600batch: iter_time=1.589e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.464, loss=1.732, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.392e-04, train_time=0.880
[alab02] 2024-08-31 13:06:18,076 (trainer:720) INFO: 109epoch:train:4601-4800batch: iter_time=1.692e-04, forward_time=0.129, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=3.531, loss=1.765, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.392e-04, train_time=0.867
[alab02] 2024-08-31 13:07:47,185 (trainer:720) INFO: 109epoch:train:4801-5000batch: iter_time=1.747e-04, forward_time=0.133, uma_reduction=0.265, text_vs_uma=0.363, loss_ctc=3.807, loss=1.904, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.392e-04, train_time=0.891
[alab02] 2024-08-31 13:09:14,053 (trainer:720) INFO: 109epoch:train:5001-5200batch: iter_time=1.623e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=3.905, loss=1.953, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.392e-04, train_time=0.868
[alab02] 2024-08-31 13:10:39,163 (trainer:720) INFO: 109epoch:train:5201-5400batch: iter_time=1.669e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.791, loss=1.895, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.391e-04, train_time=0.851
[alab02] 2024-08-31 13:12:05,427 (trainer:720) INFO: 109epoch:train:5401-5600batch: iter_time=1.701e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.369, loss_ctc=3.977, loss=1.988, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.391e-04, train_time=0.862
[alab02] 2024-08-31 13:13:32,867 (trainer:720) INFO: 109epoch:train:5601-5800batch: iter_time=1.762e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.354, loss_ctc=3.565, loss=1.782, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.391e-04, train_time=0.874
[alab02] 2024-08-31 13:14:59,841 (trainer:720) INFO: 109epoch:train:5801-6000batch: iter_time=1.579e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.379, loss_ctc=3.962, loss=1.981, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.391e-04, train_time=0.870
[alab02] 2024-08-31 13:16:25,832 (trainer:720) INFO: 109epoch:train:6001-6200batch: iter_time=1.609e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.447, loss=1.723, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.391e-04, train_time=0.860
[alab02] 2024-08-31 13:17:53,564 (trainer:720) INFO: 109epoch:train:6201-6400batch: iter_time=1.668e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=3.954, loss=1.977, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.391e-04, train_time=0.877
[alab02] 2024-08-31 13:19:20,945 (trainer:720) INFO: 109epoch:train:6401-6600batch: iter_time=1.792e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=3.616, loss=1.808, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.390e-04, train_time=0.874
[alab02] 2024-08-31 13:20:48,129 (trainer:720) INFO: 109epoch:train:6601-6800batch: iter_time=1.849e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.602, loss=1.801, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.390e-04, train_time=0.872
[alab02] 2024-08-31 13:22:15,659 (trainer:720) INFO: 109epoch:train:6801-7000batch: iter_time=1.765e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.365, loss_ctc=3.864, loss=1.932, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.390e-04, train_time=0.875
[alab02] 2024-08-31 13:23:30,880 (trainer:338) INFO: 109epoch results: [train] iter_time=2.227e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.361, loss_ctc=3.762, loss=1.881, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.393e-04, train_time=0.871, time=51 minutes and 44.3 seconds, total_count=776734, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.274, text_vs_uma=0.397, loss_ctc=3.122, cer_ctc=0.081, cer=0.081, loss=3.122, time=6.12 seconds, total_count=2834, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.51 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 13:23:35,420 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 13:23:35,491 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/90epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/108epoch.pth
[alab02] 2024-08-31 13:23:35,492 (trainer:272) INFO: 110/150epoch started. Estimated time to finish: 1 day, 13 hours and 1 minute
[alab02] 2024-08-31 13:25:04,623 (trainer:720) INFO: 110epoch:train:1-200batch: iter_time=0.002, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.353, loss_ctc=3.534, loss=1.767, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.390e-04, train_time=0.891
[alab02] 2024-08-31 13:26:32,392 (trainer:720) INFO: 110epoch:train:201-400batch: iter_time=1.903e-04, forward_time=0.130, uma_reduction=0.261, text_vs_uma=0.371, loss_ctc=3.986, loss=1.993, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.390e-04, train_time=0.877
[alab02] 2024-08-31 13:27:11,864 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 13:28:02,914 (trainer:720) INFO: 110epoch:train:401-600batch: iter_time=1.863e-04, forward_time=0.136, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=4.164, loss=2.082, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.389e-04, train_time=0.905
[alab02] 2024-08-31 13:29:27,997 (trainer:720) INFO: 110epoch:train:601-800batch: iter_time=1.739e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.667, loss=1.833, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.389e-04, train_time=0.851
[alab02] 2024-08-31 13:30:53,812 (trainer:720) INFO: 110epoch:train:801-1000batch: iter_time=1.754e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.673, loss=1.836, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.389e-04, train_time=0.858
[alab02] 2024-08-31 13:32:21,073 (trainer:720) INFO: 110epoch:train:1001-1200batch: iter_time=2.049e-04, forward_time=0.131, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=3.751, loss=1.875, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.389e-04, train_time=0.872
[alab02] 2024-08-31 13:33:47,863 (trainer:720) INFO: 110epoch:train:1201-1400batch: iter_time=1.821e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.364, loss_ctc=4.030, loss=2.015, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.389e-04, train_time=0.868
[alab02] 2024-08-31 13:35:15,788 (trainer:720) INFO: 110epoch:train:1401-1600batch: iter_time=1.956e-04, forward_time=0.131, uma_reduction=0.270, text_vs_uma=0.366, loss_ctc=3.916, loss=1.958, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.388e-04, train_time=0.879
[alab02] 2024-08-31 13:36:44,612 (trainer:720) INFO: 110epoch:train:1601-1800batch: iter_time=1.725e-04, forward_time=0.133, uma_reduction=0.281, text_vs_uma=0.333, loss_ctc=3.547, loss=1.773, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.388e-04, train_time=0.888
[alab02] 2024-08-31 13:38:11,212 (trainer:720) INFO: 110epoch:train:1801-2000batch: iter_time=1.973e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=3.636, loss=1.818, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.388e-04, train_time=0.866
[alab02] 2024-08-31 13:39:36,132 (trainer:720) INFO: 110epoch:train:2001-2200batch: iter_time=1.846e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.762, loss=1.881, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.388e-04, train_time=0.849
[alab02] 2024-08-31 13:41:01,716 (trainer:720) INFO: 110epoch:train:2201-2400batch: iter_time=1.816e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.336, loss_ctc=3.295, loss=1.647, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.388e-04, train_time=0.856
[alab02] 2024-08-31 13:42:29,056 (trainer:720) INFO: 110epoch:train:2401-2600batch: iter_time=1.823e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=3.501, loss=1.750, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.388e-04, train_time=0.873
[alab02] 2024-08-31 13:43:57,347 (trainer:720) INFO: 110epoch:train:2601-2800batch: iter_time=1.846e-04, forward_time=0.132, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.892, loss=1.946, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.387e-04, train_time=0.883
[alab02] 2024-08-31 13:45:23,504 (trainer:720) INFO: 110epoch:train:2801-3000batch: iter_time=1.655e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.877, loss=1.938, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.387e-04, train_time=0.861
[alab02] 2024-08-31 13:46:52,272 (trainer:720) INFO: 110epoch:train:3001-3200batch: iter_time=1.744e-04, forward_time=0.133, uma_reduction=0.273, text_vs_uma=0.348, loss_ctc=3.785, loss=1.892, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.387e-04, train_time=0.887
[alab02] 2024-08-31 13:48:18,737 (trainer:720) INFO: 110epoch:train:3201-3400batch: iter_time=1.924e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.874, loss=1.937, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.387e-04, train_time=0.864
[alab02] 2024-08-31 13:49:46,505 (trainer:720) INFO: 110epoch:train:3401-3600batch: iter_time=1.902e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.831, loss=1.915, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.387e-04, train_time=0.877
[alab02] 2024-08-31 13:51:16,217 (trainer:720) INFO: 110epoch:train:3601-3800batch: iter_time=1.800e-04, forward_time=0.134, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.504, loss=1.752, backward_time=0.191, optim_step_time=0.033, optim0_lr0=1.386e-04, train_time=0.897
[alab02] 2024-08-31 13:52:43,492 (trainer:720) INFO: 110epoch:train:3801-4000batch: iter_time=1.703e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=3.374, loss=1.687, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.386e-04, train_time=0.873
[alab02] 2024-08-31 13:54:09,973 (trainer:720) INFO: 110epoch:train:4001-4200batch: iter_time=1.653e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=3.786, loss=1.893, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.386e-04, train_time=0.865
[alab02] 2024-08-31 13:55:38,118 (trainer:720) INFO: 110epoch:train:4201-4400batch: iter_time=1.829e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=3.834, loss=1.917, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.386e-04, train_time=0.881
[alab02] 2024-08-31 13:57:04,556 (trainer:720) INFO: 110epoch:train:4401-4600batch: iter_time=1.729e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=3.530, loss=1.765, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.386e-04, train_time=0.864
[alab02] 2024-08-31 13:58:32,268 (trainer:720) INFO: 110epoch:train:4601-4800batch: iter_time=1.739e-04, forward_time=0.131, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.450, loss=1.725, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.386e-04, train_time=0.877
[alab02] 2024-08-31 13:59:59,743 (trainer:720) INFO: 110epoch:train:4801-5000batch: iter_time=1.627e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.372, loss_ctc=3.679, loss=1.839, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.385e-04, train_time=0.875
[alab02] 2024-08-31 14:01:29,641 (trainer:720) INFO: 110epoch:train:5001-5200batch: iter_time=1.756e-04, forward_time=0.135, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.833, loss=1.917, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.385e-04, train_time=0.899
[alab02] 2024-08-31 14:02:56,921 (trainer:720) INFO: 110epoch:train:5201-5400batch: iter_time=1.758e-04, forward_time=0.130, uma_reduction=0.262, text_vs_uma=0.374, loss_ctc=3.834, loss=1.917, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.385e-04, train_time=0.873
[alab02] 2024-08-31 14:04:22,324 (trainer:720) INFO: 110epoch:train:5401-5600batch: iter_time=1.812e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.355, loss_ctc=3.781, loss=1.891, backward_time=0.174, optim_step_time=0.034, optim0_lr0=1.385e-04, train_time=0.854
[alab02] 2024-08-31 14:05:50,115 (trainer:720) INFO: 110epoch:train:5601-5800batch: iter_time=1.638e-04, forward_time=0.131, uma_reduction=0.271, text_vs_uma=0.354, loss_ctc=3.892, loss=1.946, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.385e-04, train_time=0.878
[alab02] 2024-08-31 14:07:18,977 (trainer:720) INFO: 110epoch:train:5801-6000batch: iter_time=1.720e-04, forward_time=0.132, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.720, loss=1.860, backward_time=0.188, optim_step_time=0.034, optim0_lr0=1.385e-04, train_time=0.888
[alab02] 2024-08-31 14:08:46,811 (trainer:720) INFO: 110epoch:train:6001-6200batch: iter_time=1.768e-04, forward_time=0.131, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.822, loss=1.911, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.384e-04, train_time=0.878
[alab02] 2024-08-31 14:10:15,355 (trainer:720) INFO: 110epoch:train:6201-6400batch: iter_time=1.861e-04, forward_time=0.132, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.812, loss=1.906, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.384e-04, train_time=0.885
[alab02] 2024-08-31 14:11:42,913 (trainer:720) INFO: 110epoch:train:6401-6600batch: iter_time=1.780e-04, forward_time=0.130, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.666, loss=1.833, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.384e-04, train_time=0.875
[alab02] 2024-08-31 14:13:09,587 (trainer:720) INFO: 110epoch:train:6601-6800batch: iter_time=1.690e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.838, loss=1.919, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.384e-04, train_time=0.867
[alab02] 2024-08-31 14:14:36,065 (trainer:720) INFO: 110epoch:train:6801-7000batch: iter_time=1.670e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.939, loss=1.970, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.384e-04, train_time=0.865
[alab02] 2024-08-31 14:15:52,941 (trainer:338) INFO: 110epoch results: [train] iter_time=2.318e-04, forward_time=0.130, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.742, loss=1.871, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.387e-04, train_time=0.874, time=51 minutes and 56.86 seconds, total_count=783860, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.281, text_vs_uma=0.387, loss_ctc=3.009, cer_ctc=0.084, cer=0.084, loss=3.009, time=6.17 seconds, total_count=2860, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.41 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 14:15:58,023 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 14:15:58,030 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/100epoch.pth
[alab02] 2024-08-31 14:15:58,031 (trainer:272) INFO: 111/150epoch started. Estimated time to finish: 1 day, 12 hours and 7 minutes
[alab02] 2024-08-31 14:17:24,345 (trainer:720) INFO: 111epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.362, loss_ctc=3.896, loss=1.948, backward_time=0.172, optim_step_time=0.034, optim0_lr0=1.383e-04, train_time=0.863
[alab02] 2024-08-31 14:17:33,486 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 14:18:51,480 (trainer:720) INFO: 111epoch:train:201-400batch: iter_time=1.690e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=3.459, loss=1.729, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.383e-04, train_time=0.871
[alab02] 2024-08-31 14:20:18,305 (trainer:720) INFO: 111epoch:train:401-600batch: iter_time=1.934e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.734, loss=1.867, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.383e-04, train_time=0.868
[alab02] 2024-08-31 14:21:45,416 (trainer:720) INFO: 111epoch:train:601-800batch: iter_time=2.171e-04, forward_time=0.130, uma_reduction=0.266, text_vs_uma=0.358, loss_ctc=3.534, loss=1.767, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.383e-04, train_time=0.871
[alab02] 2024-08-31 14:23:12,346 (trainer:720) INFO: 111epoch:train:801-1000batch: iter_time=1.965e-04, forward_time=0.130, uma_reduction=0.278, text_vs_uma=0.355, loss_ctc=3.638, loss=1.819, backward_time=0.181, optim_step_time=0.035, optim0_lr0=1.383e-04, train_time=0.869
[alab02] 2024-08-31 14:24:41,845 (trainer:720) INFO: 111epoch:train:1001-1200batch: iter_time=2.054e-04, forward_time=0.134, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.900, loss=1.950, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.382e-04, train_time=0.895
[alab02] 2024-08-31 14:26:09,100 (trainer:720) INFO: 111epoch:train:1201-1400batch: iter_time=1.720e-04, forward_time=0.130, uma_reduction=0.264, text_vs_uma=0.375, loss_ctc=3.686, loss=1.843, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.382e-04, train_time=0.872
[alab02] 2024-08-31 14:27:34,718 (trainer:720) INFO: 111epoch:train:1401-1600batch: iter_time=1.751e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.384, loss=1.692, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.382e-04, train_time=0.856
[alab02] 2024-08-31 14:29:00,623 (trainer:720) INFO: 111epoch:train:1601-1800batch: iter_time=1.887e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.365, loss_ctc=3.631, loss=1.816, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.382e-04, train_time=0.859
[alab02] 2024-08-31 14:30:27,513 (trainer:720) INFO: 111epoch:train:1801-2000batch: iter_time=1.866e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.354, loss_ctc=3.417, loss=1.709, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.382e-04, train_time=0.869
[alab02] 2024-08-31 14:31:57,500 (trainer:720) INFO: 111epoch:train:2001-2200batch: iter_time=1.843e-04, forward_time=0.134, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=3.742, loss=1.871, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.382e-04, train_time=0.900
[alab02] 2024-08-31 14:33:26,758 (trainer:720) INFO: 111epoch:train:2201-2400batch: iter_time=1.691e-04, forward_time=0.133, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.357, loss=1.679, backward_time=0.190, optim_step_time=0.033, optim0_lr0=1.381e-04, train_time=0.892
[alab02] 2024-08-31 14:34:53,884 (trainer:720) INFO: 111epoch:train:2401-2600batch: iter_time=1.770e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.656, loss=1.828, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.381e-04, train_time=0.871
[alab02] 2024-08-31 14:36:19,240 (trainer:720) INFO: 111epoch:train:2601-2800batch: iter_time=1.767e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=3.334, loss=1.667, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.381e-04, train_time=0.853
[alab02] 2024-08-31 14:37:46,182 (trainer:720) INFO: 111epoch:train:2801-3000batch: iter_time=1.726e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.503, loss=1.752, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.381e-04, train_time=0.869
[alab02] 2024-08-31 14:39:14,522 (trainer:720) INFO: 111epoch:train:3001-3200batch: iter_time=1.777e-04, forward_time=0.132, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=4.186, loss=2.093, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.381e-04, train_time=0.883
[alab02] 2024-08-31 14:40:40,498 (trainer:720) INFO: 111epoch:train:3201-3400batch: iter_time=1.623e-04, forward_time=0.129, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.309, loss=1.654, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.381e-04, train_time=0.860
[alab02] 2024-08-31 14:42:07,561 (trainer:720) INFO: 111epoch:train:3401-3600batch: iter_time=1.843e-04, forward_time=0.129, uma_reduction=0.262, text_vs_uma=0.372, loss_ctc=3.733, loss=1.867, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.380e-04, train_time=0.870
[alab02] 2024-08-31 14:43:35,969 (trainer:720) INFO: 111epoch:train:3601-3800batch: iter_time=1.615e-04, forward_time=0.132, uma_reduction=0.266, text_vs_uma=0.358, loss_ctc=3.505, loss=1.752, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.380e-04, train_time=0.884
[alab02] 2024-08-31 14:45:03,901 (trainer:720) INFO: 111epoch:train:3801-4000batch: iter_time=1.646e-04, forward_time=0.131, uma_reduction=0.257, text_vs_uma=0.375, loss_ctc=3.658, loss=1.829, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.380e-04, train_time=0.879
[alab02] 2024-08-31 14:46:32,619 (trainer:720) INFO: 111epoch:train:4001-4200batch: iter_time=1.634e-04, forward_time=0.132, uma_reduction=0.258, text_vs_uma=0.377, loss_ctc=3.725, loss=1.863, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.380e-04, train_time=0.887
[alab02] 2024-08-31 14:47:58,409 (trainer:720) INFO: 111epoch:train:4201-4400batch: iter_time=1.695e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.350, loss_ctc=3.227, loss=1.614, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.380e-04, train_time=0.858
[alab02] 2024-08-31 14:48:01,291 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 14:49:24,956 (trainer:720) INFO: 111epoch:train:4401-4600batch: iter_time=1.772e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.745, loss=1.872, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.380e-04, train_time=0.865
[alab02] 2024-08-31 14:50:51,008 (trainer:720) INFO: 111epoch:train:4601-4800batch: iter_time=1.842e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=3.429, loss=1.715, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.379e-04, train_time=0.860
[alab02] 2024-08-31 14:52:18,723 (trainer:720) INFO: 111epoch:train:4801-5000batch: iter_time=1.741e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.595, loss=1.798, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.379e-04, train_time=0.877
[alab02] 2024-08-31 14:53:47,833 (trainer:720) INFO: 111epoch:train:5001-5200batch: iter_time=1.749e-04, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.366, loss_ctc=3.772, loss=1.886, backward_time=0.189, optim_step_time=0.034, optim0_lr0=1.379e-04, train_time=0.891
[alab02] 2024-08-31 14:55:15,599 (trainer:720) INFO: 111epoch:train:5201-5400batch: iter_time=2.040e-04, forward_time=0.130, uma_reduction=0.263, text_vs_uma=0.369, loss_ctc=3.778, loss=1.889, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.379e-04, train_time=0.877
[alab02] 2024-08-31 14:56:44,728 (trainer:720) INFO: 111epoch:train:5401-5600batch: iter_time=1.791e-04, forward_time=0.131, uma_reduction=0.262, text_vs_uma=0.374, loss_ctc=3.829, loss=1.915, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.379e-04, train_time=0.891
[alab02] 2024-08-31 14:58:11,416 (trainer:720) INFO: 111epoch:train:5601-5800batch: iter_time=1.721e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.303, loss=1.652, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.378e-04, train_time=0.867
[alab02] 2024-08-31 14:59:37,278 (trainer:720) INFO: 111epoch:train:5801-6000batch: iter_time=1.821e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=3.800, loss=1.900, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.378e-04, train_time=0.858
[alab02] 2024-08-31 15:01:04,358 (trainer:720) INFO: 111epoch:train:6001-6200batch: iter_time=1.750e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.373, loss=1.687, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.378e-04, train_time=0.871
[alab02] 2024-08-31 15:02:28,829 (trainer:720) INFO: 111epoch:train:6201-6400batch: iter_time=1.723e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.288, loss=1.644, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.378e-04, train_time=0.844
[alab02] 2024-08-31 15:03:55,244 (trainer:720) INFO: 111epoch:train:6401-6600batch: iter_time=1.596e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.360, loss_ctc=3.817, loss=1.908, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.378e-04, train_time=0.864
[alab02] 2024-08-31 15:05:20,305 (trainer:720) INFO: 111epoch:train:6601-6800batch: iter_time=1.622e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=3.548, loss=1.774, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.378e-04, train_time=0.850
[alab02] 2024-08-31 15:06:47,557 (trainer:720) INFO: 111epoch:train:6801-7000batch: iter_time=1.613e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.618, loss=1.809, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.377e-04, train_time=0.872
[alab02] 2024-08-31 15:08:00,384 (trainer:338) INFO: 111epoch results: [train] iter_time=2.259e-04, forward_time=0.130, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=3.599, loss=1.800, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.380e-04, train_time=0.871, time=51 minutes and 44.03 seconds, total_count=790986, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.271, text_vs_uma=0.400, loss_ctc=3.195, cer_ctc=0.089, cer=0.089, loss=3.195, time=6.02 seconds, total_count=2886, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.3 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 15:08:04,803 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 15:08:04,805 (trainer:272) INFO: 112/150epoch started. Estimated time to finish: 1 day, 11 hours and 12 minutes
[alab02] 2024-08-31 15:09:33,615 (trainer:720) INFO: 112epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.519, loss=1.759, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.377e-04, train_time=0.888
[alab02] 2024-08-31 15:10:59,522 (trainer:720) INFO: 112epoch:train:201-400batch: iter_time=1.663e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.533, loss=1.766, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.377e-04, train_time=0.859
[alab02] 2024-08-31 15:12:24,484 (trainer:720) INFO: 112epoch:train:401-600batch: iter_time=1.671e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=3.829, loss=1.915, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.377e-04, train_time=0.849
[alab02] 2024-08-31 15:13:51,103 (trainer:720) INFO: 112epoch:train:601-800batch: iter_time=1.624e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.356, loss_ctc=3.391, loss=1.696, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.377e-04, train_time=0.866
[alab02] 2024-08-31 15:15:18,029 (trainer:720) INFO: 112epoch:train:801-1000batch: iter_time=1.686e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.358, loss_ctc=3.521, loss=1.761, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.376e-04, train_time=0.869
[alab02] 2024-08-31 15:16:46,428 (trainer:720) INFO: 112epoch:train:1001-1200batch: iter_time=1.886e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=3.809, loss=1.904, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.376e-04, train_time=0.884
[alab02] 2024-08-31 15:18:13,572 (trainer:720) INFO: 112epoch:train:1201-1400batch: iter_time=1.878e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.366, loss_ctc=3.787, loss=1.893, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.376e-04, train_time=0.871
[alab02] 2024-08-31 15:19:39,213 (trainer:720) INFO: 112epoch:train:1401-1600batch: iter_time=1.673e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.598, loss=1.799, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.376e-04, train_time=0.856
[alab02] 2024-08-31 15:19:59,473 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 15:21:06,786 (trainer:720) INFO: 112epoch:train:1601-1800batch: iter_time=1.694e-04, forward_time=0.130, uma_reduction=0.275, text_vs_uma=0.346, loss_ctc=3.491, loss=1.745, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.376e-04, train_time=0.876
[alab02] 2024-08-31 15:22:34,032 (trainer:720) INFO: 112epoch:train:1801-2000batch: iter_time=1.617e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.923, loss=1.962, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.376e-04, train_time=0.872
[alab02] 2024-08-31 15:24:00,050 (trainer:720) INFO: 112epoch:train:2001-2200batch: iter_time=1.799e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.365, loss_ctc=3.535, loss=1.767, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.375e-04, train_time=0.860
[alab02] 2024-08-31 15:25:26,507 (trainer:720) INFO: 112epoch:train:2201-2400batch: iter_time=1.575e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.729, loss=1.864, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.375e-04, train_time=0.864
[alab02] 2024-08-31 15:26:53,710 (trainer:720) INFO: 112epoch:train:2401-2600batch: iter_time=1.721e-04, forward_time=0.130, uma_reduction=0.265, text_vs_uma=0.362, loss_ctc=3.687, loss=1.844, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.375e-04, train_time=0.872
[alab02] 2024-08-31 15:28:19,278 (trainer:720) INFO: 112epoch:train:2601-2800batch: iter_time=1.758e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.434, loss=1.717, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.375e-04, train_time=0.855
[alab02] 2024-08-31 15:29:46,932 (trainer:720) INFO: 112epoch:train:2801-3000batch: iter_time=1.723e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.355, loss_ctc=3.657, loss=1.828, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.375e-04, train_time=0.876
[alab02] 2024-08-31 15:31:15,109 (trainer:720) INFO: 112epoch:train:3001-3200batch: iter_time=1.811e-04, forward_time=0.131, uma_reduction=0.259, text_vs_uma=0.374, loss_ctc=3.704, loss=1.852, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.375e-04, train_time=0.882
[alab02] 2024-08-31 15:32:40,326 (trainer:720) INFO: 112epoch:train:3201-3400batch: iter_time=1.732e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=3.601, loss=1.801, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.374e-04, train_time=0.852
[alab02] 2024-08-31 15:34:10,662 (trainer:720) INFO: 112epoch:train:3401-3600batch: iter_time=1.654e-04, forward_time=0.135, uma_reduction=0.259, text_vs_uma=0.379, loss_ctc=3.995, loss=1.998, backward_time=0.189, optim_step_time=0.033, optim0_lr0=1.374e-04, train_time=0.903
[alab02] 2024-08-31 15:35:39,148 (trainer:720) INFO: 112epoch:train:3601-3800batch: iter_time=1.610e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.374, loss_ctc=3.533, loss=1.766, backward_time=0.186, optim_step_time=0.033, optim0_lr0=1.374e-04, train_time=0.885
[alab02] 2024-08-31 15:37:07,702 (trainer:720) INFO: 112epoch:train:3801-4000batch: iter_time=1.965e-04, forward_time=0.131, uma_reduction=0.257, text_vs_uma=0.381, loss_ctc=3.867, loss=1.933, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.374e-04, train_time=0.885
[alab02] 2024-08-31 15:38:33,823 (trainer:720) INFO: 112epoch:train:4001-4200batch: iter_time=1.748e-04, forward_time=0.128, uma_reduction=0.256, text_vs_uma=0.382, loss_ctc=3.621, loss=1.810, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.374e-04, train_time=0.861
[alab02] 2024-08-31 15:39:59,748 (trainer:720) INFO: 112epoch:train:4201-4400batch: iter_time=1.824e-04, forward_time=0.128, uma_reduction=0.257, text_vs_uma=0.379, loss_ctc=3.883, loss=1.941, backward_time=0.176, optim_step_time=0.034, optim0_lr0=1.373e-04, train_time=0.859
[alab02] 2024-08-31 15:41:27,100 (trainer:720) INFO: 112epoch:train:4401-4600batch: iter_time=1.683e-04, forward_time=0.131, uma_reduction=0.262, text_vs_uma=0.382, loss_ctc=4.023, loss=2.012, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.373e-04, train_time=0.873
[alab02] 2024-08-31 15:42:54,449 (trainer:720) INFO: 112epoch:train:4601-4800batch: iter_time=1.674e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=3.862, loss=1.931, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.373e-04, train_time=0.873
[alab02] 2024-08-31 15:44:19,629 (trainer:720) INFO: 112epoch:train:4801-5000batch: iter_time=1.736e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.348, loss_ctc=3.817, loss=1.909, backward_time=0.174, optim_step_time=0.033, optim0_lr0=1.373e-04, train_time=0.852
[alab02] 2024-08-31 15:45:46,590 (trainer:720) INFO: 112epoch:train:5001-5200batch: iter_time=1.688e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.358, loss_ctc=3.616, loss=1.808, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.373e-04, train_time=0.869
[alab02] 2024-08-31 15:47:11,498 (trainer:720) INFO: 112epoch:train:5201-5400batch: iter_time=1.589e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.844, loss=1.922, backward_time=0.175, optim_step_time=0.033, optim0_lr0=1.373e-04, train_time=0.849
[alab02] 2024-08-31 15:48:37,835 (trainer:720) INFO: 112epoch:train:5401-5600batch: iter_time=1.678e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.340, loss_ctc=3.657, loss=1.829, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.372e-04, train_time=0.863
[alab02] 2024-08-31 15:50:04,100 (trainer:720) INFO: 112epoch:train:5601-5800batch: iter_time=1.680e-04, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.612, loss=1.806, backward_time=0.180, optim_step_time=0.034, optim0_lr0=1.372e-04, train_time=0.862
[alab02] 2024-08-31 15:51:30,489 (trainer:720) INFO: 112epoch:train:5801-6000batch: iter_time=1.700e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.334, loss_ctc=3.511, loss=1.755, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.372e-04, train_time=0.864
[alab02] 2024-08-31 15:52:55,947 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 15:52:57,528 (trainer:720) INFO: 112epoch:train:6001-6200batch: iter_time=1.544e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.472, loss=1.736, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.372e-04, train_time=0.870
[alab02] 2024-08-31 15:54:25,722 (trainer:720) INFO: 112epoch:train:6201-6400batch: iter_time=1.715e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.356, loss_ctc=3.759, loss=1.879, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.372e-04, train_time=0.882
[alab02] 2024-08-31 15:55:52,811 (trainer:720) INFO: 112epoch:train:6401-6600batch: iter_time=1.612e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.339, loss_ctc=3.584, loss=1.792, backward_time=0.181, optim_step_time=0.034, optim0_lr0=1.372e-04, train_time=0.871
[alab02] 2024-08-31 15:57:22,837 (trainer:720) INFO: 112epoch:train:6601-6800batch: iter_time=1.700e-04, forward_time=0.134, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=3.435, loss=1.717, backward_time=0.192, optim_step_time=0.033, optim0_lr0=1.371e-04, train_time=0.900
[alab02] 2024-08-31 15:58:53,426 (trainer:720) INFO: 112epoch:train:6801-7000batch: iter_time=2.351e-04, forward_time=0.136, uma_reduction=0.266, text_vs_uma=0.357, loss_ctc=3.600, loss=1.800, backward_time=0.190, optim_step_time=0.040, optim0_lr0=1.371e-04, train_time=0.906
[alab02] 2024-08-31 16:00:08,425 (trainer:338) INFO: 112epoch results: [train] iter_time=2.123e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.666, loss=1.833, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.374e-04, train_time=0.870, time=51 minutes and 42.85 seconds, total_count=798112, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.275, text_vs_uma=0.395, loss_ctc=3.161, cer_ctc=0.086, cer=0.086, loss=3.161, time=6.49 seconds, total_count=2912, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.28 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 16:00:13,766 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 16:00:13,775 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/111epoch.pth
[alab02] 2024-08-31 16:00:13,776 (trainer:272) INFO: 113/150epoch started. Estimated time to finish: 1 day, 10 hours and 17 minutes
[alab02] 2024-08-31 16:01:43,457 (trainer:720) INFO: 113epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.261, text_vs_uma=0.372, loss_ctc=3.564, loss=1.782, backward_time=0.187, optim_step_time=0.036, optim0_lr0=1.371e-04, train_time=0.896
[alab02] 2024-08-31 16:03:10,122 (trainer:720) INFO: 113epoch:train:201-400batch: iter_time=3.050e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.652, loss=1.826, backward_time=0.176, optim_step_time=0.038, optim0_lr0=1.371e-04, train_time=0.866
[alab02] 2024-08-31 16:04:39,510 (trainer:720) INFO: 113epoch:train:401-600batch: iter_time=2.634e-04, forward_time=0.136, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.779, loss=1.890, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.371e-04, train_time=0.894
[alab02] 2024-08-31 16:06:07,524 (trainer:720) INFO: 113epoch:train:601-800batch: iter_time=2.101e-04, forward_time=0.132, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.727, loss=1.864, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.370e-04, train_time=0.880
[alab02] 2024-08-31 16:07:34,927 (trainer:720) INFO: 113epoch:train:801-1000batch: iter_time=2.284e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.691, loss=1.845, backward_time=0.180, optim_step_time=0.037, optim0_lr0=1.370e-04, train_time=0.874
[alab02] 2024-08-31 16:09:03,044 (trainer:720) INFO: 113epoch:train:1001-1200batch: iter_time=2.692e-04, forward_time=0.132, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.707, loss=1.854, backward_time=0.180, optim_step_time=0.036, optim0_lr0=1.370e-04, train_time=0.881
[alab02] 2024-08-31 16:10:28,660 (trainer:720) INFO: 113epoch:train:1201-1400batch: iter_time=2.156e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.348, loss=1.674, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.370e-04, train_time=0.856
[alab02] 2024-08-31 16:11:54,200 (trainer:720) INFO: 113epoch:train:1401-1600batch: iter_time=1.824e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.340, loss_ctc=3.273, loss=1.636, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.370e-04, train_time=0.855
[alab02] 2024-08-31 16:13:21,208 (trainer:720) INFO: 113epoch:train:1601-1800batch: iter_time=1.686e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.744, loss=1.872, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.370e-04, train_time=0.870
[alab02] 2024-08-31 16:14:47,153 (trainer:720) INFO: 113epoch:train:1801-2000batch: iter_time=1.678e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.795, loss=1.897, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.369e-04, train_time=0.859
[alab02] 2024-08-31 16:16:14,528 (trainer:720) INFO: 113epoch:train:2001-2200batch: iter_time=1.696e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.343, loss_ctc=3.488, loss=1.744, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.369e-04, train_time=0.874
[alab02] 2024-08-31 16:17:40,083 (trainer:720) INFO: 113epoch:train:2201-2400batch: iter_time=1.784e-04, forward_time=0.127, uma_reduction=0.285, text_vs_uma=0.336, loss_ctc=3.533, loss=1.767, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.369e-04, train_time=0.855
[alab02] 2024-08-31 16:19:06,829 (trainer:720) INFO: 113epoch:train:2401-2600batch: iter_time=1.680e-04, forward_time=0.129, uma_reduction=0.298, text_vs_uma=0.319, loss_ctc=3.409, loss=1.704, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.369e-04, train_time=0.867
[alab02] 2024-08-31 16:20:32,716 (trainer:720) INFO: 113epoch:train:2601-2800batch: iter_time=1.649e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.746, loss=1.873, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.369e-04, train_time=0.859
[alab02] 2024-08-31 16:21:59,392 (trainer:720) INFO: 113epoch:train:2801-3000batch: iter_time=1.673e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.345, loss_ctc=3.519, loss=1.759, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.369e-04, train_time=0.867
[alab02] 2024-08-31 16:23:27,270 (trainer:720) INFO: 113epoch:train:3001-3200batch: iter_time=1.914e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.650, loss=1.825, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.368e-04, train_time=0.879
[alab02] 2024-08-31 16:24:54,591 (trainer:720) INFO: 113epoch:train:3201-3400batch: iter_time=1.804e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.341, loss_ctc=3.406, loss=1.703, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.368e-04, train_time=0.873
[alab02] 2024-08-31 16:26:22,254 (trainer:720) INFO: 113epoch:train:3401-3600batch: iter_time=1.897e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.337, loss_ctc=3.570, loss=1.785, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.368e-04, train_time=0.876
[alab02] 2024-08-31 16:27:50,511 (trainer:720) INFO: 113epoch:train:3601-3800batch: iter_time=2.292e-04, forward_time=0.132, uma_reduction=0.284, text_vs_uma=0.341, loss_ctc=3.542, loss=1.771, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.368e-04, train_time=0.882
[alab02] 2024-08-31 16:29:19,360 (trainer:720) INFO: 113epoch:train:3801-4000batch: iter_time=3.262e-04, forward_time=0.135, uma_reduction=0.286, text_vs_uma=0.339, loss_ctc=3.561, loss=1.781, backward_time=0.182, optim_step_time=0.039, optim0_lr0=1.368e-04, train_time=0.888
[alab02] 2024-08-31 16:30:48,577 (trainer:720) INFO: 113epoch:train:4001-4200batch: iter_time=4.584e-04, forward_time=0.136, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=4.006, loss=2.003, backward_time=0.178, optim_step_time=0.041, optim0_lr0=1.368e-04, train_time=0.892
[alab02] 2024-08-31 16:32:18,988 (trainer:720) INFO: 113epoch:train:4201-4400batch: iter_time=2.701e-04, forward_time=0.134, uma_reduction=0.280, text_vs_uma=0.354, loss_ctc=3.791, loss=1.895, backward_time=0.185, optim_step_time=0.041, optim0_lr0=1.367e-04, train_time=0.904
[alab02] 2024-08-31 16:33:48,473 (trainer:720) INFO: 113epoch:train:4401-4600batch: iter_time=3.635e-04, forward_time=0.133, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.655, loss=1.827, backward_time=0.182, optim_step_time=0.042, optim0_lr0=1.367e-04, train_time=0.895
[alab02] 2024-08-31 16:35:16,069 (trainer:720) INFO: 113epoch:train:4601-4800batch: iter_time=2.828e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.537, loss=1.769, backward_time=0.181, optim_step_time=0.039, optim0_lr0=1.367e-04, train_time=0.876
[alab02] 2024-08-31 16:36:45,920 (trainer:720) INFO: 113epoch:train:4801-5000batch: iter_time=2.735e-04, forward_time=0.135, uma_reduction=0.274, text_vs_uma=0.361, loss_ctc=3.883, loss=1.941, backward_time=0.182, optim_step_time=0.040, optim0_lr0=1.367e-04, train_time=0.898
[alab02] 2024-08-31 16:38:13,200 (trainer:720) INFO: 113epoch:train:5001-5200batch: iter_time=2.577e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.349, loss_ctc=3.611, loss=1.805, backward_time=0.177, optim_step_time=0.037, optim0_lr0=1.367e-04, train_time=0.873
[alab02] 2024-08-31 16:38:39,538 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 16:39:41,255 (trainer:720) INFO: 113epoch:train:5201-5400batch: iter_time=2.375e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.880, loss=1.940, backward_time=0.180, optim_step_time=0.036, optim0_lr0=1.367e-04, train_time=0.880
[alab02] 2024-08-31 16:41:10,795 (trainer:720) INFO: 113epoch:train:5401-5600batch: iter_time=2.314e-04, forward_time=0.135, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=3.753, loss=1.877, backward_time=0.185, optim_step_time=0.038, optim0_lr0=1.366e-04, train_time=0.895
[alab02] 2024-08-31 16:42:41,650 (trainer:720) INFO: 113epoch:train:5601-5800batch: iter_time=2.182e-04, forward_time=0.137, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.488, loss=1.744, backward_time=0.192, optim_step_time=0.037, optim0_lr0=1.366e-04, train_time=0.908
[alab02] 2024-08-31 16:44:09,740 (trainer:720) INFO: 113epoch:train:5801-6000batch: iter_time=2.259e-04, forward_time=0.131, uma_reduction=0.281, text_vs_uma=0.351, loss_ctc=3.767, loss=1.884, backward_time=0.181, optim_step_time=0.037, optim0_lr0=1.366e-04, train_time=0.881
[alab02] 2024-08-31 16:45:37,989 (trainer:720) INFO: 113epoch:train:6001-6200batch: iter_time=2.259e-04, forward_time=0.133, uma_reduction=0.283, text_vs_uma=0.332, loss_ctc=3.325, loss=1.662, backward_time=0.185, optim_step_time=0.037, optim0_lr0=1.366e-04, train_time=0.882
[alab02] 2024-08-31 16:47:05,032 (trainer:720) INFO: 113epoch:train:6201-6400batch: iter_time=1.775e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=4.024, loss=2.012, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.366e-04, train_time=0.870
[alab02] 2024-08-31 16:48:31,871 (trainer:720) INFO: 113epoch:train:6401-6600batch: iter_time=1.742e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.818, loss=1.909, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.366e-04, train_time=0.868
[alab02] 2024-08-31 16:50:01,089 (trainer:720) INFO: 113epoch:train:6601-6800batch: iter_time=1.694e-04, forward_time=0.134, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=3.577, loss=1.788, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.365e-04, train_time=0.892
[alab02] 2024-08-31 16:51:29,644 (trainer:720) INFO: 113epoch:train:6801-7000batch: iter_time=1.729e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.680, loss=1.840, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.365e-04, train_time=0.885
[alab02] 2024-08-31 16:52:46,731 (trainer:338) INFO: 113epoch results: [train] iter_time=2.814e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.641, loss=1.820, backward_time=0.181, optim_step_time=0.036, optim0_lr0=1.368e-04, train_time=0.879, time=52 minutes and 12.51 seconds, total_count=805238, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.279, text_vs_uma=0.389, loss_ctc=3.047, cer_ctc=0.086, cer=0.086, loss=3.047, time=6.07 seconds, total_count=2938, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.37 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 16:52:51,341 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 16:52:51,351 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/62epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/112epoch.pth
[alab02] 2024-08-31 16:52:51,351 (trainer:272) INFO: 114/150epoch started. Estimated time to finish: 1 day, 9 hours and 22 minutes
[alab02] 2024-08-31 16:54:20,431 (trainer:720) INFO: 114epoch:train:1-200batch: iter_time=0.002, forward_time=0.132, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.438, loss=1.719, backward_time=0.185, optim_step_time=0.034, optim0_lr0=1.365e-04, train_time=0.890
[alab02] 2024-08-31 16:55:49,067 (trainer:720) INFO: 114epoch:train:201-400batch: iter_time=2.157e-04, forward_time=0.132, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.696, loss=1.848, backward_time=0.186, optim_step_time=0.036, optim0_lr0=1.365e-04, train_time=0.886
[alab02] 2024-08-31 16:57:17,820 (trainer:720) INFO: 114epoch:train:401-600batch: iter_time=1.964e-04, forward_time=0.132, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.820, loss=1.910, backward_time=0.184, optim_step_time=0.035, optim0_lr0=1.365e-04, train_time=0.887
[alab02] 2024-08-31 16:58:45,317 (trainer:720) INFO: 114epoch:train:601-800batch: iter_time=1.831e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.340, loss_ctc=3.585, loss=1.793, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.364e-04, train_time=0.875
[alab02] 2024-08-31 17:00:15,177 (trainer:720) INFO: 114epoch:train:801-1000batch: iter_time=1.924e-04, forward_time=0.135, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.595, loss=1.797, backward_time=0.188, optim_step_time=0.035, optim0_lr0=1.364e-04, train_time=0.898
[alab02] 2024-08-31 17:01:42,452 (trainer:720) INFO: 114epoch:train:1001-1200batch: iter_time=1.789e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.346, loss_ctc=3.603, loss=1.802, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.364e-04, train_time=0.873
[alab02] 2024-08-31 17:03:11,769 (trainer:720) INFO: 114epoch:train:1201-1400batch: iter_time=1.920e-04, forward_time=0.133, uma_reduction=0.272, text_vs_uma=0.349, loss_ctc=3.500, loss=1.750, backward_time=0.188, optim_step_time=0.035, optim0_lr0=1.364e-04, train_time=0.893
[alab02] 2024-08-31 17:04:38,303 (trainer:720) INFO: 114epoch:train:1401-1600batch: iter_time=1.931e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=3.753, loss=1.876, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.364e-04, train_time=0.865
[alab02] 2024-08-31 17:06:04,753 (trainer:720) INFO: 114epoch:train:1601-1800batch: iter_time=1.710e-04, forward_time=0.129, uma_reduction=0.267, text_vs_uma=0.365, loss_ctc=3.829, loss=1.915, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.364e-04, train_time=0.864
[alab02] 2024-08-31 17:07:30,182 (trainer:720) INFO: 114epoch:train:1801-2000batch: iter_time=1.782e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.738, loss=1.869, backward_time=0.177, optim_step_time=0.034, optim0_lr0=1.363e-04, train_time=0.854
[alab02] 2024-08-31 17:08:58,371 (trainer:720) INFO: 114epoch:train:2001-2200batch: iter_time=1.592e-04, forward_time=0.131, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.827, loss=1.913, backward_time=0.186, optim_step_time=0.034, optim0_lr0=1.363e-04, train_time=0.882
[alab02] 2024-08-31 17:10:26,422 (trainer:720) INFO: 114epoch:train:2201-2400batch: iter_time=1.862e-04, forward_time=0.131, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.647, loss=1.823, backward_time=0.183, optim_step_time=0.035, optim0_lr0=1.363e-04, train_time=0.880
[alab02] 2024-08-31 17:11:52,261 (trainer:720) INFO: 114epoch:train:2401-2600batch: iter_time=1.659e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.804, loss=1.902, backward_time=0.175, optim_step_time=0.034, optim0_lr0=1.363e-04, train_time=0.858
[alab02] 2024-08-31 17:12:37,461 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 17:13:17,925 (trainer:720) INFO: 114epoch:train:2601-2800batch: iter_time=1.776e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.552, loss=1.776, backward_time=0.179, optim_step_time=0.034, optim0_lr0=1.363e-04, train_time=0.856
[alab02] 2024-08-31 17:14:45,854 (trainer:720) INFO: 114epoch:train:2801-3000batch: iter_time=1.734e-04, forward_time=0.132, uma_reduction=0.277, text_vs_uma=0.344, loss_ctc=3.274, loss=1.637, backward_time=0.186, optim_step_time=0.036, optim0_lr0=1.363e-04, train_time=0.879
[alab02] 2024-08-31 17:16:14,974 (trainer:720) INFO: 114epoch:train:3001-3200batch: iter_time=1.769e-04, forward_time=0.132, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.817, loss=1.909, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.362e-04, train_time=0.891
[alab02] 2024-08-31 17:17:40,383 (trainer:720) INFO: 114epoch:train:3201-3400batch: iter_time=1.686e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.561, loss=1.780, backward_time=0.175, optim_step_time=0.035, optim0_lr0=1.362e-04, train_time=0.854
[alab02] 2024-08-31 17:19:08,441 (trainer:720) INFO: 114epoch:train:3401-3600batch: iter_time=1.740e-04, forward_time=0.132, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=4.067, loss=2.034, backward_time=0.178, optim_step_time=0.036, optim0_lr0=1.362e-04, train_time=0.880
[alab02] 2024-08-31 17:20:35,589 (trainer:720) INFO: 114epoch:train:3601-3800batch: iter_time=1.711e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.684, loss=1.842, backward_time=0.178, optim_step_time=0.035, optim0_lr0=1.362e-04, train_time=0.871
[alab02] 2024-08-31 17:22:03,736 (trainer:720) INFO: 114epoch:train:3801-4000batch: iter_time=2.050e-04, forward_time=0.132, uma_reduction=0.270, text_vs_uma=0.354, loss_ctc=3.434, loss=1.717, backward_time=0.187, optim_step_time=0.036, optim0_lr0=1.362e-04, train_time=0.881
[alab02] 2024-08-31 17:23:34,041 (trainer:720) INFO: 114epoch:train:4001-4200batch: iter_time=1.871e-04, forward_time=0.134, uma_reduction=0.275, text_vs_uma=0.349, loss_ctc=3.490, loss=1.745, backward_time=0.191, optim_step_time=0.035, optim0_lr0=1.362e-04, train_time=0.903
[alab02] 2024-08-31 17:25:04,262 (trainer:720) INFO: 114epoch:train:4201-4400batch: iter_time=2.210e-04, forward_time=0.135, uma_reduction=0.257, text_vs_uma=0.375, loss_ctc=3.595, loss=1.797, backward_time=0.190, optim_step_time=0.036, optim0_lr0=1.361e-04, train_time=0.902
[alab02] 2024-08-31 17:26:35,185 (trainer:720) INFO: 114epoch:train:4401-4600batch: iter_time=1.971e-04, forward_time=0.138, uma_reduction=0.262, text_vs_uma=0.366, loss_ctc=3.778, loss=1.889, backward_time=0.188, optim_step_time=0.036, optim0_lr0=1.361e-04, train_time=0.909
[alab02] 2024-08-31 17:28:02,946 (trainer:720) INFO: 114epoch:train:4601-4800batch: iter_time=1.940e-04, forward_time=0.132, uma_reduction=0.268, text_vs_uma=0.369, loss_ctc=3.645, loss=1.823, backward_time=0.182, optim_step_time=0.035, optim0_lr0=1.361e-04, train_time=0.877
[alab02] 2024-08-31 17:28:10,557 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 17:29:31,094 (trainer:720) INFO: 114epoch:train:4801-5000batch: iter_time=1.989e-04, forward_time=0.133, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=3.722, loss=1.861, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.361e-04, train_time=0.881
[alab02] 2024-08-31 17:30:59,915 (trainer:720) INFO: 114epoch:train:5001-5200batch: iter_time=1.755e-04, forward_time=0.133, uma_reduction=0.277, text_vs_uma=0.361, loss_ctc=3.980, loss=1.990, backward_time=0.182, optim_step_time=0.034, optim0_lr0=1.361e-04, train_time=0.888
[alab02] 2024-08-31 17:32:26,213 (trainer:720) INFO: 114epoch:train:5201-5400batch: iter_time=2.041e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.364, loss_ctc=3.605, loss=1.802, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.361e-04, train_time=0.863
[alab02] 2024-08-31 17:33:53,811 (trainer:720) INFO: 114epoch:train:5401-5600batch: iter_time=1.812e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.357, loss_ctc=3.716, loss=1.858, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.360e-04, train_time=0.876
[alab02] 2024-08-31 17:35:21,802 (trainer:720) INFO: 114epoch:train:5601-5800batch: iter_time=1.625e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.371, loss_ctc=3.717, loss=1.859, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.360e-04, train_time=0.880
[alab02] 2024-08-31 17:36:48,417 (trainer:720) INFO: 114epoch:train:5801-6000batch: iter_time=1.627e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.367, loss_ctc=3.844, loss=1.922, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.360e-04, train_time=0.866
[alab02] 2024-08-31 17:38:16,598 (trainer:720) INFO: 114epoch:train:6001-6200batch: iter_time=1.640e-04, forward_time=0.132, uma_reduction=0.270, text_vs_uma=0.353, loss_ctc=3.640, loss=1.820, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.360e-04, train_time=0.882
[alab02] 2024-08-31 17:39:43,386 (trainer:720) INFO: 114epoch:train:6201-6400batch: iter_time=1.658e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.366, loss_ctc=3.506, loss=1.753, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.360e-04, train_time=0.868
[alab02] 2024-08-31 17:41:10,454 (trainer:720) INFO: 114epoch:train:6401-6600batch: iter_time=1.679e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.832, loss=1.916, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.359e-04, train_time=0.870
[alab02] 2024-08-31 17:42:39,759 (trainer:720) INFO: 114epoch:train:6601-6800batch: iter_time=1.610e-04, forward_time=0.134, uma_reduction=0.272, text_vs_uma=0.364, loss_ctc=3.714, loss=1.857, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.359e-04, train_time=0.893
[alab02] 2024-08-31 17:44:05,667 (trainer:720) INFO: 114epoch:train:6801-7000batch: iter_time=1.619e-04, forward_time=0.129, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.198, loss=1.599, backward_time=0.183, optim_step_time=0.032, optim0_lr0=1.359e-04, train_time=0.859
[alab02] 2024-08-31 17:45:21,416 (trainer:338) INFO: 114epoch results: [train] iter_time=2.390e-04, forward_time=0.131, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.663, loss=1.832, backward_time=0.183, optim_step_time=0.034, optim0_lr0=1.362e-04, train_time=0.878, time=52 minutes and 9.91 seconds, total_count=812364, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.285, text_vs_uma=0.381, loss_ctc=3.040, cer_ctc=0.088, cer=0.088, loss=3.040, time=6.04 seconds, total_count=2964, gpu_max_cached_mem_GB=35.906, [att_plot] time=14.11 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 17:45:26,247 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 17:45:26,248 (trainer:272) INFO: 115/150epoch started. Estimated time to finish: 1 day, 8 hours and 28 minutes
[alab02] 2024-08-31 17:46:52,853 (trainer:720) INFO: 115epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.649, loss=1.824, backward_time=0.177, optim_step_time=0.033, optim0_lr0=1.359e-04, train_time=0.866
[alab02] 2024-08-31 17:48:20,074 (trainer:720) INFO: 115epoch:train:201-400batch: iter_time=1.794e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=3.573, loss=1.786, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.359e-04, train_time=0.872
[alab02] 2024-08-31 17:49:47,084 (trainer:720) INFO: 115epoch:train:401-600batch: iter_time=1.895e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.350, loss_ctc=3.769, loss=1.884, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.359e-04, train_time=0.870
[alab02] 2024-08-31 17:51:14,666 (trainer:720) INFO: 115epoch:train:601-800batch: iter_time=1.814e-04, forward_time=0.131, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.828, loss=1.914, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.358e-04, train_time=0.876
[alab02] 2024-08-31 17:52:42,874 (trainer:720) INFO: 115epoch:train:801-1000batch: iter_time=1.790e-04, forward_time=0.132, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.651, loss=1.825, backward_time=0.185, optim_step_time=0.032, optim0_lr0=1.358e-04, train_time=0.882
[alab02] 2024-08-31 17:54:10,380 (trainer:720) INFO: 115epoch:train:1001-1200batch: iter_time=1.666e-04, forward_time=0.132, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.636, loss=1.818, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.358e-04, train_time=0.875
[alab02] 2024-08-31 17:55:38,657 (trainer:720) INFO: 115epoch:train:1201-1400batch: iter_time=1.718e-04, forward_time=0.132, uma_reduction=0.272, text_vs_uma=0.350, loss_ctc=3.595, loss=1.798, backward_time=0.186, optim_step_time=0.032, optim0_lr0=1.358e-04, train_time=0.883
[alab02] 2024-08-31 17:57:07,382 (trainer:720) INFO: 115epoch:train:1401-1600batch: iter_time=1.836e-04, forward_time=0.133, uma_reduction=0.270, text_vs_uma=0.349, loss_ctc=3.464, loss=1.732, backward_time=0.188, optim_step_time=0.032, optim0_lr0=1.358e-04, train_time=0.887
[alab02] 2024-08-31 17:58:32,327 (trainer:720) INFO: 115epoch:train:1601-1800batch: iter_time=1.701e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.754, loss=1.877, backward_time=0.175, optim_step_time=0.032, optim0_lr0=1.358e-04, train_time=0.849
[alab02] 2024-08-31 18:00:01,084 (trainer:720) INFO: 115epoch:train:1801-2000batch: iter_time=1.651e-04, forward_time=0.133, uma_reduction=0.280, text_vs_uma=0.338, loss_ctc=3.584, loss=1.792, backward_time=0.186, optim_step_time=0.032, optim0_lr0=1.357e-04, train_time=0.887
[alab02] 2024-08-31 18:01:27,869 (trainer:720) INFO: 115epoch:train:2001-2200batch: iter_time=1.680e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.342, loss_ctc=3.669, loss=1.835, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.357e-04, train_time=0.868
[alab02] 2024-08-31 18:02:55,964 (trainer:720) INFO: 115epoch:train:2201-2400batch: iter_time=1.766e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.690, loss=1.845, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.357e-04, train_time=0.881
[alab02] 2024-08-31 18:04:21,940 (trainer:720) INFO: 115epoch:train:2401-2600batch: iter_time=1.543e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.343, loss_ctc=3.527, loss=1.764, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.357e-04, train_time=0.860
[alab02] 2024-08-31 18:05:46,980 (trainer:720) INFO: 115epoch:train:2601-2800batch: iter_time=1.291e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.665, loss=1.832, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.357e-04, train_time=0.850
[alab02] 2024-08-31 18:07:11,629 (trainer:720) INFO: 115epoch:train:2801-3000batch: iter_time=1.265e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.365, loss_ctc=3.557, loss=1.779, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.357e-04, train_time=0.846
[alab02] 2024-08-31 18:08:36,391 (trainer:720) INFO: 115epoch:train:3001-3200batch: iter_time=1.251e-04, forward_time=0.124, uma_reduction=0.260, text_vs_uma=0.383, loss_ctc=4.055, loss=2.027, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.356e-04, train_time=0.847
[alab02] 2024-08-31 18:09:59,454 (trainer:720) INFO: 115epoch:train:3201-3400batch: iter_time=1.321e-04, forward_time=0.122, uma_reduction=0.258, text_vs_uma=0.376, loss_ctc=3.765, loss=1.883, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.356e-04, train_time=0.830
[alab02] 2024-08-31 18:11:22,392 (trainer:720) INFO: 115epoch:train:3401-3600batch: iter_time=1.369e-04, forward_time=0.122, uma_reduction=0.259, text_vs_uma=0.379, loss_ctc=3.900, loss=1.950, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.356e-04, train_time=0.829
[alab02] 2024-08-31 18:12:47,507 (trainer:720) INFO: 115epoch:train:3601-3800batch: iter_time=1.308e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=4.134, loss=2.067, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.356e-04, train_time=0.851
[alab02] 2024-08-31 18:14:13,792 (trainer:720) INFO: 115epoch:train:3801-4000batch: iter_time=1.241e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.859, loss=1.930, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.356e-04, train_time=0.863
[alab02] 2024-08-31 18:15:39,614 (trainer:720) INFO: 115epoch:train:4001-4200batch: iter_time=1.352e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.366, loss_ctc=3.674, loss=1.837, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.356e-04, train_time=0.858
[alab02] 2024-08-31 18:17:04,242 (trainer:720) INFO: 115epoch:train:4201-4400batch: iter_time=1.336e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.341, loss_ctc=3.556, loss=1.778, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.355e-04, train_time=0.846
[alab02] 2024-08-31 18:18:30,713 (trainer:720) INFO: 115epoch:train:4401-4600batch: iter_time=1.248e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.364, loss_ctc=3.799, loss=1.900, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.355e-04, train_time=0.865
[alab02] 2024-08-31 18:19:56,810 (trainer:720) INFO: 115epoch:train:4601-4800batch: iter_time=1.298e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.377, loss_ctc=3.611, loss=1.806, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.355e-04, train_time=0.861
[alab02] 2024-08-31 18:21:22,349 (trainer:720) INFO: 115epoch:train:4801-5000batch: iter_time=1.218e-04, forward_time=0.126, uma_reduction=0.260, text_vs_uma=0.369, loss_ctc=3.612, loss=1.806, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.355e-04, train_time=0.855
[alab02] 2024-08-31 18:22:47,831 (trainer:720) INFO: 115epoch:train:5001-5200batch: iter_time=1.219e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.680, loss=1.840, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.355e-04, train_time=0.855
[alab02] 2024-08-31 18:24:09,957 (trainer:720) INFO: 115epoch:train:5201-5400batch: iter_time=1.221e-04, forward_time=0.120, uma_reduction=0.261, text_vs_uma=0.368, loss_ctc=3.687, loss=1.844, backward_time=0.168, optim_step_time=0.030, optim0_lr0=1.355e-04, train_time=0.821
[alab02] 2024-08-31 18:25:34,863 (trainer:720) INFO: 115epoch:train:5401-5600batch: iter_time=1.244e-04, forward_time=0.125, uma_reduction=0.253, text_vs_uma=0.389, loss_ctc=3.864, loss=1.932, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.354e-04, train_time=0.849
[alab02] 2024-08-31 18:27:00,845 (trainer:720) INFO: 115epoch:train:5601-5800batch: iter_time=1.229e-04, forward_time=0.126, uma_reduction=0.257, text_vs_uma=0.380, loss_ctc=3.675, loss=1.838, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.354e-04, train_time=0.860
[alab02] 2024-08-31 18:27:36,634 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 18:28:26,883 (trainer:720) INFO: 115epoch:train:5801-6000batch: iter_time=1.528e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.363, loss_ctc=3.689, loss=1.845, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.354e-04, train_time=0.860
[alab02] 2024-08-31 18:29:50,986 (trainer:720) INFO: 115epoch:train:6001-6200batch: iter_time=1.208e-04, forward_time=0.123, uma_reduction=0.262, text_vs_uma=0.368, loss_ctc=3.723, loss=1.862, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.354e-04, train_time=0.841
[alab02] 2024-08-31 18:31:16,611 (trainer:720) INFO: 115epoch:train:6201-6400batch: iter_time=1.138e-04, forward_time=0.125, uma_reduction=0.259, text_vs_uma=0.378, loss_ctc=3.679, loss=1.840, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.354e-04, train_time=0.856
[alab02] 2024-08-31 18:32:42,419 (trainer:720) INFO: 115epoch:train:6401-6600batch: iter_time=1.168e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=3.699, loss=1.850, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.354e-04, train_time=0.858
[alab02] 2024-08-31 18:32:51,861 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 18:34:06,709 (trainer:720) INFO: 115epoch:train:6601-6800batch: iter_time=1.227e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.353, loss_ctc=3.463, loss=1.732, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.353e-04, train_time=0.843
[alab02] 2024-08-31 18:35:32,743 (trainer:720) INFO: 115epoch:train:6801-7000batch: iter_time=1.414e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.848, loss=1.924, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.353e-04, train_time=0.860
[alab02] 2024-08-31 18:36:04,582 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 18:36:42,351 (trainer:338) INFO: 115epoch results: [train] iter_time=2.060e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.701, loss=1.851, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.356e-04, train_time=0.858, time=50 minutes and 58.67 seconds, total_count=819490, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.282, text_vs_uma=0.385, loss_ctc=3.094, cer_ctc=0.085, cer=0.085, loss=3.094, time=5.89 seconds, total_count=2990, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.54 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 18:36:46,539 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 18:36:46,592 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/60epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/114epoch.pth
[alab02] 2024-08-31 18:36:46,592 (trainer:272) INFO: 116/150epoch started. Estimated time to finish: 1 day, 7 hours and 33 minutes
[alab02] 2024-08-31 18:38:13,567 (trainer:720) INFO: 116epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.260, text_vs_uma=0.374, loss_ctc=3.550, loss=1.775, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.353e-04, train_time=0.869
[alab02] 2024-08-31 18:39:38,498 (trainer:720) INFO: 116epoch:train:201-400batch: iter_time=1.302e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.707, loss=1.854, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.353e-04, train_time=0.849
[alab02] 2024-08-31 18:41:01,726 (trainer:720) INFO: 116epoch:train:401-600batch: iter_time=1.325e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.344, loss_ctc=3.441, loss=1.720, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.353e-04, train_time=0.832
[alab02] 2024-08-31 18:42:25,855 (trainer:720) INFO: 116epoch:train:601-800batch: iter_time=1.342e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.773, loss=1.886, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.352e-04, train_time=0.841
[alab02] 2024-08-31 18:43:50,920 (trainer:720) INFO: 116epoch:train:801-1000batch: iter_time=1.306e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=3.295, loss=1.647, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.352e-04, train_time=0.850
[alab02] 2024-08-31 18:45:15,393 (trainer:720) INFO: 116epoch:train:1001-1200batch: iter_time=1.461e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.502, loss=1.751, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.352e-04, train_time=0.845
[alab02] 2024-08-31 18:46:39,147 (trainer:720) INFO: 116epoch:train:1201-1400batch: iter_time=1.461e-04, forward_time=0.123, uma_reduction=0.267, text_vs_uma=0.358, loss_ctc=3.407, loss=1.704, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.352e-04, train_time=0.837
[alab02] 2024-08-31 18:48:03,593 (trainer:720) INFO: 116epoch:train:1401-1600batch: iter_time=1.220e-04, forward_time=0.124, uma_reduction=0.260, text_vs_uma=0.381, loss_ctc=3.583, loss=1.792, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.352e-04, train_time=0.844
[alab02] 2024-08-31 18:49:29,105 (trainer:720) INFO: 116epoch:train:1601-1800batch: iter_time=1.311e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.365, loss_ctc=3.773, loss=1.886, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.352e-04, train_time=0.855
[alab02] 2024-08-31 18:50:53,543 (trainer:720) INFO: 116epoch:train:1801-2000batch: iter_time=1.252e-04, forward_time=0.123, uma_reduction=0.263, text_vs_uma=0.379, loss_ctc=3.996, loss=1.998, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.844
[alab02] 2024-08-31 18:52:18,946 (trainer:720) INFO: 116epoch:train:2001-2200batch: iter_time=1.318e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.376, loss_ctc=3.527, loss=1.763, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.854
[alab02] 2024-08-31 18:53:44,202 (trainer:720) INFO: 116epoch:train:2201-2400batch: iter_time=1.220e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.593, loss=1.797, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.852
[alab02] 2024-08-31 18:55:10,667 (trainer:720) INFO: 116epoch:train:2401-2600batch: iter_time=1.245e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.367, loss_ctc=3.662, loss=1.831, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.864
[alab02] 2024-08-31 18:56:36,023 (trainer:720) INFO: 116epoch:train:2601-2800batch: iter_time=1.205e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=3.486, loss=1.743, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.853
[alab02] 2024-08-31 18:57:59,908 (trainer:720) INFO: 116epoch:train:2801-3000batch: iter_time=1.229e-04, forward_time=0.123, uma_reduction=0.263, text_vs_uma=0.364, loss_ctc=3.752, loss=1.876, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.839
[alab02] 2024-08-31 18:59:24,154 (trainer:720) INFO: 116epoch:train:3001-3200batch: iter_time=1.205e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=3.453, loss=1.727, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.351e-04, train_time=0.842
[alab02] 2024-08-31 19:00:48,250 (trainer:720) INFO: 116epoch:train:3201-3400batch: iter_time=1.275e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.518, loss=1.759, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.350e-04, train_time=0.841
[alab02] 2024-08-31 19:02:15,372 (trainer:720) INFO: 116epoch:train:3401-3600batch: iter_time=1.236e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.354, loss_ctc=3.435, loss=1.717, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.350e-04, train_time=0.871
[alab02] 2024-08-31 19:03:40,195 (trainer:720) INFO: 116epoch:train:3601-3800batch: iter_time=1.221e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=3.523, loss=1.761, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.350e-04, train_time=0.848
[alab02] 2024-08-31 19:05:05,835 (trainer:720) INFO: 116epoch:train:3801-4000batch: iter_time=1.154e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=3.589, loss=1.795, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.350e-04, train_time=0.856
[alab02] 2024-08-31 19:06:30,431 (trainer:720) INFO: 116epoch:train:4001-4200batch: iter_time=1.207e-04, forward_time=0.124, uma_reduction=0.262, text_vs_uma=0.369, loss_ctc=3.639, loss=1.819, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.350e-04, train_time=0.846
[alab02] 2024-08-31 19:07:55,734 (trainer:720) INFO: 116epoch:train:4201-4400batch: iter_time=1.190e-04, forward_time=0.125, uma_reduction=0.260, text_vs_uma=0.376, loss_ctc=3.813, loss=1.907, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.350e-04, train_time=0.853
[alab02] 2024-08-31 19:09:22,141 (trainer:720) INFO: 116epoch:train:4401-4600batch: iter_time=1.257e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.361, loss_ctc=3.467, loss=1.733, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.349e-04, train_time=0.864
[alab02] 2024-08-31 19:10:46,837 (trainer:720) INFO: 116epoch:train:4601-4800batch: iter_time=1.358e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.225, loss=1.612, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.349e-04, train_time=0.847
[alab02] 2024-08-31 19:12:11,398 (trainer:720) INFO: 116epoch:train:4801-5000batch: iter_time=1.274e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=3.603, loss=1.801, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.349e-04, train_time=0.845
[alab02] 2024-08-31 19:13:39,425 (trainer:720) INFO: 116epoch:train:5001-5200batch: iter_time=1.312e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=3.612, loss=1.806, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.349e-04, train_time=0.880
[alab02] 2024-08-31 19:15:03,410 (trainer:720) INFO: 116epoch:train:5201-5400batch: iter_time=1.365e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.346, loss_ctc=3.473, loss=1.736, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.349e-04, train_time=0.840
[alab02] 2024-08-31 19:16:30,989 (trainer:720) INFO: 116epoch:train:5401-5600batch: iter_time=1.335e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.368, loss_ctc=3.638, loss=1.819, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.349e-04, train_time=0.876
[alab02] 2024-08-31 19:17:55,160 (trainer:720) INFO: 116epoch:train:5601-5800batch: iter_time=1.278e-04, forward_time=0.123, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.622, loss=1.811, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.348e-04, train_time=0.842
[alab02] 2024-08-31 19:19:21,179 (trainer:720) INFO: 116epoch:train:5801-6000batch: iter_time=1.225e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.373, loss_ctc=3.648, loss=1.824, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.348e-04, train_time=0.860
[alab02] 2024-08-31 19:20:48,105 (trainer:720) INFO: 116epoch:train:6001-6200batch: iter_time=1.273e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.518, loss=1.759, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.348e-04, train_time=0.869
[alab02] 2024-08-31 19:22:12,576 (trainer:720) INFO: 116epoch:train:6201-6400batch: iter_time=1.206e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.353, loss_ctc=3.557, loss=1.778, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.348e-04, train_time=0.845
[alab02] 2024-08-31 19:23:36,485 (trainer:720) INFO: 116epoch:train:6401-6600batch: iter_time=1.220e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.662, loss=1.831, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.348e-04, train_time=0.839
[alab02] 2024-08-31 19:25:01,182 (trainer:720) INFO: 116epoch:train:6601-6800batch: iter_time=1.232e-04, forward_time=0.124, uma_reduction=0.281, text_vs_uma=0.341, loss_ctc=3.542, loss=1.771, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.348e-04, train_time=0.847
[alab02] 2024-08-31 19:26:28,204 (trainer:720) INFO: 116epoch:train:6801-7000batch: iter_time=1.262e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.514, loss=1.757, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.347e-04, train_time=0.870
[alab02] 2024-08-31 19:27:40,299 (trainer:338) INFO: 116epoch results: [train] iter_time=1.689e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=3.576, loss=1.788, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.350e-04, train_time=0.852, time=50 minutes and 36.07 seconds, total_count=826616, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.289, text_vs_uma=0.375, loss_ctc=2.975, cer_ctc=0.080, cer=0.080, loss=2.975, time=5.83 seconds, total_count=3016, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.8 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 19:27:44,922 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-08-31 19:27:44,972 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/113epoch.pth
[alab02] 2024-08-31 19:27:44,973 (trainer:272) INFO: 117/150epoch started. Estimated time to finish: 1 day, 6 hours and 38 minutes
[alab02] 2024-08-31 19:29:09,288 (trainer:720) INFO: 117epoch:train:1-200batch: iter_time=0.001, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=3.499, loss=1.749, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.347e-04, train_time=0.843
[alab02] 2024-08-31 19:30:35,235 (trainer:720) INFO: 117epoch:train:201-400batch: iter_time=1.263e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.361, loss_ctc=3.609, loss=1.805, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.347e-04, train_time=0.859
[alab02] 2024-08-31 19:32:00,669 (trainer:720) INFO: 117epoch:train:401-600batch: iter_time=1.228e-04, forward_time=0.125, uma_reduction=0.285, text_vs_uma=0.344, loss_ctc=3.506, loss=1.753, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.347e-04, train_time=0.854
[alab02] 2024-08-31 19:33:26,745 (trainer:720) INFO: 117epoch:train:601-800batch: iter_time=1.207e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.354, loss_ctc=3.710, loss=1.855, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.347e-04, train_time=0.861
[alab02] 2024-08-31 19:34:53,853 (trainer:720) INFO: 117epoch:train:801-1000batch: iter_time=1.134e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.358, loss_ctc=3.572, loss=1.786, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.871
[alab02] 2024-08-31 19:36:18,902 (trainer:720) INFO: 117epoch:train:1001-1200batch: iter_time=1.205e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.323, loss=1.662, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.850
[alab02] 2024-08-31 19:37:44,723 (trainer:720) INFO: 117epoch:train:1201-1400batch: iter_time=1.207e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.549, loss=1.775, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.858
[alab02] 2024-08-31 19:39:10,759 (trainer:720) INFO: 117epoch:train:1401-1600batch: iter_time=1.210e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.353, loss_ctc=3.277, loss=1.639, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.860
[alab02] 2024-08-31 19:40:35,430 (trainer:720) INFO: 117epoch:train:1601-1800batch: iter_time=1.250e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.748, loss=1.874, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.847
[alab02] 2024-08-31 19:41:59,345 (trainer:720) INFO: 117epoch:train:1801-2000batch: iter_time=1.183e-04, forward_time=0.123, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.820, loss=1.910, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.839
[alab02] 2024-08-31 19:43:22,592 (trainer:720) INFO: 117epoch:train:2001-2200batch: iter_time=1.179e-04, forward_time=0.121, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.768, loss=1.884, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.346e-04, train_time=0.832
[alab02] 2024-08-31 19:44:46,538 (trainer:720) INFO: 117epoch:train:2201-2400batch: iter_time=1.226e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.343, loss_ctc=3.239, loss=1.619, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.345e-04, train_time=0.839
[alab02] 2024-08-31 19:46:14,531 (trainer:720) INFO: 117epoch:train:2401-2600batch: iter_time=1.186e-04, forward_time=0.129, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.896, loss=1.948, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.345e-04, train_time=0.880
[alab02] 2024-08-31 19:47:38,078 (trainer:720) INFO: 117epoch:train:2601-2800batch: iter_time=1.403e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.339, loss_ctc=3.482, loss=1.741, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.345e-04, train_time=0.835
[alab02] 2024-08-31 19:49:05,851 (trainer:720) INFO: 117epoch:train:2801-3000batch: iter_time=1.310e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.365, loss_ctc=3.732, loss=1.866, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.345e-04, train_time=0.878
[alab02] 2024-08-31 19:50:32,426 (trainer:720) INFO: 117epoch:train:3001-3200batch: iter_time=1.197e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.367, loss_ctc=3.598, loss=1.799, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.345e-04, train_time=0.866
[alab02] 2024-08-31 19:51:58,190 (trainer:720) INFO: 117epoch:train:3201-3400batch: iter_time=1.276e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.352, loss_ctc=3.764, loss=1.882, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.345e-04, train_time=0.857
[alab02] 2024-08-31 19:53:23,450 (trainer:720) INFO: 117epoch:train:3401-3600batch: iter_time=1.216e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.531, loss=1.766, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.344e-04, train_time=0.852
[alab02] 2024-08-31 19:54:46,979 (trainer:720) INFO: 117epoch:train:3601-3800batch: iter_time=1.279e-04, forward_time=0.123, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.298, loss=1.649, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.344e-04, train_time=0.835
[alab02] 2024-08-31 19:56:09,334 (trainer:720) INFO: 117epoch:train:3801-4000batch: iter_time=1.330e-04, forward_time=0.121, uma_reduction=0.271, text_vs_uma=0.366, loss_ctc=3.743, loss=1.872, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.344e-04, train_time=0.823
[alab02] 2024-08-31 19:57:34,917 (trainer:720) INFO: 117epoch:train:4001-4200batch: iter_time=1.359e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.354, loss_ctc=3.299, loss=1.649, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.344e-04, train_time=0.856
[alab02] 2024-08-31 19:59:01,140 (trainer:720) INFO: 117epoch:train:4201-4400batch: iter_time=1.710e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.352, loss_ctc=3.479, loss=1.740, backward_time=0.180, optim_step_time=0.033, optim0_lr0=1.344e-04, train_time=0.862
[alab02] 2024-08-31 20:00:27,107 (trainer:720) INFO: 117epoch:train:4401-4600batch: iter_time=1.460e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.347, loss_ctc=3.397, loss=1.699, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.344e-04, train_time=0.859
[alab02] 2024-08-31 20:01:53,028 (trainer:720) INFO: 117epoch:train:4601-4800batch: iter_time=1.322e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.352, loss_ctc=3.554, loss=1.777, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.343e-04, train_time=0.859
[alab02] 2024-08-31 20:03:18,849 (trainer:720) INFO: 117epoch:train:4801-5000batch: iter_time=1.409e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=3.738, loss=1.869, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.343e-04, train_time=0.858
[alab02] 2024-08-31 20:04:45,427 (trainer:720) INFO: 117epoch:train:5001-5200batch: iter_time=1.275e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.364, loss=1.682, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.343e-04, train_time=0.866
[alab02] 2024-08-31 20:06:11,167 (trainer:720) INFO: 117epoch:train:5201-5400batch: iter_time=1.184e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.376, loss=1.688, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.343e-04, train_time=0.857
[alab02] 2024-08-31 20:07:35,940 (trainer:720) INFO: 117epoch:train:5401-5600batch: iter_time=1.188e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.361, loss_ctc=4.032, loss=2.016, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.343e-04, train_time=0.848
[alab02] 2024-08-31 20:09:01,258 (trainer:720) INFO: 117epoch:train:5601-5800batch: iter_time=1.177e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=3.400, loss=1.700, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.343e-04, train_time=0.853
[alab02] 2024-08-31 20:10:27,199 (trainer:720) INFO: 117epoch:train:5801-6000batch: iter_time=1.284e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.449, loss=1.724, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.342e-04, train_time=0.859
[alab02] 2024-08-31 20:11:53,072 (trainer:720) INFO: 117epoch:train:6001-6200batch: iter_time=1.237e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=3.740, loss=1.870, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.342e-04, train_time=0.859
[alab02] 2024-08-31 20:12:30,867 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 20:13:18,755 (trainer:720) INFO: 117epoch:train:6201-6400batch: iter_time=1.312e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.338, loss_ctc=3.403, loss=1.702, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.342e-04, train_time=0.857
[alab02] 2024-08-31 20:14:44,468 (trainer:720) INFO: 117epoch:train:6401-6600batch: iter_time=1.284e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.350, loss_ctc=3.504, loss=1.752, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.342e-04, train_time=0.857
[alab02] 2024-08-31 20:16:11,140 (trainer:720) INFO: 117epoch:train:6601-6800batch: iter_time=1.349e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.357, loss_ctc=3.520, loss=1.760, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.342e-04, train_time=0.867
[alab02] 2024-08-31 20:17:37,192 (trainer:720) INFO: 117epoch:train:6801-7000batch: iter_time=1.341e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=3.802, loss=1.901, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.342e-04, train_time=0.860
[alab02] 2024-08-31 20:18:50,007 (trainer:338) INFO: 117epoch results: [train] iter_time=1.600e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.550, loss=1.775, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.344e-04, train_time=0.855, time=50 minutes and 46.98 seconds, total_count=833742, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.272, text_vs_uma=0.399, loss_ctc=3.048, cer_ctc=0.081, cer=0.081, loss=3.048, time=5.77 seconds, total_count=3042, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.28 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 20:18:54,094 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 20:18:54,146 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/115epoch.pth
[alab02] 2024-08-31 20:18:54,146 (trainer:272) INFO: 118/150epoch started. Estimated time to finish: 1 day, 5 hours and 43 minutes
[alab02] 2024-08-31 20:20:20,753 (trainer:720) INFO: 118epoch:train:1-200batch: iter_time=0.002, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=3.655, loss=1.828, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.341e-04, train_time=0.866
[alab02] 2024-08-31 20:21:47,253 (trainer:720) INFO: 118epoch:train:201-400batch: iter_time=1.254e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.648, loss=1.824, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.341e-04, train_time=0.865
[alab02] 2024-08-31 20:23:12,501 (trainer:720) INFO: 118epoch:train:401-600batch: iter_time=1.237e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.353, loss_ctc=3.454, loss=1.727, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.341e-04, train_time=0.852
[alab02] 2024-08-31 20:24:37,315 (trainer:720) INFO: 118epoch:train:601-800batch: iter_time=1.412e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.703, loss=1.852, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.341e-04, train_time=0.848
[alab02] 2024-08-31 20:26:02,690 (trainer:720) INFO: 118epoch:train:801-1000batch: iter_time=1.433e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.361, loss_ctc=3.707, loss=1.854, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.341e-04, train_time=0.854
[alab02] 2024-08-31 20:27:28,845 (trainer:720) INFO: 118epoch:train:1001-1200batch: iter_time=1.402e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.370, loss_ctc=3.820, loss=1.910, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.341e-04, train_time=0.861
[alab02] 2024-08-31 20:28:53,543 (trainer:720) INFO: 118epoch:train:1201-1400batch: iter_time=1.380e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.840, loss=1.920, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.340e-04, train_time=0.847
[alab02] 2024-08-31 20:30:20,206 (trainer:720) INFO: 118epoch:train:1401-1600batch: iter_time=1.317e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.375, loss_ctc=3.567, loss=1.783, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.340e-04, train_time=0.866
[alab02] 2024-08-31 20:31:45,020 (trainer:720) INFO: 118epoch:train:1601-1800batch: iter_time=1.385e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.754, loss=1.877, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.340e-04, train_time=0.848
[alab02] 2024-08-31 20:33:08,550 (trainer:720) INFO: 118epoch:train:1801-2000batch: iter_time=1.411e-04, forward_time=0.123, uma_reduction=0.264, text_vs_uma=0.359, loss_ctc=3.699, loss=1.849, backward_time=0.171, optim_step_time=0.031, optim0_lr0=1.340e-04, train_time=0.835
[alab02] 2024-08-31 20:34:35,001 (trainer:720) INFO: 118epoch:train:2001-2200batch: iter_time=1.333e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.538, loss=1.769, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.340e-04, train_time=0.864
[alab02] 2024-08-31 20:35:59,514 (trainer:720) INFO: 118epoch:train:2201-2400batch: iter_time=1.407e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.348, loss_ctc=3.415, loss=1.708, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.340e-04, train_time=0.845
[alab02] 2024-08-31 20:37:25,294 (trainer:720) INFO: 118epoch:train:2401-2600batch: iter_time=1.358e-04, forward_time=0.126, uma_reduction=0.261, text_vs_uma=0.372, loss_ctc=3.838, loss=1.919, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.858
[alab02] 2024-08-31 20:38:51,213 (trainer:720) INFO: 118epoch:train:2601-2800batch: iter_time=1.278e-04, forward_time=0.126, uma_reduction=0.259, text_vs_uma=0.380, loss_ctc=3.754, loss=1.877, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.859
[alab02] 2024-08-31 20:40:16,205 (trainer:720) INFO: 118epoch:train:2801-3000batch: iter_time=1.128e-04, forward_time=0.125, uma_reduction=0.259, text_vs_uma=0.373, loss_ctc=3.644, loss=1.822, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.850
[alab02] 2024-08-31 20:41:40,444 (trainer:720) INFO: 118epoch:train:3001-3200batch: iter_time=1.197e-04, forward_time=0.124, uma_reduction=0.263, text_vs_uma=0.366, loss_ctc=3.638, loss=1.819, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.842
[alab02] 2024-08-31 20:43:06,004 (trainer:720) INFO: 118epoch:train:3201-3400batch: iter_time=1.186e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.748, loss=1.874, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.855
[alab02] 2024-08-31 20:44:29,847 (trainer:720) INFO: 118epoch:train:3401-3600batch: iter_time=1.212e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=3.310, loss=1.655, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.838
[alab02] 2024-08-31 20:45:55,990 (trainer:720) INFO: 118epoch:train:3601-3800batch: iter_time=1.253e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.361, loss_ctc=3.927, loss=1.963, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.861
[alab02] 2024-08-31 20:47:21,024 (trainer:720) INFO: 118epoch:train:3801-4000batch: iter_time=1.210e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.338, loss_ctc=3.322, loss=1.661, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.850
[alab02] 2024-08-31 20:48:47,310 (trainer:720) INFO: 118epoch:train:4001-4200batch: iter_time=1.178e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.646, loss=1.823, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.863
[alab02] 2024-08-31 20:50:12,762 (trainer:720) INFO: 118epoch:train:4201-4400batch: iter_time=1.162e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.463, loss=1.731, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.854
[alab02] 2024-08-31 20:51:37,987 (trainer:720) INFO: 118epoch:train:4401-4600batch: iter_time=1.182e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.827, loss=1.914, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.852
[alab02] 2024-08-31 20:53:03,465 (trainer:720) INFO: 118epoch:train:4601-4800batch: iter_time=1.231e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.361, loss_ctc=3.698, loss=1.849, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.855
[alab02] 2024-08-31 20:53:13,266 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 20:54:29,541 (trainer:720) INFO: 118epoch:train:4801-5000batch: iter_time=1.398e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.532, loss=1.766, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.338e-04, train_time=0.861
[alab02] 2024-08-31 20:55:53,721 (trainer:720) INFO: 118epoch:train:5001-5200batch: iter_time=1.367e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.342, loss_ctc=3.222, loss=1.611, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.337e-04, train_time=0.842
[alab02] 2024-08-31 20:57:21,030 (trainer:720) INFO: 118epoch:train:5201-5400batch: iter_time=1.379e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.705, loss=1.853, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.337e-04, train_time=0.873
[alab02] 2024-08-31 20:58:44,791 (trainer:720) INFO: 118epoch:train:5401-5600batch: iter_time=1.461e-04, forward_time=0.123, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=3.441, loss=1.720, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.337e-04, train_time=0.837
[alab02] 2024-08-31 21:00:10,552 (trainer:720) INFO: 118epoch:train:5601-5800batch: iter_time=1.334e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.646, loss=1.823, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.337e-04, train_time=0.857
[alab02] 2024-08-31 21:01:34,015 (trainer:720) INFO: 118epoch:train:5801-6000batch: iter_time=1.293e-04, forward_time=0.122, uma_reduction=0.286, text_vs_uma=0.335, loss_ctc=3.581, loss=1.790, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.337e-04, train_time=0.834
[alab02] 2024-08-31 21:02:56,872 (trainer:720) INFO: 118epoch:train:6001-6200batch: iter_time=1.243e-04, forward_time=0.121, uma_reduction=0.277, text_vs_uma=0.355, loss_ctc=3.826, loss=1.913, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.337e-04, train_time=0.828
[alab02] 2024-08-31 21:04:21,349 (trainer:720) INFO: 118epoch:train:6201-6400batch: iter_time=1.233e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=3.661, loss=1.830, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.336e-04, train_time=0.845
[alab02] 2024-08-31 21:05:47,021 (trainer:720) INFO: 118epoch:train:6401-6600batch: iter_time=1.350e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=3.642, loss=1.821, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.336e-04, train_time=0.857
[alab02] 2024-08-31 21:07:13,462 (trainer:720) INFO: 118epoch:train:6601-6800batch: iter_time=1.157e-04, forward_time=0.128, uma_reduction=0.291, text_vs_uma=0.326, loss_ctc=3.288, loss=1.644, backward_time=0.188, optim_step_time=0.030, optim0_lr0=1.336e-04, train_time=0.864
[alab02] 2024-08-31 21:08:37,349 (trainer:720) INFO: 118epoch:train:6801-7000batch: iter_time=1.121e-04, forward_time=0.123, uma_reduction=0.290, text_vs_uma=0.328, loss_ctc=3.568, loss=1.784, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.336e-04, train_time=0.839
[alab02] 2024-08-31 21:09:48,858 (trainer:338) INFO: 118epoch results: [train] iter_time=1.780e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.621, loss=1.810, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.339e-04, train_time=0.852, time=50 minutes and 37.27 seconds, total_count=840868, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.292, text_vs_uma=0.372, loss_ctc=3.113, cer_ctc=0.084, cer=0.084, loss=3.113, time=5.81 seconds, total_count=3068, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.63 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 21:09:53,177 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 21:09:53,186 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/110epoch.pth
[alab02] 2024-08-31 21:09:53,186 (trainer:272) INFO: 119/150epoch started. Estimated time to finish: 1 day, 4 hours and 48 minutes
[alab02] 2024-08-31 21:11:19,289 (trainer:720) INFO: 119epoch:train:1-200batch: iter_time=0.001, forward_time=0.126, uma_reduction=0.292, text_vs_uma=0.332, loss_ctc=3.433, loss=1.717, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.336e-04, train_time=0.861
[alab02] 2024-08-31 21:12:46,314 (trainer:720) INFO: 119epoch:train:201-400batch: iter_time=1.177e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.685, loss=1.843, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.336e-04, train_time=0.870
[alab02] 2024-08-31 21:14:12,279 (trainer:720) INFO: 119epoch:train:401-600batch: iter_time=1.167e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.626, loss=1.813, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.335e-04, train_time=0.859
[alab02] 2024-08-31 21:15:38,130 (trainer:720) INFO: 119epoch:train:601-800batch: iter_time=1.161e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.350, loss_ctc=3.391, loss=1.696, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.335e-04, train_time=0.858
[alab02] 2024-08-31 21:17:02,819 (trainer:720) INFO: 119epoch:train:801-1000batch: iter_time=1.180e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.486, loss=1.743, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.335e-04, train_time=0.847
[alab02] 2024-08-31 21:18:26,353 (trainer:720) INFO: 119epoch:train:1001-1200batch: iter_time=1.141e-04, forward_time=0.122, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=3.499, loss=1.749, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.335e-04, train_time=0.835
[alab02] 2024-08-31 21:19:49,660 (trainer:720) INFO: 119epoch:train:1201-1400batch: iter_time=1.154e-04, forward_time=0.122, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=3.705, loss=1.852, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.335e-04, train_time=0.833
[alab02] 2024-08-31 21:21:17,409 (trainer:720) INFO: 119epoch:train:1401-1600batch: iter_time=1.188e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.348, loss_ctc=3.883, loss=1.941, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.335e-04, train_time=0.877
[alab02] 2024-08-31 21:22:42,343 (trainer:720) INFO: 119epoch:train:1601-1800batch: iter_time=1.257e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.359, loss_ctc=3.392, loss=1.696, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.334e-04, train_time=0.849
[alab02] 2024-08-31 21:24:08,447 (trainer:720) INFO: 119epoch:train:1801-2000batch: iter_time=1.338e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.351, loss_ctc=3.546, loss=1.773, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.334e-04, train_time=0.861
[alab02] 2024-08-31 21:25:34,201 (trainer:720) INFO: 119epoch:train:2001-2200batch: iter_time=1.377e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=3.877, loss=1.938, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.334e-04, train_time=0.857
[alab02] 2024-08-31 21:25:41,335 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 21:26:59,216 (trainer:720) INFO: 119epoch:train:2201-2400batch: iter_time=1.263e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.304, loss=1.652, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.334e-04, train_time=0.850
[alab02] 2024-08-31 21:28:24,928 (trainer:720) INFO: 119epoch:train:2401-2600batch: iter_time=1.301e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.618, loss=1.809, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.334e-04, train_time=0.857
[alab02] 2024-08-31 21:29:47,985 (trainer:720) INFO: 119epoch:train:2601-2800batch: iter_time=1.312e-04, forward_time=0.121, uma_reduction=0.285, text_vs_uma=0.334, loss_ctc=3.583, loss=1.792, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.334e-04, train_time=0.830
[alab02] 2024-08-31 21:31:13,353 (trainer:720) INFO: 119epoch:train:2801-3000batch: iter_time=1.332e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.355, loss_ctc=3.769, loss=1.884, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.853
[alab02] 2024-08-31 21:32:37,315 (trainer:720) INFO: 119epoch:train:3001-3200batch: iter_time=1.289e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.358, loss_ctc=3.965, loss=1.982, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.839
[alab02] 2024-08-31 21:34:00,755 (trainer:720) INFO: 119epoch:train:3201-3400batch: iter_time=1.253e-04, forward_time=0.123, uma_reduction=0.286, text_vs_uma=0.341, loss_ctc=3.630, loss=1.815, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.834
[alab02] 2024-08-31 21:35:26,526 (trainer:720) INFO: 119epoch:train:3401-3600batch: iter_time=1.253e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.357, loss_ctc=3.745, loss=1.873, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.858
[alab02] 2024-08-31 21:36:52,607 (trainer:720) INFO: 119epoch:train:3601-3800batch: iter_time=1.191e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.714, loss=1.857, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.861
[alab02] 2024-08-31 21:38:18,142 (trainer:720) INFO: 119epoch:train:3801-4000batch: iter_time=1.141e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.357, loss_ctc=3.432, loss=1.716, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.855
[alab02] 2024-08-31 21:39:43,208 (trainer:720) INFO: 119epoch:train:4001-4200batch: iter_time=1.183e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.512, loss=1.756, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.850
[alab02] 2024-08-31 21:41:10,126 (trainer:720) INFO: 119epoch:train:4201-4400batch: iter_time=1.175e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=3.446, loss=1.723, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.332e-04, train_time=0.869
[alab02] 2024-08-31 21:42:34,738 (trainer:720) INFO: 119epoch:train:4401-4600batch: iter_time=1.152e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.344, loss_ctc=3.742, loss=1.871, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.332e-04, train_time=0.846
[alab02] 2024-08-31 21:44:00,838 (trainer:720) INFO: 119epoch:train:4601-4800batch: iter_time=1.165e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.735, loss=1.868, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.332e-04, train_time=0.861
[alab02] 2024-08-31 21:45:24,456 (trainer:720) INFO: 119epoch:train:4801-5000batch: iter_time=1.183e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.711, loss=1.856, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.332e-04, train_time=0.836
[alab02] 2024-08-31 21:46:51,262 (trainer:720) INFO: 119epoch:train:5001-5200batch: iter_time=1.140e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.607, loss=1.803, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.332e-04, train_time=0.868
[alab02] 2024-08-31 21:48:16,873 (trainer:720) INFO: 119epoch:train:5201-5400batch: iter_time=1.127e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.356, loss_ctc=3.598, loss=1.799, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.332e-04, train_time=0.856
[alab02] 2024-08-31 21:49:40,717 (trainer:720) INFO: 119epoch:train:5401-5600batch: iter_time=1.104e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.365, loss_ctc=3.703, loss=1.851, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.331e-04, train_time=0.838
[alab02] 2024-08-31 21:51:06,551 (trainer:720) INFO: 119epoch:train:5601-5800batch: iter_time=1.138e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=4.088, loss=2.044, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.331e-04, train_time=0.858
[alab02] 2024-08-31 21:52:33,703 (trainer:720) INFO: 119epoch:train:5801-6000batch: iter_time=1.583e-04, forward_time=0.129, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=3.854, loss=1.927, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.331e-04, train_time=0.871
[alab02] 2024-08-31 21:53:59,786 (trainer:720) INFO: 119epoch:train:6001-6200batch: iter_time=1.437e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=4.029, loss=2.015, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.331e-04, train_time=0.861
[alab02] 2024-08-31 21:55:25,675 (trainer:720) INFO: 119epoch:train:6201-6400batch: iter_time=1.436e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=3.469, loss=1.735, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.331e-04, train_time=0.859
[alab02] 2024-08-31 21:56:49,394 (trainer:720) INFO: 119epoch:train:6401-6600batch: iter_time=1.511e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.816, loss=1.908, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.331e-04, train_time=0.837
[alab02] 2024-08-31 21:58:14,762 (trainer:720) INFO: 119epoch:train:6601-6800batch: iter_time=1.336e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.360, loss_ctc=3.399, loss=1.700, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.330e-04, train_time=0.853
[alab02] 2024-08-31 21:59:39,102 (trainer:720) INFO: 119epoch:train:6801-7000batch: iter_time=1.388e-04, forward_time=0.124, uma_reduction=0.259, text_vs_uma=0.367, loss_ctc=3.353, loss=1.677, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.330e-04, train_time=0.843
[alab02] 2024-08-31 22:00:49,527 (trainer:338) INFO: 119epoch results: [train] iter_time=1.619e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.634, loss=1.817, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.333e-04, train_time=0.852, time=50 minutes and 38.54 seconds, total_count=847994, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.276, text_vs_uma=0.394, loss_ctc=2.996, cer_ctc=0.083, cer=0.083, loss=2.996, time=5.75 seconds, total_count=3094, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.05 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 22:00:53,815 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 22:00:53,825 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/88epoch.pth
[alab02] 2024-08-31 22:00:53,825 (trainer:272) INFO: 120/150epoch started. Estimated time to finish: 1 day, 3 hours and 53 minutes
[alab02] 2024-08-31 22:01:01,079 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 22:02:20,662 (trainer:720) INFO: 120epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.570, loss=1.785, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.330e-04, train_time=0.868
[alab02] 2024-08-31 22:03:45,627 (trainer:720) INFO: 120epoch:train:201-400batch: iter_time=1.539e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=3.830, loss=1.915, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.330e-04, train_time=0.849
[alab02] 2024-08-31 22:05:09,260 (trainer:720) INFO: 120epoch:train:401-600batch: iter_time=1.591e-04, forward_time=0.122, uma_reduction=0.262, text_vs_uma=0.379, loss_ctc=3.842, loss=1.921, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.330e-04, train_time=0.836
[alab02] 2024-08-31 22:06:34,447 (trainer:720) INFO: 120epoch:train:601-800batch: iter_time=1.314e-04, forward_time=0.125, uma_reduction=0.260, text_vs_uma=0.368, loss_ctc=3.860, loss=1.930, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.330e-04, train_time=0.852
[alab02] 2024-08-31 22:08:00,435 (trainer:720) INFO: 120epoch:train:801-1000batch: iter_time=1.270e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.368, loss_ctc=3.709, loss=1.854, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.329e-04, train_time=0.860
[alab02] 2024-08-31 22:09:26,107 (trainer:720) INFO: 120epoch:train:1001-1200batch: iter_time=1.228e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.317, loss=1.658, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.329e-04, train_time=0.857
[alab02] 2024-08-31 22:10:51,162 (trainer:720) INFO: 120epoch:train:1201-1400batch: iter_time=1.247e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.663, loss=1.832, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.329e-04, train_time=0.850
[alab02] 2024-08-31 22:12:17,794 (trainer:720) INFO: 120epoch:train:1401-1600batch: iter_time=1.476e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.806, loss=1.903, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.329e-04, train_time=0.866
[alab02] 2024-08-31 22:13:42,958 (trainer:720) INFO: 120epoch:train:1601-1800batch: iter_time=1.441e-04, forward_time=0.124, uma_reduction=0.261, text_vs_uma=0.377, loss_ctc=4.098, loss=2.049, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.329e-04, train_time=0.851
[alab02] 2024-08-31 22:15:10,262 (trainer:720) INFO: 120epoch:train:1801-2000batch: iter_time=1.344e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.368, loss_ctc=3.976, loss=1.988, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.329e-04, train_time=0.873
[alab02] 2024-08-31 22:16:34,459 (trainer:720) INFO: 120epoch:train:2001-2200batch: iter_time=1.259e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.608, loss=1.804, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.328e-04, train_time=0.842
[alab02] 2024-08-31 22:18:00,654 (trainer:720) INFO: 120epoch:train:2201-2400batch: iter_time=1.337e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.489, loss=1.744, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.328e-04, train_time=0.862
[alab02] 2024-08-31 22:19:25,108 (trainer:720) INFO: 120epoch:train:2401-2600batch: iter_time=1.398e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.619, loss=1.810, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.328e-04, train_time=0.844
[alab02] 2024-08-31 22:20:48,796 (trainer:720) INFO: 120epoch:train:2601-2800batch: iter_time=1.338e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.680, loss=1.840, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.328e-04, train_time=0.837
[alab02] 2024-08-31 22:22:14,437 (trainer:720) INFO: 120epoch:train:2801-3000batch: iter_time=1.274e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.556, loss=1.778, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.328e-04, train_time=0.856
[alab02] 2024-08-31 22:23:39,959 (trainer:720) INFO: 120epoch:train:3001-3200batch: iter_time=1.332e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=3.548, loss=1.774, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.328e-04, train_time=0.855
[alab02] 2024-08-31 22:25:06,684 (trainer:720) INFO: 120epoch:train:3201-3400batch: iter_time=1.454e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=3.533, loss=1.767, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.328e-04, train_time=0.867
[alab02] 2024-08-31 22:26:33,131 (trainer:720) INFO: 120epoch:train:3401-3600batch: iter_time=1.302e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.374, loss_ctc=3.747, loss=1.874, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.864
[alab02] 2024-08-31 22:27:58,494 (trainer:720) INFO: 120epoch:train:3601-3800batch: iter_time=1.447e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.772, loss=1.886, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.853
[alab02] 2024-08-31 22:29:25,116 (trainer:720) INFO: 120epoch:train:3801-4000batch: iter_time=1.228e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.367, loss_ctc=3.892, loss=1.946, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.866
[alab02] 2024-08-31 22:30:51,835 (trainer:720) INFO: 120epoch:train:4001-4200batch: iter_time=1.293e-04, forward_time=0.127, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=3.727, loss=1.863, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.867
[alab02] 2024-08-31 22:30:58,582 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 22:32:17,281 (trainer:720) INFO: 120epoch:train:4201-4400batch: iter_time=1.408e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.680, loss=1.840, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.854
[alab02] 2024-08-31 22:33:42,100 (trainer:720) INFO: 120epoch:train:4401-4600batch: iter_time=1.329e-04, forward_time=0.124, uma_reduction=0.262, text_vs_uma=0.374, loss_ctc=3.738, loss=1.869, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.848
[alab02] 2024-08-31 22:35:07,466 (trainer:720) INFO: 120epoch:train:4601-4800batch: iter_time=1.203e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.356, loss_ctc=3.482, loss=1.741, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.326e-04, train_time=0.853
[alab02] 2024-08-31 22:36:32,889 (trainer:720) INFO: 120epoch:train:4801-5000batch: iter_time=1.176e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.373, loss_ctc=3.776, loss=1.888, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.326e-04, train_time=0.854
[alab02] 2024-08-31 22:37:57,051 (trainer:720) INFO: 120epoch:train:5001-5200batch: iter_time=1.170e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.512, loss=1.756, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.326e-04, train_time=0.841
[alab02] 2024-08-31 22:39:22,053 (trainer:720) INFO: 120epoch:train:5201-5400batch: iter_time=1.218e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.361, loss_ctc=3.754, loss=1.877, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.326e-04, train_time=0.850
[alab02] 2024-08-31 22:40:47,371 (trainer:720) INFO: 120epoch:train:5401-5600batch: iter_time=1.206e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.576, loss=1.788, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.326e-04, train_time=0.853
[alab02] 2024-08-31 22:42:11,307 (trainer:720) INFO: 120epoch:train:5601-5800batch: iter_time=1.221e-04, forward_time=0.123, uma_reduction=0.268, text_vs_uma=0.369, loss_ctc=3.836, loss=1.918, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.326e-04, train_time=0.839
[alab02] 2024-08-31 22:43:36,465 (trainer:720) INFO: 120epoch:train:5801-6000batch: iter_time=1.134e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.367, loss_ctc=3.411, loss=1.706, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.326e-04, train_time=0.851
[alab02] 2024-08-31 22:45:02,929 (trainer:720) INFO: 120epoch:train:6001-6200batch: iter_time=1.279e-04, forward_time=0.127, uma_reduction=0.263, text_vs_uma=0.364, loss_ctc=3.654, loss=1.827, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.325e-04, train_time=0.864
[alab02] 2024-08-31 22:46:29,052 (trainer:720) INFO: 120epoch:train:6201-6400batch: iter_time=1.213e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.368, loss_ctc=3.877, loss=1.939, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.325e-04, train_time=0.861
[alab02] 2024-08-31 22:47:55,567 (trainer:720) INFO: 120epoch:train:6401-6600batch: iter_time=1.251e-04, forward_time=0.126, uma_reduction=0.258, text_vs_uma=0.379, loss_ctc=3.929, loss=1.965, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.325e-04, train_time=0.865
[alab02] 2024-08-31 22:49:22,511 (trainer:720) INFO: 120epoch:train:6601-6800batch: iter_time=1.266e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=3.567, loss=1.783, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.325e-04, train_time=0.869
[alab02] 2024-08-31 22:50:48,376 (trainer:720) INFO: 120epoch:train:6801-7000batch: iter_time=1.220e-04, forward_time=0.126, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=3.766, loss=1.883, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.325e-04, train_time=0.858
[alab02] 2024-08-31 22:51:58,066 (trainer:338) INFO: 120epoch results: [train] iter_time=1.784e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=3.692, loss=1.846, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.327e-04, train_time=0.855, time=50 minutes and 46.7 seconds, total_count=855120, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.283, text_vs_uma=0.385, loss_ctc=3.079, cer_ctc=0.083, cer=0.083, loss=3.079, time=5.84 seconds, total_count=3120, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.7 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 22:52:02,249 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 22:52:02,256 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/97epoch.pth
[alab02] 2024-08-31 22:52:02,256 (trainer:272) INFO: 121/150epoch started. Estimated time to finish: 1 day, 2 hours and 58 minutes
[alab02] 2024-08-31 22:53:28,799 (trainer:720) INFO: 121epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.348, loss_ctc=3.537, loss=1.768, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.324e-04, train_time=0.865
[alab02] 2024-08-31 22:54:54,351 (trainer:720) INFO: 121epoch:train:201-400batch: iter_time=1.389e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.348, loss_ctc=3.205, loss=1.603, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.324e-04, train_time=0.855
[alab02] 2024-08-31 22:56:21,332 (trainer:720) INFO: 121epoch:train:401-600batch: iter_time=1.533e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.467, loss=1.734, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.324e-04, train_time=0.870
[alab02] 2024-08-31 22:57:47,545 (trainer:720) INFO: 121epoch:train:601-800batch: iter_time=1.403e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.355, loss_ctc=3.404, loss=1.702, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.324e-04, train_time=0.862
[alab02] 2024-08-31 22:59:13,232 (trainer:720) INFO: 121epoch:train:801-1000batch: iter_time=1.441e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=3.251, loss=1.625, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.324e-04, train_time=0.857
[alab02] 2024-08-31 23:00:07,668 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 23:00:38,634 (trainer:720) INFO: 121epoch:train:1001-1200batch: iter_time=1.394e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=3.445, loss=1.723, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.324e-04, train_time=0.854
[alab02] 2024-08-31 23:02:04,055 (trainer:720) INFO: 121epoch:train:1201-1400batch: iter_time=1.366e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.614, loss=1.807, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.324e-04, train_time=0.854
[alab02] 2024-08-31 23:03:28,684 (trainer:720) INFO: 121epoch:train:1401-1600batch: iter_time=1.261e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.878, loss=1.939, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.323e-04, train_time=0.846
[alab02] 2024-08-31 23:04:55,232 (trainer:720) INFO: 121epoch:train:1601-1800batch: iter_time=1.241e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.366, loss_ctc=3.456, loss=1.728, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.323e-04, train_time=0.865
[alab02] 2024-08-31 23:06:21,951 (trainer:720) INFO: 121epoch:train:1801-2000batch: iter_time=1.196e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=3.678, loss=1.839, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.323e-04, train_time=0.867
[alab02] 2024-08-31 23:07:47,260 (trainer:720) INFO: 121epoch:train:2001-2200batch: iter_time=1.210e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.245, loss=1.623, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.323e-04, train_time=0.853
[alab02] 2024-08-31 23:09:12,214 (trainer:720) INFO: 121epoch:train:2201-2400batch: iter_time=1.245e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.346, loss_ctc=3.298, loss=1.649, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.323e-04, train_time=0.849
[alab02] 2024-08-31 23:10:36,148 (trainer:720) INFO: 121epoch:train:2401-2600batch: iter_time=1.245e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.343, loss=1.672, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.323e-04, train_time=0.839
[alab02] 2024-08-31 23:12:02,179 (trainer:720) INFO: 121epoch:train:2601-2800batch: iter_time=1.217e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.335, loss_ctc=3.093, loss=1.547, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.860
[alab02] 2024-08-31 23:13:26,387 (trainer:720) INFO: 121epoch:train:2801-3000batch: iter_time=1.216e-04, forward_time=0.123, uma_reduction=0.270, text_vs_uma=0.369, loss_ctc=3.691, loss=1.846, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.842
[alab02] 2024-08-31 23:14:49,852 (trainer:720) INFO: 121epoch:train:3001-3200batch: iter_time=1.318e-04, forward_time=0.122, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.454, loss=1.727, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.834
[alab02] 2024-08-31 23:16:13,410 (trainer:720) INFO: 121epoch:train:3201-3400batch: iter_time=1.257e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.527, loss=1.763, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.835
[alab02] 2024-08-31 23:17:39,610 (trainer:720) INFO: 121epoch:train:3401-3600batch: iter_time=1.265e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.699, loss=1.849, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.862
[alab02] 2024-08-31 23:19:03,046 (trainer:720) INFO: 121epoch:train:3601-3800batch: iter_time=1.146e-04, forward_time=0.123, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.552, loss=1.776, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.834
[alab02] 2024-08-31 23:20:28,744 (trainer:720) INFO: 121epoch:train:3801-4000batch: iter_time=1.205e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=3.763, loss=1.882, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.857
[alab02] 2024-08-31 23:21:54,144 (trainer:720) INFO: 121epoch:train:4001-4200batch: iter_time=1.265e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.336, loss_ctc=3.395, loss=1.697, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.321e-04, train_time=0.854
[alab02] 2024-08-31 23:23:21,817 (trainer:720) INFO: 121epoch:train:4201-4400batch: iter_time=1.358e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.344, loss_ctc=3.432, loss=1.716, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.321e-04, train_time=0.877
[alab02] 2024-08-31 23:24:49,141 (trainer:720) INFO: 121epoch:train:4401-4600batch: iter_time=1.359e-04, forward_time=0.129, uma_reduction=0.266, text_vs_uma=0.371, loss_ctc=3.609, loss=1.804, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.321e-04, train_time=0.873
[alab02] 2024-08-31 23:26:14,069 (trainer:720) INFO: 121epoch:train:4601-4800batch: iter_time=1.300e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.683, loss=1.842, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.321e-04, train_time=0.849
[alab02] 2024-08-31 23:27:39,597 (trainer:720) INFO: 121epoch:train:4801-5000batch: iter_time=1.398e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=3.507, loss=1.753, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.321e-04, train_time=0.855
[alab02] 2024-08-31 23:29:05,996 (trainer:720) INFO: 121epoch:train:5001-5200batch: iter_time=1.334e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.360, loss_ctc=3.455, loss=1.727, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.321e-04, train_time=0.864
[alab02] 2024-08-31 23:30:32,312 (trainer:720) INFO: 121epoch:train:5201-5400batch: iter_time=1.385e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=3.447, loss=1.723, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.320e-04, train_time=0.863
[alab02] 2024-08-31 23:31:56,694 (trainer:720) INFO: 121epoch:train:5401-5600batch: iter_time=1.277e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.644, loss=1.822, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.320e-04, train_time=0.844
[alab02] 2024-08-31 23:33:23,889 (trainer:720) INFO: 121epoch:train:5601-5800batch: iter_time=1.265e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.360, loss_ctc=3.562, loss=1.781, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.320e-04, train_time=0.872
[alab02] 2024-08-31 23:34:48,396 (trainer:720) INFO: 121epoch:train:5801-6000batch: iter_time=1.157e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.551, loss=1.775, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.320e-04, train_time=0.845
[alab02] 2024-08-31 23:36:12,723 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-08-31 23:36:15,838 (trainer:720) INFO: 121epoch:train:6001-6200batch: iter_time=1.151e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=3.454, loss=1.727, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.320e-04, train_time=0.874
[alab02] 2024-08-31 23:37:40,153 (trainer:720) INFO: 121epoch:train:6201-6400batch: iter_time=1.174e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.357, loss=1.679, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.320e-04, train_time=0.843
[alab02] 2024-08-31 23:39:04,924 (trainer:720) INFO: 121epoch:train:6401-6600batch: iter_time=1.149e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=3.315, loss=1.657, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.320e-04, train_time=0.848
[alab02] 2024-08-31 23:40:30,496 (trainer:720) INFO: 121epoch:train:6601-6800batch: iter_time=1.147e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.349, loss_ctc=3.331, loss=1.666, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.319e-04, train_time=0.856
[alab02] 2024-08-31 23:41:55,170 (trainer:720) INFO: 121epoch:train:6801-7000batch: iter_time=1.104e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.432, loss=1.716, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.319e-04, train_time=0.847
[alab02] 2024-08-31 23:43:07,254 (trainer:338) INFO: 121epoch results: [train] iter_time=1.701e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.479, loss=1.740, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.322e-04, train_time=0.855, time=50 minutes and 48.25 seconds, total_count=862246, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.292, text_vs_uma=0.372, loss_ctc=3.030, cer_ctc=0.083, cer=0.083, loss=3.030, time=5.83 seconds, total_count=3146, gpu_max_cached_mem_GB=35.906, [att_plot] time=10.92 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-08-31 23:43:12,163 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-08-31 23:43:12,172 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/93epoch.pth
[alab02] 2024-08-31 23:43:12,173 (trainer:272) INFO: 122/150epoch started. Estimated time to finish: 1 day, 2 hours and 4 minutes
[alab02] 2024-08-31 23:44:38,457 (trainer:720) INFO: 122epoch:train:1-200batch: iter_time=0.002, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.349, loss_ctc=3.618, loss=1.809, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.319e-04, train_time=0.862
[alab02] 2024-08-31 23:46:03,942 (trainer:720) INFO: 122epoch:train:201-400batch: iter_time=1.406e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.543, loss=1.772, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.319e-04, train_time=0.855
[alab02] 2024-08-31 23:47:30,116 (trainer:720) INFO: 122epoch:train:401-600batch: iter_time=1.392e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.462, loss=1.731, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.319e-04, train_time=0.862
[alab02] 2024-08-31 23:48:53,637 (trainer:720) INFO: 122epoch:train:601-800batch: iter_time=1.395e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.455, loss=1.727, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.319e-04, train_time=0.835
[alab02] 2024-08-31 23:50:19,280 (trainer:720) INFO: 122epoch:train:801-1000batch: iter_time=1.440e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.368, loss_ctc=3.911, loss=1.956, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.318e-04, train_time=0.856
[alab02] 2024-08-31 23:51:43,766 (trainer:720) INFO: 122epoch:train:1001-1200batch: iter_time=1.346e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.659, loss=1.830, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.318e-04, train_time=0.845
[alab02] 2024-08-31 23:53:09,274 (trainer:720) INFO: 122epoch:train:1201-1400batch: iter_time=1.325e-04, forward_time=0.125, uma_reduction=0.284, text_vs_uma=0.337, loss_ctc=3.599, loss=1.799, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.318e-04, train_time=0.855
[alab02] 2024-08-31 23:54:33,225 (trainer:720) INFO: 122epoch:train:1401-1600batch: iter_time=1.355e-04, forward_time=0.122, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.598, loss=1.799, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.318e-04, train_time=0.839
[alab02] 2024-08-31 23:55:58,814 (trainer:720) INFO: 122epoch:train:1601-1800batch: iter_time=1.425e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.526, loss=1.763, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.318e-04, train_time=0.856
[alab02] 2024-08-31 23:57:24,322 (trainer:720) INFO: 122epoch:train:1801-2000batch: iter_time=1.373e-04, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=3.432, loss=1.716, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.318e-04, train_time=0.855
[alab02] 2024-08-31 23:58:50,897 (trainer:720) INFO: 122epoch:train:2001-2200batch: iter_time=1.313e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=3.400, loss=1.700, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.866
[alab02] 2024-09-01 00:00:16,207 (trainer:720) INFO: 122epoch:train:2201-2400batch: iter_time=1.358e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=3.524, loss=1.762, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.853
[alab02] 2024-09-01 00:01:41,327 (trainer:720) INFO: 122epoch:train:2401-2600batch: iter_time=1.210e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.714, loss=1.857, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.851
[alab02] 2024-09-01 00:03:06,878 (trainer:720) INFO: 122epoch:train:2601-2800batch: iter_time=1.202e-04, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.349, loss_ctc=3.511, loss=1.756, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.855
[alab02] 2024-09-01 00:04:29,800 (trainer:720) INFO: 122epoch:train:2801-3000batch: iter_time=1.158e-04, forward_time=0.121, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.520, loss=1.760, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.829
[alab02] 2024-09-01 00:05:54,003 (trainer:720) INFO: 122epoch:train:3001-3200batch: iter_time=1.158e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.343, loss_ctc=3.431, loss=1.715, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.842
[alab02] 2024-09-01 00:07:19,410 (trainer:720) INFO: 122epoch:train:3201-3400batch: iter_time=1.214e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.357, loss_ctc=3.215, loss=1.607, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.317e-04, train_time=0.854
[alab02] 2024-09-01 00:08:45,330 (trainer:720) INFO: 122epoch:train:3401-3600batch: iter_time=1.179e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.512, loss=1.756, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.859
[alab02] 2024-09-01 00:09:17,058 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 00:10:09,395 (trainer:720) INFO: 122epoch:train:3601-3800batch: iter_time=1.181e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=3.518, loss=1.759, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.840
[alab02] 2024-09-01 00:11:33,035 (trainer:720) INFO: 122epoch:train:3801-4000batch: iter_time=1.164e-04, forward_time=0.122, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.477, loss=1.738, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.836
[alab02] 2024-09-01 00:12:58,270 (trainer:720) INFO: 122epoch:train:4001-4200batch: iter_time=1.156e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=3.786, loss=1.893, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.852
[alab02] 2024-09-01 00:14:24,509 (trainer:720) INFO: 122epoch:train:4201-4400batch: iter_time=1.184e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.562, loss=1.781, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.862
[alab02] 2024-09-01 00:15:49,555 (trainer:720) INFO: 122epoch:train:4401-4600batch: iter_time=1.212e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.388, loss=1.694, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.850
[alab02] 2024-09-01 00:17:13,310 (trainer:720) INFO: 122epoch:train:4601-4800batch: iter_time=1.132e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.359, loss_ctc=3.679, loss=1.839, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.837
[alab02] 2024-09-01 00:18:39,066 (trainer:720) INFO: 122epoch:train:4801-5000batch: iter_time=1.220e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.697, loss=1.848, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.315e-04, train_time=0.857
[alab02] 2024-09-01 00:20:03,618 (trainer:720) INFO: 122epoch:train:5001-5200batch: iter_time=1.297e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.829, loss=1.915, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.315e-04, train_time=0.845
[alab02] 2024-09-01 00:21:29,870 (trainer:720) INFO: 122epoch:train:5201-5400batch: iter_time=1.245e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.367, loss_ctc=3.955, loss=1.977, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.315e-04, train_time=0.862
[alab02] 2024-09-01 00:22:53,880 (trainer:720) INFO: 122epoch:train:5401-5600batch: iter_time=1.181e-04, forward_time=0.123, uma_reduction=0.256, text_vs_uma=0.378, loss_ctc=3.620, loss=1.810, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.315e-04, train_time=0.840
[alab02] 2024-09-01 00:24:21,459 (trainer:720) INFO: 122epoch:train:5601-5800batch: iter_time=1.278e-04, forward_time=0.129, uma_reduction=0.258, text_vs_uma=0.372, loss_ctc=3.742, loss=1.871, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.315e-04, train_time=0.876
[alab02] 2024-09-01 00:25:49,066 (trainer:720) INFO: 122epoch:train:5801-6000batch: iter_time=1.239e-04, forward_time=0.129, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=3.465, loss=1.732, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.315e-04, train_time=0.876
[alab02] 2024-09-01 00:27:16,174 (trainer:720) INFO: 122epoch:train:6001-6200batch: iter_time=1.207e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=3.485, loss=1.743, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.314e-04, train_time=0.871
[alab02] 2024-09-01 00:28:41,474 (trainer:720) INFO: 122epoch:train:6201-6400batch: iter_time=1.251e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.348, loss_ctc=3.606, loss=1.803, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.314e-04, train_time=0.853
[alab02] 2024-09-01 00:30:06,690 (trainer:720) INFO: 122epoch:train:6401-6600batch: iter_time=1.195e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=3.487, loss=1.744, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.314e-04, train_time=0.852
[alab02] 2024-09-01 00:31:32,243 (trainer:720) INFO: 122epoch:train:6601-6800batch: iter_time=1.221e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.371, loss=1.686, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.314e-04, train_time=0.855
[alab02] 2024-09-01 00:32:56,434 (trainer:720) INFO: 122epoch:train:6801-7000batch: iter_time=1.188e-04, forward_time=0.123, uma_reduction=0.285, text_vs_uma=0.337, loss_ctc=3.422, loss=1.711, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.314e-04, train_time=0.842
[alab02] 2024-09-01 00:34:08,360 (trainer:338) INFO: 122epoch results: [train] iter_time=1.721e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.564, loss=1.782, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.316e-04, train_time=0.853, time=50 minutes and 39.16 seconds, total_count=869372, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.296, text_vs_uma=0.367, loss_ctc=3.006, cer_ctc=0.083, cer=0.083, loss=3.006, time=5.84 seconds, total_count=3172, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.18 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 00:34:14,678 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 00:34:14,728 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/118epoch.pth
[alab02] 2024-09-01 00:34:14,728 (trainer:272) INFO: 123/150epoch started. Estimated time to finish: 1 day, 1 hour and 9 minutes
[alab02] 2024-09-01 00:35:39,223 (trainer:720) INFO: 123epoch:train:1-200batch: iter_time=0.001, forward_time=0.123, uma_reduction=0.283, text_vs_uma=0.331, loss_ctc=3.292, loss=1.646, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.314e-04, train_time=0.845
[alab02] 2024-09-01 00:37:06,210 (trainer:720) INFO: 123epoch:train:201-400batch: iter_time=1.345e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.645, loss=1.823, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.313e-04, train_time=0.870
[alab02] 2024-09-01 00:38:32,806 (trainer:720) INFO: 123epoch:train:401-600batch: iter_time=1.260e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.336, loss_ctc=3.475, loss=1.738, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.313e-04, train_time=0.866
[alab02] 2024-09-01 00:39:55,844 (trainer:720) INFO: 123epoch:train:601-800batch: iter_time=1.366e-04, forward_time=0.122, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.471, loss=1.736, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.313e-04, train_time=0.830
[alab02] 2024-09-01 00:41:22,317 (trainer:720) INFO: 123epoch:train:801-1000batch: iter_time=1.212e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=4.130, loss=2.065, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.313e-04, train_time=0.865
[alab02] 2024-09-01 00:42:46,477 (trainer:720) INFO: 123epoch:train:1001-1200batch: iter_time=1.200e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.648, loss=1.824, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.313e-04, train_time=0.841
[alab02] 2024-09-01 00:44:11,193 (trainer:720) INFO: 123epoch:train:1201-1400batch: iter_time=1.254e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.368, loss_ctc=3.800, loss=1.900, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.313e-04, train_time=0.847
[alab02] 2024-09-01 00:45:38,261 (trainer:720) INFO: 123epoch:train:1401-1600batch: iter_time=1.233e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.584, loss=1.792, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.313e-04, train_time=0.870
[alab02] 2024-09-01 00:46:31,943 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 00:47:01,327 (trainer:720) INFO: 123epoch:train:1601-1800batch: iter_time=1.173e-04, forward_time=0.122, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.603, loss=1.802, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.312e-04, train_time=0.830
[alab02] 2024-09-01 00:48:27,377 (trainer:720) INFO: 123epoch:train:1801-2000batch: iter_time=1.203e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.658, loss=1.829, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.312e-04, train_time=0.860
[alab02] 2024-09-01 00:49:53,701 (trainer:720) INFO: 123epoch:train:2001-2200batch: iter_time=1.161e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.355, loss_ctc=3.491, loss=1.745, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.312e-04, train_time=0.863
[alab02] 2024-09-01 00:51:21,084 (trainer:720) INFO: 123epoch:train:2201-2400batch: iter_time=1.122e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.341, loss_ctc=3.329, loss=1.665, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.312e-04, train_time=0.874
[alab02] 2024-09-01 00:52:44,628 (trainer:720) INFO: 123epoch:train:2401-2600batch: iter_time=1.037e-04, forward_time=0.123, uma_reduction=0.285, text_vs_uma=0.335, loss_ctc=3.237, loss=1.618, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.312e-04, train_time=0.835
[alab02] 2024-09-01 00:54:08,683 (trainer:720) INFO: 123epoch:train:2601-2800batch: iter_time=1.165e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.498, loss=1.749, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.312e-04, train_time=0.840
[alab02] 2024-09-01 00:55:34,589 (trainer:720) INFO: 123epoch:train:2801-3000batch: iter_time=1.167e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.340, loss_ctc=3.374, loss=1.687, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.859
[alab02] 2024-09-01 00:56:57,542 (trainer:720) INFO: 123epoch:train:3001-3200batch: iter_time=1.210e-04, forward_time=0.122, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=3.599, loss=1.799, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.829
[alab02] 2024-09-01 00:58:23,708 (trainer:720) INFO: 123epoch:train:3201-3400batch: iter_time=1.248e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=3.361, loss=1.681, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.861
[alab02] 2024-09-01 00:59:47,753 (trainer:720) INFO: 123epoch:train:3401-3600batch: iter_time=1.178e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.547, loss=1.774, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.840
[alab02] 2024-09-01 01:01:12,442 (trainer:720) INFO: 123epoch:train:3601-3800batch: iter_time=1.176e-04, forward_time=0.125, uma_reduction=0.283, text_vs_uma=0.343, loss_ctc=3.435, loss=1.717, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.847
[alab02] 2024-09-01 01:02:37,176 (trainer:720) INFO: 123epoch:train:3801-4000batch: iter_time=1.178e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.729, loss=1.865, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.847
[alab02] 2024-09-01 01:04:01,583 (trainer:720) INFO: 123epoch:train:4001-4200batch: iter_time=1.146e-04, forward_time=0.124, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=3.251, loss=1.626, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.844
[alab02] 2024-09-01 01:05:28,420 (trainer:720) INFO: 123epoch:train:4201-4400batch: iter_time=1.317e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=3.373, loss=1.686, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.310e-04, train_time=0.868
[alab02] 2024-09-01 01:06:54,227 (trainer:720) INFO: 123epoch:train:4401-4600batch: iter_time=1.252e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.335, loss_ctc=3.413, loss=1.707, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.310e-04, train_time=0.858
[alab02] 2024-09-01 01:08:18,320 (trainer:720) INFO: 123epoch:train:4601-4800batch: iter_time=1.264e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.591, loss=1.795, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.310e-04, train_time=0.841
[alab02] 2024-09-01 01:09:44,955 (trainer:720) INFO: 123epoch:train:4801-5000batch: iter_time=1.257e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=3.646, loss=1.823, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.310e-04, train_time=0.866
[alab02] 2024-09-01 01:11:08,224 (trainer:720) INFO: 123epoch:train:5001-5200batch: iter_time=1.238e-04, forward_time=0.122, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.605, loss=1.802, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.310e-04, train_time=0.832
[alab02] 2024-09-01 01:12:32,297 (trainer:720) INFO: 123epoch:train:5201-5400batch: iter_time=1.278e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.296, loss=1.648, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.310e-04, train_time=0.841
[alab02] 2024-09-01 01:13:59,536 (trainer:720) INFO: 123epoch:train:5401-5600batch: iter_time=1.237e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.781, loss=1.891, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.310e-04, train_time=0.872
[alab02] 2024-09-01 01:15:21,809 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 01:15:24,455 (trainer:720) INFO: 123epoch:train:5601-5800batch: iter_time=1.519e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.704, loss=1.852, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.309e-04, train_time=0.849
[alab02] 2024-09-01 01:16:49,917 (trainer:720) INFO: 123epoch:train:5801-6000batch: iter_time=1.355e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=3.901, loss=1.951, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.309e-04, train_time=0.854
[alab02] 2024-09-01 01:18:15,229 (trainer:720) INFO: 123epoch:train:6001-6200batch: iter_time=1.360e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.493, loss=1.747, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.309e-04, train_time=0.853
[alab02] 2024-09-01 01:19:38,053 (trainer:720) INFO: 123epoch:train:6201-6400batch: iter_time=1.147e-04, forward_time=0.122, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=3.786, loss=1.893, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.309e-04, train_time=0.828
[alab02] 2024-09-01 01:21:03,161 (trainer:720) INFO: 123epoch:train:6401-6600batch: iter_time=1.236e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.672, loss=1.836, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.309e-04, train_time=0.851
[alab02] 2024-09-01 01:22:27,864 (trainer:720) INFO: 123epoch:train:6601-6800batch: iter_time=1.152e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.539, loss=1.769, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.309e-04, train_time=0.847
[alab02] 2024-09-01 01:23:54,477 (trainer:720) INFO: 123epoch:train:6801-7000batch: iter_time=1.143e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=3.967, loss=1.983, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.308e-04, train_time=0.866
[alab02] 2024-09-01 01:25:06,537 (trainer:338) INFO: 123epoch results: [train] iter_time=1.530e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.568, loss=1.784, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.311e-04, train_time=0.851, time=50 minutes and 33.71 seconds, total_count=876498, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.274, text_vs_uma=0.397, loss_ctc=3.080, cer_ctc=0.084, cer=0.084, loss=3.080, time=5.79 seconds, total_count=3198, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.31 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 01:25:10,773 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 01:25:10,774 (trainer:272) INFO: 124/150epoch started. Estimated time to finish: 1 day, 15 minutes and 5.97 seconds
[alab02] 2024-09-01 01:26:36,545 (trainer:720) INFO: 124epoch:train:1-200batch: iter_time=0.001, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.373, loss_ctc=3.804, loss=1.902, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.308e-04, train_time=0.857
[alab02] 2024-09-01 01:28:02,453 (trainer:720) INFO: 124epoch:train:201-400batch: iter_time=1.184e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=3.670, loss=1.835, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.308e-04, train_time=0.859
[alab02] 2024-09-01 01:29:26,941 (trainer:720) INFO: 124epoch:train:401-600batch: iter_time=1.170e-04, forward_time=0.124, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=3.608, loss=1.804, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.308e-04, train_time=0.845
[alab02] 2024-09-01 01:30:53,475 (trainer:720) INFO: 124epoch:train:601-800batch: iter_time=1.194e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.490, loss=1.745, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.308e-04, train_time=0.865
[alab02] 2024-09-01 01:32:17,165 (trainer:720) INFO: 124epoch:train:801-1000batch: iter_time=1.305e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.696, loss=1.848, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.308e-04, train_time=0.837
[alab02] 2024-09-01 01:33:41,433 (trainer:720) INFO: 124epoch:train:1001-1200batch: iter_time=1.217e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=3.756, loss=1.878, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.307e-04, train_time=0.842
[alab02] 2024-09-01 01:35:06,546 (trainer:720) INFO: 124epoch:train:1201-1400batch: iter_time=1.234e-04, forward_time=0.125, uma_reduction=0.262, text_vs_uma=0.373, loss_ctc=4.007, loss=2.003, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.307e-04, train_time=0.851
[alab02] 2024-09-01 01:36:33,470 (trainer:720) INFO: 124epoch:train:1401-1600batch: iter_time=1.414e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=3.654, loss=1.827, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.307e-04, train_time=0.869
[alab02] 2024-09-01 01:37:59,102 (trainer:720) INFO: 124epoch:train:1601-1800batch: iter_time=1.352e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.371, loss_ctc=3.998, loss=1.999, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.307e-04, train_time=0.856
[alab02] 2024-09-01 01:39:24,695 (trainer:720) INFO: 124epoch:train:1801-2000batch: iter_time=1.343e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.644, loss=1.822, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.307e-04, train_time=0.856
[alab02] 2024-09-01 01:40:52,506 (trainer:720) INFO: 124epoch:train:2001-2200batch: iter_time=1.781e-04, forward_time=0.130, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.256, loss=1.628, backward_time=0.187, optim_step_time=0.037, optim0_lr0=1.307e-04, train_time=0.878
[alab02] 2024-09-01 01:42:20,759 (trainer:720) INFO: 124epoch:train:2201-2400batch: iter_time=1.365e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.353, loss_ctc=3.547, loss=1.774, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.307e-04, train_time=0.882
[alab02] 2024-09-01 01:43:46,709 (trainer:720) INFO: 124epoch:train:2401-2600batch: iter_time=1.336e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.570, loss=1.785, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.306e-04, train_time=0.859
[alab02] 2024-09-01 01:45:13,072 (trainer:720) INFO: 124epoch:train:2601-2800batch: iter_time=1.444e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.356, loss_ctc=3.625, loss=1.812, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.306e-04, train_time=0.863
[alab02] 2024-09-01 01:45:28,807 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 01:46:38,013 (trainer:720) INFO: 124epoch:train:2801-3000batch: iter_time=1.367e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.374, loss_ctc=3.719, loss=1.859, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.306e-04, train_time=0.849
[alab02] 2024-09-01 01:48:04,443 (trainer:720) INFO: 124epoch:train:3001-3200batch: iter_time=1.342e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.496, loss=1.748, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.306e-04, train_time=0.864
[alab02] 2024-09-01 01:49:30,204 (trainer:720) INFO: 124epoch:train:3201-3400batch: iter_time=1.152e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.834, loss=1.917, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.306e-04, train_time=0.857
[alab02] 2024-09-01 01:50:56,021 (trainer:720) INFO: 124epoch:train:3401-3600batch: iter_time=1.280e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.480, loss=1.740, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.306e-04, train_time=0.858
[alab02] 2024-09-01 01:52:21,520 (trainer:720) INFO: 124epoch:train:3601-3800batch: iter_time=1.264e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.574, loss=1.787, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.306e-04, train_time=0.855
[alab02] 2024-09-01 01:53:49,478 (trainer:720) INFO: 124epoch:train:3801-4000batch: iter_time=1.457e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=3.362, loss=1.681, backward_time=0.189, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.879
[alab02] 2024-09-01 01:55:15,894 (trainer:720) INFO: 124epoch:train:4001-4200batch: iter_time=1.289e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.458, loss=1.729, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.864
[alab02] 2024-09-01 01:56:39,740 (trainer:720) INFO: 124epoch:train:4201-4400batch: iter_time=1.209e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.773, loss=1.887, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.838
[alab02] 2024-09-01 01:58:06,070 (trainer:720) INFO: 124epoch:train:4401-4600batch: iter_time=1.155e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=3.516, loss=1.758, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.863
[alab02] 2024-09-01 01:59:02,713 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 01:59:32,451 (trainer:720) INFO: 124epoch:train:4601-4800batch: iter_time=1.132e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.533, loss=1.766, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.864
[alab02] 2024-09-01 02:00:57,970 (trainer:720) INFO: 124epoch:train:4801-5000batch: iter_time=1.222e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=3.470, loss=1.735, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.855
[alab02] 2024-09-01 02:02:21,864 (trainer:720) INFO: 124epoch:train:5001-5200batch: iter_time=1.158e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.363, loss_ctc=3.847, loss=1.923, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.305e-04, train_time=0.839
[alab02] 2024-09-01 02:03:46,691 (trainer:720) INFO: 124epoch:train:5201-5400batch: iter_time=1.183e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.774, loss=1.887, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.304e-04, train_time=0.848
[alab02] 2024-09-01 02:05:11,727 (trainer:720) INFO: 124epoch:train:5401-5600batch: iter_time=1.290e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.456, loss=1.728, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.304e-04, train_time=0.850
[alab02] 2024-09-01 02:06:35,448 (trainer:720) INFO: 124epoch:train:5601-5800batch: iter_time=1.239e-04, forward_time=0.122, uma_reduction=0.259, text_vs_uma=0.376, loss_ctc=3.535, loss=1.767, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.304e-04, train_time=0.837
[alab02] 2024-09-01 02:08:00,754 (trainer:720) INFO: 124epoch:train:5801-6000batch: iter_time=1.243e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.626, loss=1.813, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.304e-04, train_time=0.853
[alab02] 2024-09-01 02:09:25,870 (trainer:720) INFO: 124epoch:train:6001-6200batch: iter_time=1.230e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.488, loss=1.744, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.304e-04, train_time=0.851
[alab02] 2024-09-01 02:10:52,006 (trainer:720) INFO: 124epoch:train:6201-6400batch: iter_time=1.295e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.488, loss=1.744, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.304e-04, train_time=0.861
[alab02] 2024-09-01 02:12:17,311 (trainer:720) INFO: 124epoch:train:6401-6600batch: iter_time=1.219e-04, forward_time=0.125, uma_reduction=0.283, text_vs_uma=0.337, loss_ctc=3.355, loss=1.677, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.853
[alab02] 2024-09-01 02:13:43,486 (trainer:720) INFO: 124epoch:train:6601-6800batch: iter_time=1.233e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.584, loss=1.792, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.862
[alab02] 2024-09-01 02:15:11,206 (trainer:720) INFO: 124epoch:train:6801-7000batch: iter_time=1.244e-04, forward_time=0.130, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.531, loss=1.765, backward_time=0.186, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.877
[alab02] 2024-09-01 02:16:23,876 (trainer:338) INFO: 124epoch results: [train] iter_time=1.625e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.606, loss=1.803, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.306e-04, train_time=0.857, time=50 minutes and 55.1 seconds, total_count=883624, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.293, text_vs_uma=0.371, loss_ctc=2.982, cer_ctc=0.083, cer=0.083, loss=2.982, time=5.81 seconds, total_count=3224, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.19 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 02:16:28,794 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 02:16:28,847 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/99epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/123epoch.pth
[alab02] 2024-09-01 02:16:28,847 (trainer:272) INFO: 125/150epoch started. Estimated time to finish: 23 hours, 20 minutes and 39.82 seconds
[alab02] 2024-09-01 02:17:53,322 (trainer:720) INFO: 125epoch:train:1-200batch: iter_time=0.001, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.605, loss=1.803, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.844
[alab02] 2024-09-01 02:19:19,205 (trainer:720) INFO: 125epoch:train:201-400batch: iter_time=1.306e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=3.906, loss=1.953, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.859
[alab02] 2024-09-01 02:20:44,722 (trainer:720) INFO: 125epoch:train:401-600batch: iter_time=1.297e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.349, loss_ctc=3.594, loss=1.797, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.855
[alab02] 2024-09-01 02:22:08,693 (trainer:720) INFO: 125epoch:train:601-800batch: iter_time=1.154e-04, forward_time=0.123, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=3.389, loss=1.694, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.303e-04, train_time=0.840
[alab02] 2024-09-01 02:23:35,496 (trainer:720) INFO: 125epoch:train:801-1000batch: iter_time=1.158e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.357, loss_ctc=3.772, loss=1.886, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.302e-04, train_time=0.868
[alab02] 2024-09-01 02:25:01,947 (trainer:720) INFO: 125epoch:train:1001-1200batch: iter_time=1.336e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.354, loss_ctc=3.406, loss=1.703, backward_time=0.185, optim_step_time=0.029, optim0_lr0=1.302e-04, train_time=0.864
[alab02] 2024-09-01 02:26:24,315 (trainer:720) INFO: 125epoch:train:1201-1400batch: iter_time=1.296e-04, forward_time=0.121, uma_reduction=0.277, text_vs_uma=0.360, loss_ctc=3.547, loss=1.773, backward_time=0.172, optim_step_time=0.032, optim0_lr0=1.302e-04, train_time=0.823
[alab02] 2024-09-01 02:27:49,049 (trainer:720) INFO: 125epoch:train:1401-1600batch: iter_time=1.221e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.363, loss_ctc=3.537, loss=1.769, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.302e-04, train_time=0.847
[alab02] 2024-09-01 02:29:12,397 (trainer:720) INFO: 125epoch:train:1601-1800batch: iter_time=1.259e-04, forward_time=0.122, uma_reduction=0.285, text_vs_uma=0.344, loss_ctc=3.566, loss=1.783, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.302e-04, train_time=0.833
[alab02] 2024-09-01 02:30:38,560 (trainer:720) INFO: 125epoch:train:1801-2000batch: iter_time=1.138e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=3.815, loss=1.908, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.302e-04, train_time=0.861
[alab02] 2024-09-01 02:32:02,531 (trainer:720) INFO: 125epoch:train:2001-2200batch: iter_time=1.185e-04, forward_time=0.122, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.743, loss=1.872, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.301e-04, train_time=0.840
[alab02] 2024-09-01 02:33:26,342 (trainer:720) INFO: 125epoch:train:2201-2400batch: iter_time=1.221e-04, forward_time=0.123, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=3.869, loss=1.934, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.301e-04, train_time=0.838
[alab02] 2024-09-01 02:34:51,768 (trainer:720) INFO: 125epoch:train:2401-2600batch: iter_time=1.321e-04, forward_time=0.126, uma_reduction=0.285, text_vs_uma=0.334, loss_ctc=3.282, loss=1.641, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.301e-04, train_time=0.854
[alab02] 2024-09-01 02:36:18,242 (trainer:720) INFO: 125epoch:train:2601-2800batch: iter_time=1.246e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.538, loss=1.769, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.301e-04, train_time=0.865
[alab02] 2024-09-01 02:37:43,179 (trainer:720) INFO: 125epoch:train:2801-3000batch: iter_time=1.357e-04, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.341, loss_ctc=3.624, loss=1.812, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.301e-04, train_time=0.849
[alab02] 2024-09-01 02:39:09,628 (trainer:720) INFO: 125epoch:train:3001-3200batch: iter_time=1.270e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.340, loss_ctc=3.550, loss=1.775, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.301e-04, train_time=0.864
[alab02] 2024-09-01 02:40:34,780 (trainer:720) INFO: 125epoch:train:3201-3400batch: iter_time=1.308e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.490, loss=1.745, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.301e-04, train_time=0.851
[alab02] 2024-09-01 02:41:59,273 (trainer:720) INFO: 125epoch:train:3401-3600batch: iter_time=1.191e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.786, loss=1.893, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.845
[alab02] 2024-09-01 02:43:24,428 (trainer:720) INFO: 125epoch:train:3601-3800batch: iter_time=1.262e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.351, loss_ctc=3.451, loss=1.726, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.851
[alab02] 2024-09-01 02:44:51,395 (trainer:720) INFO: 125epoch:train:3801-4000batch: iter_time=1.238e-04, forward_time=0.128, uma_reduction=0.265, text_vs_uma=0.362, loss_ctc=3.709, loss=1.855, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.869
[alab02] 2024-09-01 02:46:16,023 (trainer:720) INFO: 125epoch:train:4001-4200batch: iter_time=1.275e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.437, loss=1.719, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.846
[alab02] 2024-09-01 02:47:41,793 (trainer:720) INFO: 125epoch:train:4201-4400batch: iter_time=1.127e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.638, loss=1.819, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.858
[alab02] 2024-09-01 02:49:05,457 (trainer:720) INFO: 125epoch:train:4401-4600batch: iter_time=1.158e-04, forward_time=0.123, uma_reduction=0.262, text_vs_uma=0.371, loss_ctc=3.729, loss=1.864, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.836
[alab02] 2024-09-01 02:50:28,336 (trainer:720) INFO: 125epoch:train:4601-4800batch: iter_time=1.259e-04, forward_time=0.121, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=3.748, loss=1.874, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.829
[alab02] 2024-09-01 02:51:53,484 (trainer:720) INFO: 125epoch:train:4801-5000batch: iter_time=1.153e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=3.398, loss=1.699, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.299e-04, train_time=0.851
[alab02] 2024-09-01 02:53:19,087 (trainer:720) INFO: 125epoch:train:5001-5200batch: iter_time=1.139e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.609, loss=1.805, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.299e-04, train_time=0.856
[alab02] 2024-09-01 02:54:45,417 (trainer:720) INFO: 125epoch:train:5201-5400batch: iter_time=1.147e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.569, loss=1.785, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.299e-04, train_time=0.863
[alab02] 2024-09-01 02:56:10,146 (trainer:720) INFO: 125epoch:train:5401-5600batch: iter_time=1.130e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.341, loss_ctc=3.374, loss=1.687, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.299e-04, train_time=0.847
[alab02] 2024-09-01 02:57:33,067 (trainer:720) INFO: 125epoch:train:5601-5800batch: iter_time=1.178e-04, forward_time=0.121, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.625, loss=1.812, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.299e-04, train_time=0.829
[alab02] 2024-09-01 02:58:58,396 (trainer:720) INFO: 125epoch:train:5801-6000batch: iter_time=1.218e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=4.024, loss=2.012, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.299e-04, train_time=0.853
[alab02] 2024-09-01 03:00:25,340 (trainer:720) INFO: 125epoch:train:6001-6200batch: iter_time=1.242e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.743, loss=1.871, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.299e-04, train_time=0.869
[alab02] 2024-09-01 03:01:48,926 (trainer:720) INFO: 125epoch:train:6201-6400batch: iter_time=1.237e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.678, loss=1.839, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.298e-04, train_time=0.836
[alab02] 2024-09-01 03:03:15,350 (trainer:720) INFO: 125epoch:train:6401-6600batch: iter_time=1.259e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=3.990, loss=1.995, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.298e-04, train_time=0.864
[alab02] 2024-09-01 03:04:39,935 (trainer:720) INFO: 125epoch:train:6601-6800batch: iter_time=1.236e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.850, loss=1.925, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.298e-04, train_time=0.846
[alab02] 2024-09-01 03:06:03,747 (trainer:720) INFO: 125epoch:train:6801-7000batch: iter_time=1.289e-04, forward_time=0.122, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=3.470, loss=1.735, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.298e-04, train_time=0.838
[alab02] 2024-09-01 03:07:15,893 (trainer:338) INFO: 125epoch results: [train] iter_time=1.549e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.632, loss=1.816, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.300e-04, train_time=0.850, time=50 minutes and 29.11 seconds, total_count=890750, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.289, text_vs_uma=0.376, loss_ctc=2.971, cer_ctc=0.080, cer=0.080, loss=2.971, time=5.9 seconds, total_count=3250, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.04 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 03:07:21,591 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-09-01 03:07:21,643 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/121epoch.pth
[alab02] 2024-09-01 03:07:21,643 (trainer:272) INFO: 126/150epoch started. Estimated time to finish: 22 hours, 26 minutes and 11.62 seconds
[alab02] 2024-09-01 03:08:49,599 (trainer:720) INFO: 126epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=3.726, loss=1.863, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.298e-04, train_time=0.879
[alab02] 2024-09-01 03:10:15,314 (trainer:720) INFO: 126epoch:train:201-400batch: iter_time=1.359e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.343, loss_ctc=3.426, loss=1.713, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.298e-04, train_time=0.857
[alab02] 2024-09-01 03:10:24,207 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 03:11:41,845 (trainer:720) INFO: 126epoch:train:401-600batch: iter_time=1.623e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=3.636, loss=1.818, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.297e-04, train_time=0.865
[alab02] 2024-09-01 03:13:09,757 (trainer:720) INFO: 126epoch:train:601-800batch: iter_time=1.390e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.601, loss=1.801, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.297e-04, train_time=0.879
[alab02] 2024-09-01 03:13:25,676 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 03:14:34,457 (trainer:720) INFO: 126epoch:train:801-1000batch: iter_time=1.256e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=3.938, loss=1.969, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.297e-04, train_time=0.847
[alab02] 2024-09-01 03:15:59,291 (trainer:720) INFO: 126epoch:train:1001-1200batch: iter_time=1.303e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.670, loss=1.835, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.297e-04, train_time=0.848
[alab02] 2024-09-01 03:17:23,798 (trainer:720) INFO: 126epoch:train:1201-1400batch: iter_time=1.181e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.857, loss=1.928, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.297e-04, train_time=0.845
[alab02] 2024-09-01 03:18:48,956 (trainer:720) INFO: 126epoch:train:1401-1600batch: iter_time=1.203e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.398, loss=1.699, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.297e-04, train_time=0.851
[alab02] 2024-09-01 03:20:12,193 (trainer:720) INFO: 126epoch:train:1601-1800batch: iter_time=1.257e-04, forward_time=0.122, uma_reduction=0.282, text_vs_uma=0.342, loss_ctc=3.403, loss=1.702, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.297e-04, train_time=0.832
[alab02] 2024-09-01 03:21:34,365 (trainer:720) INFO: 126epoch:train:1801-2000batch: iter_time=1.194e-04, forward_time=0.120, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.371, loss=1.685, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.822
[alab02] 2024-09-01 03:23:00,232 (trainer:720) INFO: 126epoch:train:2001-2200batch: iter_time=1.157e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=3.468, loss=1.734, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.858
[alab02] 2024-09-01 03:24:24,666 (trainer:720) INFO: 126epoch:train:2201-2400batch: iter_time=1.209e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.649, loss=1.825, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.844
[alab02] 2024-09-01 03:25:50,292 (trainer:720) INFO: 126epoch:train:2401-2600batch: iter_time=1.224e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=3.433, loss=1.717, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.856
[alab02] 2024-09-01 03:27:14,065 (trainer:720) INFO: 126epoch:train:2601-2800batch: iter_time=1.234e-04, forward_time=0.123, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=3.725, loss=1.862, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.838
[alab02] 2024-09-01 03:28:39,882 (trainer:720) INFO: 126epoch:train:2801-3000batch: iter_time=1.316e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.654, loss=1.827, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.858
[alab02] 2024-09-01 03:30:05,598 (trainer:720) INFO: 126epoch:train:3001-3200batch: iter_time=1.205e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.640, loss=1.820, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.296e-04, train_time=0.857
[alab02] 2024-09-01 03:31:29,047 (trainer:720) INFO: 126epoch:train:3201-3400batch: iter_time=1.162e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.579, loss=1.790, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.295e-04, train_time=0.834
[alab02] 2024-09-01 03:32:53,146 (trainer:720) INFO: 126epoch:train:3401-3600batch: iter_time=1.333e-04, forward_time=0.124, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.586, loss=1.793, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.295e-04, train_time=0.841
[alab02] 2024-09-01 03:34:18,599 (trainer:720) INFO: 126epoch:train:3601-3800batch: iter_time=1.727e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.343, loss_ctc=3.320, loss=1.660, backward_time=0.177, optim_step_time=0.035, optim0_lr0=1.295e-04, train_time=0.854
[alab02] 2024-09-01 03:35:42,850 (trainer:720) INFO: 126epoch:train:3801-4000batch: iter_time=1.497e-04, forward_time=0.124, uma_reduction=0.286, text_vs_uma=0.338, loss_ctc=3.243, loss=1.622, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.295e-04, train_time=0.842
[alab02] 2024-09-01 03:37:09,022 (trainer:720) INFO: 126epoch:train:4001-4200batch: iter_time=1.481e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.340, loss_ctc=3.468, loss=1.734, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.295e-04, train_time=0.862
[alab02] 2024-09-01 03:38:33,624 (trainer:720) INFO: 126epoch:train:4201-4400batch: iter_time=1.677e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.426, loss=1.713, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.295e-04, train_time=0.846
[alab02] 2024-09-01 03:39:57,079 (trainer:720) INFO: 126epoch:train:4401-4600batch: iter_time=1.398e-04, forward_time=0.123, uma_reduction=0.280, text_vs_uma=0.350, loss_ctc=3.450, loss=1.725, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.295e-04, train_time=0.834
[alab02] 2024-09-01 03:41:22,748 (trainer:720) INFO: 126epoch:train:4601-4800batch: iter_time=1.261e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.350, loss_ctc=3.958, loss=1.979, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.294e-04, train_time=0.856
[alab02] 2024-09-01 03:42:47,772 (trainer:720) INFO: 126epoch:train:4801-5000batch: iter_time=1.296e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.401, loss=1.701, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.294e-04, train_time=0.850
[alab02] 2024-09-01 03:44:12,638 (trainer:720) INFO: 126epoch:train:5001-5200batch: iter_time=1.307e-04, forward_time=0.125, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=3.430, loss=1.715, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.294e-04, train_time=0.848
[alab02] 2024-09-01 03:45:38,210 (trainer:720) INFO: 126epoch:train:5201-5400batch: iter_time=1.378e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.698, loss=1.849, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.294e-04, train_time=0.856
[alab02] 2024-09-01 03:47:01,882 (trainer:720) INFO: 126epoch:train:5401-5600batch: iter_time=1.135e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.363, loss_ctc=3.734, loss=1.867, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.294e-04, train_time=0.837
[alab02] 2024-09-01 03:48:27,889 (trainer:720) INFO: 126epoch:train:5601-5800batch: iter_time=1.200e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.584, loss=1.792, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.294e-04, train_time=0.860
[alab02] 2024-09-01 03:49:53,096 (trainer:720) INFO: 126epoch:train:5801-6000batch: iter_time=1.149e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.588, loss=1.794, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.294e-04, train_time=0.852
[alab02] 2024-09-01 03:51:16,868 (trainer:720) INFO: 126epoch:train:6001-6200batch: iter_time=1.250e-04, forward_time=0.123, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=3.339, loss=1.669, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.293e-04, train_time=0.838
[alab02] 2024-09-01 03:52:42,529 (trainer:720) INFO: 126epoch:train:6201-6400batch: iter_time=1.115e-04, forward_time=0.126, uma_reduction=0.281, text_vs_uma=0.357, loss_ctc=3.294, loss=1.647, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.293e-04, train_time=0.856
[alab02] 2024-09-01 03:54:08,019 (trainer:720) INFO: 126epoch:train:6401-6600batch: iter_time=1.103e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=3.612, loss=1.806, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.293e-04, train_time=0.855
[alab02] 2024-09-01 03:55:33,310 (trainer:720) INFO: 126epoch:train:6601-6800batch: iter_time=1.124e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.341, loss_ctc=3.418, loss=1.709, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.293e-04, train_time=0.853
[alab02] 2024-09-01 03:56:58,130 (trainer:720) INFO: 126epoch:train:6801-7000batch: iter_time=1.123e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.357, loss_ctc=3.764, loss=1.882, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.293e-04, train_time=0.848
[alab02] 2024-09-01 03:58:11,064 (trainer:338) INFO: 126epoch results: [train] iter_time=1.695e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.557, loss=1.778, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.295e-04, train_time=0.850, time=50 minutes and 31.43 seconds, total_count=897876, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.298, text_vs_uma=0.365, loss_ctc=3.065, cer_ctc=0.083, cer=0.083, loss=3.065, time=5.82 seconds, total_count=3276, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.17 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 03:58:16,346 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 03:58:16,399 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/120epoch.pth
[alab02] 2024-09-01 03:58:16,399 (trainer:272) INFO: 127/150epoch started. Estimated time to finish: 21 hours, 31 minutes and 47.21 seconds
[alab02] 2024-09-01 03:59:42,075 (trainer:720) INFO: 127epoch:train:1-200batch: iter_time=0.001, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.685, loss=1.842, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.293e-04, train_time=0.856
[alab02] 2024-09-01 04:01:08,073 (trainer:720) INFO: 127epoch:train:201-400batch: iter_time=1.242e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.353, loss_ctc=3.543, loss=1.771, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.292e-04, train_time=0.860
[alab02] 2024-09-01 04:02:31,625 (trainer:720) INFO: 127epoch:train:401-600batch: iter_time=1.292e-04, forward_time=0.123, uma_reduction=0.286, text_vs_uma=0.343, loss_ctc=3.431, loss=1.715, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.292e-04, train_time=0.835
[alab02] 2024-09-01 04:03:56,027 (trainer:720) INFO: 127epoch:train:601-800batch: iter_time=1.426e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.354, loss_ctc=3.497, loss=1.748, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.292e-04, train_time=0.844
[alab02] 2024-09-01 04:05:20,742 (trainer:720) INFO: 127epoch:train:801-1000batch: iter_time=1.386e-04, forward_time=0.124, uma_reduction=0.283, text_vs_uma=0.352, loss_ctc=3.714, loss=1.857, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.292e-04, train_time=0.847
[alab02] 2024-09-01 04:06:47,065 (trainer:720) INFO: 127epoch:train:1001-1200batch: iter_time=1.502e-04, forward_time=0.126, uma_reduction=0.296, text_vs_uma=0.330, loss_ctc=3.550, loss=1.775, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.292e-04, train_time=0.863
[alab02] 2024-09-01 04:08:14,068 (trainer:720) INFO: 127epoch:train:1201-1400batch: iter_time=1.689e-04, forward_time=0.128, uma_reduction=0.300, text_vs_uma=0.322, loss_ctc=3.401, loss=1.701, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.292e-04, train_time=0.870
[alab02] 2024-09-01 04:09:40,730 (trainer:720) INFO: 127epoch:train:1401-1600batch: iter_time=1.438e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.339, loss_ctc=3.237, loss=1.619, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.292e-04, train_time=0.866
[alab02] 2024-09-01 04:11:07,371 (trainer:720) INFO: 127epoch:train:1601-1800batch: iter_time=1.532e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.766, loss=1.883, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.291e-04, train_time=0.866
[alab02] 2024-09-01 04:12:32,584 (trainer:720) INFO: 127epoch:train:1801-2000batch: iter_time=1.530e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.554, loss=1.777, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.291e-04, train_time=0.852
[alab02] 2024-09-01 04:13:57,949 (trainer:720) INFO: 127epoch:train:2001-2200batch: iter_time=1.448e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=3.609, loss=1.804, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.291e-04, train_time=0.853
[alab02] 2024-09-01 04:15:22,722 (trainer:720) INFO: 127epoch:train:2201-2400batch: iter_time=1.358e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=3.313, loss=1.657, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.291e-04, train_time=0.848
[alab02] 2024-09-01 04:15:57,959 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 04:16:48,344 (trainer:720) INFO: 127epoch:train:2401-2600batch: iter_time=1.232e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.521, loss=1.760, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.291e-04, train_time=0.856
[alab02] 2024-09-01 04:18:12,053 (trainer:720) INFO: 127epoch:train:2601-2800batch: iter_time=1.112e-04, forward_time=0.123, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=3.465, loss=1.732, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.291e-04, train_time=0.837
[alab02] 2024-09-01 04:19:38,028 (trainer:720) INFO: 127epoch:train:2801-3000batch: iter_time=1.146e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.344, loss_ctc=3.365, loss=1.682, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.291e-04, train_time=0.860
[alab02] 2024-09-01 04:21:03,896 (trainer:720) INFO: 127epoch:train:3001-3200batch: iter_time=1.177e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=3.688, loss=1.844, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.859
[alab02] 2024-09-01 04:22:30,455 (trainer:720) INFO: 127epoch:train:3201-3400batch: iter_time=1.191e-04, forward_time=0.127, uma_reduction=0.285, text_vs_uma=0.343, loss_ctc=3.389, loss=1.695, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.865
[alab02] 2024-09-01 04:23:55,521 (trainer:720) INFO: 127epoch:train:3401-3600batch: iter_time=1.177e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.343, loss_ctc=3.288, loss=1.644, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.850
[alab02] 2024-09-01 04:25:21,993 (trainer:720) INFO: 127epoch:train:3601-3800batch: iter_time=1.207e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.344, loss_ctc=3.201, loss=1.600, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.865
[alab02] 2024-09-01 04:26:48,050 (trainer:720) INFO: 127epoch:train:3801-4000batch: iter_time=1.172e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.362, loss_ctc=3.670, loss=1.835, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.860
[alab02] 2024-09-01 04:28:12,061 (trainer:720) INFO: 127epoch:train:4001-4200batch: iter_time=1.201e-04, forward_time=0.123, uma_reduction=0.278, text_vs_uma=0.344, loss_ctc=3.300, loss=1.650, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.840
[alab02] 2024-09-01 04:29:35,678 (trainer:720) INFO: 127epoch:train:4201-4400batch: iter_time=1.199e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.350, loss_ctc=3.069, loss=1.535, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.836
[alab02] 2024-09-01 04:31:02,087 (trainer:720) INFO: 127epoch:train:4401-4600batch: iter_time=1.218e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.463, loss=1.731, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.289e-04, train_time=0.864
[alab02] 2024-09-01 04:32:27,565 (trainer:720) INFO: 127epoch:train:4601-4800batch: iter_time=1.274e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=3.447, loss=1.723, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.289e-04, train_time=0.855
[alab02] 2024-09-01 04:33:52,656 (trainer:720) INFO: 127epoch:train:4801-5000batch: iter_time=1.426e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.532, loss=1.766, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.289e-04, train_time=0.851
[alab02] 2024-09-01 04:35:18,089 (trainer:720) INFO: 127epoch:train:5001-5200batch: iter_time=1.312e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.526, loss=1.763, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.289e-04, train_time=0.854
[alab02] 2024-09-01 04:36:41,745 (trainer:720) INFO: 127epoch:train:5201-5400batch: iter_time=1.275e-04, forward_time=0.122, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.664, loss=1.832, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.289e-04, train_time=0.836
[alab02] 2024-09-01 04:38:07,486 (trainer:720) INFO: 127epoch:train:5401-5600batch: iter_time=1.303e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.341, loss_ctc=3.246, loss=1.623, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.289e-04, train_time=0.857
[alab02] 2024-09-01 04:39:31,719 (trainer:720) INFO: 127epoch:train:5601-5800batch: iter_time=1.305e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=3.569, loss=1.785, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.289e-04, train_time=0.842
[alab02] 2024-09-01 04:40:57,962 (trainer:720) INFO: 127epoch:train:5801-6000batch: iter_time=1.270e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.343, loss_ctc=3.357, loss=1.679, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.288e-04, train_time=0.862
[alab02] 2024-09-01 04:42:25,578 (trainer:720) INFO: 127epoch:train:6001-6200batch: iter_time=1.265e-04, forward_time=0.130, uma_reduction=0.274, text_vs_uma=0.347, loss_ctc=3.504, loss=1.752, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.288e-04, train_time=0.876
[alab02] 2024-09-01 04:43:49,829 (trainer:720) INFO: 127epoch:train:6201-6400batch: iter_time=1.292e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.352, loss_ctc=3.363, loss=1.682, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.288e-04, train_time=0.842
[alab02] 2024-09-01 04:45:14,820 (trainer:720) INFO: 127epoch:train:6401-6600batch: iter_time=1.169e-04, forward_time=0.125, uma_reduction=0.258, text_vs_uma=0.373, loss_ctc=3.259, loss=1.629, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.288e-04, train_time=0.850
[alab02] 2024-09-01 04:46:40,829 (trainer:720) INFO: 127epoch:train:6601-6800batch: iter_time=1.183e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.360, loss_ctc=3.586, loss=1.793, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.288e-04, train_time=0.860
[alab02] 2024-09-01 04:48:06,563 (trainer:720) INFO: 127epoch:train:6801-7000batch: iter_time=1.299e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.366, loss_ctc=3.467, loss=1.734, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.288e-04, train_time=0.857
[alab02] 2024-09-01 04:48:27,875 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 04:49:17,995 (trainer:338) INFO: 127epoch results: [train] iter_time=1.651e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.466, loss=1.733, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.290e-04, train_time=0.854, time=50 minutes and 43.63 seconds, total_count=905002, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.295, text_vs_uma=0.368, loss_ctc=2.980, cer_ctc=0.084, cer=0.084, loss=2.980, time=5.84 seconds, total_count=3302, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.13 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 04:49:27,560 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 04:49:27,561 (trainer:272) INFO: 128/150epoch started. Estimated time to finish: 20 hours, 37 minutes and 29.07 seconds
[alab02] 2024-09-01 04:50:54,435 (trainer:720) INFO: 128epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.336, loss_ctc=3.297, loss=1.649, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.868
[alab02] 2024-09-01 04:52:21,136 (trainer:720) INFO: 128epoch:train:201-400batch: iter_time=1.334e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.344, loss_ctc=3.451, loss=1.725, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.867
[alab02] 2024-09-01 04:53:44,787 (trainer:720) INFO: 128epoch:train:401-600batch: iter_time=1.233e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.564, loss=1.782, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.836
[alab02] 2024-09-01 04:55:10,714 (trainer:720) INFO: 128epoch:train:601-800batch: iter_time=1.223e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.512, loss=1.756, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.859
[alab02] 2024-09-01 04:56:36,774 (trainer:720) INFO: 128epoch:train:801-1000batch: iter_time=1.162e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.371, loss_ctc=3.425, loss=1.712, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.860
[alab02] 2024-09-01 04:58:03,023 (trainer:720) INFO: 128epoch:train:1001-1200batch: iter_time=1.181e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.413, loss=1.706, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.862
[alab02] 2024-09-01 04:59:29,969 (trainer:720) INFO: 128epoch:train:1201-1400batch: iter_time=1.221e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.355, loss_ctc=3.551, loss=1.776, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.287e-04, train_time=0.869
[alab02] 2024-09-01 05:00:55,227 (trainer:720) INFO: 128epoch:train:1401-1600batch: iter_time=1.265e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.340, loss_ctc=3.427, loss=1.713, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.852
[alab02] 2024-09-01 05:02:20,488 (trainer:720) INFO: 128epoch:train:1601-1800batch: iter_time=1.389e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.522, loss=1.761, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.852
[alab02] 2024-09-01 05:03:45,118 (trainer:720) INFO: 128epoch:train:1801-2000batch: iter_time=1.285e-04, forward_time=0.124, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=3.233, loss=1.617, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.846
[alab02] 2024-09-01 05:05:10,126 (trainer:720) INFO: 128epoch:train:2001-2200batch: iter_time=1.397e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.916, loss=1.958, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.850
[alab02] 2024-09-01 05:06:32,999 (trainer:720) INFO: 128epoch:train:2201-2400batch: iter_time=1.400e-04, forward_time=0.121, uma_reduction=0.277, text_vs_uma=0.359, loss_ctc=3.678, loss=1.839, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.829
[alab02] 2024-09-01 05:07:58,140 (trainer:720) INFO: 128epoch:train:2401-2600batch: iter_time=1.287e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.339, loss_ctc=3.528, loss=1.764, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.851
[alab02] 2024-09-01 05:09:25,254 (trainer:720) INFO: 128epoch:train:2601-2800batch: iter_time=1.300e-04, forward_time=0.128, uma_reduction=0.284, text_vs_uma=0.346, loss_ctc=3.672, loss=1.836, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.286e-04, train_time=0.871
[alab02] 2024-09-01 05:10:49,673 (trainer:720) INFO: 128epoch:train:2801-3000batch: iter_time=1.327e-04, forward_time=0.124, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=3.271, loss=1.636, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.844
[alab02] 2024-09-01 05:12:15,329 (trainer:720) INFO: 128epoch:train:3001-3200batch: iter_time=1.297e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.354, loss_ctc=3.530, loss=1.765, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.856
[alab02] 2024-09-01 05:13:40,427 (trainer:720) INFO: 128epoch:train:3201-3400batch: iter_time=1.279e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=3.541, loss=1.770, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.285e-04, train_time=0.851
[alab02] 2024-09-01 05:15:07,261 (trainer:720) INFO: 128epoch:train:3401-3600batch: iter_time=1.216e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=3.453, loss=1.726, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.868
[alab02] 2024-09-01 05:16:33,713 (trainer:720) INFO: 128epoch:train:3601-3800batch: iter_time=1.427e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.365, loss=1.683, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.864
[alab02] 2024-09-01 05:17:59,949 (trainer:720) INFO: 128epoch:train:3801-4000batch: iter_time=1.274e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.644, loss=1.822, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.862
[alab02] 2024-09-01 05:19:26,680 (trainer:720) INFO: 128epoch:train:4001-4200batch: iter_time=1.235e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.376, loss=1.688, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.867
[alab02] 2024-09-01 05:20:52,310 (trainer:720) INFO: 128epoch:train:4201-4400batch: iter_time=1.212e-04, forward_time=0.126, uma_reduction=0.284, text_vs_uma=0.331, loss_ctc=3.448, loss=1.724, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.856
[alab02] 2024-09-01 05:22:16,489 (trainer:720) INFO: 128epoch:train:4401-4600batch: iter_time=1.191e-04, forward_time=0.123, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.360, loss=1.680, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.284e-04, train_time=0.842
[alab02] 2024-09-01 05:23:41,798 (trainer:720) INFO: 128epoch:train:4601-4800batch: iter_time=1.186e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=3.346, loss=1.673, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.284e-04, train_time=0.853
[alab02] 2024-09-01 05:23:49,702 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 05:25:07,342 (trainer:720) INFO: 128epoch:train:4801-5000batch: iter_time=1.228e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.365, loss_ctc=3.352, loss=1.676, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.284e-04, train_time=0.855
[alab02] 2024-09-01 05:26:33,169 (trainer:720) INFO: 128epoch:train:5001-5200batch: iter_time=1.223e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.645, loss=1.823, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.284e-04, train_time=0.858
[alab02] 2024-09-01 05:28:01,502 (trainer:720) INFO: 128epoch:train:5201-5400batch: iter_time=1.517e-04, forward_time=0.131, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.730, loss=1.865, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.284e-04, train_time=0.883
[alab02] 2024-09-01 05:29:26,665 (trainer:720) INFO: 128epoch:train:5401-5600batch: iter_time=1.213e-04, forward_time=0.125, uma_reduction=0.283, text_vs_uma=0.344, loss_ctc=3.395, loss=1.697, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.284e-04, train_time=0.851
[alab02] 2024-09-01 05:30:52,042 (trainer:720) INFO: 128epoch:train:5601-5800batch: iter_time=1.211e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.349, loss_ctc=3.425, loss=1.712, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.284e-04, train_time=0.854
[alab02] 2024-09-01 05:32:16,503 (trainer:720) INFO: 128epoch:train:5801-6000batch: iter_time=1.162e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.385, loss=1.693, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.283e-04, train_time=0.844
[alab02] 2024-09-01 05:33:39,042 (trainer:720) INFO: 128epoch:train:6001-6200batch: iter_time=1.145e-04, forward_time=0.121, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.545, loss=1.772, backward_time=0.171, optim_step_time=0.030, optim0_lr0=1.283e-04, train_time=0.825
[alab02] 2024-09-01 05:35:05,359 (trainer:720) INFO: 128epoch:train:6201-6400batch: iter_time=1.236e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.371, loss_ctc=3.618, loss=1.809, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.283e-04, train_time=0.863
[alab02] 2024-09-01 05:36:32,521 (trainer:720) INFO: 128epoch:train:6401-6600batch: iter_time=1.178e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.625, loss=1.813, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.283e-04, train_time=0.871
[alab02] 2024-09-01 05:37:54,726 (trainer:720) INFO: 128epoch:train:6601-6800batch: iter_time=1.176e-04, forward_time=0.121, uma_reduction=0.279, text_vs_uma=0.340, loss_ctc=3.108, loss=1.554, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.283e-04, train_time=0.822
[alab02] 2024-09-01 05:39:20,838 (trainer:720) INFO: 128epoch:train:6801-7000batch: iter_time=1.188e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.420, loss=1.710, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.283e-04, train_time=0.861
[alab02] 2024-09-01 05:40:31,167 (trainer:338) INFO: 128epoch results: [train] iter_time=1.672e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.478, loss=1.739, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.285e-04, train_time=0.855, time=50 minutes and 46.14 seconds, total_count=912128, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.274, text_vs_uma=0.397, loss_ctc=2.972, cer_ctc=0.083, cer=0.083, loss=2.972, time=5.94 seconds, total_count=3328, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.52 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 05:40:36,840 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 05:40:36,935 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/119epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/127epoch.pth
[alab02] 2024-09-01 05:40:36,936 (trainer:272) INFO: 129/150epoch started. Estimated time to finish: 19 hours, 43 minutes and 13.55 seconds
[alab02] 2024-09-01 05:42:02,051 (trainer:720) INFO: 129epoch:train:1-200batch: iter_time=0.002, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=3.324, loss=1.662, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.282e-04, train_time=0.851
[alab02] 2024-09-01 05:43:26,231 (trainer:720) INFO: 129epoch:train:201-400batch: iter_time=1.450e-04, forward_time=0.123, uma_reduction=0.262, text_vs_uma=0.376, loss_ctc=3.974, loss=1.987, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.282e-04, train_time=0.842
[alab02] 2024-09-01 05:44:53,584 (trainer:720) INFO: 129epoch:train:401-600batch: iter_time=1.463e-04, forward_time=0.128, uma_reduction=0.260, text_vs_uma=0.381, loss_ctc=3.886, loss=1.943, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.282e-04, train_time=0.873
[alab02] 2024-09-01 05:46:19,053 (trainer:720) INFO: 129epoch:train:601-800batch: iter_time=1.406e-04, forward_time=0.125, uma_reduction=0.259, text_vs_uma=0.382, loss_ctc=4.010, loss=2.005, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.282e-04, train_time=0.854
[alab02] 2024-09-01 05:47:45,086 (trainer:720) INFO: 129epoch:train:801-1000batch: iter_time=1.363e-04, forward_time=0.126, uma_reduction=0.258, text_vs_uma=0.378, loss_ctc=3.790, loss=1.895, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.282e-04, train_time=0.860
[alab02] 2024-09-01 05:49:09,286 (trainer:720) INFO: 129epoch:train:1001-1200batch: iter_time=1.424e-04, forward_time=0.124, uma_reduction=0.260, text_vs_uma=0.371, loss_ctc=3.510, loss=1.755, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.282e-04, train_time=0.842
[alab02] 2024-09-01 05:50:34,957 (trainer:720) INFO: 129epoch:train:1201-1400batch: iter_time=1.290e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.369, loss_ctc=4.072, loss=2.036, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.282e-04, train_time=0.857
[alab02] 2024-09-01 05:51:59,993 (trainer:720) INFO: 129epoch:train:1401-1600batch: iter_time=1.330e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.369, loss=1.685, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.281e-04, train_time=0.850
[alab02] 2024-09-01 05:53:25,437 (trainer:720) INFO: 129epoch:train:1601-1800batch: iter_time=1.346e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.499, loss=1.750, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.281e-04, train_time=0.854
[alab02] 2024-09-01 05:54:50,438 (trainer:720) INFO: 129epoch:train:1801-2000batch: iter_time=1.324e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.379, loss_ctc=3.647, loss=1.823, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.281e-04, train_time=0.850
[alab02] 2024-09-01 05:55:49,842 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 05:56:14,130 (trainer:720) INFO: 129epoch:train:2001-2200batch: iter_time=1.309e-04, forward_time=0.123, uma_reduction=0.261, text_vs_uma=0.366, loss_ctc=3.830, loss=1.915, backward_time=0.171, optim_step_time=0.031, optim0_lr0=1.281e-04, train_time=0.837
[alab02] 2024-09-01 05:57:35,704 (trainer:720) INFO: 129epoch:train:2201-2400batch: iter_time=1.206e-04, forward_time=0.120, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.526, loss=1.763, backward_time=0.168, optim_step_time=0.030, optim0_lr0=1.281e-04, train_time=0.816
[alab02] 2024-09-01 05:59:03,430 (trainer:720) INFO: 129epoch:train:2401-2600batch: iter_time=1.270e-04, forward_time=0.128, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.907, loss=1.954, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.281e-04, train_time=0.877
[alab02] 2024-09-01 06:00:30,095 (trainer:720) INFO: 129epoch:train:2601-2800batch: iter_time=1.299e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.732, loss=1.866, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.281e-04, train_time=0.866
[alab02] 2024-09-01 06:01:56,797 (trainer:720) INFO: 129epoch:train:2801-3000batch: iter_time=1.426e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.352, loss_ctc=3.543, loss=1.771, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.280e-04, train_time=0.867
[alab02] 2024-09-01 06:03:21,767 (trainer:720) INFO: 129epoch:train:3001-3200batch: iter_time=1.235e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.372, loss_ctc=3.741, loss=1.870, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.280e-04, train_time=0.849
[alab02] 2024-09-01 06:04:47,888 (trainer:720) INFO: 129epoch:train:3201-3400batch: iter_time=1.236e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.539, loss=1.769, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.280e-04, train_time=0.861
[alab02] 2024-09-01 06:06:14,641 (trainer:720) INFO: 129epoch:train:3401-3600batch: iter_time=1.188e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.803, loss=1.902, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.280e-04, train_time=0.867
[alab02] 2024-09-01 06:07:39,896 (trainer:720) INFO: 129epoch:train:3601-3800batch: iter_time=1.212e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.621, loss=1.811, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.280e-04, train_time=0.852
[alab02] 2024-09-01 06:09:04,458 (trainer:720) INFO: 129epoch:train:3801-4000batch: iter_time=1.144e-04, forward_time=0.124, uma_reduction=0.265, text_vs_uma=0.371, loss_ctc=3.582, loss=1.791, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.280e-04, train_time=0.845
[alab02] 2024-09-01 06:10:30,581 (trainer:720) INFO: 129epoch:train:4001-4200batch: iter_time=1.143e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.369, loss_ctc=3.511, loss=1.756, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.280e-04, train_time=0.861
[alab02] 2024-09-01 06:11:55,454 (trainer:720) INFO: 129epoch:train:4201-4400batch: iter_time=1.174e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=3.150, loss=1.575, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.280e-04, train_time=0.849
[alab02] 2024-09-01 06:13:18,692 (trainer:720) INFO: 129epoch:train:4401-4600batch: iter_time=1.192e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.362, loss_ctc=3.311, loss=1.656, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.279e-04, train_time=0.832
[alab02] 2024-09-01 06:14:43,825 (trainer:720) INFO: 129epoch:train:4601-4800batch: iter_time=1.201e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.355, loss_ctc=3.207, loss=1.604, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.279e-04, train_time=0.851
[alab02] 2024-09-01 06:16:08,389 (trainer:720) INFO: 129epoch:train:4801-5000batch: iter_time=1.180e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=3.655, loss=1.827, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.279e-04, train_time=0.845
[alab02] 2024-09-01 06:17:32,487 (trainer:720) INFO: 129epoch:train:5001-5200batch: iter_time=1.213e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=3.434, loss=1.717, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.279e-04, train_time=0.841
[alab02] 2024-09-01 06:18:59,995 (trainer:720) INFO: 129epoch:train:5201-5400batch: iter_time=1.185e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.330, loss_ctc=3.146, loss=1.573, backward_time=0.188, optim_step_time=0.030, optim0_lr0=1.279e-04, train_time=0.875
[alab02] 2024-09-01 06:20:25,521 (trainer:720) INFO: 129epoch:train:5401-5600batch: iter_time=1.252e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.286, loss=1.643, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.279e-04, train_time=0.855
[alab02] 2024-09-01 06:21:50,733 (trainer:720) INFO: 129epoch:train:5601-5800batch: iter_time=1.276e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.409, loss=1.704, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.279e-04, train_time=0.852
[alab02] 2024-09-01 06:23:16,117 (trainer:720) INFO: 129epoch:train:5801-6000batch: iter_time=1.217e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.354, loss_ctc=3.766, loss=1.883, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.278e-04, train_time=0.854
[alab02] 2024-09-01 06:24:42,023 (trainer:720) INFO: 129epoch:train:6001-6200batch: iter_time=1.124e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.478, loss=1.739, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.278e-04, train_time=0.859
[alab02] 2024-09-01 06:26:06,738 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 06:26:08,604 (trainer:720) INFO: 129epoch:train:6201-6400batch: iter_time=1.175e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.338, loss_ctc=3.525, loss=1.763, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.278e-04, train_time=0.866
[alab02] 2024-09-01 06:27:35,249 (trainer:720) INFO: 129epoch:train:6401-6600batch: iter_time=1.236e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.890, loss=1.945, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.278e-04, train_time=0.866
[alab02] 2024-09-01 06:28:59,300 (trainer:720) INFO: 129epoch:train:6601-6800batch: iter_time=1.209e-04, forward_time=0.123, uma_reduction=0.289, text_vs_uma=0.340, loss_ctc=3.833, loss=1.917, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.278e-04, train_time=0.840
[alab02] 2024-09-01 06:30:24,780 (trainer:720) INFO: 129epoch:train:6801-7000batch: iter_time=1.209e-04, forward_time=0.126, uma_reduction=0.291, text_vs_uma=0.328, loss_ctc=3.405, loss=1.702, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.278e-04, train_time=0.855
[alab02] 2024-09-01 06:31:36,050 (trainer:338) INFO: 129epoch results: [train] iter_time=1.663e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.580, loss=1.790, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.280e-04, train_time=0.854, time=50 minutes and 42.34 seconds, total_count=919254, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.309, text_vs_uma=0.352, loss_ctc=2.908, cer_ctc=0.083, cer=0.083, loss=2.908, time=5.81 seconds, total_count=3354, gpu_max_cached_mem_GB=35.906, [att_plot] time=10.96 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 06:31:44,475 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 06:31:44,525 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/128epoch.pth
[alab02] 2024-09-01 06:31:44,525 (trainer:272) INFO: 130/150epoch started. Estimated time to finish: 18 hours, 49 minutes and 0.62 seconds
[alab02] 2024-09-01 06:33:10,780 (trainer:720) INFO: 130epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.290, text_vs_uma=0.322, loss_ctc=3.069, loss=1.535, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.277e-04, train_time=0.862
[alab02] 2024-09-01 06:34:37,847 (trainer:720) INFO: 130epoch:train:201-400batch: iter_time=1.276e-04, forward_time=0.129, uma_reduction=0.289, text_vs_uma=0.328, loss_ctc=3.375, loss=1.688, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.277e-04, train_time=0.870
[alab02] 2024-09-01 06:36:06,561 (trainer:720) INFO: 130epoch:train:401-600batch: iter_time=1.456e-04, forward_time=0.133, uma_reduction=0.288, text_vs_uma=0.337, loss_ctc=3.536, loss=1.768, backward_time=0.183, optim_step_time=0.038, optim0_lr0=1.277e-04, train_time=0.887
[alab02] 2024-09-01 06:37:31,761 (trainer:720) INFO: 130epoch:train:601-800batch: iter_time=1.220e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.736, loss=1.868, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.277e-04, train_time=0.852
[alab02] 2024-09-01 06:38:57,122 (trainer:720) INFO: 130epoch:train:801-1000batch: iter_time=1.222e-04, forward_time=0.126, uma_reduction=0.285, text_vs_uma=0.339, loss_ctc=3.421, loss=1.711, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.277e-04, train_time=0.853
[alab02] 2024-09-01 06:40:20,997 (trainer:720) INFO: 130epoch:train:1001-1200batch: iter_time=1.235e-04, forward_time=0.123, uma_reduction=0.288, text_vs_uma=0.338, loss_ctc=3.715, loss=1.857, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.277e-04, train_time=0.839
[alab02] 2024-09-01 06:41:45,694 (trainer:720) INFO: 130epoch:train:1201-1400batch: iter_time=1.285e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.351, loss_ctc=3.441, loss=1.720, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.277e-04, train_time=0.847
[alab02] 2024-09-01 06:43:09,180 (trainer:720) INFO: 130epoch:train:1401-1600batch: iter_time=1.212e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.276, loss=1.638, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.276e-04, train_time=0.835
[alab02] 2024-09-01 06:44:33,668 (trainer:720) INFO: 130epoch:train:1601-1800batch: iter_time=1.184e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.671, loss=1.835, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.276e-04, train_time=0.845
[alab02] 2024-09-01 06:45:58,845 (trainer:720) INFO: 130epoch:train:1801-2000batch: iter_time=1.193e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.557, loss=1.779, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.276e-04, train_time=0.852
[alab02] 2024-09-01 06:47:24,449 (trainer:720) INFO: 130epoch:train:2001-2200batch: iter_time=1.228e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=3.722, loss=1.861, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.276e-04, train_time=0.856
[alab02] 2024-09-01 06:48:50,668 (trainer:720) INFO: 130epoch:train:2201-2400batch: iter_time=1.239e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=3.704, loss=1.852, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.276e-04, train_time=0.862
[alab02] 2024-09-01 06:50:15,080 (trainer:720) INFO: 130epoch:train:2401-2600batch: iter_time=1.218e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.357, loss_ctc=3.275, loss=1.638, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.276e-04, train_time=0.844
[alab02] 2024-09-01 06:51:40,910 (trainer:720) INFO: 130epoch:train:2601-2800batch: iter_time=1.219e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.350, loss_ctc=3.613, loss=1.807, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.276e-04, train_time=0.858
[alab02] 2024-09-01 06:53:07,824 (trainer:720) INFO: 130epoch:train:2801-3000batch: iter_time=1.170e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=3.256, loss=1.628, backward_time=0.189, optim_step_time=0.030, optim0_lr0=1.276e-04, train_time=0.869
[alab02] 2024-09-01 06:54:32,415 (trainer:720) INFO: 130epoch:train:3001-3200batch: iter_time=1.148e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.356, loss_ctc=3.536, loss=1.768, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.275e-04, train_time=0.846
[alab02] 2024-09-01 06:55:10,852 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 06:55:59,515 (trainer:720) INFO: 130epoch:train:3201-3400batch: iter_time=1.164e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=3.413, loss=1.706, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.275e-04, train_time=0.871
[alab02] 2024-09-01 06:57:25,487 (trainer:720) INFO: 130epoch:train:3401-3600batch: iter_time=1.228e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.497, loss=1.748, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.275e-04, train_time=0.860
[alab02] 2024-09-01 06:58:50,618 (trainer:720) INFO: 130epoch:train:3601-3800batch: iter_time=1.239e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.851, loss=1.926, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.275e-04, train_time=0.851
[alab02] 2024-09-01 07:00:16,552 (trainer:720) INFO: 130epoch:train:3801-4000batch: iter_time=1.220e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.363, loss_ctc=3.725, loss=1.863, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.275e-04, train_time=0.859
[alab02] 2024-09-01 07:01:41,215 (trainer:720) INFO: 130epoch:train:4001-4200batch: iter_time=1.182e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.365, loss_ctc=3.840, loss=1.920, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.275e-04, train_time=0.847
[alab02] 2024-09-01 07:03:07,434 (trainer:720) INFO: 130epoch:train:4201-4400batch: iter_time=1.207e-04, forward_time=0.127, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=3.621, loss=1.810, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.275e-04, train_time=0.862
[alab02] 2024-09-01 07:04:34,571 (trainer:720) INFO: 130epoch:train:4401-4600batch: iter_time=1.206e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=3.691, loss=1.846, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.274e-04, train_time=0.871
[alab02] 2024-09-01 07:05:57,560 (trainer:720) INFO: 130epoch:train:4601-4800batch: iter_time=1.185e-04, forward_time=0.122, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=3.496, loss=1.748, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.274e-04, train_time=0.830
[alab02] 2024-09-01 07:07:21,925 (trainer:720) INFO: 130epoch:train:4801-5000batch: iter_time=1.217e-04, forward_time=0.124, uma_reduction=0.283, text_vs_uma=0.341, loss_ctc=3.272, loss=1.636, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.274e-04, train_time=0.843
[alab02] 2024-09-01 07:08:47,350 (trainer:720) INFO: 130epoch:train:5001-5200batch: iter_time=1.187e-04, forward_time=0.126, uma_reduction=0.286, text_vs_uma=0.334, loss_ctc=3.252, loss=1.626, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.274e-04, train_time=0.854
[alab02] 2024-09-01 07:10:14,485 (trainer:720) INFO: 130epoch:train:5201-5400batch: iter_time=1.217e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.466, loss=1.733, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.274e-04, train_time=0.871
[alab02] 2024-09-01 07:11:39,267 (trainer:720) INFO: 130epoch:train:5401-5600batch: iter_time=1.188e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.824, loss=1.912, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.274e-04, train_time=0.848
[alab02] 2024-09-01 07:13:06,304 (trainer:720) INFO: 130epoch:train:5601-5800batch: iter_time=1.209e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.563, loss=1.781, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.274e-04, train_time=0.870
[alab02] 2024-09-01 07:14:30,340 (trainer:720) INFO: 130epoch:train:5801-6000batch: iter_time=1.204e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=3.738, loss=1.869, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.273e-04, train_time=0.840
[alab02] 2024-09-01 07:15:55,129 (trainer:720) INFO: 130epoch:train:6001-6200batch: iter_time=1.137e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=3.705, loss=1.853, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.273e-04, train_time=0.848
[alab02] 2024-09-01 07:17:20,762 (trainer:720) INFO: 130epoch:train:6201-6400batch: iter_time=1.125e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.360, loss_ctc=3.942, loss=1.971, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.273e-04, train_time=0.856
[alab02] 2024-09-01 07:18:48,332 (trainer:720) INFO: 130epoch:train:6401-6600batch: iter_time=1.178e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.555, loss=1.777, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.273e-04, train_time=0.875
[alab02] 2024-09-01 07:20:15,774 (trainer:720) INFO: 130epoch:train:6601-6800batch: iter_time=1.258e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=3.684, loss=1.842, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.273e-04, train_time=0.874
[alab02] 2024-09-01 07:21:43,419 (trainer:720) INFO: 130epoch:train:6801-7000batch: iter_time=1.296e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.346, loss_ctc=3.550, loss=1.775, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.273e-04, train_time=0.876
[alab02] 2024-09-01 07:22:55,862 (trainer:338) INFO: 130epoch results: [train] iter_time=1.611e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.552, loss=1.776, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.275e-04, train_time=0.856, time=50 minutes and 52.49 seconds, total_count=926380, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.295, text_vs_uma=0.369, loss_ctc=2.935, cer_ctc=0.076, cer=0.076, loss=2.935, time=5.89 seconds, total_count=3380, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.96 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 07:23:02,507 (trainer:386) INFO: The best model has been updated: valid.cer
[alab02] 2024-09-01 07:23:02,513 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/122epoch.pth
[alab02] 2024-09-01 07:23:02,513 (trainer:272) INFO: 131/150epoch started. Estimated time to finish: 17 hours, 54 minutes and 52.15 seconds
[alab02] 2024-09-01 07:24:28,886 (trainer:720) INFO: 131epoch:train:1-200batch: iter_time=0.001, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.178, loss=1.589, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.273e-04, train_time=0.863
[alab02] 2024-09-01 07:25:38,109 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 07:25:53,212 (trainer:720) INFO: 131epoch:train:201-400batch: iter_time=1.337e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.369, loss_ctc=3.594, loss=1.797, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.272e-04, train_time=0.843
[alab02] 2024-09-01 07:27:18,446 (trainer:720) INFO: 131epoch:train:401-600batch: iter_time=1.251e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.454, loss=1.727, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.272e-04, train_time=0.852
[alab02] 2024-09-01 07:28:45,073 (trainer:720) INFO: 131epoch:train:601-800batch: iter_time=1.248e-04, forward_time=0.128, uma_reduction=0.271, text_vs_uma=0.365, loss_ctc=3.439, loss=1.720, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.272e-04, train_time=0.866
[alab02] 2024-09-01 07:30:10,939 (trainer:720) INFO: 131epoch:train:801-1000batch: iter_time=1.200e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.365, loss_ctc=3.488, loss=1.744, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.272e-04, train_time=0.858
[alab02] 2024-09-01 07:31:37,249 (trainer:720) INFO: 131epoch:train:1001-1200batch: iter_time=1.230e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.344, loss_ctc=3.317, loss=1.659, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.272e-04, train_time=0.863
[alab02] 2024-09-01 07:33:03,137 (trainer:720) INFO: 131epoch:train:1201-1400batch: iter_time=1.228e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=3.058, loss=1.529, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.272e-04, train_time=0.859
[alab02] 2024-09-01 07:34:30,213 (trainer:720) INFO: 131epoch:train:1401-1600batch: iter_time=1.232e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.252, loss=1.626, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.272e-04, train_time=0.871
[alab02] 2024-09-01 07:35:55,154 (trainer:720) INFO: 131epoch:train:1601-1800batch: iter_time=1.203e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.586, loss=1.793, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.271e-04, train_time=0.849
[alab02] 2024-09-01 07:37:19,846 (trainer:720) INFO: 131epoch:train:1801-2000batch: iter_time=1.228e-04, forward_time=0.124, uma_reduction=0.258, text_vs_uma=0.382, loss_ctc=3.387, loss=1.694, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.271e-04, train_time=0.847
[alab02] 2024-09-01 07:38:43,439 (trainer:720) INFO: 131epoch:train:2001-2200batch: iter_time=1.260e-04, forward_time=0.123, uma_reduction=0.266, text_vs_uma=0.370, loss_ctc=3.699, loss=1.850, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.271e-04, train_time=0.836
[alab02] 2024-09-01 07:40:08,375 (trainer:720) INFO: 131epoch:train:2201-2400batch: iter_time=1.282e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.353, loss_ctc=3.452, loss=1.726, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.271e-04, train_time=0.849
[alab02] 2024-09-01 07:41:34,392 (trainer:720) INFO: 131epoch:train:2401-2600batch: iter_time=1.330e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.587, loss=1.794, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.271e-04, train_time=0.860
[alab02] 2024-09-01 07:43:01,120 (trainer:720) INFO: 131epoch:train:2601-2800batch: iter_time=1.240e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=3.611, loss=1.806, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.271e-04, train_time=0.867
[alab02] 2024-09-01 07:44:26,762 (trainer:720) INFO: 131epoch:train:2801-3000batch: iter_time=1.323e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.499, loss=1.749, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.271e-04, train_time=0.856
[alab02] 2024-09-01 07:45:52,015 (trainer:720) INFO: 131epoch:train:3001-3200batch: iter_time=1.296e-04, forward_time=0.124, uma_reduction=0.262, text_vs_uma=0.373, loss_ctc=3.499, loss=1.750, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.270e-04, train_time=0.852
[alab02] 2024-09-01 07:47:19,104 (trainer:720) INFO: 131epoch:train:3201-3400batch: iter_time=1.235e-04, forward_time=0.129, uma_reduction=0.270, text_vs_uma=0.350, loss_ctc=3.163, loss=1.581, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.270e-04, train_time=0.871
[alab02] 2024-09-01 07:48:44,199 (trainer:720) INFO: 131epoch:train:3401-3600batch: iter_time=1.194e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.121, loss=1.560, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.270e-04, train_time=0.851
[alab02] 2024-09-01 07:50:10,726 (trainer:720) INFO: 131epoch:train:3601-3800batch: iter_time=1.191e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.344, loss_ctc=3.067, loss=1.533, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.270e-04, train_time=0.865
[alab02] 2024-09-01 07:51:38,164 (trainer:720) INFO: 131epoch:train:3801-4000batch: iter_time=1.193e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.266, loss=1.633, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.270e-04, train_time=0.874
[alab02] 2024-09-01 07:53:03,551 (trainer:720) INFO: 131epoch:train:4001-4200batch: iter_time=1.203e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.374, loss=1.687, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.270e-04, train_time=0.854
[alab02] 2024-09-01 07:54:25,055 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 07:54:29,316 (trainer:720) INFO: 131epoch:train:4201-4400batch: iter_time=1.238e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.361, loss_ctc=3.432, loss=1.716, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.270e-04, train_time=0.857
[alab02] 2024-09-01 07:55:53,841 (trainer:720) INFO: 131epoch:train:4401-4600batch: iter_time=1.207e-04, forward_time=0.124, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.351, loss=1.676, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.270e-04, train_time=0.845
[alab02] 2024-09-01 07:57:19,036 (trainer:720) INFO: 131epoch:train:4601-4800batch: iter_time=1.225e-04, forward_time=0.125, uma_reduction=0.257, text_vs_uma=0.369, loss_ctc=3.432, loss=1.716, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.269e-04, train_time=0.852
[alab02] 2024-09-01 07:58:44,166 (trainer:720) INFO: 131epoch:train:4801-5000batch: iter_time=1.152e-04, forward_time=0.125, uma_reduction=0.259, text_vs_uma=0.377, loss_ctc=3.427, loss=1.714, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.269e-04, train_time=0.851
[alab02] 2024-09-01 07:59:21,766 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 08:00:08,433 (trainer:720) INFO: 131epoch:train:5001-5200batch: iter_time=1.198e-04, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.356, loss_ctc=3.396, loss=1.698, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.269e-04, train_time=0.843
[alab02] 2024-09-01 08:01:34,078 (trainer:720) INFO: 131epoch:train:5201-5400batch: iter_time=1.169e-04, forward_time=0.126, uma_reduction=0.261, text_vs_uma=0.379, loss_ctc=3.722, loss=1.861, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.269e-04, train_time=0.856
[alab02] 2024-09-01 08:02:58,755 (trainer:720) INFO: 131epoch:train:5401-5600batch: iter_time=1.215e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.370, loss_ctc=3.424, loss=1.712, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.269e-04, train_time=0.847
[alab02] 2024-09-01 08:04:22,524 (trainer:720) INFO: 131epoch:train:5601-5800batch: iter_time=1.182e-04, forward_time=0.123, uma_reduction=0.263, text_vs_uma=0.370, loss_ctc=3.286, loss=1.643, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.269e-04, train_time=0.837
[alab02] 2024-09-01 08:05:48,167 (trainer:720) INFO: 131epoch:train:5801-6000batch: iter_time=1.191e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.374, loss=1.687, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.269e-04, train_time=0.856
[alab02] 2024-09-01 08:07:14,434 (trainer:720) INFO: 131epoch:train:6001-6200batch: iter_time=1.234e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.371, loss_ctc=3.775, loss=1.888, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.268e-04, train_time=0.862
[alab02] 2024-09-01 08:08:38,867 (trainer:720) INFO: 131epoch:train:6201-6400batch: iter_time=1.159e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.509, loss=1.754, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.268e-04, train_time=0.844
[alab02] 2024-09-01 08:10:04,127 (trainer:720) INFO: 131epoch:train:6401-6600batch: iter_time=1.190e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.399, loss=1.699, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.268e-04, train_time=0.852
[alab02] 2024-09-01 08:11:29,745 (trainer:720) INFO: 131epoch:train:6601-6800batch: iter_time=1.188e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.511, loss=1.755, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.268e-04, train_time=0.856
[alab02] 2024-09-01 08:12:56,034 (trainer:720) INFO: 131epoch:train:6801-7000batch: iter_time=1.274e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.359, loss_ctc=3.674, loss=1.837, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.268e-04, train_time=0.863
[alab02] 2024-09-01 08:14:06,515 (trainer:338) INFO: 131epoch results: [train] iter_time=1.605e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.419, loss=1.710, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.270e-04, train_time=0.855, time=50 minutes and 47.2 seconds, total_count=933506, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.269, text_vs_uma=0.404, loss_ctc=3.079, cer_ctc=0.082, cer=0.082, loss=3.079, time=5.97 seconds, total_count=3406, gpu_max_cached_mem_GB=35.906, [att_plot] time=10.83 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 08:14:20,010 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 08:14:20,017 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/124epoch.pth
[alab02] 2024-09-01 08:14:20,017 (trainer:272) INFO: 132/150epoch started. Estimated time to finish: 17 hours and 46.2 seconds
[alab02] 2024-09-01 08:15:46,945 (trainer:720) INFO: 132epoch:train:1-200batch: iter_time=0.001, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=3.478, loss=1.739, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.268e-04, train_time=0.869
[alab02] 2024-09-01 08:17:10,950 (trainer:720) INFO: 132epoch:train:201-400batch: iter_time=1.386e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.591, loss=1.796, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.268e-04, train_time=0.840
[alab02] 2024-09-01 08:18:36,091 (trainer:720) INFO: 132epoch:train:401-600batch: iter_time=1.362e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.329, loss=1.665, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.267e-04, train_time=0.851
[alab02] 2024-09-01 08:20:01,654 (trainer:720) INFO: 132epoch:train:601-800batch: iter_time=1.270e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.365, loss_ctc=3.531, loss=1.766, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.267e-04, train_time=0.855
[alab02] 2024-09-01 08:21:29,592 (trainer:720) INFO: 132epoch:train:801-1000batch: iter_time=1.260e-04, forward_time=0.129, uma_reduction=0.263, text_vs_uma=0.364, loss_ctc=3.370, loss=1.685, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.267e-04, train_time=0.879
[alab02] 2024-09-01 08:22:54,632 (trainer:720) INFO: 132epoch:train:1001-1200batch: iter_time=1.236e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.555, loss=1.778, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.267e-04, train_time=0.850
[alab02] 2024-09-01 08:24:21,020 (trainer:720) INFO: 132epoch:train:1201-1400batch: iter_time=1.312e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.489, loss=1.744, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.267e-04, train_time=0.864
[alab02] 2024-09-01 08:25:46,815 (trainer:720) INFO: 132epoch:train:1401-1600batch: iter_time=1.243e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.362, loss_ctc=3.377, loss=1.689, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.267e-04, train_time=0.858
[alab02] 2024-09-01 08:27:13,231 (trainer:720) INFO: 132epoch:train:1601-1800batch: iter_time=1.220e-04, forward_time=0.127, uma_reduction=0.264, text_vs_uma=0.368, loss_ctc=3.662, loss=1.831, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.267e-04, train_time=0.864
[alab02] 2024-09-01 08:28:41,618 (trainer:720) INFO: 132epoch:train:1801-2000batch: iter_time=1.476e-04, forward_time=0.131, uma_reduction=0.270, text_vs_uma=0.347, loss_ctc=3.216, loss=1.608, backward_time=0.187, optim_step_time=0.036, optim0_lr0=1.266e-04, train_time=0.884
[alab02] 2024-09-01 08:30:09,146 (trainer:720) INFO: 132epoch:train:2001-2200batch: iter_time=1.218e-04, forward_time=0.129, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.414, loss=1.707, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.266e-04, train_time=0.875
[alab02] 2024-09-01 08:31:36,043 (trainer:720) INFO: 132epoch:train:2201-2400batch: iter_time=1.213e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.443, loss=1.722, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.266e-04, train_time=0.869
[alab02] 2024-09-01 08:33:00,073 (trainer:720) INFO: 132epoch:train:2401-2600batch: iter_time=1.251e-04, forward_time=0.123, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.572, loss=1.786, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.266e-04, train_time=0.840
[alab02] 2024-09-01 08:34:25,294 (trainer:720) INFO: 132epoch:train:2601-2800batch: iter_time=1.230e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=3.425, loss=1.713, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.266e-04, train_time=0.852
[alab02] 2024-09-01 08:35:50,943 (trainer:720) INFO: 132epoch:train:2801-3000batch: iter_time=1.330e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.227, loss=1.614, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.266e-04, train_time=0.856
[alab02] 2024-09-01 08:37:18,622 (trainer:720) INFO: 132epoch:train:3001-3200batch: iter_time=1.380e-04, forward_time=0.129, uma_reduction=0.280, text_vs_uma=0.355, loss_ctc=3.816, loss=1.908, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.266e-04, train_time=0.877
[alab02] 2024-09-01 08:38:45,068 (trainer:720) INFO: 132epoch:train:3201-3400batch: iter_time=1.348e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.669, loss=1.835, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.266e-04, train_time=0.864
[alab02] 2024-09-01 08:40:11,382 (trainer:720) INFO: 132epoch:train:3401-3600batch: iter_time=1.421e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.377, loss=1.688, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.265e-04, train_time=0.863
[alab02] 2024-09-01 08:41:33,829 (trainer:720) INFO: 132epoch:train:3601-3800batch: iter_time=1.288e-04, forward_time=0.121, uma_reduction=0.272, text_vs_uma=0.366, loss_ctc=3.766, loss=1.883, backward_time=0.168, optim_step_time=0.030, optim0_lr0=1.265e-04, train_time=0.824
[alab02] 2024-09-01 08:42:57,571 (trainer:720) INFO: 132epoch:train:3801-4000batch: iter_time=1.230e-04, forward_time=0.123, uma_reduction=0.280, text_vs_uma=0.352, loss_ctc=3.477, loss=1.738, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.265e-04, train_time=0.837
[alab02] 2024-09-01 08:44:23,674 (trainer:720) INFO: 132epoch:train:4001-4200batch: iter_time=1.259e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.475, loss=1.738, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.265e-04, train_time=0.861
[alab02] 2024-09-01 08:45:49,111 (trainer:720) INFO: 132epoch:train:4201-4400batch: iter_time=1.211e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.460, loss=1.730, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.265e-04, train_time=0.854
[alab02] 2024-09-01 08:47:13,528 (trainer:720) INFO: 132epoch:train:4401-4600batch: iter_time=1.183e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.298, loss=1.649, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.265e-04, train_time=0.844
[alab02] 2024-09-01 08:48:37,512 (trainer:720) INFO: 132epoch:train:4601-4800batch: iter_time=1.202e-04, forward_time=0.123, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.478, loss=1.739, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.265e-04, train_time=0.840
[alab02] 2024-09-01 08:50:03,336 (trainer:720) INFO: 132epoch:train:4801-5000batch: iter_time=1.151e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.378, loss_ctc=3.690, loss=1.845, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.264e-04, train_time=0.858
[alab02] 2024-09-01 08:51:29,839 (trainer:720) INFO: 132epoch:train:5001-5200batch: iter_time=1.278e-04, forward_time=0.127, uma_reduction=0.265, text_vs_uma=0.358, loss_ctc=3.256, loss=1.628, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.264e-04, train_time=0.865
[alab02] 2024-09-01 08:52:57,153 (trainer:720) INFO: 132epoch:train:5201-5400batch: iter_time=1.176e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.362, loss_ctc=3.401, loss=1.700, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.264e-04, train_time=0.873
[alab02] 2024-09-01 08:54:21,599 (trainer:720) INFO: 132epoch:train:5401-5600batch: iter_time=1.174e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.354, loss_ctc=3.108, loss=1.554, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.264e-04, train_time=0.844
[alab02] 2024-09-01 08:55:47,231 (trainer:720) INFO: 132epoch:train:5601-5800batch: iter_time=1.246e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.367, loss_ctc=3.381, loss=1.691, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.264e-04, train_time=0.856
[alab02] 2024-09-01 08:57:13,529 (trainer:720) INFO: 132epoch:train:5801-6000batch: iter_time=1.179e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.362, loss_ctc=3.560, loss=1.780, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.264e-04, train_time=0.863
[alab02] 2024-09-01 08:58:37,516 (trainer:720) INFO: 132epoch:train:6001-6200batch: iter_time=1.185e-04, forward_time=0.123, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.585, loss=1.792, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.264e-04, train_time=0.840
[alab02] 2024-09-01 09:00:01,830 (trainer:720) INFO: 132epoch:train:6201-6400batch: iter_time=1.178e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.364, loss_ctc=3.372, loss=1.686, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.263e-04, train_time=0.843
[alab02] 2024-09-01 09:01:25,214 (trainer:720) INFO: 132epoch:train:6401-6600batch: iter_time=1.211e-04, forward_time=0.122, uma_reduction=0.263, text_vs_uma=0.371, loss_ctc=3.498, loss=1.749, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.263e-04, train_time=0.834
[alab02] 2024-09-01 09:02:51,090 (trainer:720) INFO: 132epoch:train:6601-6800batch: iter_time=1.242e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.638, loss=1.819, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.263e-04, train_time=0.859
[alab02] 2024-09-01 09:04:14,811 (trainer:720) INFO: 132epoch:train:6801-7000batch: iter_time=1.190e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.339, loss=1.670, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.263e-04, train_time=0.837
[alab02] 2024-09-01 09:04:55,059 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 09:05:26,172 (trainer:338) INFO: 132epoch results: [train] iter_time=1.632e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.465, loss=1.732, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.265e-04, train_time=0.855, time=50 minutes and 48.69 seconds, total_count=940632, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.260, text_vs_uma=0.417, loss_ctc=3.158, cer_ctc=0.086, cer=0.086, loss=3.158, time=5.7 seconds, total_count=3432, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.76 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 09:05:32,887 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 09:05:32,889 (trainer:272) INFO: 133/150epoch started. Estimated time to finish: 16 hours, 6 minutes and 42.18 seconds
[alab02] 2024-09-01 09:06:58,740 (trainer:720) INFO: 133epoch:train:1-200batch: iter_time=0.002, forward_time=0.125, uma_reduction=0.262, text_vs_uma=0.373, loss_ctc=3.634, loss=1.817, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.263e-04, train_time=0.858
[alab02] 2024-09-01 09:08:25,671 (trainer:720) INFO: 133epoch:train:201-400batch: iter_time=1.192e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.361, loss_ctc=3.738, loss=1.869, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.263e-04, train_time=0.869
[alab02] 2024-09-01 09:09:49,483 (trainer:720) INFO: 133epoch:train:401-600batch: iter_time=1.191e-04, forward_time=0.122, uma_reduction=0.269, text_vs_uma=0.356, loss_ctc=3.357, loss=1.679, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.263e-04, train_time=0.838
[alab02] 2024-09-01 09:11:16,067 (trainer:720) INFO: 133epoch:train:601-800batch: iter_time=1.250e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.363, loss_ctc=3.616, loss=1.808, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.262e-04, train_time=0.866
[alab02] 2024-09-01 09:12:42,829 (trainer:720) INFO: 133epoch:train:801-1000batch: iter_time=1.262e-04, forward_time=0.128, uma_reduction=0.266, text_vs_uma=0.372, loss_ctc=3.815, loss=1.908, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.262e-04, train_time=0.868
[alab02] 2024-09-01 09:14:08,950 (trainer:720) INFO: 133epoch:train:1001-1200batch: iter_time=1.481e-04, forward_time=0.126, uma_reduction=0.258, text_vs_uma=0.381, loss_ctc=3.812, loss=1.906, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.262e-04, train_time=0.861
[alab02] 2024-09-01 09:15:31,234 (trainer:720) INFO: 133epoch:train:1201-1400batch: iter_time=1.203e-04, forward_time=0.121, uma_reduction=0.262, text_vs_uma=0.368, loss_ctc=3.504, loss=1.752, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.262e-04, train_time=0.823
[alab02] 2024-09-01 09:15:53,242 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 09:16:58,473 (trainer:720) INFO: 133epoch:train:1401-1600batch: iter_time=1.276e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.366, loss_ctc=3.696, loss=1.848, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.262e-04, train_time=0.872
[alab02] 2024-09-01 09:18:25,030 (trainer:720) INFO: 133epoch:train:1601-1800batch: iter_time=1.228e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.365, loss_ctc=3.264, loss=1.632, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.262e-04, train_time=0.865
[alab02] 2024-09-01 09:19:51,020 (trainer:720) INFO: 133epoch:train:1801-2000batch: iter_time=1.289e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.353, loss_ctc=3.356, loss=1.678, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.262e-04, train_time=0.860
[alab02] 2024-09-01 09:21:15,467 (trainer:720) INFO: 133epoch:train:2001-2200batch: iter_time=1.302e-04, forward_time=0.124, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=3.556, loss=1.778, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.262e-04, train_time=0.844
[alab02] 2024-09-01 09:22:41,049 (trainer:720) INFO: 133epoch:train:2201-2400batch: iter_time=1.180e-04, forward_time=0.126, uma_reduction=0.259, text_vs_uma=0.370, loss_ctc=3.596, loss=1.798, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.261e-04, train_time=0.856
[alab02] 2024-09-01 09:24:09,822 (trainer:720) INFO: 133epoch:train:2401-2600batch: iter_time=1.289e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=3.747, loss=1.873, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.261e-04, train_time=0.888
[alab02] 2024-09-01 09:25:38,960 (trainer:720) INFO: 133epoch:train:2601-2800batch: iter_time=1.216e-04, forward_time=0.131, uma_reduction=0.266, text_vs_uma=0.362, loss_ctc=3.254, loss=1.627, backward_time=0.193, optim_step_time=0.031, optim0_lr0=1.261e-04, train_time=0.891
[alab02] 2024-09-01 09:27:03,655 (trainer:720) INFO: 133epoch:train:2801-3000batch: iter_time=1.175e-04, forward_time=0.124, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.480, loss=1.740, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.261e-04, train_time=0.847
[alab02] 2024-09-01 09:28:28,204 (trainer:720) INFO: 133epoch:train:3001-3200batch: iter_time=1.216e-04, forward_time=0.124, uma_reduction=0.265, text_vs_uma=0.362, loss_ctc=3.462, loss=1.731, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.261e-04, train_time=0.845
[alab02] 2024-09-01 09:29:53,815 (trainer:720) INFO: 133epoch:train:3201-3400batch: iter_time=1.197e-04, forward_time=0.125, uma_reduction=0.262, text_vs_uma=0.369, loss_ctc=3.750, loss=1.875, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.261e-04, train_time=0.856
[alab02] 2024-09-01 09:31:21,503 (trainer:720) INFO: 133epoch:train:3401-3600batch: iter_time=1.147e-04, forward_time=0.130, uma_reduction=0.267, text_vs_uma=0.362, loss_ctc=3.658, loss=1.829, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.261e-04, train_time=0.877
[alab02] 2024-09-01 09:32:48,433 (trainer:720) INFO: 133epoch:train:3601-3800batch: iter_time=1.305e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.546, loss=1.773, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.260e-04, train_time=0.869
[alab02] 2024-09-01 09:34:12,131 (trainer:720) INFO: 133epoch:train:3801-4000batch: iter_time=1.261e-04, forward_time=0.122, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=3.432, loss=1.716, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.260e-04, train_time=0.837
[alab02] 2024-09-01 09:35:35,443 (trainer:720) INFO: 133epoch:train:4001-4200batch: iter_time=1.203e-04, forward_time=0.122, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=3.385, loss=1.692, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.260e-04, train_time=0.833
[alab02] 2024-09-01 09:37:00,963 (trainer:720) INFO: 133epoch:train:4201-4400batch: iter_time=1.183e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.369, loss_ctc=3.691, loss=1.846, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.260e-04, train_time=0.855
[alab02] 2024-09-01 09:38:27,241 (trainer:720) INFO: 133epoch:train:4401-4600batch: iter_time=1.277e-04, forward_time=0.127, uma_reduction=0.262, text_vs_uma=0.378, loss_ctc=3.856, loss=1.928, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.260e-04, train_time=0.863
[alab02] 2024-09-01 09:39:52,062 (trainer:720) INFO: 133epoch:train:4601-4800batch: iter_time=1.252e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.357, loss_ctc=3.738, loss=1.869, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.260e-04, train_time=0.848
[alab02] 2024-09-01 09:41:17,464 (trainer:720) INFO: 133epoch:train:4801-5000batch: iter_time=1.244e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.369, loss_ctc=3.808, loss=1.904, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.260e-04, train_time=0.854
[alab02] 2024-09-01 09:42:43,326 (trainer:720) INFO: 133epoch:train:5001-5200batch: iter_time=1.184e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.371, loss_ctc=3.494, loss=1.747, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.260e-04, train_time=0.858
[alab02] 2024-09-01 09:44:10,408 (trainer:720) INFO: 133epoch:train:5201-5400batch: iter_time=1.190e-04, forward_time=0.129, uma_reduction=0.264, text_vs_uma=0.361, loss_ctc=3.341, loss=1.671, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.259e-04, train_time=0.871
[alab02] 2024-09-01 09:45:36,299 (trainer:720) INFO: 133epoch:train:5401-5600batch: iter_time=1.162e-04, forward_time=0.126, uma_reduction=0.257, text_vs_uma=0.373, loss_ctc=3.473, loss=1.736, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.259e-04, train_time=0.859
[alab02] 2024-09-01 09:47:01,673 (trainer:720) INFO: 133epoch:train:5601-5800batch: iter_time=1.189e-04, forward_time=0.125, uma_reduction=0.257, text_vs_uma=0.376, loss_ctc=3.420, loss=1.710, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.259e-04, train_time=0.854
[alab02] 2024-09-01 09:48:27,544 (trainer:720) INFO: 133epoch:train:5801-6000batch: iter_time=1.143e-04, forward_time=0.126, uma_reduction=0.261, text_vs_uma=0.367, loss_ctc=3.357, loss=1.678, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.259e-04, train_time=0.859
[alab02] 2024-09-01 09:49:52,215 (trainer:720) INFO: 133epoch:train:6001-6200batch: iter_time=1.196e-04, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.370, loss_ctc=3.430, loss=1.715, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.259e-04, train_time=0.847
[alab02] 2024-09-01 09:51:18,541 (trainer:720) INFO: 133epoch:train:6201-6400batch: iter_time=1.323e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.635, loss=1.817, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.259e-04, train_time=0.863
[alab02] 2024-09-01 09:52:43,190 (trainer:720) INFO: 133epoch:train:6401-6600batch: iter_time=1.198e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.352, loss_ctc=3.534, loss=1.767, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.259e-04, train_time=0.846
[alab02] 2024-09-01 09:54:08,526 (trainer:720) INFO: 133epoch:train:6601-6800batch: iter_time=1.274e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.332, loss=1.666, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.258e-04, train_time=0.853
[alab02] 2024-09-01 09:55:33,933 (trainer:720) INFO: 133epoch:train:6801-7000batch: iter_time=1.177e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=3.229, loss=1.614, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.258e-04, train_time=0.854
[alab02] 2024-09-01 09:56:47,197 (trainer:338) INFO: 133epoch results: [train] iter_time=1.644e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.538, loss=1.769, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.261e-04, train_time=0.857, time=50 minutes and 56.12 seconds, total_count=947758, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.286, text_vs_uma=0.380, loss_ctc=2.976, cer_ctc=0.081, cer=0.081, loss=2.976, time=5.86 seconds, total_count=3458, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.33 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 09:56:53,032 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 09:56:53,091 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/126epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/132epoch.pth
[alab02] 2024-09-01 09:56:53,091 (trainer:272) INFO: 134/150epoch started. Estimated time to finish: 15 hours, 12 minutes and 41.67 seconds
[alab02] 2024-09-01 09:58:17,751 (trainer:720) INFO: 134epoch:train:1-200batch: iter_time=0.001, forward_time=0.123, uma_reduction=0.275, text_vs_uma=0.351, loss_ctc=3.424, loss=1.712, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.258e-04, train_time=0.846
[alab02] 2024-09-01 09:59:44,188 (trainer:720) INFO: 134epoch:train:201-400batch: iter_time=1.504e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.350, loss_ctc=3.524, loss=1.762, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.258e-04, train_time=0.864
[alab02] 2024-09-01 10:01:08,864 (trainer:720) INFO: 134epoch:train:401-600batch: iter_time=1.252e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=3.332, loss=1.666, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.258e-04, train_time=0.847
[alab02] 2024-09-01 10:02:34,425 (trainer:720) INFO: 134epoch:train:601-800batch: iter_time=1.291e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.356, loss_ctc=3.508, loss=1.754, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.258e-04, train_time=0.855
[alab02] 2024-09-01 10:03:58,339 (trainer:720) INFO: 134epoch:train:801-1000batch: iter_time=1.332e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.356, loss_ctc=3.621, loss=1.811, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.258e-04, train_time=0.839
[alab02] 2024-09-01 10:05:22,673 (trainer:720) INFO: 134epoch:train:1001-1200batch: iter_time=1.203e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.525, loss=1.762, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.843
[alab02] 2024-09-01 10:06:46,387 (trainer:720) INFO: 134epoch:train:1201-1400batch: iter_time=1.200e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.365, loss_ctc=3.610, loss=1.805, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.837
[alab02] 2024-09-01 10:08:10,331 (trainer:720) INFO: 134epoch:train:1401-1600batch: iter_time=1.212e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.348, loss_ctc=3.221, loss=1.611, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.839
[alab02] 2024-09-01 10:09:37,151 (trainer:720) INFO: 134epoch:train:1601-1800batch: iter_time=1.179e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=3.288, loss=1.644, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.868
[alab02] 2024-09-01 10:11:01,297 (trainer:720) INFO: 134epoch:train:1801-2000batch: iter_time=1.197e-04, forward_time=0.125, uma_reduction=0.288, text_vs_uma=0.334, loss_ctc=3.026, loss=1.513, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.841
[alab02] 2024-09-01 10:12:27,789 (trainer:720) INFO: 134epoch:train:2001-2200batch: iter_time=1.217e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.413, loss=1.707, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.865
[alab02] 2024-09-01 10:13:52,350 (trainer:720) INFO: 134epoch:train:2201-2400batch: iter_time=1.237e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.261, loss=1.631, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.257e-04, train_time=0.845
[alab02] 2024-09-01 10:15:17,108 (trainer:720) INFO: 134epoch:train:2401-2600batch: iter_time=1.284e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.344, loss=1.672, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.257e-04, train_time=0.847
[alab02] 2024-09-01 10:16:40,481 (trainer:720) INFO: 134epoch:train:2601-2800batch: iter_time=1.209e-04, forward_time=0.123, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.186, loss=1.593, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.834
[alab02] 2024-09-01 10:18:05,546 (trainer:720) INFO: 134epoch:train:2801-3000batch: iter_time=1.197e-04, forward_time=0.126, uma_reduction=0.266, text_vs_uma=0.359, loss_ctc=3.096, loss=1.548, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.850
[alab02] 2024-09-01 10:19:02,660 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 10:19:29,178 (trainer:720) INFO: 134epoch:train:3001-3200batch: iter_time=1.175e-04, forward_time=0.123, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.640, loss=1.820, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.836
[alab02] 2024-09-01 10:20:54,329 (trainer:720) INFO: 134epoch:train:3201-3400batch: iter_time=1.216e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.324, loss=1.662, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.851
[alab02] 2024-09-01 10:22:18,257 (trainer:720) INFO: 134epoch:train:3401-3600batch: iter_time=1.273e-04, forward_time=0.124, uma_reduction=0.264, text_vs_uma=0.370, loss_ctc=3.708, loss=1.854, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.839
[alab02] 2024-09-01 10:23:45,002 (trainer:720) INFO: 134epoch:train:3601-3800batch: iter_time=1.178e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.506, loss=1.753, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.256e-04, train_time=0.867
[alab02] 2024-09-01 10:25:09,427 (trainer:720) INFO: 134epoch:train:3801-4000batch: iter_time=1.327e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.509, loss=1.754, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.844
[alab02] 2024-09-01 10:26:36,306 (trainer:720) INFO: 134epoch:train:4001-4200batch: iter_time=1.269e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.604, loss=1.802, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.255e-04, train_time=0.869
[alab02] 2024-09-01 10:28:02,823 (trainer:720) INFO: 134epoch:train:4201-4400batch: iter_time=1.184e-04, forward_time=0.128, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.557, loss=1.778, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.865
[alab02] 2024-09-01 10:29:27,984 (trainer:720) INFO: 134epoch:train:4401-4600batch: iter_time=1.244e-04, forward_time=0.125, uma_reduction=0.287, text_vs_uma=0.343, loss_ctc=3.742, loss=1.871, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.851
[alab02] 2024-09-01 10:30:52,026 (trainer:720) INFO: 134epoch:train:4601-4800batch: iter_time=1.245e-04, forward_time=0.124, uma_reduction=0.289, text_vs_uma=0.336, loss_ctc=3.289, loss=1.645, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.840
[alab02] 2024-09-01 10:32:17,252 (trainer:720) INFO: 134epoch:train:4801-5000batch: iter_time=1.150e-04, forward_time=0.125, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=3.671, loss=1.836, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.852
[alab02] 2024-09-01 10:33:42,463 (trainer:720) INFO: 134epoch:train:5001-5200batch: iter_time=1.151e-04, forward_time=0.125, uma_reduction=0.286, text_vs_uma=0.340, loss_ctc=3.582, loss=1.791, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.852
[alab02] 2024-09-01 10:35:08,373 (trainer:720) INFO: 134epoch:train:5201-5400batch: iter_time=1.261e-04, forward_time=0.126, uma_reduction=0.280, text_vs_uma=0.334, loss_ctc=3.342, loss=1.671, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.859
[alab02] 2024-09-01 10:36:34,247 (trainer:720) INFO: 134epoch:train:5401-5600batch: iter_time=1.215e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=3.553, loss=1.776, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.255e-04, train_time=0.859
[alab02] 2024-09-01 10:38:01,363 (trainer:720) INFO: 134epoch:train:5601-5800batch: iter_time=1.146e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.349, loss_ctc=3.566, loss=1.783, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.254e-04, train_time=0.871
[alab02] 2024-09-01 10:39:25,404 (trainer:720) INFO: 134epoch:train:5801-6000batch: iter_time=1.196e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.617, loss=1.808, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.254e-04, train_time=0.840
[alab02] 2024-09-01 10:40:48,022 (trainer:720) INFO: 134epoch:train:6001-6200batch: iter_time=1.207e-04, forward_time=0.121, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.498, loss=1.749, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.254e-04, train_time=0.826
[alab02] 2024-09-01 10:42:13,897 (trainer:720) INFO: 134epoch:train:6201-6400batch: iter_time=1.129e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.687, loss=1.844, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.254e-04, train_time=0.859
[alab02] 2024-09-01 10:43:40,233 (trainer:720) INFO: 134epoch:train:6401-6600batch: iter_time=1.176e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.370, loss_ctc=3.950, loss=1.975, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.254e-04, train_time=0.863
[alab02] 2024-09-01 10:45:07,337 (trainer:720) INFO: 134epoch:train:6601-6800batch: iter_time=1.196e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.639, loss=1.819, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.254e-04, train_time=0.871
[alab02] 2024-09-01 10:46:30,047 (trainer:720) INFO: 134epoch:train:6801-7000batch: iter_time=1.165e-04, forward_time=0.121, uma_reduction=0.266, text_vs_uma=0.366, loss_ctc=3.517, loss=1.758, backward_time=0.171, optim_step_time=0.031, optim0_lr0=1.254e-04, train_time=0.827
[alab02] 2024-09-01 10:47:41,313 (trainer:338) INFO: 134epoch results: [train] iter_time=1.586e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.477, loss=1.738, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.256e-04, train_time=0.850, time=50 minutes and 29.87 seconds, total_count=954884, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.271, text_vs_uma=0.400, loss_ctc=3.042, cer_ctc=0.083, cer=0.083, loss=3.042, time=5.83 seconds, total_count=3484, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.52 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 10:47:47,159 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 10:47:47,160 (trainer:272) INFO: 135/150epoch started. Estimated time to finish: 14 hours, 18 minutes and 40.43 seconds
[alab02] 2024-09-01 10:49:12,912 (trainer:720) INFO: 135epoch:train:1-200batch: iter_time=0.001, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.369, loss_ctc=3.530, loss=1.765, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.253e-04, train_time=0.857
[alab02] 2024-09-01 10:50:42,238 (trainer:720) INFO: 135epoch:train:201-400batch: iter_time=1.264e-04, forward_time=0.131, uma_reduction=0.258, text_vs_uma=0.373, loss_ctc=3.525, loss=1.762, backward_time=0.191, optim_step_time=0.031, optim0_lr0=1.253e-04, train_time=0.893
[alab02] 2024-09-01 10:52:10,339 (trainer:720) INFO: 135epoch:train:401-600batch: iter_time=1.243e-04, forward_time=0.130, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.455, loss=1.728, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.253e-04, train_time=0.881
[alab02] 2024-09-01 10:53:32,011 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 10:53:34,994 (trainer:720) INFO: 135epoch:train:601-800batch: iter_time=1.360e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.369, loss_ctc=3.432, loss=1.716, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.253e-04, train_time=0.846
[alab02] 2024-09-01 10:54:16,507 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 10:54:58,610 (trainer:720) INFO: 135epoch:train:801-1000batch: iter_time=1.258e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.499, loss=1.749, backward_time=0.172, optim_step_time=0.030, optim0_lr0=1.253e-04, train_time=0.836
[alab02] 2024-09-01 10:56:23,587 (trainer:720) INFO: 135epoch:train:1001-1200batch: iter_time=1.322e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.354, loss_ctc=3.702, loss=1.851, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.253e-04, train_time=0.850
[alab02] 2024-09-01 10:57:47,069 (trainer:720) INFO: 135epoch:train:1201-1400batch: iter_time=1.175e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.595, loss=1.797, backward_time=0.173, optim_step_time=0.031, optim0_lr0=1.253e-04, train_time=0.835
[alab02] 2024-09-01 10:59:13,801 (trainer:720) INFO: 135epoch:train:1401-1600batch: iter_time=1.206e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.505, loss=1.753, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.253e-04, train_time=0.867
[alab02] 2024-09-01 11:00:40,300 (trainer:720) INFO: 135epoch:train:1601-1800batch: iter_time=1.197e-04, forward_time=0.127, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.706, loss=1.853, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.252e-04, train_time=0.865
[alab02] 2024-09-01 11:02:07,317 (trainer:720) INFO: 135epoch:train:1801-2000batch: iter_time=1.211e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.316, loss=1.658, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.252e-04, train_time=0.870
[alab02] 2024-09-01 11:03:33,867 (trainer:720) INFO: 135epoch:train:2001-2200batch: iter_time=1.210e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.342, loss_ctc=3.306, loss=1.653, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.252e-04, train_time=0.865
[alab02] 2024-09-01 11:04:57,877 (trainer:720) INFO: 135epoch:train:2201-2400batch: iter_time=1.152e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.275, loss=1.637, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.252e-04, train_time=0.840
[alab02] 2024-09-01 11:06:23,451 (trainer:720) INFO: 135epoch:train:2401-2600batch: iter_time=1.191e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.256, loss=1.628, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.252e-04, train_time=0.856
[alab02] 2024-09-01 11:07:50,538 (trainer:720) INFO: 135epoch:train:2601-2800batch: iter_time=1.500e-04, forward_time=0.128, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.418, loss=1.709, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.252e-04, train_time=0.871
[alab02] 2024-09-01 11:09:15,206 (trainer:720) INFO: 135epoch:train:2801-3000batch: iter_time=1.406e-04, forward_time=0.124, uma_reduction=0.283, text_vs_uma=0.338, loss_ctc=3.415, loss=1.708, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.252e-04, train_time=0.846
[alab02] 2024-09-01 11:10:41,476 (trainer:720) INFO: 135epoch:train:3001-3200batch: iter_time=1.282e-04, forward_time=0.127, uma_reduction=0.291, text_vs_uma=0.324, loss_ctc=3.231, loss=1.615, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.862
[alab02] 2024-09-01 11:12:07,171 (trainer:720) INFO: 135epoch:train:3201-3400batch: iter_time=1.317e-04, forward_time=0.126, uma_reduction=0.291, text_vs_uma=0.333, loss_ctc=3.469, loss=1.735, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.857
[alab02] 2024-09-01 11:13:32,503 (trainer:720) INFO: 135epoch:train:3401-3600batch: iter_time=1.477e-04, forward_time=0.125, uma_reduction=0.283, text_vs_uma=0.349, loss_ctc=3.431, loss=1.716, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.853
[alab02] 2024-09-01 11:14:57,730 (trainer:720) INFO: 135epoch:train:3601-3800batch: iter_time=1.592e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.366, loss_ctc=3.394, loss=1.697, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.852
[alab02] 2024-09-01 11:16:23,947 (trainer:720) INFO: 135epoch:train:3801-4000batch: iter_time=1.251e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.788, loss=1.894, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.862
[alab02] 2024-09-01 11:17:49,132 (trainer:720) INFO: 135epoch:train:4001-4200batch: iter_time=1.212e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.349, loss_ctc=3.401, loss=1.700, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.852
[alab02] 2024-09-01 11:19:14,943 (trainer:720) INFO: 135epoch:train:4201-4400batch: iter_time=1.253e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=3.320, loss=1.660, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.858
[alab02] 2024-09-01 11:20:40,271 (trainer:720) INFO: 135epoch:train:4401-4600batch: iter_time=1.273e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.499, loss=1.750, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.853
[alab02] 2024-09-01 11:22:07,784 (trainer:720) INFO: 135epoch:train:4601-4800batch: iter_time=1.178e-04, forward_time=0.128, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.679, loss=1.840, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.250e-04, train_time=0.875
[alab02] 2024-09-01 11:23:32,729 (trainer:720) INFO: 135epoch:train:4801-5000batch: iter_time=1.349e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.358, loss_ctc=3.657, loss=1.829, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.250e-04, train_time=0.849
[alab02] 2024-09-01 11:24:57,489 (trainer:720) INFO: 135epoch:train:5001-5200batch: iter_time=1.337e-04, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=3.393, loss=1.696, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.250e-04, train_time=0.847
[alab02] 2024-09-01 11:26:22,563 (trainer:720) INFO: 135epoch:train:5201-5400batch: iter_time=1.353e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.360, loss_ctc=3.392, loss=1.696, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.250e-04, train_time=0.851
[alab02] 2024-09-01 11:27:49,360 (trainer:720) INFO: 135epoch:train:5401-5600batch: iter_time=1.250e-04, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.363, loss_ctc=3.281, loss=1.641, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.250e-04, train_time=0.868
[alab02] 2024-09-01 11:29:15,124 (trainer:720) INFO: 135epoch:train:5601-5800batch: iter_time=1.358e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.404, loss=1.702, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.250e-04, train_time=0.857
[alab02] 2024-09-01 11:30:41,032 (trainer:720) INFO: 135epoch:train:5801-6000batch: iter_time=1.298e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.494, loss=1.747, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.250e-04, train_time=0.859
[alab02] 2024-09-01 11:32:06,350 (trainer:720) INFO: 135epoch:train:6001-6200batch: iter_time=1.304e-04, forward_time=0.125, uma_reduction=0.265, text_vs_uma=0.369, loss_ctc=3.677, loss=1.839, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.853
[alab02] 2024-09-01 11:33:31,529 (trainer:720) INFO: 135epoch:train:6201-6400batch: iter_time=1.302e-04, forward_time=0.124, uma_reduction=0.256, text_vs_uma=0.382, loss_ctc=4.014, loss=2.007, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.852
[alab02] 2024-09-01 11:34:56,870 (trainer:720) INFO: 135epoch:train:6401-6600batch: iter_time=1.321e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=3.420, loss=1.710, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.853
[alab02] 2024-09-01 11:36:21,336 (trainer:720) INFO: 135epoch:train:6601-6800batch: iter_time=1.351e-04, forward_time=0.124, uma_reduction=0.262, text_vs_uma=0.370, loss_ctc=3.678, loss=1.839, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.844
[alab02] 2024-09-01 11:37:44,595 (trainer:720) INFO: 135epoch:train:6801-7000batch: iter_time=1.263e-04, forward_time=0.122, uma_reduction=0.266, text_vs_uma=0.369, loss_ctc=3.313, loss=1.657, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.832
[alab02] 2024-09-01 11:38:55,555 (trainer:338) INFO: 135epoch results: [train] iter_time=1.659e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.476, loss=1.738, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.251e-04, train_time=0.856, time=50 minutes and 50.85 seconds, total_count=962010, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.268, text_vs_uma=0.406, loss_ctc=3.020, cer_ctc=0.080, cer=0.080, loss=3.020, time=5.79 seconds, total_count=3510, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.75 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 11:39:02,847 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 11:39:02,858 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/129epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/134epoch.pth
[alab02] 2024-09-01 11:39:02,858 (trainer:272) INFO: 136/150epoch started. Estimated time to finish: 13 hours, 24 minutes and 44.37 seconds
[alab02] 2024-09-01 11:40:29,481 (trainer:720) INFO: 136epoch:train:1-200batch: iter_time=0.002, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.353, loss_ctc=3.264, loss=1.632, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.866
[alab02] 2024-09-01 11:41:53,838 (trainer:720) INFO: 136epoch:train:201-400batch: iter_time=1.363e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=3.305, loss=1.653, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.843
[alab02] 2024-09-01 11:43:20,848 (trainer:720) INFO: 136epoch:train:401-600batch: iter_time=1.425e-04, forward_time=0.128, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.118, loss=1.559, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.249e-04, train_time=0.870
[alab02] 2024-09-01 11:44:45,170 (trainer:720) INFO: 136epoch:train:601-800batch: iter_time=1.800e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.361, loss_ctc=3.264, loss=1.632, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.843
[alab02] 2024-09-01 11:46:11,180 (trainer:720) INFO: 136epoch:train:801-1000batch: iter_time=1.174e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.342, loss_ctc=3.150, loss=1.575, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.860
[alab02] 2024-09-01 11:47:36,303 (trainer:720) INFO: 136epoch:train:1001-1200batch: iter_time=1.295e-04, forward_time=0.124, uma_reduction=0.268, text_vs_uma=0.369, loss_ctc=3.889, loss=1.945, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.851
[alab02] 2024-09-01 11:49:01,373 (trainer:720) INFO: 136epoch:train:1201-1400batch: iter_time=1.367e-04, forward_time=0.124, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=3.626, loss=1.813, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.851
[alab02] 2024-09-01 11:50:26,422 (trainer:720) INFO: 136epoch:train:1401-1600batch: iter_time=1.187e-04, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.370, loss_ctc=3.502, loss=1.751, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.850
[alab02] 2024-09-01 11:51:51,892 (trainer:720) INFO: 136epoch:train:1601-1800batch: iter_time=1.238e-04, forward_time=0.124, uma_reduction=0.262, text_vs_uma=0.369, loss_ctc=3.500, loss=1.750, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.854
[alab02] 2024-09-01 11:53:18,025 (trainer:720) INFO: 136epoch:train:1801-2000batch: iter_time=1.322e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.376, loss_ctc=3.515, loss=1.757, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.248e-04, train_time=0.861
[alab02] 2024-09-01 11:54:42,591 (trainer:720) INFO: 136epoch:train:2001-2200batch: iter_time=1.254e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.337, loss=1.669, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.845
[alab02] 2024-09-01 11:55:53,359 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 11:56:07,520 (trainer:720) INFO: 136epoch:train:2201-2400batch: iter_time=1.246e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.343, loss_ctc=3.139, loss=1.569, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.849
[alab02] 2024-09-01 11:57:32,324 (trainer:720) INFO: 136epoch:train:2401-2600batch: iter_time=1.251e-04, forward_time=0.124, uma_reduction=0.284, text_vs_uma=0.336, loss_ctc=3.262, loss=1.631, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.848
[alab02] 2024-09-01 11:58:55,965 (trainer:720) INFO: 136epoch:train:2601-2800batch: iter_time=1.247e-04, forward_time=0.122, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.467, loss=1.734, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.836
[alab02] 2024-09-01 12:00:21,758 (trainer:720) INFO: 136epoch:train:2801-3000batch: iter_time=1.223e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.382, loss=1.691, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.247e-04, train_time=0.858
[alab02] 2024-09-01 12:01:48,775 (trainer:720) INFO: 136epoch:train:3001-3200batch: iter_time=1.385e-04, forward_time=0.129, uma_reduction=0.277, text_vs_uma=0.339, loss_ctc=3.241, loss=1.621, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.870
[alab02] 2024-09-01 12:03:14,398 (trainer:720) INFO: 136epoch:train:3201-3400batch: iter_time=1.216e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.351, loss_ctc=3.213, loss=1.607, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.856
[alab02] 2024-09-01 12:04:38,659 (trainer:720) INFO: 136epoch:train:3401-3600batch: iter_time=1.232e-04, forward_time=0.123, uma_reduction=0.267, text_vs_uma=0.367, loss_ctc=3.499, loss=1.749, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.247e-04, train_time=0.842
[alab02] 2024-09-01 12:06:02,587 (trainer:720) INFO: 136epoch:train:3601-3800batch: iter_time=1.191e-04, forward_time=0.123, uma_reduction=0.268, text_vs_uma=0.362, loss_ctc=3.265, loss=1.632, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.246e-04, train_time=0.839
[alab02] 2024-09-01 12:07:26,405 (trainer:720) INFO: 136epoch:train:3801-4000batch: iter_time=1.307e-04, forward_time=0.122, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.211, loss=1.605, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.246e-04, train_time=0.838
[alab02] 2024-09-01 12:08:50,902 (trainer:720) INFO: 136epoch:train:4001-4200batch: iter_time=1.326e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.206, loss=1.603, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.246e-04, train_time=0.845
[alab02] 2024-09-01 12:10:16,648 (trainer:720) INFO: 136epoch:train:4201-4400batch: iter_time=1.274e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.355, loss_ctc=3.381, loss=1.691, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.246e-04, train_time=0.857
[alab02] 2024-09-01 12:11:42,570 (trainer:720) INFO: 136epoch:train:4401-4600batch: iter_time=1.247e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.213, loss=1.606, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.246e-04, train_time=0.859
[alab02] 2024-09-01 12:13:09,274 (trainer:720) INFO: 136epoch:train:4601-4800batch: iter_time=1.386e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.462, loss=1.731, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.246e-04, train_time=0.867
[alab02] 2024-09-01 12:14:37,145 (trainer:720) INFO: 136epoch:train:4801-5000batch: iter_time=1.407e-04, forward_time=0.129, uma_reduction=0.272, text_vs_uma=0.356, loss_ctc=3.224, loss=1.612, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.246e-04, train_time=0.879
[alab02] 2024-09-01 12:16:03,433 (trainer:720) INFO: 136epoch:train:5001-5200batch: iter_time=1.300e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.212, loss=1.606, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.246e-04, train_time=0.863
[alab02] 2024-09-01 12:17:27,646 (trainer:720) INFO: 136epoch:train:5201-5400batch: iter_time=1.411e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.357, loss_ctc=3.357, loss=1.678, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.245e-04, train_time=0.842
[alab02] 2024-09-01 12:18:52,927 (trainer:720) INFO: 136epoch:train:5401-5600batch: iter_time=1.296e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.047, loss=1.524, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.245e-04, train_time=0.853
[alab02] 2024-09-01 12:20:17,705 (trainer:720) INFO: 136epoch:train:5601-5800batch: iter_time=1.315e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=3.200, loss=1.600, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.245e-04, train_time=0.848
[alab02] 2024-09-01 12:21:43,307 (trainer:720) INFO: 136epoch:train:5801-6000batch: iter_time=1.291e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.579, loss=1.790, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.245e-04, train_time=0.856
[alab02] 2024-09-01 12:23:07,186 (trainer:720) INFO: 136epoch:train:6001-6200batch: iter_time=1.255e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.363, loss_ctc=3.395, loss=1.698, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.245e-04, train_time=0.839
[alab02] 2024-09-01 12:24:32,121 (trainer:720) INFO: 136epoch:train:6201-6400batch: iter_time=1.276e-04, forward_time=0.124, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.671, loss=1.835, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.245e-04, train_time=0.849
[alab02] 2024-09-01 12:25:56,231 (trainer:720) INFO: 136epoch:train:6401-6600batch: iter_time=1.218e-04, forward_time=0.123, uma_reduction=0.259, text_vs_uma=0.377, loss_ctc=3.546, loss=1.773, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.245e-04, train_time=0.841
[alab02] 2024-09-01 12:26:21,838 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 12:27:21,956 (trainer:720) INFO: 136epoch:train:6601-6800batch: iter_time=1.284e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.374, loss_ctc=3.687, loss=1.844, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.245e-04, train_time=0.857
[alab02] 2024-09-01 12:28:46,259 (trainer:720) INFO: 136epoch:train:6801-7000batch: iter_time=1.358e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.557, loss=1.779, backward_time=0.174, optim_step_time=0.031, optim0_lr0=1.244e-04, train_time=0.843
[alab02] 2024-09-01 12:29:58,289 (trainer:338) INFO: 136epoch results: [train] iter_time=1.735e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.362, loss=1.681, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.247e-04, train_time=0.852, time=50 minutes and 38.12 seconds, total_count=969136, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.286, text_vs_uma=0.380, loss_ctc=2.934, cer_ctc=0.081, cer=0.081, loss=2.934, time=5.71 seconds, total_count=3536, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.59 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 12:30:06,392 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 12:30:06,398 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/131epoch.pth
[alab02] 2024-09-01 12:30:06,398 (trainer:272) INFO: 137/150epoch started. Estimated time to finish: 12 hours, 30 minutes and 49.41 seconds
[alab02] 2024-09-01 12:31:31,627 (trainer:720) INFO: 137epoch:train:1-200batch: iter_time=0.002, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.341, loss_ctc=3.457, loss=1.729, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.244e-04, train_time=0.852
[alab02] 2024-09-01 12:32:56,136 (trainer:720) INFO: 137epoch:train:201-400batch: iter_time=1.348e-04, forward_time=0.124, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=3.743, loss=1.872, backward_time=0.172, optim_step_time=0.031, optim0_lr0=1.244e-04, train_time=0.845
[alab02] 2024-09-01 12:33:33,465 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 12:34:21,072 (trainer:720) INFO: 137epoch:train:401-600batch: iter_time=1.352e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.355, loss=1.678, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.244e-04, train_time=0.849
[alab02] 2024-09-01 12:35:45,666 (trainer:720) INFO: 137epoch:train:601-800batch: iter_time=1.892e-04, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.345, loss_ctc=3.393, loss=1.697, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.244e-04, train_time=0.846
[alab02] 2024-09-01 12:37:10,548 (trainer:720) INFO: 137epoch:train:801-1000batch: iter_time=1.265e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.483, loss=1.741, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.244e-04, train_time=0.849
[alab02] 2024-09-01 12:38:36,250 (trainer:720) INFO: 137epoch:train:1001-1200batch: iter_time=1.390e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.369, loss_ctc=3.627, loss=1.813, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.244e-04, train_time=0.857
[alab02] 2024-09-01 12:40:04,080 (trainer:720) INFO: 137epoch:train:1201-1400batch: iter_time=1.252e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.422, loss=1.711, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.243e-04, train_time=0.878
[alab02] 2024-09-01 12:41:31,498 (trainer:720) INFO: 137epoch:train:1401-1600batch: iter_time=1.368e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.324, loss=1.662, backward_time=0.185, optim_step_time=0.031, optim0_lr0=1.243e-04, train_time=0.874
[alab02] 2024-09-01 12:42:57,046 (trainer:720) INFO: 137epoch:train:1601-1800batch: iter_time=1.383e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.419, loss=1.709, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.243e-04, train_time=0.855
[alab02] 2024-09-01 12:44:21,464 (trainer:720) INFO: 137epoch:train:1801-2000batch: iter_time=1.251e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.408, loss=1.704, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.243e-04, train_time=0.844
[alab02] 2024-09-01 12:45:46,035 (trainer:720) INFO: 137epoch:train:2001-2200batch: iter_time=1.278e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.529, loss=1.764, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.243e-04, train_time=0.846
[alab02] 2024-09-01 12:47:11,210 (trainer:720) INFO: 137epoch:train:2201-2400batch: iter_time=1.361e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.461, loss=1.730, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.243e-04, train_time=0.852
[alab02] 2024-09-01 12:48:35,890 (trainer:720) INFO: 137epoch:train:2401-2600batch: iter_time=1.392e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.350, loss_ctc=3.217, loss=1.608, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.243e-04, train_time=0.847
[alab02] 2024-09-01 12:50:01,756 (trainer:720) INFO: 137epoch:train:2601-2800batch: iter_time=1.294e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.290, loss=1.645, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.243e-04, train_time=0.859
[alab02] 2024-09-01 12:51:26,569 (trainer:720) INFO: 137epoch:train:2801-3000batch: iter_time=1.374e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.365, loss_ctc=3.523, loss=1.761, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.848
[alab02] 2024-09-01 12:52:52,086 (trainer:720) INFO: 137epoch:train:3001-3200batch: iter_time=1.343e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.349, loss=1.674, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.242e-04, train_time=0.855
[alab02] 2024-09-01 12:54:17,814 (trainer:720) INFO: 137epoch:train:3201-3400batch: iter_time=1.405e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.515, loss=1.757, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.857
[alab02] 2024-09-01 12:55:42,852 (trainer:720) INFO: 137epoch:train:3401-3600batch: iter_time=1.240e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.360, loss_ctc=3.216, loss=1.608, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.850
[alab02] 2024-09-01 12:57:07,640 (trainer:720) INFO: 137epoch:train:3601-3800batch: iter_time=1.385e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.361, loss_ctc=3.705, loss=1.853, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.848
[alab02] 2024-09-01 12:58:32,388 (trainer:720) INFO: 137epoch:train:3801-4000batch: iter_time=1.328e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.465, loss=1.732, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.847
[alab02] 2024-09-01 12:59:57,020 (trainer:720) INFO: 137epoch:train:4001-4200batch: iter_time=1.285e-04, forward_time=0.125, uma_reduction=0.285, text_vs_uma=0.341, loss_ctc=3.139, loss=1.569, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.846
[alab02] 2024-09-01 13:01:23,320 (trainer:720) INFO: 137epoch:train:4201-4400batch: iter_time=1.426e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=3.356, loss=1.678, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.863
[alab02] 2024-09-01 13:02:49,273 (trainer:720) INFO: 137epoch:train:4401-4600batch: iter_time=1.284e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.402, loss=1.701, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.859
[alab02] 2024-09-01 13:04:13,554 (trainer:720) INFO: 137epoch:train:4601-4800batch: iter_time=1.265e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=3.497, loss=1.748, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.843
[alab02] 2024-09-01 13:05:39,583 (trainer:720) INFO: 137epoch:train:4801-5000batch: iter_time=1.177e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.154, loss=1.577, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.860
[alab02] 2024-09-01 13:07:04,624 (trainer:720) INFO: 137epoch:train:5001-5200batch: iter_time=1.224e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.356, loss_ctc=3.567, loss=1.783, backward_time=0.176, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.850
[alab02] 2024-09-01 13:08:30,055 (trainer:720) INFO: 137epoch:train:5201-5400batch: iter_time=1.344e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.404, loss=1.702, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.241e-04, train_time=0.854
[alab02] 2024-09-01 13:09:55,977 (trainer:720) INFO: 137epoch:train:5401-5600batch: iter_time=1.273e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.355, loss_ctc=3.065, loss=1.533, backward_time=0.185, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.859
[alab02] 2024-09-01 13:11:21,486 (trainer:720) INFO: 137epoch:train:5601-5800batch: iter_time=1.267e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.358, loss_ctc=3.499, loss=1.750, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.241e-04, train_time=0.855
[alab02] 2024-09-01 13:12:46,580 (trainer:720) INFO: 137epoch:train:5801-6000batch: iter_time=1.273e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.314, loss=1.657, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.240e-04, train_time=0.851
[alab02] 2024-09-01 13:14:11,534 (trainer:720) INFO: 137epoch:train:6001-6200batch: iter_time=1.280e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.546, loss=1.773, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.240e-04, train_time=0.849
[alab02] 2024-09-01 13:15:37,638 (trainer:720) INFO: 137epoch:train:6201-6400batch: iter_time=1.347e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.346, loss_ctc=3.283, loss=1.641, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.240e-04, train_time=0.861
[alab02] 2024-09-01 13:17:06,096 (trainer:720) INFO: 137epoch:train:6401-6600batch: iter_time=1.312e-04, forward_time=0.131, uma_reduction=0.269, text_vs_uma=0.368, loss_ctc=3.483, loss=1.741, backward_time=0.188, optim_step_time=0.031, optim0_lr0=1.240e-04, train_time=0.884
[alab02] 2024-09-01 13:18:32,207 (trainer:720) INFO: 137epoch:train:6601-6800batch: iter_time=1.343e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.416, loss=1.708, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.240e-04, train_time=0.861
[alab02] 2024-09-01 13:19:56,937 (trainer:720) INFO: 137epoch:train:6801-7000batch: iter_time=1.320e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.422, loss=1.711, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.240e-04, train_time=0.847
[alab02] 2024-09-01 13:21:08,430 (trainer:338) INFO: 137epoch results: [train] iter_time=1.739e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.413, loss=1.706, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.242e-04, train_time=0.854, time=50 minutes and 44.18 seconds, total_count=976262, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.270, text_vs_uma=0.402, loss_ctc=2.958, cer_ctc=0.084, cer=0.084, loss=2.958, time=5.81 seconds, total_count=3562, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.04 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 13:21:15,532 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 13:21:15,533 (trainer:272) INFO: 138/150epoch started. Estimated time to finish: 11 hours, 36 minutes and 57.49 seconds
[alab02] 2024-09-01 13:22:40,457 (trainer:720) INFO: 138epoch:train:1-200batch: iter_time=0.001, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.347, loss_ctc=3.217, loss=1.609, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.240e-04, train_time=0.849
[alab02] 2024-09-01 13:24:05,630 (trainer:720) INFO: 138epoch:train:201-400batch: iter_time=1.371e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.352, loss_ctc=3.458, loss=1.729, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.239e-04, train_time=0.852
[alab02] 2024-09-01 13:25:31,505 (trainer:720) INFO: 138epoch:train:401-600batch: iter_time=1.643e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.350, loss_ctc=3.099, loss=1.550, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.239e-04, train_time=0.859
[alab02] 2024-09-01 13:26:58,709 (trainer:720) INFO: 138epoch:train:601-800batch: iter_time=1.370e-04, forward_time=0.128, uma_reduction=0.273, text_vs_uma=0.359, loss_ctc=3.435, loss=1.718, backward_time=0.184, optim_step_time=0.031, optim0_lr0=1.239e-04, train_time=0.872
[alab02] 2024-09-01 13:28:25,063 (trainer:720) INFO: 138epoch:train:801-1000batch: iter_time=1.328e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.347, loss_ctc=3.357, loss=1.679, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.239e-04, train_time=0.863
[alab02] 2024-09-01 13:29:49,222 (trainer:720) INFO: 138epoch:train:1001-1200batch: iter_time=1.283e-04, forward_time=0.123, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.508, loss=1.754, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.239e-04, train_time=0.841
[alab02] 2024-09-01 13:31:16,165 (trainer:720) INFO: 138epoch:train:1201-1400batch: iter_time=1.473e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.346, loss=1.673, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.239e-04, train_time=0.869
[alab02] 2024-09-01 13:32:42,995 (trainer:720) INFO: 138epoch:train:1401-1600batch: iter_time=1.334e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.450, loss=1.725, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.239e-04, train_time=0.868
[alab02] 2024-09-01 13:34:07,691 (trainer:720) INFO: 138epoch:train:1601-1800batch: iter_time=1.316e-04, forward_time=0.124, uma_reduction=0.281, text_vs_uma=0.339, loss_ctc=3.304, loss=1.652, backward_time=0.179, optim_step_time=0.031, optim0_lr0=1.239e-04, train_time=0.847
[alab02] 2024-09-01 13:35:33,964 (trainer:720) INFO: 138epoch:train:1801-2000batch: iter_time=1.274e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.345, loss_ctc=3.386, loss=1.693, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.238e-04, train_time=0.863
[alab02] 2024-09-01 13:36:58,641 (trainer:720) INFO: 138epoch:train:2001-2200batch: iter_time=1.451e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.526, loss=1.763, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.238e-04, train_time=0.847
[alab02] 2024-09-01 13:37:13,572 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 13:38:25,023 (trainer:720) INFO: 138epoch:train:2201-2400batch: iter_time=1.395e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.358, loss_ctc=3.788, loss=1.894, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.238e-04, train_time=0.864
[alab02] 2024-09-01 13:39:51,833 (trainer:720) INFO: 138epoch:train:2401-2600batch: iter_time=1.347e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.347, loss_ctc=3.570, loss=1.785, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.238e-04, train_time=0.868
[alab02] 2024-09-01 13:41:17,545 (trainer:720) INFO: 138epoch:train:2601-2800batch: iter_time=1.267e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.340, loss_ctc=3.383, loss=1.691, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.238e-04, train_time=0.857
[alab02] 2024-09-01 13:42:42,060 (trainer:720) INFO: 138epoch:train:2801-3000batch: iter_time=1.295e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.338, loss=1.669, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.238e-04, train_time=0.845
[alab02] 2024-09-01 13:44:06,911 (trainer:720) INFO: 138epoch:train:3001-3200batch: iter_time=1.238e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.347, loss_ctc=3.492, loss=1.746, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.238e-04, train_time=0.848
[alab02] 2024-09-01 13:45:27,080 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 13:45:33,440 (trainer:720) INFO: 138epoch:train:3201-3400batch: iter_time=1.268e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.352, loss_ctc=3.241, loss=1.621, backward_time=0.186, optim_step_time=0.031, optim0_lr0=1.238e-04, train_time=0.865
[alab02] 2024-09-01 13:46:58,645 (trainer:720) INFO: 138epoch:train:3401-3600batch: iter_time=1.197e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.360, loss_ctc=3.755, loss=1.877, backward_time=0.175, optim_step_time=0.031, optim0_lr0=1.237e-04, train_time=0.852
[alab02] 2024-09-01 13:48:22,548 (trainer:720) INFO: 138epoch:train:3601-3800batch: iter_time=1.240e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.309, loss=1.655, backward_time=0.177, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.839
[alab02] 2024-09-01 13:49:47,481 (trainer:720) INFO: 138epoch:train:3801-4000batch: iter_time=1.312e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.339, loss_ctc=3.010, loss=1.505, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.849
[alab02] 2024-09-01 13:51:12,514 (trainer:720) INFO: 138epoch:train:4001-4200batch: iter_time=1.271e-04, forward_time=0.124, uma_reduction=0.283, text_vs_uma=0.344, loss_ctc=3.503, loss=1.752, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.850
[alab02] 2024-09-01 13:52:38,738 (trainer:720) INFO: 138epoch:train:4201-4400batch: iter_time=1.309e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.358, loss=1.679, backward_time=0.183, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.862
[alab02] 2024-09-01 13:54:06,582 (trainer:720) INFO: 138epoch:train:4401-4600batch: iter_time=1.283e-04, forward_time=0.129, uma_reduction=0.269, text_vs_uma=0.356, loss_ctc=3.667, loss=1.834, backward_time=0.184, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.878
[alab02] 2024-09-01 13:55:33,326 (trainer:720) INFO: 138epoch:train:4601-4800batch: iter_time=1.315e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.576, loss=1.788, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.237e-04, train_time=0.867
[alab02] 2024-09-01 13:56:58,625 (trainer:720) INFO: 138epoch:train:4801-5000batch: iter_time=1.250e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.334, loss_ctc=3.281, loss=1.641, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.853
[alab02] 2024-09-01 13:58:22,633 (trainer:720) INFO: 138epoch:train:5001-5200batch: iter_time=1.300e-04, forward_time=0.123, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.617, loss=1.808, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.236e-04, train_time=0.840
[alab02] 2024-09-01 13:59:47,608 (trainer:720) INFO: 138epoch:train:5201-5400batch: iter_time=1.250e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.369, loss_ctc=3.746, loss=1.873, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.236e-04, train_time=0.850
[alab02] 2024-09-01 14:01:14,185 (trainer:720) INFO: 138epoch:train:5401-5600batch: iter_time=1.316e-04, forward_time=0.127, uma_reduction=0.284, text_vs_uma=0.344, loss_ctc=3.442, loss=1.721, backward_time=0.181, optim_step_time=0.031, optim0_lr0=1.236e-04, train_time=0.866
[alab02] 2024-09-01 14:02:38,553 (trainer:720) INFO: 138epoch:train:5601-5800batch: iter_time=1.314e-04, forward_time=0.123, uma_reduction=0.286, text_vs_uma=0.341, loss_ctc=3.525, loss=1.762, backward_time=0.175, optim_step_time=0.030, optim0_lr0=1.236e-04, train_time=0.843
[alab02] 2024-09-01 14:04:04,015 (trainer:720) INFO: 138epoch:train:5801-6000batch: iter_time=1.455e-04, forward_time=0.125, uma_reduction=0.271, text_vs_uma=0.366, loss_ctc=3.671, loss=1.835, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.236e-04, train_time=0.854
[alab02] 2024-09-01 14:05:28,161 (trainer:720) INFO: 138epoch:train:6001-6200batch: iter_time=1.331e-04, forward_time=0.123, uma_reduction=0.260, text_vs_uma=0.377, loss_ctc=3.516, loss=1.758, backward_time=0.176, optim_step_time=0.031, optim0_lr0=1.236e-04, train_time=0.841
[alab02] 2024-09-01 14:06:53,827 (trainer:720) INFO: 138epoch:train:6201-6400batch: iter_time=1.335e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.347, loss_ctc=3.514, loss=1.757, backward_time=0.178, optim_step_time=0.030, optim0_lr0=1.236e-04, train_time=0.856
[alab02] 2024-09-01 14:08:16,614 (trainer:720) INFO: 138epoch:train:6401-6600batch: iter_time=1.250e-04, forward_time=0.121, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.247, loss=1.624, backward_time=0.173, optim_step_time=0.030, optim0_lr0=1.236e-04, train_time=0.828
[alab02] 2024-09-01 14:09:40,523 (trainer:720) INFO: 138epoch:train:6601-6800batch: iter_time=1.280e-04, forward_time=0.123, uma_reduction=0.278, text_vs_uma=0.351, loss_ctc=3.370, loss=1.685, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.235e-04, train_time=0.839
[alab02] 2024-09-01 14:11:06,796 (trainer:720) INFO: 138epoch:train:6801-7000batch: iter_time=1.285e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=3.013, loss=1.506, backward_time=0.187, optim_step_time=0.030, optim0_lr0=1.235e-04, train_time=0.863
[alab02] 2024-09-01 14:12:20,004 (trainer:338) INFO: 138epoch results: [train] iter_time=1.647e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.428, loss=1.714, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.237e-04, train_time=0.855, time=50 minutes and 46.33 seconds, total_count=983388, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.286, text_vs_uma=0.380, loss_ctc=3.036, cer_ctc=0.082, cer=0.082, loss=3.036, time=5.91 seconds, total_count=3588, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.23 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 14:12:25,623 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 14:12:25,671 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/137epoch.pth
[alab02] 2024-09-01 14:12:25,671 (trainer:272) INFO: 139/150epoch started. Estimated time to finish: 10 hours, 43 minutes and 8.01 seconds
[alab02] 2024-09-01 14:13:52,507 (trainer:720) INFO: 139epoch:train:1-200batch: iter_time=0.001, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.533, loss=1.767, backward_time=0.181, optim_step_time=0.030, optim0_lr0=1.235e-04, train_time=0.868
[alab02] 2024-09-01 14:15:18,356 (trainer:720) INFO: 139epoch:train:201-400batch: iter_time=1.535e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.522, loss=1.761, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.235e-04, train_time=0.858
[alab02] 2024-09-01 14:16:43,549 (trainer:720) INFO: 139epoch:train:401-600batch: iter_time=1.763e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=3.330, loss=1.665, backward_time=0.176, optim_step_time=0.033, optim0_lr0=1.235e-04, train_time=0.852
[alab02] 2024-09-01 14:18:08,498 (trainer:720) INFO: 139epoch:train:601-800batch: iter_time=1.499e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.234, loss=1.617, backward_time=0.180, optim_step_time=0.031, optim0_lr0=1.235e-04, train_time=0.849
[alab02] 2024-09-01 14:19:34,180 (trainer:720) INFO: 139epoch:train:801-1000batch: iter_time=1.394e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.370, loss_ctc=3.171, loss=1.585, backward_time=0.183, optim_step_time=0.031, optim0_lr0=1.235e-04, train_time=0.857
[alab02] 2024-09-01 14:20:59,400 (trainer:720) INFO: 139epoch:train:1001-1200batch: iter_time=1.438e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.351, loss_ctc=3.444, loss=1.722, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.234e-04, train_time=0.852
[alab02] 2024-09-01 14:22:24,479 (trainer:720) INFO: 139epoch:train:1201-1400batch: iter_time=1.338e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.456, loss=1.728, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.851
[alab02] 2024-09-01 14:23:49,418 (trainer:720) INFO: 139epoch:train:1401-1600batch: iter_time=1.322e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.361, loss_ctc=3.597, loss=1.799, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.849
[alab02] 2024-09-01 14:25:16,664 (trainer:720) INFO: 139epoch:train:1601-1800batch: iter_time=1.329e-04, forward_time=0.128, uma_reduction=0.261, text_vs_uma=0.382, loss_ctc=3.743, loss=1.871, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.872
[alab02] 2024-09-01 14:26:40,373 (trainer:720) INFO: 139epoch:train:1801-2000batch: iter_time=1.298e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.367, loss_ctc=3.589, loss=1.795, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.837
[alab02] 2024-09-01 14:28:06,224 (trainer:720) INFO: 139epoch:train:2001-2200batch: iter_time=1.282e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.349, loss_ctc=3.314, loss=1.657, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.858
[alab02] 2024-09-01 14:29:31,549 (trainer:720) INFO: 139epoch:train:2201-2400batch: iter_time=1.422e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.180, loss=1.590, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.853
[alab02] 2024-09-01 14:30:57,630 (trainer:720) INFO: 139epoch:train:2401-2600batch: iter_time=1.435e-04, forward_time=0.127, uma_reduction=0.281, text_vs_uma=0.336, loss_ctc=3.477, loss=1.739, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.234e-04, train_time=0.861
[alab02] 2024-09-01 14:32:24,248 (trainer:720) INFO: 139epoch:train:2601-2800batch: iter_time=1.314e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.647, loss=1.823, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.866
[alab02] 2024-09-01 14:33:48,321 (trainer:720) INFO: 139epoch:train:2801-3000batch: iter_time=1.038e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.565, loss=1.782, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.841
[alab02] 2024-09-01 14:35:10,777 (trainer:720) INFO: 139epoch:train:3001-3200batch: iter_time=1.035e-04, forward_time=0.121, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.357, loss=1.678, backward_time=0.172, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.824
[alab02] 2024-09-01 14:36:37,535 (trainer:720) INFO: 139epoch:train:3201-3400batch: iter_time=1.103e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.350, loss_ctc=3.468, loss=1.734, backward_time=0.184, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.867
[alab02] 2024-09-01 14:38:00,205 (trainer:720) INFO: 139epoch:train:3401-3600batch: iter_time=1.226e-04, forward_time=0.121, uma_reduction=0.286, text_vs_uma=0.338, loss_ctc=3.428, loss=1.714, backward_time=0.171, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.827
[alab02] 2024-09-01 14:39:25,817 (trainer:720) INFO: 139epoch:train:3601-3800batch: iter_time=1.141e-04, forward_time=0.126, uma_reduction=0.281, text_vs_uma=0.342, loss_ctc=3.110, loss=1.555, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.856
[alab02] 2024-09-01 14:40:49,671 (trainer:720) INFO: 139epoch:train:3801-4000batch: iter_time=1.178e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.385, loss=1.693, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.838
[alab02] 2024-09-01 14:42:14,822 (trainer:720) INFO: 139epoch:train:4001-4200batch: iter_time=1.199e-04, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.347, loss_ctc=3.328, loss=1.664, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.233e-04, train_time=0.851
[alab02] 2024-09-01 14:43:39,816 (trainer:720) INFO: 139epoch:train:4201-4400batch: iter_time=1.209e-04, forward_time=0.126, uma_reduction=0.283, text_vs_uma=0.336, loss_ctc=3.256, loss=1.628, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.232e-04, train_time=0.850
[alab02] 2024-09-01 14:45:04,507 (trainer:720) INFO: 139epoch:train:4401-4600batch: iter_time=1.111e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.532, loss=1.766, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.847
[alab02] 2024-09-01 14:46:28,654 (trainer:720) INFO: 139epoch:train:4601-4800batch: iter_time=1.175e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.347, loss_ctc=3.406, loss=1.703, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.841
[alab02] 2024-09-01 14:47:26,566 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 14:47:54,175 (trainer:720) INFO: 139epoch:train:4801-5000batch: iter_time=1.189e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.015, loss=1.508, backward_time=0.184, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.855
[alab02] 2024-09-01 14:49:17,036 (trainer:720) INFO: 139epoch:train:5001-5200batch: iter_time=1.175e-04, forward_time=0.122, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=3.203, loss=1.602, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.828
[alab02] 2024-09-01 14:49:30,521 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 14:50:41,885 (trainer:720) INFO: 139epoch:train:5201-5400batch: iter_time=1.114e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.349, loss_ctc=3.138, loss=1.569, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.848
[alab02] 2024-09-01 14:52:06,433 (trainer:720) INFO: 139epoch:train:5401-5600batch: iter_time=1.291e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=3.432, loss=1.716, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.845
[alab02] 2024-09-01 14:53:32,530 (trainer:720) INFO: 139epoch:train:5601-5800batch: iter_time=1.134e-04, forward_time=0.126, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.253, loss=1.626, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.232e-04, train_time=0.861
[alab02] 2024-09-01 14:54:57,356 (trainer:720) INFO: 139epoch:train:5801-6000batch: iter_time=9.532e-05, forward_time=0.124, uma_reduction=0.283, text_vs_uma=0.348, loss_ctc=3.475, loss=1.737, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.848
[alab02] 2024-09-01 14:56:22,570 (trainer:720) INFO: 139epoch:train:6001-6200batch: iter_time=1.074e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.580, loss=1.790, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.852
[alab02] 2024-09-01 14:57:45,894 (trainer:720) INFO: 139epoch:train:6201-6400batch: iter_time=1.175e-04, forward_time=0.122, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=3.495, loss=1.747, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.833
[alab02] 2024-09-01 14:59:11,307 (trainer:720) INFO: 139epoch:train:6401-6600batch: iter_time=1.125e-04, forward_time=0.125, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=3.135, loss=1.568, backward_time=0.184, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.854
[alab02] 2024-09-01 15:00:35,100 (trainer:720) INFO: 139epoch:train:6601-6800batch: iter_time=1.172e-04, forward_time=0.123, uma_reduction=0.285, text_vs_uma=0.337, loss_ctc=3.209, loss=1.604, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.231e-04, train_time=0.838
[alab02] 2024-09-01 15:02:00,730 (trainer:720) INFO: 139epoch:train:6801-7000batch: iter_time=1.183e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.349, loss_ctc=3.680, loss=1.840, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.856
[alab02] 2024-09-01 15:03:11,218 (trainer:338) INFO: 139epoch results: [train] iter_time=1.604e-04, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.387, loss=1.694, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.233e-04, train_time=0.849, time=50 minutes and 27.78 seconds, total_count=990514, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.291, text_vs_uma=0.374, loss_ctc=3.030, cer_ctc=0.080, cer=0.080, loss=3.030, time=5.66 seconds, total_count=3614, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.11 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 15:03:18,367 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 15:03:18,439 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/84epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/138epoch.pth
[alab02] 2024-09-01 15:03:18,439 (trainer:272) INFO: 140/150epoch started. Estimated time to finish: 9 hours, 49 minutes and 19.45 seconds
[alab02] 2024-09-01 15:04:45,266 (trainer:720) INFO: 140epoch:train:1-200batch: iter_time=0.002, forward_time=0.128, uma_reduction=0.285, text_vs_uma=0.332, loss_ctc=3.042, loss=1.521, backward_time=0.184, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.868
[alab02] 2024-09-01 15:06:11,359 (trainer:720) INFO: 140epoch:train:201-400batch: iter_time=1.404e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.482, loss=1.741, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.231e-04, train_time=0.861
[alab02] 2024-09-01 15:07:37,016 (trainer:720) INFO: 140epoch:train:401-600batch: iter_time=1.353e-04, forward_time=0.126, uma_reduction=0.264, text_vs_uma=0.371, loss_ctc=3.888, loss=1.944, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.230e-04, train_time=0.856
[alab02] 2024-09-01 15:09:03,606 (trainer:720) INFO: 140epoch:train:601-800batch: iter_time=1.343e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.358, loss_ctc=3.664, loss=1.832, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.230e-04, train_time=0.866
[alab02] 2024-09-01 15:10:28,072 (trainer:720) INFO: 140epoch:train:801-1000batch: iter_time=1.199e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.487, loss=1.743, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.230e-04, train_time=0.844
[alab02] 2024-09-01 15:11:54,055 (trainer:720) INFO: 140epoch:train:1001-1200batch: iter_time=1.246e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.740, loss=1.870, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.230e-04, train_time=0.860
[alab02] 2024-09-01 15:13:19,239 (trainer:720) INFO: 140epoch:train:1201-1400batch: iter_time=1.219e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.373, loss_ctc=3.485, loss=1.743, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.230e-04, train_time=0.852
[alab02] 2024-09-01 15:14:42,502 (trainer:720) INFO: 140epoch:train:1401-1600batch: iter_time=1.036e-04, forward_time=0.122, uma_reduction=0.267, text_vs_uma=0.364, loss_ctc=3.388, loss=1.694, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.230e-04, train_time=0.832
[alab02] 2024-09-01 15:16:06,713 (trainer:720) INFO: 140epoch:train:1601-1800batch: iter_time=9.501e-05, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.381, loss=1.690, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.230e-04, train_time=0.842
[alab02] 2024-09-01 15:17:30,820 (trainer:720) INFO: 140epoch:train:1801-2000batch: iter_time=1.227e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.424, loss=1.712, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.230e-04, train_time=0.841
[alab02] 2024-09-01 15:18:54,694 (trainer:720) INFO: 140epoch:train:2001-2200batch: iter_time=1.239e-04, forward_time=0.123, uma_reduction=0.269, text_vs_uma=0.361, loss_ctc=3.674, loss=1.837, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.229e-04, train_time=0.839
[alab02] 2024-09-01 15:20:21,260 (trainer:720) INFO: 140epoch:train:2201-2400batch: iter_time=1.255e-04, forward_time=0.127, uma_reduction=0.266, text_vs_uma=0.371, loss_ctc=3.645, loss=1.823, backward_time=0.184, optim_step_time=0.029, optim0_lr0=1.229e-04, train_time=0.865
[alab02] 2024-09-01 15:21:46,522 (trainer:720) INFO: 140epoch:train:2401-2600batch: iter_time=1.533e-04, forward_time=0.126, uma_reduction=0.263, text_vs_uma=0.370, loss_ctc=3.334, loss=1.667, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.229e-04, train_time=0.852
[alab02] 2024-09-01 15:23:12,860 (trainer:720) INFO: 140epoch:train:2601-2800batch: iter_time=1.537e-04, forward_time=0.127, uma_reduction=0.263, text_vs_uma=0.376, loss_ctc=3.699, loss=1.849, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.229e-04, train_time=0.863
[alab02] 2024-09-01 15:24:37,552 (trainer:720) INFO: 140epoch:train:2801-3000batch: iter_time=1.519e-04, forward_time=0.125, uma_reduction=0.261, text_vs_uma=0.369, loss_ctc=3.800, loss=1.900, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.229e-04, train_time=0.847
[alab02] 2024-09-01 15:26:02,662 (trainer:720) INFO: 140epoch:train:3001-3200batch: iter_time=1.592e-04, forward_time=0.124, uma_reduction=0.263, text_vs_uma=0.372, loss_ctc=3.884, loss=1.942, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.229e-04, train_time=0.851
[alab02] 2024-09-01 15:27:27,686 (trainer:720) INFO: 140epoch:train:3201-3400batch: iter_time=1.417e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=3.599, loss=1.800, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.229e-04, train_time=0.850
[alab02] 2024-09-01 15:27:32,488 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 15:28:52,665 (trainer:720) INFO: 140epoch:train:3401-3600batch: iter_time=1.308e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.774, loss=1.887, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.229e-04, train_time=0.850
[alab02] 2024-09-01 15:30:18,614 (trainer:720) INFO: 140epoch:train:3601-3800batch: iter_time=1.272e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.359, loss_ctc=3.338, loss=1.669, backward_time=0.180, optim_step_time=0.030, optim0_lr0=1.228e-04, train_time=0.859
[alab02] 2024-09-01 15:31:45,447 (trainer:720) INFO: 140epoch:train:3801-4000batch: iter_time=1.226e-04, forward_time=0.128, uma_reduction=0.264, text_vs_uma=0.365, loss_ctc=3.620, loss=1.810, backward_time=0.185, optim_step_time=0.028, optim0_lr0=1.228e-04, train_time=0.868
[alab02] 2024-09-01 15:33:11,925 (trainer:720) INFO: 140epoch:train:4001-4200batch: iter_time=1.211e-04, forward_time=0.126, uma_reduction=0.262, text_vs_uma=0.376, loss_ctc=3.987, loss=1.993, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.228e-04, train_time=0.865
[alab02] 2024-09-01 15:34:41,676 (trainer:720) INFO: 140epoch:train:4201-4400batch: iter_time=2.467e-04, forward_time=0.136, uma_reduction=0.258, text_vs_uma=0.373, loss_ctc=3.633, loss=1.817, backward_time=0.185, optim_step_time=0.036, optim0_lr0=1.228e-04, train_time=0.897
[alab02] 2024-09-01 15:36:11,009 (trainer:720) INFO: 140epoch:train:4401-4600batch: iter_time=1.860e-04, forward_time=0.137, uma_reduction=0.251, text_vs_uma=0.388, loss_ctc=3.704, loss=1.852, backward_time=0.181, optim_step_time=0.038, optim0_lr0=1.228e-04, train_time=0.893
[alab02] 2024-09-01 15:37:41,369 (trainer:720) INFO: 140epoch:train:4601-4800batch: iter_time=1.994e-04, forward_time=0.139, uma_reduction=0.249, text_vs_uma=0.397, loss_ctc=3.474, loss=1.737, backward_time=0.186, optim_step_time=0.040, optim0_lr0=1.228e-04, train_time=0.903
[alab02] 2024-09-01 15:39:14,944 (trainer:720) INFO: 140epoch:train:4801-5000batch: iter_time=2.312e-04, forward_time=0.146, uma_reduction=0.256, text_vs_uma=0.375, loss_ctc=3.495, loss=1.747, backward_time=0.193, optim_step_time=0.048, optim0_lr0=1.228e-04, train_time=0.935
[alab02] 2024-09-01 15:40:50,272 (trainer:720) INFO: 140epoch:train:5001-5200batch: iter_time=2.462e-04, forward_time=0.149, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.644, loss=1.822, backward_time=0.195, optim_step_time=0.049, optim0_lr0=1.228e-04, train_time=0.953
[alab02] 2024-09-01 15:42:24,423 (trainer:720) INFO: 140epoch:train:5201-5400batch: iter_time=2.299e-04, forward_time=0.145, uma_reduction=0.270, text_vs_uma=0.355, loss_ctc=3.595, loss=1.798, backward_time=0.195, optim_step_time=0.048, optim0_lr0=1.227e-04, train_time=0.941
[alab02] 2024-09-01 15:43:56,883 (trainer:720) INFO: 140epoch:train:5401-5600batch: iter_time=2.337e-04, forward_time=0.143, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.131, loss=1.566, backward_time=0.193, optim_step_time=0.047, optim0_lr0=1.227e-04, train_time=0.924
[alab02] 2024-09-01 15:45:33,463 (trainer:720) INFO: 140epoch:train:5601-5800batch: iter_time=2.326e-04, forward_time=0.148, uma_reduction=0.268, text_vs_uma=0.368, loss_ctc=3.682, loss=1.841, backward_time=0.198, optim_step_time=0.050, optim0_lr0=1.227e-04, train_time=0.965
[alab02] 2024-09-01 15:47:06,687 (trainer:720) INFO: 140epoch:train:5801-6000batch: iter_time=2.393e-04, forward_time=0.145, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.342, loss=1.671, backward_time=0.192, optim_step_time=0.049, optim0_lr0=1.227e-04, train_time=0.932
[alab02] 2024-09-01 15:48:39,349 (trainer:720) INFO: 140epoch:train:6001-6200batch: iter_time=2.094e-04, forward_time=0.142, uma_reduction=0.278, text_vs_uma=0.351, loss_ctc=3.630, loss=1.815, backward_time=0.190, optim_step_time=0.042, optim0_lr0=1.227e-04, train_time=0.926
[alab02] 2024-09-01 15:50:07,091 (trainer:720) INFO: 140epoch:train:6201-6400batch: iter_time=1.661e-04, forward_time=0.133, uma_reduction=0.278, text_vs_uma=0.344, loss_ctc=3.389, loss=1.694, backward_time=0.180, optim_step_time=0.035, optim0_lr0=1.227e-04, train_time=0.877
[alab02] 2024-09-01 15:51:31,449 (trainer:720) INFO: 140epoch:train:6401-6600batch: iter_time=1.327e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=3.276, loss=1.638, backward_time=0.174, optim_step_time=0.030, optim0_lr0=1.227e-04, train_time=0.843
[alab02] 2024-09-01 15:52:57,059 (trainer:720) INFO: 140epoch:train:6601-6800batch: iter_time=1.193e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.327, loss_ctc=3.146, loss=1.573, backward_time=0.182, optim_step_time=0.030, optim0_lr0=1.227e-04, train_time=0.856
[alab02] 2024-09-01 15:54:22,404 (trainer:720) INFO: 140epoch:train:6801-7000batch: iter_time=1.260e-04, forward_time=0.126, uma_reduction=0.283, text_vs_uma=0.349, loss_ctc=3.509, loss=1.755, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.226e-04, train_time=0.853
[alab02] 2024-09-01 15:55:32,944 (trainer:338) INFO: 140epoch results: [train] iter_time=2.061e-04, forward_time=0.131, uma_reduction=0.268, text_vs_uma=0.363, loss_ctc=3.542, loss=1.771, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.229e-04, train_time=0.874, time=51 minutes and 56.21 seconds, total_count=997640, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.306, text_vs_uma=0.355, loss_ctc=3.009, cer_ctc=0.081, cer=0.081, loss=3.009, time=5.81 seconds, total_count=3640, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.48 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 15:55:39,344 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 15:55:39,356 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/109epoch.pth
[alab02] 2024-09-01 15:55:39,356 (trainer:272) INFO: 141/150epoch started. Estimated time to finish: 8 hours, 55 minutes and 39.7 seconds
[alab02] 2024-09-01 15:57:05,658 (trainer:720) INFO: 141epoch:train:1-200batch: iter_time=0.002, forward_time=0.126, uma_reduction=0.286, text_vs_uma=0.348, loss_ctc=3.490, loss=1.745, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.226e-04, train_time=0.863
[alab02] 2024-09-01 15:58:31,180 (trainer:720) INFO: 141epoch:train:201-400batch: iter_time=1.330e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.361, loss_ctc=3.327, loss=1.664, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.226e-04, train_time=0.855
[alab02] 2024-09-01 15:59:54,273 (trainer:720) INFO: 141epoch:train:401-600batch: iter_time=1.401e-04, forward_time=0.122, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.489, loss=1.744, backward_time=0.171, optim_step_time=0.028, optim0_lr0=1.226e-04, train_time=0.831
[alab02] 2024-09-01 16:00:05,423 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 16:01:19,187 (trainer:720) INFO: 141epoch:train:601-800batch: iter_time=1.347e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.348, loss=1.674, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.226e-04, train_time=0.849
[alab02] 2024-09-01 16:02:44,666 (trainer:720) INFO: 141epoch:train:801-1000batch: iter_time=1.479e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.355, loss_ctc=3.553, loss=1.776, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.226e-04, train_time=0.855
[alab02] 2024-09-01 16:04:09,721 (trainer:720) INFO: 141epoch:train:1001-1200batch: iter_time=1.297e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.360, loss_ctc=3.148, loss=1.574, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.226e-04, train_time=0.850
[alab02] 2024-09-01 16:05:33,672 (trainer:720) INFO: 141epoch:train:1201-1400batch: iter_time=1.311e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.354, loss_ctc=3.221, loss=1.610, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.226e-04, train_time=0.839
[alab02] 2024-09-01 16:06:59,461 (trainer:720) INFO: 141epoch:train:1401-1600batch: iter_time=1.326e-04, forward_time=0.126, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.274, loss=1.637, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.225e-04, train_time=0.858
[alab02] 2024-09-01 16:08:23,976 (trainer:720) INFO: 141epoch:train:1601-1800batch: iter_time=1.305e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=3.433, loss=1.717, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.225e-04, train_time=0.845
[alab02] 2024-09-01 16:09:50,290 (trainer:720) INFO: 141epoch:train:1801-2000batch: iter_time=1.287e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.374, loss_ctc=3.511, loss=1.756, backward_time=0.183, optim_step_time=0.029, optim0_lr0=1.225e-04, train_time=0.863
[alab02] 2024-09-01 16:11:13,945 (trainer:720) INFO: 141epoch:train:2001-2200batch: iter_time=1.242e-04, forward_time=0.122, uma_reduction=0.263, text_vs_uma=0.367, loss_ctc=3.241, loss=1.620, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.225e-04, train_time=0.836
[alab02] 2024-09-01 16:12:38,193 (trainer:720) INFO: 141epoch:train:2201-2400batch: iter_time=1.244e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.120, loss=1.560, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.225e-04, train_time=0.842
[alab02] 2024-09-01 16:14:04,401 (trainer:720) INFO: 141epoch:train:2401-2600batch: iter_time=1.216e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.355, loss_ctc=3.257, loss=1.629, backward_time=0.184, optim_step_time=0.028, optim0_lr0=1.225e-04, train_time=0.862
[alab02] 2024-09-01 16:15:29,705 (trainer:720) INFO: 141epoch:train:2601-2800batch: iter_time=1.292e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.346, loss_ctc=3.256, loss=1.628, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.225e-04, train_time=0.853
[alab02] 2024-09-01 16:16:52,803 (trainer:720) INFO: 141epoch:train:2801-3000batch: iter_time=9.710e-05, forward_time=0.121, uma_reduction=0.269, text_vs_uma=0.357, loss_ctc=3.601, loss=1.801, backward_time=0.172, optim_step_time=0.028, optim0_lr0=1.225e-04, train_time=0.831
[alab02] 2024-09-01 16:18:17,365 (trainer:720) INFO: 141epoch:train:3001-3200batch: iter_time=9.443e-05, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.367, loss_ctc=3.469, loss=1.735, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.224e-04, train_time=0.845
[alab02] 2024-09-01 16:19:42,730 (trainer:720) INFO: 141epoch:train:3201-3400batch: iter_time=1.204e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.358, loss_ctc=3.585, loss=1.792, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.224e-04, train_time=0.853
[alab02] 2024-09-01 16:21:06,927 (trainer:720) INFO: 141epoch:train:3401-3600batch: iter_time=1.305e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.373, loss_ctc=3.503, loss=1.752, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.224e-04, train_time=0.842
[alab02] 2024-09-01 16:22:32,136 (trainer:720) INFO: 141epoch:train:3601-3800batch: iter_time=1.263e-04, forward_time=0.126, uma_reduction=0.267, text_vs_uma=0.360, loss_ctc=3.547, loss=1.774, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.224e-04, train_time=0.852
[alab02] 2024-09-01 16:23:58,680 (trainer:720) INFO: 141epoch:train:3801-4000batch: iter_time=1.220e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.352, loss=1.676, backward_time=0.185, optim_step_time=0.028, optim0_lr0=1.224e-04, train_time=0.865
[alab02] 2024-09-01 16:25:22,975 (trainer:720) INFO: 141epoch:train:4001-4200batch: iter_time=1.270e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.266, loss=1.633, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.224e-04, train_time=0.843
[alab02] 2024-09-01 16:26:45,512 (trainer:720) INFO: 141epoch:train:4201-4400batch: iter_time=1.171e-04, forward_time=0.121, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.664, loss=1.832, backward_time=0.166, optim_step_time=0.029, optim0_lr0=1.224e-04, train_time=0.825
[alab02] 2024-09-01 16:28:08,851 (trainer:720) INFO: 141epoch:train:4401-4600batch: iter_time=1.256e-04, forward_time=0.122, uma_reduction=0.281, text_vs_uma=0.352, loss_ctc=3.227, loss=1.613, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.224e-04, train_time=0.833
[alab02] 2024-09-01 16:29:31,172 (trainer:720) INFO: 141epoch:train:4601-4800batch: iter_time=1.254e-04, forward_time=0.121, uma_reduction=0.282, text_vs_uma=0.336, loss_ctc=3.162, loss=1.581, backward_time=0.172, optim_step_time=0.029, optim0_lr0=1.223e-04, train_time=0.823
[alab02] 2024-09-01 16:30:55,845 (trainer:720) INFO: 141epoch:train:4801-5000batch: iter_time=1.268e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.551, loss=1.776, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.847
[alab02] 2024-09-01 16:32:21,342 (trainer:720) INFO: 141epoch:train:5001-5200batch: iter_time=1.137e-04, forward_time=0.126, uma_reduction=0.272, text_vs_uma=0.349, loss_ctc=3.364, loss=1.682, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.855
[alab02] 2024-09-01 16:33:44,085 (trainer:720) INFO: 141epoch:train:5201-5400batch: iter_time=1.198e-04, forward_time=0.122, uma_reduction=0.274, text_vs_uma=0.345, loss_ctc=3.268, loss=1.634, backward_time=0.172, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.827
[alab02] 2024-09-01 16:35:11,174 (trainer:720) INFO: 141epoch:train:5401-5600batch: iter_time=1.228e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.127, loss=1.564, backward_time=0.189, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.871
[alab02] 2024-09-01 16:36:36,604 (trainer:720) INFO: 141epoch:train:5601-5800batch: iter_time=1.114e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.345, loss_ctc=3.427, loss=1.714, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.854
[alab02] 2024-09-01 16:38:01,426 (trainer:720) INFO: 141epoch:train:5801-6000batch: iter_time=9.314e-05, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.196, loss=1.598, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.848
[alab02] 2024-09-01 16:39:26,722 (trainer:720) INFO: 141epoch:train:6001-6200batch: iter_time=1.043e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.361, loss_ctc=3.514, loss=1.757, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.223e-04, train_time=0.853
[alab02] 2024-09-01 16:40:51,124 (trainer:720) INFO: 141epoch:train:6201-6400batch: iter_time=1.303e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.386, loss=1.693, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.222e-04, train_time=0.844
[alab02] 2024-09-01 16:42:15,197 (trainer:720) INFO: 141epoch:train:6401-6600batch: iter_time=1.295e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=3.437, loss=1.719, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.222e-04, train_time=0.840
[alab02] 2024-09-01 16:43:39,549 (trainer:720) INFO: 141epoch:train:6601-6800batch: iter_time=1.237e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.361, loss_ctc=3.761, loss=1.880, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.222e-04, train_time=0.843
[alab02] 2024-09-01 16:45:03,863 (trainer:720) INFO: 141epoch:train:6801-7000batch: iter_time=1.251e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.492, loss=1.746, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.222e-04, train_time=0.843
[alab02] 2024-09-01 16:45:29,276 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 16:46:16,183 (trainer:338) INFO: 141epoch results: [train] iter_time=1.759e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.355, loss_ctc=3.381, loss=1.691, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.224e-04, train_time=0.847, time=50 minutes and 19.33 seconds, total_count=1004766, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.280, text_vs_uma=0.387, loss_ctc=3.113, cer_ctc=0.080, cer=0.080, loss=3.113, time=5.67 seconds, total_count=3666, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.83 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 16:46:23,184 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 16:46:23,245 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/136epoch.pth
[alab02] 2024-09-01 16:46:23,245 (trainer:272) INFO: 142/150epoch started. Estimated time to finish: 8 hours, 1 minute and 54.87 seconds
[alab02] 2024-09-01 16:47:48,860 (trainer:720) INFO: 142epoch:train:1-200batch: iter_time=0.001, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.359, loss_ctc=3.528, loss=1.764, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.222e-04, train_time=0.856
[alab02] 2024-09-01 16:49:14,551 (trainer:720) INFO: 142epoch:train:201-400batch: iter_time=1.309e-04, forward_time=0.127, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.539, loss=1.770, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.222e-04, train_time=0.857
[alab02] 2024-09-01 16:50:38,946 (trainer:720) INFO: 142epoch:train:401-600batch: iter_time=1.189e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.341, loss_ctc=3.068, loss=1.534, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.222e-04, train_time=0.844
[alab02] 2024-09-01 16:52:03,384 (trainer:720) INFO: 142epoch:train:601-800batch: iter_time=1.173e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.359, loss=1.680, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.222e-04, train_time=0.844
[alab02] 2024-09-01 16:53:29,480 (trainer:720) INFO: 142epoch:train:801-1000batch: iter_time=1.225e-04, forward_time=0.127, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.332, loss=1.666, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.861
[alab02] 2024-09-01 16:54:53,859 (trainer:720) INFO: 142epoch:train:1001-1200batch: iter_time=1.338e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.289, loss=1.644, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.221e-04, train_time=0.844
[alab02] 2024-09-01 16:56:17,311 (trainer:720) INFO: 142epoch:train:1201-1400batch: iter_time=1.260e-04, forward_time=0.123, uma_reduction=0.267, text_vs_uma=0.372, loss_ctc=3.375, loss=1.687, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.834
[alab02] 2024-09-01 16:57:44,759 (trainer:720) INFO: 142epoch:train:1401-1600batch: iter_time=1.132e-04, forward_time=0.128, uma_reduction=0.262, text_vs_uma=0.366, loss_ctc=3.616, loss=1.808, backward_time=0.184, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.874
[alab02] 2024-09-01 16:59:08,228 (trainer:720) INFO: 142epoch:train:1601-1800batch: iter_time=1.064e-04, forward_time=0.122, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.562, loss=1.781, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.834
[alab02] 2024-09-01 17:00:33,104 (trainer:720) INFO: 142epoch:train:1801-2000batch: iter_time=1.191e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.353, loss_ctc=3.379, loss=1.690, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.849
[alab02] 2024-09-01 17:01:57,579 (trainer:720) INFO: 142epoch:train:2001-2200batch: iter_time=1.235e-04, forward_time=0.124, uma_reduction=0.286, text_vs_uma=0.338, loss_ctc=3.268, loss=1.634, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.845
[alab02] 2024-09-01 17:03:23,713 (trainer:720) INFO: 142epoch:train:2201-2400batch: iter_time=1.228e-04, forward_time=0.126, uma_reduction=0.290, text_vs_uma=0.334, loss_ctc=3.456, loss=1.728, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.221e-04, train_time=0.861
[alab02] 2024-09-01 17:04:47,803 (trainer:720) INFO: 142epoch:train:2401-2600batch: iter_time=1.232e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.355, loss=1.678, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.220e-04, train_time=0.841
[alab02] 2024-09-01 17:06:12,865 (trainer:720) INFO: 142epoch:train:2601-2800batch: iter_time=1.266e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.353, loss_ctc=3.324, loss=1.662, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.220e-04, train_time=0.850
[alab02] 2024-09-01 17:07:36,332 (trainer:720) INFO: 142epoch:train:2801-3000batch: iter_time=1.307e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=3.328, loss=1.664, backward_time=0.171, optim_step_time=0.029, optim0_lr0=1.220e-04, train_time=0.834
[alab02] 2024-09-01 17:09:00,025 (trainer:720) INFO: 142epoch:train:3001-3200batch: iter_time=1.270e-04, forward_time=0.123, uma_reduction=0.272, text_vs_uma=0.363, loss_ctc=3.376, loss=1.688, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.220e-04, train_time=0.837
[alab02] 2024-09-01 17:10:25,413 (trainer:720) INFO: 142epoch:train:3201-3400batch: iter_time=1.273e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.349, loss_ctc=3.137, loss=1.569, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.220e-04, train_time=0.854
[alab02] 2024-09-01 17:11:49,909 (trainer:720) INFO: 142epoch:train:3401-3600batch: iter_time=1.268e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.339, loss_ctc=3.107, loss=1.553, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.220e-04, train_time=0.845
[alab02] 2024-09-01 17:13:14,652 (trainer:720) INFO: 142epoch:train:3601-3800batch: iter_time=1.149e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.295, loss=1.648, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.220e-04, train_time=0.847
[alab02] 2024-09-01 17:14:40,292 (trainer:720) INFO: 142epoch:train:3801-4000batch: iter_time=1.178e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.354, loss_ctc=3.410, loss=1.705, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.220e-04, train_time=0.856
[alab02] 2024-09-01 17:16:04,901 (trainer:720) INFO: 142epoch:train:4001-4200batch: iter_time=1.235e-04, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.363, loss_ctc=3.676, loss=1.838, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.219e-04, train_time=0.846
[alab02] 2024-09-01 17:16:08,812 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 17:17:29,869 (trainer:720) INFO: 142epoch:train:4201-4400batch: iter_time=1.237e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.754, loss=1.877, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.219e-04, train_time=0.849
[alab02] 2024-09-01 17:18:56,687 (trainer:720) INFO: 142epoch:train:4401-4600batch: iter_time=1.037e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.356, loss_ctc=3.496, loss=1.748, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.219e-04, train_time=0.868
[alab02] 2024-09-01 17:20:21,303 (trainer:720) INFO: 142epoch:train:4601-4800batch: iter_time=1.118e-04, forward_time=0.124, uma_reduction=0.285, text_vs_uma=0.348, loss_ctc=3.553, loss=1.777, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.219e-04, train_time=0.846
[alab02] 2024-09-01 17:21:46,306 (trainer:720) INFO: 142epoch:train:4801-5000batch: iter_time=1.367e-04, forward_time=0.126, uma_reduction=0.293, text_vs_uma=0.324, loss_ctc=3.026, loss=1.513, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.219e-04, train_time=0.850
[alab02] 2024-09-01 17:23:06,063 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 17:23:10,757 (trainer:720) INFO: 142epoch:train:5001-5200batch: iter_time=1.236e-04, forward_time=0.124, uma_reduction=0.285, text_vs_uma=0.340, loss_ctc=3.359, loss=1.680, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.219e-04, train_time=0.844
[alab02] 2024-09-01 17:24:34,905 (trainer:720) INFO: 142epoch:train:5201-5400batch: iter_time=1.154e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.356, loss_ctc=3.735, loss=1.867, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.219e-04, train_time=0.841
[alab02] 2024-09-01 17:26:00,477 (trainer:720) INFO: 142epoch:train:5401-5600batch: iter_time=1.178e-04, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.336, loss_ctc=3.177, loss=1.588, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.219e-04, train_time=0.856
[alab02] 2024-09-01 17:27:25,422 (trainer:720) INFO: 142epoch:train:5601-5800batch: iter_time=1.222e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.338, loss_ctc=3.207, loss=1.604, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.219e-04, train_time=0.849
[alab02] 2024-09-01 17:28:48,874 (trainer:720) INFO: 142epoch:train:5801-6000batch: iter_time=1.203e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.353, loss_ctc=3.426, loss=1.713, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.218e-04, train_time=0.834
[alab02] 2024-09-01 17:30:12,543 (trainer:720) INFO: 142epoch:train:6001-6200batch: iter_time=1.178e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.237, loss=1.619, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.218e-04, train_time=0.836
[alab02] 2024-09-01 17:31:37,427 (trainer:720) INFO: 142epoch:train:6201-6400batch: iter_time=1.205e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.343, loss_ctc=3.155, loss=1.577, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.218e-04, train_time=0.849
[alab02] 2024-09-01 17:33:01,563 (trainer:720) INFO: 142epoch:train:6401-6600batch: iter_time=1.229e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=3.694, loss=1.847, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.218e-04, train_time=0.841
[alab02] 2024-09-01 17:34:26,082 (trainer:720) INFO: 142epoch:train:6601-6800batch: iter_time=1.160e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.469, loss=1.735, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.218e-04, train_time=0.845
[alab02] 2024-09-01 17:35:52,035 (trainer:720) INFO: 142epoch:train:6801-7000batch: iter_time=1.195e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.351, loss_ctc=3.456, loss=1.728, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.218e-04, train_time=0.859
[alab02] 2024-09-01 17:37:03,903 (trainer:338) INFO: 142epoch results: [train] iter_time=1.556e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.377, loss=1.689, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.220e-04, train_time=0.848, time=50 minutes and 23.01 seconds, total_count=1011892, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.308, text_vs_uma=0.352, loss_ctc=2.892, cer_ctc=0.078, cer=0.078, loss=2.892, time=5.72 seconds, total_count=3692, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.92 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 17:37:09,882 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 17:37:09,891 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/117epoch.pth
[alab02] 2024-09-01 17:37:09,891 (trainer:272) INFO: 143/150epoch started. Estimated time to finish: 7 hours, 8 minutes and 12.75 seconds
[alab02] 2024-09-01 17:38:33,618 (trainer:720) INFO: 143epoch:train:1-200batch: iter_time=0.002, forward_time=0.122, uma_reduction=0.285, text_vs_uma=0.346, loss_ctc=3.540, loss=1.770, backward_time=0.171, optim_step_time=0.028, optim0_lr0=1.218e-04, train_time=0.837
[alab02] 2024-09-01 17:39:58,827 (trainer:720) INFO: 143epoch:train:201-400batch: iter_time=1.016e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.355, loss_ctc=3.127, loss=1.564, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.852
[alab02] 2024-09-01 17:41:25,435 (trainer:720) INFO: 143epoch:train:401-600batch: iter_time=1.253e-04, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.771, loss=1.886, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.866
[alab02] 2024-09-01 17:42:49,430 (trainer:720) INFO: 143epoch:train:601-800batch: iter_time=1.254e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=3.449, loss=1.724, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.217e-04, train_time=0.840
[alab02] 2024-09-01 17:44:14,526 (trainer:720) INFO: 143epoch:train:801-1000batch: iter_time=1.223e-04, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.565, loss=1.783, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.851
[alab02] 2024-09-01 17:45:39,933 (trainer:720) INFO: 143epoch:train:1001-1200batch: iter_time=1.365e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.357, loss_ctc=3.519, loss=1.759, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.854
[alab02] 2024-09-01 17:47:02,617 (trainer:720) INFO: 143epoch:train:1201-1400batch: iter_time=1.445e-04, forward_time=0.122, uma_reduction=0.286, text_vs_uma=0.332, loss_ctc=2.986, loss=1.493, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.827
[alab02] 2024-09-01 17:48:26,134 (trainer:720) INFO: 143epoch:train:1401-1600batch: iter_time=1.201e-04, forward_time=0.122, uma_reduction=0.287, text_vs_uma=0.335, loss_ctc=3.313, loss=1.657, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.835
[alab02] 2024-09-01 17:49:54,448 (trainer:720) INFO: 143epoch:train:1601-1800batch: iter_time=1.171e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.337, loss_ctc=3.322, loss=1.661, backward_time=0.189, optim_step_time=0.029, optim0_lr0=1.217e-04, train_time=0.883
[alab02] 2024-09-01 17:51:19,200 (trainer:720) INFO: 143epoch:train:1801-2000batch: iter_time=1.180e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.354, loss_ctc=3.513, loss=1.756, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.217e-04, train_time=0.847
[alab02] 2024-09-01 17:52:41,696 (trainer:720) INFO: 143epoch:train:2001-2200batch: iter_time=1.318e-04, forward_time=0.122, uma_reduction=0.265, text_vs_uma=0.365, loss_ctc=3.433, loss=1.716, backward_time=0.170, optim_step_time=0.030, optim0_lr0=1.216e-04, train_time=0.825
[alab02] 2024-09-01 17:54:14,682 (trainer:720) INFO: 143epoch:train:2201-2400batch: iter_time=2.163e-04, forward_time=0.143, uma_reduction=0.263, text_vs_uma=0.368, loss_ctc=3.784, loss=1.892, backward_time=0.188, optim_step_time=0.042, optim0_lr0=1.216e-04, train_time=0.929
[alab02] 2024-09-01 17:55:46,160 (trainer:720) INFO: 143epoch:train:2401-2600batch: iter_time=2.143e-04, forward_time=0.140, uma_reduction=0.266, text_vs_uma=0.357, loss_ctc=3.448, loss=1.724, backward_time=0.188, optim_step_time=0.041, optim0_lr0=1.216e-04, train_time=0.914
[alab02] 2024-09-01 17:57:15,875 (trainer:720) INFO: 143epoch:train:2601-2800batch: iter_time=1.955e-04, forward_time=0.137, uma_reduction=0.265, text_vs_uma=0.368, loss_ctc=3.523, loss=1.761, backward_time=0.182, optim_step_time=0.039, optim0_lr0=1.216e-04, train_time=0.897
[alab02] 2024-09-01 17:58:44,087 (trainer:720) INFO: 143epoch:train:2801-3000batch: iter_time=1.890e-04, forward_time=0.134, uma_reduction=0.271, text_vs_uma=0.355, loss_ctc=3.350, loss=1.675, backward_time=0.181, optim_step_time=0.038, optim0_lr0=1.216e-04, train_time=0.882
[alab02] 2024-09-01 18:00:09,894 (trainer:720) INFO: 143epoch:train:3001-3200batch: iter_time=1.596e-04, forward_time=0.128, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.583, loss=1.791, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.216e-04, train_time=0.858
[alab02] 2024-09-01 18:01:35,048 (trainer:720) INFO: 143epoch:train:3201-3400batch: iter_time=1.430e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.349, loss_ctc=3.044, loss=1.522, backward_time=0.179, optim_step_time=0.030, optim0_lr0=1.216e-04, train_time=0.851
[alab02] 2024-09-01 18:03:02,434 (trainer:720) INFO: 143epoch:train:3401-3600batch: iter_time=1.280e-04, forward_time=0.129, uma_reduction=0.282, text_vs_uma=0.336, loss_ctc=3.123, loss=1.562, backward_time=0.185, optim_step_time=0.029, optim0_lr0=1.216e-04, train_time=0.874
[alab02] 2024-09-01 18:04:29,483 (trainer:720) INFO: 143epoch:train:3601-3800batch: iter_time=1.192e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.087, loss=1.543, backward_time=0.187, optim_step_time=0.028, optim0_lr0=1.215e-04, train_time=0.870
[alab02] 2024-09-01 18:05:57,322 (trainer:720) INFO: 143epoch:train:3801-4000batch: iter_time=1.362e-04, forward_time=0.130, uma_reduction=0.279, text_vs_uma=0.347, loss_ctc=3.272, loss=1.636, backward_time=0.187, optim_step_time=0.031, optim0_lr0=1.215e-04, train_time=0.878
[alab02] 2024-09-01 18:07:31,058 (trainer:720) INFO: 143epoch:train:4001-4200batch: iter_time=2.571e-04, forward_time=0.146, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=3.496, loss=1.748, backward_time=0.190, optim_step_time=0.051, optim0_lr0=1.215e-04, train_time=0.937
[alab02] 2024-09-01 18:09:05,392 (trainer:720) INFO: 143epoch:train:4201-4400batch: iter_time=2.317e-04, forward_time=0.146, uma_reduction=0.277, text_vs_uma=0.352, loss_ctc=3.410, loss=1.705, backward_time=0.193, optim_step_time=0.047, optim0_lr0=1.215e-04, train_time=0.943
[alab02] 2024-09-01 18:10:39,042 (trainer:720) INFO: 143epoch:train:4401-4600batch: iter_time=2.446e-04, forward_time=0.147, uma_reduction=0.277, text_vs_uma=0.357, loss_ctc=3.399, loss=1.700, backward_time=0.189, optim_step_time=0.048, optim0_lr0=1.215e-04, train_time=0.936
[alab02] 2024-09-01 18:12:12,574 (trainer:720) INFO: 143epoch:train:4601-4800batch: iter_time=2.417e-04, forward_time=0.144, uma_reduction=0.279, text_vs_uma=0.349, loss_ctc=3.413, loss=1.706, backward_time=0.193, optim_step_time=0.048, optim0_lr0=1.215e-04, train_time=0.935
[alab02] 2024-09-01 18:13:49,636 (trainer:720) INFO: 143epoch:train:4801-5000batch: iter_time=2.780e-04, forward_time=0.150, uma_reduction=0.283, text_vs_uma=0.345, loss_ctc=3.545, loss=1.772, backward_time=0.199, optim_step_time=0.051, optim0_lr0=1.215e-04, train_time=0.970
[alab02] 2024-09-01 18:15:24,708 (trainer:720) INFO: 143epoch:train:5001-5200batch: iter_time=2.511e-04, forward_time=0.149, uma_reduction=0.280, text_vs_uma=0.336, loss_ctc=3.090, loss=1.545, backward_time=0.196, optim_step_time=0.051, optim0_lr0=1.215e-04, train_time=0.950
[alab02] 2024-09-01 18:16:56,158 (trainer:720) INFO: 143epoch:train:5201-5400batch: iter_time=2.128e-04, forward_time=0.142, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.577, loss=1.789, backward_time=0.182, optim_step_time=0.040, optim0_lr0=1.214e-04, train_time=0.914
[alab02] 2024-09-01 18:18:23,578 (trainer:720) INFO: 143epoch:train:5401-5600batch: iter_time=2.024e-04, forward_time=0.135, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.354, loss=1.677, backward_time=0.176, optim_step_time=0.039, optim0_lr0=1.214e-04, train_time=0.874
[alab02] 2024-09-01 18:19:52,902 (trainer:720) INFO: 143epoch:train:5601-5800batch: iter_time=2.011e-04, forward_time=0.138, uma_reduction=0.283, text_vs_uma=0.342, loss_ctc=3.209, loss=1.604, backward_time=0.182, optim_step_time=0.039, optim0_lr0=1.214e-04, train_time=0.893
[alab02] 2024-09-01 18:21:23,355 (trainer:720) INFO: 143epoch:train:5801-6000batch: iter_time=2.044e-04, forward_time=0.139, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.366, loss=1.683, backward_time=0.183, optim_step_time=0.039, optim0_lr0=1.214e-04, train_time=0.904
[alab02] 2024-09-01 18:22:53,312 (trainer:720) INFO: 143epoch:train:6001-6200batch: iter_time=1.980e-04, forward_time=0.138, uma_reduction=0.277, text_vs_uma=0.346, loss_ctc=3.511, loss=1.756, backward_time=0.181, optim_step_time=0.038, optim0_lr0=1.214e-04, train_time=0.899
[alab02] 2024-09-01 18:24:25,025 (trainer:720) INFO: 143epoch:train:6201-6400batch: iter_time=2.038e-04, forward_time=0.141, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.329, loss=1.665, backward_time=0.187, optim_step_time=0.039, optim0_lr0=1.214e-04, train_time=0.917
[alab02] 2024-09-01 18:26:00,327 (trainer:720) INFO: 143epoch:train:6401-6600batch: iter_time=2.388e-04, forward_time=0.148, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.274, loss=1.637, backward_time=0.195, optim_step_time=0.049, optim0_lr0=1.214e-04, train_time=0.953
[alab02] 2024-09-01 18:27:28,499 (trainer:720) INFO: 143epoch:train:6601-6800batch: iter_time=1.568e-04, forward_time=0.132, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.226, loss=1.613, backward_time=0.185, optim_step_time=0.035, optim0_lr0=1.214e-04, train_time=0.881
[alab02] 2024-09-01 18:28:53,815 (trainer:720) INFO: 143epoch:train:6801-7000batch: iter_time=1.203e-04, forward_time=0.126, uma_reduction=0.286, text_vs_uma=0.329, loss_ctc=3.131, loss=1.566, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.214e-04, train_time=0.853
[alab02] 2024-09-01 18:30:05,025 (trainer:338) INFO: 143epoch results: [train] iter_time=2.137e-04, forward_time=0.134, uma_reduction=0.277, text_vs_uma=0.350, loss_ctc=3.366, loss=1.683, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.216e-04, train_time=0.886, time=52 minutes and 37.38 seconds, total_count=1019018, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.296, text_vs_uma=0.366, loss_ctc=2.987, cer_ctc=0.079, cer=0.079, loss=2.987, time=6.03 seconds, total_count=3718, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.72 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 18:30:12,860 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 18:30:12,866 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/133epoch.pth
[alab02] 2024-09-01 18:30:12,866 (trainer:272) INFO: 144/150epoch started. Estimated time to finish: 6 hours, 14 minutes and 39.76 seconds
[alab02] 2024-09-01 18:30:57,550 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 18:31:46,492 (trainer:720) INFO: 144epoch:train:1-200batch: iter_time=0.002, forward_time=0.142, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=3.469, loss=1.734, backward_time=0.192, optim_step_time=0.045, optim0_lr0=1.213e-04, train_time=0.935
[alab02] 2024-09-01 18:33:20,536 (trainer:720) INFO: 144epoch:train:201-400batch: iter_time=2.934e-04, forward_time=0.147, uma_reduction=0.283, text_vs_uma=0.345, loss_ctc=3.318, loss=1.659, backward_time=0.191, optim_step_time=0.054, optim0_lr0=1.213e-04, train_time=0.940
[alab02] 2024-09-01 18:34:55,584 (trainer:720) INFO: 144epoch:train:401-600batch: iter_time=3.491e-04, forward_time=0.149, uma_reduction=0.274, text_vs_uma=0.358, loss_ctc=3.300, loss=1.650, backward_time=0.195, optim_step_time=0.057, optim0_lr0=1.213e-04, train_time=0.950
[alab02] 2024-09-01 18:36:30,867 (trainer:720) INFO: 144epoch:train:601-800batch: iter_time=3.109e-04, forward_time=0.149, uma_reduction=0.269, text_vs_uma=0.360, loss_ctc=3.507, loss=1.754, backward_time=0.192, optim_step_time=0.054, optim0_lr0=1.213e-04, train_time=0.952
[alab02] 2024-09-01 18:38:05,421 (trainer:720) INFO: 144epoch:train:801-1000batch: iter_time=2.932e-04, forward_time=0.147, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.550, loss=1.775, backward_time=0.190, optim_step_time=0.052, optim0_lr0=1.213e-04, train_time=0.945
[alab02] 2024-09-01 18:39:34,909 (trainer:720) INFO: 144epoch:train:1001-1200batch: iter_time=2.354e-04, forward_time=0.137, uma_reduction=0.268, text_vs_uma=0.365, loss_ctc=3.426, loss=1.713, backward_time=0.183, optim_step_time=0.043, optim0_lr0=1.213e-04, train_time=0.895
[alab02] 2024-09-01 18:41:07,070 (trainer:720) INFO: 144epoch:train:1201-1400batch: iter_time=2.373e-04, forward_time=0.141, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.585, loss=1.793, backward_time=0.186, optim_step_time=0.044, optim0_lr0=1.213e-04, train_time=0.921
[alab02] 2024-09-01 18:42:34,942 (trainer:720) INFO: 144epoch:train:1401-1600batch: iter_time=2.237e-04, forward_time=0.134, uma_reduction=0.271, text_vs_uma=0.367, loss_ctc=3.302, loss=1.651, backward_time=0.179, optim_step_time=0.042, optim0_lr0=1.213e-04, train_time=0.878
[alab02] 2024-09-01 18:44:06,607 (trainer:720) INFO: 144epoch:train:1601-1800batch: iter_time=2.142e-04, forward_time=0.139, uma_reduction=0.277, text_vs_uma=0.354, loss_ctc=3.365, loss=1.683, backward_time=0.191, optim_step_time=0.041, optim0_lr0=1.212e-04, train_time=0.916
[alab02] 2024-09-01 18:45:35,666 (trainer:720) INFO: 144epoch:train:1801-2000batch: iter_time=1.977e-04, forward_time=0.134, uma_reduction=0.277, text_vs_uma=0.345, loss_ctc=3.449, loss=1.725, backward_time=0.182, optim_step_time=0.037, optim0_lr0=1.212e-04, train_time=0.890
[alab02] 2024-09-01 18:47:05,410 (trainer:720) INFO: 144epoch:train:2001-2200batch: iter_time=1.993e-04, forward_time=0.136, uma_reduction=0.285, text_vs_uma=0.335, loss_ctc=3.189, loss=1.594, backward_time=0.188, optim_step_time=0.038, optim0_lr0=1.212e-04, train_time=0.897
[alab02] 2024-09-01 18:48:31,720 (trainer:720) INFO: 144epoch:train:2201-2400batch: iter_time=1.903e-04, forward_time=0.130, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=3.455, loss=1.728, backward_time=0.175, optim_step_time=0.038, optim0_lr0=1.212e-04, train_time=0.863
[alab02] 2024-09-01 18:49:59,914 (trainer:720) INFO: 144epoch:train:2401-2600batch: iter_time=1.670e-04, forward_time=0.133, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.600, loss=1.800, backward_time=0.179, optim_step_time=0.035, optim0_lr0=1.212e-04, train_time=0.882
[alab02] 2024-09-01 18:51:28,555 (trainer:720) INFO: 144epoch:train:2601-2800batch: iter_time=1.709e-04, forward_time=0.133, uma_reduction=0.283, text_vs_uma=0.341, loss_ctc=3.250, loss=1.625, backward_time=0.188, optim_step_time=0.034, optim0_lr0=1.212e-04, train_time=0.886
[alab02] 2024-09-01 18:52:56,401 (trainer:720) INFO: 144epoch:train:2801-3000batch: iter_time=1.817e-04, forward_time=0.131, uma_reduction=0.278, text_vs_uma=0.348, loss_ctc=3.712, loss=1.856, backward_time=0.179, optim_step_time=0.036, optim0_lr0=1.212e-04, train_time=0.878
[alab02] 2024-09-01 18:54:33,129 (trainer:720) INFO: 144epoch:train:3001-3200batch: iter_time=2.786e-04, forward_time=0.151, uma_reduction=0.282, text_vs_uma=0.333, loss_ctc=3.227, loss=1.614, backward_time=0.195, optim_step_time=0.057, optim0_lr0=1.212e-04, train_time=0.967
[alab02] 2024-09-01 18:56:11,112 (trainer:720) INFO: 144epoch:train:3201-3400batch: iter_time=2.560e-04, forward_time=0.151, uma_reduction=0.283, text_vs_uma=0.340, loss_ctc=3.398, loss=1.699, backward_time=0.206, optim_step_time=0.053, optim0_lr0=1.211e-04, train_time=0.979
[alab02] 2024-09-01 18:57:45,972 (trainer:720) INFO: 144epoch:train:3401-3600batch: iter_time=2.478e-04, forward_time=0.146, uma_reduction=0.275, text_vs_uma=0.350, loss_ctc=3.314, loss=1.657, backward_time=0.199, optim_step_time=0.050, optim0_lr0=1.211e-04, train_time=0.948
[alab02] 2024-09-01 18:59:17,918 (trainer:720) INFO: 144epoch:train:3601-3800batch: iter_time=2.195e-04, forward_time=0.140, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.455, loss=1.727, backward_time=0.187, optim_step_time=0.047, optim0_lr0=1.211e-04, train_time=0.919
[alab02] 2024-09-01 19:00:47,629 (trainer:720) INFO: 144epoch:train:3801-4000batch: iter_time=1.880e-04, forward_time=0.137, uma_reduction=0.266, text_vs_uma=0.368, loss_ctc=3.655, loss=1.827, backward_time=0.182, optim_step_time=0.040, optim0_lr0=1.211e-04, train_time=0.897
[alab02] 2024-09-01 19:02:16,426 (trainer:720) INFO: 144epoch:train:4001-4200batch: iter_time=1.834e-04, forward_time=0.135, uma_reduction=0.282, text_vs_uma=0.344, loss_ctc=3.533, loss=1.766, backward_time=0.181, optim_step_time=0.038, optim0_lr0=1.211e-04, train_time=0.888
[alab02] 2024-09-01 19:03:47,541 (trainer:720) INFO: 144epoch:train:4201-4400batch: iter_time=1.778e-04, forward_time=0.137, uma_reduction=0.281, text_vs_uma=0.347, loss_ctc=3.408, loss=1.704, backward_time=0.188, optim_step_time=0.036, optim0_lr0=1.211e-04, train_time=0.911
[alab02] 2024-09-01 19:05:16,323 (trainer:720) INFO: 144epoch:train:4401-4600batch: iter_time=1.618e-04, forward_time=0.132, uma_reduction=0.288, text_vs_uma=0.331, loss_ctc=3.100, loss=1.550, backward_time=0.187, optim_step_time=0.034, optim0_lr0=1.211e-04, train_time=0.888
[alab02] 2024-09-01 19:06:44,496 (trainer:720) INFO: 144epoch:train:4601-4800batch: iter_time=1.563e-04, forward_time=0.132, uma_reduction=0.292, text_vs_uma=0.337, loss_ctc=3.392, loss=1.696, backward_time=0.185, optim_step_time=0.033, optim0_lr0=1.211e-04, train_time=0.881
[alab02] 2024-09-01 19:08:13,857 (trainer:720) INFO: 144epoch:train:4801-5000batch: iter_time=2.027e-04, forward_time=0.135, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.401, loss=1.701, backward_time=0.184, optim_step_time=0.041, optim0_lr0=1.210e-04, train_time=0.893
[alab02] 2024-09-01 19:09:47,068 (trainer:720) INFO: 144epoch:train:5001-5200batch: iter_time=2.484e-04, forward_time=0.143, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.156, loss=1.578, backward_time=0.193, optim_step_time=0.050, optim0_lr0=1.210e-04, train_time=0.932
[alab02] 2024-09-01 19:11:20,681 (trainer:720) INFO: 144epoch:train:5201-5400batch: iter_time=2.749e-04, forward_time=0.143, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.402, loss=1.701, backward_time=0.194, optim_step_time=0.049, optim0_lr0=1.210e-04, train_time=0.936
[alab02] 2024-09-01 19:12:52,621 (trainer:720) INFO: 144epoch:train:5401-5600batch: iter_time=2.305e-04, forward_time=0.141, uma_reduction=0.272, text_vs_uma=0.363, loss_ctc=3.635, loss=1.817, backward_time=0.183, optim_step_time=0.046, optim0_lr0=1.210e-04, train_time=0.919
[alab02] 2024-09-01 19:14:27,598 (trainer:720) INFO: 144epoch:train:5601-5800batch: iter_time=2.408e-04, forward_time=0.148, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.405, loss=1.702, backward_time=0.192, optim_step_time=0.051, optim0_lr0=1.210e-04, train_time=0.949
[alab02] 2024-09-01 19:16:03,035 (trainer:720) INFO: 144epoch:train:5801-6000batch: iter_time=2.486e-04, forward_time=0.146, uma_reduction=0.284, text_vs_uma=0.338, loss_ctc=3.208, loss=1.604, backward_time=0.199, optim_step_time=0.051, optim0_lr0=1.210e-04, train_time=0.954
[alab02] 2024-09-01 19:17:34,313 (trainer:720) INFO: 144epoch:train:6001-6200batch: iter_time=2.309e-04, forward_time=0.140, uma_reduction=0.278, text_vs_uma=0.347, loss_ctc=3.336, loss=1.668, backward_time=0.185, optim_step_time=0.050, optim0_lr0=1.210e-04, train_time=0.912
[alab02] 2024-09-01 19:19:08,985 (trainer:720) INFO: 144epoch:train:6201-6400batch: iter_time=2.616e-04, forward_time=0.145, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.492, loss=1.746, backward_time=0.193, optim_step_time=0.051, optim0_lr0=1.210e-04, train_time=0.946
[alab02] 2024-09-01 19:20:44,171 (trainer:720) INFO: 144epoch:train:6401-6600batch: iter_time=2.483e-04, forward_time=0.147, uma_reduction=0.281, text_vs_uma=0.351, loss_ctc=3.650, loss=1.825, backward_time=0.193, optim_step_time=0.052, optim0_lr0=1.210e-04, train_time=0.951
[alab02] 2024-09-01 19:22:16,846 (trainer:720) INFO: 144epoch:train:6601-6800batch: iter_time=2.259e-04, forward_time=0.143, uma_reduction=0.288, text_vs_uma=0.332, loss_ctc=3.118, loss=1.559, backward_time=0.190, optim_step_time=0.047, optim0_lr0=1.209e-04, train_time=0.926
[alab02] 2024-09-01 19:23:46,455 (trainer:720) INFO: 144epoch:train:6801-7000batch: iter_time=2.098e-04, forward_time=0.137, uma_reduction=0.289, text_vs_uma=0.327, loss_ctc=3.141, loss=1.571, backward_time=0.185, optim_step_time=0.043, optim0_lr0=1.209e-04, train_time=0.896
[alab02] 2024-09-01 19:25:09,233 (trainer:338) INFO: 144epoch results: [train] iter_time=2.720e-04, forward_time=0.140, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.397, loss=1.699, backward_time=0.188, optim_step_time=0.045, optim0_lr0=1.211e-04, train_time=0.917, time=54 minutes and 30.41 seconds, total_count=1026144, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.290, text_vs_uma=0.375, loss_ctc=3.048, cer_ctc=0.082, cer=0.082, loss=3.048, time=6.89 seconds, total_count=3744, gpu_max_cached_mem_GB=35.906, [att_plot] time=19.07 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 19:25:16,939 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 19:25:16,941 (trainer:272) INFO: 145/150epoch started. Estimated time to finish: 5 hours, 21 minutes and 12.22 seconds
[alab02] 2024-09-01 19:26:51,234 (trainer:720) INFO: 145epoch:train:1-200batch: iter_time=0.002, forward_time=0.142, uma_reduction=0.278, text_vs_uma=0.345, loss_ctc=3.327, loss=1.663, backward_time=0.195, optim_step_time=0.044, optim0_lr0=1.209e-04, train_time=0.942
[alab02] 2024-09-01 19:28:21,864 (trainer:720) INFO: 145epoch:train:201-400batch: iter_time=2.367e-04, forward_time=0.139, uma_reduction=0.266, text_vs_uma=0.375, loss_ctc=3.615, loss=1.807, backward_time=0.180, optim_step_time=0.043, optim0_lr0=1.209e-04, train_time=0.906
[alab02] 2024-09-01 19:29:53,619 (trainer:720) INFO: 145epoch:train:401-600batch: iter_time=2.443e-04, forward_time=0.142, uma_reduction=0.269, text_vs_uma=0.363, loss_ctc=3.648, loss=1.824, backward_time=0.184, optim_step_time=0.041, optim0_lr0=1.209e-04, train_time=0.917
[alab02] 2024-09-01 19:31:30,762 (trainer:720) INFO: 145epoch:train:601-800batch: iter_time=2.819e-04, forward_time=0.152, uma_reduction=0.272, text_vs_uma=0.348, loss_ctc=3.243, loss=1.622, backward_time=0.199, optim_step_time=0.053, optim0_lr0=1.209e-04, train_time=0.971
[alab02] 2024-09-01 19:33:05,546 (trainer:720) INFO: 145epoch:train:801-1000batch: iter_time=2.915e-04, forward_time=0.148, uma_reduction=0.272, text_vs_uma=0.362, loss_ctc=3.631, loss=1.815, backward_time=0.191, optim_step_time=0.051, optim0_lr0=1.209e-04, train_time=0.947
[alab02] 2024-09-01 19:34:39,309 (trainer:720) INFO: 145epoch:train:1001-1200batch: iter_time=2.787e-04, forward_time=0.145, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=3.453, loss=1.726, backward_time=0.193, optim_step_time=0.048, optim0_lr0=1.209e-04, train_time=0.937
[alab02] 2024-09-01 19:36:13,992 (trainer:720) INFO: 145epoch:train:1201-1400batch: iter_time=2.464e-04, forward_time=0.145, uma_reduction=0.269, text_vs_uma=0.368, loss_ctc=3.490, loss=1.745, backward_time=0.194, optim_step_time=0.046, optim0_lr0=1.208e-04, train_time=0.946
[alab02] 2024-09-01 19:37:47,219 (trainer:720) INFO: 145epoch:train:1401-1600batch: iter_time=2.182e-04, forward_time=0.143, uma_reduction=0.280, text_vs_uma=0.342, loss_ctc=3.231, loss=1.616, backward_time=0.194, optim_step_time=0.044, optim0_lr0=1.208e-04, train_time=0.932
[alab02] 2024-09-01 19:39:16,204 (trainer:720) INFO: 145epoch:train:1601-1800batch: iter_time=2.287e-04, forward_time=0.136, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=3.386, loss=1.693, backward_time=0.182, optim_step_time=0.042, optim0_lr0=1.208e-04, train_time=0.890
[alab02] 2024-09-01 19:40:46,003 (trainer:720) INFO: 145epoch:train:1801-2000batch: iter_time=2.099e-04, forward_time=0.136, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.290, loss=1.645, backward_time=0.184, optim_step_time=0.041, optim0_lr0=1.208e-04, train_time=0.898
[alab02] 2024-09-01 19:42:15,046 (trainer:720) INFO: 145epoch:train:2001-2200batch: iter_time=2.056e-04, forward_time=0.135, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=3.404, loss=1.702, backward_time=0.181, optim_step_time=0.037, optim0_lr0=1.208e-04, train_time=0.890
[alab02] 2024-09-01 19:43:44,010 (trainer:720) INFO: 145epoch:train:2201-2400batch: iter_time=1.799e-04, forward_time=0.136, uma_reduction=0.286, text_vs_uma=0.337, loss_ctc=3.409, loss=1.705, backward_time=0.184, optim_step_time=0.034, optim0_lr0=1.208e-04, train_time=0.889
[alab02] 2024-09-01 19:44:09,327 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 19:45:10,143 (trainer:720) INFO: 145epoch:train:2401-2600batch: iter_time=1.666e-04, forward_time=0.130, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=3.189, loss=1.594, backward_time=0.182, optim_step_time=0.031, optim0_lr0=1.208e-04, train_time=0.861
[alab02] 2024-09-01 19:46:36,724 (trainer:720) INFO: 145epoch:train:2601-2800batch: iter_time=1.722e-04, forward_time=0.130, uma_reduction=0.280, text_vs_uma=0.331, loss_ctc=3.085, loss=1.543, backward_time=0.182, optim_step_time=0.032, optim0_lr0=1.208e-04, train_time=0.866
[alab02] 2024-09-01 19:48:04,929 (trainer:720) INFO: 145epoch:train:2801-3000batch: iter_time=1.659e-04, forward_time=0.131, uma_reduction=0.275, text_vs_uma=0.355, loss_ctc=3.612, loss=1.806, backward_time=0.183, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.882
[alab02] 2024-09-01 19:49:33,184 (trainer:720) INFO: 145epoch:train:3001-3200batch: iter_time=1.661e-04, forward_time=0.131, uma_reduction=0.279, text_vs_uma=0.349, loss_ctc=3.224, loss=1.612, backward_time=0.188, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.882
[alab02] 2024-09-01 19:50:59,326 (trainer:720) INFO: 145epoch:train:3201-3400batch: iter_time=1.641e-04, forward_time=0.129, uma_reduction=0.279, text_vs_uma=0.355, loss_ctc=3.355, loss=1.678, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.207e-04, train_time=0.861
[alab02] 2024-09-01 19:52:25,446 (trainer:720) INFO: 145epoch:train:3401-3600batch: iter_time=1.560e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.463, loss=1.732, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.861
[alab02] 2024-09-01 19:53:52,398 (trainer:720) INFO: 145epoch:train:3601-3800batch: iter_time=1.975e-04, forward_time=0.131, uma_reduction=0.288, text_vs_uma=0.332, loss_ctc=3.352, loss=1.676, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.869
[alab02] 2024-09-01 19:55:19,565 (trainer:720) INFO: 145epoch:train:3801-4000batch: iter_time=1.887e-04, forward_time=0.131, uma_reduction=0.285, text_vs_uma=0.344, loss_ctc=3.565, loss=1.783, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.871
[alab02] 2024-09-01 19:56:46,883 (trainer:720) INFO: 145epoch:train:4001-4200batch: iter_time=1.642e-04, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.340, loss_ctc=3.565, loss=1.783, backward_time=0.179, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.873
[alab02] 2024-09-01 19:58:14,411 (trainer:720) INFO: 145epoch:train:4201-4400batch: iter_time=1.606e-04, forward_time=0.130, uma_reduction=0.287, text_vs_uma=0.343, loss_ctc=3.482, loss=1.741, backward_time=0.182, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.875
[alab02] 2024-09-01 19:59:41,875 (trainer:720) INFO: 145epoch:train:4401-4600batch: iter_time=1.833e-04, forward_time=0.131, uma_reduction=0.282, text_vs_uma=0.340, loss_ctc=3.227, loss=1.614, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.207e-04, train_time=0.874
[alab02] 2024-09-01 20:01:08,906 (trainer:720) INFO: 145epoch:train:4601-4800batch: iter_time=1.609e-04, forward_time=0.130, uma_reduction=0.286, text_vs_uma=0.349, loss_ctc=3.658, loss=1.829, backward_time=0.178, optim_step_time=0.033, optim0_lr0=1.206e-04, train_time=0.870
[alab02] 2024-09-01 20:02:38,971 (trainer:720) INFO: 145epoch:train:4801-5000batch: iter_time=1.831e-04, forward_time=0.135, uma_reduction=0.286, text_vs_uma=0.346, loss_ctc=3.643, loss=1.821, backward_time=0.187, optim_step_time=0.033, optim0_lr0=1.206e-04, train_time=0.900
[alab02] 2024-09-01 20:04:05,156 (trainer:720) INFO: 145epoch:train:5001-5200batch: iter_time=1.662e-04, forward_time=0.129, uma_reduction=0.286, text_vs_uma=0.340, loss_ctc=3.645, loss=1.823, backward_time=0.178, optim_step_time=0.034, optim0_lr0=1.206e-04, train_time=0.862
[alab02] 2024-09-01 20:05:31,912 (trainer:720) INFO: 145epoch:train:5201-5400batch: iter_time=1.467e-04, forward_time=0.129, uma_reduction=0.285, text_vs_uma=0.342, loss_ctc=3.444, loss=1.722, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.206e-04, train_time=0.867
[alab02] 2024-09-01 20:06:56,520 (trainer:720) INFO: 145epoch:train:5401-5600batch: iter_time=1.482e-04, forward_time=0.125, uma_reduction=0.291, text_vs_uma=0.340, loss_ctc=3.515, loss=1.758, backward_time=0.173, optim_step_time=0.032, optim0_lr0=1.206e-04, train_time=0.846
[alab02] 2024-09-01 20:08:25,524 (trainer:720) INFO: 145epoch:train:5601-5800batch: iter_time=1.672e-04, forward_time=0.133, uma_reduction=0.294, text_vs_uma=0.331, loss_ctc=3.249, loss=1.625, backward_time=0.187, optim_step_time=0.032, optim0_lr0=1.206e-04, train_time=0.890
[alab02] 2024-09-01 20:09:54,358 (trainer:720) INFO: 145epoch:train:5801-6000batch: iter_time=1.602e-04, forward_time=0.133, uma_reduction=0.292, text_vs_uma=0.325, loss_ctc=3.334, loss=1.667, backward_time=0.184, optim_step_time=0.033, optim0_lr0=1.206e-04, train_time=0.888
[alab02] 2024-09-01 20:11:22,503 (trainer:720) INFO: 145epoch:train:6001-6200batch: iter_time=1.478e-04, forward_time=0.133, uma_reduction=0.287, text_vs_uma=0.339, loss_ctc=3.547, loss=1.773, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.206e-04, train_time=0.881
[alab02] 2024-09-01 20:12:49,786 (trainer:720) INFO: 145epoch:train:6201-6400batch: iter_time=1.502e-04, forward_time=0.130, uma_reduction=0.282, text_vs_uma=0.338, loss_ctc=3.451, loss=1.725, backward_time=0.181, optim_step_time=0.033, optim0_lr0=1.205e-04, train_time=0.873
[alab02] 2024-09-01 20:14:15,759 (trainer:720) INFO: 145epoch:train:6401-6600batch: iter_time=1.631e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.349, loss=1.674, backward_time=0.179, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.859
[alab02] 2024-09-01 20:15:43,232 (trainer:720) INFO: 145epoch:train:6601-6800batch: iter_time=1.412e-04, forward_time=0.130, uma_reduction=0.284, text_vs_uma=0.347, loss_ctc=3.653, loss=1.826, backward_time=0.181, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.875
[alab02] 2024-09-01 20:17:09,630 (trainer:720) INFO: 145epoch:train:6801-7000batch: iter_time=1.477e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.850, loss=1.925, backward_time=0.176, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.864
[alab02] 2024-09-01 20:18:22,929 (trainer:338) INFO: 145epoch results: [train] iter_time=2.488e-04, forward_time=0.134, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.444, loss=1.722, backward_time=0.183, optim_step_time=0.036, optim0_lr0=1.207e-04, train_time=0.888, time=52 minutes and 46.45 seconds, total_count=1033270, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.308, text_vs_uma=0.353, loss_ctc=2.838, cer_ctc=0.078, cer=0.078, loss=2.838, time=5.95 seconds, total_count=3770, gpu_max_cached_mem_GB=35.906, [att_plot] time=13.59 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 20:18:34,818 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 20:18:34,932 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/140epoch.pth, exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/144epoch.pth
[alab02] 2024-09-01 20:18:34,932 (trainer:272) INFO: 146/150epoch started. Estimated time to finish: 4 hours, 27 minutes and 39.7 seconds
[alab02] 2024-09-01 20:20:01,134 (trainer:720) INFO: 146epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.289, text_vs_uma=0.334, loss_ctc=3.344, loss=1.672, backward_time=0.178, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.862
[alab02] 2024-09-01 20:21:28,517 (trainer:720) INFO: 146epoch:train:201-400batch: iter_time=1.582e-04, forward_time=0.130, uma_reduction=0.288, text_vs_uma=0.332, loss_ctc=3.059, loss=1.530, backward_time=0.184, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.874
[alab02] 2024-09-01 20:22:53,248 (trainer:720) INFO: 146epoch:train:401-600batch: iter_time=1.807e-04, forward_time=0.125, uma_reduction=0.288, text_vs_uma=0.332, loss_ctc=3.280, loss=1.640, backward_time=0.177, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.847
[alab02] 2024-09-01 20:24:19,191 (trainer:720) INFO: 146epoch:train:601-800batch: iter_time=1.552e-04, forward_time=0.127, uma_reduction=0.290, text_vs_uma=0.338, loss_ctc=3.221, loss=1.610, backward_time=0.180, optim_step_time=0.032, optim0_lr0=1.205e-04, train_time=0.859
[alab02] 2024-09-01 20:25:45,252 (trainer:720) INFO: 146epoch:train:801-1000batch: iter_time=1.426e-04, forward_time=0.127, uma_reduction=0.283, text_vs_uma=0.343, loss_ctc=3.547, loss=1.773, backward_time=0.177, optim_step_time=0.031, optim0_lr0=1.204e-04, train_time=0.860
[alab02] 2024-09-01 20:27:11,433 (trainer:720) INFO: 146epoch:train:1001-1200batch: iter_time=1.450e-04, forward_time=0.127, uma_reduction=0.285, text_vs_uma=0.333, loss_ctc=3.268, loss=1.634, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.204e-04, train_time=0.862
[alab02] 2024-09-01 20:28:36,047 (trainer:720) INFO: 146epoch:train:1201-1400batch: iter_time=1.468e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.339, loss_ctc=3.076, loss=1.538, backward_time=0.178, optim_step_time=0.031, optim0_lr0=1.204e-04, train_time=0.846
[alab02] 2024-09-01 20:29:59,790 (trainer:720) INFO: 146epoch:train:1401-1600batch: iter_time=1.456e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.349, loss_ctc=3.279, loss=1.639, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.204e-04, train_time=0.837
[alab02] 2024-09-01 20:31:24,080 (trainer:720) INFO: 146epoch:train:1601-1800batch: iter_time=1.274e-04, forward_time=0.124, uma_reduction=0.280, text_vs_uma=0.344, loss_ctc=3.542, loss=1.771, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.204e-04, train_time=0.843
[alab02] 2024-09-01 20:32:51,440 (trainer:720) INFO: 146epoch:train:1801-2000batch: iter_time=1.238e-04, forward_time=0.128, uma_reduction=0.286, text_vs_uma=0.346, loss_ctc=3.142, loss=1.571, backward_time=0.188, optim_step_time=0.028, optim0_lr0=1.204e-04, train_time=0.873
[alab02] 2024-09-01 20:33:00,209 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 20:34:17,832 (trainer:720) INFO: 146epoch:train:2001-2200batch: iter_time=1.291e-04, forward_time=0.128, uma_reduction=0.279, text_vs_uma=0.348, loss_ctc=3.344, loss=1.672, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.204e-04, train_time=0.864
[alab02] 2024-09-01 20:35:42,251 (trainer:720) INFO: 146epoch:train:2201-2400batch: iter_time=1.176e-04, forward_time=0.124, uma_reduction=0.274, text_vs_uma=0.356, loss_ctc=3.427, loss=1.713, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.204e-04, train_time=0.844
[alab02] 2024-09-01 20:37:09,057 (trainer:720) INFO: 146epoch:train:2401-2600batch: iter_time=1.296e-04, forward_time=0.128, uma_reduction=0.283, text_vs_uma=0.333, loss_ctc=3.396, loss=1.698, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.204e-04, train_time=0.868
[alab02] 2024-09-01 20:38:32,881 (trainer:720) INFO: 146epoch:train:2601-2800batch: iter_time=1.352e-04, forward_time=0.123, uma_reduction=0.275, text_vs_uma=0.360, loss_ctc=3.402, loss=1.701, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.203e-04, train_time=0.838
[alab02] 2024-09-01 20:39:59,368 (trainer:720) INFO: 146epoch:train:2801-3000batch: iter_time=1.218e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.367, loss_ctc=3.597, loss=1.799, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.203e-04, train_time=0.865
[alab02] 2024-09-01 20:41:24,851 (trainer:720) INFO: 146epoch:train:3001-3200batch: iter_time=1.166e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.202, loss=1.601, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.203e-04, train_time=0.855
[alab02] 2024-09-01 20:42:49,038 (trainer:720) INFO: 146epoch:train:3201-3400batch: iter_time=1.213e-04, forward_time=0.124, uma_reduction=0.259, text_vs_uma=0.380, loss_ctc=3.230, loss=1.615, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.203e-04, train_time=0.842
[alab02] 2024-09-01 20:44:12,364 (trainer:720) INFO: 146epoch:train:3401-3600batch: iter_time=1.252e-04, forward_time=0.122, uma_reduction=0.273, text_vs_uma=0.366, loss_ctc=3.570, loss=1.785, backward_time=0.172, optim_step_time=0.029, optim0_lr0=1.203e-04, train_time=0.833
[alab02] 2024-09-01 20:45:36,169 (trainer:720) INFO: 146epoch:train:3601-3800batch: iter_time=1.247e-04, forward_time=0.123, uma_reduction=0.271, text_vs_uma=0.357, loss_ctc=2.997, loss=1.499, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.203e-04, train_time=0.838
[alab02] 2024-09-01 20:47:03,152 (trainer:720) INFO: 146epoch:train:3801-4000batch: iter_time=1.132e-04, forward_time=0.127, uma_reduction=0.270, text_vs_uma=0.365, loss_ctc=3.548, loss=1.774, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.203e-04, train_time=0.870
[alab02] 2024-09-01 20:48:27,965 (trainer:720) INFO: 146epoch:train:4001-4200batch: iter_time=1.223e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.360, loss_ctc=3.522, loss=1.761, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.203e-04, train_time=0.848
[alab02] 2024-09-01 20:49:54,229 (trainer:720) INFO: 146epoch:train:4201-4400batch: iter_time=1.169e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.343, loss_ctc=3.055, loss=1.527, backward_time=0.184, optim_step_time=0.029, optim0_lr0=1.203e-04, train_time=0.862
[alab02] 2024-09-01 20:51:19,581 (trainer:720) INFO: 146epoch:train:4401-4600batch: iter_time=1.095e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.356, loss_ctc=3.627, loss=1.814, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.202e-04, train_time=0.853
[alab02] 2024-09-01 20:52:44,854 (trainer:720) INFO: 146epoch:train:4601-4800batch: iter_time=9.846e-05, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.344, loss_ctc=3.285, loss=1.643, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.202e-04, train_time=0.853
[alab02] 2024-09-01 20:54:11,131 (trainer:720) INFO: 146epoch:train:4801-5000batch: iter_time=1.175e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.341, loss_ctc=3.266, loss=1.633, backward_time=0.183, optim_step_time=0.029, optim0_lr0=1.202e-04, train_time=0.863
[alab02] 2024-09-01 20:55:36,854 (trainer:720) INFO: 146epoch:train:5001-5200batch: iter_time=1.273e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.310, loss=1.655, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.202e-04, train_time=0.857
[alab02] 2024-09-01 20:57:03,220 (trainer:720) INFO: 146epoch:train:5201-5400batch: iter_time=1.213e-04, forward_time=0.127, uma_reduction=0.278, text_vs_uma=0.352, loss_ctc=3.416, loss=1.708, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.202e-04, train_time=0.863
[alab02] 2024-09-01 20:58:28,092 (trainer:720) INFO: 146epoch:train:5401-5600batch: iter_time=1.137e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.460, loss=1.730, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.202e-04, train_time=0.849
[alab02] 2024-09-01 20:59:55,952 (trainer:720) INFO: 146epoch:train:5601-5800batch: iter_time=1.221e-04, forward_time=0.130, uma_reduction=0.279, text_vs_uma=0.345, loss_ctc=3.504, loss=1.752, backward_time=0.183, optim_step_time=0.029, optim0_lr0=1.202e-04, train_time=0.878
[alab02] 2024-09-01 21:01:20,498 (trainer:720) INFO: 146epoch:train:5801-6000batch: iter_time=1.124e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.352, loss_ctc=3.227, loss=1.614, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.202e-04, train_time=0.845
[alab02] 2024-09-01 21:02:43,827 (trainer:720) INFO: 146epoch:train:6001-6200batch: iter_time=1.245e-04, forward_time=0.123, uma_reduction=0.285, text_vs_uma=0.343, loss_ctc=3.177, loss=1.588, backward_time=0.173, optim_step_time=0.029, optim0_lr0=1.201e-04, train_time=0.833
[alab02] 2024-09-01 21:04:08,823 (trainer:720) INFO: 146epoch:train:6201-6400batch: iter_time=1.155e-04, forward_time=0.125, uma_reduction=0.282, text_vs_uma=0.348, loss_ctc=3.406, loss=1.703, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.201e-04, train_time=0.850
[alab02] 2024-09-01 21:05:32,672 (trainer:720) INFO: 146epoch:train:6401-6600batch: iter_time=1.222e-04, forward_time=0.123, uma_reduction=0.279, text_vs_uma=0.338, loss_ctc=3.265, loss=1.633, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.201e-04, train_time=0.838
[alab02] 2024-09-01 21:06:57,723 (trainer:720) INFO: 146epoch:train:6601-6800batch: iter_time=1.293e-04, forward_time=0.125, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.222, loss=1.611, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.201e-04, train_time=0.850
[alab02] 2024-09-01 21:08:21,112 (trainer:720) INFO: 146epoch:train:6801-7000batch: iter_time=1.112e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.347, loss_ctc=3.343, loss=1.672, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.201e-04, train_time=0.834
[alab02] 2024-09-01 21:09:33,554 (trainer:338) INFO: 146epoch results: [train] iter_time=1.698e-04, forward_time=0.126, uma_reduction=0.278, text_vs_uma=0.349, loss_ctc=3.329, loss=1.665, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.203e-04, train_time=0.853, time=50 minutes and 41.19 seconds, total_count=1040396, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.290, text_vs_uma=0.375, loss_ctc=2.966, cer_ctc=0.078, cer=0.078, loss=2.966, time=5.7 seconds, total_count=3796, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.73 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 21:09:38,422 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 21:09:38,435 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/135epoch.pth
[alab02] 2024-09-01 21:09:38,436 (trainer:272) INFO: 147/150epoch started. Estimated time to finish: 3 hours, 34 minutes and 3.69 seconds
[alab02] 2024-09-01 21:11:04,521 (trainer:720) INFO: 147epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.275, text_vs_uma=0.341, loss_ctc=3.102, loss=1.551, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.201e-04, train_time=0.860
[alab02] 2024-09-01 21:12:29,012 (trainer:720) INFO: 147epoch:train:201-400batch: iter_time=1.048e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.354, loss_ctc=3.512, loss=1.756, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.201e-04, train_time=0.845
[alab02] 2024-09-01 21:13:53,424 (trainer:720) INFO: 147epoch:train:401-600batch: iter_time=1.093e-04, forward_time=0.123, uma_reduction=0.264, text_vs_uma=0.374, loss_ctc=3.416, loss=1.708, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.201e-04, train_time=0.844
[alab02] 2024-09-01 21:15:17,600 (trainer:720) INFO: 147epoch:train:601-800batch: iter_time=1.324e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.364, loss_ctc=3.661, loss=1.830, backward_time=0.173, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.842
[alab02] 2024-09-01 21:16:43,463 (trainer:720) INFO: 147epoch:train:801-1000batch: iter_time=1.257e-04, forward_time=0.126, uma_reduction=0.270, text_vs_uma=0.357, loss_ctc=3.319, loss=1.659, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.858
[alab02] 2024-09-01 21:18:08,275 (trainer:720) INFO: 147epoch:train:1001-1200batch: iter_time=1.205e-04, forward_time=0.125, uma_reduction=0.281, text_vs_uma=0.346, loss_ctc=3.061, loss=1.531, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.200e-04, train_time=0.848
[alab02] 2024-09-01 21:18:57,547 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 21:19:35,124 (trainer:720) INFO: 147epoch:train:1201-1400batch: iter_time=1.242e-04, forward_time=0.128, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=3.548, loss=1.774, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.868
[alab02] 2024-09-01 21:20:59,767 (trainer:720) INFO: 147epoch:train:1401-1600batch: iter_time=1.210e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.362, loss_ctc=3.377, loss=1.689, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.846
[alab02] 2024-09-01 21:22:24,570 (trainer:720) INFO: 147epoch:train:1601-1800batch: iter_time=1.196e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.545, loss=1.773, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.848
[alab02] 2024-09-01 21:23:49,378 (trainer:720) INFO: 147epoch:train:1801-2000batch: iter_time=1.284e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.357, loss_ctc=3.337, loss=1.669, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.200e-04, train_time=0.848
[alab02] 2024-09-01 21:25:14,909 (trainer:720) INFO: 147epoch:train:2001-2200batch: iter_time=1.215e-04, forward_time=0.126, uma_reduction=0.271, text_vs_uma=0.362, loss_ctc=3.441, loss=1.721, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.855
[alab02] 2024-09-01 21:26:40,569 (trainer:720) INFO: 147epoch:train:2201-2400batch: iter_time=1.152e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.243, loss=1.621, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.200e-04, train_time=0.856
[alab02] 2024-09-01 21:28:02,655 (trainer:720) INFO: 147epoch:train:2401-2600batch: iter_time=1.154e-04, forward_time=0.120, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.374, loss=1.687, backward_time=0.168, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.821
[alab02] 2024-09-01 21:29:26,781 (trainer:720) INFO: 147epoch:train:2601-2800batch: iter_time=1.216e-04, forward_time=0.123, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.311, loss=1.655, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.841
[alab02] 2024-09-01 21:30:51,497 (trainer:720) INFO: 147epoch:train:2801-3000batch: iter_time=1.206e-04, forward_time=0.124, uma_reduction=0.269, text_vs_uma=0.362, loss_ctc=3.436, loss=1.718, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.199e-04, train_time=0.847
[alab02] 2024-09-01 21:32:16,184 (trainer:720) INFO: 147epoch:train:3001-3200batch: iter_time=1.056e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.358, loss_ctc=3.261, loss=1.631, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.847
[alab02] 2024-09-01 21:33:42,417 (trainer:720) INFO: 147epoch:train:3201-3400batch: iter_time=9.702e-05, forward_time=0.126, uma_reduction=0.287, text_vs_uma=0.329, loss_ctc=3.063, loss=1.531, backward_time=0.186, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.862
[alab02] 2024-09-01 21:35:07,065 (trainer:720) INFO: 147epoch:train:3401-3600batch: iter_time=1.094e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.683, loss=1.841, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.846
[alab02] 2024-09-01 21:36:31,344 (trainer:720) INFO: 147epoch:train:3601-3800batch: iter_time=1.278e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.476, loss=1.738, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.199e-04, train_time=0.843
[alab02] 2024-09-01 21:37:57,307 (trainer:720) INFO: 147epoch:train:3801-4000batch: iter_time=1.279e-04, forward_time=0.126, uma_reduction=0.269, text_vs_uma=0.358, loss_ctc=3.438, loss=1.719, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.859
[alab02] 2024-09-01 21:39:21,564 (trainer:720) INFO: 147epoch:train:4001-4200batch: iter_time=1.189e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.351, loss_ctc=3.478, loss=1.739, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.199e-04, train_time=0.842
[alab02] 2024-09-01 21:40:46,990 (trainer:720) INFO: 147epoch:train:4201-4400batch: iter_time=1.247e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.445, loss=1.723, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.198e-04, train_time=0.854
[alab02] 2024-09-01 21:42:10,755 (trainer:720) INFO: 147epoch:train:4401-4600batch: iter_time=1.270e-04, forward_time=0.124, uma_reduction=0.266, text_vs_uma=0.373, loss_ctc=3.409, loss=1.704, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.198e-04, train_time=0.837
[alab02] 2024-09-01 21:43:34,711 (trainer:720) INFO: 147epoch:train:4601-4800batch: iter_time=1.302e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.366, loss_ctc=3.352, loss=1.676, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.198e-04, train_time=0.839
[alab02] 2024-09-01 21:45:00,138 (trainer:720) INFO: 147epoch:train:4801-5000batch: iter_time=1.243e-04, forward_time=0.125, uma_reduction=0.262, text_vs_uma=0.363, loss_ctc=3.489, loss=1.745, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.198e-04, train_time=0.854
[alab02] 2024-09-01 21:46:24,134 (trainer:720) INFO: 147epoch:train:5001-5200batch: iter_time=1.440e-04, forward_time=0.123, uma_reduction=0.261, text_vs_uma=0.370, loss_ctc=3.625, loss=1.813, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.198e-04, train_time=0.840
[alab02] 2024-09-01 21:47:48,551 (trainer:720) INFO: 147epoch:train:5201-5400batch: iter_time=1.451e-04, forward_time=0.124, uma_reduction=0.257, text_vs_uma=0.385, loss_ctc=3.555, loss=1.777, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.198e-04, train_time=0.844
[alab02] 2024-09-01 21:47:58,536 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 21:49:13,865 (trainer:720) INFO: 147epoch:train:5401-5600batch: iter_time=1.419e-04, forward_time=0.126, uma_reduction=0.262, text_vs_uma=0.372, loss_ctc=3.598, loss=1.799, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.198e-04, train_time=0.853
[alab02] 2024-09-01 21:50:39,145 (trainer:720) INFO: 147epoch:train:5601-5800batch: iter_time=1.593e-04, forward_time=0.125, uma_reduction=0.263, text_vs_uma=0.369, loss_ctc=3.440, loss=1.720, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.198e-04, train_time=0.853
[alab02] 2024-09-01 21:52:05,589 (trainer:720) INFO: 147epoch:train:5801-6000batch: iter_time=1.563e-04, forward_time=0.127, uma_reduction=0.269, text_vs_uma=0.359, loss_ctc=3.462, loss=1.731, backward_time=0.183, optim_step_time=0.029, optim0_lr0=1.197e-04, train_time=0.864
[alab02] 2024-09-01 21:53:27,316 (trainer:720) INFO: 147epoch:train:6001-6200batch: iter_time=1.447e-04, forward_time=0.120, uma_reduction=0.272, text_vs_uma=0.364, loss_ctc=3.441, loss=1.721, backward_time=0.169, optim_step_time=0.029, optim0_lr0=1.197e-04, train_time=0.817
[alab02] 2024-09-01 21:54:53,526 (trainer:720) INFO: 147epoch:train:6201-6400batch: iter_time=1.403e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.347, loss_ctc=3.481, loss=1.741, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.197e-04, train_time=0.862
[alab02] 2024-09-01 21:56:16,433 (trainer:720) INFO: 147epoch:train:6401-6600batch: iter_time=1.280e-04, forward_time=0.121, uma_reduction=0.267, text_vs_uma=0.357, loss_ctc=3.544, loss=1.772, backward_time=0.171, optim_step_time=0.029, optim0_lr0=1.197e-04, train_time=0.829
[alab02] 2024-09-01 21:57:42,726 (trainer:720) INFO: 147epoch:train:6601-6800batch: iter_time=1.195e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.342, loss_ctc=3.323, loss=1.662, backward_time=0.183, optim_step_time=0.028, optim0_lr0=1.197e-04, train_time=0.863
[alab02] 2024-09-01 21:59:06,869 (trainer:720) INFO: 147epoch:train:6801-7000batch: iter_time=1.261e-04, forward_time=0.123, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.342, loss=1.671, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.197e-04, train_time=0.841
[alab02] 2024-09-01 22:00:19,546 (trainer:338) INFO: 147epoch results: [train] iter_time=1.778e-04, forward_time=0.124, uma_reduction=0.271, text_vs_uma=0.358, loss_ctc=3.417, loss=1.708, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.199e-04, train_time=0.848, time=50 minutes and 22.99 seconds, total_count=1047522, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.302, text_vs_uma=0.360, loss_ctc=2.957, cer_ctc=0.082, cer=0.082, loss=2.957, time=5.78 seconds, total_count=3822, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.35 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 22:00:27,201 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 22:00:27,202 (trainer:272) INFO: 148/150epoch started. Estimated time to finish: 2 hours, 40 minutes and 29.46 seconds
[alab02] 2024-09-01 22:01:51,548 (trainer:720) INFO: 148epoch:train:1-200batch: iter_time=0.002, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.348, loss_ctc=3.497, loss=1.749, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.197e-04, train_time=0.843
[alab02] 2024-09-01 22:03:17,015 (trainer:720) INFO: 148epoch:train:201-400batch: iter_time=1.309e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.348, loss_ctc=3.231, loss=1.615, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.197e-04, train_time=0.855
[alab02] 2024-09-01 22:04:42,323 (trainer:720) INFO: 148epoch:train:401-600batch: iter_time=1.395e-04, forward_time=0.125, uma_reduction=0.270, text_vs_uma=0.363, loss_ctc=3.352, loss=1.676, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.196e-04, train_time=0.853
[alab02] 2024-09-01 22:06:09,057 (trainer:720) INFO: 148epoch:train:601-800batch: iter_time=1.379e-04, forward_time=0.127, uma_reduction=0.268, text_vs_uma=0.366, loss_ctc=3.858, loss=1.929, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.196e-04, train_time=0.867
[alab02] 2024-09-01 22:07:32,752 (trainer:720) INFO: 148epoch:train:801-1000batch: iter_time=1.178e-04, forward_time=0.123, uma_reduction=0.275, text_vs_uma=0.348, loss_ctc=3.154, loss=1.577, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.196e-04, train_time=0.837
[alab02] 2024-09-01 22:08:58,173 (trainer:720) INFO: 148epoch:train:1001-1200batch: iter_time=1.312e-04, forward_time=0.125, uma_reduction=0.268, text_vs_uma=0.364, loss_ctc=3.575, loss=1.788, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.196e-04, train_time=0.854
[alab02] 2024-09-01 22:10:23,506 (trainer:720) INFO: 148epoch:train:1201-1400batch: iter_time=1.260e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.245, loss=1.622, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.196e-04, train_time=0.853
[alab02] 2024-09-01 22:11:48,205 (trainer:720) INFO: 148epoch:train:1401-1600batch: iter_time=1.223e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.336, loss=1.668, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.196e-04, train_time=0.847
[alab02] 2024-09-01 22:13:13,267 (trainer:720) INFO: 148epoch:train:1601-1800batch: iter_time=1.100e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.350, loss_ctc=3.345, loss=1.672, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.196e-04, train_time=0.850
[alab02] 2024-09-01 22:14:36,879 (trainer:720) INFO: 148epoch:train:1801-2000batch: iter_time=1.020e-04, forward_time=0.123, uma_reduction=0.283, text_vs_uma=0.344, loss_ctc=3.072, loss=1.536, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.196e-04, train_time=0.836
[alab02] 2024-09-01 22:16:01,660 (trainer:720) INFO: 148epoch:train:2001-2200batch: iter_time=1.176e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.369, loss_ctc=3.468, loss=1.734, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.196e-04, train_time=0.848
[alab02] 2024-09-01 22:17:27,540 (trainer:720) INFO: 148epoch:train:2201-2400batch: iter_time=1.258e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.502, loss=1.751, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.859
[alab02] 2024-09-01 22:18:53,355 (trainer:720) INFO: 148epoch:train:2401-2600batch: iter_time=1.250e-04, forward_time=0.126, uma_reduction=0.275, text_vs_uma=0.350, loss_ctc=3.007, loss=1.503, backward_time=0.184, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.858
[alab02] 2024-09-01 22:20:19,043 (trainer:720) INFO: 148epoch:train:2601-2800batch: iter_time=1.287e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.352, loss_ctc=3.264, loss=1.632, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.857
[alab02] 2024-09-01 22:21:44,308 (trainer:720) INFO: 148epoch:train:2801-3000batch: iter_time=1.263e-04, forward_time=0.125, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.340, loss=1.670, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.852
[alab02] 2024-09-01 22:23:10,471 (trainer:720) INFO: 148epoch:train:3001-3200batch: iter_time=1.210e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.256, loss=1.628, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.195e-04, train_time=0.861
[alab02] 2024-09-01 22:24:33,332 (trainer:720) INFO: 148epoch:train:3201-3400batch: iter_time=1.232e-04, forward_time=0.121, uma_reduction=0.282, text_vs_uma=0.350, loss_ctc=3.185, loss=1.592, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.195e-04, train_time=0.828
[alab02] 2024-09-01 22:25:57,119 (trainer:720) INFO: 148epoch:train:3401-3600batch: iter_time=1.248e-04, forward_time=0.123, uma_reduction=0.288, text_vs_uma=0.332, loss_ctc=3.039, loss=1.520, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.838
[alab02] 2024-09-01 22:26:33,063 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 22:27:19,579 (trainer:720) INFO: 148epoch:train:3601-3800batch: iter_time=1.147e-04, forward_time=0.121, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.220, loss=1.610, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.195e-04, train_time=0.824
[alab02] 2024-09-01 22:28:46,578 (trainer:720) INFO: 148epoch:train:3801-4000batch: iter_time=1.266e-04, forward_time=0.128, uma_reduction=0.263, text_vs_uma=0.374, loss_ctc=3.648, loss=1.824, backward_time=0.183, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.870
[alab02] 2024-09-01 22:30:09,770 (trainer:720) INFO: 148epoch:train:4001-4200batch: iter_time=1.234e-04, forward_time=0.122, uma_reduction=0.273, text_vs_uma=0.351, loss_ctc=3.247, loss=1.623, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.194e-04, train_time=0.832
[alab02] 2024-09-01 22:31:36,184 (trainer:720) INFO: 148epoch:train:4201-4400batch: iter_time=1.384e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.342, loss_ctc=3.419, loss=1.709, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.194e-04, train_time=0.864
[alab02] 2024-09-01 22:32:59,844 (trainer:720) INFO: 148epoch:train:4401-4600batch: iter_time=1.354e-04, forward_time=0.123, uma_reduction=0.287, text_vs_uma=0.338, loss_ctc=3.437, loss=1.719, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.194e-04, train_time=0.836
[alab02] 2024-09-01 22:34:22,611 (trainer:720) INFO: 148epoch:train:4601-4800batch: iter_time=1.178e-04, forward_time=0.121, uma_reduction=0.280, text_vs_uma=0.349, loss_ctc=3.285, loss=1.643, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.194e-04, train_time=0.827
[alab02] 2024-09-01 22:35:47,506 (trainer:720) INFO: 148epoch:train:4801-5000batch: iter_time=1.091e-04, forward_time=0.125, uma_reduction=0.266, text_vs_uma=0.355, loss_ctc=3.320, loss=1.660, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.194e-04, train_time=0.849
[alab02] 2024-09-01 22:37:12,767 (trainer:720) INFO: 148epoch:train:5001-5200batch: iter_time=1.302e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.356, loss_ctc=3.319, loss=1.659, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.194e-04, train_time=0.852
[alab02] 2024-09-01 22:38:37,478 (trainer:720) INFO: 148epoch:train:5201-5400batch: iter_time=1.361e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.537, loss=1.769, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.194e-04, train_time=0.847
[alab02] 2024-09-01 22:40:04,438 (trainer:720) INFO: 148epoch:train:5401-5600batch: iter_time=1.245e-04, forward_time=0.128, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.343, loss=1.672, backward_time=0.185, optim_step_time=0.029, optim0_lr0=1.194e-04, train_time=0.869
[alab02] 2024-09-01 22:41:30,001 (trainer:720) INFO: 148epoch:train:5601-5800batch: iter_time=1.277e-04, forward_time=0.125, uma_reduction=0.269, text_vs_uma=0.368, loss_ctc=3.655, loss=1.828, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.194e-04, train_time=0.855
[alab02] 2024-09-01 22:42:53,854 (trainer:720) INFO: 148epoch:train:5801-6000batch: iter_time=1.248e-04, forward_time=0.123, uma_reduction=0.266, text_vs_uma=0.364, loss_ctc=3.427, loss=1.714, backward_time=0.173, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.838
[alab02] 2024-09-01 22:44:17,282 (trainer:720) INFO: 148epoch:train:6001-6200batch: iter_time=1.263e-04, forward_time=0.122, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.394, loss=1.697, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.834
[alab02] 2024-09-01 22:45:44,065 (trainer:720) INFO: 148epoch:train:6201-6400batch: iter_time=1.243e-04, forward_time=0.127, uma_reduction=0.267, text_vs_uma=0.373, loss_ctc=3.608, loss=1.804, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.868
[alab02] 2024-09-01 22:47:08,422 (trainer:720) INFO: 148epoch:train:6401-6600batch: iter_time=1.365e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.359, loss_ctc=3.218, loss=1.609, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.843
[alab02] 2024-09-01 22:48:34,510 (trainer:720) INFO: 148epoch:train:6601-6800batch: iter_time=1.232e-04, forward_time=0.126, uma_reduction=0.265, text_vs_uma=0.370, loss_ctc=3.403, loss=1.702, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.861
[alab02] 2024-09-01 22:50:00,448 (trainer:720) INFO: 148epoch:train:6801-7000batch: iter_time=1.236e-04, forward_time=0.126, uma_reduction=0.268, text_vs_uma=0.358, loss_ctc=3.307, loss=1.653, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.859
[alab02] 2024-09-01 22:51:13,886 (trainer:338) INFO: 148epoch results: [train] iter_time=1.683e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.354, loss_ctc=3.350, loss=1.675, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.195e-04, train_time=0.850, time=50 minutes and 28.28 seconds, total_count=1054648, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.291, text_vs_uma=0.373, loss_ctc=2.987, cer_ctc=0.081, cer=0.081, loss=2.987, time=5.77 seconds, total_count=3848, gpu_max_cached_mem_GB=35.906, [att_plot] time=12.64 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 22:51:21,738 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 22:51:21,786 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/147epoch.pth
[alab02] 2024-09-01 22:51:21,786 (trainer:272) INFO: 149/150epoch started. Estimated time to finish: 1 hour, 46 minutes and 57.54 seconds
[alab02] 2024-09-01 22:52:48,341 (trainer:720) INFO: 149epoch:train:1-200batch: iter_time=0.002, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.244, loss=1.622, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.193e-04, train_time=0.865
[alab02] 2024-09-01 22:54:14,812 (trainer:720) INFO: 149epoch:train:201-400batch: iter_time=1.034e-04, forward_time=0.127, uma_reduction=0.273, text_vs_uma=0.356, loss_ctc=3.183, loss=1.592, backward_time=0.185, optim_step_time=0.028, optim0_lr0=1.193e-04, train_time=0.865
[alab02] 2024-09-01 22:55:38,776 (trainer:720) INFO: 149epoch:train:401-600batch: iter_time=1.035e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.415, loss=1.707, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.192e-04, train_time=0.839
[alab02] 2024-09-01 22:57:01,745 (trainer:720) INFO: 149epoch:train:601-800batch: iter_time=1.404e-04, forward_time=0.122, uma_reduction=0.273, text_vs_uma=0.358, loss_ctc=3.405, loss=1.703, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.192e-04, train_time=0.829
[alab02] 2024-09-01 22:58:28,316 (trainer:720) INFO: 149epoch:train:801-1000batch: iter_time=1.158e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.351, loss_ctc=3.489, loss=1.744, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.192e-04, train_time=0.866
[alab02] 2024-09-01 22:59:53,902 (trainer:720) INFO: 149epoch:train:1001-1200batch: iter_time=1.218e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.359, loss_ctc=3.679, loss=1.840, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.192e-04, train_time=0.856
[alab02] 2024-09-01 23:01:17,508 (trainer:720) INFO: 149epoch:train:1201-1400batch: iter_time=1.231e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.371, loss_ctc=3.461, loss=1.730, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.192e-04, train_time=0.836
[alab02] 2024-09-01 23:02:41,672 (trainer:720) INFO: 149epoch:train:1401-1600batch: iter_time=1.259e-04, forward_time=0.123, uma_reduction=0.266, text_vs_uma=0.360, loss_ctc=3.578, loss=1.789, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.192e-04, train_time=0.841
[alab02] 2024-09-01 23:04:05,308 (trainer:720) INFO: 149epoch:train:1601-1800batch: iter_time=1.303e-04, forward_time=0.122, uma_reduction=0.273, text_vs_uma=0.362, loss_ctc=3.592, loss=1.796, backward_time=0.173, optim_step_time=0.029, optim0_lr0=1.192e-04, train_time=0.836
[alab02] 2024-09-01 23:05:28,731 (trainer:720) INFO: 149epoch:train:1801-2000batch: iter_time=1.313e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.230, loss=1.615, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.192e-04, train_time=0.834
[alab02] 2024-09-01 23:06:51,798 (trainer:720) INFO: 149epoch:train:2001-2200batch: iter_time=1.384e-04, forward_time=0.121, uma_reduction=0.276, text_vs_uma=0.353, loss_ctc=3.600, loss=1.800, backward_time=0.171, optim_step_time=0.029, optim0_lr0=1.192e-04, train_time=0.830
[alab02] 2024-09-01 23:08:15,609 (trainer:720) INFO: 149epoch:train:2201-2400batch: iter_time=1.240e-04, forward_time=0.123, uma_reduction=0.287, text_vs_uma=0.341, loss_ctc=3.329, loss=1.664, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.191e-04, train_time=0.838
[alab02] 2024-09-01 23:09:08,546 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 23:09:38,406 (trainer:720) INFO: 149epoch:train:2401-2600batch: iter_time=1.201e-04, forward_time=0.121, uma_reduction=0.281, text_vs_uma=0.343, loss_ctc=3.358, loss=1.679, backward_time=0.172, optim_step_time=0.028, optim0_lr0=1.191e-04, train_time=0.828
[alab02] 2024-09-01 23:11:01,705 (trainer:720) INFO: 149epoch:train:2601-2800batch: iter_time=1.163e-04, forward_time=0.121, uma_reduction=0.278, text_vs_uma=0.357, loss_ctc=3.754, loss=1.877, backward_time=0.169, optim_step_time=0.029, optim0_lr0=1.191e-04, train_time=0.833
[alab02] 2024-09-01 23:12:28,606 (trainer:720) INFO: 149epoch:train:2801-3000batch: iter_time=1.262e-04, forward_time=0.128, uma_reduction=0.282, text_vs_uma=0.340, loss_ctc=3.279, loss=1.640, backward_time=0.185, optim_step_time=0.028, optim0_lr0=1.191e-04, train_time=0.869
[alab02] 2024-09-01 23:13:53,418 (trainer:720) INFO: 149epoch:train:3001-3200batch: iter_time=1.267e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.521, loss=1.760, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.191e-04, train_time=0.848
[alab02] 2024-09-01 23:15:18,305 (trainer:720) INFO: 149epoch:train:3201-3400batch: iter_time=1.087e-04, forward_time=0.125, uma_reduction=0.286, text_vs_uma=0.329, loss_ctc=3.225, loss=1.613, backward_time=0.179, optim_step_time=0.029, optim0_lr0=1.191e-04, train_time=0.849
[alab02] 2024-09-01 23:16:41,317 (trainer:720) INFO: 149epoch:train:3401-3600batch: iter_time=9.971e-05, forward_time=0.122, uma_reduction=0.286, text_vs_uma=0.336, loss_ctc=3.174, loss=1.587, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.191e-04, train_time=0.830
[alab02] 2024-09-01 23:18:05,292 (trainer:720) INFO: 149epoch:train:3601-3800batch: iter_time=1.293e-04, forward_time=0.123, uma_reduction=0.285, text_vs_uma=0.334, loss_ctc=3.082, loss=1.541, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.191e-04, train_time=0.840
[alab02] 2024-09-01 23:19:32,085 (trainer:720) INFO: 149epoch:train:3801-4000batch: iter_time=1.284e-04, forward_time=0.127, uma_reduction=0.279, text_vs_uma=0.346, loss_ctc=3.235, loss=1.617, backward_time=0.186, optim_step_time=0.028, optim0_lr0=1.191e-04, train_time=0.868
[alab02] 2024-09-01 23:20:56,840 (trainer:720) INFO: 149epoch:train:4001-4200batch: iter_time=1.255e-04, forward_time=0.125, uma_reduction=0.280, text_vs_uma=0.351, loss_ctc=3.250, loss=1.625, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.190e-04, train_time=0.847
[alab02] 2024-09-01 23:22:20,972 (trainer:720) INFO: 149epoch:train:4201-4400batch: iter_time=1.243e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.360, loss_ctc=3.354, loss=1.677, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.190e-04, train_time=0.841
[alab02] 2024-09-01 23:23:47,713 (trainer:720) INFO: 149epoch:train:4401-4600batch: iter_time=1.342e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.350, loss_ctc=3.469, loss=1.735, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.190e-04, train_time=0.867
[alab02] 2024-09-01 23:25:14,091 (trainer:720) INFO: 149epoch:train:4601-4800batch: iter_time=1.266e-04, forward_time=0.127, uma_reduction=0.276, text_vs_uma=0.360, loss_ctc=3.467, loss=1.733, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.190e-04, train_time=0.864
[alab02] 2024-09-01 23:26:40,079 (trainer:720) INFO: 149epoch:train:4801-5000batch: iter_time=1.300e-04, forward_time=0.127, uma_reduction=0.280, text_vs_uma=0.343, loss_ctc=3.279, loss=1.640, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.190e-04, train_time=0.860
[alab02] 2024-09-01 23:28:05,640 (trainer:720) INFO: 149epoch:train:5001-5200batch: iter_time=1.237e-04, forward_time=0.126, uma_reduction=0.281, text_vs_uma=0.345, loss_ctc=3.478, loss=1.739, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.190e-04, train_time=0.855
[alab02] 2024-09-01 23:29:30,141 (trainer:720) INFO: 149epoch:train:5201-5400batch: iter_time=1.289e-04, forward_time=0.124, uma_reduction=0.275, text_vs_uma=0.359, loss_ctc=3.385, loss=1.693, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.190e-04, train_time=0.845
[alab02] 2024-09-01 23:30:53,747 (trainer:720) INFO: 149epoch:train:5401-5600batch: iter_time=1.217e-04, forward_time=0.123, uma_reduction=0.285, text_vs_uma=0.334, loss_ctc=3.289, loss=1.645, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.190e-04, train_time=0.836
[alab02] 2024-09-01 23:32:19,310 (trainer:720) INFO: 149epoch:train:5601-5800batch: iter_time=1.231e-04, forward_time=0.125, uma_reduction=0.279, text_vs_uma=0.343, loss_ctc=2.988, loss=1.494, backward_time=0.183, optim_step_time=0.029, optim0_lr0=1.190e-04, train_time=0.855
[alab02] 2024-09-01 23:33:44,456 (trainer:720) INFO: 149epoch:train:5801-6000batch: iter_time=1.199e-04, forward_time=0.124, uma_reduction=0.273, text_vs_uma=0.362, loss_ctc=3.355, loss=1.678, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.189e-04, train_time=0.851
[alab02] 2024-09-01 23:35:08,641 (trainer:720) INFO: 149epoch:train:6001-6200batch: iter_time=1.074e-04, forward_time=0.123, uma_reduction=0.276, text_vs_uma=0.345, loss_ctc=3.158, loss=1.579, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.189e-04, train_time=0.842
[alab02] 2024-09-01 23:36:32,460 (trainer:720) INFO: 149epoch:train:6201-6400batch: iter_time=1.014e-04, forward_time=0.123, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.408, loss=1.704, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.189e-04, train_time=0.838
[alab02] 2024-09-01 23:37:57,426 (trainer:720) INFO: 149epoch:train:6401-6600batch: iter_time=1.203e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.346, loss_ctc=3.197, loss=1.599, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.189e-04, train_time=0.849
[alab02] 2024-09-01 23:39:23,384 (trainer:720) INFO: 149epoch:train:6601-6800batch: iter_time=1.291e-04, forward_time=0.126, uma_reduction=0.273, text_vs_uma=0.353, loss_ctc=3.308, loss=1.654, backward_time=0.182, optim_step_time=0.029, optim0_lr0=1.189e-04, train_time=0.859
[alab02] 2024-09-01 23:40:48,692 (trainer:720) INFO: 149epoch:train:6801-7000batch: iter_time=1.180e-04, forward_time=0.125, uma_reduction=0.264, text_vs_uma=0.378, loss_ctc=4.015, loss=2.007, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.189e-04, train_time=0.853
[alab02] 2024-09-01 23:41:58,953 (trainer:338) INFO: 149epoch results: [train] iter_time=1.671e-04, forward_time=0.124, uma_reduction=0.277, text_vs_uma=0.351, loss_ctc=3.370, loss=1.685, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.191e-04, train_time=0.847, time=50 minutes and 19.94 seconds, total_count=1061774, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.282, text_vs_uma=0.385, loss_ctc=3.060, cer_ctc=0.085, cer=0.085, loss=3.060, time=5.65 seconds, total_count=3874, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.58 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-01 23:42:05,228 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-01 23:42:05,279 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/148epoch.pth
[alab02] 2024-09-01 23:42:05,279 (trainer:272) INFO: 150/150epoch started. Estimated time to finish: 53 minutes and 27.66 seconds
[alab02] 2024-09-01 23:43:31,199 (trainer:720) INFO: 150epoch:train:1-200batch: iter_time=0.002, forward_time=0.125, uma_reduction=0.273, text_vs_uma=0.363, loss_ctc=3.400, loss=1.700, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.189e-04, train_time=0.859
[alab02] 2024-09-01 23:44:57,834 (trainer:720) INFO: 150epoch:train:201-400batch: iter_time=1.302e-04, forward_time=0.127, uma_reduction=0.272, text_vs_uma=0.360, loss_ctc=3.548, loss=1.774, backward_time=0.182, optim_step_time=0.028, optim0_lr0=1.189e-04, train_time=0.866
[alab02] 2024-09-01 23:46:08,641 (trainer:662) WARNING: The grad norm is nan. Skipping updating the model.
[alab02] 2024-09-01 23:46:23,412 (trainer:720) INFO: 150epoch:train:401-600batch: iter_time=1.291e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.356, loss_ctc=3.560, loss=1.780, backward_time=0.176, optim_step_time=0.029, optim0_lr0=1.188e-04, train_time=0.856
[alab02] 2024-09-01 23:47:47,207 (trainer:720) INFO: 150epoch:train:601-800batch: iter_time=1.246e-04, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.362, loss_ctc=3.601, loss=1.801, backward_time=0.173, optim_step_time=0.028, optim0_lr0=1.188e-04, train_time=0.838
[alab02] 2024-09-01 23:49:10,443 (trainer:720) INFO: 150epoch:train:801-1000batch: iter_time=1.222e-04, forward_time=0.122, uma_reduction=0.276, text_vs_uma=0.355, loss_ctc=3.281, loss=1.641, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.188e-04, train_time=0.832
[alab02] 2024-09-01 23:50:35,921 (trainer:720) INFO: 150epoch:train:1001-1200batch: iter_time=1.227e-04, forward_time=0.126, uma_reduction=0.282, text_vs_uma=0.346, loss_ctc=3.373, loss=1.686, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.188e-04, train_time=0.855
[alab02] 2024-09-01 23:52:02,286 (trainer:720) INFO: 150epoch:train:1201-1400batch: iter_time=1.154e-04, forward_time=0.128, uma_reduction=0.267, text_vs_uma=0.363, loss_ctc=3.174, loss=1.587, backward_time=0.185, optim_step_time=0.029, optim0_lr0=1.188e-04, train_time=0.863
[alab02] 2024-09-01 23:53:26,708 (trainer:720) INFO: 150epoch:train:1401-1600batch: iter_time=1.156e-04, forward_time=0.123, uma_reduction=0.270, text_vs_uma=0.360, loss_ctc=3.437, loss=1.718, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.188e-04, train_time=0.844
[alab02] 2024-09-01 23:54:51,925 (trainer:720) INFO: 150epoch:train:1601-1800batch: iter_time=1.200e-04, forward_time=0.125, uma_reduction=0.272, text_vs_uma=0.364, loss_ctc=3.412, loss=1.706, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.188e-04, train_time=0.852
[alab02] 2024-09-01 23:56:16,913 (trainer:720) INFO: 150epoch:train:1801-2000batch: iter_time=9.975e-05, forward_time=0.125, uma_reduction=0.276, text_vs_uma=0.339, loss_ctc=3.084, loss=1.542, backward_time=0.180, optim_step_time=0.028, optim0_lr0=1.188e-04, train_time=0.850
[alab02] 2024-09-01 23:57:40,980 (trainer:720) INFO: 150epoch:train:2001-2200batch: iter_time=9.858e-05, forward_time=0.123, uma_reduction=0.274, text_vs_uma=0.347, loss_ctc=3.383, loss=1.691, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.188e-04, train_time=0.840
[alab02] 2024-09-01 23:59:06,700 (trainer:720) INFO: 150epoch:train:2201-2400batch: iter_time=1.212e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.357, loss_ctc=3.533, loss=1.767, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.857
[alab02] 2024-09-02 00:00:31,279 (trainer:720) INFO: 150epoch:train:2401-2600batch: iter_time=1.191e-04, forward_time=0.124, uma_reduction=0.282, text_vs_uma=0.339, loss_ctc=3.234, loss=1.617, backward_time=0.177, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.846
[alab02] 2024-09-02 00:01:55,595 (trainer:720) INFO: 150epoch:train:2601-2800batch: iter_time=1.272e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.340, loss_ctc=3.068, loss=1.534, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.843
[alab02] 2024-09-02 00:03:23,143 (trainer:720) INFO: 150epoch:train:2801-3000batch: iter_time=1.198e-04, forward_time=0.129, uma_reduction=0.281, text_vs_uma=0.339, loss_ctc=3.326, loss=1.663, backward_time=0.185, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.875
[alab02] 2024-09-02 00:04:45,702 (trainer:720) INFO: 150epoch:train:3001-3200batch: iter_time=1.176e-04, forward_time=0.121, uma_reduction=0.282, text_vs_uma=0.337, loss_ctc=3.080, loss=1.540, backward_time=0.172, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.825
[alab02] 2024-09-02 00:06:09,437 (trainer:720) INFO: 150epoch:train:3201-3400batch: iter_time=1.243e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=3.534, loss=1.767, backward_time=0.173, optim_step_time=0.029, optim0_lr0=1.187e-04, train_time=0.837
[alab02] 2024-09-02 00:07:34,154 (trainer:720) INFO: 150epoch:train:3401-3600batch: iter_time=1.351e-04, forward_time=0.124, uma_reduction=0.276, text_vs_uma=0.357, loss_ctc=3.245, loss=1.623, backward_time=0.178, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.847
[alab02] 2024-09-02 00:08:58,766 (trainer:720) INFO: 150epoch:train:3601-3800batch: iter_time=1.242e-04, forward_time=0.124, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.066, loss=1.533, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.187e-04, train_time=0.846
[alab02] 2024-09-02 00:10:22,766 (trainer:720) INFO: 150epoch:train:3801-4000batch: iter_time=1.247e-04, forward_time=0.123, uma_reduction=0.273, text_vs_uma=0.357, loss_ctc=3.158, loss=1.579, backward_time=0.178, optim_step_time=0.029, optim0_lr0=1.187e-04, train_time=0.840
[alab02] 2024-09-02 00:11:49,427 (trainer:720) INFO: 150epoch:train:4001-4200batch: iter_time=1.188e-04, forward_time=0.128, uma_reduction=0.274, text_vs_uma=0.346, loss_ctc=3.087, loss=1.543, backward_time=0.186, optim_step_time=0.029, optim0_lr0=1.186e-04, train_time=0.866
[alab02] 2024-09-02 00:13:15,497 (trainer:720) INFO: 150epoch:train:4201-4400batch: iter_time=1.217e-04, forward_time=0.127, uma_reduction=0.282, text_vs_uma=0.337, loss_ctc=3.343, loss=1.671, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.186e-04, train_time=0.860
[alab02] 2024-09-02 00:14:38,435 (trainer:720) INFO: 150epoch:train:4401-4600batch: iter_time=1.180e-04, forward_time=0.122, uma_reduction=0.282, text_vs_uma=0.343, loss_ctc=3.143, loss=1.572, backward_time=0.174, optim_step_time=0.029, optim0_lr0=1.186e-04, train_time=0.829
[alab02] 2024-09-02 00:16:03,835 (trainer:720) INFO: 150epoch:train:4601-4800batch: iter_time=1.142e-04, forward_time=0.126, uma_reduction=0.276, text_vs_uma=0.349, loss_ctc=3.124, loss=1.562, backward_time=0.181, optim_step_time=0.028, optim0_lr0=1.186e-04, train_time=0.854
[alab02] 2024-09-02 00:17:27,427 (trainer:720) INFO: 150epoch:train:4801-5000batch: iter_time=1.158e-04, forward_time=0.123, uma_reduction=0.265, text_vs_uma=0.363, loss_ctc=3.305, loss=1.653, backward_time=0.174, optim_step_time=0.028, optim0_lr0=1.186e-04, train_time=0.836
[alab02] 2024-09-02 00:18:52,243 (trainer:720) INFO: 150epoch:train:5001-5200batch: iter_time=1.189e-04, forward_time=0.125, uma_reduction=0.267, text_vs_uma=0.361, loss_ctc=3.553, loss=1.777, backward_time=0.175, optim_step_time=0.028, optim0_lr0=1.186e-04, train_time=0.848
[alab02] 2024-09-02 00:20:19,188 (trainer:720) INFO: 150epoch:train:5201-5400batch: iter_time=1.279e-04, forward_time=0.129, uma_reduction=0.271, text_vs_uma=0.360, loss_ctc=3.124, loss=1.562, backward_time=0.188, optim_step_time=0.029, optim0_lr0=1.186e-04, train_time=0.869
[alab02] 2024-09-02 00:21:43,030 (trainer:720) INFO: 150epoch:train:5401-5600batch: iter_time=1.287e-04, forward_time=0.124, uma_reduction=0.272, text_vs_uma=0.352, loss_ctc=3.288, loss=1.644, backward_time=0.175, optim_step_time=0.029, optim0_lr0=1.186e-04, train_time=0.838
[alab02] 2024-09-02 00:23:09,353 (trainer:720) INFO: 150epoch:train:5601-5800batch: iter_time=1.324e-04, forward_time=0.126, uma_reduction=0.274, text_vs_uma=0.353, loss_ctc=3.204, loss=1.602, backward_time=0.184, optim_step_time=0.029, optim0_lr0=1.186e-04, train_time=0.863
[alab02] 2024-09-02 00:24:36,252 (trainer:720) INFO: 150epoch:train:5801-6000batch: iter_time=1.214e-04, forward_time=0.128, uma_reduction=0.278, text_vs_uma=0.350, loss_ctc=3.265, loss=1.632, backward_time=0.185, optim_step_time=0.029, optim0_lr0=1.185e-04, train_time=0.869
[alab02] 2024-09-02 00:26:01,109 (trainer:720) INFO: 150epoch:train:6001-6200batch: iter_time=1.223e-04, forward_time=0.124, uma_reduction=0.265, text_vs_uma=0.369, loss_ctc=3.289, loss=1.645, backward_time=0.177, optim_step_time=0.029, optim0_lr0=1.185e-04, train_time=0.848
[alab02] 2024-09-02 00:27:25,344 (trainer:720) INFO: 150epoch:train:6201-6400batch: iter_time=1.193e-04, forward_time=0.124, uma_reduction=0.270, text_vs_uma=0.364, loss_ctc=3.070, loss=1.535, backward_time=0.181, optim_step_time=0.029, optim0_lr0=1.185e-04, train_time=0.842
[alab02] 2024-09-02 00:28:49,834 (trainer:720) INFO: 150epoch:train:6401-6600batch: iter_time=1.156e-04, forward_time=0.124, uma_reduction=0.279, text_vs_uma=0.353, loss_ctc=3.327, loss=1.663, backward_time=0.176, optim_step_time=0.028, optim0_lr0=1.185e-04, train_time=0.845
[alab02] 2024-09-02 00:30:15,448 (trainer:720) INFO: 150epoch:train:6601-6800batch: iter_time=1.151e-04, forward_time=0.125, uma_reduction=0.274, text_vs_uma=0.352, loss_ctc=3.434, loss=1.717, backward_time=0.180, optim_step_time=0.029, optim0_lr0=1.185e-04, train_time=0.856
[alab02] 2024-09-02 00:31:39,121 (trainer:720) INFO: 150epoch:train:6801-7000batch: iter_time=1.123e-04, forward_time=0.123, uma_reduction=0.277, text_vs_uma=0.348, loss_ctc=2.986, loss=1.493, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.185e-04, train_time=0.837
[alab02] 2024-09-02 00:32:49,127 (trainer:338) INFO: 150epoch results: [train] iter_time=1.658e-04, forward_time=0.125, uma_reduction=0.275, text_vs_uma=0.353, loss_ctc=3.287, loss=1.644, backward_time=0.179, optim_step_time=0.028, optim0_lr0=1.187e-04, train_time=0.849, time=50 minutes and 26.48 seconds, total_count=1068900, gpu_max_cached_mem_GB=35.906, [valid] uma_reduction=0.284, text_vs_uma=0.383, loss_ctc=2.948, cer_ctc=0.083, cer=0.083, loss=2.948, time=5.95 seconds, total_count=3900, gpu_max_cached_mem_GB=35.906, [att_plot] time=11.42 seconds, total_count=0, gpu_max_cached_mem_GB=35.906
[alab02] 2024-09-02 00:32:55,602 (trainer:384) INFO: There are no improvements in this epoch
[alab02] 2024-09-02 00:32:55,652 (trainer:440) INFO: The model files were removed: exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/149epoch.pth
[alab02] 2024-09-02 00:32:55,652 (trainer:458) INFO: The training was finished at 150 epochs 
[alab02] 2024-09-02 00:32:55,680 (average_nbest_models:69) INFO: Averaging 10best models: criterion="valid.cer": exp_uma_mamba_0819/asr_train_asr_uma_mamba_b_raw_zh_char_sp/valid.cer.ave_10best.pth
# Accounting: time=481051 threads=1
# Ended (code 0) at Mon Sep  2 00:33:15 CST 2024, elapsed time 481051 seconds
