 # python3 -m espnet2.bin.asr_unimodal_train --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev_ios/wav.scp,speech,sound --valid_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 51200 --output_dir exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp --config conf/train_asr_uma_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_noeng_sp/wav.scp,speech,sound --train_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_noeng_sp/text,text,text --train_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/dev_ios/text,text,text --valid_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 2 --multiprocessing_distributed True 
# Started at Tue Jul 18 15:52:15 CST 2023
#
/data/home/fangying/anaconda3/envs/espnet/bin/python3 /data/home/fangying/espnet/espnet2/bin/asr_unimodal_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/zh_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev_ios/wav.scp,speech,sound --valid_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 51200 --output_dir exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp --config conf/train_asr_uma_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_noeng_sp/wav.scp,speech,sound --train_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_noeng_sp/text,text,text --train_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/dev_ios/text,text,text --valid_shape_file exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/valid/text_shape.char --ngpu 2 --multiprocessing_distributed True
[ALab02:0/2] 2023-07-18 15:52:21,892 (distributed_c10d:228) INFO: Added key: store_based_barrier_key:1 to store for rank: 0
[ALab02:0/2] 2023-07-18 15:52:21,892 (distributed_c10d:262) INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[ALab02:0/2] 2023-07-18 15:52:21,924 (asr_unimodal:512) INFO: Vocabulary size: 5179
[ALab02:0/2] 2023-07-18 15:52:22,113 (conformer_encoder:139) WARNING: Using legacy_rel_pos and it will be deprecated in the future.
[ALab02:0/2] 2023-07-18 15:52:22,218 (conformer_encoder:246) WARNING: Using legacy_rel_selfattn and it will be deprecated in the future.
[ALab02:0/2] 2023-07-18 15:52:25,199 (abs_task:1201) INFO: pytorch.version=1.12.1, cuda.available=True, cudnn.version=8302, cudnn.benchmark=False, cudnn.deterministic=True
[ALab02:0/2] 2023-07-18 15:52:25,205 (abs_task:1202) INFO: Model structure:
UAMASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=128, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=2, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=9728, out_features=512, bias=True)
        (1): LegacyRelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (uma): UMA(
    (linear_sigmoid): Sequential(
      (0): Linear(in_features=512, out_features=1, bias=True)
      (1): Sigmoid()
    )
  )
  (decoder): UnimodalAttentionDecoder(
    (embed): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): ReLU()
      (4): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=5179, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: UAMASRModel
    Total Number of model parameters: 105.07 M
    Number of trainable parameters: 105.07 M (100.0%)
    Size: 420.27 MB
    Type: torch.float32
[ALab02:0/2] 2023-07-18 15:52:25,205 (abs_task:1205) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0005
    lr: 1.6666666666666667e-08
    maximize: False
    weight_decay: 0
)
[ALab02:0/2] 2023-07-18 15:52:25,206 (abs_task:1206) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[ALab02:0/2] 2023-07-18 15:52:25,206 (abs_task:1215) INFO: Saving the configuration in exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/config.yaml
[ALab02:0/2] 2023-07-18 15:52:31,069 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02:0/2] 2023-07-18 15:52:59,377 (abs_task:1570) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_noeng_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_noeng_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fe425871580>)
[ALab02:0/2] 2023-07-18 15:52:59,378 (abs_task:1571) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=18176, batch_bins=20000000, sort_in_batch=descending, sort_batch=descending)
[ALab02:0/2] 2023-07-18 15:52:59,380 (abs_task:1572) INFO: [train] mini-batch sizes summary: N-batch=18176, mean=158.9, min=24, max=585
[ALab02:0/2] 2023-07-18 15:52:59,609 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02:0/2] 2023-07-18 15:52:59,621 (abs_task:1570) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev_ios/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev_ios/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fe425871970>)
[ALab02:0/2] 2023-07-18 15:52:59,622 (abs_task:1571) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=15, batch_bins=20000000, sort_in_batch=descending, sort_batch=descending)
[ALab02:0/2] 2023-07-18 15:52:59,622 (abs_task:1572) INFO: [valid] mini-batch sizes summary: N-batch=15, mean=166.7, min=23, max=301
[ALab02:0/2] 2023-07-18 15:52:59,627 (asr_unimodal:483) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4')
[ALab02:0/2] 2023-07-18 15:52:59,649 (abs_task:1570) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev_ios/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev_ios/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fe425871250>)
[ALab02:0/2] 2023-07-18 15:52:59,649 (abs_task:1571) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=2500, batch_size=1, key_file=exp_uma_conformer_12e_718/asr_stats_raw_zh_char_sp/valid/speech_shape, 
[ALab02:0/2] 2023-07-18 15:52:59,649 (abs_task:1572) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
ALab02:93070:93070 [0] NCCL INFO Bootstrap : Using ens22f0:10.0.1.2<0>
ALab02:93070:93070 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
ALab02:93070:93070 [0] NCCL INFO NET/IB : No device found.
ALab02:93070:93070 [0] NCCL INFO NET/Socket : Using [0]ens22f0:10.0.1.2<0> [1]br-110b18748052:172.18.0.1<0> [2]br-b20a2544a87a:172.19.0.1<0> [3]vethbf8df4e:fe80::83a:8fff:fe42:4a9e%vethbf8df4e<0> [4]veth5bef5b4:fe80::18b3:41ff:fef2:68b5%veth5bef5b4<0> [5]veth4f0f0af:fe80::cc6a:fcff:fee1:3f07%veth4f0f0af<0>
ALab02:93070:93070 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.6
ALab02:93071:93071 [1] NCCL INFO Bootstrap : Using ens22f0:10.0.1.2<0>
ALab02:93071:93071 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
ALab02:93071:93071 [1] NCCL INFO NET/IB : No device found.
ALab02:93071:93071 [1] NCCL INFO NET/Socket : Using [0]ens22f0:10.0.1.2<0> [1]br-110b18748052:172.18.0.1<0> [2]br-b20a2544a87a:172.19.0.1<0> [3]vethbf8df4e:fe80::83a:8fff:fe42:4a9e%vethbf8df4e<0> [4]veth5bef5b4:fe80::18b3:41ff:fef2:68b5%veth5bef5b4<0> [5]veth4f0f0af:fe80::cc6a:fcff:fee1:3f07%veth4f0f0af<0>
ALab02:93071:93071 [1] NCCL INFO Using network Socket
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 00/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 01/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 02/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 03/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 04/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 05/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 06/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 07/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 08/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 09/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 10/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 11/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 12/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 13/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 14/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 15/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 16/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 17/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 18/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 19/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 20/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 21/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 22/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Channel 23/24 :    0   1
ALab02:93070:94957 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
ALab02:93070:94957 [0] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
ALab02:93071:94958 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0 [8] -1/-1/-1->1->0 [9] -1/-1/-1->1->0 [10] -1/-1/-1->1->0 [11] -1/-1/-1->1->0 [12] -1/-1/-1->1->0 [13] -1/-1/-1->1->0 [14] -1/-1/-1->1->0 [15] -1/-1/-1->1->0 [16] -1/-1/-1->1->0 [17] -1/-1/-1->1->0 [18] -1/-1/-1->1->0 [19] -1/-1/-1->1->0 [20] -1/-1/-1->1->0 [21] -1/-1/-1->1->0 [22] -1/-1/-1->1->0 [23] -1/-1/-1->1->0
ALab02:93071:94958 [1] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Channel 00 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 01 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 02 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 03 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 04 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 05 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 06 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 07 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 08 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 09 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 10 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 11 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 12 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 13 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 14 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 15 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 16 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93070:94957 [0] NCCL INFO Channel 17 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 18 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 19 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 20 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 21 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 22 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93070:94957 [0] NCCL INFO Could not enable P2P between dev 0(=c6000) and dev 1(=ca000)
ALab02:93070:94957 [0] NCCL INFO Channel 23 : 0[c6000] -> 1[ca000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 02 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 03 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 04 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 05 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 06 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 07 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 08 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 09 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 10 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 11 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 12 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 13 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 14 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 15 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 16 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 17 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 18 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 19 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 20 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 21 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 22 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Could not enable P2P between dev 1(=ca000) and dev 0(=c6000)
ALab02:93071:94958 [1] NCCL INFO Channel 23 : 1[ca000] -> 0[c6000] via direct shared memory
ALab02:93071:94958 [1] NCCL INFO Connected all rings
ALab02:93071:94958 [1] NCCL INFO Connected all trees
ALab02:93071:94958 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
ALab02:93071:94958 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
ALab02:93070:94957 [0] NCCL INFO Connected all rings
ALab02:93070:94957 [0] NCCL INFO Connected all trees
ALab02:93070:94957 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
ALab02:93070:94957 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
ALab02:93070:94957 [0] NCCL INFO comm 0x7fe33c003010 rank 0 nranks 2 cudaDev 0 busId c6000 - Init COMPLETE
ALab02:93071:94958 [1] NCCL INFO comm 0x7fc918003010 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
ALab02:93070:93070 [0] NCCL INFO Launch mode Parallel
[ALab02:0/2] 2023-07-18 15:53:00,458 (trainer:284) INFO: 1/50epoch started
[ALab02:0/2] 2023-07-18 15:53:15,635 (distributed:995) INFO: Reducer buckets have been rebuilt in this iteration.
[ALab02:0/2] 2023-07-18 16:03:39,856 (trainer:721) INFO: 1epoch:train:1-908batch: iter_time=6.923e-04, forward_time=0.219, loss_ctc=165.581, loss=82.790, backward_time=0.309, optim_step_time=0.035, optim0_lr0=1.917e-06, train_time=2.816
[ALab02:0/2] 2023-07-18 16:13:52,598 (trainer:721) INFO: 1epoch:train:909-1816batch: iter_time=2.602e-04, forward_time=0.211, loss_ctc=88.267, loss=44.134, backward_time=0.302, optim_step_time=0.034, optim0_lr0=5.700e-06, train_time=2.699
[ALab02:0/2] 2023-07-18 16:24:48,466 (trainer:721) INFO: 1epoch:train:1817-2724batch: iter_time=2.579e-04, forward_time=0.226, loss_ctc=77.017, loss=38.508, backward_time=0.323, optim_step_time=0.034, optim0_lr0=9.483e-06, train_time=2.889
[ALab02:0/2] 2023-07-18 16:35:38,604 (trainer:721) INFO: 1epoch:train:2725-3632batch: iter_time=2.460e-04, forward_time=0.224, loss_ctc=75.239, loss=37.620, backward_time=0.320, optim_step_time=0.034, optim0_lr0=1.327e-05, train_time=2.864
[ALab02:0/2] 2023-07-18 16:46:36,037 (trainer:721) INFO: 1epoch:train:3633-4540batch: iter_time=2.362e-04, forward_time=0.226, loss_ctc=72.466, loss=36.233, backward_time=0.323, optim_step_time=0.034, optim0_lr0=1.705e-05, train_time=2.896
[ALab02:0/2] 2023-07-18 16:57:14,774 (trainer:721) INFO: 1epoch:train:4541-5448batch: iter_time=2.255e-04, forward_time=0.201, loss_ctc=71.654, loss=35.827, backward_time=0.302, optim_step_time=0.034, optim0_lr0=2.083e-05, train_time=2.814
[ALab02:0/2] 2023-07-18 17:07:45,467 (trainer:721) INFO: 1epoch:train:5449-6356batch: iter_time=2.495e-04, forward_time=0.196, loss_ctc=67.726, loss=33.863, backward_time=0.301, optim_step_time=0.035, optim0_lr0=2.462e-05, train_time=2.778
[ALab02:0/2] 2023-07-18 17:18:17,301 (trainer:721) INFO: 1epoch:train:6357-7264batch: iter_time=2.782e-04, forward_time=0.202, loss_ctc=63.977, loss=31.989, backward_time=0.304, optim_step_time=0.036, optim0_lr0=2.840e-05, train_time=2.783
[ALab02:0/2] 2023-07-18 17:28:40,091 (trainer:721) INFO: 1epoch:train:7265-8172batch: iter_time=2.596e-04, forward_time=0.198, loss_ctc=57.225, loss=28.613, backward_time=0.299, optim_step_time=0.034, optim0_lr0=3.218e-05, train_time=2.743
[ALab02:0/2] 2023-07-18 17:38:05,223 (trainer:721) INFO: 1epoch:train:8173-9080batch: iter_time=2.451e-04, forward_time=0.194, loss_ctc=52.674, loss=26.337, backward_time=0.280, optim_step_time=0.033, optim0_lr0=3.597e-05, train_time=2.489
[ALab02:0/2] 2023-07-18 17:47:36,400 (trainer:721) INFO: 1epoch:train:9081-9988batch: iter_time=2.295e-04, forward_time=0.197, loss_ctc=50.134, loss=25.067, backward_time=0.283, optim_step_time=0.033, optim0_lr0=3.975e-05, train_time=2.516
[ALab02:0/2] 2023-07-18 17:57:06,600 (trainer:721) INFO: 1epoch:train:9989-10896batch: iter_time=2.349e-04, forward_time=0.196, loss_ctc=44.278, loss=22.139, backward_time=0.282, optim_step_time=0.033, optim0_lr0=4.353e-05, train_time=2.512
[ALab02:0/2] 2023-07-18 18:06:37,919 (trainer:721) INFO: 1epoch:train:10897-11804batch: iter_time=2.336e-04, forward_time=0.197, loss_ctc=39.639, loss=19.820, backward_time=0.283, optim_step_time=0.033, optim0_lr0=4.732e-05, train_time=2.517
[ALab02:0/2] 2023-07-18 18:16:02,496 (trainer:721) INFO: 1epoch:train:11805-12712batch: iter_time=2.324e-04, forward_time=0.194, loss_ctc=35.109, loss=17.554, backward_time=0.280, optim_step_time=0.033, optim0_lr0=5.110e-05, train_time=2.487
[ALab02:0/2] 2023-07-18 18:25:28,312 (trainer:721) INFO: 1epoch:train:12713-13620batch: iter_time=2.336e-04, forward_time=0.194, loss_ctc=32.187, loss=16.093, backward_time=0.281, optim_step_time=0.033, optim0_lr0=5.488e-05, train_time=2.492
[ALab02:0/2] 2023-07-18 18:34:55,065 (trainer:721) INFO: 1epoch:train:13621-14528batch: iter_time=2.404e-04, forward_time=0.196, loss_ctc=30.343, loss=15.172, backward_time=0.281, optim_step_time=0.033, optim0_lr0=5.867e-05, train_time=2.496
[ALab02:0/2] 2023-07-18 18:44:21,628 (trainer:721) INFO: 1epoch:train:14529-15436batch: iter_time=2.286e-04, forward_time=0.195, loss_ctc=26.762, loss=13.381, backward_time=0.280, optim_step_time=0.033, optim0_lr0=6.245e-05, train_time=2.496
[ALab02:0/2] 2023-07-18 18:53:41,862 (trainer:721) INFO: 1epoch:train:15437-16344batch: iter_time=2.427e-04, forward_time=0.193, loss_ctc=25.058, loss=12.529, backward_time=0.278, optim_step_time=0.034, optim0_lr0=6.623e-05, train_time=2.468
[ALab02:0/2] 2023-07-18 19:03:08,680 (trainer:721) INFO: 1epoch:train:16345-17252batch: iter_time=2.447e-04, forward_time=0.196, loss_ctc=23.909, loss=11.955, backward_time=0.282, optim_step_time=0.034, optim0_lr0=7.002e-05, train_time=2.497
[ALab02:0/2] 2023-07-18 19:12:32,186 (trainer:721) INFO: 1epoch:train:17253-18160batch: iter_time=2.472e-04, forward_time=0.194, loss_ctc=21.698, loss=10.849, backward_time=0.280, optim_step_time=0.033, optim0_lr0=7.380e-05, train_time=2.482
[ALab02:0/2] 2023-07-18 19:13:32,546 (trainer:338) INFO: 1epoch results: [train] iter_time=2.659e-04, forward_time=0.202, loss_ctc=56.052, loss=28.026, backward_time=0.294, optim_step_time=0.034, optim0_lr0=3.789e-05, train_time=2.637, time=3 hours, 19 minutes and 43.11 seconds, total_count=18176, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=16.958, cer_ctc=0.371, cer=0.371, loss=8.479, time=7.41 seconds, total_count=15, gpu_max_cached_mem_GB=42.221, [att_plot] time=41.55 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-18 19:13:35,972 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-18 19:13:35,973 (trainer:272) INFO: 2/50epoch started. Estimated time to finish: 6 days, 19 hours and 49 minutes
[ALab02:0/2] 2023-07-18 19:23:13,290 (trainer:721) INFO: 2epoch:train:1-908batch: iter_time=8.049e-04, forward_time=0.195, loss_ctc=19.264, loss=9.632, backward_time=0.280, optim_step_time=0.034, optim0_lr0=7.765e-05, train_time=2.543
[ALab02:0/2] 2023-07-18 19:32:35,573 (trainer:721) INFO: 2epoch:train:909-1816batch: iter_time=2.740e-04, forward_time=0.194, loss_ctc=19.297, loss=9.649, backward_time=0.279, optim_step_time=0.034, optim0_lr0=8.143e-05, train_time=2.477
[ALab02:0/2] 2023-07-18 19:41:59,096 (trainer:721) INFO: 2epoch:train:1817-2724batch: iter_time=2.672e-04, forward_time=0.195, loss_ctc=17.692, loss=8.846, backward_time=0.280, optim_step_time=0.034, optim0_lr0=8.522e-05, train_time=2.482
[ALab02:0/2] 2023-07-18 19:51:09,963 (trainer:721) INFO: 2epoch:train:2725-3632batch: iter_time=2.443e-04, forward_time=0.190, loss_ctc=17.073, loss=8.537, backward_time=0.273, optim_step_time=0.035, optim0_lr0=8.900e-05, train_time=2.426
[ALab02:0/2] 2023-07-18 19:58:50,822 (trainer:721) INFO: 2epoch:train:3633-4540batch: iter_time=2.378e-04, forward_time=0.154, loss_ctc=16.655, loss=8.328, backward_time=0.226, optim_step_time=0.033, optim0_lr0=9.278e-05, train_time=2.030
[ALab02:0/2] 2023-07-18 20:06:30,896 (trainer:721) INFO: 2epoch:train:4541-5448batch: iter_time=2.328e-04, forward_time=0.154, loss_ctc=15.567, loss=7.784, backward_time=0.225, optim_step_time=0.034, optim0_lr0=9.657e-05, train_time=2.027
[ALab02:0/2] 2023-07-18 20:14:10,889 (trainer:721) INFO: 2epoch:train:5449-6356batch: iter_time=2.324e-04, forward_time=0.154, loss_ctc=15.093, loss=7.547, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.003e-04, train_time=2.026
[ALab02:0/2] 2023-07-18 20:21:53,992 (trainer:721) INFO: 2epoch:train:6357-7264batch: iter_time=2.282e-04, forward_time=0.154, loss_ctc=14.258, loss=7.129, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.041e-04, train_time=2.040
[ALab02:0/2] 2023-07-18 20:29:36,887 (trainer:721) INFO: 2epoch:train:7265-8172batch: iter_time=2.428e-04, forward_time=0.155, loss_ctc=13.333, loss=6.667, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.079e-04, train_time=2.039
[ALab02:0/2] 2023-07-18 20:37:18,277 (trainer:721) INFO: 2epoch:train:8173-9080batch: iter_time=2.388e-04, forward_time=0.154, loss_ctc=13.159, loss=6.580, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.117e-04, train_time=2.032
[ALab02:0/2] 2023-07-18 20:44:58,748 (trainer:721) INFO: 2epoch:train:9081-9988batch: iter_time=2.449e-04, forward_time=0.153, loss_ctc=12.610, loss=6.305, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.155e-04, train_time=2.028
[ALab02:0/2] 2023-07-18 20:52:39,314 (trainer:721) INFO: 2epoch:train:9989-10896batch: iter_time=2.290e-04, forward_time=0.154, loss_ctc=12.497, loss=6.248, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.193e-04, train_time=2.029
[ALab02:0/2] 2023-07-18 21:00:21,421 (trainer:721) INFO: 2epoch:train:10897-11804batch: iter_time=2.278e-04, forward_time=0.155, loss_ctc=11.793, loss=5.897, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.231e-04, train_time=2.035
[ALab02:0/2] 2023-07-18 21:08:02,778 (trainer:721) INFO: 2epoch:train:11805-12712batch: iter_time=2.331e-04, forward_time=0.154, loss_ctc=11.210, loss=5.605, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.268e-04, train_time=2.032
[ALab02:0/2] 2023-07-18 21:15:46,115 (trainer:721) INFO: 2epoch:train:12713-13620batch: iter_time=2.309e-04, forward_time=0.155, loss_ctc=11.084, loss=5.542, backward_time=0.227, optim_step_time=0.033, optim0_lr0=1.306e-04, train_time=2.041
[ALab02:0/2] 2023-07-18 21:23:25,299 (trainer:721) INFO: 2epoch:train:13621-14528batch: iter_time=2.343e-04, forward_time=0.153, loss_ctc=10.879, loss=5.439, backward_time=0.224, optim_step_time=0.034, optim0_lr0=1.344e-04, train_time=2.023
[ALab02:0/2] 2023-07-18 21:31:06,766 (trainer:721) INFO: 2epoch:train:14529-15436batch: iter_time=2.243e-04, forward_time=0.154, loss_ctc=10.414, loss=5.207, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.382e-04, train_time=2.033
[ALab02:0/2] 2023-07-18 21:38:50,331 (trainer:721) INFO: 2epoch:train:15437-16344batch: iter_time=2.431e-04, forward_time=0.155, loss_ctc=9.978, loss=4.989, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.420e-04, train_time=2.042
[ALab02:0/2] 2023-07-18 21:46:32,391 (trainer:721) INFO: 2epoch:train:16345-17252batch: iter_time=2.222e-04, forward_time=0.154, loss_ctc=9.919, loss=4.959, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.457e-04, train_time=2.035
[ALab02:0/2] 2023-07-18 21:54:13,896 (trainer:721) INFO: 2epoch:train:17253-18160batch: iter_time=2.433e-04, forward_time=0.154, loss_ctc=9.615, loss=4.808, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.495e-04, train_time=2.033
[ALab02:0/2] 2023-07-18 21:55:12,573 (trainer:338) INFO: 2epoch results: [train] iter_time=2.668e-04, forward_time=0.162, loss_ctc=13.568, loss=6.784, backward_time=0.236, optim_step_time=0.034, optim0_lr0=1.136e-04, train_time=2.123, time=2 hours, 40 minutes and 47.74 seconds, total_count=36352, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=6.778, cer_ctc=0.170, cer=0.170, loss=3.389, time=8.16 seconds, total_count=30, gpu_max_cached_mem_GB=42.221, [att_plot] time=40.7 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-18 21:55:17,045 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-18 21:55:17,045 (trainer:272) INFO: 3/50epoch started. Estimated time to finish: 6 days, 54 minutes and 38.09 seconds
[ALab02:0/2] 2023-07-18 22:03:09,632 (trainer:721) INFO: 3epoch:train:1-908batch: iter_time=6.458e-04, forward_time=0.155, loss_ctc=9.531, loss=4.766, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.534e-04, train_time=2.082
[ALab02:0/2] 2023-07-18 22:10:49,846 (trainer:721) INFO: 3epoch:train:909-1816batch: iter_time=2.331e-04, forward_time=0.154, loss_ctc=9.125, loss=4.563, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.572e-04, train_time=2.027
[ALab02:0/2] 2023-07-18 22:18:33,689 (trainer:721) INFO: 3epoch:train:1817-2724batch: iter_time=2.379e-04, forward_time=0.155, loss_ctc=8.731, loss=4.365, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.609e-04, train_time=2.043
[ALab02:0/2] 2023-07-18 22:26:17,749 (trainer:721) INFO: 3epoch:train:2725-3632batch: iter_time=2.337e-04, forward_time=0.155, loss_ctc=8.971, loss=4.485, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.647e-04, train_time=2.044
[ALab02:0/2] 2023-07-18 22:33:58,508 (trainer:721) INFO: 3epoch:train:3633-4540batch: iter_time=2.442e-04, forward_time=0.154, loss_ctc=8.621, loss=4.310, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.685e-04, train_time=2.030
[ALab02:0/2] 2023-07-18 22:41:39,605 (trainer:721) INFO: 3epoch:train:4541-5448batch: iter_time=2.387e-04, forward_time=0.154, loss_ctc=8.366, loss=4.183, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.723e-04, train_time=2.031
[ALab02:0/2] 2023-07-18 22:49:20,152 (trainer:721) INFO: 3epoch:train:5449-6356batch: iter_time=2.279e-04, forward_time=0.154, loss_ctc=8.220, loss=4.110, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.761e-04, train_time=2.029
[ALab02:0/2] 2023-07-18 22:57:03,258 (trainer:721) INFO: 3epoch:train:6357-7264batch: iter_time=2.313e-04, forward_time=0.155, loss_ctc=7.864, loss=3.932, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.799e-04, train_time=2.040
[ALab02:0/2] 2023-07-18 23:04:45,114 (trainer:721) INFO: 3epoch:train:7265-8172batch: iter_time=2.393e-04, forward_time=0.154, loss_ctc=8.074, loss=4.037, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.836e-04, train_time=2.034
[ALab02:0/2] 2023-07-18 23:12:26,064 (trainer:721) INFO: 3epoch:train:8173-9080batch: iter_time=2.318e-04, forward_time=0.154, loss_ctc=7.840, loss=3.920, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.874e-04, train_time=2.030
[ALab02:0/2] 2023-07-18 23:20:08,502 (trainer:721) INFO: 3epoch:train:9081-9988batch: iter_time=2.300e-04, forward_time=0.154, loss_ctc=7.741, loss=3.871, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.912e-04, train_time=2.037
[ALab02:0/2] 2023-07-18 23:27:51,534 (trainer:721) INFO: 3epoch:train:9989-10896batch: iter_time=2.264e-04, forward_time=0.155, loss_ctc=7.649, loss=3.825, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.950e-04, train_time=2.040
[ALab02:0/2] 2023-07-18 23:35:33,263 (trainer:721) INFO: 3epoch:train:10897-11804batch: iter_time=2.270e-04, forward_time=0.154, loss_ctc=7.600, loss=3.800, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.988e-04, train_time=2.034
[ALab02:0/2] 2023-07-18 23:43:13,311 (trainer:721) INFO: 3epoch:train:11805-12712batch: iter_time=2.287e-04, forward_time=0.153, loss_ctc=7.522, loss=3.761, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.026e-04, train_time=2.026
[ALab02:0/2] 2023-07-18 23:50:54,704 (trainer:721) INFO: 3epoch:train:12713-13620batch: iter_time=2.267e-04, forward_time=0.154, loss_ctc=7.227, loss=3.613, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.064e-04, train_time=2.032
[ALab02:0/2] 2023-07-18 23:58:36,430 (trainer:721) INFO: 3epoch:train:13621-14528batch: iter_time=2.259e-04, forward_time=0.154, loss_ctc=7.159, loss=3.579, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.101e-04, train_time=2.034
[ALab02:0/2] 2023-07-19 00:06:18,670 (trainer:721) INFO: 3epoch:train:14529-15436batch: iter_time=2.436e-04, forward_time=0.154, loss_ctc=6.961, loss=3.480, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.139e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 00:14:01,276 (trainer:721) INFO: 3epoch:train:15437-16344batch: iter_time=2.267e-04, forward_time=0.154, loss_ctc=6.885, loss=3.443, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.177e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 00:21:41,408 (trainer:721) INFO: 3epoch:train:16345-17252batch: iter_time=2.200e-04, forward_time=0.153, loss_ctc=6.954, loss=3.477, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.215e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 00:29:21,067 (trainer:721) INFO: 3epoch:train:17253-18160batch: iter_time=2.168e-04, forward_time=0.153, loss_ctc=6.808, loss=3.404, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.253e-04, train_time=2.025
[ALab02:0/2] 2023-07-19 00:30:19,799 (trainer:338) INFO: 3epoch results: [train] iter_time=2.518e-04, forward_time=0.154, loss_ctc=7.891, loss=3.945, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.894e-04, train_time=2.036, time=2 hours, 34 minutes and 13.42 seconds, total_count=54528, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=4.894, cer_ctc=0.127, cer=0.127, loss=2.447, time=8.08 seconds, total_count=45, gpu_max_cached_mem_GB=42.221, [att_plot] time=41.26 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-19 00:30:23,425 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 00:30:23,425 (trainer:272) INFO: 4/50epoch started. Estimated time to finish: 5 days, 15 hours and 5 minutes
[ALab02:0/2] 2023-07-19 00:38:14,538 (trainer:721) INFO: 4epoch:train:1-908batch: iter_time=7.391e-04, forward_time=0.153, loss_ctc=6.508, loss=3.254, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.291e-04, train_time=2.075
[ALab02:0/2] 2023-07-19 00:45:55,835 (trainer:721) INFO: 4epoch:train:909-1816batch: iter_time=2.259e-04, forward_time=0.153, loss_ctc=6.422, loss=3.211, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.329e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 00:53:37,712 (trainer:721) INFO: 4epoch:train:1817-2724batch: iter_time=2.139e-04, forward_time=0.153, loss_ctc=6.647, loss=3.323, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.367e-04, train_time=2.034
[ALab02:0/2] 2023-07-19 01:01:19,111 (trainer:721) INFO: 4epoch:train:2725-3632batch: iter_time=2.209e-04, forward_time=0.153, loss_ctc=6.220, loss=3.110, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.405e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 01:09:00,408 (trainer:721) INFO: 4epoch:train:3633-4540batch: iter_time=2.144e-04, forward_time=0.154, loss_ctc=6.411, loss=3.206, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.442e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 01:16:40,915 (trainer:721) INFO: 4epoch:train:4541-5448batch: iter_time=2.287e-04, forward_time=0.153, loss_ctc=6.282, loss=3.141, backward_time=0.225, optim_step_time=0.032, optim0_lr0=2.480e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 01:24:23,803 (trainer:721) INFO: 4epoch:train:5449-6356batch: iter_time=2.153e-04, forward_time=0.154, loss_ctc=6.216, loss=3.108, backward_time=0.227, optim_step_time=0.032, optim0_lr0=2.518e-04, train_time=2.039
[ALab02:0/2] 2023-07-19 01:32:04,989 (trainer:721) INFO: 4epoch:train:6357-7264batch: iter_time=2.169e-04, forward_time=0.153, loss_ctc=6.240, loss=3.120, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.556e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 01:39:45,083 (trainer:721) INFO: 4epoch:train:7265-8172batch: iter_time=2.102e-04, forward_time=0.153, loss_ctc=6.101, loss=3.050, backward_time=0.225, optim_step_time=0.032, optim0_lr0=2.594e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 01:47:24,432 (trainer:721) INFO: 4epoch:train:8173-9080batch: iter_time=2.149e-04, forward_time=0.153, loss_ctc=5.977, loss=2.988, backward_time=0.225, optim_step_time=0.032, optim0_lr0=2.632e-04, train_time=2.023
[ALab02:0/2] 2023-07-19 01:55:05,691 (trainer:721) INFO: 4epoch:train:9081-9988batch: iter_time=2.092e-04, forward_time=0.153, loss_ctc=5.938, loss=2.969, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.669e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 02:02:46,023 (trainer:721) INFO: 4epoch:train:9989-10896batch: iter_time=2.101e-04, forward_time=0.153, loss_ctc=5.991, loss=2.996, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.707e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 02:10:27,500 (trainer:721) INFO: 4epoch:train:10897-11804batch: iter_time=2.295e-04, forward_time=0.154, loss_ctc=5.758, loss=2.879, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.745e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 02:18:08,094 (trainer:721) INFO: 4epoch:train:11805-12712batch: iter_time=2.239e-04, forward_time=0.153, loss_ctc=5.870, loss=2.935, backward_time=0.225, optim_step_time=0.032, optim0_lr0=2.783e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 02:25:47,801 (trainer:721) INFO: 4epoch:train:12713-13620batch: iter_time=2.100e-04, forward_time=0.153, loss_ctc=5.795, loss=2.898, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.821e-04, train_time=2.025
[ALab02:0/2] 2023-07-19 02:33:29,256 (trainer:721) INFO: 4epoch:train:13621-14528batch: iter_time=2.144e-04, forward_time=0.153, loss_ctc=5.695, loss=2.847, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.859e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 02:41:06,341 (trainer:721) INFO: 4epoch:train:14529-15436batch: iter_time=2.178e-04, forward_time=0.152, loss_ctc=5.773, loss=2.886, backward_time=0.224, optim_step_time=0.033, optim0_lr0=2.896e-04, train_time=2.013
[ALab02:0/2] 2023-07-19 02:48:47,780 (trainer:721) INFO: 4epoch:train:15437-16344batch: iter_time=2.093e-04, forward_time=0.154, loss_ctc=5.584, loss=2.792, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.934e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 02:56:29,038 (trainer:721) INFO: 4epoch:train:16345-17252batch: iter_time=2.075e-04, forward_time=0.154, loss_ctc=5.486, loss=2.743, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.972e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 03:04:10,622 (trainer:721) INFO: 4epoch:train:17253-18160batch: iter_time=2.221e-04, forward_time=0.154, loss_ctc=5.529, loss=2.765, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.010e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 03:05:08,758 (trainer:338) INFO: 4epoch results: [train] iter_time=2.426e-04, forward_time=0.153, loss_ctc=6.020, loss=3.010, backward_time=0.226, optim_step_time=0.032, optim0_lr0=2.651e-04, train_time=2.032, time=2 hours, 33 minutes and 56.38 seconds, total_count=72704, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=4.190, cer_ctc=0.110, cer=0.110, loss=2.095, time=7.16 seconds, total_count=60, gpu_max_cached_mem_GB=42.221, [att_plot] time=41.79 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-19 03:05:12,429 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 03:05:12,429 (trainer:272) INFO: 5/50epoch started. Estimated time to finish: 5 days, 8 hours and 50 minutes
[ALab02:0/2] 2023-07-19 03:13:05,362 (trainer:721) INFO: 5epoch:train:1-908batch: iter_time=6.754e-04, forward_time=0.154, loss_ctc=5.281, loss=2.641, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.049e-04, train_time=2.083
[ALab02:0/2] 2023-07-19 03:20:45,876 (trainer:721) INFO: 5epoch:train:909-1816batch: iter_time=2.157e-04, forward_time=0.153, loss_ctc=5.368, loss=2.684, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.086e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 03:28:26,132 (trainer:721) INFO: 5epoch:train:1817-2724batch: iter_time=2.240e-04, forward_time=0.153, loss_ctc=5.098, loss=2.549, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.124e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 03:36:07,463 (trainer:721) INFO: 5epoch:train:2725-3632batch: iter_time=2.160e-04, forward_time=0.153, loss_ctc=5.328, loss=2.664, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.162e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 03:43:46,055 (trainer:721) INFO: 5epoch:train:3633-4540batch: iter_time=2.134e-04, forward_time=0.153, loss_ctc=5.360, loss=2.680, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.200e-04, train_time=2.020
[ALab02:0/2] 2023-07-19 03:51:28,688 (trainer:721) INFO: 5epoch:train:4541-5448batch: iter_time=2.163e-04, forward_time=0.154, loss_ctc=5.240, loss=2.620, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.238e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 03:59:08,338 (trainer:721) INFO: 5epoch:train:5449-6356batch: iter_time=2.123e-04, forward_time=0.153, loss_ctc=5.226, loss=2.613, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.276e-04, train_time=2.025
[ALab02:0/2] 2023-07-19 04:06:50,474 (trainer:721) INFO: 5epoch:train:6357-7264batch: iter_time=2.115e-04, forward_time=0.154, loss_ctc=5.124, loss=2.562, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.313e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 04:14:29,685 (trainer:721) INFO: 5epoch:train:7265-8172batch: iter_time=2.191e-04, forward_time=0.153, loss_ctc=5.081, loss=2.540, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.351e-04, train_time=2.023
[ALab02:0/2] 2023-07-19 04:22:09,266 (trainer:721) INFO: 5epoch:train:8173-9080batch: iter_time=2.114e-04, forward_time=0.153, loss_ctc=5.053, loss=2.527, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.389e-04, train_time=2.024
[ALab02:0/2] 2023-07-19 04:29:50,375 (trainer:721) INFO: 5epoch:train:9081-9988batch: iter_time=2.116e-04, forward_time=0.153, loss_ctc=5.142, loss=2.571, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.427e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 04:37:30,756 (trainer:721) INFO: 5epoch:train:9989-10896batch: iter_time=2.075e-04, forward_time=0.153, loss_ctc=5.130, loss=2.565, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.465e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 04:45:11,641 (trainer:721) INFO: 5epoch:train:10897-11804batch: iter_time=2.185e-04, forward_time=0.153, loss_ctc=4.993, loss=2.496, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.502e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 04:52:49,952 (trainer:721) INFO: 5epoch:train:11805-12712batch: iter_time=2.149e-04, forward_time=0.153, loss_ctc=5.005, loss=2.503, backward_time=0.224, optim_step_time=0.033, optim0_lr0=3.540e-04, train_time=2.019
[ALab02:0/2] 2023-07-19 05:00:30,043 (trainer:721) INFO: 5epoch:train:12713-13620batch: iter_time=2.148e-04, forward_time=0.153, loss_ctc=5.077, loss=2.538, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.578e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 05:08:06,140 (trainer:721) INFO: 5epoch:train:13621-14528batch: iter_time=2.154e-04, forward_time=0.152, loss_ctc=4.925, loss=2.462, backward_time=0.223, optim_step_time=0.032, optim0_lr0=3.616e-04, train_time=2.009
[ALab02:0/2] 2023-07-19 05:15:48,783 (trainer:721) INFO: 5epoch:train:14529-15436batch: iter_time=2.232e-04, forward_time=0.154, loss_ctc=4.878, loss=2.439, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.654e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 05:23:29,146 (trainer:721) INFO: 5epoch:train:15437-16344batch: iter_time=2.274e-04, forward_time=0.153, loss_ctc=5.116, loss=2.558, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.692e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 05:31:09,026 (trainer:721) INFO: 5epoch:train:16345-17252batch: iter_time=2.162e-04, forward_time=0.153, loss_ctc=4.956, loss=2.478, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.730e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 05:38:50,034 (trainer:721) INFO: 5epoch:train:17253-18160batch: iter_time=2.145e-04, forward_time=0.154, loss_ctc=4.980, loss=2.490, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.767e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 05:39:48,182 (trainer:338) INFO: 5epoch results: [train] iter_time=2.389e-04, forward_time=0.153, loss_ctc=5.118, loss=2.559, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.408e-04, train_time=2.030, time=2 hours, 33 minutes and 47.21 seconds, total_count=90880, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=3.904, cer_ctc=0.099, cer=0.099, loss=1.952, time=6.65 seconds, total_count=75, gpu_max_cached_mem_GB=42.221, [att_plot] time=41.9 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-19 05:39:51,675 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 05:39:51,676 (trainer:272) INFO: 6/50epoch started. Estimated time to finish: 5 days, 4 hours and 1 minute
[ALab02:0/2] 2023-07-19 05:47:42,889 (trainer:721) INFO: 6epoch:train:1-908batch: iter_time=8.036e-04, forward_time=0.153, loss_ctc=4.775, loss=2.387, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.806e-04, train_time=2.076
[ALab02:0/2] 2023-07-19 05:55:22,995 (trainer:721) INFO: 6epoch:train:909-1816batch: iter_time=2.268e-04, forward_time=0.153, loss_ctc=4.725, loss=2.363, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.844e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 06:03:03,979 (trainer:721) INFO: 6epoch:train:1817-2724batch: iter_time=2.242e-04, forward_time=0.153, loss_ctc=4.727, loss=2.363, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.881e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 06:10:44,887 (trainer:721) INFO: 6epoch:train:2725-3632batch: iter_time=2.063e-04, forward_time=0.153, loss_ctc=4.725, loss=2.362, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.919e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 06:18:26,076 (trainer:721) INFO: 6epoch:train:3633-4540batch: iter_time=2.102e-04, forward_time=0.153, loss_ctc=4.835, loss=2.417, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.957e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 06:26:09,043 (trainer:721) INFO: 6epoch:train:4541-5448batch: iter_time=2.137e-04, forward_time=0.154, loss_ctc=4.563, loss=2.281, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.995e-04, train_time=2.039
[ALab02:0/2] 2023-07-19 06:33:50,007 (trainer:721) INFO: 6epoch:train:5449-6356batch: iter_time=2.234e-04, forward_time=0.154, loss_ctc=4.570, loss=2.285, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.033e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 06:41:31,941 (trainer:721) INFO: 6epoch:train:6357-7264batch: iter_time=2.249e-04, forward_time=0.153, loss_ctc=4.594, loss=2.297, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.071e-04, train_time=2.035
[ALab02:0/2] 2023-07-19 06:49:15,604 (trainer:721) INFO: 6epoch:train:7265-8172batch: iter_time=2.121e-04, forward_time=0.154, loss_ctc=4.553, loss=2.277, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.108e-04, train_time=2.042
[ALab02:0/2] 2023-07-19 06:56:56,133 (trainer:721) INFO: 6epoch:train:8173-9080batch: iter_time=2.163e-04, forward_time=0.153, loss_ctc=4.531, loss=2.266, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.146e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 07:04:36,924 (trainer:721) INFO: 6epoch:train:9081-9988batch: iter_time=2.231e-04, forward_time=0.153, loss_ctc=4.546, loss=2.273, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.184e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 07:12:17,668 (trainer:721) INFO: 6epoch:train:9989-10896batch: iter_time=2.216e-04, forward_time=0.153, loss_ctc=4.615, loss=2.307, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.222e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 07:19:57,526 (trainer:721) INFO: 6epoch:train:10897-11804batch: iter_time=2.276e-04, forward_time=0.152, loss_ctc=4.606, loss=2.303, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.260e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 07:27:37,726 (trainer:721) INFO: 6epoch:train:11805-12712batch: iter_time=2.204e-04, forward_time=0.153, loss_ctc=4.551, loss=2.275, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.298e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 07:35:19,369 (trainer:721) INFO: 6epoch:train:12713-13620batch: iter_time=2.187e-04, forward_time=0.154, loss_ctc=4.492, loss=2.246, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.335e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 07:42:59,515 (trainer:721) INFO: 6epoch:train:13621-14528batch: iter_time=2.117e-04, forward_time=0.153, loss_ctc=4.602, loss=2.301, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.373e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 07:50:40,045 (trainer:721) INFO: 6epoch:train:14529-15436batch: iter_time=2.158e-04, forward_time=0.153, loss_ctc=4.503, loss=2.252, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.411e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 07:58:21,270 (trainer:721) INFO: 6epoch:train:15437-16344batch: iter_time=2.165e-04, forward_time=0.154, loss_ctc=4.531, loss=2.266, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.449e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 08:06:04,100 (trainer:721) INFO: 6epoch:train:16345-17252batch: iter_time=2.184e-04, forward_time=0.154, loss_ctc=4.452, loss=2.226, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.487e-04, train_time=2.039
[ALab02:0/2] 2023-07-19 08:13:44,625 (trainer:721) INFO: 6epoch:train:17253-18160batch: iter_time=7.074e-04, forward_time=0.153, loss_ctc=4.403, loss=2.202, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.525e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 08:14:45,341 (trainer:338) INFO: 6epoch results: [train] iter_time=2.721e-04, forward_time=0.153, loss_ctc=4.594, loss=2.297, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.166e-04, train_time=2.033, time=2 hours, 34 minutes and 2.62 seconds, total_count=109056, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=3.745, cer_ctc=0.095, cer=0.095, loss=1.872, time=8.53 seconds, total_count=90, gpu_max_cached_mem_GB=42.221, [att_plot] time=42.51 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-19 08:14:50,441 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 08:14:50,441 (trainer:272) INFO: 7/50epoch started. Estimated time to finish: 5 days and 6.54 seconds
[ALab02:0/2] 2023-07-19 08:22:41,327 (trainer:721) INFO: 7epoch:train:1-908batch: iter_time=0.001, forward_time=0.153, loss_ctc=4.243, loss=2.121, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.563e-04, train_time=2.074
[ALab02:0/2] 2023-07-19 08:30:23,806 (trainer:721) INFO: 7epoch:train:909-1816batch: iter_time=2.241e-04, forward_time=0.154, loss_ctc=4.209, loss=2.104, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.601e-04, train_time=2.037
[ALab02:0/2] 2023-07-19 08:38:06,431 (trainer:721) INFO: 7epoch:train:1817-2724batch: iter_time=2.187e-04, forward_time=0.154, loss_ctc=4.308, loss=2.154, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.639e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 08:45:46,969 (trainer:721) INFO: 7epoch:train:2725-3632batch: iter_time=5.903e-04, forward_time=0.153, loss_ctc=4.279, loss=2.140, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.677e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 08:53:29,137 (trainer:721) INFO: 7epoch:train:3633-4540batch: iter_time=2.218e-04, forward_time=0.154, loss_ctc=4.243, loss=2.121, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.714e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 09:01:09,076 (trainer:721) INFO: 7epoch:train:4541-5448batch: iter_time=2.176e-04, forward_time=0.152, loss_ctc=4.268, loss=2.134, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.752e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 09:08:48,388 (trainer:721) INFO: 7epoch:train:5449-6356batch: iter_time=2.309e-04, forward_time=0.153, loss_ctc=4.264, loss=2.132, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.790e-04, train_time=2.023
[ALab02:0/2] 2023-07-19 09:16:29,816 (trainer:721) INFO: 7epoch:train:6357-7264batch: iter_time=2.064e-04, forward_time=0.153, loss_ctc=4.269, loss=2.135, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.828e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 09:24:12,027 (trainer:721) INFO: 7epoch:train:7265-8172batch: iter_time=2.138e-04, forward_time=0.154, loss_ctc=4.302, loss=2.151, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.866e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 09:31:53,278 (trainer:721) INFO: 7epoch:train:8173-9080batch: iter_time=2.376e-04, forward_time=0.153, loss_ctc=4.422, loss=2.211, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.904e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 09:39:35,992 (trainer:721) INFO: 7epoch:train:9081-9988batch: iter_time=2.099e-04, forward_time=0.154, loss_ctc=4.277, loss=2.138, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.941e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 09:47:17,784 (trainer:721) INFO: 7epoch:train:9989-10896batch: iter_time=2.094e-04, forward_time=0.154, loss_ctc=4.277, loss=2.139, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.979e-04, train_time=2.034
[ALab02:0/2] 2023-07-19 09:54:57,716 (trainer:721) INFO: 7epoch:train:10897-11804batch: iter_time=2.203e-04, forward_time=0.153, loss_ctc=4.236, loss=2.118, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.991e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 10:02:38,681 (trainer:721) INFO: 7epoch:train:11805-12712batch: iter_time=2.395e-04, forward_time=0.153, loss_ctc=4.221, loss=2.110, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.973e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 10:10:19,798 (trainer:721) INFO: 7epoch:train:12713-13620batch: iter_time=2.230e-04, forward_time=0.154, loss_ctc=4.173, loss=2.087, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.954e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 10:17:59,886 (trainer:721) INFO: 7epoch:train:13621-14528batch: iter_time=2.189e-04, forward_time=0.153, loss_ctc=4.011, loss=2.005, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.936e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 10:25:42,798 (trainer:721) INFO: 7epoch:train:14529-15436batch: iter_time=2.080e-04, forward_time=0.154, loss_ctc=4.073, loss=2.036, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.918e-04, train_time=2.039
[ALab02:0/2] 2023-07-19 10:33:24,587 (trainer:721) INFO: 7epoch:train:15437-16344batch: iter_time=2.156e-04, forward_time=0.154, loss_ctc=4.080, loss=2.040, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.900e-04, train_time=2.034
[ALab02:0/2] 2023-07-19 10:41:05,565 (trainer:721) INFO: 7epoch:train:16345-17252batch: iter_time=2.065e-04, forward_time=0.154, loss_ctc=4.037, loss=2.019, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.882e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 10:48:45,657 (trainer:721) INFO: 7epoch:train:17253-18160batch: iter_time=2.192e-04, forward_time=0.153, loss_ctc=4.040, loss=2.020, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.865e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 10:49:43,591 (trainer:338) INFO: 7epoch results: [train] iter_time=2.780e-04, forward_time=0.153, loss_ctc=4.211, loss=2.106, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.834e-04, train_time=2.034, time=2 hours, 34 minutes and 4.67 seconds, total_count=127232, gpu_max_cached_mem_GB=42.221, [valid] loss_ctc=3.402, cer_ctc=0.085, cer=0.085, loss=1.701, time=8.81 seconds, total_count=105, gpu_max_cached_mem_GB=42.221, [att_plot] time=39.66 seconds, total_count=0, gpu_max_cached_mem_GB=42.221
[ALab02:0/2] 2023-07-19 10:49:47,971 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 10:49:47,972 (trainer:272) INFO: 8/50epoch started. Estimated time to finish: 4 days, 20 hours and 23 minutes
[ALab02:0/2] 2023-07-19 10:57:39,441 (trainer:721) INFO: 8epoch:train:1-908batch: iter_time=7.455e-04, forward_time=0.153, loss_ctc=3.806, loss=1.903, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.847e-04, train_time=2.077
[ALab02:0/2] 2023-07-19 11:05:21,036 (trainer:721) INFO: 8epoch:train:909-1816batch: iter_time=2.151e-04, forward_time=0.154, loss_ctc=3.853, loss=1.926, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.830e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 11:13:01,946 (trainer:721) INFO: 8epoch:train:1817-2724batch: iter_time=2.200e-04, forward_time=0.153, loss_ctc=3.862, loss=1.931, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.813e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 11:20:42,566 (trainer:721) INFO: 8epoch:train:2725-3632batch: iter_time=2.101e-04, forward_time=0.153, loss_ctc=3.804, loss=1.902, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.796e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 11:28:24,638 (trainer:721) INFO: 8epoch:train:3633-4540batch: iter_time=2.065e-04, forward_time=0.154, loss_ctc=3.669, loss=1.834, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.780e-04, train_time=2.035
[ALab02:0/2] 2023-07-19 11:36:05,890 (trainer:721) INFO: 8epoch:train:4541-5448batch: iter_time=2.185e-04, forward_time=0.153, loss_ctc=3.763, loss=1.882, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.763e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 11:43:48,662 (trainer:721) INFO: 8epoch:train:5449-6356batch: iter_time=9.897e-04, forward_time=0.154, loss_ctc=3.771, loss=1.885, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.747e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 11:51:29,092 (trainer:721) INFO: 8epoch:train:6357-7264batch: iter_time=2.125e-04, forward_time=0.153, loss_ctc=3.812, loss=1.906, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.731e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 11:59:10,463 (trainer:721) INFO: 8epoch:train:7265-8172batch: iter_time=2.037e-04, forward_time=0.154, loss_ctc=3.747, loss=1.874, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.715e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 12:06:50,035 (trainer:721) INFO: 8epoch:train:8173-9080batch: iter_time=2.192e-04, forward_time=0.153, loss_ctc=3.695, loss=1.848, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.699e-04, train_time=2.024
[ALab02:0/2] 2023-07-19 12:14:33,716 (trainer:721) INFO: 8epoch:train:9081-9988batch: iter_time=2.975e-04, forward_time=0.155, loss_ctc=3.572, loss=1.786, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.683e-04, train_time=2.042
[ALab02:0/2] 2023-07-19 12:22:16,291 (trainer:721) INFO: 8epoch:train:9989-10896batch: iter_time=2.115e-04, forward_time=0.154, loss_ctc=3.644, loss=1.822, backward_time=0.227, optim_step_time=0.032, optim0_lr0=4.668e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 12:29:56,326 (trainer:721) INFO: 8epoch:train:10897-11804batch: iter_time=2.107e-04, forward_time=0.153, loss_ctc=3.631, loss=1.815, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.653e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 12:37:36,490 (trainer:721) INFO: 8epoch:train:11805-12712batch: iter_time=2.138e-04, forward_time=0.153, loss_ctc=3.581, loss=1.791, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.637e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 12:45:17,313 (trainer:721) INFO: 8epoch:train:12713-13620batch: iter_time=2.195e-04, forward_time=0.153, loss_ctc=3.582, loss=1.791, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.622e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 12:52:57,073 (trainer:721) INFO: 8epoch:train:13621-14528batch: iter_time=2.064e-04, forward_time=0.153, loss_ctc=3.553, loss=1.776, backward_time=0.225, optim_step_time=0.032, optim0_lr0=4.608e-04, train_time=2.025
[ALab02:0/2] 2023-07-19 13:00:39,120 (trainer:721) INFO: 8epoch:train:14529-15436batch: iter_time=2.190e-04, forward_time=0.154, loss_ctc=3.499, loss=1.749, backward_time=0.226, optim_step_time=0.032, optim0_lr0=4.593e-04, train_time=2.035
[ALab02:0/2] 2023-07-19 13:08:17,457 (trainer:721) INFO: 8epoch:train:15437-16344batch: iter_time=2.206e-04, forward_time=0.153, loss_ctc=3.495, loss=1.748, backward_time=0.224, optim_step_time=0.033, optim0_lr0=4.578e-04, train_time=2.019
[ALab02:0/2] 2023-07-19 13:15:59,082 (trainer:721) INFO: 8epoch:train:16345-17252batch: iter_time=2.213e-04, forward_time=0.154, loss_ctc=3.521, loss=1.760, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.564e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 13:23:38,751 (trainer:721) INFO: 8epoch:train:17253-18160batch: iter_time=2.216e-04, forward_time=0.153, loss_ctc=3.468, loss=1.734, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.549e-04, train_time=2.025
[ALab02:0/2] 2023-07-19 13:24:38,495 (trainer:338) INFO: 8epoch results: [train] iter_time=2.841e-04, forward_time=0.153, loss_ctc=3.666, loss=1.833, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.694e-04, train_time=2.033, time=2 hours, 34 minutes and 0.36 seconds, total_count=145408, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.287, cer_ctc=0.079, cer=0.079, loss=1.644, time=8.58 seconds, total_count=120, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.59 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-19 13:24:42,324 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 13:24:42,324 (trainer:272) INFO: 9/50epoch started. Estimated time to finish: 4 days, 17 hours and 1 minute
[ALab02:0/2] 2023-07-19 13:32:34,249 (trainer:721) INFO: 9epoch:train:1-908batch: iter_time=8.737e-04, forward_time=0.154, loss_ctc=3.270, loss=1.635, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.535e-04, train_time=2.079
[ALab02:0/2] 2023-07-19 13:40:14,128 (trainer:721) INFO: 9epoch:train:909-1816batch: iter_time=2.314e-04, forward_time=0.153, loss_ctc=3.279, loss=1.640, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.521e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 13:47:56,047 (trainer:721) INFO: 9epoch:train:1817-2724batch: iter_time=2.227e-04, forward_time=0.154, loss_ctc=3.374, loss=1.687, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.507e-04, train_time=2.035
[ALab02:0/2] 2023-07-19 13:55:36,227 (trainer:721) INFO: 9epoch:train:2725-3632batch: iter_time=2.260e-04, forward_time=0.153, loss_ctc=3.373, loss=1.686, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.493e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 14:03:16,985 (trainer:721) INFO: 9epoch:train:3633-4540batch: iter_time=0.001, forward_time=0.153, loss_ctc=3.272, loss=1.636, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.480e-04, train_time=2.030
[ALab02:0/2] 2023-07-19 14:10:57,160 (trainer:721) INFO: 9epoch:train:4541-5448batch: iter_time=2.296e-04, forward_time=0.153, loss_ctc=3.254, loss=1.627, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.466e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 14:18:39,692 (trainer:721) INFO: 9epoch:train:5449-6356batch: iter_time=2.115e-04, forward_time=0.154, loss_ctc=3.268, loss=1.634, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.453e-04, train_time=2.037
[ALab02:0/2] 2023-07-19 14:26:20,388 (trainer:721) INFO: 9epoch:train:6357-7264batch: iter_time=2.197e-04, forward_time=0.154, loss_ctc=3.260, loss=1.630, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.439e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 14:34:02,699 (trainer:721) INFO: 9epoch:train:7265-8172batch: iter_time=2.263e-04, forward_time=0.154, loss_ctc=3.267, loss=1.634, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.426e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 14:41:42,778 (trainer:721) INFO: 9epoch:train:8173-9080batch: iter_time=2.227e-04, forward_time=0.153, loss_ctc=3.304, loss=1.652, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.413e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 14:49:25,929 (trainer:721) INFO: 9epoch:train:9081-9988batch: iter_time=2.294e-04, forward_time=0.155, loss_ctc=3.213, loss=1.607, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.400e-04, train_time=2.040
[ALab02:0/2] 2023-07-19 14:57:05,511 (trainer:721) INFO: 9epoch:train:9989-10896batch: iter_time=2.150e-04, forward_time=0.153, loss_ctc=3.170, loss=1.585, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.387e-04, train_time=2.024
[ALab02:0/2] 2023-07-19 15:04:45,885 (trainer:721) INFO: 9epoch:train:10897-11804batch: iter_time=2.138e-04, forward_time=0.153, loss_ctc=3.286, loss=1.643, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.375e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 15:12:26,326 (trainer:721) INFO: 9epoch:train:11805-12712batch: iter_time=2.623e-04, forward_time=0.153, loss_ctc=3.256, loss=1.628, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.362e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 15:20:09,769 (trainer:721) INFO: 9epoch:train:12713-13620batch: iter_time=2.255e-04, forward_time=0.155, loss_ctc=3.107, loss=1.553, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.349e-04, train_time=2.041
[ALab02:0/2] 2023-07-19 15:27:49,841 (trainer:721) INFO: 9epoch:train:13621-14528batch: iter_time=2.169e-04, forward_time=0.153, loss_ctc=3.103, loss=1.552, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.337e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 15:35:29,698 (trainer:721) INFO: 9epoch:train:14529-15436batch: iter_time=2.272e-04, forward_time=0.153, loss_ctc=3.182, loss=1.591, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.325e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 15:43:11,109 (trainer:721) INFO: 9epoch:train:15437-16344batch: iter_time=2.308e-04, forward_time=0.154, loss_ctc=3.090, loss=1.545, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.313e-04, train_time=2.032
[ALab02:0/2] 2023-07-19 15:50:52,571 (trainer:721) INFO: 9epoch:train:16345-17252batch: iter_time=2.171e-04, forward_time=0.154, loss_ctc=3.085, loss=1.542, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.301e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 15:58:34,724 (trainer:721) INFO: 9epoch:train:17253-18160batch: iter_time=2.116e-04, forward_time=0.154, loss_ctc=3.063, loss=1.531, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.289e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 15:59:32,036 (trainer:338) INFO: 9epoch results: [train] iter_time=3.106e-04, forward_time=0.154, loss_ctc=3.224, loss=1.612, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.408e-04, train_time=2.033, time=2 hours, 34 minutes and 1.69 seconds, total_count=163584, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.056, cer_ctc=0.075, cer=0.075, loss=1.528, time=6.65 seconds, total_count=135, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.37 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-19 15:59:36,374 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 15:59:36,375 (trainer:272) INFO: 10/50epoch started. Estimated time to finish: 4 days, 13 hours and 50 minutes
[ALab02:0/2] 2023-07-19 16:07:27,863 (trainer:721) INFO: 10epoch:train:1-908batch: iter_time=7.134e-04, forward_time=0.154, loss_ctc=3.014, loss=1.507, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.276e-04, train_time=2.077
[ALab02:0/2] 2023-07-19 16:15:06,294 (trainer:721) INFO: 10epoch:train:909-1816batch: iter_time=2.124e-04, forward_time=0.153, loss_ctc=2.952, loss=1.476, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.265e-04, train_time=2.019
[ALab02:0/2] 2023-07-19 16:22:48,417 (trainer:721) INFO: 10epoch:train:1817-2724batch: iter_time=2.182e-04, forward_time=0.154, loss_ctc=2.811, loss=1.405, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.253e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 16:30:27,120 (trainer:721) INFO: 10epoch:train:2725-3632batch: iter_time=2.171e-04, forward_time=0.153, loss_ctc=2.932, loss=1.466, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.241e-04, train_time=2.021
[ALab02:0/2] 2023-07-19 16:38:08,673 (trainer:721) INFO: 10epoch:train:3633-4540batch: iter_time=2.130e-04, forward_time=0.154, loss_ctc=2.919, loss=1.459, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.230e-04, train_time=2.033
[ALab02:0/2] 2023-07-19 16:45:51,739 (trainer:721) INFO: 10epoch:train:4541-5448batch: iter_time=2.207e-04, forward_time=0.154, loss_ctc=2.919, loss=1.460, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.218e-04, train_time=2.040
[ALab02:0/2] 2023-07-19 16:53:33,667 (trainer:721) INFO: 10epoch:train:5449-6356batch: iter_time=2.191e-04, forward_time=0.154, loss_ctc=2.911, loss=1.456, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.207e-04, train_time=2.035
[ALab02:0/2] 2023-07-19 17:01:16,184 (trainer:721) INFO: 10epoch:train:6357-7264batch: iter_time=2.254e-04, forward_time=0.154, loss_ctc=2.889, loss=1.445, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.196e-04, train_time=2.037
[ALab02:0/2] 2023-07-19 17:08:57,376 (trainer:721) INFO: 10epoch:train:7265-8172batch: iter_time=2.176e-04, forward_time=0.154, loss_ctc=2.923, loss=1.462, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.185e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 17:16:39,836 (trainer:721) INFO: 10epoch:train:8173-9080batch: iter_time=2.168e-04, forward_time=0.154, loss_ctc=2.926, loss=1.463, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.174e-04, train_time=2.037
[ALab02:0/2] 2023-07-19 17:24:20,418 (trainer:721) INFO: 10epoch:train:9081-9988batch: iter_time=2.128e-04, forward_time=0.154, loss_ctc=2.905, loss=1.453, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.163e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 17:32:02,591 (trainer:721) INFO: 10epoch:train:9989-10896batch: iter_time=2.246e-04, forward_time=0.154, loss_ctc=2.844, loss=1.422, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.152e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 17:39:44,910 (trainer:721) INFO: 10epoch:train:10897-11804batch: iter_time=2.114e-04, forward_time=0.154, loss_ctc=2.968, loss=1.484, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.141e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 17:47:26,922 (trainer:721) INFO: 10epoch:train:11805-12712batch: iter_time=2.222e-04, forward_time=0.154, loss_ctc=2.807, loss=1.404, backward_time=0.226, optim_step_time=0.034, optim0_lr0=4.130e-04, train_time=2.035
[ALab02:0/2] 2023-07-19 17:55:06,104 (trainer:721) INFO: 10epoch:train:12713-13620batch: iter_time=2.333e-04, forward_time=0.153, loss_ctc=2.873, loss=1.437, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.120e-04, train_time=2.023
[ALab02:0/2] 2023-07-19 18:02:49,226 (trainer:721) INFO: 10epoch:train:13621-14528batch: iter_time=2.291e-04, forward_time=0.154, loss_ctc=2.788, loss=1.394, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.109e-04, train_time=2.040
[ALab02:0/2] 2023-07-19 18:10:33,666 (trainer:721) INFO: 10epoch:train:14529-15436batch: iter_time=9.309e-04, forward_time=0.155, loss_ctc=2.789, loss=1.395, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.099e-04, train_time=2.046
[ALab02:0/2] 2023-07-19 18:18:13,585 (trainer:721) INFO: 10epoch:train:15437-16344batch: iter_time=2.220e-04, forward_time=0.153, loss_ctc=2.793, loss=1.396, backward_time=0.225, optim_step_time=0.033, optim0_lr0=4.088e-04, train_time=2.026
[ALab02:0/2] 2023-07-19 18:25:54,299 (trainer:721) INFO: 10epoch:train:16345-17252batch: iter_time=2.275e-04, forward_time=0.153, loss_ctc=2.732, loss=1.366, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.078e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 18:33:34,717 (trainer:721) INFO: 10epoch:train:17253-18160batch: iter_time=2.254e-04, forward_time=0.153, loss_ctc=2.676, loss=1.338, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.068e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 18:34:39,277 (trainer:338) INFO: 10epoch results: [train] iter_time=2.806e-04, forward_time=0.154, loss_ctc=2.868, loss=1.434, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.170e-04, train_time=2.035, time=2 hours, 34 minutes and 7.8 seconds, total_count=181760, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.006, cer_ctc=0.073, cer=0.073, loss=1.503, time=8.85 seconds, total_count=150, gpu_max_cached_mem_GB=42.223, [att_plot] time=46.25 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-19 18:34:44,641 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 18:34:44,642 (trainer:272) INFO: 11/50epoch started. Estimated time to finish: 4 days, 10 hours and 46 minutes
[ALab02:0/2] 2023-07-19 18:42:36,722 (trainer:721) INFO: 11epoch:train:1-908batch: iter_time=0.001, forward_time=0.154, loss_ctc=2.595, loss=1.297, backward_time=0.226, optim_step_time=0.034, optim0_lr0=4.058e-04, train_time=2.079
[ALab02:0/2] 2023-07-19 18:50:18,898 (trainer:721) INFO: 11epoch:train:909-1816batch: iter_time=2.294e-04, forward_time=0.154, loss_ctc=2.642, loss=1.321, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.047e-04, train_time=2.036
[ALab02:0/2] 2023-07-19 18:57:59,904 (trainer:721) INFO: 11epoch:train:1817-2724batch: iter_time=2.149e-04, forward_time=0.154, loss_ctc=2.681, loss=1.340, backward_time=0.226, optim_step_time=0.033, optim0_lr0=4.037e-04, train_time=2.031
[ALab02:0/2] 2023-07-19 19:05:44,460 (trainer:721) INFO: 11epoch:train:2725-3632batch: iter_time=2.200e-04, forward_time=0.155, loss_ctc=2.633, loss=1.317, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.028e-04, train_time=2.046
[ALab02:0/2] 2023-07-19 19:13:27,981 (trainer:721) INFO: 11epoch:train:3633-4540batch: iter_time=2.240e-04, forward_time=0.155, loss_ctc=2.611, loss=1.305, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.018e-04, train_time=2.042
[ALab02:0/2] 2023-07-19 19:21:11,064 (trainer:721) INFO: 11epoch:train:4541-5448batch: iter_time=2.280e-04, forward_time=0.154, loss_ctc=2.637, loss=1.319, backward_time=0.227, optim_step_time=0.033, optim0_lr0=4.008e-04, train_time=2.040
[ALab02:0/2] 2023-07-19 19:28:53,781 (trainer:721) INFO: 11epoch:train:5449-6356batch: iter_time=2.139e-04, forward_time=0.154, loss_ctc=2.666, loss=1.333, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.998e-04, train_time=2.038
[ALab02:0/2] 2023-07-19 19:36:33,907 (trainer:721) INFO: 11epoch:train:6357-7264batch: iter_time=2.146e-04, forward_time=0.153, loss_ctc=2.770, loss=1.385, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.989e-04, train_time=2.027
[ALab02:0/2] 2023-07-19 19:46:09,267 (trainer:721) INFO: 11epoch:train:7265-8172batch: iter_time=2.340e-04, forward_time=0.202, loss_ctc=2.704, loss=1.352, backward_time=0.277, optim_step_time=0.033, optim0_lr0=3.979e-04, train_time=2.534
[ALab02:0/2] 2023-07-19 19:58:30,993 (trainer:721) INFO: 11epoch:train:8173-9080batch: iter_time=2.644e-04, forward_time=0.252, loss_ctc=2.634, loss=1.317, backward_time=0.346, optim_step_time=0.035, optim0_lr0=3.970e-04, train_time=3.267
[ALab02:0/2] 2023-07-19 20:10:51,149 (trainer:721) INFO: 11epoch:train:9081-9988batch: iter_time=2.515e-04, forward_time=0.253, loss_ctc=2.631, loss=1.315, backward_time=0.348, optim_step_time=0.035, optim0_lr0=3.960e-04, train_time=3.260
[ALab02:0/2] 2023-07-19 20:22:43,043 (trainer:721) INFO: 11epoch:train:9989-10896batch: iter_time=2.533e-04, forward_time=0.246, loss_ctc=2.628, loss=1.314, backward_time=0.336, optim_step_time=0.035, optim0_lr0=3.951e-04, train_time=3.136
[ALab02:0/2] 2023-07-19 20:34:52,558 (trainer:721) INFO: 11epoch:train:10897-11804batch: iter_time=2.880e-04, forward_time=0.249, loss_ctc=2.564, loss=1.282, backward_time=0.342, optim_step_time=0.035, optim0_lr0=3.941e-04, train_time=3.213
[ALab02:0/2] 2023-07-19 20:47:28,569 (trainer:721) INFO: 11epoch:train:11805-12712batch: iter_time=2.779e-04, forward_time=0.257, loss_ctc=2.585, loss=1.293, backward_time=0.352, optim_step_time=0.035, optim0_lr0=3.932e-04, train_time=3.330
[ALab02:0/2] 2023-07-19 20:57:01,431 (trainer:721) INFO: 11epoch:train:12713-13620batch: iter_time=2.534e-04, forward_time=0.167, loss_ctc=2.604, loss=1.302, backward_time=0.249, optim_step_time=0.035, optim0_lr0=3.923e-04, train_time=2.523
[ALab02:0/2] 2023-07-19 21:06:09,924 (trainer:721) INFO: 11epoch:train:13621-14528batch: iter_time=2.473e-04, forward_time=0.156, loss_ctc=2.560, loss=1.280, backward_time=0.235, optim_step_time=0.034, optim0_lr0=3.914e-04, train_time=2.416
[ALab02:0/2] 2023-07-19 21:14:22,263 (trainer:721) INFO: 11epoch:train:14529-15436batch: iter_time=2.272e-04, forward_time=0.154, loss_ctc=2.616, loss=1.308, backward_time=0.229, optim_step_time=0.034, optim0_lr0=3.905e-04, train_time=2.169
[ALab02:0/2] 2023-07-19 21:22:07,548 (trainer:721) INFO: 11epoch:train:15437-16344batch: iter_time=2.285e-04, forward_time=0.154, loss_ctc=2.527, loss=1.263, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.896e-04, train_time=2.049
[ALab02:0/2] 2023-07-19 21:33:45,942 (trainer:721) INFO: 11epoch:train:16345-17252batch: iter_time=2.281e-04, forward_time=0.224, loss_ctc=2.514, loss=1.257, backward_time=0.298, optim_step_time=0.034, optim0_lr0=3.887e-04, train_time=3.076
[ALab02:0/2] 2023-07-19 21:48:32,600 (trainer:721) INFO: 11epoch:train:17253-18160batch: iter_time=2.681e-04, forward_time=0.244, loss_ctc=2.512, loss=1.256, backward_time=0.336, optim_step_time=0.034, optim0_lr0=3.878e-04, train_time=3.906
[ALab02:0/2] 2023-07-19 21:49:43,590 (trainer:338) INFO: 11epoch results: [train] iter_time=2.836e-04, forward_time=0.190, loss_ctc=2.615, loss=1.308, backward_time=0.269, optim_step_time=0.034, optim0_lr0=3.966e-04, train_time=2.563, time=3 hours, 14 minutes and 7.32 seconds, total_count=199936, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.053, cer_ctc=0.071, cer=0.071, loss=1.527, time=9.69 seconds, total_count=165, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.94 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-19 21:49:47,505 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-19 21:49:47,508 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/1epoch.pth
[ALab02:0/2] 2023-07-19 21:49:47,508 (trainer:272) INFO: 12/50epoch started. Estimated time to finish: 4 days, 10 hours and 10 minutes
[ALab02:0/2] 2023-07-19 22:04:48,392 (trainer:721) INFO: 12epoch:train:1-908batch: iter_time=8.469e-04, forward_time=0.244, loss_ctc=2.469, loss=1.234, backward_time=0.337, optim_step_time=0.034, optim0_lr0=3.869e-04, train_time=3.968
[ALab02:0/2] 2023-07-19 22:18:51,929 (trainer:721) INFO: 12epoch:train:909-1816batch: iter_time=2.778e-04, forward_time=0.245, loss_ctc=2.411, loss=1.206, backward_time=0.331, optim_step_time=0.034, optim0_lr0=3.860e-04, train_time=3.716
[ALab02:0/2] 2023-07-19 22:29:20,053 (trainer:721) INFO: 12epoch:train:1817-2724batch: iter_time=2.464e-04, forward_time=0.238, loss_ctc=2.499, loss=1.249, backward_time=0.295, optim_step_time=0.033, optim0_lr0=3.852e-04, train_time=2.767
[ALab02:0/2] 2023-07-19 22:39:51,433 (trainer:721) INFO: 12epoch:train:2725-3632batch: iter_time=2.401e-04, forward_time=0.239, loss_ctc=2.462, loss=1.231, backward_time=0.296, optim_step_time=0.033, optim0_lr0=3.843e-04, train_time=2.781
[ALab02:0/2] 2023-07-19 22:50:13,436 (trainer:721) INFO: 12epoch:train:3633-4540batch: iter_time=2.342e-04, forward_time=0.238, loss_ctc=2.466, loss=1.233, backward_time=0.289, optim_step_time=0.033, optim0_lr0=3.835e-04, train_time=2.740
[ALab02:0/2] 2023-07-19 23:00:30,661 (trainer:721) INFO: 12epoch:train:4541-5448batch: iter_time=2.348e-04, forward_time=0.233, loss_ctc=2.473, loss=1.236, backward_time=0.290, optim_step_time=0.033, optim0_lr0=3.826e-04, train_time=2.719
[ALab02:0/2] 2023-07-19 23:10:55,906 (trainer:721) INFO: 12epoch:train:5449-6356batch: iter_time=2.360e-04, forward_time=0.240, loss_ctc=2.509, loss=1.254, backward_time=0.290, optim_step_time=0.033, optim0_lr0=3.818e-04, train_time=2.754
[ALab02:0/2] 2023-07-19 23:21:20,666 (trainer:721) INFO: 12epoch:train:6357-7264batch: iter_time=2.268e-04, forward_time=0.236, loss_ctc=2.386, loss=1.193, backward_time=0.294, optim_step_time=0.033, optim0_lr0=3.809e-04, train_time=2.752
[ALab02:0/2] 2023-07-19 23:31:27,264 (trainer:721) INFO: 12epoch:train:7265-8172batch: iter_time=2.302e-04, forward_time=0.227, loss_ctc=2.402, loss=1.201, backward_time=0.285, optim_step_time=0.033, optim0_lr0=3.801e-04, train_time=2.672
[ALab02:0/2] 2023-07-19 23:39:07,635 (trainer:721) INFO: 12epoch:train:8173-9080batch: iter_time=2.167e-04, forward_time=0.153, loss_ctc=2.387, loss=1.193, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.793e-04, train_time=2.028
[ALab02:0/2] 2023-07-19 23:46:48,173 (trainer:721) INFO: 12epoch:train:9081-9988batch: iter_time=2.174e-04, forward_time=0.153, loss_ctc=2.418, loss=1.209, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.784e-04, train_time=2.029
[ALab02:0/2] 2023-07-19 23:54:28,642 (trainer:721) INFO: 12epoch:train:9989-10896batch: iter_time=2.177e-04, forward_time=0.153, loss_ctc=2.442, loss=1.221, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.776e-04, train_time=2.028
[ALab02:0/2] 2023-07-20 00:02:10,374 (trainer:721) INFO: 12epoch:train:10897-11804batch: iter_time=2.234e-04, forward_time=0.154, loss_ctc=2.369, loss=1.185, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.768e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 00:09:53,490 (trainer:721) INFO: 12epoch:train:11805-12712batch: iter_time=2.203e-04, forward_time=0.154, loss_ctc=2.375, loss=1.188, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.760e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 00:17:34,815 (trainer:721) INFO: 12epoch:train:12713-13620batch: iter_time=2.199e-04, forward_time=0.153, loss_ctc=2.341, loss=1.170, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.752e-04, train_time=2.032
[ALab02:0/2] 2023-07-20 00:25:18,126 (trainer:721) INFO: 12epoch:train:13621-14528batch: iter_time=2.216e-04, forward_time=0.154, loss_ctc=2.398, loss=1.199, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.744e-04, train_time=2.041
[ALab02:0/2] 2023-07-20 00:33:01,065 (trainer:721) INFO: 12epoch:train:14529-15436batch: iter_time=2.343e-04, forward_time=0.154, loss_ctc=2.385, loss=1.193, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.736e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 00:40:44,230 (trainer:721) INFO: 12epoch:train:15437-16344batch: iter_time=2.212e-04, forward_time=0.154, loss_ctc=2.361, loss=1.181, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.728e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 00:48:25,731 (trainer:721) INFO: 12epoch:train:16345-17252batch: iter_time=2.258e-04, forward_time=0.154, loss_ctc=2.339, loss=1.169, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.720e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 00:56:09,213 (trainer:721) INFO: 12epoch:train:17253-18160batch: iter_time=2.468e-04, forward_time=0.154, loss_ctc=2.352, loss=1.176, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.713e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 00:57:07,524 (trainer:338) INFO: 12epoch results: [train] iter_time=2.618e-04, forward_time=0.192, loss_ctc=2.412, loss=1.206, backward_time=0.260, optim_step_time=0.033, optim0_lr0=3.789e-04, train_time=2.462, time=3 hours, 6 minutes and 31.13 seconds, total_count=218112, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=2.955, cer_ctc=0.069, cer=0.069, loss=1.478, time=8.23 seconds, total_count=180, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.66 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 00:57:11,172 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 00:57:11,179 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/2epoch.pth
[ALab02:0/2] 2023-07-20 00:57:11,179 (trainer:272) INFO: 13/50epoch started. Estimated time to finish: 4 days, 8 hours and 43 minutes
[ALab02:0/2] 2023-07-20 01:05:03,916 (trainer:721) INFO: 13epoch:train:1-908batch: iter_time=8.831e-04, forward_time=0.154, loss_ctc=2.229, loss=1.114, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.705e-04, train_time=2.082
[ALab02:0/2] 2023-07-20 01:12:44,673 (trainer:721) INFO: 13epoch:train:909-1816batch: iter_time=2.242e-04, forward_time=0.153, loss_ctc=2.276, loss=1.138, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.697e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 01:20:26,490 (trainer:721) INFO: 13epoch:train:1817-2724batch: iter_time=2.242e-04, forward_time=0.153, loss_ctc=2.218, loss=1.109, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.689e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 01:28:07,523 (trainer:721) INFO: 13epoch:train:2725-3632batch: iter_time=2.214e-04, forward_time=0.153, loss_ctc=2.234, loss=1.117, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.682e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 01:35:50,981 (trainer:721) INFO: 13epoch:train:3633-4540batch: iter_time=2.131e-04, forward_time=0.154, loss_ctc=2.263, loss=1.131, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.674e-04, train_time=2.041
[ALab02:0/2] 2023-07-20 01:43:32,464 (trainer:721) INFO: 13epoch:train:4541-5448batch: iter_time=2.328e-04, forward_time=0.154, loss_ctc=2.286, loss=1.143, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.667e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 01:51:15,319 (trainer:721) INFO: 13epoch:train:5449-6356batch: iter_time=2.166e-04, forward_time=0.154, loss_ctc=2.304, loss=1.152, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.659e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 01:58:56,806 (trainer:721) INFO: 13epoch:train:6357-7264batch: iter_time=2.221e-04, forward_time=0.154, loss_ctc=2.266, loss=1.133, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.652e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 02:06:39,794 (trainer:721) INFO: 13epoch:train:7265-8172batch: iter_time=2.163e-04, forward_time=0.154, loss_ctc=2.271, loss=1.136, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.645e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 02:14:21,603 (trainer:721) INFO: 13epoch:train:8173-9080batch: iter_time=2.173e-04, forward_time=0.154, loss_ctc=2.224, loss=1.112, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.637e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 02:22:00,775 (trainer:721) INFO: 13epoch:train:9081-9988batch: iter_time=2.181e-04, forward_time=0.153, loss_ctc=2.171, loss=1.086, backward_time=0.224, optim_step_time=0.032, optim0_lr0=3.630e-04, train_time=2.023
[ALab02:0/2] 2023-07-20 02:29:44,974 (trainer:721) INFO: 13epoch:train:9989-10896batch: iter_time=2.228e-04, forward_time=0.155, loss_ctc=2.240, loss=1.120, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.623e-04, train_time=2.045
[ALab02:0/2] 2023-07-20 02:37:28,366 (trainer:721) INFO: 13epoch:train:10897-11804batch: iter_time=2.197e-04, forward_time=0.154, loss_ctc=2.252, loss=1.126, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.616e-04, train_time=2.041
[ALab02:0/2] 2023-07-20 02:45:09,011 (trainer:721) INFO: 13epoch:train:11805-12712batch: iter_time=2.204e-04, forward_time=0.153, loss_ctc=2.225, loss=1.112, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.609e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 02:52:49,896 (trainer:721) INFO: 13epoch:train:12713-13620batch: iter_time=2.440e-04, forward_time=0.154, loss_ctc=2.216, loss=1.108, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.602e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 03:00:31,645 (trainer:721) INFO: 13epoch:train:13621-14528batch: iter_time=2.177e-04, forward_time=0.154, loss_ctc=2.184, loss=1.092, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.594e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 03:08:10,953 (trainer:721) INFO: 13epoch:train:14529-15436batch: iter_time=2.138e-04, forward_time=0.153, loss_ctc=2.204, loss=1.102, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.587e-04, train_time=2.023
[ALab02:0/2] 2023-07-20 03:15:53,995 (trainer:721) INFO: 13epoch:train:15437-16344batch: iter_time=2.167e-04, forward_time=0.154, loss_ctc=2.155, loss=1.077, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.581e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 03:23:36,813 (trainer:721) INFO: 13epoch:train:16345-17252batch: iter_time=2.782e-04, forward_time=0.154, loss_ctc=2.202, loss=1.101, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.574e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 03:31:19,991 (trainer:721) INFO: 13epoch:train:17253-18160batch: iter_time=2.205e-04, forward_time=0.154, loss_ctc=2.231, loss=1.116, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.567e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 03:32:16,746 (trainer:338) INFO: 13epoch results: [train] iter_time=2.571e-04, forward_time=0.154, loss_ctc=2.232, loss=1.116, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.634e-04, train_time=2.037, time=2 hours, 34 minutes and 18.48 seconds, total_count=236288, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.262, cer_ctc=0.069, cer=0.069, loss=1.631, time=6.92 seconds, total_count=195, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.17 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 03:32:21,451 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-20 03:32:21,457 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/3epoch.pth
[ALab02:0/2] 2023-07-20 03:32:21,457 (trainer:272) INFO: 14/50epoch started. Estimated time to finish: 4 days, 5 hours and 28 minutes
[ALab02:0/2] 2023-07-20 03:40:13,304 (trainer:721) INFO: 14epoch:train:1-908batch: iter_time=8.622e-04, forward_time=0.153, loss_ctc=2.101, loss=1.051, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.560e-04, train_time=2.078
[ALab02:0/2] 2023-07-20 03:47:54,567 (trainer:721) INFO: 14epoch:train:909-1816batch: iter_time=2.350e-04, forward_time=0.154, loss_ctc=2.096, loss=1.048, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.553e-04, train_time=2.032
[ALab02:0/2] 2023-07-20 03:55:38,081 (trainer:721) INFO: 14epoch:train:1817-2724batch: iter_time=2.204e-04, forward_time=0.155, loss_ctc=2.129, loss=1.064, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.546e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 04:03:19,103 (trainer:721) INFO: 14epoch:train:2725-3632batch: iter_time=6.812e-04, forward_time=0.153, loss_ctc=2.143, loss=1.071, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.539e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 04:11:02,605 (trainer:721) INFO: 14epoch:train:3633-4540batch: iter_time=2.219e-04, forward_time=0.154, loss_ctc=2.107, loss=1.053, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.533e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 04:18:46,136 (trainer:721) INFO: 14epoch:train:4541-5448batch: iter_time=2.305e-04, forward_time=0.154, loss_ctc=2.088, loss=1.044, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.526e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 04:26:26,843 (trainer:721) INFO: 14epoch:train:5449-6356batch: iter_time=2.295e-04, forward_time=0.154, loss_ctc=2.142, loss=1.071, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.519e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 04:34:10,204 (trainer:721) INFO: 14epoch:train:6357-7264batch: iter_time=2.284e-04, forward_time=0.154, loss_ctc=2.063, loss=1.031, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.513e-04, train_time=2.041
[ALab02:0/2] 2023-07-20 04:41:50,766 (trainer:721) INFO: 14epoch:train:7265-8172batch: iter_time=2.244e-04, forward_time=0.153, loss_ctc=2.077, loss=1.039, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.506e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 04:49:31,268 (trainer:721) INFO: 14epoch:train:8173-9080batch: iter_time=2.279e-04, forward_time=0.153, loss_ctc=2.084, loss=1.042, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.500e-04, train_time=2.028
[ALab02:0/2] 2023-07-20 04:57:12,940 (trainer:721) INFO: 14epoch:train:9081-9988batch: iter_time=2.162e-04, forward_time=0.154, loss_ctc=2.094, loss=1.047, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.493e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 05:04:56,316 (trainer:721) INFO: 14epoch:train:9989-10896batch: iter_time=2.198e-04, forward_time=0.154, loss_ctc=2.025, loss=1.012, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.487e-04, train_time=2.041
[ALab02:0/2] 2023-07-20 05:12:35,923 (trainer:721) INFO: 14epoch:train:10897-11804batch: iter_time=2.217e-04, forward_time=0.153, loss_ctc=2.147, loss=1.074, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.481e-04, train_time=2.024
[ALab02:0/2] 2023-07-20 05:20:18,752 (trainer:721) INFO: 14epoch:train:11805-12712batch: iter_time=2.278e-04, forward_time=0.154, loss_ctc=2.079, loss=1.040, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.474e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 05:28:00,751 (trainer:721) INFO: 14epoch:train:12713-13620batch: iter_time=2.240e-04, forward_time=0.154, loss_ctc=2.071, loss=1.036, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.468e-04, train_time=2.035
[ALab02:0/2] 2023-07-20 05:35:42,183 (trainer:721) INFO: 14epoch:train:13621-14528batch: iter_time=2.194e-04, forward_time=0.154, loss_ctc=2.063, loss=1.031, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.462e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 05:43:24,352 (trainer:721) INFO: 14epoch:train:14529-15436batch: iter_time=8.227e-04, forward_time=0.154, loss_ctc=2.059, loss=1.030, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.455e-04, train_time=2.036
[ALab02:0/2] 2023-07-20 05:51:07,283 (trainer:721) INFO: 14epoch:train:15437-16344batch: iter_time=2.247e-04, forward_time=0.155, loss_ctc=2.043, loss=1.022, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.449e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 05:58:50,983 (trainer:721) INFO: 14epoch:train:16345-17252batch: iter_time=2.195e-04, forward_time=0.154, loss_ctc=2.028, loss=1.014, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.443e-04, train_time=2.043
[ALab02:0/2] 2023-07-20 06:06:34,182 (trainer:721) INFO: 14epoch:train:17253-18160batch: iter_time=2.206e-04, forward_time=0.154, loss_ctc=2.052, loss=1.026, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.437e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 06:07:30,090 (trainer:338) INFO: 14epoch results: [train] iter_time=3.088e-04, forward_time=0.154, loss_ctc=2.085, loss=1.042, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.497e-04, train_time=2.038, time=2 hours, 34 minutes and 21.96 seconds, total_count=254464, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.073, cer_ctc=0.067, cer=0.067, loss=1.536, time=6.85 seconds, total_count=210, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.81 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 06:07:33,829 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 06:07:33,832 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/4epoch.pth
[ALab02:0/2] 2023-07-20 06:07:33,833 (trainer:272) INFO: 15/50epoch started. Estimated time to finish: 4 days, 2 hours and 20 minutes
[ALab02:0/2] 2023-07-20 06:15:26,124 (trainer:721) INFO: 15epoch:train:1-908batch: iter_time=8.454e-04, forward_time=0.153, loss_ctc=2.002, loss=1.001, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.430e-04, train_time=2.080
[ALab02:0/2] 2023-07-20 06:23:07,301 (trainer:721) INFO: 15epoch:train:909-1816batch: iter_time=2.232e-04, forward_time=0.153, loss_ctc=1.976, loss=0.988, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.424e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 06:30:48,839 (trainer:721) INFO: 15epoch:train:1817-2724batch: iter_time=2.174e-04, forward_time=0.154, loss_ctc=1.990, loss=0.995, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.418e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 06:38:28,545 (trainer:721) INFO: 15epoch:train:2725-3632batch: iter_time=2.196e-04, forward_time=0.153, loss_ctc=2.013, loss=1.006, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.412e-04, train_time=2.025
[ALab02:0/2] 2023-07-20 06:46:11,754 (trainer:721) INFO: 15epoch:train:3633-4540batch: iter_time=2.286e-04, forward_time=0.154, loss_ctc=1.997, loss=0.998, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.406e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 06:53:57,162 (trainer:721) INFO: 15epoch:train:4541-5448batch: iter_time=2.177e-04, forward_time=0.155, loss_ctc=1.972, loss=0.986, backward_time=0.228, optim_step_time=0.033, optim0_lr0=3.400e-04, train_time=2.050
[ALab02:0/2] 2023-07-20 07:01:40,710 (trainer:721) INFO: 15epoch:train:5449-6356batch: iter_time=2.188e-04, forward_time=0.154, loss_ctc=1.991, loss=0.996, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.394e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 07:09:23,154 (trainer:721) INFO: 15epoch:train:6357-7264batch: iter_time=2.091e-04, forward_time=0.154, loss_ctc=1.967, loss=0.984, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.389e-04, train_time=2.037
[ALab02:0/2] 2023-07-20 07:17:05,588 (trainer:721) INFO: 15epoch:train:7265-8172batch: iter_time=2.349e-04, forward_time=0.154, loss_ctc=1.986, loss=0.993, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.383e-04, train_time=2.037
[ALab02:0/2] 2023-07-20 07:24:45,129 (trainer:721) INFO: 15epoch:train:8173-9080batch: iter_time=2.104e-04, forward_time=0.152, loss_ctc=2.039, loss=1.019, backward_time=0.225, optim_step_time=0.032, optim0_lr0=3.377e-04, train_time=2.024
[ALab02:0/2] 2023-07-20 07:32:29,799 (trainer:721) INFO: 15epoch:train:9081-9988batch: iter_time=7.972e-04, forward_time=0.155, loss_ctc=2.017, loss=1.009, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.371e-04, train_time=2.047
[ALab02:0/2] 2023-07-20 07:40:13,587 (trainer:721) INFO: 15epoch:train:9989-10896batch: iter_time=2.149e-04, forward_time=0.154, loss_ctc=1.945, loss=0.973, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.365e-04, train_time=2.043
[ALab02:0/2] 2023-07-20 07:47:54,818 (trainer:721) INFO: 15epoch:train:10897-11804batch: iter_time=2.199e-04, forward_time=0.154, loss_ctc=2.021, loss=1.011, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.359e-04, train_time=2.032
[ALab02:0/2] 2023-07-20 07:55:35,749 (trainer:721) INFO: 15epoch:train:11805-12712batch: iter_time=2.187e-04, forward_time=0.153, loss_ctc=1.940, loss=0.970, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.354e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 08:03:18,429 (trainer:721) INFO: 15epoch:train:12713-13620batch: iter_time=9.683e-04, forward_time=0.154, loss_ctc=1.967, loss=0.984, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.348e-04, train_time=2.038
[ALab02:0/2] 2023-07-20 08:11:01,530 (trainer:721) INFO: 15epoch:train:13621-14528batch: iter_time=2.355e-04, forward_time=0.154, loss_ctc=1.964, loss=0.982, backward_time=0.227, optim_step_time=0.032, optim0_lr0=3.342e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 08:18:43,713 (trainer:721) INFO: 15epoch:train:14529-15436batch: iter_time=2.323e-04, forward_time=0.154, loss_ctc=1.954, loss=0.977, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.337e-04, train_time=2.036
[ALab02:0/2] 2023-07-20 08:26:26,011 (trainer:721) INFO: 15epoch:train:15437-16344batch: iter_time=2.162e-04, forward_time=0.154, loss_ctc=1.925, loss=0.962, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.331e-04, train_time=2.036
[ALab02:0/2] 2023-07-20 08:34:06,987 (trainer:721) INFO: 15epoch:train:16345-17252batch: iter_time=2.166e-04, forward_time=0.153, loss_ctc=1.918, loss=0.959, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.326e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 08:41:47,974 (trainer:721) INFO: 15epoch:train:17253-18160batch: iter_time=3.833e-04, forward_time=0.154, loss_ctc=1.973, loss=0.986, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.320e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 08:42:47,802 (trainer:338) INFO: 15epoch results: [train] iter_time=3.263e-04, forward_time=0.154, loss_ctc=1.978, loss=0.989, backward_time=0.226, optim_step_time=0.033, optim0_lr0=3.374e-04, train_time=2.038, time=2 hours, 34 minutes and 23.8 seconds, total_count=272640, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.065, cer_ctc=0.066, cer=0.066, loss=1.533, time=8.32 seconds, total_count=225, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.85 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 08:42:51,955 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 08:42:51,957 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/5epoch.pth
[ALab02:0/2] 2023-07-20 08:42:51,957 (trainer:272) INFO: 16/50epoch started. Estimated time to finish: 3 days, 23 hours and 16 minutes
[ALab02:0/2] 2023-07-20 08:50:44,092 (trainer:721) INFO: 16epoch:train:1-908batch: iter_time=6.743e-04, forward_time=0.153, loss_ctc=1.911, loss=0.955, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.314e-04, train_time=2.080
[ALab02:0/2] 2023-07-20 08:58:24,830 (trainer:721) INFO: 16epoch:train:909-1816batch: iter_time=2.199e-04, forward_time=0.153, loss_ctc=1.868, loss=0.934, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.309e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 09:06:06,009 (trainer:721) INFO: 16epoch:train:1817-2724batch: iter_time=2.100e-04, forward_time=0.153, loss_ctc=1.890, loss=0.945, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.303e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 09:13:50,864 (trainer:721) INFO: 16epoch:train:2725-3632batch: iter_time=5.238e-04, forward_time=0.155, loss_ctc=1.832, loss=0.916, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.298e-04, train_time=2.048
[ALab02:0/2] 2023-07-20 09:21:33,178 (trainer:721) INFO: 16epoch:train:3633-4540batch: iter_time=2.140e-04, forward_time=0.154, loss_ctc=1.845, loss=0.923, backward_time=0.227, optim_step_time=0.033, optim0_lr0=3.293e-04, train_time=2.036
[ALab02:0/2] 2023-07-20 09:29:14,153 (trainer:721) INFO: 16epoch:train:4541-5448batch: iter_time=2.095e-04, forward_time=0.153, loss_ctc=1.876, loss=0.938, backward_time=0.226, optim_step_time=0.032, optim0_lr0=3.287e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 09:36:53,830 (trainer:721) INFO: 16epoch:train:5449-6356batch: iter_time=2.191e-04, forward_time=0.153, loss_ctc=1.890, loss=0.945, backward_time=0.225, optim_step_time=0.033, optim0_lr0=3.282e-04, train_time=2.025
[ALab02:0/2] 2023-07-20 09:44:32,478 (trainer:721) INFO: 16epoch:train:6357-7264batch: iter_time=2.343e-04, forward_time=0.152, loss_ctc=1.905, loss=0.953, backward_time=0.224, optim_step_time=0.033, optim0_lr0=3.276e-04, train_time=2.020
[ALab02:0/2] 2023-07-20 09:52:13,038 (trainer:721) INFO: 16epoch:train:7265-8172batch: iter_time=2.779e-04, forward_time=0.153, loss_ctc=1.884, loss=0.942, backward_time=0.226, optim_step_time=0.035, optim0_lr0=3.271e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 09:59:52,809 (trainer:721) INFO: 16epoch:train:8173-9080batch: iter_time=2.843e-04, forward_time=0.153, loss_ctc=1.837, loss=0.918, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.266e-04, train_time=2.025
[ALab02:0/2] 2023-07-20 10:07:34,101 (trainer:721) INFO: 16epoch:train:9081-9988batch: iter_time=2.889e-04, forward_time=0.154, loss_ctc=1.815, loss=0.907, backward_time=0.226, optim_step_time=0.035, optim0_lr0=3.261e-04, train_time=2.032
[ALab02:0/2] 2023-07-20 10:15:15,207 (trainer:721) INFO: 16epoch:train:9989-10896batch: iter_time=2.678e-04, forward_time=0.154, loss_ctc=1.860, loss=0.930, backward_time=0.226, optim_step_time=0.035, optim0_lr0=3.255e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 10:22:56,088 (trainer:721) INFO: 16epoch:train:10897-11804batch: iter_time=2.541e-04, forward_time=0.154, loss_ctc=1.847, loss=0.924, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.250e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 10:30:36,905 (trainer:721) INFO: 16epoch:train:11805-12712batch: iter_time=2.393e-04, forward_time=0.153, loss_ctc=1.798, loss=0.899, backward_time=0.226, optim_step_time=0.035, optim0_lr0=3.245e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 10:38:17,394 (trainer:721) INFO: 16epoch:train:12713-13620batch: iter_time=2.341e-04, forward_time=0.153, loss_ctc=1.882, loss=0.941, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.240e-04, train_time=2.028
[ALab02:0/2] 2023-07-20 10:45:58,201 (trainer:721) INFO: 16epoch:train:13621-14528batch: iter_time=2.405e-04, forward_time=0.153, loss_ctc=1.917, loss=0.959, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.235e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 10:54:02,522 (trainer:721) INFO: 16epoch:train:14529-15436batch: iter_time=2.390e-04, forward_time=0.162, loss_ctc=1.894, loss=0.947, backward_time=0.236, optim_step_time=0.034, optim0_lr0=3.230e-04, train_time=2.133
[ALab02:0/2] 2023-07-20 11:02:24,717 (trainer:721) INFO: 16epoch:train:15437-16344batch: iter_time=2.456e-04, forward_time=0.160, loss_ctc=1.903, loss=0.951, backward_time=0.240, optim_step_time=0.034, optim0_lr0=3.224e-04, train_time=2.212
[ALab02:0/2] 2023-07-20 11:10:23,257 (trainer:721) INFO: 16epoch:train:16345-17252batch: iter_time=2.367e-04, forward_time=0.153, loss_ctc=1.855, loss=0.928, backward_time=0.230, optim_step_time=0.035, optim0_lr0=3.219e-04, train_time=2.108
[ALab02:0/2] 2023-07-20 11:18:04,515 (trainer:721) INFO: 16epoch:train:17253-18160batch: iter_time=2.257e-04, forward_time=0.153, loss_ctc=1.868, loss=0.934, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.214e-04, train_time=2.032
[ALab02:0/2] 2023-07-20 11:19:01,747 (trainer:338) INFO: 16epoch results: [train] iter_time=2.769e-04, forward_time=0.154, loss_ctc=1.869, loss=0.934, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.264e-04, train_time=2.051, time=2 hours, 35 minutes and 22.17 seconds, total_count=290816, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=2.981, cer_ctc=0.065, cer=0.065, loss=1.491, time=8.37 seconds, total_count=240, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.25 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 11:19:05,900 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 11:19:05,903 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/6epoch.pth
[ALab02:0/2] 2023-07-20 11:19:05,904 (trainer:272) INFO: 17/50epoch started. Estimated time to finish: 3 days, 20 hours and 17 minutes
[ALab02:0/2] 2023-07-20 11:26:57,603 (trainer:721) INFO: 17epoch:train:1-908batch: iter_time=0.001, forward_time=0.153, loss_ctc=1.788, loss=0.894, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.209e-04, train_time=2.078
[ALab02:0/2] 2023-07-20 11:35:05,662 (trainer:721) INFO: 17epoch:train:909-1816batch: iter_time=2.557e-04, forward_time=0.153, loss_ctc=1.780, loss=0.890, backward_time=0.232, optim_step_time=0.035, optim0_lr0=3.204e-04, train_time=2.150
[ALab02:0/2] 2023-07-20 11:43:15,969 (trainer:721) INFO: 17epoch:train:1817-2724batch: iter_time=2.558e-04, forward_time=0.154, loss_ctc=1.787, loss=0.894, backward_time=0.233, optim_step_time=0.035, optim0_lr0=3.199e-04, train_time=2.160
[ALab02:0/2] 2023-07-20 11:51:24,917 (trainer:721) INFO: 17epoch:train:2725-3632batch: iter_time=2.579e-04, forward_time=0.154, loss_ctc=1.774, loss=0.887, backward_time=0.233, optim_step_time=0.035, optim0_lr0=3.194e-04, train_time=2.154
[ALab02:0/2] 2023-07-20 11:59:14,475 (trainer:721) INFO: 17epoch:train:3633-4540batch: iter_time=2.455e-04, forward_time=0.153, loss_ctc=1.838, loss=0.919, backward_time=0.228, optim_step_time=0.034, optim0_lr0=3.189e-04, train_time=2.068
[ALab02:0/2] 2023-07-20 12:06:54,436 (trainer:721) INFO: 17epoch:train:4541-5448batch: iter_time=2.273e-04, forward_time=0.152, loss_ctc=1.840, loss=0.920, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.185e-04, train_time=2.026
[ALab02:0/2] 2023-07-20 12:14:35,671 (trainer:721) INFO: 17epoch:train:5449-6356batch: iter_time=2.318e-04, forward_time=0.153, loss_ctc=1.782, loss=0.891, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.180e-04, train_time=2.032
[ALab02:0/2] 2023-07-20 12:22:19,917 (trainer:721) INFO: 17epoch:train:6357-7264batch: iter_time=2.476e-04, forward_time=0.154, loss_ctc=1.821, loss=0.911, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.175e-04, train_time=2.045
[ALab02:0/2] 2023-07-20 12:30:01,424 (trainer:721) INFO: 17epoch:train:7265-8172batch: iter_time=2.304e-04, forward_time=0.153, loss_ctc=1.766, loss=0.883, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.170e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 12:37:43,165 (trainer:721) INFO: 17epoch:train:8173-9080batch: iter_time=2.209e-04, forward_time=0.153, loss_ctc=1.809, loss=0.905, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.165e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 12:45:26,173 (trainer:721) INFO: 17epoch:train:9081-9988batch: iter_time=2.243e-04, forward_time=0.154, loss_ctc=1.728, loss=0.864, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.160e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 12:53:09,102 (trainer:721) INFO: 17epoch:train:9989-10896batch: iter_time=2.346e-04, forward_time=0.154, loss_ctc=1.831, loss=0.915, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.156e-04, train_time=2.039
[ALab02:0/2] 2023-07-20 13:00:50,566 (trainer:721) INFO: 17epoch:train:10897-11804batch: iter_time=2.249e-04, forward_time=0.153, loss_ctc=1.746, loss=0.873, backward_time=0.226, optim_step_time=0.035, optim0_lr0=3.151e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 13:08:32,088 (trainer:721) INFO: 17epoch:train:11805-12712batch: iter_time=2.337e-04, forward_time=0.153, loss_ctc=1.808, loss=0.904, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.146e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 13:16:15,195 (trainer:721) INFO: 17epoch:train:12713-13620batch: iter_time=0.001, forward_time=0.154, loss_ctc=1.811, loss=0.905, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.141e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 13:23:55,943 (trainer:721) INFO: 17epoch:train:13621-14528batch: iter_time=2.313e-04, forward_time=0.153, loss_ctc=1.763, loss=0.882, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.137e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 13:31:37,810 (trainer:721) INFO: 17epoch:train:14529-15436batch: iter_time=2.234e-04, forward_time=0.153, loss_ctc=1.758, loss=0.879, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.132e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 13:39:17,908 (trainer:721) INFO: 17epoch:train:15437-16344batch: iter_time=2.182e-04, forward_time=0.153, loss_ctc=1.768, loss=0.884, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.127e-04, train_time=2.027
[ALab02:0/2] 2023-07-20 13:46:59,989 (trainer:721) INFO: 17epoch:train:16345-17252batch: iter_time=2.260e-04, forward_time=0.154, loss_ctc=1.751, loss=0.876, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.123e-04, train_time=2.035
[ALab02:0/2] 2023-07-20 13:54:40,908 (trainer:721) INFO: 17epoch:train:17253-18160batch: iter_time=3.510e-04, forward_time=0.153, loss_ctc=1.743, loss=0.872, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.118e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 13:55:42,738 (trainer:338) INFO: 17epoch results: [train] iter_time=3.288e-04, forward_time=0.153, loss_ctc=1.784, loss=0.892, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.163e-04, train_time=2.056, time=2 hours, 35 minutes and 45.88 seconds, total_count=308992, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=2.989, cer_ctc=0.064, cer=0.064, loss=1.495, time=9.13 seconds, total_count=255, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.81 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 13:55:46,649 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 13:55:46,651 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/7epoch.pth
[ALab02:0/2] 2023-07-20 13:55:46,652 (trainer:272) INFO: 18/50epoch started. Estimated time to finish: 3 days, 17 hours and 23 minutes
[ALab02:0/2] 2023-07-20 14:03:35,676 (trainer:721) INFO: 18epoch:train:1-908batch: iter_time=5.962e-04, forward_time=0.152, loss_ctc=1.669, loss=0.834, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.114e-04, train_time=2.066
[ALab02:0/2] 2023-07-20 14:11:16,696 (trainer:721) INFO: 18epoch:train:909-1816batch: iter_time=2.312e-04, forward_time=0.153, loss_ctc=1.662, loss=0.831, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.109e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 14:18:59,338 (trainer:721) INFO: 18epoch:train:1817-2724batch: iter_time=2.384e-04, forward_time=0.154, loss_ctc=1.658, loss=0.829, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.105e-04, train_time=2.038
[ALab02:0/2] 2023-07-20 14:26:42,029 (trainer:721) INFO: 18epoch:train:2725-3632batch: iter_time=2.336e-04, forward_time=0.153, loss_ctc=1.662, loss=0.831, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.100e-04, train_time=2.038
[ALab02:0/2] 2023-07-20 14:34:23,618 (trainer:721) INFO: 18epoch:train:3633-4540batch: iter_time=2.243e-04, forward_time=0.154, loss_ctc=1.695, loss=0.847, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.095e-04, train_time=2.033
[ALab02:0/2] 2023-07-20 14:42:07,020 (trainer:721) INFO: 18epoch:train:4541-5448batch: iter_time=2.280e-04, forward_time=0.153, loss_ctc=1.710, loss=0.855, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.091e-04, train_time=2.041
[ALab02:0/2] 2023-07-20 14:49:52,000 (trainer:721) INFO: 18epoch:train:5449-6356batch: iter_time=2.248e-04, forward_time=0.152, loss_ctc=1.700, loss=0.850, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.087e-04, train_time=2.048
[ALab02:0/2] 2023-07-20 14:57:34,136 (trainer:721) INFO: 18epoch:train:6357-7264batch: iter_time=2.186e-04, forward_time=0.153, loss_ctc=1.719, loss=0.859, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.082e-04, train_time=2.036
[ALab02:0/2] 2023-07-20 15:05:17,639 (trainer:721) INFO: 18epoch:train:7265-8172batch: iter_time=2.258e-04, forward_time=0.153, loss_ctc=1.715, loss=0.857, backward_time=0.227, optim_step_time=0.034, optim0_lr0=3.078e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 15:12:59,489 (trainer:721) INFO: 18epoch:train:8173-9080batch: iter_time=2.231e-04, forward_time=0.153, loss_ctc=1.754, loss=0.877, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.073e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 15:20:40,191 (trainer:721) INFO: 18epoch:train:9081-9988batch: iter_time=2.310e-04, forward_time=0.153, loss_ctc=1.676, loss=0.838, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.069e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 15:28:20,928 (trainer:721) INFO: 18epoch:train:9989-10896batch: iter_time=2.318e-04, forward_time=0.153, loss_ctc=1.675, loss=0.837, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.065e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 15:35:59,693 (trainer:721) INFO: 18epoch:train:10897-11804batch: iter_time=2.276e-04, forward_time=0.152, loss_ctc=1.721, loss=0.860, backward_time=0.225, optim_step_time=0.034, optim0_lr0=3.060e-04, train_time=2.021
[ALab02:0/2] 2023-07-20 15:43:40,890 (trainer:721) INFO: 18epoch:train:11805-12712batch: iter_time=2.318e-04, forward_time=0.153, loss_ctc=1.690, loss=0.845, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.056e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 15:51:21,880 (trainer:721) INFO: 18epoch:train:12713-13620batch: iter_time=2.292e-04, forward_time=0.153, loss_ctc=1.662, loss=0.831, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.052e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 15:59:02,070 (trainer:721) INFO: 18epoch:train:13621-14528batch: iter_time=2.215e-04, forward_time=0.153, loss_ctc=1.633, loss=0.816, backward_time=0.226, optim_step_time=0.034, optim0_lr0=3.047e-04, train_time=2.027
[ALab02:0/2] 2023-07-20 16:06:49,633 (trainer:721) INFO: 18epoch:train:14529-15436batch: iter_time=2.477e-04, forward_time=0.158, loss_ctc=1.724, loss=0.862, backward_time=0.225, optim_step_time=0.043, optim0_lr0=3.043e-04, train_time=2.059
[ALab02:0/2] 2023-07-20 16:17:51,596 (trainer:721) INFO: 18epoch:train:15437-16344batch: iter_time=3.428e-04, forward_time=0.248, loss_ctc=1.680, loss=0.840, backward_time=0.306, optim_step_time=0.059, optim0_lr0=3.039e-04, train_time=2.916
[ALab02:0/2] 2023-07-20 16:30:21,947 (trainer:721) INFO: 18epoch:train:16345-17252batch: iter_time=3.674e-04, forward_time=0.290, loss_ctc=1.683, loss=0.841, backward_time=0.345, optim_step_time=0.058, optim0_lr0=3.035e-04, train_time=3.305
[ALab02:0/2] 2023-07-20 16:43:46,926 (trainer:721) INFO: 18epoch:train:17253-18160batch: iter_time=2.452e-04, forward_time=0.310, loss_ctc=1.646, loss=0.823, backward_time=0.377, optim_step_time=0.037, optim0_lr0=3.030e-04, train_time=3.546
[ALab02:0/2] 2023-07-20 16:44:49,193 (trainer:338) INFO: 18epoch results: [train] iter_time=2.610e-04, forward_time=0.173, loss_ctc=1.687, loss=0.843, backward_time=0.244, optim_step_time=0.037, optim0_lr0=3.071e-04, train_time=2.221, time=2 hours, 48 minutes and 12.51 seconds, total_count=327168, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.083, cer_ctc=0.065, cer=0.065, loss=1.542, time=9.62 seconds, total_count=270, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.4 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 16:44:53,521 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-20 16:44:53,523 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/8epoch.pth
[ALab02:0/2] 2023-07-20 16:44:53,523 (trainer:272) INFO: 19/50epoch started. Estimated time to finish: 3 days, 14 hours and 52 minutes
[ALab02:0/2] 2023-07-20 16:58:26,189 (trainer:721) INFO: 19epoch:train:1-908batch: iter_time=9.392e-04, forward_time=0.312, loss_ctc=1.586, loss=0.793, backward_time=0.372, optim_step_time=0.034, optim0_lr0=3.026e-04, train_time=3.580
[ALab02:0/2] 2023-07-20 17:08:53,414 (trainer:721) INFO: 19epoch:train:909-1816batch: iter_time=2.336e-04, forward_time=0.231, loss_ctc=1.637, loss=0.818, backward_time=0.297, optim_step_time=0.034, optim0_lr0=3.022e-04, train_time=2.763
[ALab02:0/2] 2023-07-20 17:16:41,257 (trainer:721) INFO: 19epoch:train:1817-2724batch: iter_time=2.288e-04, forward_time=0.156, loss_ctc=1.644, loss=0.822, backward_time=0.229, optim_step_time=0.034, optim0_lr0=3.018e-04, train_time=2.061
[ALab02:0/2] 2023-07-20 17:25:23,411 (trainer:721) INFO: 19epoch:train:2725-3632batch: iter_time=2.325e-04, forward_time=0.183, loss_ctc=1.618, loss=0.809, backward_time=0.253, optim_step_time=0.035, optim0_lr0=3.014e-04, train_time=2.300
[ALab02:0/2] 2023-07-20 17:36:57,072 (trainer:721) INFO: 19epoch:train:3633-4540batch: iter_time=2.580e-04, forward_time=0.232, loss_ctc=1.619, loss=0.809, backward_time=0.313, optim_step_time=0.035, optim0_lr0=3.009e-04, train_time=3.056
[ALab02:0/2] 2023-07-20 17:48:53,651 (trainer:721) INFO: 19epoch:train:4541-5448batch: iter_time=2.538e-04, forward_time=0.241, loss_ctc=1.665, loss=0.832, backward_time=0.319, optim_step_time=0.035, optim0_lr0=3.005e-04, train_time=3.156
[ALab02:0/2] 2023-07-20 18:00:54,696 (trainer:721) INFO: 19epoch:train:5449-6356batch: iter_time=2.527e-04, forward_time=0.241, loss_ctc=1.642, loss=0.821, backward_time=0.320, optim_step_time=0.036, optim0_lr0=3.001e-04, train_time=3.176
[ALab02:0/2] 2023-07-20 18:12:50,883 (trainer:721) INFO: 19epoch:train:6357-7264batch: iter_time=2.453e-04, forward_time=0.239, loss_ctc=1.617, loss=0.808, backward_time=0.320, optim_step_time=0.035, optim0_lr0=2.997e-04, train_time=3.155
[ALab02:0/2] 2023-07-20 18:24:51,135 (trainer:721) INFO: 19epoch:train:7265-8172batch: iter_time=2.516e-04, forward_time=0.240, loss_ctc=1.605, loss=0.803, backward_time=0.322, optim_step_time=0.035, optim0_lr0=2.993e-04, train_time=3.173
[ALab02:0/2] 2023-07-20 18:36:46,239 (trainer:721) INFO: 19epoch:train:8173-9080batch: iter_time=2.660e-04, forward_time=0.240, loss_ctc=1.604, loss=0.802, backward_time=0.319, optim_step_time=0.034, optim0_lr0=2.989e-04, train_time=3.150
[ALab02:0/2] 2023-07-20 18:48:48,343 (trainer:721) INFO: 19epoch:train:9081-9988batch: iter_time=2.618e-04, forward_time=0.242, loss_ctc=1.629, loss=0.814, backward_time=0.322, optim_step_time=0.034, optim0_lr0=2.985e-04, train_time=3.181
[ALab02:0/2] 2023-07-20 19:00:50,384 (trainer:721) INFO: 19epoch:train:9989-10896batch: iter_time=2.557e-04, forward_time=0.241, loss_ctc=1.629, loss=0.815, backward_time=0.322, optim_step_time=0.034, optim0_lr0=2.981e-04, train_time=3.181
[ALab02:0/2] 2023-07-20 19:12:47,206 (trainer:721) INFO: 19epoch:train:10897-11804batch: iter_time=2.562e-04, forward_time=0.241, loss_ctc=1.630, loss=0.815, backward_time=0.323, optim_step_time=0.034, optim0_lr0=2.977e-04, train_time=3.158
[ALab02:0/2] 2023-07-20 19:24:46,299 (trainer:721) INFO: 19epoch:train:11805-12712batch: iter_time=2.684e-04, forward_time=0.244, loss_ctc=1.655, loss=0.828, backward_time=0.322, optim_step_time=0.034, optim0_lr0=2.973e-04, train_time=3.168
[ALab02:0/2] 2023-07-20 19:36:49,420 (trainer:721) INFO: 19epoch:train:12713-13620batch: iter_time=2.618e-04, forward_time=0.242, loss_ctc=1.591, loss=0.795, backward_time=0.325, optim_step_time=0.034, optim0_lr0=2.969e-04, train_time=3.185
[ALab02:0/2] 2023-07-20 19:48:44,219 (trainer:721) INFO: 19epoch:train:13621-14528batch: iter_time=2.680e-04, forward_time=0.242, loss_ctc=1.591, loss=0.795, backward_time=0.320, optim_step_time=0.034, optim0_lr0=2.965e-04, train_time=3.149
[ALab02:0/2] 2023-07-20 19:59:52,657 (trainer:721) INFO: 19epoch:train:14529-15436batch: iter_time=3.190e-04, forward_time=0.231, loss_ctc=1.641, loss=0.820, backward_time=0.307, optim_step_time=0.044, optim0_lr0=2.961e-04, train_time=2.944
[ALab02:0/2] 2023-07-20 20:07:35,717 (trainer:721) INFO: 19epoch:train:15437-16344batch: iter_time=2.481e-04, forward_time=0.156, loss_ctc=1.632, loss=0.816, backward_time=0.226, optim_step_time=0.037, optim0_lr0=2.957e-04, train_time=2.040
[ALab02:0/2] 2023-07-20 20:15:19,386 (trainer:721) INFO: 19epoch:train:16345-17252batch: iter_time=2.563e-04, forward_time=0.155, loss_ctc=1.614, loss=0.807, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.953e-04, train_time=2.042
[ALab02:0/2] 2023-07-20 20:23:05,309 (trainer:721) INFO: 19epoch:train:17253-18160batch: iter_time=2.538e-04, forward_time=0.155, loss_ctc=1.619, loss=0.809, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.949e-04, train_time=2.052
[ALab02:0/2] 2023-07-20 20:24:03,359 (trainer:338) INFO: 19epoch results: [train] iter_time=2.905e-04, forward_time=0.223, loss_ctc=1.623, loss=0.812, backward_time=0.299, optim_step_time=0.035, optim0_lr0=2.987e-04, train_time=2.883, time=3 hours, 38 minutes and 21.37 seconds, total_count=345344, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.107, cer_ctc=0.063, cer=0.063, loss=1.553, time=7.65 seconds, total_count=285, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.81 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 20:24:07,241 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 20:24:07,243 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/9epoch.pth
[ALab02:0/2] 2023-07-20 20:24:07,243 (trainer:272) INFO: 20/50epoch started. Estimated time to finish: 3 days, 13 hours and 41 minutes
[ALab02:0/2] 2023-07-20 20:32:00,610 (trainer:721) INFO: 20epoch:train:1-908batch: iter_time=6.654e-04, forward_time=0.154, loss_ctc=1.582, loss=0.791, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.945e-04, train_time=2.085
[ALab02:0/2] 2023-07-20 20:39:41,551 (trainer:721) INFO: 20epoch:train:909-1816batch: iter_time=2.303e-04, forward_time=0.153, loss_ctc=1.597, loss=0.799, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.942e-04, train_time=2.030
[ALab02:0/2] 2023-07-20 20:47:22,041 (trainer:721) INFO: 20epoch:train:1817-2724batch: iter_time=2.355e-04, forward_time=0.153, loss_ctc=1.543, loss=0.772, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.938e-04, train_time=2.028
[ALab02:0/2] 2023-07-20 20:55:03,712 (trainer:721) INFO: 20epoch:train:2725-3632batch: iter_time=2.255e-04, forward_time=0.153, loss_ctc=1.540, loss=0.770, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.934e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 21:02:50,648 (trainer:721) INFO: 20epoch:train:3633-4540batch: iter_time=2.293e-04, forward_time=0.153, loss_ctc=1.540, loss=0.770, backward_time=0.228, optim_step_time=0.033, optim0_lr0=2.930e-04, train_time=2.057
[ALab02:0/2] 2023-07-20 21:11:17,794 (trainer:721) INFO: 20epoch:train:4541-5448batch: iter_time=6.194e-04, forward_time=0.177, loss_ctc=1.518, loss=0.759, backward_time=0.229, optim_step_time=0.080, optim0_lr0=2.926e-04, train_time=2.234
[ALab02:0/2] 2023-07-20 21:20:00,438 (trainer:721) INFO: 20epoch:train:5449-6356batch: iter_time=9.427e-04, forward_time=0.186, loss_ctc=1.537, loss=0.769, backward_time=0.228, optim_step_time=0.098, optim0_lr0=2.922e-04, train_time=2.302
[ALab02:0/2] 2023-07-20 21:28:42,762 (trainer:721) INFO: 20epoch:train:6357-7264batch: iter_time=8.291e-04, forward_time=0.187, loss_ctc=1.568, loss=0.784, backward_time=0.230, optim_step_time=0.095, optim0_lr0=2.919e-04, train_time=2.300
[ALab02:0/2] 2023-07-20 21:37:21,560 (trainer:721) INFO: 20epoch:train:7265-8172batch: iter_time=9.491e-04, forward_time=0.187, loss_ctc=1.558, loss=0.779, backward_time=0.228, optim_step_time=0.099, optim0_lr0=2.915e-04, train_time=2.285
[ALab02:0/2] 2023-07-20 21:45:58,643 (trainer:721) INFO: 20epoch:train:8173-9080batch: iter_time=8.164e-04, forward_time=0.185, loss_ctc=1.546, loss=0.773, backward_time=0.227, optim_step_time=0.097, optim0_lr0=2.911e-04, train_time=2.277
[ALab02:0/2] 2023-07-20 21:54:34,922 (trainer:721) INFO: 20epoch:train:9081-9988batch: iter_time=8.494e-04, forward_time=0.186, loss_ctc=1.558, loss=0.779, backward_time=0.227, optim_step_time=0.099, optim0_lr0=2.907e-04, train_time=2.274
[ALab02:0/2] 2023-07-20 22:03:13,710 (trainer:721) INFO: 20epoch:train:9989-10896batch: iter_time=0.001, forward_time=0.185, loss_ctc=1.605, loss=0.802, backward_time=0.227, optim_step_time=0.098, optim0_lr0=2.904e-04, train_time=2.285
[ALab02:0/2] 2023-07-20 22:11:38,976 (trainer:721) INFO: 20epoch:train:10897-11804batch: iter_time=6.364e-04, forward_time=0.179, loss_ctc=1.525, loss=0.763, backward_time=0.227, optim_step_time=0.087, optim0_lr0=2.900e-04, train_time=2.225
[ALab02:0/2] 2023-07-20 22:19:20,653 (trainer:721) INFO: 20epoch:train:11805-12712batch: iter_time=2.807e-04, forward_time=0.155, loss_ctc=1.573, loss=0.786, backward_time=0.225, optim_step_time=0.037, optim0_lr0=2.896e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 22:27:00,900 (trainer:721) INFO: 20epoch:train:12713-13620batch: iter_time=2.348e-04, forward_time=0.153, loss_ctc=1.582, loss=0.791, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.893e-04, train_time=2.027
[ALab02:0/2] 2023-07-20 22:34:43,306 (trainer:721) INFO: 20epoch:train:13621-14528batch: iter_time=2.361e-04, forward_time=0.154, loss_ctc=1.552, loss=0.776, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.889e-04, train_time=2.037
[ALab02:0/2] 2023-07-20 22:42:23,354 (trainer:721) INFO: 20epoch:train:14529-15436batch: iter_time=2.342e-04, forward_time=0.153, loss_ctc=1.556, loss=0.778, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.885e-04, train_time=2.026
[ALab02:0/2] 2023-07-20 22:50:04,061 (trainer:721) INFO: 20epoch:train:15437-16344batch: iter_time=2.369e-04, forward_time=0.153, loss_ctc=1.528, loss=0.764, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.882e-04, train_time=2.029
[ALab02:0/2] 2023-07-20 22:57:43,811 (trainer:721) INFO: 20epoch:train:16345-17252batch: iter_time=2.295e-04, forward_time=0.152, loss_ctc=1.576, loss=0.788, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.878e-04, train_time=2.025
[ALab02:0/2] 2023-07-20 23:05:26,076 (trainer:721) INFO: 20epoch:train:17253-18160batch: iter_time=2.416e-04, forward_time=0.154, loss_ctc=1.557, loss=0.778, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.875e-04, train_time=2.036
[ALab02:0/2] 2023-07-20 23:06:20,788 (trainer:338) INFO: 20epoch results: [train] iter_time=4.976e-04, forward_time=0.166, loss_ctc=1.557, loss=0.778, backward_time=0.227, optim_step_time=0.058, optim0_lr0=2.910e-04, train_time=2.131, time=2 hours, 41 minutes and 28.12 seconds, total_count=363520, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.301, cer_ctc=0.061, cer=0.061, loss=1.651, time=6.39 seconds, total_count=300, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.04 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-20 23:06:24,982 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-20 23:06:24,985 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/10epoch.pth
[ALab02:0/2] 2023-07-20 23:06:24,985 (trainer:272) INFO: 21/50epoch started. Estimated time to finish: 3 days, 10 hours and 50 minutes
[ALab02:0/2] 2023-07-20 23:14:16,842 (trainer:721) INFO: 21epoch:train:1-908batch: iter_time=6.027e-04, forward_time=0.154, loss_ctc=1.461, loss=0.730, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.871e-04, train_time=2.078
[ALab02:0/2] 2023-07-20 23:21:57,961 (trainer:721) INFO: 21epoch:train:909-1816batch: iter_time=2.361e-04, forward_time=0.153, loss_ctc=1.460, loss=0.730, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.867e-04, train_time=2.031
[ALab02:0/2] 2023-07-20 23:29:39,688 (trainer:721) INFO: 21epoch:train:1817-2724batch: iter_time=2.380e-04, forward_time=0.153, loss_ctc=1.471, loss=0.736, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.864e-04, train_time=2.034
[ALab02:0/2] 2023-07-20 23:37:19,858 (trainer:721) INFO: 21epoch:train:2725-3632batch: iter_time=2.393e-04, forward_time=0.153, loss_ctc=1.465, loss=0.732, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.860e-04, train_time=2.027
[ALab02:0/2] 2023-07-20 23:45:00,292 (trainer:721) INFO: 21epoch:train:3633-4540batch: iter_time=2.437e-04, forward_time=0.153, loss_ctc=1.503, loss=0.752, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.857e-04, train_time=2.028
[ALab02:0/2] 2023-07-20 23:52:41,378 (trainer:721) INFO: 21epoch:train:4541-5448batch: iter_time=2.411e-04, forward_time=0.153, loss_ctc=1.550, loss=0.775, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.853e-04, train_time=2.031
[ALab02:0/2] 2023-07-21 00:00:22,833 (trainer:721) INFO: 21epoch:train:5449-6356batch: iter_time=2.303e-04, forward_time=0.153, loss_ctc=1.512, loss=0.756, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.850e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 00:08:03,754 (trainer:721) INFO: 21epoch:train:6357-7264batch: iter_time=2.283e-04, forward_time=0.153, loss_ctc=1.507, loss=0.753, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.846e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 00:15:46,649 (trainer:721) INFO: 21epoch:train:7265-8172batch: iter_time=2.436e-04, forward_time=0.154, loss_ctc=1.505, loss=0.753, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.843e-04, train_time=2.039
[ALab02:0/2] 2023-07-21 00:23:27,066 (trainer:721) INFO: 21epoch:train:8173-9080batch: iter_time=2.415e-04, forward_time=0.153, loss_ctc=1.482, loss=0.741, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.839e-04, train_time=2.028
[ALab02:0/2] 2023-07-21 00:31:07,756 (trainer:721) INFO: 21epoch:train:9081-9988batch: iter_time=2.332e-04, forward_time=0.153, loss_ctc=1.581, loss=0.791, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.836e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 00:38:50,622 (trainer:721) INFO: 21epoch:train:9989-10896batch: iter_time=2.363e-04, forward_time=0.154, loss_ctc=1.433, loss=0.716, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.832e-04, train_time=2.039
[ALab02:0/2] 2023-07-21 00:46:30,854 (trainer:721) INFO: 21epoch:train:10897-11804batch: iter_time=2.395e-04, forward_time=0.153, loss_ctc=1.515, loss=0.757, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.829e-04, train_time=2.027
[ALab02:0/2] 2023-07-21 00:54:13,797 (trainer:721) INFO: 21epoch:train:11805-12712batch: iter_time=2.437e-04, forward_time=0.154, loss_ctc=1.524, loss=0.762, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.825e-04, train_time=2.039
[ALab02:0/2] 2023-07-21 01:01:56,863 (trainer:721) INFO: 21epoch:train:12713-13620batch: iter_time=2.300e-04, forward_time=0.154, loss_ctc=1.475, loss=0.737, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.822e-04, train_time=2.040
[ALab02:0/2] 2023-07-21 01:09:40,203 (trainer:721) INFO: 21epoch:train:13621-14528batch: iter_time=2.290e-04, forward_time=0.154, loss_ctc=1.487, loss=0.743, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.819e-04, train_time=2.041
[ALab02:0/2] 2023-07-21 01:17:20,509 (trainer:721) INFO: 21epoch:train:14529-15436batch: iter_time=2.265e-04, forward_time=0.153, loss_ctc=1.485, loss=0.743, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.815e-04, train_time=2.028
[ALab02:0/2] 2023-07-21 01:25:00,785 (trainer:721) INFO: 21epoch:train:15437-16344batch: iter_time=2.407e-04, forward_time=0.153, loss_ctc=1.479, loss=0.739, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.812e-04, train_time=2.027
[ALab02:0/2] 2023-07-21 01:32:42,015 (trainer:721) INFO: 21epoch:train:16345-17252batch: iter_time=2.292e-04, forward_time=0.153, loss_ctc=1.532, loss=0.766, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.809e-04, train_time=2.032
[ALab02:0/2] 2023-07-21 01:40:23,771 (trainer:721) INFO: 21epoch:train:17253-18160batch: iter_time=2.275e-04, forward_time=0.153, loss_ctc=1.538, loss=0.769, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.805e-04, train_time=2.034
[ALab02:0/2] 2023-07-21 01:41:18,466 (trainer:338) INFO: 21epoch results: [train] iter_time=2.540e-04, forward_time=0.153, loss_ctc=1.498, loss=0.749, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.838e-04, train_time=2.035, time=2 hours, 34 minutes and 7.97 seconds, total_count=381696, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.010, cer_ctc=0.061, cer=0.061, loss=1.505, time=6.26 seconds, total_count=315, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.25 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 01:41:22,837 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-21 01:41:22,839 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/11epoch.pth
[ALab02:0/2] 2023-07-21 01:41:22,839 (trainer:272) INFO: 22/50epoch started. Estimated time to finish: 3 days, 7 hours and 49 minutes
[ALab02:0/2] 2023-07-21 01:49:14,410 (trainer:721) INFO: 22epoch:train:1-908batch: iter_time=6.416e-04, forward_time=0.154, loss_ctc=1.494, loss=0.747, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.802e-04, train_time=2.077
[ALab02:0/2] 2023-07-21 01:56:53,954 (trainer:721) INFO: 22epoch:train:909-1816batch: iter_time=2.205e-04, forward_time=0.152, loss_ctc=1.454, loss=0.727, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.798e-04, train_time=2.024
[ALab02:0/2] 2023-07-21 02:04:36,004 (trainer:721) INFO: 22epoch:train:1817-2724batch: iter_time=2.282e-04, forward_time=0.153, loss_ctc=1.418, loss=0.709, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.795e-04, train_time=2.035
[ALab02:0/2] 2023-07-21 02:12:19,378 (trainer:721) INFO: 22epoch:train:2725-3632batch: iter_time=2.400e-04, forward_time=0.154, loss_ctc=1.462, loss=0.731, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.792e-04, train_time=2.041
[ALab02:0/2] 2023-07-21 02:20:00,841 (trainer:721) INFO: 22epoch:train:3633-4540batch: iter_time=2.279e-04, forward_time=0.153, loss_ctc=1.445, loss=0.722, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.789e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 02:27:41,819 (trainer:721) INFO: 22epoch:train:4541-5448batch: iter_time=2.336e-04, forward_time=0.153, loss_ctc=1.412, loss=0.706, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.785e-04, train_time=2.031
[ALab02:0/2] 2023-07-21 02:35:22,743 (trainer:721) INFO: 22epoch:train:5449-6356batch: iter_time=2.244e-04, forward_time=0.153, loss_ctc=1.458, loss=0.729, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.782e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 02:43:06,010 (trainer:721) INFO: 22epoch:train:6357-7264batch: iter_time=2.253e-04, forward_time=0.154, loss_ctc=1.468, loss=0.734, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.779e-04, train_time=2.041
[ALab02:0/2] 2023-07-21 02:50:48,564 (trainer:721) INFO: 22epoch:train:7265-8172batch: iter_time=2.348e-04, forward_time=0.153, loss_ctc=1.446, loss=0.723, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.776e-04, train_time=2.037
[ALab02:0/2] 2023-07-21 02:58:30,215 (trainer:721) INFO: 22epoch:train:8173-9080batch: iter_time=2.233e-04, forward_time=0.153, loss_ctc=1.435, loss=0.718, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.772e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 03:06:08,629 (trainer:721) INFO: 22epoch:train:9081-9988batch: iter_time=2.328e-04, forward_time=0.152, loss_ctc=1.453, loss=0.726, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.769e-04, train_time=2.019
[ALab02:0/2] 2023-07-21 03:13:48,103 (trainer:721) INFO: 22epoch:train:9989-10896batch: iter_time=2.252e-04, forward_time=0.153, loss_ctc=1.408, loss=0.704, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.766e-04, train_time=2.024
[ALab02:0/2] 2023-07-21 03:21:27,950 (trainer:721) INFO: 22epoch:train:10897-11804batch: iter_time=2.211e-04, forward_time=0.153, loss_ctc=1.417, loss=0.709, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.763e-04, train_time=2.026
[ALab02:0/2] 2023-07-21 03:29:07,691 (trainer:721) INFO: 22epoch:train:11805-12712batch: iter_time=2.278e-04, forward_time=0.153, loss_ctc=1.473, loss=0.737, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.760e-04, train_time=2.025
[ALab02:0/2] 2023-07-21 03:36:49,815 (trainer:721) INFO: 22epoch:train:12713-13620batch: iter_time=2.211e-04, forward_time=0.154, loss_ctc=1.425, loss=0.713, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.756e-04, train_time=2.036
[ALab02:0/2] 2023-07-21 03:44:31,388 (trainer:721) INFO: 22epoch:train:13621-14528batch: iter_time=2.267e-04, forward_time=0.153, loss_ctc=1.463, loss=0.731, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.753e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 03:52:11,334 (trainer:721) INFO: 22epoch:train:14529-15436batch: iter_time=2.197e-04, forward_time=0.153, loss_ctc=1.431, loss=0.716, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.750e-04, train_time=2.026
[ALab02:0/2] 2023-07-21 03:59:52,158 (trainer:721) INFO: 22epoch:train:15437-16344batch: iter_time=2.290e-04, forward_time=0.153, loss_ctc=1.473, loss=0.737, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.747e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 04:07:32,839 (trainer:721) INFO: 22epoch:train:16345-17252batch: iter_time=2.302e-04, forward_time=0.153, loss_ctc=1.475, loss=0.738, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.744e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 04:15:13,464 (trainer:721) INFO: 22epoch:train:17253-18160batch: iter_time=2.166e-04, forward_time=0.153, loss_ctc=1.450, loss=0.725, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.741e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 04:16:07,625 (trainer:338) INFO: 22epoch results: [train] iter_time=2.475e-04, forward_time=0.153, loss_ctc=1.448, loss=0.724, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.771e-04, train_time=2.033, time=2 hours, 33 minutes and 59.65 seconds, total_count=399872, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.142, cer_ctc=0.062, cer=0.062, loss=1.571, time=6.26 seconds, total_count=330, gpu_max_cached_mem_GB=42.223, [att_plot] time=38.87 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 04:16:11,681 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-21 04:16:11,682 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/13epoch.pth
[ALab02:0/2] 2023-07-21 04:16:11,683 (trainer:272) INFO: 23/50epoch started. Estimated time to finish: 3 days, 4 hours and 51 minutes
[ALab02:0/2] 2023-07-21 04:24:01,610 (trainer:721) INFO: 23epoch:train:1-908batch: iter_time=6.119e-04, forward_time=0.153, loss_ctc=1.414, loss=0.707, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.737e-04, train_time=2.070
[ALab02:0/2] 2023-07-21 04:31:43,992 (trainer:721) INFO: 23epoch:train:909-1816batch: iter_time=2.334e-04, forward_time=0.154, loss_ctc=1.399, loss=0.700, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.734e-04, train_time=2.037
[ALab02:0/2] 2023-07-21 04:39:22,655 (trainer:721) INFO: 23epoch:train:1817-2724batch: iter_time=2.159e-04, forward_time=0.152, loss_ctc=1.403, loss=0.701, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.731e-04, train_time=2.020
[ALab02:0/2] 2023-07-21 04:47:05,004 (trainer:721) INFO: 23epoch:train:2725-3632batch: iter_time=2.338e-04, forward_time=0.154, loss_ctc=1.372, loss=0.686, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.728e-04, train_time=2.037
[ALab02:0/2] 2023-07-21 04:54:44,897 (trainer:721) INFO: 23epoch:train:3633-4540batch: iter_time=2.324e-04, forward_time=0.153, loss_ctc=1.397, loss=0.698, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.725e-04, train_time=2.026
[ALab02:0/2] 2023-07-21 05:02:27,590 (trainer:721) INFO: 23epoch:train:4541-5448batch: iter_time=2.286e-04, forward_time=0.154, loss_ctc=1.376, loss=0.688, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.722e-04, train_time=2.038
[ALab02:0/2] 2023-07-21 05:10:10,939 (trainer:721) INFO: 23epoch:train:5449-6356batch: iter_time=2.346e-04, forward_time=0.154, loss_ctc=1.366, loss=0.683, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.719e-04, train_time=2.041
[ALab02:0/2] 2023-07-21 05:17:51,485 (trainer:721) INFO: 23epoch:train:6357-7264batch: iter_time=2.203e-04, forward_time=0.153, loss_ctc=1.442, loss=0.721, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.716e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 05:25:32,167 (trainer:721) INFO: 23epoch:train:7265-8172batch: iter_time=2.236e-04, forward_time=0.153, loss_ctc=1.372, loss=0.686, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.713e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 05:33:13,148 (trainer:721) INFO: 23epoch:train:8173-9080batch: iter_time=2.273e-04, forward_time=0.153, loss_ctc=1.405, loss=0.702, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.710e-04, train_time=2.031
[ALab02:0/2] 2023-07-21 05:40:53,991 (trainer:721) INFO: 23epoch:train:9081-9988batch: iter_time=2.261e-04, forward_time=0.153, loss_ctc=1.418, loss=0.709, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.707e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 05:48:34,775 (trainer:721) INFO: 23epoch:train:9989-10896batch: iter_time=2.258e-04, forward_time=0.153, loss_ctc=1.412, loss=0.706, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.704e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 05:56:15,693 (trainer:721) INFO: 23epoch:train:10897-11804batch: iter_time=2.151e-04, forward_time=0.153, loss_ctc=1.361, loss=0.680, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.701e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 06:03:56,960 (trainer:721) INFO: 23epoch:train:11805-12712batch: iter_time=2.210e-04, forward_time=0.153, loss_ctc=1.373, loss=0.686, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.698e-04, train_time=2.032
[ALab02:0/2] 2023-07-21 06:11:37,622 (trainer:721) INFO: 23epoch:train:12713-13620batch: iter_time=2.234e-04, forward_time=0.153, loss_ctc=1.366, loss=0.683, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.695e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 06:19:19,045 (trainer:721) INFO: 23epoch:train:13621-14528batch: iter_time=2.250e-04, forward_time=0.154, loss_ctc=1.400, loss=0.700, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.692e-04, train_time=2.032
[ALab02:0/2] 2023-07-21 06:26:59,000 (trainer:721) INFO: 23epoch:train:14529-15436batch: iter_time=2.130e-04, forward_time=0.153, loss_ctc=1.374, loss=0.687, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.689e-04, train_time=2.026
[ALab02:0/2] 2023-07-21 06:34:39,158 (trainer:721) INFO: 23epoch:train:15437-16344batch: iter_time=2.189e-04, forward_time=0.153, loss_ctc=1.402, loss=0.701, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.686e-04, train_time=2.027
[ALab02:0/2] 2023-07-21 06:42:18,323 (trainer:721) INFO: 23epoch:train:16345-17252batch: iter_time=2.324e-04, forward_time=0.153, loss_ctc=1.390, loss=0.695, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.683e-04, train_time=2.023
[ALab02:0/2] 2023-07-21 06:49:58,012 (trainer:721) INFO: 23epoch:train:17253-18160batch: iter_time=2.255e-04, forward_time=0.153, loss_ctc=1.369, loss=0.684, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.680e-04, train_time=2.025
[ALab02:0/2] 2023-07-21 06:50:51,996 (trainer:338) INFO: 23epoch results: [train] iter_time=2.444e-04, forward_time=0.153, loss_ctc=1.390, loss=0.695, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.709e-04, train_time=2.032, time=2 hours, 33 minutes and 55.3 seconds, total_count=418048, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.146, cer_ctc=0.063, cer=0.063, loss=1.573, time=6.27 seconds, total_count=345, gpu_max_cached_mem_GB=42.223, [att_plot] time=38.74 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 06:50:57,428 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-21 06:50:57,430 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/12epoch.pth
[ALab02:0/2] 2023-07-21 06:50:57,430 (trainer:272) INFO: 24/50epoch started. Estimated time to finish: 3 days, 1 hour and 54 minutes
[ALab02:0/2] 2023-07-21 06:58:48,322 (trainer:721) INFO: 24epoch:train:1-908batch: iter_time=9.773e-04, forward_time=0.153, loss_ctc=1.369, loss=0.684, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.677e-04, train_time=2.074
[ALab02:0/2] 2023-07-21 07:06:31,974 (trainer:721) INFO: 24epoch:train:909-1816batch: iter_time=2.352e-04, forward_time=0.154, loss_ctc=1.350, loss=0.675, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.674e-04, train_time=2.042
[ALab02:0/2] 2023-07-21 07:14:12,756 (trainer:721) INFO: 24epoch:train:1817-2724batch: iter_time=2.274e-04, forward_time=0.153, loss_ctc=1.326, loss=0.663, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.672e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 07:21:54,682 (trainer:721) INFO: 24epoch:train:2725-3632batch: iter_time=2.279e-04, forward_time=0.153, loss_ctc=1.386, loss=0.693, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.669e-04, train_time=2.035
[ALab02:0/2] 2023-07-21 07:29:35,426 (trainer:721) INFO: 24epoch:train:3633-4540batch: iter_time=2.276e-04, forward_time=0.153, loss_ctc=1.332, loss=0.666, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.666e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 07:37:15,503 (trainer:721) INFO: 24epoch:train:4541-5448batch: iter_time=2.342e-04, forward_time=0.153, loss_ctc=1.388, loss=0.694, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.663e-04, train_time=2.027
[ALab02:0/2] 2023-07-21 07:44:55,607 (trainer:721) INFO: 24epoch:train:5449-6356batch: iter_time=2.277e-04, forward_time=0.153, loss_ctc=1.319, loss=0.659, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.660e-04, train_time=2.027
[ALab02:0/2] 2023-07-21 07:52:36,575 (trainer:721) INFO: 24epoch:train:6357-7264batch: iter_time=2.366e-04, forward_time=0.153, loss_ctc=1.314, loss=0.657, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.657e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 08:00:18,207 (trainer:721) INFO: 24epoch:train:7265-8172batch: iter_time=2.287e-04, forward_time=0.153, loss_ctc=1.335, loss=0.667, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.654e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 08:08:00,058 (trainer:721) INFO: 24epoch:train:8173-9080batch: iter_time=2.298e-04, forward_time=0.154, loss_ctc=1.337, loss=0.668, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.652e-04, train_time=2.034
[ALab02:0/2] 2023-07-21 08:15:40,377 (trainer:721) INFO: 24epoch:train:9081-9988batch: iter_time=2.274e-04, forward_time=0.153, loss_ctc=1.365, loss=0.682, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.649e-04, train_time=2.028
[ALab02:0/2] 2023-07-21 08:23:19,013 (trainer:721) INFO: 24epoch:train:9989-10896batch: iter_time=2.314e-04, forward_time=0.152, loss_ctc=1.367, loss=0.683, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.646e-04, train_time=2.020
[ALab02:0/2] 2023-07-21 08:31:00,234 (trainer:721) INFO: 24epoch:train:10897-11804batch: iter_time=2.263e-04, forward_time=0.153, loss_ctc=1.331, loss=0.665, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.643e-04, train_time=2.032
[ALab02:0/2] 2023-07-21 08:38:41,102 (trainer:721) INFO: 24epoch:train:11805-12712batch: iter_time=2.224e-04, forward_time=0.153, loss_ctc=1.361, loss=0.680, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.640e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 08:46:20,694 (trainer:721) INFO: 24epoch:train:12713-13620batch: iter_time=2.240e-04, forward_time=0.153, loss_ctc=1.341, loss=0.670, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.638e-04, train_time=2.024
[ALab02:0/2] 2023-07-21 08:54:00,707 (trainer:721) INFO: 24epoch:train:13621-14528batch: iter_time=2.370e-04, forward_time=0.153, loss_ctc=1.360, loss=0.680, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.635e-04, train_time=2.026
[ALab02:0/2] 2023-07-21 09:01:41,405 (trainer:721) INFO: 24epoch:train:14529-15436batch: iter_time=2.277e-04, forward_time=0.153, loss_ctc=1.339, loss=0.669, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.632e-04, train_time=2.029
[ALab02:0/2] 2023-07-21 09:09:23,796 (trainer:721) INFO: 24epoch:train:15437-16344batch: iter_time=2.446e-04, forward_time=0.154, loss_ctc=1.423, loss=0.712, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.629e-04, train_time=2.037
[ALab02:0/2] 2023-07-21 09:17:05,266 (trainer:721) INFO: 24epoch:train:16345-17252batch: iter_time=2.267e-04, forward_time=0.153, loss_ctc=1.383, loss=0.691, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.627e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 09:24:45,011 (trainer:721) INFO: 24epoch:train:17253-18160batch: iter_time=2.262e-04, forward_time=0.153, loss_ctc=1.368, loss=0.684, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.624e-04, train_time=2.025
[ALab02:0/2] 2023-07-21 09:25:39,712 (trainer:338) INFO: 24epoch results: [train] iter_time=2.673e-04, forward_time=0.153, loss_ctc=1.354, loss=0.677, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.650e-04, train_time=2.032, time=2 hours, 33 minutes and 56.76 seconds, total_count=436224, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.147, cer_ctc=0.060, cer=0.060, loss=1.573, time=6.14 seconds, total_count=360, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.39 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 09:25:44,182 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-21 09:25:44,183 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/14epoch.pth
[ALab02:0/2] 2023-07-21 09:25:44,183 (trainer:272) INFO: 25/50epoch started. Estimated time to finish: 2 days, 23 hours and 27.37 seconds
[ALab02:0/2] 2023-07-21 09:33:34,018 (trainer:721) INFO: 25epoch:train:1-908batch: iter_time=6.086e-04, forward_time=0.152, loss_ctc=1.314, loss=0.657, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.621e-04, train_time=2.069
[ALab02:0/2] 2023-07-21 09:41:16,536 (trainer:721) INFO: 25epoch:train:909-1816batch: iter_time=2.338e-04, forward_time=0.153, loss_ctc=1.308, loss=0.654, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.618e-04, train_time=2.037
[ALab02:0/2] 2023-07-21 09:48:58,249 (trainer:721) INFO: 25epoch:train:1817-2724batch: iter_time=2.320e-04, forward_time=0.153, loss_ctc=1.318, loss=0.659, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.616e-04, train_time=2.034
[ALab02:0/2] 2023-07-21 09:56:45,149 (trainer:721) INFO: 25epoch:train:2725-3632batch: iter_time=2.906e-04, forward_time=0.156, loss_ctc=1.278, loss=0.639, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.613e-04, train_time=2.056
[ALab02:0/2] 2023-07-21 10:05:02,491 (trainer:721) INFO: 25epoch:train:3633-4540batch: iter_time=8.793e-04, forward_time=0.174, loss_ctc=1.345, loss=0.673, backward_time=0.226, optim_step_time=0.077, optim0_lr0=2.610e-04, train_time=2.191
[ALab02:0/2] 2023-07-21 10:12:51,200 (trainer:721) INFO: 25epoch:train:4541-5448batch: iter_time=2.748e-04, forward_time=0.157, loss_ctc=1.337, loss=0.668, backward_time=0.226, optim_step_time=0.040, optim0_lr0=2.608e-04, train_time=2.065
[ALab02:0/2] 2023-07-21 10:21:04,104 (trainer:721) INFO: 25epoch:train:5449-6356batch: iter_time=7.843e-04, forward_time=0.173, loss_ctc=1.308, loss=0.654, backward_time=0.226, optim_step_time=0.074, optim0_lr0=2.605e-04, train_time=2.171
[ALab02:0/2] 2023-07-21 10:29:10,536 (trainer:721) INFO: 25epoch:train:6357-7264batch: iter_time=5.467e-04, forward_time=0.170, loss_ctc=1.366, loss=0.683, backward_time=0.227, optim_step_time=0.063, optim0_lr0=2.602e-04, train_time=2.142
[ALab02:0/2] 2023-07-21 10:37:34,079 (trainer:721) INFO: 25epoch:train:7265-8172batch: iter_time=0.001, forward_time=0.180, loss_ctc=1.359, loss=0.680, backward_time=0.226, optim_step_time=0.088, optim0_lr0=2.600e-04, train_time=2.217
[ALab02:0/2] 2023-07-21 10:46:08,027 (trainer:721) INFO: 25epoch:train:8173-9080batch: iter_time=0.001, forward_time=0.187, loss_ctc=1.317, loss=0.659, backward_time=0.228, optim_step_time=0.096, optim0_lr0=2.597e-04, train_time=2.264
[ALab02:0/2] 2023-07-21 10:54:44,321 (trainer:721) INFO: 25epoch:train:9081-9988batch: iter_time=0.001, forward_time=0.185, loss_ctc=1.272, loss=0.636, backward_time=0.228, optim_step_time=0.096, optim0_lr0=2.594e-04, train_time=2.274
[ALab02:0/2] 2023-07-21 11:03:10,259 (trainer:721) INFO: 25epoch:train:9989-10896batch: iter_time=9.729e-04, forward_time=0.180, loss_ctc=1.312, loss=0.656, backward_time=0.226, optim_step_time=0.090, optim0_lr0=2.592e-04, train_time=2.229
[ALab02:0/2] 2023-07-21 11:11:04,826 (trainer:721) INFO: 25epoch:train:10897-11804batch: iter_time=4.575e-04, forward_time=0.161, loss_ctc=1.334, loss=0.667, backward_time=0.225, optim_step_time=0.050, optim0_lr0=2.589e-04, train_time=2.090
[ALab02:0/2] 2023-07-21 11:18:46,709 (trainer:721) INFO: 25epoch:train:11805-12712batch: iter_time=2.317e-04, forward_time=0.153, loss_ctc=1.313, loss=0.656, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.586e-04, train_time=2.035
[ALab02:0/2] 2023-07-21 11:26:34,068 (trainer:721) INFO: 25epoch:train:12713-13620batch: iter_time=2.883e-04, forward_time=0.158, loss_ctc=1.294, loss=0.647, backward_time=0.226, optim_step_time=0.041, optim0_lr0=2.584e-04, train_time=2.059
[ALab02:0/2] 2023-07-21 11:34:34,897 (trainer:721) INFO: 25epoch:train:13621-14528batch: iter_time=2.903e-04, forward_time=0.167, loss_ctc=1.317, loss=0.658, backward_time=0.227, optim_step_time=0.054, optim0_lr0=2.581e-04, train_time=2.118
[ALab02:0/2] 2023-07-21 11:42:34,896 (trainer:721) INFO: 25epoch:train:14529-15436batch: iter_time=3.301e-04, forward_time=0.166, loss_ctc=1.317, loss=0.659, backward_time=0.226, optim_step_time=0.055, optim0_lr0=2.579e-04, train_time=2.114
[ALab02:0/2] 2023-07-21 11:50:36,117 (trainer:721) INFO: 25epoch:train:15437-16344batch: iter_time=3.199e-04, forward_time=0.167, loss_ctc=1.269, loss=0.634, backward_time=0.227, optim_step_time=0.055, optim0_lr0=2.576e-04, train_time=2.119
[ALab02:0/2] 2023-07-21 11:58:21,430 (trainer:721) INFO: 25epoch:train:16345-17252batch: iter_time=2.688e-04, forward_time=0.157, loss_ctc=1.353, loss=0.677, backward_time=0.225, optim_step_time=0.042, optim0_lr0=2.573e-04, train_time=2.050
[ALab02:0/2] 2023-07-21 12:06:02,576 (trainer:721) INFO: 25epoch:train:17253-18160batch: iter_time=2.322e-04, forward_time=0.153, loss_ctc=1.329, loss=0.665, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.571e-04, train_time=2.031
[ALab02:0/2] 2023-07-21 12:06:57,138 (trainer:338) INFO: 25epoch results: [train] iter_time=5.389e-04, forward_time=0.165, loss_ctc=1.318, loss=0.659, backward_time=0.226, optim_step_time=0.056, optim0_lr0=2.596e-04, train_time=2.118, time=2 hours, 40 minutes and 27.69 seconds, total_count=454400, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.426, cer_ctc=0.061, cer=0.061, loss=1.713, time=6.14 seconds, total_count=375, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.12 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 12:07:01,192 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-21 12:07:01,193 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/15epoch.pth
[ALab02:0/2] 2023-07-21 12:07:01,193 (trainer:272) INFO: 26/50epoch started. Estimated time to finish: 2 days, 20 hours and 14 minutes
[ALab02:0/2] 2023-07-21 12:14:53,564 (trainer:721) INFO: 26epoch:train:1-908batch: iter_time=6.335e-04, forward_time=0.154, loss_ctc=1.274, loss=0.637, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.568e-04, train_time=2.081
[ALab02:0/2] 2023-07-21 12:22:33,864 (trainer:721) INFO: 26epoch:train:909-1816batch: iter_time=2.426e-04, forward_time=0.153, loss_ctc=1.302, loss=0.651, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.566e-04, train_time=2.028
[ALab02:0/2] 2023-07-21 12:30:14,137 (trainer:721) INFO: 26epoch:train:1817-2724batch: iter_time=2.317e-04, forward_time=0.153, loss_ctc=1.306, loss=0.653, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.563e-04, train_time=2.027
[ALab02:0/2] 2023-07-21 12:37:55,645 (trainer:721) INFO: 26epoch:train:2725-3632batch: iter_time=2.298e-04, forward_time=0.153, loss_ctc=1.299, loss=0.650, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.561e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 12:45:37,027 (trainer:721) INFO: 26epoch:train:3633-4540batch: iter_time=2.228e-04, forward_time=0.153, loss_ctc=1.312, loss=0.656, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.558e-04, train_time=2.032
[ALab02:0/2] 2023-07-21 12:53:16,990 (trainer:721) INFO: 26epoch:train:4541-5448batch: iter_time=2.354e-04, forward_time=0.153, loss_ctc=1.272, loss=0.636, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.555e-04, train_time=2.026
[ALab02:0/2] 2023-07-21 13:01:00,090 (trainer:721) INFO: 26epoch:train:5449-6356batch: iter_time=2.375e-04, forward_time=0.155, loss_ctc=1.229, loss=0.614, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.553e-04, train_time=2.040
[ALab02:0/2] 2023-07-21 13:08:40,440 (trainer:721) INFO: 26epoch:train:6357-7264batch: iter_time=2.411e-04, forward_time=0.153, loss_ctc=1.306, loss=0.653, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.550e-04, train_time=2.028
[ALab02:0/2] 2023-07-21 13:16:28,460 (trainer:721) INFO: 26epoch:train:7265-8172batch: iter_time=3.682e-04, forward_time=0.157, loss_ctc=1.334, loss=0.667, backward_time=0.226, optim_step_time=0.043, optim0_lr0=2.548e-04, train_time=2.062
[ALab02:0/2] 2023-07-21 13:24:11,045 (trainer:721) INFO: 26epoch:train:8173-9080batch: iter_time=2.346e-04, forward_time=0.154, loss_ctc=1.277, loss=0.638, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.545e-04, train_time=2.038
[ALab02:0/2] 2023-07-21 13:32:17,962 (trainer:721) INFO: 26epoch:train:9081-9988batch: iter_time=2.440e-04, forward_time=0.157, loss_ctc=1.270, loss=0.635, backward_time=0.234, optim_step_time=0.034, optim0_lr0=2.543e-04, train_time=2.145
[ALab02:0/2] 2023-07-21 13:40:11,595 (trainer:721) INFO: 26epoch:train:9989-10896batch: iter_time=2.268e-04, forward_time=0.157, loss_ctc=1.253, loss=0.627, backward_time=0.231, optim_step_time=0.033, optim0_lr0=2.540e-04, train_time=2.086
[ALab02:0/2] 2023-07-21 13:47:52,435 (trainer:721) INFO: 26epoch:train:10897-11804batch: iter_time=2.296e-04, forward_time=0.153, loss_ctc=1.239, loss=0.620, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.538e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 13:55:34,531 (trainer:721) INFO: 26epoch:train:11805-12712batch: iter_time=2.341e-04, forward_time=0.154, loss_ctc=1.254, loss=0.627, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.535e-04, train_time=2.035
[ALab02:0/2] 2023-07-21 14:03:17,898 (trainer:721) INFO: 26epoch:train:12713-13620batch: iter_time=2.257e-04, forward_time=0.154, loss_ctc=1.268, loss=0.634, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.533e-04, train_time=2.041
[ALab02:0/2] 2023-07-21 14:10:57,285 (trainer:721) INFO: 26epoch:train:13621-14528batch: iter_time=2.245e-04, forward_time=0.153, loss_ctc=1.270, loss=0.635, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.531e-04, train_time=2.024
[ALab02:0/2] 2023-07-21 14:18:39,489 (trainer:721) INFO: 26epoch:train:14529-15436batch: iter_time=2.352e-04, forward_time=0.154, loss_ctc=1.292, loss=0.646, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.528e-04, train_time=2.036
[ALab02:0/2] 2023-07-21 14:26:52,800 (trainer:721) INFO: 26epoch:train:15437-16344batch: iter_time=0.002, forward_time=0.160, loss_ctc=1.259, loss=0.629, backward_time=0.226, optim_step_time=0.040, optim0_lr0=2.526e-04, train_time=2.173
[ALab02:0/2] 2023-07-21 14:35:04,207 (trainer:721) INFO: 26epoch:train:16345-17252batch: iter_time=2.384e-04, forward_time=0.155, loss_ctc=1.248, loss=0.624, backward_time=0.242, optim_step_time=0.035, optim0_lr0=2.523e-04, train_time=2.165
[ALab02:0/2] 2023-07-21 14:42:47,603 (trainer:721) INFO: 26epoch:train:17253-18160batch: iter_time=2.472e-04, forward_time=0.155, loss_ctc=1.273, loss=0.636, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.521e-04, train_time=2.041
[ALab02:0/2] 2023-07-21 14:43:43,284 (trainer:338) INFO: 26epoch results: [train] iter_time=3.497e-04, forward_time=0.154, loss_ctc=1.277, loss=0.638, backward_time=0.228, optim_step_time=0.034, optim0_lr0=2.544e-04, train_time=2.058, time=2 hours, 35 minutes and 55.73 seconds, total_count=472576, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.193, cer_ctc=0.061, cer=0.061, loss=1.596, time=6.49 seconds, total_count=390, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.87 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 14:43:47,400 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-21 14:43:47,401 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/18epoch.pth
[ALab02:0/2] 2023-07-21 14:43:47,401 (trainer:272) INFO: 27/50epoch started. Estimated time to finish: 2 days, 17 hours and 23 minutes
[ALab02:0/2] 2023-07-21 14:51:37,298 (trainer:721) INFO: 27epoch:train:1-908batch: iter_time=9.552e-04, forward_time=0.153, loss_ctc=1.202, loss=0.601, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.518e-04, train_time=2.070
[ALab02:0/2] 2023-07-21 15:00:32,777 (trainer:721) INFO: 27epoch:train:909-1816batch: iter_time=2.432e-04, forward_time=0.157, loss_ctc=1.207, loss=0.603, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.516e-04, train_time=2.359
[ALab02:0/2] 2023-07-21 15:08:23,086 (trainer:721) INFO: 27epoch:train:1817-2724batch: iter_time=2.469e-04, forward_time=0.153, loss_ctc=1.239, loss=0.620, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.514e-04, train_time=2.072
[ALab02:0/2] 2023-07-21 15:16:04,530 (trainer:721) INFO: 27epoch:train:2725-3632batch: iter_time=2.357e-04, forward_time=0.153, loss_ctc=1.232, loss=0.616, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.511e-04, train_time=2.033
[ALab02:0/2] 2023-07-21 15:23:45,744 (trainer:721) INFO: 27epoch:train:3633-4540batch: iter_time=2.253e-04, forward_time=0.153, loss_ctc=1.234, loss=0.617, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.509e-04, train_time=2.032
[ALab02:0/2] 2023-07-21 15:31:26,681 (trainer:721) INFO: 27epoch:train:4541-5448batch: iter_time=2.303e-04, forward_time=0.153, loss_ctc=1.265, loss=0.633, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.506e-04, train_time=2.030
[ALab02:0/2] 2023-07-21 15:39:09,422 (trainer:721) INFO: 27epoch:train:5449-6356batch: iter_time=2.265e-04, forward_time=0.154, loss_ctc=1.260, loss=0.630, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.504e-04, train_time=2.038
[ALab02:0/2] 2023-07-21 15:46:52,340 (trainer:721) INFO: 27epoch:train:6357-7264batch: iter_time=2.204e-04, forward_time=0.153, loss_ctc=1.268, loss=0.634, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.502e-04, train_time=2.039
[ALab02:0/2] 2023-07-21 15:54:35,290 (trainer:721) INFO: 27epoch:train:7265-8172batch: iter_time=2.356e-04, forward_time=0.154, loss_ctc=1.268, loss=0.634, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.499e-04, train_time=2.039
[ALab02:0/2] 2023-07-21 16:02:17,896 (trainer:721) INFO: 27epoch:train:8173-9080batch: iter_time=2.250e-04, forward_time=0.153, loss_ctc=1.293, loss=0.646, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.497e-04, train_time=2.038
[ALab02:0/2] 2023-07-21 16:10:01,899 (trainer:721) INFO: 27epoch:train:9081-9988batch: iter_time=2.297e-04, forward_time=0.153, loss_ctc=1.257, loss=0.628, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.495e-04, train_time=2.044
[ALab02:0/2] 2023-07-21 16:17:56,903 (trainer:721) INFO: 27epoch:train:9989-10896batch: iter_time=3.110e-04, forward_time=0.159, loss_ctc=1.253, loss=0.626, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.492e-04, train_time=2.092
[ALab02:0/2] 2023-07-21 16:25:53,055 (trainer:721) INFO: 27epoch:train:10897-11804batch: iter_time=2.907e-04, forward_time=0.156, loss_ctc=1.217, loss=0.609, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.490e-04, train_time=2.097
[ALab02:0/2] 2023-07-21 16:34:06,263 (trainer:721) INFO: 27epoch:train:11805-12712batch: iter_time=2.405e-04, forward_time=0.173, loss_ctc=1.271, loss=0.636, backward_time=0.230, optim_step_time=0.034, optim0_lr0=2.487e-04, train_time=2.173
[ALab02:0/2] 2023-07-21 16:41:57,247 (trainer:721) INFO: 27epoch:train:12713-13620batch: iter_time=2.473e-04, forward_time=0.155, loss_ctc=1.251, loss=0.625, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.485e-04, train_time=2.075
[ALab02:0/2] 2023-07-21 16:49:48,510 (trainer:721) INFO: 27epoch:train:13621-14528batch: iter_time=2.710e-04, forward_time=0.158, loss_ctc=1.248, loss=0.624, backward_time=0.229, optim_step_time=0.036, optim0_lr0=2.483e-04, train_time=2.076
[ALab02:0/2] 2023-07-21 16:57:42,201 (trainer:721) INFO: 27epoch:train:14529-15436batch: iter_time=2.843e-04, forward_time=0.158, loss_ctc=1.271, loss=0.635, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.481e-04, train_time=2.087
[ALab02:0/2] 2023-07-21 17:05:31,573 (trainer:721) INFO: 27epoch:train:15437-16344batch: iter_time=2.489e-04, forward_time=0.157, loss_ctc=1.286, loss=0.643, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.478e-04, train_time=2.067
[ALab02:0/2] 2023-07-21 17:13:22,008 (trainer:721) INFO: 27epoch:train:16345-17252batch: iter_time=2.750e-04, forward_time=0.158, loss_ctc=1.248, loss=0.624, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.476e-04, train_time=2.072
[ALab02:0/2] 2023-07-21 17:21:11,165 (trainer:721) INFO: 27epoch:train:17253-18160batch: iter_time=2.934e-04, forward_time=0.158, loss_ctc=1.227, loss=0.613, backward_time=0.229, optim_step_time=0.035, optim0_lr0=2.474e-04, train_time=2.067
[ALab02:0/2] 2023-07-21 17:22:14,702 (trainer:338) INFO: 27epoch results: [train] iter_time=2.868e-04, forward_time=0.156, loss_ctc=1.250, loss=0.625, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.496e-04, train_time=2.080, time=2 hours, 37 minutes and 33.13 seconds, total_count=490752, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.461, cer_ctc=0.060, cer=0.060, loss=1.730, time=6.55 seconds, total_count=405, gpu_max_cached_mem_GB=42.223, [att_plot] time=47.62 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 17:22:19,105 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-21 17:22:19,107 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/16epoch.pth
[ALab02:0/2] 2023-07-21 17:22:19,107 (trainer:272) INFO: 28/50epoch started. Estimated time to finish: 2 days, 14 hours and 36 minutes
[ALab02:0/2] 2023-07-21 17:30:18,608 (trainer:721) INFO: 28epoch:train:1-908batch: iter_time=6.940e-04, forward_time=0.157, loss_ctc=1.204, loss=0.602, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.471e-04, train_time=2.112
[ALab02:0/2] 2023-07-21 17:38:09,442 (trainer:721) INFO: 28epoch:train:909-1816batch: iter_time=2.683e-04, forward_time=0.158, loss_ctc=1.188, loss=0.594, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.469e-04, train_time=2.074
[ALab02:0/2] 2023-07-21 17:45:57,035 (trainer:721) INFO: 28epoch:train:1817-2724batch: iter_time=2.849e-04, forward_time=0.157, loss_ctc=1.209, loss=0.604, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.467e-04, train_time=2.060
[ALab02:0/2] 2023-07-21 17:53:45,441 (trainer:721) INFO: 28epoch:train:2725-3632batch: iter_time=2.579e-04, forward_time=0.158, loss_ctc=1.219, loss=0.609, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.464e-04, train_time=2.063
[ALab02:0/2] 2023-07-21 18:01:34,418 (trainer:721) INFO: 28epoch:train:3633-4540batch: iter_time=2.762e-04, forward_time=0.157, loss_ctc=1.214, loss=0.607, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.462e-04, train_time=2.066
[ALab02:0/2] 2023-07-21 18:09:24,604 (trainer:721) INFO: 28epoch:train:4541-5448batch: iter_time=2.672e-04, forward_time=0.157, loss_ctc=1.193, loss=0.596, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.460e-04, train_time=2.071
[ALab02:0/2] 2023-07-21 18:17:15,057 (trainer:721) INFO: 28epoch:train:5449-6356batch: iter_time=2.747e-04, forward_time=0.158, loss_ctc=1.225, loss=0.613, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.458e-04, train_time=2.072
[ALab02:0/2] 2023-07-21 18:25:01,378 (trainer:721) INFO: 28epoch:train:6357-7264batch: iter_time=2.676e-04, forward_time=0.157, loss_ctc=1.267, loss=0.633, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.455e-04, train_time=2.054
[ALab02:0/2] 2023-07-21 18:32:51,717 (trainer:721) INFO: 28epoch:train:7265-8172batch: iter_time=2.776e-04, forward_time=0.159, loss_ctc=1.249, loss=0.625, backward_time=0.229, optim_step_time=0.038, optim0_lr0=2.453e-04, train_time=2.072
[ALab02:0/2] 2023-07-21 18:40:39,901 (trainer:721) INFO: 28epoch:train:8173-9080batch: iter_time=2.517e-04, forward_time=0.157, loss_ctc=1.244, loss=0.622, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.451e-04, train_time=2.062
[ALab02:0/2] 2023-07-21 18:48:32,383 (trainer:721) INFO: 28epoch:train:9081-9988batch: iter_time=2.797e-04, forward_time=0.159, loss_ctc=1.251, loss=0.625, backward_time=0.229, optim_step_time=0.036, optim0_lr0=2.449e-04, train_time=2.081
[ALab02:0/2] 2023-07-21 18:56:20,361 (trainer:721) INFO: 28epoch:train:9989-10896batch: iter_time=2.716e-04, forward_time=0.156, loss_ctc=1.234, loss=0.617, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.447e-04, train_time=2.061
[ALab02:0/2] 2023-07-21 19:04:10,186 (trainer:721) INFO: 28epoch:train:10897-11804batch: iter_time=2.704e-04, forward_time=0.158, loss_ctc=1.220, loss=0.610, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.444e-04, train_time=2.069
[ALab02:0/2] 2023-07-21 19:11:55,463 (trainer:721) INFO: 28epoch:train:11805-12712batch: iter_time=2.777e-04, forward_time=0.156, loss_ctc=1.223, loss=0.611, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.442e-04, train_time=2.049
[ALab02:0/2] 2023-07-21 19:19:43,304 (trainer:721) INFO: 28epoch:train:12713-13620batch: iter_time=2.545e-04, forward_time=0.157, loss_ctc=1.186, loss=0.593, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.440e-04, train_time=2.061
[ALab02:0/2] 2023-07-21 19:27:35,721 (trainer:721) INFO: 28epoch:train:13621-14528batch: iter_time=2.736e-04, forward_time=0.160, loss_ctc=1.239, loss=0.620, backward_time=0.230, optim_step_time=0.037, optim0_lr0=2.438e-04, train_time=2.081
[ALab02:0/2] 2023-07-21 19:35:21,751 (trainer:721) INFO: 28epoch:train:14529-15436batch: iter_time=2.502e-04, forward_time=0.155, loss_ctc=1.217, loss=0.608, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.436e-04, train_time=2.053
[ALab02:0/2] 2023-07-21 19:43:11,143 (trainer:721) INFO: 28epoch:train:15437-16344batch: iter_time=2.683e-04, forward_time=0.158, loss_ctc=1.206, loss=0.603, backward_time=0.228, optim_step_time=0.038, optim0_lr0=2.433e-04, train_time=2.068
[ALab02:0/2] 2023-07-21 19:50:59,378 (trainer:721) INFO: 28epoch:train:16345-17252batch: iter_time=2.824e-04, forward_time=0.158, loss_ctc=1.197, loss=0.599, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.431e-04, train_time=2.062
[ALab02:0/2] 2023-07-21 19:58:49,210 (trainer:721) INFO: 28epoch:train:17253-18160batch: iter_time=3.128e-04, forward_time=0.159, loss_ctc=1.213, loss=0.607, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.429e-04, train_time=2.070
[ALab02:0/2] 2023-07-21 19:59:44,232 (trainer:338) INFO: 28epoch results: [train] iter_time=2.931e-04, forward_time=0.157, loss_ctc=1.220, loss=0.610, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.450e-04, train_time=2.068, time=2 hours, 36 minutes and 39.23 seconds, total_count=508928, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.311, cer_ctc=0.059, cer=0.059, loss=1.656, time=6.43 seconds, total_count=420, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.46 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 19:59:48,822 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-21 19:59:48,823 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/17epoch.pth
[ALab02:0/2] 2023-07-21 19:59:48,823 (trainer:272) INFO: 29/50epoch started. Estimated time to finish: 2 days, 11 hours and 48 minutes
[ALab02:0/2] 2023-07-21 20:07:50,144 (trainer:721) INFO: 29epoch:train:1-908batch: iter_time=6.415e-04, forward_time=0.159, loss_ctc=1.130, loss=0.565, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.427e-04, train_time=2.120
[ALab02:0/2] 2023-07-21 20:15:36,065 (trainer:721) INFO: 29epoch:train:909-1816batch: iter_time=3.026e-04, forward_time=0.156, loss_ctc=1.163, loss=0.582, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.425e-04, train_time=2.052
[ALab02:0/2] 2023-07-21 20:23:23,896 (trainer:721) INFO: 29epoch:train:1817-2724batch: iter_time=2.928e-04, forward_time=0.156, loss_ctc=1.195, loss=0.598, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.422e-04, train_time=2.060
[ALab02:0/2] 2023-07-21 20:31:15,022 (trainer:721) INFO: 29epoch:train:2725-3632batch: iter_time=2.644e-04, forward_time=0.159, loss_ctc=1.189, loss=0.594, backward_time=0.230, optim_step_time=0.037, optim0_lr0=2.420e-04, train_time=2.076
[ALab02:0/2] 2023-07-21 20:39:00,660 (trainer:721) INFO: 29epoch:train:3633-4540batch: iter_time=2.539e-04, forward_time=0.156, loss_ctc=1.204, loss=0.602, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.418e-04, train_time=2.051
[ALab02:0/2] 2023-07-21 20:49:57,859 (trainer:721) INFO: 29epoch:train:4541-5448batch: iter_time=3.323e-04, forward_time=0.229, loss_ctc=1.169, loss=0.584, backward_time=0.300, optim_step_time=0.038, optim0_lr0=2.416e-04, train_time=2.895
[ALab02:0/2] 2023-07-21 21:06:28,396 (trainer:721) INFO: 29epoch:train:5449-6356batch: iter_time=3.542e-04, forward_time=0.347, loss_ctc=1.199, loss=0.600, backward_time=0.417, optim_step_time=0.040, optim0_lr0=2.414e-04, train_time=4.363
[ALab02:0/2] 2023-07-21 21:22:56,355 (trainer:721) INFO: 29epoch:train:6357-7264batch: iter_time=3.659e-04, forward_time=0.348, loss_ctc=1.161, loss=0.581, backward_time=0.416, optim_step_time=0.041, optim0_lr0=2.412e-04, train_time=4.352
[ALab02:0/2] 2023-07-21 21:37:21,337 (trainer:721) INFO: 29epoch:train:7265-8172batch: iter_time=4.200e-04, forward_time=0.302, loss_ctc=1.207, loss=0.603, backward_time=0.372, optim_step_time=0.042, optim0_lr0=2.410e-04, train_time=3.810
[ALab02:0/2] 2023-07-21 21:45:08,887 (trainer:721) INFO: 29epoch:train:8173-9080batch: iter_time=2.705e-04, forward_time=0.156, loss_ctc=1.177, loss=0.589, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.408e-04, train_time=2.059
[ALab02:0/2] 2023-07-21 21:52:54,216 (trainer:721) INFO: 29epoch:train:9081-9988batch: iter_time=2.708e-04, forward_time=0.155, loss_ctc=1.145, loss=0.573, backward_time=0.226, optim_step_time=0.035, optim0_lr0=2.405e-04, train_time=2.050
[ALab02:0/2] 2023-07-21 22:00:45,138 (trainer:721) INFO: 29epoch:train:9989-10896batch: iter_time=2.801e-04, forward_time=0.159, loss_ctc=1.164, loss=0.582, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.403e-04, train_time=2.074
[ALab02:0/2] 2023-07-21 22:08:34,168 (trainer:721) INFO: 29epoch:train:10897-11804batch: iter_time=2.929e-04, forward_time=0.157, loss_ctc=1.162, loss=0.581, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.401e-04, train_time=2.066
[ALab02:0/2] 2023-07-21 22:16:23,811 (trainer:721) INFO: 29epoch:train:11805-12712batch: iter_time=3.194e-04, forward_time=0.158, loss_ctc=1.163, loss=0.581, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.399e-04, train_time=2.069
[ALab02:0/2] 2023-07-21 22:24:12,576 (trainer:721) INFO: 29epoch:train:12713-13620batch: iter_time=2.739e-04, forward_time=0.158, loss_ctc=1.128, loss=0.564, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.397e-04, train_time=2.065
[ALab02:0/2] 2023-07-21 22:32:03,393 (trainer:721) INFO: 29epoch:train:13621-14528batch: iter_time=2.820e-04, forward_time=0.160, loss_ctc=1.184, loss=0.592, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.395e-04, train_time=2.074
[ALab02:0/2] 2023-07-21 22:39:52,077 (trainer:721) INFO: 29epoch:train:14529-15436batch: iter_time=3.024e-04, forward_time=0.157, loss_ctc=1.215, loss=0.608, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.393e-04, train_time=2.064
[ALab02:0/2] 2023-07-21 22:47:42,120 (trainer:721) INFO: 29epoch:train:15437-16344batch: iter_time=2.775e-04, forward_time=0.159, loss_ctc=1.213, loss=0.607, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.391e-04, train_time=2.070
[ALab02:0/2] 2023-07-21 22:55:29,385 (trainer:721) INFO: 29epoch:train:16345-17252batch: iter_time=2.884e-04, forward_time=0.157, loss_ctc=1.180, loss=0.590, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.389e-04, train_time=2.058
[ALab02:0/2] 2023-07-21 23:03:19,025 (trainer:721) INFO: 29epoch:train:17253-18160batch: iter_time=2.720e-04, forward_time=0.157, loss_ctc=1.178, loss=0.589, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.387e-04, train_time=2.069
[ALab02:0/2] 2023-07-21 23:04:18,200 (trainer:338) INFO: 29epoch results: [train] iter_time=3.198e-04, forward_time=0.187, loss_ctc=1.176, loss=0.588, backward_time=0.258, optim_step_time=0.037, optim0_lr0=2.407e-04, train_time=2.425, time=3 hours, 3 minutes and 42.11 seconds, total_count=527104, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.236, cer_ctc=0.059, cer=0.059, loss=1.618, time=6.56 seconds, total_count=435, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.71 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-21 23:04:22,174 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-21 23:04:22,175 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/19epoch.pth
[ALab02:0/2] 2023-07-21 23:04:22,175 (trainer:272) INFO: 30/50epoch started. Estimated time to finish: 2 days, 9 hours and 20 minutes
[ALab02:0/2] 2023-07-21 23:12:19,689 (trainer:721) INFO: 30epoch:train:1-908batch: iter_time=8.791e-04, forward_time=0.156, loss_ctc=1.108, loss=0.554, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.385e-04, train_time=2.103
[ALab02:0/2] 2023-07-21 23:20:09,547 (trainer:721) INFO: 30epoch:train:909-1816batch: iter_time=3.139e-04, forward_time=0.158, loss_ctc=1.146, loss=0.573, backward_time=0.228, optim_step_time=0.038, optim0_lr0=2.383e-04, train_time=2.070
[ALab02:0/2] 2023-07-21 23:27:55,963 (trainer:721) INFO: 30epoch:train:1817-2724batch: iter_time=2.818e-04, forward_time=0.157, loss_ctc=1.169, loss=0.585, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.381e-04, train_time=2.054
[ALab02:0/2] 2023-07-21 23:35:44,666 (trainer:721) INFO: 30epoch:train:2725-3632batch: iter_time=2.950e-04, forward_time=0.157, loss_ctc=1.176, loss=0.588, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.379e-04, train_time=2.065
[ALab02:0/2] 2023-07-21 23:43:30,722 (trainer:721) INFO: 30epoch:train:3633-4540batch: iter_time=2.768e-04, forward_time=0.156, loss_ctc=1.159, loss=0.580, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.376e-04, train_time=2.053
[ALab02:0/2] 2023-07-21 23:51:17,094 (trainer:721) INFO: 30epoch:train:4541-5448batch: iter_time=2.901e-04, forward_time=0.156, loss_ctc=1.126, loss=0.563, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.374e-04, train_time=2.054
[ALab02:0/2] 2023-07-21 23:59:05,755 (trainer:721) INFO: 30epoch:train:5449-6356batch: iter_time=2.728e-04, forward_time=0.158, loss_ctc=1.154, loss=0.577, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.372e-04, train_time=2.064
[ALab02:0/2] 2023-07-22 00:06:53,695 (trainer:721) INFO: 30epoch:train:6357-7264batch: iter_time=2.687e-04, forward_time=0.157, loss_ctc=1.137, loss=0.569, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.370e-04, train_time=2.061
[ALab02:0/2] 2023-07-22 00:14:41,787 (trainer:721) INFO: 30epoch:train:7265-8172batch: iter_time=2.928e-04, forward_time=0.158, loss_ctc=1.139, loss=0.570, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.368e-04, train_time=2.062
[ALab02:0/2] 2023-07-22 00:22:29,702 (trainer:721) INFO: 30epoch:train:8173-9080batch: iter_time=2.960e-04, forward_time=0.157, loss_ctc=1.130, loss=0.565, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.366e-04, train_time=2.061
[ALab02:0/2] 2023-07-22 00:30:18,361 (trainer:721) INFO: 30epoch:train:9081-9988batch: iter_time=2.682e-04, forward_time=0.158, loss_ctc=1.136, loss=0.568, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.364e-04, train_time=2.064
[ALab02:0/2] 2023-07-22 00:38:04,458 (trainer:721) INFO: 30epoch:train:9989-10896batch: iter_time=2.924e-04, forward_time=0.156, loss_ctc=1.198, loss=0.599, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.362e-04, train_time=2.053
[ALab02:0/2] 2023-07-22 00:45:55,998 (trainer:721) INFO: 30epoch:train:10897-11804batch: iter_time=2.694e-04, forward_time=0.160, loss_ctc=1.159, loss=0.580, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.360e-04, train_time=2.077
[ALab02:0/2] 2023-07-22 00:53:41,604 (trainer:721) INFO: 30epoch:train:11805-12712batch: iter_time=2.595e-04, forward_time=0.156, loss_ctc=1.190, loss=0.595, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.358e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 01:01:28,432 (trainer:721) INFO: 30epoch:train:12713-13620batch: iter_time=2.703e-04, forward_time=0.157, loss_ctc=1.226, loss=0.613, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.356e-04, train_time=2.056
[ALab02:0/2] 2023-07-22 01:09:18,276 (trainer:721) INFO: 30epoch:train:13621-14528batch: iter_time=2.858e-04, forward_time=0.157, loss_ctc=1.233, loss=0.616, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.354e-04, train_time=2.070
[ALab02:0/2] 2023-07-22 01:17:05,279 (trainer:721) INFO: 30epoch:train:14529-15436batch: iter_time=2.467e-04, forward_time=0.155, loss_ctc=1.176, loss=0.588, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.352e-04, train_time=2.057
[ALab02:0/2] 2023-07-22 01:24:53,543 (trainer:721) INFO: 30epoch:train:15437-16344batch: iter_time=2.980e-04, forward_time=0.156, loss_ctc=1.193, loss=0.596, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.351e-04, train_time=2.063
[ALab02:0/2] 2023-07-22 01:32:39,279 (trainer:721) INFO: 30epoch:train:16345-17252batch: iter_time=2.823e-04, forward_time=0.157, loss_ctc=1.155, loss=0.578, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.349e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 01:40:28,027 (trainer:721) INFO: 30epoch:train:17253-18160batch: iter_time=2.704e-04, forward_time=0.157, loss_ctc=1.109, loss=0.554, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.347e-04, train_time=2.065
[ALab02:0/2] 2023-07-22 01:41:25,859 (trainer:338) INFO: 30epoch results: [train] iter_time=3.104e-04, forward_time=0.157, loss_ctc=1.161, loss=0.580, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.365e-04, train_time=2.063, time=2 hours, 36 minutes and 15.23 seconds, total_count=545280, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.404, cer_ctc=0.062, cer=0.062, loss=1.702, time=6.44 seconds, total_count=450, gpu_max_cached_mem_GB=42.223, [att_plot] time=42.01 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 01:41:29,468 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 01:41:29,476 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/23epoch.pth
[ALab02:0/2] 2023-07-22 01:41:29,476 (trainer:272) INFO: 31/50epoch started. Estimated time to finish: 2 days, 6 hours and 32 minutes
[ALab02:0/2] 2023-07-22 01:49:24,022 (trainer:721) INFO: 31epoch:train:1-908batch: iter_time=6.374e-04, forward_time=0.156, loss_ctc=1.109, loss=0.554, backward_time=0.226, optim_step_time=0.036, optim0_lr0=2.345e-04, train_time=2.090
[ALab02:0/2] 2023-07-22 01:57:11,611 (trainer:721) INFO: 31epoch:train:909-1816batch: iter_time=2.880e-04, forward_time=0.156, loss_ctc=1.123, loss=0.561, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.343e-04, train_time=2.060
[ALab02:0/2] 2023-07-22 02:04:58,860 (trainer:721) INFO: 31epoch:train:1817-2724batch: iter_time=2.545e-04, forward_time=0.157, loss_ctc=1.140, loss=0.570, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.341e-04, train_time=2.058
[ALab02:0/2] 2023-07-22 02:12:45,555 (trainer:721) INFO: 31epoch:train:2725-3632batch: iter_time=2.781e-04, forward_time=0.156, loss_ctc=1.128, loss=0.564, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.339e-04, train_time=2.056
[ALab02:0/2] 2023-07-22 02:20:30,710 (trainer:721) INFO: 31epoch:train:3633-4540batch: iter_time=2.534e-04, forward_time=0.155, loss_ctc=1.102, loss=0.551, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.337e-04, train_time=2.049
[ALab02:0/2] 2023-07-22 02:28:22,907 (trainer:721) INFO: 31epoch:train:4541-5448batch: iter_time=3.093e-04, forward_time=0.158, loss_ctc=1.124, loss=0.562, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.335e-04, train_time=2.080
[ALab02:0/2] 2023-07-22 02:36:10,989 (trainer:721) INFO: 31epoch:train:5449-6356batch: iter_time=2.784e-04, forward_time=0.157, loss_ctc=1.104, loss=0.552, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.333e-04, train_time=2.062
[ALab02:0/2] 2023-07-22 02:43:58,640 (trainer:721) INFO: 31epoch:train:6357-7264batch: iter_time=2.859e-04, forward_time=0.156, loss_ctc=1.177, loss=0.589, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.331e-04, train_time=2.060
[ALab02:0/2] 2023-07-22 02:51:44,074 (trainer:721) INFO: 31epoch:train:7265-8172batch: iter_time=2.492e-04, forward_time=0.156, loss_ctc=1.145, loss=0.573, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.329e-04, train_time=2.050
[ALab02:0/2] 2023-07-22 02:59:31,816 (trainer:721) INFO: 31epoch:train:8173-9080batch: iter_time=2.612e-04, forward_time=0.157, loss_ctc=1.103, loss=0.552, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.327e-04, train_time=2.060
[ALab02:0/2] 2023-07-22 03:07:20,125 (trainer:721) INFO: 31epoch:train:9081-9988batch: iter_time=2.698e-04, forward_time=0.157, loss_ctc=1.128, loss=0.564, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.325e-04, train_time=2.063
[ALab02:0/2] 2023-07-22 03:15:08,926 (trainer:721) INFO: 31epoch:train:9989-10896batch: iter_time=2.851e-04, forward_time=0.157, loss_ctc=1.142, loss=0.571, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.323e-04, train_time=2.065
[ALab02:0/2] 2023-07-22 03:22:57,921 (trainer:721) INFO: 31epoch:train:10897-11804batch: iter_time=2.971e-04, forward_time=0.158, loss_ctc=1.127, loss=0.563, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.322e-04, train_time=2.066
[ALab02:0/2] 2023-07-22 03:30:45,724 (trainer:721) INFO: 31epoch:train:11805-12712batch: iter_time=2.779e-04, forward_time=0.156, loss_ctc=1.158, loss=0.579, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.320e-04, train_time=2.061
[ALab02:0/2] 2023-07-22 03:38:33,838 (trainer:721) INFO: 31epoch:train:12713-13620batch: iter_time=2.770e-04, forward_time=0.157, loss_ctc=1.114, loss=0.557, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.318e-04, train_time=2.062
[ALab02:0/2] 2023-07-22 03:46:20,422 (trainer:721) INFO: 31epoch:train:13621-14528batch: iter_time=2.985e-04, forward_time=0.157, loss_ctc=1.120, loss=0.560, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.316e-04, train_time=2.055
[ALab02:0/2] 2023-07-22 03:54:09,514 (trainer:721) INFO: 31epoch:train:14529-15436batch: iter_time=3.190e-04, forward_time=0.157, loss_ctc=1.137, loss=0.568, backward_time=0.229, optim_step_time=0.038, optim0_lr0=2.314e-04, train_time=2.066
[ALab02:0/2] 2023-07-22 04:01:56,211 (trainer:721) INFO: 31epoch:train:15437-16344batch: iter_time=2.752e-04, forward_time=0.157, loss_ctc=1.128, loss=0.564, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.312e-04, train_time=2.056
[ALab02:0/2] 2023-07-22 04:09:43,115 (trainer:721) INFO: 31epoch:train:16345-17252batch: iter_time=3.229e-04, forward_time=0.157, loss_ctc=1.110, loss=0.555, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.310e-04, train_time=2.056
[ALab02:0/2] 2023-07-22 04:17:31,435 (trainer:721) INFO: 31epoch:train:17253-18160batch: iter_time=2.879e-04, forward_time=0.158, loss_ctc=1.116, loss=0.558, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.308e-04, train_time=2.063
[ALab02:0/2] 2023-07-22 04:18:28,054 (trainer:338) INFO: 31epoch results: [train] iter_time=3.002e-04, forward_time=0.157, loss_ctc=1.127, loss=0.563, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.326e-04, train_time=2.062, time=2 hours, 36 minutes and 11.42 seconds, total_count=563456, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.295, cer_ctc=0.060, cer=0.060, loss=1.648, time=6.35 seconds, total_count=465, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.8 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 04:18:31,777 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 04:18:31,817 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/30epoch.pth
[ALab02:0/2] 2023-07-22 04:18:31,818 (trainer:272) INFO: 32/50epoch started. Estimated time to finish: 2 days, 3 hours and 44 minutes
[ALab02:0/2] 2023-07-22 04:26:26,483 (trainer:721) INFO: 32epoch:train:1-908batch: iter_time=6.968e-04, forward_time=0.157, loss_ctc=1.098, loss=0.549, backward_time=0.226, optim_step_time=0.037, optim0_lr0=2.306e-04, train_time=2.091
[ALab02:0/2] 2023-07-22 04:34:15,911 (trainer:721) INFO: 32epoch:train:909-1816batch: iter_time=2.780e-04, forward_time=0.157, loss_ctc=1.090, loss=0.545, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.305e-04, train_time=2.068
[ALab02:0/2] 2023-07-22 04:42:08,868 (trainer:721) INFO: 32epoch:train:1817-2724batch: iter_time=3.216e-04, forward_time=0.160, loss_ctc=1.104, loss=0.552, backward_time=0.230, optim_step_time=0.037, optim0_lr0=2.303e-04, train_time=2.083
[ALab02:0/2] 2023-07-22 04:49:55,779 (trainer:721) INFO: 32epoch:train:2725-3632batch: iter_time=2.860e-04, forward_time=0.157, loss_ctc=1.093, loss=0.547, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.301e-04, train_time=2.057
[ALab02:0/2] 2023-07-22 04:57:46,218 (trainer:721) INFO: 32epoch:train:3633-4540batch: iter_time=2.807e-04, forward_time=0.159, loss_ctc=1.093, loss=0.546, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.299e-04, train_time=2.072
[ALab02:0/2] 2023-07-22 05:05:33,400 (trainer:721) INFO: 32epoch:train:4541-5448batch: iter_time=2.645e-04, forward_time=0.155, loss_ctc=1.088, loss=0.544, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.297e-04, train_time=2.058
[ALab02:0/2] 2023-07-22 05:13:20,146 (trainer:721) INFO: 32epoch:train:5449-6356batch: iter_time=2.595e-04, forward_time=0.156, loss_ctc=1.087, loss=0.543, backward_time=0.228, optim_step_time=0.034, optim0_lr0=2.295e-04, train_time=2.056
[ALab02:0/2] 2023-07-22 05:21:05,903 (trainer:721) INFO: 32epoch:train:6357-7264batch: iter_time=2.992e-04, forward_time=0.156, loss_ctc=1.128, loss=0.564, backward_time=0.226, optim_step_time=0.037, optim0_lr0=2.294e-04, train_time=2.052
[ALab02:0/2] 2023-07-22 05:28:52,205 (trainer:721) INFO: 32epoch:train:7265-8172batch: iter_time=3.187e-04, forward_time=0.156, loss_ctc=1.113, loss=0.557, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.292e-04, train_time=2.054
[ALab02:0/2] 2023-07-22 05:36:40,073 (trainer:721) INFO: 32epoch:train:8173-9080batch: iter_time=2.728e-04, forward_time=0.157, loss_ctc=1.115, loss=0.557, backward_time=0.226, optim_step_time=0.037, optim0_lr0=2.290e-04, train_time=2.061
[ALab02:0/2] 2023-07-22 05:44:27,691 (trainer:721) INFO: 32epoch:train:9081-9988batch: iter_time=2.663e-04, forward_time=0.157, loss_ctc=1.101, loss=0.551, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.288e-04, train_time=2.060
[ALab02:0/2] 2023-07-22 05:52:17,650 (trainer:721) INFO: 32epoch:train:9989-10896batch: iter_time=2.607e-04, forward_time=0.157, loss_ctc=1.121, loss=0.561, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.286e-04, train_time=2.070
[ALab02:0/2] 2023-07-22 06:00:03,679 (trainer:721) INFO: 32epoch:train:10897-11804batch: iter_time=2.699e-04, forward_time=0.157, loss_ctc=1.096, loss=0.548, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.285e-04, train_time=2.053
[ALab02:0/2] 2023-07-22 06:07:48,850 (trainer:721) INFO: 32epoch:train:11805-12712batch: iter_time=2.720e-04, forward_time=0.155, loss_ctc=1.136, loss=0.568, backward_time=0.226, optim_step_time=0.035, optim0_lr0=2.283e-04, train_time=2.049
[ALab02:0/2] 2023-07-22 06:15:36,224 (trainer:721) INFO: 32epoch:train:12713-13620batch: iter_time=2.983e-04, forward_time=0.157, loss_ctc=1.157, loss=0.578, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.281e-04, train_time=2.059
[ALab02:0/2] 2023-07-22 06:23:22,137 (trainer:721) INFO: 32epoch:train:13621-14528batch: iter_time=2.739e-04, forward_time=0.157, loss_ctc=1.103, loss=0.551, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.279e-04, train_time=2.052
[ALab02:0/2] 2023-07-22 06:31:13,683 (trainer:721) INFO: 32epoch:train:14529-15436batch: iter_time=2.933e-04, forward_time=0.158, loss_ctc=1.065, loss=0.532, backward_time=0.230, optim_step_time=0.037, optim0_lr0=2.277e-04, train_time=2.077
[ALab02:0/2] 2023-07-22 06:38:58,442 (trainer:721) INFO: 32epoch:train:15437-16344batch: iter_time=2.555e-04, forward_time=0.156, loss_ctc=1.116, loss=0.558, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.276e-04, train_time=2.047
[ALab02:0/2] 2023-07-22 06:46:48,935 (trainer:721) INFO: 32epoch:train:16345-17252batch: iter_time=2.994e-04, forward_time=0.158, loss_ctc=1.106, loss=0.553, backward_time=0.229, optim_step_time=0.038, optim0_lr0=2.274e-04, train_time=2.072
[ALab02:0/2] 2023-07-22 06:54:34,489 (trainer:721) INFO: 32epoch:train:17253-18160batch: iter_time=2.903e-04, forward_time=0.156, loss_ctc=1.104, loss=0.552, backward_time=0.228, optim_step_time=0.035, optim0_lr0=2.272e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 06:55:29,551 (trainer:338) INFO: 32epoch results: [train] iter_time=3.028e-04, forward_time=0.157, loss_ctc=1.106, loss=0.553, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.289e-04, train_time=2.062, time=2 hours, 36 minutes and 11.99 seconds, total_count=581632, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.366, cer_ctc=0.059, cer=0.059, loss=1.683, time=6.28 seconds, total_count=480, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.46 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 06:55:34,312 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 06:55:34,323 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/22epoch.pth
[ALab02:0/2] 2023-07-22 06:55:34,323 (trainer:272) INFO: 33/50epoch started. Estimated time to finish: 2 days, 57 minutes and 41.55 seconds
[ALab02:0/2] 2023-07-22 07:03:35,976 (trainer:721) INFO: 33epoch:train:1-908batch: iter_time=8.056e-04, forward_time=0.157, loss_ctc=1.061, loss=0.531, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.270e-04, train_time=2.121
[ALab02:0/2] 2023-07-22 07:11:21,691 (trainer:721) INFO: 33epoch:train:909-1816batch: iter_time=2.805e-04, forward_time=0.157, loss_ctc=1.045, loss=0.522, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.268e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 07:19:12,688 (trainer:721) INFO: 33epoch:train:1817-2724batch: iter_time=2.874e-04, forward_time=0.158, loss_ctc=1.091, loss=0.545, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.267e-04, train_time=2.075
[ALab02:0/2] 2023-07-22 07:26:58,908 (trainer:721) INFO: 33epoch:train:2725-3632batch: iter_time=2.832e-04, forward_time=0.156, loss_ctc=1.085, loss=0.542, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.265e-04, train_time=2.054
[ALab02:0/2] 2023-07-22 07:34:49,788 (trainer:721) INFO: 33epoch:train:3633-4540batch: iter_time=2.983e-04, forward_time=0.159, loss_ctc=1.052, loss=0.526, backward_time=0.229, optim_step_time=0.038, optim0_lr0=2.263e-04, train_time=2.074
[ALab02:0/2] 2023-07-22 07:42:37,062 (trainer:721) INFO: 33epoch:train:4541-5448batch: iter_time=2.737e-04, forward_time=0.157, loss_ctc=1.071, loss=0.535, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.261e-04, train_time=2.058
[ALab02:0/2] 2023-07-22 07:50:26,630 (trainer:721) INFO: 33epoch:train:5449-6356batch: iter_time=3.268e-04, forward_time=0.158, loss_ctc=1.089, loss=0.545, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.260e-04, train_time=2.068
[ALab02:0/2] 2023-07-22 07:58:16,205 (trainer:721) INFO: 33epoch:train:6357-7264batch: iter_time=2.962e-04, forward_time=0.158, loss_ctc=1.068, loss=0.534, backward_time=0.229, optim_step_time=0.036, optim0_lr0=2.258e-04, train_time=2.068
[ALab02:0/2] 2023-07-22 08:06:07,687 (trainer:721) INFO: 33epoch:train:7265-8172batch: iter_time=3.065e-04, forward_time=0.159, loss_ctc=1.101, loss=0.550, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.256e-04, train_time=2.077
[ALab02:0/2] 2023-07-22 08:13:54,988 (trainer:721) INFO: 33epoch:train:8173-9080batch: iter_time=2.721e-04, forward_time=0.157, loss_ctc=1.085, loss=0.542, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.254e-04, train_time=2.058
[ALab02:0/2] 2023-07-22 08:21:43,100 (trainer:721) INFO: 33epoch:train:9081-9988batch: iter_time=2.697e-04, forward_time=0.157, loss_ctc=1.074, loss=0.537, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.253e-04, train_time=2.062
[ALab02:0/2] 2023-07-22 08:29:32,378 (trainer:721) INFO: 33epoch:train:9989-10896batch: iter_time=3.476e-04, forward_time=0.158, loss_ctc=1.096, loss=0.548, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.251e-04, train_time=2.067
[ALab02:0/2] 2023-07-22 08:37:17,927 (trainer:721) INFO: 33epoch:train:10897-11804batch: iter_time=2.543e-04, forward_time=0.156, loss_ctc=1.089, loss=0.545, backward_time=0.226, optim_step_time=0.036, optim0_lr0=2.249e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 08:45:08,369 (trainer:721) INFO: 33epoch:train:11805-12712batch: iter_time=3.106e-04, forward_time=0.157, loss_ctc=1.125, loss=0.562, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.248e-04, train_time=2.072
[ALab02:0/2] 2023-07-22 08:52:53,216 (trainer:721) INFO: 33epoch:train:12713-13620batch: iter_time=2.592e-04, forward_time=0.156, loss_ctc=1.075, loss=0.538, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.246e-04, train_time=2.048
[ALab02:0/2] 2023-07-22 09:00:41,495 (trainer:721) INFO: 33epoch:train:13621-14528batch: iter_time=2.993e-04, forward_time=0.157, loss_ctc=1.092, loss=0.546, backward_time=0.227, optim_step_time=0.037, optim0_lr0=2.244e-04, train_time=2.063
[ALab02:0/2] 2023-07-22 09:08:27,269 (trainer:721) INFO: 33epoch:train:14529-15436batch: iter_time=2.763e-04, forward_time=0.155, loss_ctc=1.085, loss=0.543, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.242e-04, train_time=2.052
[ALab02:0/2] 2023-07-22 09:16:17,656 (trainer:721) INFO: 33epoch:train:15437-16344batch: iter_time=3.012e-04, forward_time=0.159, loss_ctc=1.089, loss=0.544, backward_time=0.229, optim_step_time=0.036, optim0_lr0=2.241e-04, train_time=2.072
[ALab02:0/2] 2023-07-22 09:24:03,158 (trainer:721) INFO: 33epoch:train:16345-17252batch: iter_time=2.881e-04, forward_time=0.156, loss_ctc=1.101, loss=0.551, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.239e-04, train_time=2.050
[ALab02:0/2] 2023-07-22 09:31:49,043 (trainer:721) INFO: 33epoch:train:17253-18160batch: iter_time=2.518e-04, forward_time=0.156, loss_ctc=1.060, loss=0.530, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.237e-04, train_time=2.052
[ALab02:0/2] 2023-07-22 09:32:49,746 (trainer:338) INFO: 33epoch results: [train] iter_time=3.144e-04, forward_time=0.157, loss_ctc=1.082, loss=0.541, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.254e-04, train_time=2.065, time=2 hours, 36 minutes and 25 seconds, total_count=599808, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.583, cer_ctc=0.059, cer=0.059, loss=1.792, time=10.2 seconds, total_count=495, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.22 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 09:32:54,609 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 09:32:54,624 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/20epoch.pth
[ALab02:0/2] 2023-07-22 09:32:54,624 (trainer:272) INFO: 34/50epoch started. Estimated time to finish: 1 day, 22 hours and 11 minutes
[ALab02:0/2] 2023-07-22 09:40:52,053 (trainer:721) INFO: 34epoch:train:1-908batch: iter_time=7.379e-04, forward_time=0.156, loss_ctc=1.104, loss=0.552, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.236e-04, train_time=2.103
[ALab02:0/2] 2023-07-22 09:48:41,965 (trainer:721) INFO: 34epoch:train:909-1816batch: iter_time=2.887e-04, forward_time=0.157, loss_ctc=1.096, loss=0.548, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.234e-04, train_time=2.070
[ALab02:0/2] 2023-07-22 09:56:29,328 (trainer:721) INFO: 34epoch:train:1817-2724batch: iter_time=2.606e-04, forward_time=0.157, loss_ctc=1.042, loss=0.521, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.232e-04, train_time=2.059
[ALab02:0/2] 2023-07-22 10:04:19,698 (trainer:721) INFO: 34epoch:train:2725-3632batch: iter_time=2.739e-04, forward_time=0.157, loss_ctc=1.079, loss=0.540, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.231e-04, train_time=2.072
[ALab02:0/2] 2023-07-22 10:12:05,658 (trainer:721) INFO: 34epoch:train:3633-4540batch: iter_time=2.723e-04, forward_time=0.156, loss_ctc=1.057, loss=0.528, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.229e-04, train_time=2.052
[ALab02:0/2] 2023-07-22 10:19:51,873 (trainer:721) INFO: 34epoch:train:4541-5448batch: iter_time=2.961e-04, forward_time=0.156, loss_ctc=1.036, loss=0.518, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.227e-04, train_time=2.054
[ALab02:0/2] 2023-07-22 10:27:39,953 (trainer:721) INFO: 34epoch:train:5449-6356batch: iter_time=2.641e-04, forward_time=0.157, loss_ctc=1.071, loss=0.535, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.225e-04, train_time=2.062
[ALab02:0/2] 2023-07-22 10:35:27,607 (trainer:721) INFO: 34epoch:train:6357-7264batch: iter_time=2.819e-04, forward_time=0.156, loss_ctc=1.056, loss=0.528, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.224e-04, train_time=2.060
[ALab02:0/2] 2023-07-22 10:43:18,665 (trainer:721) INFO: 34epoch:train:7265-8172batch: iter_time=3.517e-04, forward_time=0.159, loss_ctc=1.060, loss=0.530, backward_time=0.229, optim_step_time=0.037, optim0_lr0=2.222e-04, train_time=2.075
[ALab02:0/2] 2023-07-22 10:51:05,513 (trainer:721) INFO: 34epoch:train:8173-9080batch: iter_time=2.680e-04, forward_time=0.157, loss_ctc=1.079, loss=0.540, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.221e-04, train_time=2.056
[ALab02:0/2] 2023-07-22 10:58:54,537 (trainer:721) INFO: 34epoch:train:9081-9988batch: iter_time=2.845e-04, forward_time=0.158, loss_ctc=1.075, loss=0.538, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.219e-04, train_time=2.066
[ALab02:0/2] 2023-07-22 11:06:42,477 (trainer:721) INFO: 34epoch:train:9989-10896batch: iter_time=3.067e-04, forward_time=0.157, loss_ctc=1.077, loss=0.539, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.217e-04, train_time=2.061
[ALab02:0/2] 2023-07-22 11:14:31,751 (trainer:721) INFO: 34epoch:train:10897-11804batch: iter_time=3.246e-04, forward_time=0.157, loss_ctc=1.045, loss=0.523, backward_time=0.228, optim_step_time=0.037, optim0_lr0=2.216e-04, train_time=2.067
[ALab02:0/2] 2023-07-22 11:22:20,179 (trainer:721) INFO: 34epoch:train:11805-12712batch: iter_time=2.708e-04, forward_time=0.158, loss_ctc=1.067, loss=0.533, backward_time=0.228, optim_step_time=0.036, optim0_lr0=2.214e-04, train_time=2.063
[ALab02:0/2] 2023-07-22 11:30:11,200 (trainer:721) INFO: 34epoch:train:12713-13620batch: iter_time=3.289e-04, forward_time=0.158, loss_ctc=1.048, loss=0.524, backward_time=0.229, optim_step_time=0.039, optim0_lr0=2.212e-04, train_time=2.075
[ALab02:0/2] 2023-07-22 11:37:57,261 (trainer:721) INFO: 34epoch:train:13621-14528batch: iter_time=2.926e-04, forward_time=0.156, loss_ctc=1.046, loss=0.523, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.211e-04, train_time=2.053
[ALab02:0/2] 2023-07-22 11:45:42,964 (trainer:721) INFO: 34epoch:train:14529-15436batch: iter_time=3.045e-04, forward_time=0.157, loss_ctc=1.019, loss=0.509, backward_time=0.227, optim_step_time=0.035, optim0_lr0=2.209e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 11:53:28,082 (trainer:721) INFO: 34epoch:train:15437-16344batch: iter_time=2.885e-04, forward_time=0.156, loss_ctc=1.069, loss=0.535, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.207e-04, train_time=2.049
[ALab02:0/2] 2023-07-22 12:01:10,431 (trainer:721) INFO: 34epoch:train:16345-17252batch: iter_time=2.268e-04, forward_time=0.153, loss_ctc=1.061, loss=0.530, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.206e-04, train_time=2.037
[ALab02:0/2] 2023-07-22 12:08:53,736 (trainer:721) INFO: 34epoch:train:17253-18160batch: iter_time=2.354e-04, forward_time=0.154, loss_ctc=1.025, loss=0.512, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.204e-04, train_time=2.041
[ALab02:0/2] 2023-07-22 12:09:49,551 (trainer:338) INFO: 34epoch results: [train] iter_time=3.079e-04, forward_time=0.157, loss_ctc=1.061, loss=0.530, backward_time=0.227, optim_step_time=0.036, optim0_lr0=2.220e-04, train_time=2.061, time=2 hours, 36 minutes and 8.39 seconds, total_count=617984, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.722, cer_ctc=0.059, cer=0.059, loss=1.861, time=6.35 seconds, total_count=510, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.19 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 12:09:53,689 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 12:09:53,711 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/25epoch.pth
[ALab02:0/2] 2023-07-22 12:09:53,711 (trainer:272) INFO: 35/50epoch started. Estimated time to finish: 1 day, 19 hours and 25 minutes
[ALab02:0/2] 2023-07-22 12:17:47,595 (trainer:721) INFO: 35epoch:train:1-908batch: iter_time=9.966e-04, forward_time=0.155, loss_ctc=1.012, loss=0.506, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.202e-04, train_time=2.087
[ALab02:0/2] 2023-07-22 12:25:28,677 (trainer:721) INFO: 35epoch:train:909-1816batch: iter_time=2.419e-04, forward_time=0.153, loss_ctc=1.054, loss=0.527, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.201e-04, train_time=2.031
[ALab02:0/2] 2023-07-22 12:33:10,025 (trainer:721) INFO: 35epoch:train:1817-2724batch: iter_time=2.531e-04, forward_time=0.154, loss_ctc=1.000, loss=0.500, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.199e-04, train_time=2.032
[ALab02:0/2] 2023-07-22 12:40:53,110 (trainer:721) INFO: 35epoch:train:2725-3632batch: iter_time=2.498e-04, forward_time=0.154, loss_ctc=1.034, loss=0.517, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.198e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 12:48:33,009 (trainer:721) INFO: 35epoch:train:3633-4540batch: iter_time=2.565e-04, forward_time=0.153, loss_ctc=1.050, loss=0.525, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.196e-04, train_time=2.026
[ALab02:0/2] 2023-07-22 12:56:13,769 (trainer:721) INFO: 35epoch:train:4541-5448batch: iter_time=2.498e-04, forward_time=0.153, loss_ctc=1.043, loss=0.522, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.194e-04, train_time=2.030
[ALab02:0/2] 2023-07-22 13:03:55,734 (trainer:721) INFO: 35epoch:train:5449-6356batch: iter_time=2.427e-04, forward_time=0.154, loss_ctc=1.113, loss=0.556, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.193e-04, train_time=2.035
[ALab02:0/2] 2023-07-22 13:11:36,677 (trainer:721) INFO: 35epoch:train:6357-7264batch: iter_time=2.508e-04, forward_time=0.154, loss_ctc=1.062, loss=0.531, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.191e-04, train_time=2.030
[ALab02:0/2] 2023-07-22 13:19:19,166 (trainer:721) INFO: 35epoch:train:7265-8172batch: iter_time=2.358e-04, forward_time=0.154, loss_ctc=1.056, loss=0.528, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.190e-04, train_time=2.037
[ALab02:0/2] 2023-07-22 13:27:01,980 (trainer:721) INFO: 35epoch:train:8173-9080batch: iter_time=2.458e-04, forward_time=0.154, loss_ctc=1.027, loss=0.514, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.188e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 13:34:42,307 (trainer:721) INFO: 35epoch:train:9081-9988batch: iter_time=2.410e-04, forward_time=0.154, loss_ctc=1.047, loss=0.523, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.186e-04, train_time=2.028
[ALab02:0/2] 2023-07-22 13:42:24,359 (trainer:721) INFO: 35epoch:train:9989-10896batch: iter_time=2.641e-04, forward_time=0.154, loss_ctc=1.047, loss=0.523, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.185e-04, train_time=2.035
[ALab02:0/2] 2023-07-22 13:50:23,993 (trainer:721) INFO: 35epoch:train:10897-11804batch: iter_time=2.454e-04, forward_time=0.159, loss_ctc=1.057, loss=0.529, backward_time=0.231, optim_step_time=0.033, optim0_lr0=2.183e-04, train_time=2.113
[ALab02:0/2] 2023-07-22 13:58:24,727 (trainer:721) INFO: 35epoch:train:11805-12712batch: iter_time=2.925e-04, forward_time=0.158, loss_ctc=1.035, loss=0.518, backward_time=0.231, optim_step_time=0.033, optim0_lr0=2.182e-04, train_time=2.118
[ALab02:0/2] 2023-07-22 14:06:19,443 (trainer:721) INFO: 35epoch:train:12713-13620batch: iter_time=2.574e-04, forward_time=0.157, loss_ctc=1.023, loss=0.512, backward_time=0.231, optim_step_time=0.033, optim0_lr0=2.180e-04, train_time=2.091
[ALab02:0/2] 2023-07-22 14:14:16,901 (trainer:721) INFO: 35epoch:train:13621-14528batch: iter_time=3.027e-04, forward_time=0.156, loss_ctc=1.038, loss=0.519, backward_time=0.229, optim_step_time=0.033, optim0_lr0=2.179e-04, train_time=2.103
[ALab02:0/2] 2023-07-22 14:21:59,428 (trainer:721) INFO: 35epoch:train:14529-15436batch: iter_time=2.349e-04, forward_time=0.154, loss_ctc=1.054, loss=0.527, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.177e-04, train_time=2.037
[ALab02:0/2] 2023-07-22 14:29:40,338 (trainer:721) INFO: 35epoch:train:15437-16344batch: iter_time=2.418e-04, forward_time=0.153, loss_ctc=1.054, loss=0.527, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.175e-04, train_time=2.030
[ALab02:0/2] 2023-07-22 14:37:22,187 (trainer:721) INFO: 35epoch:train:16345-17252batch: iter_time=2.349e-04, forward_time=0.153, loss_ctc=1.087, loss=0.544, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.174e-04, train_time=2.034
[ALab02:0/2] 2023-07-22 14:45:04,680 (trainer:721) INFO: 35epoch:train:17253-18160batch: iter_time=2.264e-04, forward_time=0.153, loss_ctc=1.013, loss=0.506, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.172e-04, train_time=2.037
[ALab02:0/2] 2023-07-22 14:45:58,918 (trainer:338) INFO: 35epoch results: [train] iter_time=2.881e-04, forward_time=0.154, loss_ctc=1.045, loss=0.523, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.187e-04, train_time=2.051, time=2 hours, 35 minutes and 20.13 seconds, total_count=636160, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.544, cer_ctc=0.061, cer=0.061, loss=1.772, time=6.77 seconds, total_count=525, gpu_max_cached_mem_GB=42.223, [att_plot] time=38.3 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 14:46:03,127 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 14:46:03,157 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/26epoch.pth
[ALab02:0/2] 2023-07-22 14:46:03,157 (trainer:272) INFO: 36/50epoch started. Estimated time to finish: 1 day, 16 hours and 39 minutes
[ALab02:0/2] 2023-07-22 14:53:52,071 (trainer:721) INFO: 36epoch:train:1-908batch: iter_time=6.377e-04, forward_time=0.153, loss_ctc=1.020, loss=0.510, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.171e-04, train_time=2.065
[ALab02:0/2] 2023-07-22 15:01:32,929 (trainer:721) INFO: 36epoch:train:909-1816batch: iter_time=2.297e-04, forward_time=0.153, loss_ctc=0.986, loss=0.493, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.169e-04, train_time=2.030
[ALab02:0/2] 2023-07-22 15:09:14,397 (trainer:721) INFO: 36epoch:train:1817-2724batch: iter_time=2.423e-04, forward_time=0.153, loss_ctc=0.995, loss=0.498, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.168e-04, train_time=2.033
[ALab02:0/2] 2023-07-22 15:16:57,646 (trainer:721) INFO: 36epoch:train:2725-3632batch: iter_time=2.380e-04, forward_time=0.154, loss_ctc=0.992, loss=0.496, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.166e-04, train_time=2.041
[ALab02:0/2] 2023-07-22 15:24:36,341 (trainer:721) INFO: 36epoch:train:3633-4540batch: iter_time=2.366e-04, forward_time=0.152, loss_ctc=1.001, loss=0.500, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.165e-04, train_time=2.020
[ALab02:0/2] 2023-07-22 15:32:17,969 (trainer:721) INFO: 36epoch:train:4541-5448batch: iter_time=2.353e-04, forward_time=0.153, loss_ctc=1.047, loss=0.524, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.163e-04, train_time=2.033
[ALab02:0/2] 2023-07-22 15:40:00,837 (trainer:721) INFO: 36epoch:train:5449-6356batch: iter_time=2.442e-04, forward_time=0.154, loss_ctc=1.020, loss=0.510, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.162e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 15:47:40,371 (trainer:721) INFO: 36epoch:train:6357-7264batch: iter_time=2.359e-04, forward_time=0.153, loss_ctc=1.042, loss=0.521, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.160e-04, train_time=2.024
[ALab02:0/2] 2023-07-22 15:55:22,401 (trainer:721) INFO: 36epoch:train:7265-8172batch: iter_time=2.619e-04, forward_time=0.154, loss_ctc=1.017, loss=0.508, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.159e-04, train_time=2.035
[ALab02:0/2] 2023-07-22 16:03:02,491 (trainer:721) INFO: 36epoch:train:8173-9080batch: iter_time=2.495e-04, forward_time=0.153, loss_ctc=1.030, loss=0.515, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.157e-04, train_time=2.027
[ALab02:0/2] 2023-07-22 16:10:46,657 (trainer:721) INFO: 36epoch:train:9081-9988batch: iter_time=2.455e-04, forward_time=0.155, loss_ctc=1.020, loss=0.510, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.155e-04, train_time=2.045
[ALab02:0/2] 2023-07-22 16:18:31,079 (trainer:721) INFO: 36epoch:train:9989-10896batch: iter_time=2.487e-04, forward_time=0.155, loss_ctc=1.048, loss=0.524, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.154e-04, train_time=2.046
[ALab02:0/2] 2023-07-22 16:26:15,105 (trainer:721) INFO: 36epoch:train:10897-11804batch: iter_time=2.569e-04, forward_time=0.155, loss_ctc=1.027, loss=0.514, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.152e-04, train_time=2.044
[ALab02:0/2] 2023-07-22 16:33:57,624 (trainer:721) INFO: 36epoch:train:11805-12712batch: iter_time=2.466e-04, forward_time=0.154, loss_ctc=1.042, loss=0.521, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.151e-04, train_time=2.037
[ALab02:0/2] 2023-07-22 16:41:39,650 (trainer:721) INFO: 36epoch:train:12713-13620batch: iter_time=2.431e-04, forward_time=0.154, loss_ctc=1.015, loss=0.508, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.149e-04, train_time=2.035
[ALab02:0/2] 2023-07-22 16:49:24,283 (trainer:721) INFO: 36epoch:train:13621-14528batch: iter_time=2.476e-04, forward_time=0.155, loss_ctc=1.030, loss=0.515, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.148e-04, train_time=2.047
[ALab02:0/2] 2023-07-22 16:57:08,293 (trainer:721) INFO: 36epoch:train:14529-15436batch: iter_time=2.465e-04, forward_time=0.155, loss_ctc=1.004, loss=0.502, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.146e-04, train_time=2.044
[ALab02:0/2] 2023-07-22 17:04:53,184 (trainer:721) INFO: 36epoch:train:15437-16344batch: iter_time=2.458e-04, forward_time=0.155, loss_ctc=0.973, loss=0.486, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.145e-04, train_time=2.048
[ALab02:0/2] 2023-07-22 17:12:37,378 (trainer:721) INFO: 36epoch:train:16345-17252batch: iter_time=2.449e-04, forward_time=0.155, loss_ctc=1.014, loss=0.507, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.143e-04, train_time=2.045
[ALab02:0/2] 2023-07-22 17:20:19,698 (trainer:721) INFO: 36epoch:train:17253-18160batch: iter_time=2.455e-04, forward_time=0.154, loss_ctc=1.037, loss=0.518, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.142e-04, train_time=2.036
[ALab02:0/2] 2023-07-22 17:21:15,585 (trainer:338) INFO: 36epoch results: [train] iter_time=2.640e-04, forward_time=0.154, loss_ctc=1.018, loss=0.509, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.156e-04, train_time=2.039, time=2 hours, 34 minutes and 25.87 seconds, total_count=654336, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.897, cer_ctc=0.059, cer=0.059, loss=1.949, time=6.46 seconds, total_count=540, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.1 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 17:21:19,732 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 17:21:19,772 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/35epoch.pth
[ALab02:0/2] 2023-07-22 17:21:19,773 (trainer:272) INFO: 37/50epoch started. Estimated time to finish: 1 day, 13 hours and 54 minutes
[ALab02:0/2] 2023-07-22 17:29:13,641 (trainer:721) INFO: 37epoch:train:1-908batch: iter_time=7.479e-04, forward_time=0.154, loss_ctc=0.979, loss=0.490, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.140e-04, train_time=2.087
[ALab02:0/2] 2023-07-22 17:36:57,410 (trainer:721) INFO: 37epoch:train:909-1816batch: iter_time=2.539e-04, forward_time=0.155, loss_ctc=0.976, loss=0.488, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.139e-04, train_time=2.043
[ALab02:0/2] 2023-07-22 17:44:41,431 (trainer:721) INFO: 37epoch:train:1817-2724batch: iter_time=2.564e-04, forward_time=0.155, loss_ctc=0.985, loss=0.493, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.138e-04, train_time=2.044
[ALab02:0/2] 2023-07-22 17:52:24,379 (trainer:721) INFO: 37epoch:train:2725-3632batch: iter_time=2.531e-04, forward_time=0.154, loss_ctc=1.030, loss=0.515, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.136e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 18:00:07,795 (trainer:721) INFO: 37epoch:train:3633-4540batch: iter_time=2.574e-04, forward_time=0.155, loss_ctc=1.004, loss=0.502, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.135e-04, train_time=2.041
[ALab02:0/2] 2023-07-22 18:07:50,897 (trainer:721) INFO: 37epoch:train:4541-5448batch: iter_time=2.533e-04, forward_time=0.154, loss_ctc=0.987, loss=0.494, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.133e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 18:15:33,005 (trainer:721) INFO: 37epoch:train:5449-6356batch: iter_time=2.489e-04, forward_time=0.154, loss_ctc=1.021, loss=0.510, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.132e-04, train_time=2.036
[ALab02:0/2] 2023-07-22 18:23:15,374 (trainer:721) INFO: 37epoch:train:6357-7264batch: iter_time=2.502e-04, forward_time=0.154, loss_ctc=0.997, loss=0.498, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.130e-04, train_time=2.037
[ALab02:0/2] 2023-07-22 18:31:00,230 (trainer:721) INFO: 37epoch:train:7265-8172batch: iter_time=2.468e-04, forward_time=0.155, loss_ctc=0.995, loss=0.498, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.129e-04, train_time=2.048
[ALab02:0/2] 2023-07-22 18:38:40,956 (trainer:721) INFO: 37epoch:train:8173-9080batch: iter_time=2.442e-04, forward_time=0.153, loss_ctc=0.973, loss=0.486, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.127e-04, train_time=2.029
[ALab02:0/2] 2023-07-22 18:46:22,077 (trainer:721) INFO: 37epoch:train:9081-9988batch: iter_time=2.419e-04, forward_time=0.154, loss_ctc=0.979, loss=0.489, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.126e-04, train_time=2.031
[ALab02:0/2] 2023-07-22 18:54:06,299 (trainer:721) INFO: 37epoch:train:9989-10896batch: iter_time=2.449e-04, forward_time=0.155, loss_ctc=0.974, loss=0.487, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.124e-04, train_time=2.045
[ALab02:0/2] 2023-07-22 19:01:49,465 (trainer:721) INFO: 37epoch:train:10897-11804batch: iter_time=2.304e-04, forward_time=0.154, loss_ctc=1.040, loss=0.520, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.123e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 19:09:31,035 (trainer:721) INFO: 37epoch:train:11805-12712batch: iter_time=2.515e-04, forward_time=0.154, loss_ctc=1.002, loss=0.501, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.121e-04, train_time=2.033
[ALab02:0/2] 2023-07-22 19:17:12,243 (trainer:721) INFO: 37epoch:train:12713-13620batch: iter_time=2.478e-04, forward_time=0.154, loss_ctc=1.018, loss=0.509, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.120e-04, train_time=2.032
[ALab02:0/2] 2023-07-22 19:24:54,459 (trainer:721) INFO: 37epoch:train:13621-14528batch: iter_time=2.491e-04, forward_time=0.154, loss_ctc=1.014, loss=0.507, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.119e-04, train_time=2.036
[ALab02:0/2] 2023-07-22 19:32:38,012 (trainer:721) INFO: 37epoch:train:14529-15436batch: iter_time=2.597e-04, forward_time=0.155, loss_ctc=1.013, loss=0.506, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.117e-04, train_time=2.042
[ALab02:0/2] 2023-07-22 19:40:21,378 (trainer:721) INFO: 37epoch:train:15437-16344batch: iter_time=2.474e-04, forward_time=0.155, loss_ctc=0.990, loss=0.495, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.116e-04, train_time=2.041
[ALab02:0/2] 2023-07-22 19:48:04,529 (trainer:721) INFO: 37epoch:train:16345-17252batch: iter_time=2.462e-04, forward_time=0.154, loss_ctc=1.006, loss=0.503, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.114e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 19:55:45,238 (trainer:721) INFO: 37epoch:train:17253-18160batch: iter_time=2.478e-04, forward_time=0.154, loss_ctc=1.000, loss=0.500, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.113e-04, train_time=2.029
[ALab02:0/2] 2023-07-22 19:56:40,843 (trainer:338) INFO: 37epoch results: [train] iter_time=2.739e-04, forward_time=0.154, loss_ctc=0.999, loss=0.500, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.127e-04, train_time=2.041, time=2 hours, 34 minutes and 34.79 seconds, total_count=672512, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.798, cer_ctc=0.059, cer=0.059, loss=1.899, time=6.19 seconds, total_count=555, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.09 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 19:56:44,720 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-22 19:56:44,727 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/21epoch.pth
[ALab02:0/2] 2023-07-22 19:56:44,727 (trainer:272) INFO: 38/50epoch started. Estimated time to finish: 1 day, 11 hours and 9 minutes
[ALab02:0/2] 2023-07-22 20:04:35,625 (trainer:721) INFO: 38epoch:train:1-908batch: iter_time=6.957e-04, forward_time=0.153, loss_ctc=0.955, loss=0.478, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.111e-04, train_time=2.074
[ALab02:0/2] 2023-07-22 20:12:19,981 (trainer:721) INFO: 38epoch:train:909-1816batch: iter_time=2.762e-04, forward_time=0.155, loss_ctc=0.959, loss=0.479, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.110e-04, train_time=2.045
[ALab02:0/2] 2023-07-22 20:20:02,122 (trainer:721) INFO: 38epoch:train:1817-2724batch: iter_time=2.507e-04, forward_time=0.154, loss_ctc=0.984, loss=0.492, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.109e-04, train_time=2.036
[ALab02:0/2] 2023-07-22 20:27:45,733 (trainer:721) INFO: 38epoch:train:2725-3632batch: iter_time=2.501e-04, forward_time=0.155, loss_ctc=0.959, loss=0.479, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.107e-04, train_time=2.042
[ALab02:0/2] 2023-07-22 20:35:28,706 (trainer:721) INFO: 38epoch:train:3633-4540batch: iter_time=2.495e-04, forward_time=0.155, loss_ctc=0.989, loss=0.494, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.106e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 20:43:09,386 (trainer:721) INFO: 38epoch:train:4541-5448batch: iter_time=2.442e-04, forward_time=0.153, loss_ctc=0.999, loss=0.499, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.104e-04, train_time=2.029
[ALab02:0/2] 2023-07-22 20:50:49,116 (trainer:721) INFO: 38epoch:train:5449-6356batch: iter_time=2.483e-04, forward_time=0.153, loss_ctc=0.966, loss=0.483, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.103e-04, train_time=2.025
[ALab02:0/2] 2023-07-22 20:58:30,955 (trainer:721) INFO: 38epoch:train:6357-7264batch: iter_time=2.487e-04, forward_time=0.154, loss_ctc=0.957, loss=0.478, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.101e-04, train_time=2.034
[ALab02:0/2] 2023-07-22 21:06:12,173 (trainer:721) INFO: 38epoch:train:7265-8172batch: iter_time=2.734e-04, forward_time=0.153, loss_ctc=0.950, loss=0.475, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.100e-04, train_time=2.032
[ALab02:0/2] 2023-07-22 21:13:53,171 (trainer:721) INFO: 38epoch:train:8173-9080batch: iter_time=2.572e-04, forward_time=0.154, loss_ctc=0.976, loss=0.488, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.099e-04, train_time=2.031
[ALab02:0/2] 2023-07-22 21:21:33,774 (trainer:721) INFO: 38epoch:train:9081-9988batch: iter_time=2.569e-04, forward_time=0.154, loss_ctc=0.976, loss=0.488, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.097e-04, train_time=2.029
[ALab02:0/2] 2023-07-22 21:29:15,968 (trainer:721) INFO: 38epoch:train:9989-10896batch: iter_time=2.485e-04, forward_time=0.154, loss_ctc=0.951, loss=0.476, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.096e-04, train_time=2.036
[ALab02:0/2] 2023-07-22 21:36:57,825 (trainer:721) INFO: 38epoch:train:10897-11804batch: iter_time=2.424e-04, forward_time=0.154, loss_ctc=1.008, loss=0.504, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.094e-04, train_time=2.034
[ALab02:0/2] 2023-07-22 21:44:40,441 (trainer:721) INFO: 38epoch:train:11805-12712batch: iter_time=2.532e-04, forward_time=0.154, loss_ctc=0.984, loss=0.492, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.093e-04, train_time=2.038
[ALab02:0/2] 2023-07-22 21:52:23,832 (trainer:721) INFO: 38epoch:train:12713-13620batch: iter_time=2.418e-04, forward_time=0.155, loss_ctc=0.969, loss=0.485, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.092e-04, train_time=2.041
[ALab02:0/2] 2023-07-22 22:00:07,653 (trainer:721) INFO: 38epoch:train:13621-14528batch: iter_time=2.445e-04, forward_time=0.155, loss_ctc=0.985, loss=0.493, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.090e-04, train_time=2.043
[ALab02:0/2] 2023-07-22 22:07:50,875 (trainer:721) INFO: 38epoch:train:14529-15436batch: iter_time=2.473e-04, forward_time=0.154, loss_ctc=0.957, loss=0.478, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.089e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 22:15:34,937 (trainer:721) INFO: 38epoch:train:15437-16344batch: iter_time=2.566e-04, forward_time=0.155, loss_ctc=0.971, loss=0.486, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.088e-04, train_time=2.044
[ALab02:0/2] 2023-07-22 22:23:18,004 (trainer:721) INFO: 38epoch:train:16345-17252batch: iter_time=2.344e-04, forward_time=0.154, loss_ctc=1.033, loss=0.517, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.086e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 22:31:02,041 (trainer:721) INFO: 38epoch:train:17253-18160batch: iter_time=2.495e-04, forward_time=0.155, loss_ctc=0.975, loss=0.488, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.085e-04, train_time=2.044
[ALab02:0/2] 2023-07-22 22:31:57,293 (trainer:338) INFO: 38epoch results: [train] iter_time=2.735e-04, forward_time=0.154, loss_ctc=0.976, loss=0.488, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.098e-04, train_time=2.039, time=2 hours, 34 minutes and 26.23 seconds, total_count=690688, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.725, cer_ctc=0.058, cer=0.058, loss=1.862, time=6.43 seconds, total_count=570, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.91 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-22 22:32:01,434 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-22 22:32:01,440 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/24epoch.pth
[ALab02:0/2] 2023-07-22 22:32:01,440 (trainer:272) INFO: 39/50epoch started. Estimated time to finish: 1 day, 8 hours and 24 minutes
[ALab02:0/2] 2023-07-22 22:39:54,247 (trainer:721) INFO: 39epoch:train:1-908batch: iter_time=6.836e-04, forward_time=0.154, loss_ctc=0.939, loss=0.469, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.083e-04, train_time=2.083
[ALab02:0/2] 2023-07-22 22:47:37,449 (trainer:721) INFO: 39epoch:train:909-1816batch: iter_time=2.468e-04, forward_time=0.154, loss_ctc=0.943, loss=0.471, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.082e-04, train_time=2.040
[ALab02:0/2] 2023-07-22 22:55:20,389 (trainer:721) INFO: 39epoch:train:1817-2724batch: iter_time=2.603e-04, forward_time=0.154, loss_ctc=0.942, loss=0.471, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.081e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 23:03:03,022 (trainer:721) INFO: 39epoch:train:2725-3632batch: iter_time=2.574e-04, forward_time=0.154, loss_ctc=1.006, loss=0.503, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.079e-04, train_time=2.038
[ALab02:0/2] 2023-07-22 23:10:43,928 (trainer:721) INFO: 39epoch:train:3633-4540batch: iter_time=2.515e-04, forward_time=0.154, loss_ctc=0.992, loss=0.496, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.078e-04, train_time=2.030
[ALab02:0/2] 2023-07-22 23:18:29,653 (trainer:721) INFO: 39epoch:train:4541-5448batch: iter_time=2.531e-04, forward_time=0.155, loss_ctc=0.940, loss=0.470, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.077e-04, train_time=2.051
[ALab02:0/2] 2023-07-22 23:26:13,284 (trainer:721) INFO: 39epoch:train:5449-6356batch: iter_time=2.472e-04, forward_time=0.154, loss_ctc=0.968, loss=0.484, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.075e-04, train_time=2.042
[ALab02:0/2] 2023-07-22 23:33:57,537 (trainer:721) INFO: 39epoch:train:6357-7264batch: iter_time=2.531e-04, forward_time=0.155, loss_ctc=0.964, loss=0.482, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.074e-04, train_time=2.045
[ALab02:0/2] 2023-07-22 23:41:40,424 (trainer:721) INFO: 39epoch:train:7265-8172batch: iter_time=2.514e-04, forward_time=0.155, loss_ctc=0.971, loss=0.485, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.073e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 23:49:23,246 (trainer:721) INFO: 39epoch:train:8173-9080batch: iter_time=2.533e-04, forward_time=0.155, loss_ctc=0.959, loss=0.479, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.071e-04, train_time=2.039
[ALab02:0/2] 2023-07-22 23:57:07,954 (trainer:721) INFO: 39epoch:train:9081-9988batch: iter_time=2.511e-04, forward_time=0.156, loss_ctc=0.985, loss=0.492, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.070e-04, train_time=2.047
[ALab02:0/2] 2023-07-23 00:04:50,334 (trainer:721) INFO: 39epoch:train:9989-10896batch: iter_time=2.457e-04, forward_time=0.155, loss_ctc=0.969, loss=0.484, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.069e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 00:12:35,363 (trainer:721) INFO: 39epoch:train:10897-11804batch: iter_time=2.544e-04, forward_time=0.156, loss_ctc=0.948, loss=0.474, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.067e-04, train_time=2.048
[ALab02:0/2] 2023-07-23 00:20:20,157 (trainer:721) INFO: 39epoch:train:11805-12712batch: iter_time=2.519e-04, forward_time=0.156, loss_ctc=0.955, loss=0.478, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.066e-04, train_time=2.047
[ALab02:0/2] 2023-07-23 00:28:02,363 (trainer:721) INFO: 39epoch:train:12713-13620batch: iter_time=2.565e-04, forward_time=0.155, loss_ctc=0.956, loss=0.478, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.065e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 00:35:45,248 (trainer:721) INFO: 39epoch:train:13621-14528batch: iter_time=2.397e-04, forward_time=0.154, loss_ctc=0.967, loss=0.484, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.063e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 00:43:27,063 (trainer:721) INFO: 39epoch:train:14529-15436batch: iter_time=2.518e-04, forward_time=0.154, loss_ctc=0.989, loss=0.495, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.062e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 00:51:10,026 (trainer:721) INFO: 39epoch:train:15437-16344batch: iter_time=2.541e-04, forward_time=0.155, loss_ctc=0.961, loss=0.481, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.061e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 00:58:52,481 (trainer:721) INFO: 39epoch:train:16345-17252batch: iter_time=2.604e-04, forward_time=0.154, loss_ctc=0.974, loss=0.487, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.059e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 01:06:34,863 (trainer:721) INFO: 39epoch:train:17253-18160batch: iter_time=2.636e-04, forward_time=0.155, loss_ctc=0.966, loss=0.483, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.058e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 01:07:33,623 (trainer:338) INFO: 39epoch results: [train] iter_time=2.743e-04, forward_time=0.155, loss_ctc=0.965, loss=0.482, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.071e-04, train_time=2.042, time=2 hours, 34 minutes and 42.43 seconds, total_count=708864, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.707, cer_ctc=0.060, cer=0.060, loss=1.853, time=7.89 seconds, total_count=585, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.86 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 01:07:37,978 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 01:07:37,979 (trainer:272) INFO: 40/50epoch started. Estimated time to finish: 1 day, 5 hours and 41 minutes
[ALab02:0/2] 2023-07-23 01:15:29,469 (trainer:721) INFO: 40epoch:train:1-908batch: iter_time=7.924e-04, forward_time=0.155, loss_ctc=0.953, loss=0.477, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.057e-04, train_time=2.077
[ALab02:0/2] 2023-07-23 01:23:11,080 (trainer:721) INFO: 40epoch:train:909-1816batch: iter_time=2.547e-04, forward_time=0.154, loss_ctc=0.940, loss=0.470, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.055e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 01:30:52,819 (trainer:721) INFO: 40epoch:train:1817-2724batch: iter_time=2.499e-04, forward_time=0.154, loss_ctc=0.916, loss=0.458, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.054e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 01:38:34,460 (trainer:721) INFO: 40epoch:train:2725-3632batch: iter_time=2.494e-04, forward_time=0.154, loss_ctc=0.916, loss=0.458, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.053e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 01:46:16,064 (trainer:721) INFO: 40epoch:train:3633-4540batch: iter_time=2.416e-04, forward_time=0.154, loss_ctc=1.009, loss=0.505, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.051e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 01:53:58,381 (trainer:721) INFO: 40epoch:train:4541-5448batch: iter_time=2.491e-04, forward_time=0.154, loss_ctc=0.975, loss=0.488, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.050e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 02:01:40,137 (trainer:721) INFO: 40epoch:train:5449-6356batch: iter_time=2.435e-04, forward_time=0.154, loss_ctc=0.986, loss=0.493, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.049e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 02:09:24,233 (trainer:721) INFO: 40epoch:train:6357-7264batch: iter_time=2.488e-04, forward_time=0.155, loss_ctc=0.948, loss=0.474, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.047e-04, train_time=2.044
[ALab02:0/2] 2023-07-23 02:17:07,960 (trainer:721) INFO: 40epoch:train:7265-8172batch: iter_time=2.576e-04, forward_time=0.154, loss_ctc=0.971, loss=0.485, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.046e-04, train_time=2.043
[ALab02:0/2] 2023-07-23 02:24:50,694 (trainer:721) INFO: 40epoch:train:8173-9080batch: iter_time=2.537e-04, forward_time=0.154, loss_ctc=0.937, loss=0.468, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.045e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 02:32:32,114 (trainer:721) INFO: 40epoch:train:9081-9988batch: iter_time=2.517e-04, forward_time=0.154, loss_ctc=0.967, loss=0.484, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.044e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 02:40:15,660 (trainer:721) INFO: 40epoch:train:9989-10896batch: iter_time=2.525e-04, forward_time=0.154, loss_ctc=0.957, loss=0.478, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.042e-04, train_time=2.042
[ALab02:0/2] 2023-07-23 02:47:57,792 (trainer:721) INFO: 40epoch:train:10897-11804batch: iter_time=2.508e-04, forward_time=0.154, loss_ctc=0.931, loss=0.466, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.041e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 02:55:42,470 (trainer:721) INFO: 40epoch:train:11805-12712batch: iter_time=2.560e-04, forward_time=0.155, loss_ctc=0.949, loss=0.474, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.040e-04, train_time=2.047
[ALab02:0/2] 2023-07-23 03:03:27,324 (trainer:721) INFO: 40epoch:train:12713-13620batch: iter_time=2.525e-04, forward_time=0.155, loss_ctc=0.925, loss=0.462, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.038e-04, train_time=2.048
[ALab02:0/2] 2023-07-23 03:11:12,774 (trainer:721) INFO: 40epoch:train:13621-14528batch: iter_time=2.412e-04, forward_time=0.155, loss_ctc=0.937, loss=0.468, backward_time=0.228, optim_step_time=0.034, optim0_lr0=2.037e-04, train_time=2.050
[ALab02:0/2] 2023-07-23 03:18:57,936 (trainer:721) INFO: 40epoch:train:14529-15436batch: iter_time=2.588e-04, forward_time=0.155, loss_ctc=0.944, loss=0.472, backward_time=0.228, optim_step_time=0.034, optim0_lr0=2.036e-04, train_time=2.049
[ALab02:0/2] 2023-07-23 03:26:43,829 (trainer:721) INFO: 40epoch:train:15437-16344batch: iter_time=2.530e-04, forward_time=0.155, loss_ctc=0.959, loss=0.480, backward_time=0.228, optim_step_time=0.034, optim0_lr0=2.035e-04, train_time=2.052
[ALab02:0/2] 2023-07-23 03:34:27,883 (trainer:721) INFO: 40epoch:train:16345-17252batch: iter_time=2.421e-04, forward_time=0.155, loss_ctc=0.949, loss=0.475, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.033e-04, train_time=2.044
[ALab02:0/2] 2023-07-23 03:42:10,926 (trainer:721) INFO: 40epoch:train:17253-18160batch: iter_time=2.416e-04, forward_time=0.154, loss_ctc=0.950, loss=0.475, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.032e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 03:43:08,943 (trainer:338) INFO: 40epoch results: [train] iter_time=2.770e-04, forward_time=0.154, loss_ctc=0.951, loss=0.476, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.044e-04, train_time=2.042, time=2 hours, 34 minutes and 42.36 seconds, total_count=727040, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.767, cer_ctc=0.059, cer=0.059, loss=1.883, time=8.85 seconds, total_count=600, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.75 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 03:43:12,905 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 03:43:12,907 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/27epoch.pth, exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/39epoch.pth
[ALab02:0/2] 2023-07-23 03:43:12,908 (trainer:272) INFO: 41/50epoch started. Estimated time to finish: 1 day, 2 hours and 57 minutes
[ALab02:0/2] 2023-07-23 03:51:07,011 (trainer:721) INFO: 41epoch:train:1-908batch: iter_time=6.562e-04, forward_time=0.154, loss_ctc=0.912, loss=0.456, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.031e-04, train_time=2.088
[ALab02:0/2] 2023-07-23 03:58:48,526 (trainer:721) INFO: 41epoch:train:909-1816batch: iter_time=2.630e-04, forward_time=0.154, loss_ctc=0.935, loss=0.468, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.029e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 04:06:30,869 (trainer:721) INFO: 41epoch:train:1817-2724batch: iter_time=2.476e-04, forward_time=0.154, loss_ctc=0.896, loss=0.448, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.028e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 04:14:15,008 (trainer:721) INFO: 41epoch:train:2725-3632batch: iter_time=2.529e-04, forward_time=0.155, loss_ctc=0.974, loss=0.487, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.027e-04, train_time=2.044
[ALab02:0/2] 2023-07-23 04:21:56,195 (trainer:721) INFO: 41epoch:train:3633-4540batch: iter_time=2.564e-04, forward_time=0.154, loss_ctc=0.923, loss=0.461, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.026e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 04:29:39,001 (trainer:721) INFO: 41epoch:train:4541-5448batch: iter_time=2.521e-04, forward_time=0.154, loss_ctc=0.967, loss=0.484, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.024e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 04:37:24,266 (trainer:721) INFO: 41epoch:train:5449-6356batch: iter_time=2.499e-04, forward_time=0.155, loss_ctc=0.923, loss=0.461, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.023e-04, train_time=2.049
[ALab02:0/2] 2023-07-23 04:45:05,339 (trainer:721) INFO: 41epoch:train:6357-7264batch: iter_time=2.517e-04, forward_time=0.153, loss_ctc=0.941, loss=0.470, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.022e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 04:52:45,955 (trainer:721) INFO: 41epoch:train:7265-8172batch: iter_time=2.462e-04, forward_time=0.153, loss_ctc=0.941, loss=0.471, backward_time=0.225, optim_step_time=0.033, optim0_lr0=2.021e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 05:00:28,279 (trainer:721) INFO: 41epoch:train:8173-9080batch: iter_time=2.493e-04, forward_time=0.154, loss_ctc=0.933, loss=0.466, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.019e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 05:08:12,568 (trainer:721) INFO: 41epoch:train:9081-9988batch: iter_time=2.530e-04, forward_time=0.155, loss_ctc=0.937, loss=0.469, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.018e-04, train_time=2.045
[ALab02:0/2] 2023-07-23 05:15:55,837 (trainer:721) INFO: 41epoch:train:9989-10896batch: iter_time=2.456e-04, forward_time=0.155, loss_ctc=0.914, loss=0.457, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.017e-04, train_time=2.041
[ALab02:0/2] 2023-07-23 05:23:39,247 (trainer:721) INFO: 41epoch:train:10897-11804batch: iter_time=2.446e-04, forward_time=0.154, loss_ctc=0.929, loss=0.464, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.016e-04, train_time=2.041
[ALab02:0/2] 2023-07-23 05:31:25,528 (trainer:721) INFO: 41epoch:train:11805-12712batch: iter_time=2.524e-04, forward_time=0.156, loss_ctc=0.936, loss=0.468, backward_time=0.228, optim_step_time=0.034, optim0_lr0=2.014e-04, train_time=2.054
[ALab02:0/2] 2023-07-23 05:39:08,335 (trainer:721) INFO: 41epoch:train:12713-13620batch: iter_time=2.479e-04, forward_time=0.154, loss_ctc=0.912, loss=0.456, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.013e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 05:46:52,155 (trainer:721) INFO: 41epoch:train:13621-14528batch: iter_time=2.550e-04, forward_time=0.155, loss_ctc=0.927, loss=0.463, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.012e-04, train_time=2.043
[ALab02:0/2] 2023-07-23 05:54:34,663 (trainer:721) INFO: 41epoch:train:14529-15436batch: iter_time=2.563e-04, forward_time=0.154, loss_ctc=0.943, loss=0.471, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.011e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 06:02:19,130 (trainer:721) INFO: 41epoch:train:15437-16344batch: iter_time=2.610e-04, forward_time=0.155, loss_ctc=0.929, loss=0.464, backward_time=0.227, optim_step_time=0.033, optim0_lr0=2.009e-04, train_time=2.046
[ALab02:0/2] 2023-07-23 06:10:01,743 (trainer:721) INFO: 41epoch:train:16345-17252batch: iter_time=2.521e-04, forward_time=0.154, loss_ctc=0.948, loss=0.474, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.008e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 06:17:44,807 (trainer:721) INFO: 41epoch:train:17253-18160batch: iter_time=2.474e-04, forward_time=0.154, loss_ctc=0.936, loss=0.468, backward_time=0.226, optim_step_time=0.033, optim0_lr0=2.007e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 06:18:42,394 (trainer:338) INFO: 41epoch results: [train] iter_time=2.720e-04, forward_time=0.154, loss_ctc=0.933, loss=0.466, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.019e-04, train_time=2.042, time=2 hours, 34 minutes and 41.39 seconds, total_count=745216, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.769, cer_ctc=0.060, cer=0.060, loss=1.884, time=6.81 seconds, total_count=615, gpu_max_cached_mem_GB=42.223, [att_plot] time=41.28 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 06:18:46,286 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 06:18:46,288 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/31epoch.pth
[ALab02:0/2] 2023-07-23 06:18:46,288 (trainer:272) INFO: 42/50epoch started. Estimated time to finish: 1 day, 14 minutes and 26.16 seconds
[ALab02:0/2] 2023-07-23 06:26:37,432 (trainer:721) INFO: 42epoch:train:1-908batch: iter_time=6.626e-04, forward_time=0.153, loss_ctc=0.926, loss=0.463, backward_time=0.225, optim_step_time=0.034, optim0_lr0=2.006e-04, train_time=2.075
[ALab02:0/2] 2023-07-23 06:34:20,527 (trainer:721) INFO: 42epoch:train:909-1816batch: iter_time=2.564e-04, forward_time=0.154, loss_ctc=0.926, loss=0.463, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.005e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 06:42:04,713 (trainer:721) INFO: 42epoch:train:1817-2724batch: iter_time=2.539e-04, forward_time=0.155, loss_ctc=0.916, loss=0.458, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.003e-04, train_time=2.045
[ALab02:0/2] 2023-07-23 06:49:48,381 (trainer:721) INFO: 42epoch:train:2725-3632batch: iter_time=2.513e-04, forward_time=0.154, loss_ctc=0.922, loss=0.461, backward_time=0.227, optim_step_time=0.034, optim0_lr0=2.002e-04, train_time=2.042
[ALab02:0/2] 2023-07-23 06:57:30,676 (trainer:721) INFO: 42epoch:train:3633-4540batch: iter_time=2.508e-04, forward_time=0.154, loss_ctc=0.898, loss=0.449, backward_time=0.226, optim_step_time=0.035, optim0_lr0=2.001e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 07:05:13,133 (trainer:721) INFO: 42epoch:train:4541-5448batch: iter_time=2.580e-04, forward_time=0.154, loss_ctc=0.905, loss=0.452, backward_time=0.226, optim_step_time=0.034, optim0_lr0=2.000e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 07:12:55,100 (trainer:721) INFO: 42epoch:train:5449-6356batch: iter_time=2.484e-04, forward_time=0.153, loss_ctc=0.895, loss=0.447, backward_time=0.225, optim_step_time=0.035, optim0_lr0=1.999e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 07:20:36,177 (trainer:721) INFO: 42epoch:train:6357-7264batch: iter_time=2.460e-04, forward_time=0.153, loss_ctc=0.898, loss=0.449, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.997e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 07:28:18,695 (trainer:721) INFO: 42epoch:train:7265-8172batch: iter_time=2.371e-04, forward_time=0.154, loss_ctc=0.935, loss=0.467, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.996e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 07:36:03,051 (trainer:721) INFO: 42epoch:train:8173-9080batch: iter_time=2.693e-04, forward_time=0.156, loss_ctc=0.909, loss=0.455, backward_time=0.227, optim_step_time=0.035, optim0_lr0=1.995e-04, train_time=2.045
[ALab02:0/2] 2023-07-23 07:43:46,113 (trainer:721) INFO: 42epoch:train:9081-9988batch: iter_time=2.602e-04, forward_time=0.154, loss_ctc=0.926, loss=0.463, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.994e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 07:51:32,139 (trainer:721) INFO: 42epoch:train:9989-10896batch: iter_time=2.695e-04, forward_time=0.156, loss_ctc=0.880, loss=0.440, backward_time=0.227, optim_step_time=0.035, optim0_lr0=1.992e-04, train_time=2.053
[ALab02:0/2] 2023-07-23 07:59:15,478 (trainer:721) INFO: 42epoch:train:10897-11804batch: iter_time=2.735e-04, forward_time=0.155, loss_ctc=0.901, loss=0.450, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.991e-04, train_time=2.041
[ALab02:0/2] 2023-07-23 08:06:56,130 (trainer:721) INFO: 42epoch:train:11805-12712batch: iter_time=2.627e-04, forward_time=0.153, loss_ctc=0.928, loss=0.464, backward_time=0.225, optim_step_time=0.035, optim0_lr0=1.990e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 08:14:40,634 (trainer:721) INFO: 42epoch:train:12713-13620batch: iter_time=2.543e-04, forward_time=0.155, loss_ctc=0.906, loss=0.453, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.989e-04, train_time=2.046
[ALab02:0/2] 2023-07-23 08:22:23,821 (trainer:721) INFO: 42epoch:train:13621-14528batch: iter_time=2.607e-04, forward_time=0.155, loss_ctc=0.943, loss=0.471, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.988e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 08:30:05,708 (trainer:721) INFO: 42epoch:train:14529-15436batch: iter_time=2.500e-04, forward_time=0.154, loss_ctc=0.917, loss=0.458, backward_time=0.225, optim_step_time=0.035, optim0_lr0=1.987e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 08:37:50,062 (trainer:721) INFO: 42epoch:train:15437-16344batch: iter_time=2.506e-04, forward_time=0.155, loss_ctc=0.917, loss=0.458, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.985e-04, train_time=2.045
[ALab02:0/2] 2023-07-23 08:45:32,807 (trainer:721) INFO: 42epoch:train:16345-17252batch: iter_time=2.425e-04, forward_time=0.154, loss_ctc=0.946, loss=0.473, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.984e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 08:53:15,194 (trainer:721) INFO: 42epoch:train:17253-18160batch: iter_time=2.407e-04, forward_time=0.154, loss_ctc=0.915, loss=0.458, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.983e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 08:54:11,443 (trainer:338) INFO: 42epoch results: [train] iter_time=2.748e-04, forward_time=0.154, loss_ctc=0.915, loss=0.458, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.994e-04, train_time=2.041, time=2 hours, 34 minutes and 37.95 seconds, total_count=763392, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.782, cer_ctc=0.059, cer=0.059, loss=1.891, time=7.9 seconds, total_count=630, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.3 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 08:54:15,454 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 08:54:15,458 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/41epoch.pth
[ALab02:0/2] 2023-07-23 08:54:15,458 (trainer:272) INFO: 43/50epoch started. Estimated time to finish: 21 hours, 31 minutes and 40 seconds
[ALab02:0/2] 2023-07-23 09:02:07,350 (trainer:721) INFO: 43epoch:train:1-908batch: iter_time=8.034e-04, forward_time=0.153, loss_ctc=0.891, loss=0.446, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.982e-04, train_time=2.078
[ALab02:0/2] 2023-07-23 09:09:50,496 (trainer:721) INFO: 43epoch:train:909-1816batch: iter_time=2.240e-04, forward_time=0.154, loss_ctc=0.879, loss=0.439, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.981e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 09:17:28,631 (trainer:721) INFO: 43epoch:train:1817-2724batch: iter_time=2.256e-04, forward_time=0.152, loss_ctc=0.889, loss=0.445, backward_time=0.225, optim_step_time=0.036, optim0_lr0=1.979e-04, train_time=2.018
[ALab02:0/2] 2023-07-23 09:25:11,030 (trainer:721) INFO: 43epoch:train:2725-3632batch: iter_time=2.406e-04, forward_time=0.153, loss_ctc=0.902, loss=0.451, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.978e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 09:32:52,013 (trainer:721) INFO: 43epoch:train:3633-4540batch: iter_time=2.297e-04, forward_time=0.153, loss_ctc=0.923, loss=0.461, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.977e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 09:40:33,372 (trainer:721) INFO: 43epoch:train:4541-5448batch: iter_time=2.260e-04, forward_time=0.153, loss_ctc=0.889, loss=0.445, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.976e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 09:48:14,177 (trainer:721) INFO: 43epoch:train:5449-6356batch: iter_time=2.211e-04, forward_time=0.153, loss_ctc=0.923, loss=0.461, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.975e-04, train_time=2.030
[ALab02:0/2] 2023-07-23 09:55:55,070 (trainer:721) INFO: 43epoch:train:6357-7264batch: iter_time=2.352e-04, forward_time=0.153, loss_ctc=0.914, loss=0.457, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.974e-04, train_time=2.030
[ALab02:0/2] 2023-07-23 10:03:35,612 (trainer:721) INFO: 43epoch:train:7265-8172batch: iter_time=2.261e-04, forward_time=0.153, loss_ctc=0.913, loss=0.457, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.972e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 10:11:15,474 (trainer:721) INFO: 43epoch:train:8173-9080batch: iter_time=2.279e-04, forward_time=0.153, loss_ctc=0.900, loss=0.450, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.971e-04, train_time=2.026
[ALab02:0/2] 2023-07-23 10:18:57,126 (trainer:721) INFO: 43epoch:train:9081-9988batch: iter_time=2.210e-04, forward_time=0.153, loss_ctc=0.922, loss=0.461, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.970e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 10:26:38,199 (trainer:721) INFO: 43epoch:train:9989-10896batch: iter_time=2.186e-04, forward_time=0.153, loss_ctc=0.954, loss=0.477, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.969e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 10:34:17,611 (trainer:721) INFO: 43epoch:train:10897-11804batch: iter_time=2.311e-04, forward_time=0.153, loss_ctc=0.902, loss=0.451, backward_time=0.225, optim_step_time=0.035, optim0_lr0=1.968e-04, train_time=2.024
[ALab02:0/2] 2023-07-23 10:42:01,857 (trainer:721) INFO: 43epoch:train:11805-12712batch: iter_time=2.251e-04, forward_time=0.154, loss_ctc=0.908, loss=0.454, backward_time=0.228, optim_step_time=0.036, optim0_lr0=1.967e-04, train_time=2.045
[ALab02:0/2] 2023-07-23 10:49:42,484 (trainer:721) INFO: 43epoch:train:12713-13620batch: iter_time=2.224e-04, forward_time=0.153, loss_ctc=0.916, loss=0.458, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.965e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 10:57:23,740 (trainer:721) INFO: 43epoch:train:13621-14528batch: iter_time=2.270e-04, forward_time=0.153, loss_ctc=0.879, loss=0.440, backward_time=0.226, optim_step_time=0.037, optim0_lr0=1.964e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 11:05:06,108 (trainer:721) INFO: 43epoch:train:14529-15436batch: iter_time=2.175e-04, forward_time=0.154, loss_ctc=0.883, loss=0.441, backward_time=0.228, optim_step_time=0.036, optim0_lr0=1.963e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 11:12:45,949 (trainer:721) INFO: 43epoch:train:15437-16344batch: iter_time=2.168e-04, forward_time=0.153, loss_ctc=0.901, loss=0.451, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.962e-04, train_time=2.025
[ALab02:0/2] 2023-07-23 11:20:26,521 (trainer:721) INFO: 43epoch:train:16345-17252batch: iter_time=2.206e-04, forward_time=0.153, loss_ctc=0.891, loss=0.445, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.961e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 11:28:06,720 (trainer:721) INFO: 43epoch:train:17253-18160batch: iter_time=2.186e-04, forward_time=0.153, loss_ctc=0.898, loss=0.449, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.960e-04, train_time=2.027
[ALab02:0/2] 2023-07-23 11:29:08,668 (trainer:338) INFO: 43epoch results: [train] iter_time=2.539e-04, forward_time=0.153, loss_ctc=0.904, loss=0.452, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.971e-04, train_time=2.033, time=2 hours, 34 minutes and 1.32 seconds, total_count=781568, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.665, cer_ctc=0.059, cer=0.059, loss=1.833, time=8.78 seconds, total_count=645, gpu_max_cached_mem_GB=42.223, [att_plot] time=43.11 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 11:29:13,033 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 11:29:13,046 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/32epoch.pth
[ALab02:0/2] 2023-07-23 11:29:13,047 (trainer:272) INFO: 44/50epoch started. Estimated time to finish: 18 hours, 49 minutes and 9.03 seconds
[ALab02:0/2] 2023-07-23 11:37:03,842 (trainer:721) INFO: 44epoch:train:1-908batch: iter_time=0.001, forward_time=0.153, loss_ctc=0.911, loss=0.456, backward_time=0.226, optim_step_time=0.037, optim0_lr0=1.959e-04, train_time=2.074
[ALab02:0/2] 2023-07-23 11:44:46,060 (trainer:721) INFO: 44epoch:train:909-1816batch: iter_time=2.366e-04, forward_time=0.153, loss_ctc=0.889, loss=0.444, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.957e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 11:52:25,307 (trainer:721) INFO: 44epoch:train:1817-2724batch: iter_time=2.295e-04, forward_time=0.152, loss_ctc=0.912, loss=0.456, backward_time=0.225, optim_step_time=0.036, optim0_lr0=1.956e-04, train_time=2.023
[ALab02:0/2] 2023-07-23 12:00:06,248 (trainer:721) INFO: 44epoch:train:2725-3632batch: iter_time=2.330e-04, forward_time=0.153, loss_ctc=0.884, loss=0.442, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.955e-04, train_time=2.030
[ALab02:0/2] 2023-07-23 12:07:46,318 (trainer:721) INFO: 44epoch:train:3633-4540batch: iter_time=2.316e-04, forward_time=0.152, loss_ctc=0.884, loss=0.442, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.954e-04, train_time=2.027
[ALab02:0/2] 2023-07-23 12:15:29,115 (trainer:721) INFO: 44epoch:train:4541-5448batch: iter_time=2.427e-04, forward_time=0.154, loss_ctc=0.858, loss=0.429, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.953e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 12:23:10,273 (trainer:721) INFO: 44epoch:train:5449-6356batch: iter_time=2.318e-04, forward_time=0.153, loss_ctc=0.905, loss=0.452, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.952e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 12:30:51,906 (trainer:721) INFO: 44epoch:train:6357-7264batch: iter_time=2.245e-04, forward_time=0.153, loss_ctc=0.896, loss=0.448, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.951e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 12:38:34,884 (trainer:721) INFO: 44epoch:train:7265-8172batch: iter_time=2.257e-04, forward_time=0.154, loss_ctc=0.888, loss=0.444, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.950e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 12:46:16,187 (trainer:721) INFO: 44epoch:train:8173-9080batch: iter_time=2.287e-04, forward_time=0.153, loss_ctc=0.873, loss=0.437, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.948e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 12:53:58,112 (trainer:721) INFO: 44epoch:train:9081-9988batch: iter_time=2.249e-04, forward_time=0.153, loss_ctc=0.897, loss=0.448, backward_time=0.227, optim_step_time=0.035, optim0_lr0=1.947e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 13:01:39,171 (trainer:721) INFO: 44epoch:train:9989-10896batch: iter_time=2.264e-04, forward_time=0.153, loss_ctc=0.882, loss=0.441, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.946e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 13:09:21,291 (trainer:721) INFO: 44epoch:train:10897-11804batch: iter_time=2.328e-04, forward_time=0.154, loss_ctc=0.904, loss=0.452, backward_time=0.227, optim_step_time=0.036, optim0_lr0=1.945e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 13:17:02,023 (trainer:721) INFO: 44epoch:train:11805-12712batch: iter_time=2.240e-04, forward_time=0.152, loss_ctc=0.892, loss=0.446, backward_time=0.226, optim_step_time=0.036, optim0_lr0=1.944e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 13:24:44,761 (trainer:721) INFO: 44epoch:train:12713-13620batch: iter_time=2.218e-04, forward_time=0.153, loss_ctc=0.884, loss=0.442, backward_time=0.227, optim_step_time=0.037, optim0_lr0=1.943e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 13:32:26,158 (trainer:721) INFO: 44epoch:train:13621-14528batch: iter_time=2.291e-04, forward_time=0.153, loss_ctc=0.882, loss=0.441, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.942e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 13:40:07,215 (trainer:721) INFO: 44epoch:train:14529-15436batch: iter_time=2.344e-04, forward_time=0.154, loss_ctc=0.919, loss=0.459, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.941e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 13:47:49,168 (trainer:721) INFO: 44epoch:train:15437-16344batch: iter_time=2.509e-04, forward_time=0.154, loss_ctc=0.893, loss=0.446, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.940e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 13:55:30,713 (trainer:721) INFO: 44epoch:train:16345-17252batch: iter_time=2.354e-04, forward_time=0.154, loss_ctc=0.907, loss=0.453, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.938e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 14:03:14,396 (trainer:721) INFO: 44epoch:train:17253-18160batch: iter_time=2.411e-04, forward_time=0.155, loss_ctc=0.902, loss=0.451, backward_time=0.227, optim_step_time=0.033, optim0_lr0=1.937e-04, train_time=2.042
[ALab02:0/2] 2023-07-23 14:04:10,719 (trainer:338) INFO: 44epoch results: [train] iter_time=2.708e-04, forward_time=0.153, loss_ctc=0.893, loss=0.447, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.948e-04, train_time=2.035, time=2 hours, 34 minutes and 11.08 seconds, total_count=799744, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.526, cer_ctc=0.056, cer=0.056, loss=1.763, time=7.62 seconds, total_count=660, gpu_max_cached_mem_GB=42.223, [att_plot] time=38.97 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 14:04:14,226 (trainer:386) INFO: The best model has been updated: valid.cer
[ALab02:0/2] 2023-07-23 14:04:14,228 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/29epoch.pth
[ALab02:0/2] 2023-07-23 14:04:14,228 (trainer:272) INFO: 45/50epoch started. Estimated time to finish: 16 hours, 6 minutes and 59.15 seconds
[ALab02:0/2] 2023-07-23 14:12:05,949 (trainer:721) INFO: 45epoch:train:1-908batch: iter_time=0.001, forward_time=0.153, loss_ctc=0.855, loss=0.427, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.936e-04, train_time=2.078
[ALab02:0/2] 2023-07-23 14:19:50,646 (trainer:721) INFO: 45epoch:train:909-1816batch: iter_time=2.444e-04, forward_time=0.155, loss_ctc=0.842, loss=0.421, backward_time=0.228, optim_step_time=0.033, optim0_lr0=1.935e-04, train_time=2.047
[ALab02:0/2] 2023-07-23 14:27:32,992 (trainer:721) INFO: 45epoch:train:1817-2724batch: iter_time=2.491e-04, forward_time=0.154, loss_ctc=0.900, loss=0.450, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.934e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 14:35:15,299 (trainer:721) INFO: 45epoch:train:2725-3632batch: iter_time=2.391e-04, forward_time=0.154, loss_ctc=0.880, loss=0.440, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.933e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 14:43:00,643 (trainer:721) INFO: 45epoch:train:3633-4540batch: iter_time=2.406e-04, forward_time=0.155, loss_ctc=0.862, loss=0.431, backward_time=0.228, optim_step_time=0.033, optim0_lr0=1.932e-04, train_time=2.050
[ALab02:0/2] 2023-07-23 14:50:41,811 (trainer:721) INFO: 45epoch:train:4541-5448batch: iter_time=2.339e-04, forward_time=0.153, loss_ctc=0.878, loss=0.439, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.931e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 14:58:23,767 (trainer:721) INFO: 45epoch:train:5449-6356batch: iter_time=2.418e-04, forward_time=0.154, loss_ctc=0.872, loss=0.436, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.930e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 15:06:06,220 (trainer:721) INFO: 45epoch:train:6357-7264batch: iter_time=2.355e-04, forward_time=0.154, loss_ctc=0.913, loss=0.457, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.929e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 15:13:48,326 (trainer:721) INFO: 45epoch:train:7265-8172batch: iter_time=2.431e-04, forward_time=0.154, loss_ctc=0.923, loss=0.462, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.928e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 15:21:31,345 (trainer:721) INFO: 45epoch:train:8173-9080batch: iter_time=2.396e-04, forward_time=0.154, loss_ctc=0.905, loss=0.453, backward_time=0.227, optim_step_time=0.033, optim0_lr0=1.926e-04, train_time=2.040
[ALab02:0/2] 2023-07-23 15:29:13,971 (trainer:721) INFO: 45epoch:train:9081-9988batch: iter_time=2.434e-04, forward_time=0.154, loss_ctc=0.896, loss=0.448, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.925e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 15:36:56,810 (trainer:721) INFO: 45epoch:train:9989-10896batch: iter_time=2.421e-04, forward_time=0.154, loss_ctc=0.863, loss=0.431, backward_time=0.227, optim_step_time=0.033, optim0_lr0=1.924e-04, train_time=2.039
[ALab02:0/2] 2023-07-23 15:44:38,955 (trainer:721) INFO: 45epoch:train:10897-11804batch: iter_time=2.455e-04, forward_time=0.154, loss_ctc=0.889, loss=0.445, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.923e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 15:52:20,059 (trainer:721) INFO: 45epoch:train:11805-12712batch: iter_time=2.367e-04, forward_time=0.154, loss_ctc=0.919, loss=0.460, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.922e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 16:00:00,750 (trainer:721) INFO: 45epoch:train:12713-13620batch: iter_time=2.326e-04, forward_time=0.153, loss_ctc=0.889, loss=0.445, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.921e-04, train_time=2.029
[ALab02:0/2] 2023-07-23 16:07:40,284 (trainer:721) INFO: 45epoch:train:13621-14528batch: iter_time=2.330e-04, forward_time=0.153, loss_ctc=0.889, loss=0.444, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.920e-04, train_time=2.024
[ALab02:0/2] 2023-07-23 16:15:21,856 (trainer:721) INFO: 45epoch:train:14529-15436batch: iter_time=2.319e-04, forward_time=0.154, loss_ctc=0.854, loss=0.427, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.919e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 16:23:05,189 (trainer:721) INFO: 45epoch:train:15437-16344batch: iter_time=2.334e-04, forward_time=0.154, loss_ctc=0.878, loss=0.439, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.918e-04, train_time=2.041
[ALab02:0/2] 2023-07-23 16:30:50,041 (trainer:721) INFO: 45epoch:train:16345-17252batch: iter_time=2.313e-04, forward_time=0.155, loss_ctc=0.886, loss=0.443, backward_time=0.228, optim_step_time=0.033, optim0_lr0=1.917e-04, train_time=2.048
[ALab02:0/2] 2023-07-23 16:38:34,130 (trainer:721) INFO: 45epoch:train:17253-18160batch: iter_time=2.365e-04, forward_time=0.155, loss_ctc=0.890, loss=0.445, backward_time=0.227, optim_step_time=0.033, optim0_lr0=1.916e-04, train_time=2.044
[ALab02:0/2] 2023-07-23 16:39:28,454 (trainer:338) INFO: 45epoch results: [train] iter_time=2.823e-04, forward_time=0.154, loss_ctc=0.884, loss=0.442, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.926e-04, train_time=2.039, time=2 hours, 34 minutes and 29.04 seconds, total_count=817920, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.621, cer_ctc=0.059, cer=0.059, loss=1.811, time=6.33 seconds, total_count=675, gpu_max_cached_mem_GB=42.223, [att_plot] time=38.86 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 16:39:32,257 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 16:39:32,258 (trainer:272) INFO: 46/50epoch started. Estimated time to finish: 13 hours, 25 minutes and 10.2 seconds
[ALab02:0/2] 2023-07-23 16:47:24,154 (trainer:721) INFO: 46epoch:train:1-908batch: iter_time=0.001, forward_time=0.154, loss_ctc=0.878, loss=0.439, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.915e-04, train_time=2.079
[ALab02:0/2] 2023-07-23 16:55:09,108 (trainer:721) INFO: 46epoch:train:909-1816batch: iter_time=2.404e-04, forward_time=0.154, loss_ctc=0.887, loss=0.444, backward_time=0.228, optim_step_time=0.033, optim0_lr0=1.914e-04, train_time=2.048
[ALab02:0/2] 2023-07-23 17:02:49,038 (trainer:721) INFO: 46epoch:train:1817-2724batch: iter_time=2.392e-04, forward_time=0.152, loss_ctc=0.872, loss=0.436, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.913e-04, train_time=2.026
[ALab02:0/2] 2023-07-23 17:10:29,057 (trainer:721) INFO: 46epoch:train:2725-3632batch: iter_time=2.227e-04, forward_time=0.152, loss_ctc=0.872, loss=0.436, backward_time=0.225, optim_step_time=0.033, optim0_lr0=1.911e-04, train_time=2.026
[ALab02:0/2] 2023-07-23 17:18:10,046 (trainer:721) INFO: 46epoch:train:3633-4540batch: iter_time=2.336e-04, forward_time=0.153, loss_ctc=0.851, loss=0.425, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.910e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 17:25:51,939 (trainer:721) INFO: 46epoch:train:4541-5448batch: iter_time=2.394e-04, forward_time=0.153, loss_ctc=0.834, loss=0.417, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.909e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 17:33:36,887 (trainer:721) INFO: 46epoch:train:5449-6356batch: iter_time=2.488e-04, forward_time=0.155, loss_ctc=0.836, loss=0.418, backward_time=0.228, optim_step_time=0.034, optim0_lr0=1.908e-04, train_time=2.048
[ALab02:0/2] 2023-07-23 17:41:19,278 (trainer:721) INFO: 46epoch:train:6357-7264batch: iter_time=2.374e-04, forward_time=0.153, loss_ctc=0.834, loss=0.417, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.907e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 17:49:00,482 (trainer:721) INFO: 46epoch:train:7265-8172batch: iter_time=2.397e-04, forward_time=0.154, loss_ctc=0.867, loss=0.433, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.906e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 17:56:42,925 (trainer:721) INFO: 46epoch:train:8173-9080batch: iter_time=2.382e-04, forward_time=0.154, loss_ctc=0.877, loss=0.439, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.905e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 18:04:23,376 (trainer:721) INFO: 46epoch:train:9081-9988batch: iter_time=2.489e-04, forward_time=0.153, loss_ctc=0.862, loss=0.431, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.904e-04, train_time=2.028
[ALab02:0/2] 2023-07-23 18:12:04,529 (trainer:721) INFO: 46epoch:train:9989-10896batch: iter_time=2.423e-04, forward_time=0.153, loss_ctc=0.878, loss=0.439, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.903e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 18:19:44,871 (trainer:721) INFO: 46epoch:train:10897-11804batch: iter_time=2.374e-04, forward_time=0.153, loss_ctc=0.869, loss=0.434, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.902e-04, train_time=2.028
[ALab02:0/2] 2023-07-23 18:27:24,789 (trainer:721) INFO: 46epoch:train:11805-12712batch: iter_time=2.413e-04, forward_time=0.153, loss_ctc=0.873, loss=0.436, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.901e-04, train_time=2.026
[ALab02:0/2] 2023-07-23 18:35:05,598 (trainer:721) INFO: 46epoch:train:12713-13620batch: iter_time=2.433e-04, forward_time=0.153, loss_ctc=0.871, loss=0.435, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.900e-04, train_time=2.030
[ALab02:0/2] 2023-07-23 18:42:48,246 (trainer:721) INFO: 46epoch:train:13621-14528batch: iter_time=2.509e-04, forward_time=0.154, loss_ctc=0.860, loss=0.430, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.899e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 18:50:27,693 (trainer:721) INFO: 46epoch:train:14529-15436batch: iter_time=2.331e-04, forward_time=0.153, loss_ctc=0.887, loss=0.444, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.898e-04, train_time=2.024
[ALab02:0/2] 2023-07-23 18:58:09,393 (trainer:721) INFO: 46epoch:train:15437-16344batch: iter_time=2.340e-04, forward_time=0.153, loss_ctc=0.878, loss=0.439, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.897e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 19:05:51,653 (trainer:721) INFO: 46epoch:train:16345-17252batch: iter_time=2.396e-04, forward_time=0.153, loss_ctc=0.875, loss=0.437, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.896e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 19:13:33,264 (trainer:721) INFO: 46epoch:train:17253-18160batch: iter_time=2.390e-04, forward_time=0.154, loss_ctc=0.875, loss=0.437, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.895e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 19:14:27,730 (trainer:338) INFO: 46epoch results: [train] iter_time=2.788e-04, forward_time=0.153, loss_ctc=0.867, loss=0.433, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.905e-04, train_time=2.035, time=2 hours, 34 minutes and 10.25 seconds, total_count=836096, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.604, cer_ctc=0.057, cer=0.057, loss=1.802, time=6.24 seconds, total_count=690, gpu_max_cached_mem_GB=42.223, [att_plot] time=38.98 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 19:14:31,527 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 19:14:31,567 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/36epoch.pth, exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/45epoch.pth
[ALab02:0/2] 2023-07-23 19:14:31,568 (trainer:272) INFO: 47/50epoch started. Estimated time to finish: 10 hours, 43 minutes and 36.62 seconds
[ALab02:0/2] 2023-07-23 19:22:21,123 (trainer:721) INFO: 47epoch:train:1-908batch: iter_time=7.893e-04, forward_time=0.153, loss_ctc=0.847, loss=0.424, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.894e-04, train_time=2.068
[ALab02:0/2] 2023-07-23 19:30:02,132 (trainer:721) INFO: 47epoch:train:909-1816batch: iter_time=2.396e-04, forward_time=0.153, loss_ctc=0.859, loss=0.430, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.893e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 19:37:45,804 (trainer:721) INFO: 47epoch:train:1817-2724batch: iter_time=2.445e-04, forward_time=0.154, loss_ctc=0.860, loss=0.430, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.892e-04, train_time=2.042
[ALab02:0/2] 2023-07-23 19:45:27,279 (trainer:721) INFO: 47epoch:train:2725-3632batch: iter_time=2.429e-04, forward_time=0.153, loss_ctc=0.844, loss=0.422, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.891e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 19:53:08,445 (trainer:721) INFO: 47epoch:train:3633-4540batch: iter_time=2.414e-04, forward_time=0.153, loss_ctc=0.852, loss=0.426, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.890e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 20:00:48,566 (trainer:721) INFO: 47epoch:train:4541-5448batch: iter_time=2.415e-04, forward_time=0.152, loss_ctc=0.868, loss=0.434, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.889e-04, train_time=2.027
[ALab02:0/2] 2023-07-23 20:08:27,993 (trainer:721) INFO: 47epoch:train:5449-6356batch: iter_time=2.473e-04, forward_time=0.153, loss_ctc=0.866, loss=0.433, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.888e-04, train_time=2.024
[ALab02:0/2] 2023-07-23 20:16:09,883 (trainer:721) INFO: 47epoch:train:6357-7264batch: iter_time=2.389e-04, forward_time=0.153, loss_ctc=0.862, loss=0.431, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.887e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 20:23:50,927 (trainer:721) INFO: 47epoch:train:7265-8172batch: iter_time=2.344e-04, forward_time=0.153, loss_ctc=0.866, loss=0.433, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.886e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 20:31:33,108 (trainer:721) INFO: 47epoch:train:8173-9080batch: iter_time=2.405e-04, forward_time=0.153, loss_ctc=0.852, loss=0.426, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.885e-04, train_time=2.036
[ALab02:0/2] 2023-07-23 20:39:14,635 (trainer:721) INFO: 47epoch:train:9081-9988batch: iter_time=2.372e-04, forward_time=0.153, loss_ctc=0.882, loss=0.441, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.884e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 20:46:55,760 (trainer:721) INFO: 47epoch:train:9989-10896batch: iter_time=2.392e-04, forward_time=0.153, loss_ctc=0.842, loss=0.421, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.883e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 20:54:37,577 (trainer:721) INFO: 47epoch:train:10897-11804batch: iter_time=2.398e-04, forward_time=0.154, loss_ctc=0.847, loss=0.423, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.881e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 21:02:19,126 (trainer:721) INFO: 47epoch:train:11805-12712batch: iter_time=2.331e-04, forward_time=0.153, loss_ctc=0.846, loss=0.423, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.880e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 21:10:01,109 (trainer:721) INFO: 47epoch:train:12713-13620batch: iter_time=2.408e-04, forward_time=0.153, loss_ctc=0.845, loss=0.423, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.879e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 21:17:42,657 (trainer:721) INFO: 47epoch:train:13621-14528batch: iter_time=2.474e-04, forward_time=0.153, loss_ctc=0.887, loss=0.444, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.878e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 21:25:21,247 (trainer:721) INFO: 47epoch:train:14529-15436batch: iter_time=2.360e-04, forward_time=0.152, loss_ctc=0.874, loss=0.437, backward_time=0.224, optim_step_time=0.034, optim0_lr0=1.877e-04, train_time=2.020
[ALab02:0/2] 2023-07-23 21:33:03,019 (trainer:721) INFO: 47epoch:train:15437-16344batch: iter_time=2.494e-04, forward_time=0.153, loss_ctc=0.838, loss=0.419, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.876e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 21:40:44,435 (trainer:721) INFO: 47epoch:train:16345-17252batch: iter_time=2.588e-04, forward_time=0.153, loss_ctc=0.854, loss=0.427, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.875e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 21:48:27,027 (trainer:721) INFO: 47epoch:train:17253-18160batch: iter_time=2.387e-04, forward_time=0.154, loss_ctc=0.849, loss=0.425, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.874e-04, train_time=2.038
[ALab02:0/2] 2023-07-23 21:49:22,119 (trainer:338) INFO: 47epoch results: [train] iter_time=2.690e-04, forward_time=0.153, loss_ctc=0.857, loss=0.429, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.884e-04, train_time=2.034, time=2 hours, 34 minutes and 4.73 seconds, total_count=854272, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.607, cer_ctc=0.056, cer=0.056, loss=1.804, time=6.41 seconds, total_count=705, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.4 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-23 21:49:26,058 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-23 21:49:26,059 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/43epoch.pth
[ALab02:0/2] 2023-07-23 21:49:26,059 (trainer:272) INFO: 48/50epoch started. Estimated time to finish: 8 hours, 2 minutes and 19.51 seconds
[ALab02:0/2] 2023-07-23 21:57:15,126 (trainer:721) INFO: 48epoch:train:1-908batch: iter_time=6.205e-04, forward_time=0.152, loss_ctc=0.840, loss=0.420, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.873e-04, train_time=2.066
[ALab02:0/2] 2023-07-23 22:04:56,195 (trainer:721) INFO: 48epoch:train:909-1816batch: iter_time=2.563e-04, forward_time=0.153, loss_ctc=0.833, loss=0.417, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.872e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 22:12:37,990 (trainer:721) INFO: 48epoch:train:1817-2724batch: iter_time=2.418e-04, forward_time=0.153, loss_ctc=0.829, loss=0.414, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.871e-04, train_time=2.034
[ALab02:0/2] 2023-07-23 22:20:18,793 (trainer:721) INFO: 48epoch:train:2725-3632batch: iter_time=2.453e-04, forward_time=0.153, loss_ctc=0.872, loss=0.436, backward_time=0.225, optim_step_time=0.035, optim0_lr0=1.870e-04, train_time=2.030
[ALab02:0/2] 2023-07-23 22:27:59,974 (trainer:721) INFO: 48epoch:train:3633-4540batch: iter_time=2.458e-04, forward_time=0.153, loss_ctc=0.866, loss=0.433, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.869e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 22:35:41,373 (trainer:721) INFO: 48epoch:train:4541-5448batch: iter_time=2.443e-04, forward_time=0.153, loss_ctc=0.832, loss=0.416, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.869e-04, train_time=2.032
[ALab02:0/2] 2023-07-23 22:43:22,831 (trainer:721) INFO: 48epoch:train:5449-6356batch: iter_time=2.399e-04, forward_time=0.153, loss_ctc=0.835, loss=0.418, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.868e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 22:51:03,958 (trainer:721) INFO: 48epoch:train:6357-7264batch: iter_time=2.419e-04, forward_time=0.153, loss_ctc=0.827, loss=0.414, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.867e-04, train_time=2.031
[ALab02:0/2] 2023-07-23 22:58:46,372 (trainer:721) INFO: 48epoch:train:7265-8172batch: iter_time=2.348e-04, forward_time=0.153, loss_ctc=0.839, loss=0.420, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.866e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 23:06:26,664 (trainer:721) INFO: 48epoch:train:8173-9080batch: iter_time=2.366e-04, forward_time=0.153, loss_ctc=0.842, loss=0.421, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.865e-04, train_time=2.028
[ALab02:0/2] 2023-07-23 23:14:08,155 (trainer:721) INFO: 48epoch:train:9081-9988batch: iter_time=2.436e-04, forward_time=0.153, loss_ctc=0.842, loss=0.421, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.864e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 23:21:50,679 (trainer:721) INFO: 48epoch:train:9989-10896batch: iter_time=2.436e-04, forward_time=0.154, loss_ctc=0.815, loss=0.407, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.863e-04, train_time=2.037
[ALab02:0/2] 2023-07-23 23:29:32,710 (trainer:721) INFO: 48epoch:train:10897-11804batch: iter_time=2.333e-04, forward_time=0.153, loss_ctc=0.823, loss=0.411, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.862e-04, train_time=2.035
[ALab02:0/2] 2023-07-23 23:37:12,850 (trainer:721) INFO: 48epoch:train:11805-12712batch: iter_time=2.383e-04, forward_time=0.153, loss_ctc=0.870, loss=0.435, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.861e-04, train_time=2.027
[ALab02:0/2] 2023-07-23 23:44:54,317 (trainer:721) INFO: 48epoch:train:12713-13620batch: iter_time=2.365e-04, forward_time=0.153, loss_ctc=0.845, loss=0.422, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.860e-04, train_time=2.033
[ALab02:0/2] 2023-07-23 23:52:35,667 (trainer:721) INFO: 48epoch:train:13621-14528batch: iter_time=2.380e-04, forward_time=0.153, loss_ctc=0.840, loss=0.420, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.859e-04, train_time=2.032
[ALab02:0/2] 2023-07-24 00:00:16,571 (trainer:721) INFO: 48epoch:train:14529-15436batch: iter_time=2.325e-04, forward_time=0.153, loss_ctc=0.833, loss=0.417, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.858e-04, train_time=2.030
[ALab02:0/2] 2023-07-24 00:07:58,020 (trainer:721) INFO: 48epoch:train:15437-16344batch: iter_time=2.433e-04, forward_time=0.153, loss_ctc=0.855, loss=0.428, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.857e-04, train_time=2.033
[ALab02:0/2] 2023-07-24 00:15:37,932 (trainer:721) INFO: 48epoch:train:16345-17252batch: iter_time=2.447e-04, forward_time=0.152, loss_ctc=0.856, loss=0.428, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.856e-04, train_time=2.026
[ALab02:0/2] 2023-07-24 00:23:18,476 (trainer:721) INFO: 48epoch:train:17253-18160batch: iter_time=2.451e-04, forward_time=0.153, loss_ctc=0.823, loss=0.412, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.855e-04, train_time=2.029
[ALab02:0/2] 2023-07-24 00:24:15,131 (trainer:338) INFO: 48epoch results: [train] iter_time=2.603e-04, forward_time=0.153, loss_ctc=0.841, loss=0.421, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.864e-04, train_time=2.033, time=2 hours, 34 minutes and 1.82 seconds, total_count=872448, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=4.125, cer_ctc=0.060, cer=0.060, loss=2.063, time=6.72 seconds, total_count=720, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.52 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-24 00:24:19,870 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-24 00:24:19,871 (trainer:272) INFO: 49/50epoch started. Estimated time to finish: 5 hours, 21 minutes and 18.31 seconds
[ALab02:0/2] 2023-07-24 00:32:07,908 (trainer:721) INFO: 49epoch:train:1-908batch: iter_time=6.236e-04, forward_time=0.152, loss_ctc=0.823, loss=0.411, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.854e-04, train_time=2.062
[ALab02:0/2] 2023-07-24 00:39:49,487 (trainer:721) INFO: 49epoch:train:909-1816batch: iter_time=2.473e-04, forward_time=0.153, loss_ctc=0.832, loss=0.416, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.853e-04, train_time=2.033
[ALab02:0/2] 2023-07-24 00:47:31,187 (trainer:721) INFO: 49epoch:train:1817-2724batch: iter_time=2.400e-04, forward_time=0.153, loss_ctc=0.841, loss=0.420, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.852e-04, train_time=2.034
[ALab02:0/2] 2023-07-24 00:55:14,364 (trainer:721) INFO: 49epoch:train:2725-3632batch: iter_time=2.325e-04, forward_time=0.154, loss_ctc=0.829, loss=0.414, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.851e-04, train_time=2.040
[ALab02:0/2] 2023-07-24 01:02:57,025 (trainer:721) INFO: 49epoch:train:3633-4540batch: iter_time=2.308e-04, forward_time=0.153, loss_ctc=0.807, loss=0.403, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.850e-04, train_time=2.038
[ALab02:0/2] 2023-07-24 01:10:40,420 (trainer:721) INFO: 49epoch:train:4541-5448batch: iter_time=2.342e-04, forward_time=0.154, loss_ctc=0.797, loss=0.398, backward_time=0.227, optim_step_time=0.035, optim0_lr0=1.849e-04, train_time=2.041
[ALab02:0/2] 2023-07-24 01:18:20,510 (trainer:721) INFO: 49epoch:train:5449-6356batch: iter_time=2.327e-04, forward_time=0.152, loss_ctc=0.821, loss=0.410, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.848e-04, train_time=2.027
[ALab02:0/2] 2023-07-24 01:26:02,515 (trainer:721) INFO: 49epoch:train:6357-7264batch: iter_time=2.430e-04, forward_time=0.153, loss_ctc=0.819, loss=0.409, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.847e-04, train_time=2.035
[ALab02:0/2] 2023-07-24 01:33:42,567 (trainer:721) INFO: 49epoch:train:7265-8172batch: iter_time=2.355e-04, forward_time=0.152, loss_ctc=0.815, loss=0.407, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.846e-04, train_time=2.026
[ALab02:0/2] 2023-07-24 01:41:25,348 (trainer:721) INFO: 49epoch:train:8173-9080batch: iter_time=2.332e-04, forward_time=0.154, loss_ctc=0.818, loss=0.409, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.845e-04, train_time=2.038
[ALab02:0/2] 2023-07-24 01:49:07,467 (trainer:721) INFO: 49epoch:train:9081-9988batch: iter_time=2.485e-04, forward_time=0.154, loss_ctc=0.837, loss=0.419, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.844e-04, train_time=2.036
[ALab02:0/2] 2023-07-24 01:56:51,660 (trainer:721) INFO: 49epoch:train:9989-10896batch: iter_time=2.397e-04, forward_time=0.154, loss_ctc=0.783, loss=0.392, backward_time=0.228, optim_step_time=0.033, optim0_lr0=1.843e-04, train_time=2.045
[ALab02:0/2] 2023-07-24 02:04:32,535 (trainer:721) INFO: 49epoch:train:10897-11804batch: iter_time=2.406e-04, forward_time=0.153, loss_ctc=0.805, loss=0.402, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.842e-04, train_time=2.030
[ALab02:0/2] 2023-07-24 02:12:12,874 (trainer:721) INFO: 49epoch:train:11805-12712batch: iter_time=2.362e-04, forward_time=0.153, loss_ctc=0.845, loss=0.423, backward_time=0.226, optim_step_time=0.033, optim0_lr0=1.841e-04, train_time=2.028
[ALab02:0/2] 2023-07-24 02:19:53,927 (trainer:721) INFO: 49epoch:train:12713-13620batch: iter_time=2.382e-04, forward_time=0.153, loss_ctc=0.816, loss=0.408, backward_time=0.226, optim_step_time=0.035, optim0_lr0=1.841e-04, train_time=2.031
[ALab02:0/2] 2023-07-24 02:27:33,269 (trainer:721) INFO: 49epoch:train:13621-14528batch: iter_time=2.414e-04, forward_time=0.152, loss_ctc=0.797, loss=0.398, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.840e-04, train_time=2.023
[ALab02:0/2] 2023-07-24 02:35:13,310 (trainer:721) INFO: 49epoch:train:14529-15436batch: iter_time=2.420e-04, forward_time=0.152, loss_ctc=0.835, loss=0.417, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.839e-04, train_time=2.026
[ALab02:0/2] 2023-07-24 02:42:55,582 (trainer:721) INFO: 49epoch:train:15437-16344batch: iter_time=2.420e-04, forward_time=0.153, loss_ctc=0.815, loss=0.408, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.838e-04, train_time=2.036
[ALab02:0/2] 2023-07-24 02:50:36,638 (trainer:721) INFO: 49epoch:train:16345-17252batch: iter_time=2.425e-04, forward_time=0.153, loss_ctc=0.829, loss=0.414, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.837e-04, train_time=2.031
[ALab02:0/2] 2023-07-24 02:58:18,421 (trainer:721) INFO: 49epoch:train:17253-18160batch: iter_time=2.441e-04, forward_time=0.153, loss_ctc=0.824, loss=0.412, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.836e-04, train_time=2.034
[ALab02:0/2] 2023-07-24 02:59:13,230 (trainer:338) INFO: 49epoch results: [train] iter_time=2.584e-04, forward_time=0.153, loss_ctc=0.819, loss=0.410, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.845e-04, train_time=2.035, time=2 hours, 34 minutes and 7.68 seconds, total_count=890624, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.586, cer_ctc=0.058, cer=0.058, loss=1.793, time=6.4 seconds, total_count=735, gpu_max_cached_mem_GB=42.223, [att_plot] time=39.29 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-24 02:59:18,505 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-24 02:59:18,547 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/40epoch.pth, exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/48epoch.pth
[ALab02:0/2] 2023-07-24 02:59:18,547 (trainer:272) INFO: 50/50epoch started. Estimated time to finish: 2 hours, 40 minutes and 32.21 seconds
[ALab02:0/2] 2023-07-24 03:07:09,038 (trainer:721) INFO: 50epoch:train:1-908batch: iter_time=0.001, forward_time=0.153, loss_ctc=0.809, loss=0.405, backward_time=0.225, optim_step_time=0.035, optim0_lr0=1.835e-04, train_time=2.072
[ALab02:0/2] 2023-07-24 03:14:50,375 (trainer:721) INFO: 50epoch:train:909-1816batch: iter_time=2.524e-04, forward_time=0.153, loss_ctc=0.807, loss=0.404, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.834e-04, train_time=2.032
[ALab02:0/2] 2023-07-24 03:22:30,012 (trainer:721) INFO: 50epoch:train:1817-2724batch: iter_time=2.370e-04, forward_time=0.152, loss_ctc=0.807, loss=0.403, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.833e-04, train_time=2.025
[ALab02:0/2] 2023-07-24 03:30:11,742 (trainer:721) INFO: 50epoch:train:2725-3632batch: iter_time=2.417e-04, forward_time=0.153, loss_ctc=0.819, loss=0.409, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.832e-04, train_time=2.034
[ALab02:0/2] 2023-07-24 03:37:53,214 (trainer:721) INFO: 50epoch:train:3633-4540batch: iter_time=2.432e-04, forward_time=0.153, loss_ctc=0.825, loss=0.412, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.831e-04, train_time=2.033
[ALab02:0/2] 2023-07-24 03:45:32,586 (trainer:721) INFO: 50epoch:train:4541-5448batch: iter_time=2.397e-04, forward_time=0.152, loss_ctc=0.840, loss=0.420, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.830e-04, train_time=2.023
[ALab02:0/2] 2023-07-24 03:53:15,638 (trainer:721) INFO: 50epoch:train:5449-6356batch: iter_time=2.461e-04, forward_time=0.154, loss_ctc=0.806, loss=0.403, backward_time=0.227, optim_step_time=0.035, optim0_lr0=1.829e-04, train_time=2.040
[ALab02:0/2] 2023-07-24 04:00:57,548 (trainer:721) INFO: 50epoch:train:6357-7264batch: iter_time=2.390e-04, forward_time=0.153, loss_ctc=0.826, loss=0.413, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.828e-04, train_time=2.035
[ALab02:0/2] 2023-07-24 04:08:38,711 (trainer:721) INFO: 50epoch:train:7265-8172batch: iter_time=2.438e-04, forward_time=0.153, loss_ctc=0.822, loss=0.411, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.827e-04, train_time=2.031
[ALab02:0/2] 2023-07-24 04:16:19,438 (trainer:721) INFO: 50epoch:train:8173-9080batch: iter_time=2.387e-04, forward_time=0.153, loss_ctc=0.814, loss=0.407, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.826e-04, train_time=2.029
[ALab02:0/2] 2023-07-24 04:24:01,906 (trainer:721) INFO: 50epoch:train:9081-9988batch: iter_time=2.432e-04, forward_time=0.154, loss_ctc=0.809, loss=0.405, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.826e-04, train_time=2.037
[ALab02:0/2] 2023-07-24 04:31:44,624 (trainer:721) INFO: 50epoch:train:9989-10896batch: iter_time=2.436e-04, forward_time=0.154, loss_ctc=0.835, loss=0.418, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.825e-04, train_time=2.038
[ALab02:0/2] 2023-07-24 04:39:26,094 (trainer:721) INFO: 50epoch:train:10897-11804batch: iter_time=2.403e-04, forward_time=0.153, loss_ctc=0.845, loss=0.423, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.824e-04, train_time=2.033
[ALab02:0/2] 2023-07-24 04:47:08,723 (trainer:721) INFO: 50epoch:train:11805-12712batch: iter_time=2.458e-04, forward_time=0.154, loss_ctc=0.817, loss=0.409, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.823e-04, train_time=2.038
[ALab02:0/2] 2023-07-24 04:54:48,379 (trainer:721) INFO: 50epoch:train:12713-13620batch: iter_time=2.480e-04, forward_time=0.153, loss_ctc=0.842, loss=0.421, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.822e-04, train_time=2.025
[ALab02:0/2] 2023-07-24 05:02:31,399 (trainer:721) INFO: 50epoch:train:13621-14528batch: iter_time=2.462e-04, forward_time=0.154, loss_ctc=0.820, loss=0.410, backward_time=0.227, optim_step_time=0.035, optim0_lr0=1.821e-04, train_time=2.040
[ALab02:0/2] 2023-07-24 05:10:12,159 (trainer:721) INFO: 50epoch:train:14529-15436batch: iter_time=2.384e-04, forward_time=0.153, loss_ctc=0.817, loss=0.408, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.820e-04, train_time=2.030
[ALab02:0/2] 2023-07-24 05:17:55,044 (trainer:721) INFO: 50epoch:train:15437-16344batch: iter_time=2.369e-04, forward_time=0.154, loss_ctc=0.814, loss=0.407, backward_time=0.227, optim_step_time=0.034, optim0_lr0=1.819e-04, train_time=2.039
[ALab02:0/2] 2023-07-24 05:25:36,604 (trainer:721) INFO: 50epoch:train:16345-17252batch: iter_time=2.437e-04, forward_time=0.153, loss_ctc=0.843, loss=0.421, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.818e-04, train_time=2.033
[ALab02:0/2] 2023-07-24 05:33:16,564 (trainer:721) INFO: 50epoch:train:17253-18160batch: iter_time=2.406e-04, forward_time=0.153, loss_ctc=0.830, loss=0.415, backward_time=0.225, optim_step_time=0.034, optim0_lr0=1.817e-04, train_time=2.026
[ALab02:0/2] 2023-07-24 05:34:11,937 (trainer:338) INFO: 50epoch results: [train] iter_time=2.859e-04, forward_time=0.153, loss_ctc=0.823, loss=0.411, backward_time=0.226, optim_step_time=0.034, optim0_lr0=1.826e-04, train_time=2.035, time=2 hours, 34 minutes and 6.99 seconds, total_count=908800, gpu_max_cached_mem_GB=42.223, [valid] loss_ctc=3.975, cer_ctc=0.059, cer=0.059, loss=1.988, time=6.35 seconds, total_count=750, gpu_max_cached_mem_GB=42.223, [att_plot] time=40.05 seconds, total_count=0, gpu_max_cached_mem_GB=42.223
[ALab02:0/2] 2023-07-24 05:34:15,883 (trainer:384) INFO: There are no improvements in this epoch
[ALab02:0/2] 2023-07-24 05:34:15,884 (trainer:440) INFO: The model files were removed: exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/37epoch.pth
[ALab02:0/2] 2023-07-24 05:34:15,885 (trainer:458) INFO: The training was finished at 50 epochs 
[ALab02:0/2] 2023-07-24 05:34:15,913 (average_nbest_models:69) INFO: Averaging 10best models: criterion="valid.cer": exp_uma_conformer_12e_718/asr_train_asr_uma_conformer_raw_zh_char_sp/valid.cer.ave_10best.pth
# Accounting: time=481331 threads=1
# Ended (code 0) at Mon Jul 24 05:34:26 CST 2023, elapsed time 481331 seconds
